<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>My Customized Papers</title><link>https://github.com/your_username/your_repo</link><description>Aggregated research papers</description><language>en-US</language><lastBuildDate>Mon, 26 Jan 2026 12:37:39 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>[cs updates on arXiv.org] ChiEngMixBench: Evaluating Large Language Models on Spontaneous and Natural Chinese-English Code-Mixed Generation</title><link>https://arxiv.org/abs/2601.16217</link><description>arXiv:2601.16217v1 Announce Type: new 
Abstract: Code-mixing is increasingly prevalent in interactions between humans and large language models, yet existing work often reduces it to a translation or convertibility problem, making it difficult to assess whether a model's switching behavior is context-appropriate and aligned with human conventions. We introduce ChiEngMixBench, the first benchmark designed to evaluate code-mixing ability in authentic community contexts, built upon a general construction pipeline that enables scalable dataset development across domains and bilingual pairs. ChiEngMixBench formulates code-mixing as a cognitive alignment problem, characterized by two complementary signals: Spontaneity and Naturalness. Empirical evaluation shows that our metrics can systematically distinguish code-mixing performance across models. Beyond benchmarking, we further uncover an implicitly emergent Terminology Layering Strategy, a phenomenon consistent with the Matrix Language Frame (MLF) theory, indicating structured cognitive alignment between multilingual large language models and human communication.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16217v1</guid></item><item><title>[cs updates on arXiv.org] M3Kang: Evaluating Multilingual Multimodal Mathematical Reasoning in Vision-Language Models</title><link>https://arxiv.org/abs/2601.16218</link><description>arXiv:2601.16218v1 Announce Type: new 
Abstract: Despite state-of-the-art vision-language models (VLMs) have demonstrated strong reasoning capabilities, their performance in multilingual mathematical reasoning remains underexplored, particularly when compared to human performance. To bridge this gap, we introduce M3Kang, the first massively multilingual, multimodal mathematical reasoning dataset for VLMs. It is derived from the Kangaroo Math Competition, the world's largest mathematics contest, which annually engages over six million participants under the age of 18 across more than 90 countries. M3Kang includes 1,747 unique multiple-choice problems organized by grade-level difficulty, with translations into 108 culturally diverse languages, some of them including diagrams essential for solving them. Using this dataset, we conduct extensive benchmarking on both closed- and open-source SOTA models. We observe that, despite recent advances, models still struggle with basic math and diagram-based reasoning, with performance scaling with language presence and model size, but not with grade level. We also find that multilingual techniques can be effectively extended to the multimodal setting, resulting in significant improvements over baseline approaches. Our analysis also incorporates performance data from over 68,000 students, enabling direct comparison with human performance. We are open-sourcing M3Kang, including the English-only subset M2Kang, along with the framework and codebase used to construct the dataset.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16218v1</guid></item><item><title>[cs updates on arXiv.org] Domain Specific Specialization in Low-Resource Settings: The Efficacy of Offline Response-Based Knowledge Distillation in Large Language Models</title><link>https://arxiv.org/abs/2601.16219</link><description>arXiv:2601.16219v1 Announce Type: new 
Abstract: Large Language Models (LLMs) excel in general tasks but often struggle with hallucinations when handling domain-specific or institutional knowledge absent from their pre-training. We present an offline response-based knowledge distillation method that develops high-accuracy specialized assistants under constrained hardware resources. We evaluate three distinct data strategies: general domain adaptation (15,000 lines), unstructured knowledge injection (2,000 lines), and a context-aware synthetic dataset (500 lines) generated by a teacher model. To minimize computational costs, we utilize the Unsloth library to optimize the Qwen-2.5-7B student model, reducing NVIDIA A100 GPU memory requirements from 40 GB to 16 GB. Experimental results demonstrate that while larger unstructured datasets suffer from persistent hallucinations, the 500-line context-aware dataset achieves a 96.7% accuracy rate and robust rejection capability. These findings validate the LIMA hypothesis, showing that data quality and structural alignment are more critical than quantity for domain adaptation in low-resource settings.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16219v1</guid></item><item><title>[cs updates on arXiv.org] Towards Latent Diffusion Suitable For Text</title><link>https://arxiv.org/abs/2601.16220</link><description>arXiv:2601.16220v1 Announce Type: new 
Abstract: Language diffusion models aim to improve sampling speed and coherence over autoregressive LLMs. We introduce Neural Flow Diffusion Models for language generation, an extension of NFDM that enables the straightforward application of continuous diffusion models to discrete state spaces. NFDM learns a multivariate forward process from the data, ensuring that the forward process and generative trajectory are a good fit for language modeling. Our model substantially reduces the likelihood gap with autoregressive models of the same size, while achieving sample quality comparable to that of previous latent diffusion models.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16220v1</guid></item><item><title>[cs updates on arXiv.org] Limits of n-gram Style Control for LLMs via Logit-Space Injection</title><link>https://arxiv.org/abs/2601.16224</link><description>arXiv:2601.16224v1 Announce Type: new 
Abstract: Large language models (LLMs) are typically personalized via prompt engineering or parameter-efficient fine-tuning such as LoRA. However, writing style can be difficult to distill into a single prompt, and LoRA fine-tuning requires computationally intensive training and infrastructure. We investigate a possible lightweight alternative: steering a frozen LLM with n-gram style priors injected in logit space at decoding time. We train an n-gram model on stylistically distinct corpora -- including Don Quixote, CNN/DailyMail news headlines, and arXiv abstracts -- constructing an interpolated 1-to-3-gram prior over next-token probabilities. During generation we modify the LLM's logits by adding a weighted sum of style log-probabilities from each n-gram order that matches the current context, scaled by a control parameter lambda in [0, 1].
  We sweep lambda and style corpora and report style perplexity under the n-gram model, base-model perplexity as a proxy for fluency, Jensen-Shannon (JS) divergence between the original and steered token distributions, and token-overlap statistics. On TinyLlama-1.1B we identify a single narrow regime (for the Don Quixote corpus at lambda=0.1) where style perplexity improves by 24.7% and base-model perplexity improves by 51.4% relative to the frozen model. Outside this regime, and for multi-author corpora such as CNN/DailyMail and arXiv abstracts, even small nonzero lambda values generally result in worse style and fluency, and larger lambda values lead to collapse with extreme perplexities and incoherent text. Logit-space injection of n-gram style priors provides lightweight, tunable style control, but it is fragile: it operates effectively only within a narrow range of low lambda values and is consistently outperformed by prompting and LoRA.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16224v1</guid></item><item><title>[cs updates on arXiv.org] SoundBreak: A Systematic Study of Audio-Only Adversarial Attacks on Trimodal Models</title><link>https://arxiv.org/abs/2601.16231</link><description>arXiv:2601.16231v1 Announce Type: new 
Abstract: Multimodal foundation models that integrate audio, vision, and language achieve strong performance on reasoning and generation tasks, yet their robustness to adversarial manipulation remains poorly understood. We study a realistic and underexplored threat model: untargeted, audio-only adversarial attacks on trimodal audio-video-language models. We analyze six complementary attack objectives that target different stages of multimodal processing, including audio encoder representations, cross-modal attention, hidden states, and output likelihoods. Across three state-of-the-art models and multiple benchmarks, we show that audio-only perturbations can induce severe multimodal failures, achieving up to 96% attack success rate. We further show that attacks can be successful at low perceptual distortions (LPIPS &lt;= 0.08, SI-SNR &gt;= 0) and benefit more from extended optimization than increased data scale. Transferability across models and encoders remains limited, while speech recognition systems such as Whisper primarily respond to perturbation magnitude, achieving &gt;97% attack success under severe distortion. These results expose a previously overlooked single-modality attack surface in multimodal systems and motivate defenses that enforce cross-modal consistency.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16231v1</guid></item><item><title>[cs updates on arXiv.org] Policy-Embedded Graph Expansion: Networked HIV Testing with Diffusion-Driven Network Samples</title><link>https://arxiv.org/abs/2601.16233</link><description>arXiv:2601.16233v1 Announce Type: new 
Abstract: HIV is a retrovirus that attacks the human immune system and can lead to death without proper treatment. In collaboration with the WHO and Wits University, we study how to improve the efficiency of HIV testing with the goal of eventual deployment, directly supporting progress toward UN Sustainable Development Goal 3.3. While prior work has demonstrated the promise of intelligent algorithms for sequential, network-based HIV testing, existing approaches rely on assumptions that are impractical in our real-world implementations. Here, we study sequential testing on incrementally revealed disease networks and introduce Policy-Embedded Graph Expansion (PEGE), a novel framework that directly embeds a generative distribution over graph expansions into the decision-making policy rather than attempting explicit topological reconstruction. We further propose Dynamics-Driven Branching (DDB), a diffusion-based graph expansion model that supports decision making in PEGE and is designed for data-limited settings where forest structures arise naturally, as in our real-world referral process. Experiments on real HIV transmission networks show that the combined approach (PEGE + DDB) consistently outperforms existing baselines (e.g., 13% improvement in discounted reward and 9% more HIV detections with 25% of the population tested) and explore key tradeoffs that drive decision quality.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16233v1</guid></item><item><title>[cs updates on arXiv.org] Algorithmic Identity Based on Metaparameters: A Path to Reliability, Auditability, and Traceability</title><link>https://arxiv.org/abs/2601.16234</link><description>arXiv:2601.16234v1 Announce Type: new 
Abstract: The use of algorithms is increasing across various fields such as healthcare, justice, finance, and education. This growth has significantly accelerated with the advent of Artificial Intelligence (AI) technologies based on Large Language Models (LLMs) since 2022. This expansion presents substantial challenges related to accountability, ethics, and transparency. This article explores the potential of the Digital Object Identifier (DOI) to identify algorithms, aiming to enhance accountability, transparency, and reliability in their development and application, particularly in AI agents and multimodal LLMs. The use of DOIs facilitates tracking the origin of algorithms, enables audits, prevents biases, promotes research reproducibility, and strengthens ethical considerations. The discussion addresses the challenges and solutions associated with maintaining algorithms identified by DOI, their application in API security, and the proposal of a cryptographic authentication protocol.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16234v1</guid></item><item><title>[cs updates on arXiv.org] Contrastive Knowledge Distillation for Embedding Refinement in Personalized Speech Enhancement</title><link>https://arxiv.org/abs/2601.16235</link><description>arXiv:2601.16235v1 Announce Type: new 
Abstract: Personalized speech enhancement (PSE) has shown convincing results when it comes to extracting a known target voice among interfering ones. The corresponding systems usually incorporate a representation of the target voice within the enhancement system, which is extracted from an enrollment clip of the target voice with upstream models. Those models are generally heavy as the speaker embedding's quality directly affects PSE performances. Yet, embeddings generated beforehand cannot account for the variations of the target voice during inference time. In this paper, we propose to perform on-thefly refinement of the speaker embedding using a tiny speaker encoder. We first introduce a novel contrastive knowledge distillation methodology in order to train a 150k-parameter encoder from complex embeddings. We then use this encoder within the enhancement system during inference and show that the proposed method greatly improves PSE performances while maintaining a low computational load.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16235v1</guid></item><item><title>[cs updates on arXiv.org] Bringing order to network centrality measures</title><link>https://arxiv.org/abs/2601.16236</link><description>arXiv:2601.16236v1 Announce Type: new 
Abstract: We introduce a quantitative method to compare arbitrary pairs of graph centrality measures, based on the ordering of vertices induced by them. The proposed method is conceptually simple, mathematically elegant, and allows for a quantitative restatement of many conjectures that were previously cumbersome to formalize. Moreover, it produces an approximation scheme useful for network scientists. We explore some of these uses and formulate new conjectures that are of independent interest.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16236v1</guid></item><item><title>[cs updates on arXiv.org] Computational Foundations for Strategic Coopetition: Formalizing Collective Action and Loyalty</title><link>https://arxiv.org/abs/2601.16237</link><description>arXiv:2601.16237v1 Announce Type: new 
Abstract: Mixed-motive multi-agent settings are rife with persistent free-riding because individual effort benefits all members equally, yet each member bears the full cost of their own contribution. Classical work by Holmstr\"om established that under pure self-interest, Nash equilibrium is universal shirking. While i* represents teams as composite actors, it lacks scalable computational mechanisms for analyzing how collective action problems emerge and resolve in coopetitive settings. This technical report extends computational foundations for strategic coopetition to team-level dynamics, building on companion work formalizing interdependence/complementarity (arXiv:2510.18802) and trust dynamics (arXiv:2510.24909). We develop loyalty-moderated utility functions with two mechanisms: loyalty benefit (welfare internalization plus intrinsic contribution satisfaction) and cost tolerance (reduced effort burden for loyal members). We integrate i* structural dependencies through dependency-weighted team cohesion, connecting member incentives to team-level positioning. The framework applies to both human teams (loyalty as psychological identification) and multi-agent systems (alignment coefficients and adjusted cost functions). Experimental validation across 3,125 configurations demonstrates robust loyalty effects (15.04x median effort differentiation). All six behavioral targets achieve thresholds: free-riding baseline (96.5%), loyalty monotonicity (100%), effort differentiation (100%), team size effect (100%), mechanism synergy (99.5%), and bounded outcomes (100%). Empirical validation using published Apache HTTP Server (1995-2023) case study achieves 60/60 points, reproducing contribution patterns across formation, growth, maturation, and governance phases. Statistical significance confirmed at p&lt;0.001, Cohen's d=0.71.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16237v1</guid></item><item><title>[cs updates on arXiv.org] VibeTensor: System Software for Deep Learning, Fully Generated by AI Agents</title><link>https://arxiv.org/abs/2601.16238</link><description>arXiv:2601.16238v1 Announce Type: new 
Abstract: VIBETENSOR is an open-source research system software stack for deep learning, generated by LLM-powered coding agents under high-level human guidance. In this paper, "fully generated" refers to code provenance: implementation changes were produced and applied as agent-proposed diffs; validation relied on agent-run builds, tests, and differential checks, without per-change manual diff review. It implements a PyTorch-style eager tensor library with a C++20 core (CPU+CUDA), a torch-like Python overlay via nanobind, and an experimental Node.js/TypeScript interface. Unlike thin bindings, VIBETENSOR includes its own tensor/storage system, schema-lite dispatcher, reverse-mode autograd, CUDA runtime (streams/events/graphs), a stream-ordered caching allocator with diagnostics, and a stable C ABI for dynamically loaded operator plugins. We view this release as a milestone for AI-assisted software engineering: it shows coding agents can generate a coherent deep learning runtime spanning language bindings down to CUDA memory management, validated primarily by builds and tests. We describe the architecture, summarize the workflow used to produce and validate the system, and evaluate the artifact. We report repository scale and test-suite composition, and summarize reproducible microbenchmarks from an accompanying AI-generated kernel suite, including fused attention versus PyTorch SDPA/FlashAttention. We also report end-to-end training sanity checks on 3 small workloads (sequence reversal, ViT, miniGPT) on NVIDIA H100 (Hopper, SM90) and Blackwell-class GPUs; multi-GPU results are Blackwell-only and use an optional CUTLASS-based ring-allreduce plugin gated on CUDA 13+ and sm103a toolchain support. Finally, we discuss failure modes in generated system software, including a "Frankenstein" composition effect where locally correct subsystems interact to yield globally suboptimal performance.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16238v1</guid></item><item><title>[cs updates on arXiv.org] Combining Tests and Proofs for Better Software Verification</title><link>https://arxiv.org/abs/2601.16239</link><description>arXiv:2601.16239v1 Announce Type: new 
Abstract: Test or prove? These two approaches to software verification have long been presented as opposites. One is dynamic, the other static: a test executes the program, a proof only analyzes the program text. A different perspective is emerging, in which testing and proving are complementary rather than competing techniques for producing software of verified quality.
  Work performed over the past few years and reviewed here develops this complementarity by taking advantage of Design by Contract, as available in Eiffel, and exploiting a feature of modern program-proving tools based on ``Satisfiability Modulo Theories'' (SMT): counterexample generation. A counterexample is an input combination that makes the program fail. If we are trying to prove a program correct, we hope not to find any. One can, however, apply counterexample generation to incorrect programs, as a tool for automatic test generation. We can also introduce faults into a correct program and turn the counterexamples into an automatically generated regression test suite with full coverage. Additionally, we can use these mechanisms to help produce program fixes for incorrect programs, with a guarantee that the fixes are correct. All three applications, leveraging on the mechanisms of Eiffel and Design by Contract, hold significant promise to address some of the challenges of program testing, software maintenance and Automatic Program Repair.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16239v1</guid></item><item><title>[cs updates on arXiv.org] A New Paradigm for Trusted Respiratory Monitoring Via Consumer Electronics-grade Radar Signals</title><link>https://arxiv.org/abs/2601.16241</link><description>arXiv:2601.16241v1 Announce Type: new 
Abstract: Respiratory monitoring is an extremely important task in modern medical services. Due to its significant advantages, e.g., non-contact, radar-based respiratory monitoring has attracted widespread attention from both academia and industry. Unfortunately, though it can achieve high monitoring accuracy, consumer electronics-grade radar data inevitably contains User-sensitive Identity Information (USI), which may be maliciously used and further lead to privacy leakage. To track these challenges, by variational mode decomposition (VMD) and adversarial loss-based encryption, we propose a novel Trusted Respiratory Monitoring paradigm, Tru-RM, to perform automated respiratory monitoring through radio signals while effectively anonymizing USI. The key enablers of Tru-RM are Attribute Feature Decoupling (AFD), Flexible Perturbation Encryptor (FPE), and robust Perturbation Tolerable Network (PTN) used for attribute decomposition, identity encryption, and perturbed respiratory monitoring, respectively. Specifically, AFD is designed to decompose the raw radar signals into the universal respiratory component, the personal difference component, and other unrelated components. Then, by using large noise to drown out the other unrelated components, and the phase noise algorithm with a learning intensity parameter to eliminate USI in the personal difference component, FPE is designed to achieve complete user identity information encryption without affecting respiratory features. Finally, by designing the transferred generalized domain-independent network, PTN is employed to accurately detect respiration when waveforms change significantly. Extensive experiments based on various detection distances, respiratory patterns, and durations demonstrate the superior performance of Tru-RM on strong anonymity of USI, and high detection accuracy of perturbed respiratory waveforms.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16241v1</guid></item><item><title>[cs updates on arXiv.org] Scalable Screw-Theoretic Synthesis for PDE-Based Dynamic Modeling of Multibody Flexible Manipulators</title><link>https://arxiv.org/abs/2601.16242</link><description>arXiv:2601.16242v1 Announce Type: new 
Abstract: This paper presents a novel and scalable screw-theoretic multibody synthesis framework for PDE-based dynamic modeling of serial robotic manipulators with an arbitrary number of flexible links in three-dimensional space. The proposed approach systematically constructs screw-theoretic PDE models for individual flexible links and rigorously enforces holonomic joint constraints through interaction forces. The dynamics of each link are formulated using a set of dual screws expressed in body-fixed coordinates: one describing the motion of the body-fixed frame relative to the inertial frame, a second relating the body-fixed frame to the undeformed configuration, and a third capturing elastic deformations. By expressing the system energy and applying variational principles, the governing dynamics of each link had been previously derived in a unified manner. Synthesizing the individual link models yields an infinitely scalable multibody representation capable of capturing both local (subsystem-level) and global (system-level) dynamics. The framework explicitly recovers all dynamic states, including the motion of each body-fixed frame and the distributed deformation fields of the flexible links. For computational tractability and mathematical rigor, the resulting governing equations are formulated as a semi-explicit index-1 differential-algebraic system. Furthermore, by applying separation of variables, the PDE model is recast as an abstract Cauchy problem, and well-posedness of the resulting system is established.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16242v1</guid></item><item><title>[cs updates on arXiv.org] Topological transitivity of group cellular automata is decidable</title><link>https://arxiv.org/abs/2601.16243</link><description>arXiv:2601.16243v1 Announce Type: new 
Abstract: Topological transitivity is a fundamental notion in topological dynamics and is widely regarded as a basic indicator of global dynamical complexity. For general cellular automata, topological transitivity is known to be undecidable. By contrast, positive decidability results have been established for one-dimensional group cellular automata over abelian groups, while the extension to higher dimensions and to non-abelian groups has remained an open problem. In this work, we settle this problem by proving that topological transitivity is decidable for the class of $d$-dimensional ($d\geq 1$) group cellular automata over arbitrary finite groups. Our approach combines a decomposition technique for group cellular automata, reducing the problem to the analysis of simpler components, with an extension of several results from the existing literature in the one-dimensional setting. As a consequence of our results, and exploiting known equivalences among dynamical properties for group cellular automata, we also obtain the decidability of several related notions, including total transitivity, topological mixing and weak mixing, weak and strong ergodic mixing, and ergodicity.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16243v1</guid></item><item><title>[cs updates on arXiv.org] Ordering-based Causal Discovery via Generalized Score Matching</title><link>https://arxiv.org/abs/2601.16249</link><description>arXiv:2601.16249v1 Announce Type: new 
Abstract: Learning DAG structures from purely observational data remains a long-standing challenge across scientific domains. An emerging line of research leverages the score of the data distribution to initially identify a topological order of the underlying DAG via leaf node detection and subsequently performs edge pruning for graph recovery. This paper extends the score matching framework for causal discovery, which is originally designated for continuous data, and introduces a novel leaf discriminant criterion based on the discrete score function. Through simulated and real-world experiments, we demonstrate that our theory enables accurate inference of true causal orders from observed discrete data and the identified ordering can significantly boost the accuracy of existing causal discovery baselines on nearly all of the settings.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16249v1</guid></item><item><title>[cs updates on arXiv.org] GR3EN: Generative Relighting for 3D Environments</title><link>https://arxiv.org/abs/2601.16272</link><description>arXiv:2601.16272v1 Announce Type: new 
Abstract: We present a method for relighting 3D reconstructions of large room-scale environments. Existing solutions for 3D scene relighting often require solving under-determined or ill-conditioned inverse rendering problems, and are as such unable to produce high-quality results on complex real-world scenes. Though recent progress in using generative image and video diffusion models for relighting has been promising, these techniques are either limited to 2D image and video relighting or 3D relighting of individual objects. Our approach enables controllable 3D relighting of room-scale scenes by distilling the outputs of a video-to-video relighting diffusion model into a 3D reconstruction. This side-steps the need to solve a difficult inverse rendering problem, and results in a flexible system that can relight 3D reconstructions of complex real-world scenes. We validate our approach on both synthetic and real-world datasets to show that it can faithfully render novel views of scenes under new lighting conditions.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16272v1</guid></item><item><title>[cs updates on arXiv.org] GameTalk: Training LLMs for Strategic Conversation</title><link>https://arxiv.org/abs/2601.16276</link><description>arXiv:2601.16276v1 Announce Type: new 
Abstract: Strategic decision-making in multi-agent settings is a key challenge for large language models (LLMs), particularly when coordination and negotiation must unfold over extended conversations. While recent work has explored the use of LLMs in isolated decision tasks, little attention has been given to optimizing long-term objectives through dialogue. We introduce \textbf{GameTalk}, a framework for training LLMs to make strategic decisions via multi-turn interactions. Unlike prior work that focuses on single-turn objectives or static action prediction, we train LLMs to optimize a global objective across full conversations. We achieve this by adapting fine-tuning methods like GRPO, DPO, and STaR to incorporate reward signals that depend on the entire interaction. We evaluate this approach on a suite of increasingly complex games, designed to stress different aspects of reasoning, coordination, and opponent modeling. Our results show that GameTalk significantly outperforms untrained models, especially under reward shaping, with DPO consistently yielding the strongest gains. These findings position conversational fine-tuning as a promising path for LLMs to reason, negotiate, and act in interactive environments.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16276v1</guid></item><item><title>[cs updates on arXiv.org] Better as Generators Than Classifiers: Leveraging LLMs and Synthetic Data for Low-Resource Multilingual Classification</title><link>https://arxiv.org/abs/2601.16278</link><description>arXiv:2601.16278v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable multilingual capabilities, making them promising tools in both high- and low-resource languages. One particularly valuable use case is generating synthetic samples that can be used to train smaller models in low-resource scenarios where human-labelled data is scarce. In this work, we investigate whether these synthetic data generation capabilities can serve as a form of distillation, producing smaller models that perform on par with or even better than massive LLMs across languages and tasks. To this end, we use a state-of-the-art multilingual LLM to generate synthetic datasets covering 11 languages and 4 classification tasks. These datasets are then used to train smaller models via fine-tuning or instruction tuning, or as synthetic in-context examples for compact LLMs. Our experiments show that even small amounts of synthetic data enable smaller models to outperform the large generator itself, particularly in low-resource languages. Overall, the results suggest that LLMs are best utilised as generators (teachers) rather than classifiers, producing data that empowers smaller and more efficient multilingual models.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16278v1</guid></item><item><title>[cs updates on arXiv.org] When Agents Fail to Act: A Diagnostic Framework for Tool Invocation Reliability in Multi-Agent LLM Systems</title><link>https://arxiv.org/abs/2601.16280</link><description>arXiv:2601.16280v1 Announce Type: new 
Abstract: Multi-agent systems powered by large language models (LLMs) are transforming enterprise automation, yet systematic evaluation methodologies for assessing tool-use reliability remain underdeveloped. We introduce a comprehensive diagnostic framework that leverages big data analytics to evaluate procedural reliability in intelligent agent systems, addressing critical needs for SME-centric deployment in privacy-sensitive environments. Our approach features a 12-category error taxonomy capturing failure modes across tool initialization, parameter handling, execution, and result interpretation. Through systematic evaluation of 1,980 deterministic test instances spanning both open-weight models (Qwen2.5 series, Functionary) and proprietary alternatives (GPT-4, Claude 3.5/3.7) across diverse edge hardware configurations, we identify actionable reliability thresholds for production deployment. Our analysis reveals that procedural reliability, particularly tool initialization failures, constitutes the primary bottleneck for smaller models, while qwen2.5:32b achieves flawless performance matching GPT-4.1. The framework demonstrates that mid-sized models (qwen2.5:14b) offer practical accuracy-efficiency trade-offs on commodity hardware (96.6\% success rate, 7.3 s latency), enabling cost-effective intelligent agent deployment for resource-constrained organizations. This work establishes foundational infrastructure for systematic reliability evaluation of tool-augmented multi-agent AI systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16280v1</guid></item><item><title>[cs updates on arXiv.org] Generating Literature-Driven Scientific Theories at Scale</title><link>https://arxiv.org/abs/2601.16282</link><description>arXiv:2601.16282v1 Announce Type: new 
Abstract: Contemporary automated scientific discovery has focused on agents for generating scientific experiments, while systems that perform higher-level scientific activities such as theory building remain underexplored. In this work, we formulate the problem of synthesizing theories consisting of qualitative and quantitative laws from large corpora of scientific literature. We study theory generation at scale, using 13.7k source papers to synthesize 2.9k theories, examining how generation using literature-grounding versus parametric knowledge, and accuracy-focused versus novelty-focused generation objectives change theory properties. Our experiments show that, compared to using parametric LLM memory for generation, our literature-supported method creates theories that are significantly better at both matching existing evidence and at predicting future results from 4.6k subsequently-written papers</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16282v1</guid></item><item><title>[cs updates on arXiv.org] BESTOpt: A Modular, Physics-Informed Machine Learning based Building Modeling, Control and Optimization Framework</title><link>https://arxiv.org/abs/2601.16283</link><description>arXiv:2601.16283v1 Announce Type: new 
Abstract: Modern buildings are increasingly interconnected with occupancy, heating, ventilation, and air-conditioning (HVAC) systems, distributed energy resources (DERs), and power grids. Modeling, control, and optimization of such multi-domain systems play a critical role in achieving building-sector decarbonization. However, most existing tools lack scalability and physical consistency for addressing these complex, multi-scale ecosystem problems. To bridge this gap, this study presents BESTOpt, a modular, physics-informed machine learning (PIML) framework that unifies building applications, including benchmarking, evaluation, diagnostics, control, optimization, and performance simulation. The framework adopts a cluster-domain-system/building-component hierarchy and a standardized state-action-disturbance-observation data typology. By embedding physics priors into data-driven modules, BESTOpt improves model accuracy and physical consistency under unseen conditions. Case studies on single-building and cluster scenarios demonstrate its capability for multi-level centralized and decentralized control. Looking ahead, BESTOpt lays the foundation for an open, extensible platform that accelerates interdisciplinary research toward smart, resilient, and decarbonized building ecosystems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16283v1</guid></item><item><title>[cs updates on arXiv.org] SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems</title><link>https://arxiv.org/abs/2601.16286</link><description>arXiv:2601.16286v1 Announce Type: new 
Abstract: Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundary caching fails to capture this inefficiency because it treats inference as a monolithic black box.
  We introduce SemanticALLI, a pipeline-aware architecture within Alli (PMG's marketing intelligence platform), designed to operationalize redundant reasoning. By decomposing generation into Analytic Intent Resolution (AIR) and Visualization Synthesis (VS), SemanticALLI elevates structured intermediate representations (IRs) to first-class, cacheable artifacts.
  The impact of caching within the agentic loop is substantial. In our evaluation, baseline monolithic caching caps at a 38.7% hit rate due to linguistic variance. In contrast, our structured approach allows for an additional stage, the Visualization Synthesis stage, to achieve an 83.10% hit rate, bypassing 4,023 LLM calls with a median latency of just 2.66 ms. This internal reuse reduces total token consumption, offering a practical lesson for AI system design: even when users rarely repeat themselves, the pipeline often does, at stable, structured checkpoints where caching is most reliable.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16286v1</guid></item><item><title>[cs updates on arXiv.org] Space Filling Curves is All You Need: Communication-Avoiding Matrix Multiplication Made Simple</title><link>https://arxiv.org/abs/2601.16294</link><description>arXiv:2601.16294v1 Announce Type: new 
Abstract: General Matrix Multiplication (GEMM) is the cornerstone of Deep Learning and HPC workloads; accordingly, academia and industry have heavily optimized this kernel. Modern platforms with matrix multiplication accelerators exhibit high FLOP/Byte machine balance, which makes implementing optimal matrix multiplication challenging. On modern CPU platforms with matrix engines, state-of-the-art vendor libraries tune input tensor layouts, parallelization schemes, and cache blocking to minimize data movement across the memory hierarchy and maximize throughput. However, the best settings for these parameters depend strongly on the target platform (number of cores, memory hierarchy, cache sizes) and on the shapes of the matrices, making exhaustive tuning infeasible; in practice this leads to performance "glass jaws". In this work we revisit space filling curves (SFC) to alleviate the problem of this cumbersome tuning. SFC convert multi-dimensional coordinates (e.g. 2D) into a single dimension (1D), keeping nearby points in the high-dimensional space close in the 1D order. We partition the Matrix Multiplication computation space using recent advancements in generalized SFC (Generalized Hilbert Curves), and we obtain platform-oblivious and shape-oblivious matrix-multiplication schemes that exhibit inherently high degree of data locality. Furthermore, we extend the SFC-based work partitioning to implement Communication-Avoiding (CA) algorithms that replicate the input tensors and provably minimize communication/data-movement on the critical path. The integration of CA-algorithms is seamless and yields compact code (~30 LOC), yet it achieves state-of-the-art results on multiple CPU platforms, outperforming vendor libraries by up to 2x(geometric-mean speedup) for a range of GEMM shapes.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16294v1</guid></item><item><title>[cs updates on arXiv.org] Memory-V2V: Augmenting Video-to-Video Diffusion Models with Memory</title><link>https://arxiv.org/abs/2601.16296</link><description>arXiv:2601.16296v1 Announce Type: new 
Abstract: Recent foundational video-to-video diffusion models have achieved impressive results in editing user provided videos by modifying appearance, motion, or camera movement. However, real-world video editing is often an iterative process, where users refine results across multiple rounds of interaction. In this multi-turn setting, current video editors struggle to maintain cross-consistency across sequential edits. In this work, we tackle, for the first time, the problem of cross-consistency in multi-turn video editing and introduce Memory-V2V, a simple, yet effective framework that augments existing video-to-video models with explicit memory. Given an external cache of previously edited videos, Memory-V2V employs accurate retrieval and dynamic tokenization strategies to condition the current editing step on prior results. To further mitigate redundancy and computational overhead, we propose a learnable token compressor within the DiT backbone that compresses redundant conditioning tokens while preserving essential visual cues, achieving an overall speedup of 30%. We validate Memory-V2V on challenging tasks including video novel view synthesis and text-conditioned long video editing. Extensive experiments show that Memory-V2V produces videos that are significantly more cross-consistent with minimal computational overhead, while maintaining or even improving task-specific performance over state-of-the-art baselines. Project page: https://dohunlee1.github.io/MemoryV2V</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16296v1</guid></item><item><title>[cs updates on arXiv.org] FC-GUARD: Enabling Anonymous yet Compliant Fiat-to-Cryptocurrency Exchanges</title><link>https://arxiv.org/abs/2601.16298</link><description>arXiv:2601.16298v1 Announce Type: new 
Abstract: With the rise of decentralized finance, fiat-to-cryptocurrency exchange platforms have become popular entry points into the cryptocurrency ecosystem. However, these platforms frequently fail to ensure adequate privacy protection, as evidenced by real-world breaches that exposed personally identifiable information (PII) and crypto addresses. Such leaks enable adversaries to link real-world identities to cryptocurrency transactions, undermining the presumed anonymity of cryptocurrency use.
  We propose FC-GUARD, a privacy-preserving exchange system designed to preserve user anonymity without compromising regulatory compliance in the exchange of fiat currency for cryptocurrencies. Leveraging verifiable credentials and zero-knowledge proof techniques, FC-GUARD enables fiat-to-cryptocurrency exchanges without revealing users' PII or fiat account details. This breaks the linkage between users' real-world identities and their cryptocurrency addresses, thereby upholding anonymity, a fundamental expectation in the cryptocurrency ecosystem. In addition, FC-GUARD complies with key regulations over cryptocurrency usage, such as know-your-customer requirements and auditability for tax reporting obligations by integrating a lawful de-anonymization mechanism that allows the auditing authority to identify misbehaving users. This ensures regulatory compliance while defaulting to privacy protection. We implement our system on both desktop and mobile platforms, and our evaluation shows its feasibility for practical deployment.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16298v1</guid></item><item><title>[cs updates on arXiv.org] FeTTL: Federated Template and Task Learning for Multi-Institutional Medical Imaging</title><link>https://arxiv.org/abs/2601.16302</link><description>arXiv:2601.16302v1 Announce Type: new 
Abstract: Federated learning enables collaborative model training across geographically distributed medical centers while preserving data privacy. However, domain shifts and heterogeneity in data often lead to a degradation in model performance. Medical imaging applications are particularly affected by variations in acquisition protocols, scanner types, and patient populations. To address these issues, we introduce Federated Template and Task Learning (FeTTL), a novel framework designed to harmonize multi-institutional medical imaging data in federated environments. FeTTL learns a global template together with a task model to align data distributions among clients. We evaluated FeTTL on two challenging and diverse multi-institutional medical imaging tasks: retinal fundus optical disc segmentation and histopathological metastasis classification. Experimental results show that FeTTL significantly outperforms the state-of-the-art federated learning baselines (p-values &lt;0.002) for optical disc segmentation and classification of metastases from multi-institutional data. Our experiments further highlight the importance of jointly learning the template and the task. These findings suggest that FeTTL offers a principled and extensible solution for mitigating distribution shifts in federated learning, supporting robust model deployment in real-world, multi-institutional environments.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16302v1</guid></item><item><title>[cs updates on arXiv.org] A Longitudinal, Multinational, and Multilingual Corpus of News Coverage of the Russo-Ukrainian War</title><link>https://arxiv.org/abs/2601.16309</link><description>arXiv:2601.16309v1 Announce Type: new 
Abstract: We introduce DNIPRO, a novel longitudinal corpus of 246K news articles documenting the Russo-Ukrainian war from Feb 2022 to Aug 2024, spanning eleven media outlets across five nation states (Russia, Ukraine, U.S., U.K., and China) and three languages (English, Russian, and Mandarin Chinese). This multilingual resource features consistent and comprehensive metadata, and multiple types of annotation with rigorous human evaluations for downstream tasks relevant to systematic transnational analyses of contentious wartime discourse. DNIPRO's distinctive value lies in its inclusion of competing geopolitical perspectives, making it uniquely suited for studying narrative divergence, media framing, and information warfare. To demonstrate its utility, we include use case experiments using stance detection, sentiment analysis, topical framing, and contradiction analysis of major conflict events within the larger war. Our explorations reveal how outlets construct competing realities, with coverage exhibiting polarized interpretations that reflect geopolitical interests. Beyond supporting computational journalism research, DNIPRO provides a foundational resource for understanding how conflicting narratives emerge and evolve across global information ecosystems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16309v1</guid></item><item><title>[cs updates on arXiv.org] Teaching and Evaluating LLMs to Reason About Polymer Design Related Tasks</title><link>https://arxiv.org/abs/2601.16312</link><description>arXiv:2601.16312v1 Announce Type: new 
Abstract: Research in AI4Science has shown promise in many science applications, including polymer design. However, current LLMs prove ineffective on this problem space because: (i) most models lack polymer-specific knowledge (ii) existing aligned models lack coverage of knowledge and capabilities relevant to polymer design. Addressing this, we introduce PolyBench, a large scale training and test benchmark dataset of more than 125K polymer design related tasks, leveraging a knowledge base of 13M+ data points obtained from experimental and synthetic sources to ensure broad coverage of polymers and their properties. For effective alignment using PolyBench, we introduce a knowledge-augmented reasoning distillation method that augments this dataset with structured CoT. Furthermore, tasks in PolyBench are organized from simple to complex analytical reasoning problems, enabling generalization tests and diagnostic probes across the problem space. Experiments show that small language models (SLMs), of 7B to 14B parameters, trained on PolyBench data outperform similar sized models, and even closed source frontier LLMs on PolyBench test dataset while demonstrating gains on other polymer benchmarks as well.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16312v1</guid></item><item><title>[cs updates on arXiv.org] Machine-Assisted Grading of Nationwide School-Leaving Essay Exams with LLMs and Statistical NLP</title><link>https://arxiv.org/abs/2601.16314</link><description>arXiv:2601.16314v1 Announce Type: new 
Abstract: Large language models (LLMs) enable rapid and consistent automated evaluation of open-ended exam responses, including dimensions of content and argumentation that have traditionally required human judgment. This is particularly important in cases where a large amount of exams need to be graded in a limited time frame, such as nation-wide graduation exams in various countries. Here, we examine the applicability of automated scoring on two large datasets of trial exam essays of two full national cohorts from Estonia. We operationalize the official curriculum-based rubric and compare LLM and statistical natural language processing (NLP) based assessments with human panel scores. The results show that automated scoring can achieve performance comparable to that of human raters and tends to fall within the human scoring range. We also evaluate bias, prompt injection risks, and LLMs as essay writers. These findings demonstrate that a principled, rubric-driven, human-in-the-loop scoring pipeline is viable for high-stakes writing assessment, particularly relevant for digitally advanced societies like Estonia, which is about to adapt a fully electronic examination system. Furthermore, the system produces fine-grained subscore profiles that can be used to generate systematic, personalized feedback for instruction and exam preparation. The study provides evidence that LLM-assisted assessment can be implemented at a national scale, even in a small-language context, while maintaining human oversight and compliance with emerging educational and regulatory standards.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16314v1</guid></item><item><title>[cs updates on arXiv.org] Optimal County-Level Siting of Data Centers in the United States</title><link>https://arxiv.org/abs/2601.16315</link><description>arXiv:2601.16315v1 Announce Type: new 
Abstract: Data centers are growing rapidly, creating the pressing need for the development of critical infrastructure build out to support these resource-intensive large loads. Their immense consumption of electricity and, often, freshwater, continues to stress an already constrained and aging power grid and water resources. This paper presents a comprehensive modeling approach to determine the optimal locations to construct such facilities by quantifying their resource use and minimizing associated costs. The interdisciplinary modeling approach incorporates a number of factors including the power grid, telecommunications, climate, water use, and collocated generation potential. This work establishes the base model whose functionality is shown through several test cases focusing on carbon-free generation collocation on a county-level in the United States. The results suggest that while capital costs are the biggest driver, having a longer future outlook and allowing more variable generation collocation influences the model to choose sites with higher renewable potential.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16315v1</guid></item><item><title>[cs updates on arXiv.org] My Parents Expectations Were Overwhelming: Online Dating Romance Scams Targeting Minors in Iran Through Exploitation of Parental Pressure</title><link>https://arxiv.org/abs/2601.16321</link><description>arXiv:2601.16321v1 Announce Type: new 
Abstract: Minors are at risk of myriad harms online, yet online dating romance scams are seldom considered one of them. While research of romance scams in Western countries finds victims to predominantly be middle-age, it is unknown if minors in geographic regions with cultural norms around teenage marriage are uniquely susceptible to online dating romance scams. We present an interview study with 16 victims of online dating romance scams in Iran who were minors when scammed. Findings show that, with westernized dating apps banned in Iran, scammers find teenage victims through messaging platforms tethered to local neighborhoods, offering relief for parental pressures around finding a marital partner and academic performance. Using threats, lies, and exploitation of emotional attachment lacking from their families, scammers pressured minors into financial and sexual favors. The study demonstrates how local cultural context should be foregrounded in future research on, and solutions for, technology-mediated harm against minors. Content Warning: This paper discusses sexual abuse.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16321v1</guid></item><item><title>[cs updates on arXiv.org] DMV-AVP: Distributed Multi-Vehicle Autonomous Valet Parking using Autoware</title><link>https://arxiv.org/abs/2601.16327</link><description>arXiv:2601.16327v1 Announce Type: new 
Abstract: This paper presents the DMV-AVP System, a distributed simulation of Multi-Vehicle Autonomous Valet Parking (AVP). The system was implemented as an application of the Distributed Multi-Vehicle Architecture (DMAVA) for synchronized multi-host execution. Most existing simulation approaches rely on centralized or non-distributed designs that constrain scalability and limit fully autonomous control. This work introduces two modules built on top of the DMAVA: 1) a Multi-Vehicle AVP Node that performs state-based coordination, queuing, and reservation management across multiple vehicles, and 2) a Unity-Integrated YOLOv5 Parking Spot Detection Module that provides real-time, vision-based perception within AWSIM Labs. Both modules integrate seamlessly with the DMAVA and extend it specifically for multi-vehicle AVP operation, supported by a Zenoh-based communication layer that ensures low-latency topic synchronization and coordinated behavior across hosts. Experiments conducted on two- and three-host configurations demonstrate deterministic coordination, conflict-free parking behavior, and scalable performance across distributed Autoware instances. The results confirm that the proposed Distributed Multi-Vehicle AVP System supports cooperative AVP simulation and establishes a foundation for future real-world and hardware-in-the-loop validation. Demo videos and source code are available at https://github.com/zubxxr/multi-vehicle-avp</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16327v1</guid></item><item><title>[cs updates on arXiv.org] Efficient Gaussian process learning via subspace projections</title><link>https://arxiv.org/abs/2601.16332</link><description>arXiv:2601.16332v1 Announce Type: new 
Abstract: We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random projections on the unit sphere. We show the superiority of the PL, in terms of accuracy and computational efficiency, over the exact GP training and the variational free energy approach to sparse GPs over different optimisers, kernels and datasets of moderately large sizes.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16332v1</guid></item><item><title>[cs updates on arXiv.org] Where is the multimodal goal post? On the Ability of Foundation Models to Recognize Contextually Important Moments</title><link>https://arxiv.org/abs/2601.16333</link><description>arXiv:2601.16333v1 Announce Type: new 
Abstract: Foundation models are used for many real-world applications involving language generation from temporally-ordered multimodal events. In this work, we study the ability of models to identify the most important sub-events in a video, which is a fundamental prerequisite for narrating or summarizing multimodal events. Specifically, we focus on football games and evaluate models on their ability to distinguish between important and non-important sub-events in a game. To this end, we construct a new dataset by leveraging human preferences for importance implicit in football game highlight reels, without any additional annotation costs. Using our dataset, which we will publicly release to the community, we compare several state-of-the-art multimodal models and show that they are not far from chance level performance. Analyses of models beyond standard evaluation metrics reveal their tendency to rely on a single dominant modality and their ineffectiveness in synthesizing necessary information from multiple sources. Our findings underline the importance of modular architectures that can handle sample-level heterogeneity in multimodal data and the need for complementary training procedures that can maximize cross-modal synergy.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16333v1</guid></item><item><title>[cs updates on arXiv.org] Identifying Concurrency Bug Reports via Linguistic Patterns</title><link>https://arxiv.org/abs/2601.16338</link><description>arXiv:2601.16338v1 Announce Type: new 
Abstract: With the growing ubiquity of multi-core architectures, concurrent systems have become essential but increasingly prone to complex issues such as data races and deadlocks. While modern issue-tracking systems facilitate the reporting of such problems, labeling concurrency-related bug reports remains a labor-intensive and error-prone task. This paper presents a linguistic-pattern-based framework for automatically identifying concurrency bug reports. We derive 58 distinct linguistic patterns from 730 manually labeled concurrency bug reports, organized across four levels: word-level (keywords), phrase-level (n-grams), sentence-level (semantic), and bug report-level (contextual). To assess their effectiveness, we evaluate four complementary approaches-matching, learning, prompt-based, and fine-tuning-spanning traditional machine learning, large language models (LLMs), and pre-trained language models (PLMs). Our comprehensive evaluation on 12 large-scale open-source projects (10,920 issue reports from GitHub and Jira) demonstrates that fine-tuning PLMs with linguistic-pattern-enriched inputs achieves the best performance, reaching a precision of 91% on GitHub and 93% on Jira, and maintaining strong precision on post cut-off data (91%). The contributions of this work include: (1) a comprehensive taxonomy of linguistic patterns for concurrency bugs, (2) a novel fine-tuning strategy that integrates domain-specific linguistic knowledge into PLMs, and (3) a curated, labeled dataset to support reproducible research. Together, these advances provide a foundation for improving the automation, precision, and interpretability of concurrency bug classification.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16338v1</guid></item><item><title>[cs updates on arXiv.org] DSGym: A Holistic Framework for Evaluating and Training Data Science Agents</title><link>https://arxiv.org/abs/2601.16344</link><description>arXiv:2601.16344v1 Announce Type: new 
Abstract: Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses and findings. Yet existing data science benchmarks fall short due to fragmented evaluation interfaces that make cross-benchmark comparison difficult, narrow task coverage and a lack of rigorous data grounding. In particular, we show that a substantial portion of tasks in current benchmarks can be solved without using the actual data. To address these limitations, we introduce DSGym, a standardized framework for evaluating and training data science agents in self-contained execution environments. Unlike static benchmarks, DSGym provides a modular architecture that makes it easy to add tasks, agent scaffolds, and tools, positioning it as a live, extensible testbed. We curate DSGym-Tasks, a holistic task suite that standardizes and refines existing benchmarks via quality and shortcut solvability filtering. We further expand coverage with (1) DSBio: expert-derived bioinformatics tasks grounded in literature and (2) DSPredict: challenging prediction tasks spanning domains such as computer vision, molecular prediction, and single-cell perturbation. Beyond evaluation, DSGym enables agent training via execution-verified data synthesis pipeline. As a case study, we build a 2,000-example training set and trained a 4B model in DSGym that outperforms GPT-4o on standardized analysis benchmarks. Overall, DSGym enables rigorous end-to-end measurement of whether agents can plan, implement, and validate data analyses in realistic scientific context.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16344v1</guid></item><item><title>[cs updates on arXiv.org] Coarse-to-Fine Non-rigid Multi-modal Image Registration for Historical Panel Paintings based on Crack Structures</title><link>https://arxiv.org/abs/2601.16348</link><description>arXiv:2601.16348v1 Announce Type: new 
Abstract: Art technological investigations of historical panel paintings rely on acquiring multi-modal image data, including visual light photography, infrared reflectography, ultraviolet fluorescence photography, x-radiography, and macro photography. For a comprehensive analysis, the multi-modal images require pixel-wise alignment, which is still often performed manually. Multi-modal image registration can reduce this laborious manual work, is substantially faster, and enables higher precision. Due to varying image resolutions, huge image sizes, non-rigid distortions, and modality-dependent image content, registration is challenging. Therefore, we propose a coarse-to-fine non-rigid multi-modal registration method efficiently relying on sparse keypoints and thin-plate-splines. Historical paintings exhibit a fine crack pattern, called craquelure, on the paint layer, which is captured by all image systems and is well-suited as a feature for registration. In our one-stage non-rigid registration approach, we employ a convolutional neural network for joint keypoint detection and description based on the craquelure and a graph neural network for descriptor matching in a patch-based manner, and filter matches based on homography reprojection errors in local areas. For coarse-to-fine registration, we introduce a novel multi-level keypoint refinement approach to register mixed-resolution images up to the highest resolution. We created a multi-modal dataset of panel paintings with a high number of keypoint annotations, and a large test set comprising five multi-modal domains and varying image resolutions. The ablation study demonstrates the effectiveness of all modules of our refinement method. Our proposed approaches achieve the best registration results compared to competing keypoint and dense matching methods and refinement methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16348v1</guid></item><item><title>[cs updates on arXiv.org] Regional Bias in Large Language Models</title><link>https://arxiv.org/abs/2601.16349</link><description>arXiv:2601.16349v1 Announce Type: new 
Abstract: This study investigates regional bias in large language models (LLMs), an emerging concern in AI fairness and global representation. We evaluate ten prominent LLMs: GPT-3.5, GPT-4o, Gemini 1.5 Flash, Gemini 1.0 Pro, Claude 3 Opus, Claude 3.5 Sonnet, Llama 3, Gemma 7B, Mistral 7B, and Vicuna-13B using a dataset of 100 carefully designed prompts that probe forced-choice decisions between regions under contextually neutral scenarios. We introduce FAZE, a prompt-based evaluation framework that measures regional bias on a 10-point scale, where higher scores indicate a stronger tendency to favor specific regions. Experimental results reveal substantial variation in bias levels across models, with GPT-3.5 exhibiting the highest bias score (9.5) and Claude 3.5 Sonnet scoring the lowest (2.5). These findings indicate that regional bias can meaningfully undermine the reliability, fairness, and inclusivity of LLM outputs in real-world, cross-cultural applications. This work contributes to AI fairness research by highlighting the importance of inclusive evaluation frameworks and systematic approaches for identifying and mitigating geographic biases in language models.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16349v1</guid></item><item><title>[cs updates on arXiv.org] NOIR: Privacy-Preserving Generation of Code with Open-Source LLMs</title><link>https://arxiv.org/abs/2601.16354</link><description>arXiv:2601.16354v1 Announce Type: new 
Abstract: Although boosting software development performance, large language model (LLM)-powered code generation introduces intellectual property and data security risks rooted in the fact that a service provider (cloud) observes a client's prompts and generated code, which can be proprietary in commercial systems. To mitigate this problem, we propose NOIR, the first framework to protect the client's prompts and generated code from the cloud. NOIR uses an encoder and a decoder at the client to encode and send the prompts' embeddings to the cloud to get enriched embeddings from the LLM, which are then decoded to generate the code locally at the client. Since the cloud can use the embeddings to infer the prompt and the generated code, NOIR introduces a new mechanism to achieve indistinguishability, a local differential privacy protection at the token embedding level, in the vocabulary used in the prompts and code, and a data-independent and randomized tokenizer on the client side. These components effectively defend against reconstruction and frequency analysis attacks by an honest-but-curious cloud. Extensive analysis and results using open-source LLMs show that NOIR significantly outperforms existing baselines on benchmarks, including the Evalplus (MBPP and HumanEval, Pass@1 of 76.7 and 77.4), and BigCodeBench (Pass@1 of 38.7, only a 1.77% drop from the original LLM) under strong privacy against attacks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16354v1</guid></item><item><title>[cs updates on arXiv.org] Identity, Cooperation and Framing Effects within Groups of Real and Simulated Humans</title><link>https://arxiv.org/abs/2601.16355</link><description>arXiv:2601.16355v1 Announce Type: new 
Abstract: Humans act via a nuanced process that depends both on rational deliberation and also on identity and contextual factors. In this work, we study how large language models (LLMs) can simulate human action in the context of social dilemma games. While prior work has focused on "steering" (weak binding) of chat models to simulate personas, we analyze here how deep binding of base models with extended backstories leads to more faithful replication of identity-based behaviors. Our study has these findings: simulation fidelity vs human studies is improved by conditioning base LMs with rich context of narrative identities and checking consistency using instruction-tuned models. We show that LLMs can also model contextual factors such as time (year that a study was performed), question framing, and participant pool effects. LLMs, therefore, allow us to explore the details that affect human studies but which are often omitted from experiment descriptions, and which hamper accurate replication.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16355v1</guid></item><item><title>[cs updates on arXiv.org] The Behavioral Fabric of LLM-Powered GUI Agents: Human Values and Interaction Outcomes</title><link>https://arxiv.org/abs/2601.16356</link><description>arXiv:2601.16356v1 Announce Type: new 
Abstract: Large Language Model (LLM)-powered web GUI agents are increasingly automating everyday online tasks. Despite their popularity, little is known about how users' preferences and values impact agents' reasoning and behavior. In this work, we investigate how both explicit and implicit user preferences, as well as the underlying user values, influence agent decision-making and action trajectories. We built a controlled testbed of 14 common interactive web tasks, spanning shopping, travel, dining, and housing, each replicated from real websites and integrated with a low-fidelity LLM-based recommender system. We injected 12 human preferences and values as personas into four state-of-the-art agents and systematically analyzed their task behaviors. Our results show that preference and value-infused prompts consistently guided agents toward outcomes that reflected these preferences and values. While the absence of user preference or value guidance led agents to exhibit a strong efficiency bias and employ shortest-path strategies, their presence steered agents' behavior trajectories through the greater use of corresponding filters and interactive web features. Despite their influence, dominant interface cues, such as discounts and advertisements, frequently overrode these effects, shortening the agents' action trajectories and inducing rationalizations that masked rather than reflected value-consistent reasoning. The contributions of this paper are twofold: (1) an open-source testbed for studying the influence of values in agent behaviors, and (2) an empirical investigation of how user preferences and values shape web agent behaviors.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16356v1</guid></item><item><title>[cs updates on arXiv.org] SE Research is a Complex Ecosystem: Isolated Fixes Keep Failing -- and Systems Thinking Shows Why</title><link>https://arxiv.org/abs/2601.16363</link><description>arXiv:2601.16363v1 Announce Type: new 
Abstract: The software engineering research community is productive, yet it faces a constellation of challenges: swamped review processes, metric-driven incentives, distorted publication practices, and increasing pressures from AI, scale, and outright scams. These issues are often treated in isolation, yet they arise from deep structural dynamics within the research ecosystem itself and distract us from the larger role of research in society. Meaningful progress requires a holistic system-level view. We sketch such a framework drawing on ideas from complex systems, ecosystems, and theory of change. Reframing SE's challenges through this lens reveals non-linear feedback loops that sustain current dysfunctions, and it helps to identify leverage points for reform. These are less a matter of isolated fixes and more a matter of exploring coordinated sets of fixes that operate across the SE ecosystem</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16363v1</guid></item><item><title>[cs updates on arXiv.org] Analyzing Neural Network Information Flow Using Differential Geometry</title><link>https://arxiv.org/abs/2601.16366</link><description>arXiv:2601.16366v1 Announce Type: new 
Abstract: This paper provides a fresh view of the neural network (NN) data flow problem, i.e., identifying the NN connections that are most important for the performance of the full model, through the lens of graph theory. Understanding the NN data flow provides a tool for symbolic NN analysis, e.g.,~robustness analysis or model repair. Unlike the standard approach to NN data flow analysis, which is based on information theory, we employ the notion of graph curvature, specifically Ollivier-Ricci curvature (ORC). The ORC has been successfully used to identify important graph edges in various domains such as road traffic analysis, biological and social networks. In particular, edges with negative ORC are considered bottlenecks and as such are critical to the graph's overall connectivity, whereas positive-ORC edges are not essential. We use this intuition for the case of NNs as well: we 1)~construct a graph induced by the NN structure and introduce the notion of neural curvature (NC) based on the ORC; 2)~calculate curvatures based on activation patterns for a set of input examples; 3)~aim to demonstrate that NC can indeed be used to rank edges according to their importance for the overall NN functionality. We evaluate our method through pruning experiments and show that removing negative-ORC edges quickly degrades the overall NN performance, whereas positive-ORC edges have little impact. The proposed method is evaluated on a variety of models trained on three image datasets, namely MNIST, CIFAR-10 and CIFAR-100. The results indicate that our method can identify a larger number of unimportant edges as compared to state-of-the-art pruning methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16366v1</guid></item><item><title>[cs updates on arXiv.org] Game-to-Real Gap: Quantifying the Effect of Model Misspecification in Network Games</title><link>https://arxiv.org/abs/2601.16367</link><description>arXiv:2601.16367v1 Announce Type: new 
Abstract: Game-theoretic models and solution concepts provide rigorous tools for predicting collective behavior in multi-agent systems. In practice, however, different agents may rely on different game-theoretic models to design their strategies. As a result, when these heterogeneous models interact, the realized outcome can deviate substantially from the outcome each agent expects based on its own local model. In this work, we introduce the game-to-real gap, a new metric that quantifies the impact of such model misspecification in multi-agent environments. The game-to-real gap is defined as the difference between the utility an agent actually obtains in the multi-agent environment (where other agents may have misspecified models) and the utility it expects under its own game model. Focusing on quadratic network games, we show that misspecifications in either (i) the external shock or (ii) the player interaction network can lead to arbitrarily large game-to-real gaps. We further develop novel network centrality measures that allow exact evaluation of this gap in quadratic network games. Our analysis reveals that standard network centrality measures fail to capture the effects of model misspecification, underscoring the need for new structural metrics that account for this limitation. Finally, through illustrative numerical experiments, we show that existing centrality measures in network games may provide a counterintuitive understanding of the impact of model misspecification.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16367v1</guid></item><item><title>[cs updates on arXiv.org] Improving the Accuracy of Community Detection on Signed Networks via Community Refinement and Contrastive Learning</title><link>https://arxiv.org/abs/2601.16372</link><description>arXiv:2601.16372v1 Announce Type: new 
Abstract: Community detection (CD) on signed networks is crucial for understanding how positive and negative relations jointly shape network structure. However, existing CD methods often yield inconsistent communities due to noisy or conflicting edge signs. In this paper, we propose ReCon, a model-agnostic post-processing framework that progressively refines community structures through four iterative steps: (1) structural refinement, (2) boundary refinement, (3) contrastive learning, and (4) clustering. Extensive experiments on eighteen synthetic and four real-world networks using four CD methods demonstrate that ReCon consistently enhances community detection accuracy, serving as an effective and easily integrable solution for reliable CD across diverse network properties.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16372v1</guid></item><item><title>[cs updates on arXiv.org] PolyAgent: Large Language Model Agent for Polymer Design</title><link>https://arxiv.org/abs/2601.16376</link><description>arXiv:2601.16376v1 Announce Type: new 
Abstract: On-demand Polymer discovery is essential for various industries, ranging from biomedical to reinforcement materials. Experiments with polymers have a long trial-and-error process, leading to long procedures and extensive resources. For these processes, machine learning has accelerated scientific discovery at the property prediction and latent space search fronts. However, laboratory researchers cannot readily access codes and these models to extract individual structures and properties due to infrastructure limitations. We present a closed-loop polymer structure-property predictor integrated in a terminal for early-stage polymer discovery. The framework is powered by LLM reasoning to provide users with property prediction, property-guided polymer structure generation, and structure modification capabilities. The SMILES sequences are guided by the synthetic accessibility score and the synthetic complexity score (SC Score) to ensure that polymer generation is as close as possible to synthetically accessible monomer-level structures. This framework addresses the challenge of generating novel polymer structures for laboratory researchers, thereby providing computational insights into polymer research.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16376v1</guid></item><item><title>[cs updates on arXiv.org] Cognitively-Inspired Tokens Overcome Egocentric Bias in Multimodal Models</title><link>https://arxiv.org/abs/2601.16378</link><description>arXiv:2601.16378v1 Announce Type: new 
Abstract: Multimodal language models (MLMs) perform well on semantic vision-language tasks but fail at spatial reasoning that requires adopting another agent's visual perspective. These errors reflect a persistent egocentric bias and raise questions about whether current models support allocentric reasoning. Inspired by human spatial cognition, we introduce perspective tokens, specialized embeddings that encode orientation through either (1) embodied body-keypoint cues or (2) abstract representations supporting mental rotation. Integrating these tokens into LLaVA-1.5-13B yields performance on level-2 visual perspective-taking tasks. Across synthetic and naturalistic benchmarks (Isle Bricks V2, COCO, 3DSRBench), perspective tokens improve accuracy, with rotation-based tokens generalizing to non-human reference agents. Representational analyses reveal that fine-tuning enhances latent orientation sensitivity already present in the base model, suggesting that MLMs contain precursors of allocentric reasoning but lack appropriate internal structure. Overall, embedding cognitively grounded spatial structure directly into token space provides a lightweight, model-agnostic mechanism for perspective-taking and more human-like spatial reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16378v1</guid></item><item><title>[cs updates on arXiv.org] VTFusion: A Vision-Text Multimodal Fusion Network for Few-Shot Anomaly Detection</title><link>https://arxiv.org/abs/2601.16381</link><description>arXiv:2601.16381v1 Announce Type: new 
Abstract: Few-Shot Anomaly Detection (FSAD) has emerged as a critical paradigm for identifying irregularities using scarce normal references. While recent methods have integrated textual semantics to complement visual data, they predominantly rely on features pre-trained on natural scenes, thereby neglecting the granular, domain-specific semantics essential for industrial inspection. Furthermore, prevalent fusion strategies often resort to superficial concatenation, failing to address the inherent semantic misalignment between visual and textual modalities, which compromises robustness against cross-modal interference. To bridge these gaps, this study proposes VTFusion, a vision-text multimodal fusion framework tailored for FSAD. The framework rests on two core designs. First, adaptive feature extractors for both image and text modalities are introduced to learn task-specific representations, bridging the domain gap between pre-trained models and industrial data; this is further augmented by generating diverse synthetic anomalies to enhance feature discriminability. Second, a dedicated multimodal prediction fusion module is developed, comprising a fusion block that facilitates rich cross-modal information exchange and a segmentation network that generates refined pixel-level anomaly maps under multimodal guidance. VTFusion significantly advances FSAD performance, achieving image-level AUROCs of 96.8% and 86.2% in the 2-shot scenario on the MVTec AD and VisA datasets, respectively. Furthermore, VTFusion achieves an AUPRO of 93.5% on a real-world dataset of industrial automotive plastic parts introduced in this paper, further demonstrating its practical applicability in demanding industrial scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16381v1</guid></item><item><title>[cs updates on arXiv.org] Cross-Lingual Activation Steering for Multilingual Language Models</title><link>https://arxiv.org/abs/2601.16390</link><description>arXiv:2601.16390v1 Announce Type: new 
Abstract: Large language models exhibit strong multilingual capabilities, yet significant performance gaps persist between dominant and non-dominant languages. Prior work attributes this gap to imbalances between shared and language-specific neurons in multilingual representations. We propose Cross-Lingual Activation Steering (CLAS), a training-free inference-time intervention that selectively modulates neuron activations. We evaluate CLAS on classification and generation benchmarks, achieving average improvements of 2.3% (Acc.) and 3.4% (F1) respectively, while maintaining high-resource language performance. We discover that effective transfer operates through functional divergence rather than strict alignment; performance gains correlate with increased language cluster separation. Our results demonstrate that targeted activation steering can unlock latent multilingual capacity in existing models without modification to model weights.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16390v1</guid></item><item><title>[cs updates on arXiv.org] Toward Agentic Software Project Management: A Vision and Roadmap</title><link>https://arxiv.org/abs/2601.16392</link><description>arXiv:2601.16392v1 Announce Type: new 
Abstract: With the advent of agentic AI, Software Engineering is transforming to a new era dubbed Software Engineering 3.0. Software project management (SPM) must also evolve with such transformations to boost successful project completion, while keeping humans at the heart of it. Building on our preliminary ideas of "agentic SPM", and supporting literature, we present our vision of an "Agentic Project Manager (PM)" as a multi-agent system for SPM 3.0. They will work like a "junior project manager", or an "intern project manager" collaboratively with software teams. We introduce four working modes, with varying autonomy levels to choose from, based on the SPM task. This addresses concerns with ethics, accountability, and trust related to agentic PMs. We also share insights on human PM role evolution and new skill requirements as a "strategic leader" and a "coach" for humans and agents. While creating the foundation for agentic SPM research, we present a research agenda for the wider research community.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16392v1</guid></item><item><title>[cs updates on arXiv.org] ResAgent: Entropy-based Prior Point Discovery and Visual Reasoning for Referring Expression Segmentation</title><link>https://arxiv.org/abs/2601.16394</link><description>arXiv:2601.16394v1 Announce Type: new 
Abstract: Referring Expression Segmentation (RES) is a core vision-language segmentation task that enables pixel-level understanding of targets via free-form linguistic expressions, supporting critical applications such as human-robot interaction and augmented reality. Despite the progress of Multimodal Large Language Model (MLLM)-based approaches, existing RES methods still suffer from two key limitations: first, the coarse bounding boxes from MLLMs lead to redundant or non-discriminative point prompts; second, the prevalent reliance on textual coordinate reasoning is unreliable, as it fails to distinguish targets from visually similar distractors. To address these issues, we propose \textbf{\model}, a novel RES framework integrating \textbf{E}ntropy-\textbf{B}ased Point \textbf{D}iscovery (\textbf{EBD}) and \textbf{V}ision-\textbf{B}ased \textbf{R}easoning (\textbf{VBR}). Specifically, EBD identifies high-information candidate points by modeling spatial uncertainty within coarse bounding boxes, treating point selection as an information maximization process. VBR verifies point correctness through joint visual-semantic alignment, abandoning text-only coordinate inference for more robust validation. Built on these components, \model implements a coarse-to-fine workflow: bounding box initialization, entropy-guided point discovery, vision-based validation, and mask decoding. Extensive evaluations on four benchmark datasets (RefCOCO, RefCOCO+, RefCOCOg, and ReasonSeg) demonstrate that \model achieves new state-of-the-art performance across all four benchmarks, highlighting its effectiveness in generating accurate and semantically grounded segmentation masks with minimal prompts.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16394v1</guid></item><item><title>[cs updates on arXiv.org] Cite-While-You-Generate: Training-Free Evidence Attribution for Multimodal Clinical Summarization</title><link>https://arxiv.org/abs/2601.16397</link><description>arXiv:2601.16397v1 Announce Type: new 
Abstract: Trustworthy clinical summarization requires not only fluent generation but also transparency about where each statement comes from. We propose a training-free framework for generation-time source attribution that leverages decoder attentions to directly cite supporting text spans or images, overcoming the limitations of post-hoc or retraining-based methods. We introduce two strategies for multimodal attribution: a raw image mode, which directly uses image patch attentions, and a caption-as-span mode, which substitutes images with generated captions to enable purely text-based alignment. Evaluations on two representative domains: clinician-patient dialogues (CliConSummation) and radiology reports (MIMIC-CXR), show that our approach consistently outperforms embedding-based and self-attribution baselines, improving both text-level and multimodal attribution accuracy (e.g., +15% F1 over embedding baselines). Caption-based attribution achieves competitive performance with raw-image attention while being more lightweight and practical. These findings highlight attention-guided attribution as a promising step toward interpretable and deployable clinical summarization systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16397v1</guid></item><item><title>[cs updates on arXiv.org] White-Box Sensitivity Auditing with Steering Vectors</title><link>https://arxiv.org/abs/2601.16398</link><description>arXiv:2601.16398v1 Announce Type: new 
Abstract: Algorithmic audits are essential tools for examining systems for properties required by regulators or desired by operators. Current audits of large language models (LLMs) primarily rely on black-box evaluations that assess model behavior only through input-output testing. These methods are limited to tests constructed in the input space, often generated by heuristics. In addition, many socially relevant model properties (e.g., gender bias) are abstract and difficult to measure through text-based inputs alone. To address these limitations, we propose a white-box sensitivity auditing framework for LLMs that leverages activation steering to conduct more rigorous assessments through model internals. Our auditing method conducts internal sensitivity tests by manipulating key concepts relevant to the model's intended function for the task. We demonstrate its application to bias audits in four simulated high-stakes LLM decision tasks. Our method consistently reveals substantial dependence on protected attributes in model predictions, even in settings where standard black-box evaluations suggest little or no bias. Our code is openly available at https://github.com/hannahxchen/llm-steering-audit</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16398v1</guid></item><item><title>[cs updates on arXiv.org] A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning</title><link>https://arxiv.org/abs/2601.16399</link><description>arXiv:2601.16399v1 Announce Type: new 
Abstract: We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objective depends on the optimal induced policy. Existing methods for bi-level optimization and RL often require second-order information, impose strong regularization at the lower level, or inefficiently use samples through nested-loop procedures. In this work, we propose a single-loop, first-order actor-critic algorithm that optimizes the bi-level objective via a penalty-based reformulation. We introduce into the lower-level RL objective an attenuating entropy regularization, which enables asymptotically unbiased upper-level hyper-gradient estimation without solving the unregularized RL problem exactly. We establish the finite-time and finite-sample convergence of the proposed algorithm to a stationary point of the original, unregularized bi-level optimization problem through a novel lower-level residual analysis under a special type of Polyak-Lojasiewicz condition. We validate the performance of our method through experiments on a GridWorld goal position problem and on happy tweet generation through reinforcement learning from human feedback (RLHF).</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16399v1</guid></item><item><title>[cs updates on arXiv.org] Clarify or Answer: Reinforcement Learning for Agentic VQA with Context Under-specification</title><link>https://arxiv.org/abs/2601.16400</link><description>arXiv:2601.16400v1 Announce Type: new 
Abstract: Real-world visual question answering (VQA) is often context-dependent: an image-question pair may be under-specified, such that the correct answer depends on external information that is not observable in the image. In such cases, directly answering can lead to confident but incorrect predictions. We propose CoA(Clarify-or-Answer), an ask-or-answer agent that separately models the decision to ask or answer, and what to ask if needed. CoA first determines whether clarification is necessary; if so, it asks a single focused question and then incorporates the response to produce the final answer. We introduce CONTEXTCLARIFY with a set of ambiguous VQA questions and the contrast set that is non-ambiguous. We further introduce GRPO-CR (Clarification Reasoning), a reinforcement learning approach that optimizes clarification question generation with multiple reward signals encouraging well-formed, focused, non-trivial questions that resolve ambiguity. Across three VLLMs and three datasets, CoA achieves consistent improvements at both the module and system levels, improving end-to-end VQA accuracy by an average of +15.3 points (83%) over prompting-based baselines</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16400v1</guid></item><item><title>[cs updates on arXiv.org] Towards a Theoretical Understanding to the Generalization of RLHF</title><link>https://arxiv.org/abs/2601.16403</link><description>arXiv:2601.16403v1 Announce Type: new 
Abstract: Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored. To this end, we build the generalization theory on RLHF of LLMs under the linear reward model, through the framework of algorithmic stability. In contrast to the existing works built upon the consistency of maximum likelihood estimations on reward model, our analysis is presented under an end-to-end learning framework, which is consistent with practice. Concretely, we prove that under a key \textbf{feature coverage} condition, the empirical optima of policy model have a generalization bound of order $\mathcal{O}(n^{-\frac{1}{2}})$. Moreover, the results can be extrapolated to parameters obtained by gradient-based learning algorithms, i.e., Gradient Ascent (GA) and Stochastic Gradient Ascent (SGA). Thus, we argue that our results provide new theoretical evidence for the empirically observed generalization of LLMs after RLHF.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16403v1</guid></item><item><title>[cs updates on arXiv.org] Reinforcement Learning-Based Energy-Aware Coverage Path Planning for Precision Agriculture</title><link>https://arxiv.org/abs/2601.16405</link><description>arXiv:2601.16405v1 Announce Type: new 
Abstract: Coverage Path Planning (CPP) is a fundamental capability for agricultural robots; however, existing solutions often overlook energy constraints, resulting in incomplete operations in large-scale or resource-limited environments. This paper proposes an energy-aware CPP framework grounded in Soft Actor-Critic (SAC) reinforcement learning, designed for grid-based environments with obstacles and charging stations. To enable robust and adaptive decision-making under energy limitations, the framework integrates Convolutional Neural Networks (CNNs) for spatial feature extraction and Long Short-Term Memory (LSTM) networks for temporal dynamics. A dedicated reward function is designed to jointly optimize coverage efficiency, energy consumption, and return-to-base constraints. Experimental results demonstrate that the proposed approach consistently achieves over 90% coverage while ensuring energy safety, outperforming traditional heuristic algorithms such as Rapidly-exploring Random Tree (RRT), Particle Swarm Optimization (PSO), and Ant Colony Optimization (ACO) baselines by 13.4-19.5% in coverage and reducing constraint violations by 59.9-88.3%. These findings validate the proposed SAC-based framework as an effective and scalable solution for energy-constrained CPP in agricultural robotics.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16405v1</guid></item><item><title>[cs updates on arXiv.org] Reasoning-Enhanced Rare-Event Prediction with Balanced Outcome Correction</title><link>https://arxiv.org/abs/2601.16406</link><description>arXiv:2601.16406v1 Announce Type: new 
Abstract: Rare-event prediction is critical in domains such as healthcare, finance, reliability engineering, customer support, aviation safety, where positive outcomes are infrequent yet potentially catastrophic. Extreme class imbalance biases conventional models toward majority-class predictions, limiting recall, calibration, and operational usefulness. We propose LPCORP (Low-Prevalence CORrector for Prediction)*, a two-stage framework that combines reasoningenhanced prediction with confidence-based outcome correction. A reasoning model first produces enriched predictions from narrative inputs, after which a lightweight logistic-regression classifier evaluates and selectively corrects these outputs to mitigate prevalence-driven bias. We evaluate LPCORP on real-world datasets from medical and consumer service domains. The results show that this method transforms a highly imbalanced setting into a well-balanced one while preserving the original number of samples and without applying any resampling strategies. Test-set evaluation demonstrates substantially improved performance, particularly in precision, which is a known weakness in low-prevalence data. We further provide a costreduction analysis comparing the expenses associated with rare-event damage control without preventive measures to those incurred when low-cost, prediction-based preventive interventions are applied that showed more than 50% reduction in some cases. * Patent pending: U.S. Provisional 63/933,518, filed 8 December 2025.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16406v1</guid></item><item><title>[cs updates on arXiv.org] Jacobian Scopes: token-level causal attributions in LLMs</title><link>https://arxiv.org/abs/2601.16407</link><description>arXiv:2601.16407v1 Announce Type: new 
Abstract: Large language models (LLMs) make next-token predictions based on clues present in their context, such as semantic descriptions and in-context examples. Yet, elucidating which prior tokens most strongly influence a given prediction remains challenging due to the proliferation of layers and attention heads in modern architectures. We propose Jacobian Scopes, a suite of gradient-based, token-level causal attribution methods for interpreting LLM predictions. By analyzing the linearized relations of final hidden state with respect to inputs, Jacobian Scopes quantify how input tokens influence a model's prediction. We introduce three variants - Semantic, Fisher, and Temperature Scopes - which respectively target sensitivity of specific logits, the full predictive distribution, and model confidence (inverse temperature). Through case studies spanning instruction understanding, translation and in-context learning (ICL), we uncover interesting findings, such as when Jacobian Scopes point to implicit political biases. We believe that our proposed methods also shed light on recently debated mechanisms underlying in-context time-series forecasting. Our code and interactive demonstrations are publicly available at https://github.com/AntonioLiu97/JacobianScopes.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16407v1</guid></item><item><title>[cs updates on arXiv.org] Gen-DBA: Generative Database Agents (Towards a Move 37 for Databases)</title><link>https://arxiv.org/abs/2601.16409</link><description>arXiv:2601.16409v1 Announce Type: new 
Abstract: Move\,37 marks one of the major breakthroughs in AI in terms of its ability to surpass human expertise and discover novel strategies beyond the traditional game play in the strategic two-player board game of Go. The domains of Natural Language Processing, Computer Vision, and Robotics have also undergone a similar phenomenon through the advent of large foundational models in the form of Large Language Models (LLMs), Vision Language Models (VLMs) and Vision Language Action models (VLAs), respectively. In this paper, we investigate the current state of Artificial Intelligence for Database Systems research (AI4DB), and assess how far AI4DB systems are from achieving their own Move\,37 moment. We envision a Generative Database Agent (Gen-DBA, for short) as the pathway to achieving Move\,37 for database systems that will bring generative reasoning and creativity into the realm of database learning tasks. This vision paper explores this direction by presenting the recipe for building Gen-DBA that encompasses but is not limited to a Transformer backbone, a hardware-grounded tokenization mechanism, a two-stage Goal-Directed Next Token Prediction training paradigm, and a generative inference process.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16409v1</guid></item><item><title>[cs updates on arXiv.org] A Cosine Network for Image Super-Resolution</title><link>https://arxiv.org/abs/2601.16413</link><description>arXiv:2601.16413v1 Announce Type: new 
Abstract: Deep convolutional neural networks can use hierarchical information to progressively extract structural information to recover high-quality images. However, preserving the effectiveness of the obtained structural information is important in image super-resolution. In this paper, we propose a cosine network for image super-resolution (CSRNet) by improving a network architecture and optimizing the training strategy. To extract complementary homologous structural information, odd and even heterogeneous blocks are designed to enlarge the architectural differences and improve the performance of image super-resolution. Combining linear and non-linear structural information can overcome the drawback of homologous information and enhance the robustness of the obtained structural information in image super-resolution. Taking into account the local minimum of gradient descent, a cosine annealing mechanism is used to optimize the training procedure by performing warm restarts and adjusting the learning rate. Experimental results illustrate that the proposed CSRNet is competitive with state-of-the-art methods in image super-resolution.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16413v1</guid></item><item><title>[cs updates on arXiv.org] PyHealth 2.0: A Comprehensive Open-Source Toolkit for Accessible and Reproducible Clinical Deep Learning</title><link>https://arxiv.org/abs/2601.16414</link><description>arXiv:2601.16414v1 Announce Type: new 
Abstract: Difficulty replicating baselines, high computational costs, and required domain expertise create persistent barriers to clinical AI research. To address these challenges, we introduce PyHealth 2.0, an enhanced clinical deep learning toolkit that enables predictive modeling in as few as 7 lines of code. PyHealth 2.0 offers three key contributions: (1) a comprehensive toolkit addressing reproducibility and compatibility challenges by unifying 15+ datasets, 20+ clinical tasks, 25+ models, 5+ interpretability methods, and uncertainty quantification including conformal prediction within a single framework that supports diverse clinical data modalities - signals, imaging, and electronic health records - with translation of 5+ medical coding standards; (2) accessibility-focused design accommodating multimodal data and diverse computational resources with up to 39x faster processing and 20x lower memory usage, enabling work from 16GB laptops to production systems; and (3) an active open-source community of 400+ members lowering domain expertise barriers through extensive documentation, reproducible research contributions, and collaborations with academic health systems and industry partners, including multi-language support via RHealth. PyHealth 2.0 establishes an open-source foundation and community advancing accessible, reproducible healthcare AI. Available at pip install pyhealth.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16414v1</guid></item><item><title>[cs updates on arXiv.org] Learning Domain Knowledge in Multimodal Large Language Models through Reinforcement Fine-Tuning</title><link>https://arxiv.org/abs/2601.16419</link><description>arXiv:2601.16419v1 Announce Type: new 
Abstract: Multimodal large language models (MLLMs) have shown remarkable capabilities in multimodal perception and understanding tasks. However, their effectiveness in specialized domains, such as remote sensing and medical imaging, remains limited. A natural approach to domain adaptation is to inject domain knowledge through textual instructions, prompts, or auxiliary captions. Surprisingly, we find that such input-level domain knowledge injection yields little to no improvement on scientific multimodal tasks, even when the domain knowledge is explicitly provided. This observation suggests that current MLLMs fail to internalize domain-specific priors through language alone, and that domain knowledge must be integrated at the optimization level. Motivated by this insight, we propose a reinforcement fine-tuning framework that incorporates domain knowledge directly into the learning objective. Instead of treating domain knowledge as descriptive information, we encode it as domain-informed constraints and reward signals, shaping the model's behavior in the output space. Extensive experiments across multiple datasets in remote sensing and medical domains consistently demonstrate good performance gains, achieving state-of-the-art results on multimodal domain tasks. Our results highlight the necessity of optimization-level domain knowledge integration and reveal a fundamental limitation of textual domain conditioning in current MLLMs.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16419v1</guid></item><item><title>[cs updates on arXiv.org] RENEW: Risk- and Energy-Aware Navigation in Dynamic Waterways</title><link>https://arxiv.org/abs/2601.16424</link><description>arXiv:2601.16424v1 Announce Type: new 
Abstract: We present RENEW, a global path planner for Autonomous Surface Vehicle (ASV) in dynamic environments with external disturbances (e.g., water currents). RENEW introduces a unified risk- and energy-aware strategy that ensures safety by dynamically identifying non-navigable regions and enforcing adaptive safety constraints. Inspired by maritime contingency planning, it employs a best-effort strategy to maintain control under adverse conditions. The hierarchical architecture combines high-level constrained triangulation for topological diversity with low-level trajectory optimization within safe corridors. Validated with real-world ocean data, RENEW is the first framework to jointly address adaptive non-navigability and topological path diversity for robust maritime navigation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16424v1</guid></item><item><title>[cs updates on arXiv.org] Bayesian Experimental Design for Model Discrepancy Calibration: A Rivalry between Kullback--Leibler Divergence and Wasserstein Distance</title><link>https://arxiv.org/abs/2601.16425</link><description>arXiv:2601.16425v1 Announce Type: new 
Abstract: Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experimental planning with probabilistic inference, the selection of utility functions in BED is a long-standing and active topic, where different criteria emphasize different notions of information. Although Kullback--Leibler (KL) divergence has been one of the most common choices, recent studies have proposed Wasserstein distance as an alternative. In this work, we first employ a toy example to illustrate an issue of Wasserstein distance - the value of Wasserstein distance of a fixed-shape posterior depends on the relative position of its main mass within the support and can exhibit false rewards unrelated to information gain, especially with a non-informative prior (e.g., uniform distribution). We then further provide a systematic comparison between these two criteria through a classical source inversion problem in the BED literature, revealing that the KL divergence tends to lead to faster convergence in the absence of model discrepancy, while Wasserstein metrics provide more robust sequential BED results if model discrepancy is non-negligible. These findings clarify the trade-offs between KL divergence and Wasserstein metrics for the utility function and provide guidelines for selecting suitable criteria in practical BED applications.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16425v1</guid></item><item><title>[cs updates on arXiv.org] Safe Multitask Molecular Graph Networks for Vapor Pressure and Odor Threshold Prediction</title><link>https://arxiv.org/abs/2601.16426</link><description>arXiv:2601.16426v1 Announce Type: new 
Abstract: We investigate two important tasks in odor-related property modeling: Vapor Pressure (VP) and Odor Threshold (OP). To evaluate the model's out-of-distribution (OOD) capability, we adopt the Bemis-Murcko scaffold split. In terms of features, we introduce the rich A20/E17 molecular graph features (20-dimensional atom features + 17-dimensional bond features) and systematically compare GINE and PNA backbones. The results show: for VP, PNA with a simple regression head achieves Val MSE $\approx$ 0.21 (normalized space); for the OP single task under the same scaffold split, using A20/E17 with robust training (Huber/winsor) achieves Val MSE $\approx$ 0.60-0.61. For multitask training, we propose a **"safe multitask"** approach: VP as the primary task and OP as the auxiliary task, using delayed activation + gradient clipping + small weight, which avoids harming the primary task and simultaneously yields the best VP generalization performance. This paper provides complete reproducible experiments, ablation studies, and error-similarity analysis while discussing the impact of data noise and method limitations.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16426v1</guid></item><item><title>[cs updates on arXiv.org] DCCS-Det: Directional Context and Cross-Scale-Aware Detector for Infrared Small Target</title><link>https://arxiv.org/abs/2601.16428</link><description>arXiv:2601.16428v1 Announce Type: new 
Abstract: Infrared small target detection (IRSTD) is critical for applications like remote sensing and surveillance, which aims to identify small, low-contrast targets against complex backgrounds. However, existing methods often struggle with inadequate joint modeling of local-global features (harming target-background discrimination) or feature redundancy and semantic dilution (degrading target representation quality). To tackle these issues, we propose DCCS-Det (Directional Context and Cross-Scale Aware Detector for Infrared Small Target), a novel detector that incorporates a Dual-stream Saliency Enhancement (DSE) block and a Latent-aware Semantic Extraction and Aggregation (LaSEA) module. The DSE block integrates localized perception with direction-aware context aggregation to help capture long-range spatial dependencies and local details. On this basis, the LaSEA module mitigates feature degradation via cross-scale feature extraction and random pooling sampling strategies, enhancing discriminative features and suppressing noise. Extensive experiments show that DCCS-Det achieves state-of-the-art detection accuracy with competitive efficiency across multiple datasets. Ablation studies further validate the contributions of DSE and LaSEA in improving target perception and feature representation under complex scenarios. \href{https://huggingface.co/InPeerReview/InfraredSmallTargetDetection-IRSTD.DCCS}{DCCS-Det Official Code is Available Here!}</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16428v1</guid></item><item><title>[cs updates on arXiv.org] AlphaFace: High Fidelity and Real-time Face Swapper Robust to Facial Pose</title><link>https://arxiv.org/abs/2601.16429</link><description>arXiv:2601.16429v1 Announce Type: new 
Abstract: Existing face-swapping methods often deliver competitive results in constrained settings but exhibit substantial quality degradation when handling extreme facial poses. To improve facial pose robustness, explicit geometric features are applied, but this approach remains problematic since it introduces additional dependencies and increases computational cost. Diffusion-based methods have achieved remarkable results; however, they are impractical for real-time processing. We introduce AlphaFace, which leverages an open-source vision-language model and CLIP image and text embeddings to apply novel visual and textual semantic contrastive losses. AlphaFace enables stronger identity representation and more precise attribute preservation, all while maintaining real-time performance. Comprehensive experiments across FF++, MPIE, and LPFF demonstrate that AlphaFace surpasses state-of-the-art methods in pose-challenging cases. The project is publicly available on `https://github.com/andrewyu90/Alphaface_Official.git'.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16429v1</guid></item><item><title>[cs updates on arXiv.org] iPDB -- Optimizing SQL Queries with ML and LLM Predicates</title><link>https://arxiv.org/abs/2601.16432</link><description>arXiv:2601.16432v1 Announce Type: new 
Abstract: Structured Query Language (SQL) has remained the standard query language for databases. SQL is highly optimized for processing structured data laid out in relations. Meanwhile, in the present application development landscape, it is highly desirable to utilize the power of learned models to perform complex tasks. Large language models (LLMs) have been shown to understand and extract information from unstructured textual data. However, SQL as a query language and accompanying relational database systems are either incompatible or inefficient for workloads that require leveraging learned models. This results in complex engineering and multiple data migration operations that move data between the data sources and the model inference platform. In this paper, we present iPDB, a relational system that supports in-database machine learning (ML) and large language model (LLM) inferencing using extended SQL syntax. In iPDB, LLMs and ML calls can function as semantic projects, as predicates to perform semantic selects and semantic joins, or for semantic grouping in group-by clauses. iPDB has a novel relational predict operator and semantic query optimizations that enable users to write and efficiently execute semantic SQL queries, outperforming the state-of-the-art.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16432v1</guid></item><item><title>[cs updates on arXiv.org] MDAFNet: Multiscale Differential Edge and Adaptive Frequency Guided Network for Infrared Small Target Detection</title><link>https://arxiv.org/abs/2601.16434</link><description>arXiv:2601.16434v1 Announce Type: new 
Abstract: Infrared small target detection (IRSTD) plays a crucial role in numerous military and civilian applications. However, existing methods often face the gradual degradation of target edge pixels as the number of network layers increases, and traditional convolution struggles to differentiate between frequency components during feature extraction, leading to low-frequency backgrounds interfering with high-frequency targets and high-frequency noise triggering false detections. To address these limitations, we propose MDAFNet (Multi-scale Differential Edge and Adaptive Frequency Guided Network for Infrared Small Target Detection), which integrates the Multi-Scale Differential Edge (MSDE) module and Dual-Domain Adaptive Feature Enhancement (DAFE) module. The MSDE module, through a multi-scale edge extraction and enhancement mechanism, effectively compensates for the cumulative loss of target edge information during downsampling. The DAFE module combines frequency domain processing mechanisms with simulated frequency decomposition and fusion mechanisms in the spatial domain to effectively improve the network's capability to adaptively enhance high-frequency targets and selectively suppress high-frequency noise. Experimental results on multiple datasets demonstrate the superior detection performance of MDAFNet.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16434v1</guid></item><item><title>[cs updates on arXiv.org] Two classes of LCD codes derived from $(\mathcal{L},\mathcal{P})$-TGRS codes</title><link>https://arxiv.org/abs/2601.16438</link><description>arXiv:2601.16438v1 Announce Type: new 
Abstract: Twisted generalized Reed-Solomon (TGRS) codes, as a flexible extension of classical generalized Reed-Solomon (GRS) codes, have attracted significant attention in recent years. In this paper, we construct two classes of LCD codes from the $(\mathcal{L},\mathcal{P})$-TGRS code $\mathcal{C}_h$ of length $n$ and dimension $k$, where $\mathcal{L}=\{0,1,\ldots,l\}$ for $l\leq n-k-1$ and $\mathcal{P}=\{h\}$ for $1\leq h\leq k-1$. First, we derive the parity check matrix of $\mathcal{C}_h$ and provide a necessary and sufficient condition for $\mathcal{C}_h$ to be an AMDS code. Then, we construct two classes of LCD codes from $\mathcal{C}_h$ by suitably choosing the evaluation points together with certain restrictions on the coefficient of $x^{h-1}$ in the polynomial associated with the twisting term. From the constructed LCD codes we further obtain two classes of LCD MDS codes. Finally, several examples are presented.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16438v1</guid></item><item><title>[cs updates on arXiv.org] Masked Face Recognition under Different Backbones</title><link>https://arxiv.org/abs/2601.16440</link><description>arXiv:2601.16440v1 Announce Type: new 
Abstract: Erratum to the paper (Zhang et al., 2025): corrections to Table IV and the data in Page 3, Section A. In the post-pandemic era, a high proportion of civil aviation passengers wear masks during security checks, posing significant challenges to traditional face recognition models. The backbone network serves as the core component of face recognition models. In standard tests, r100 series models excelled (98%+ accuracy at 0.01% FAR in face comparison, high top1/top5 in search). r50 ranked second, r34_mask_v1 lagged. In masked tests, r100_mask_v2 led (90.07% accuracy), r50_mask_v3 performed best among r50 but trailed r100. Vit-Small/Tiny showed strong masked performance with gains in effectiveness. Through extensive comparative experiments, this paper conducts a comprehensive evaluation of several core backbone networks, aiming to reveal the impacts of different models on face recognition with and without masks, and provide specific deployment recommendations.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16440v1</guid></item><item><title>[cs updates on arXiv.org] Endless Terminals: Scaling RL Environments for Terminal Agents</title><link>https://arxiv.org/abs/2601.16443</link><description>arXiv:2601.16443v1 Announce Type: new 
Abstract: Environments are the bottleneck for self-improving agents. Current terminal benchmarks were built for evaluation, not training; reinforcement learning requires a scalable pipeline, not just a dataset. We introduce Endless Terminals, a fully autonomous pipeline that procedurally generates terminal-use tasks without human annotation. The pipeline has four stages: generating diverse task descriptions, building and validating containerized environments, producing completion tests, and filtering for solvability. From this pipeline we obtain 3255 tasks spanning file operations, log management, data processing, scripting, and database operations. We train agents using vanilla PPO with binary episode level rewards and a minimal interaction loop: no retrieval, multi-agent coordination, or specialized tools. Despite this simplicity, models trained on Endless Terminals show substantial gains: on our held-out dev set, Llama-3.2-3B improves from 4.0% to 18.2%, Qwen2.5-7B from 10.7% to 53.3%, and Qwen3-8B-openthinker-sft from 42.6% to 59.0%. These improvements transfer to human-curated benchmarks: models trained on Endless Terminals show substantial gains on held out human curated benchmarks: on TerminalBench 2.0, Llama-3.2-3B improves from 0.0% to 2.2%, Qwen2.5-7B from 2.2% to 3.4%, and Qwen3-8B-openthinker-sft from 1.1% to 6.7%, in each case outperforming alternative approaches including models with more complex agentic scaffolds. These results demonstrate that simple RL succeeds when environments scale.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16443v1</guid></item><item><title>[cs updates on arXiv.org] Exploring the Effects of Alignment on Numerical Bias in Large Language Models</title><link>https://arxiv.org/abs/2601.16444</link><description>arXiv:2601.16444v1 Announce Type: new 
Abstract: ``LLM-as-a-judge,'' which utilizes large language models (LLMs) as evaluators, has proven effective in many evaluation tasks. However, evaluator LLMs exhibit numerical bias, a phenomenon where certain evaluation scores are generated disproportionately often, leading reduced evaluation performance. This study investigates the cause of this bias. Given that most evaluator LLMs are aligned through instruction tuning and preference tuning, and that prior research suggests alignment reduces output diversity, we hypothesize that numerical bias arises from alignment. To test this, we compare outputs from pre- and post-alignment LLMs, and observe that alignment indeed increases numerical bias. We also explore mitigation strategies for post-alignment LLMs, including temperature scaling, distribution calibration, and score range adjustment. Among these, score range adjustment is most effective in reducing bias and improving performance, though still heuristic. Our findings highlight the need for further work on optimal score range selection and more robust mitigation strategies.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16444v1</guid></item><item><title>[cs updates on arXiv.org] Brownian ReLU(Br-ReLU): A New Activation Function for a Long-Short Term Memory (LSTM) Network</title><link>https://arxiv.org/abs/2601.16446</link><description>arXiv:2601.16446v1 Announce Type: new 
Abstract: Deep learning models are effective for sequential data modeling, yet commonly used activation functions such as ReLU, LeakyReLU, and PReLU often exhibit gradient instability when applied to noisy, non-stationary financial time series. This study introduces BrownianReLU, a stochastic activation function induced by Brownian motion that enhances gradient propagation and learning stability in Long Short-Term Memory (LSTM) networks. Using Monte Carlo simulation, BrownianReLU provides a smooth, adaptive response for negative inputs, mitigating the dying ReLU problem. The proposed activation is evaluated on financial time series from Apple, GCB, and the S&amp;amp;P 500, as well as LendingClub loan data for classification. Results show consistently lower Mean Squared Error and higher $R^2$ values, indicating improved predictive accuracy and generalization. Although ROC-AUC metric is limited in classification tasks, activation choice significantly affects the trade-off between accuracy and sensitivity, with Brownian ReLU and the selected activation functions yielding practically meaningful performance.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16446v1</guid></item><item><title>[cs updates on arXiv.org] Mixing Expert Knowledge: Bring Human Thoughts Back To the Game of Go</title><link>https://arxiv.org/abs/2601.16447</link><description>arXiv:2601.16447v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated exceptional performance in reasoning tasks such as mathematics and coding, matching or surpassing human capabilities. However, these impressive reasoning abilities face significant challenges in specialized domains. Taking Go as an example, although AlphaGo has established the high performance ceiling of AI systems in Go, mainstream LLMs still struggle to reach even beginner-level proficiency, let alone perform natural language reasoning. This performance gap between general-purpose LLMs and domain experts is significantly limiting the application of LLMs on a wider range of domain-specific tasks. In this work, we aim to bridge the divide between LLMs' general reasoning capabilities and expert knowledge in domain-specific tasks. We perform mixed fine-tuning with structured Go expertise and general long Chain-of-Thought (CoT) reasoning data as a cold start, followed by reinforcement learning to integrate expert knowledge in Go with general reasoning capabilities. Through this methodology, we present \textbf{LoGos}, a powerful LLM that not only maintains outstanding general reasoning abilities, but also conducts Go gameplay in natural language, demonstrating effective strategic reasoning and accurate next-move prediction. LoGos achieves performance comparable to human professional players, substantially surpassing all existing LLMs. Through this work, we aim to contribute insights on applying general LLM reasoning capabilities to specialized domains. We will release the first large-scale Go dataset for LLM training, the first LLM Go evaluation benchmark, and the first general LLM that reaches human professional-level performance in Go at: https://github.com/Entarochuan/LoGos.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16447v1</guid></item><item><title>[cs updates on arXiv.org] Emotion-LLaMAv2 and MMEVerse: A New Framework and Benchmark for Multimodal Emotion Understanding</title><link>https://arxiv.org/abs/2601.16449</link><description>arXiv:2601.16449v1 Announce Type: new 
Abstract: Understanding human emotions from multimodal signals poses a significant challenge in affective computing and human-robot interaction. While multimodal large language models (MLLMs) have excelled in general vision-language tasks, their capabilities in emotional reasoning remain limited. The field currently suffers from a scarcity of large-scale datasets with high-quality, descriptive emotion annotations and lacks standardized benchmarks for evaluation. Our preliminary framework, Emotion-LLaMA, pioneered instruction-tuned multimodal learning for emotion reasoning but was restricted by explicit face detectors, implicit fusion strategies, and low-quality training data with limited scale. To address these limitations, we present Emotion-LLaMAv2 and the MMEVerse benchmark, establishing an end-to-end pipeline together with a standardized evaluation setting for emotion recognition and reasoning. Emotion-LLaMAv2 introduces three key advances. First, an end-to-end multiview encoder eliminates external face detection and captures nuanced emotional cues via richer spatial and temporal multiview tokens. Second, a Conv Attention pre-fusion module is designed to enable simultaneous local and global multimodal feature interactions external to the LLM backbone. Third, a perception-to-cognition curriculum instruction tuning scheme within the LLaMA2 backbone unifies emotion recognition and free-form emotion reasoning. To support large-scale training and reproducible evaluation, MMEVerse aggregates twelve publicly available emotion datasets, including IEMOCAP, MELD, DFEW, and MAFW, into a unified multimodal instruction format. The data are re-annotated via a multi-agent pipeline involving Qwen2 Audio, Qwen2.5 VL, and GPT 4o, producing 130k training clips and 36k testing clips across 18 evaluation benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16449v1</guid></item><item><title>[cs updates on arXiv.org] On the Expressive Power of Floating-Point Transformers</title><link>https://arxiv.org/abs/2601.16450</link><description>arXiv:2601.16450v1 Announce Type: new 
Abstract: The study on the expressive power of transformers shows that transformers are permutation equivariant, and they can approximate all permutation-equivariant continuous functions on a compact domain. However, these results are derived under real parameters and exact operations, while real implementations on computers can only use a finite set of numbers and inexact machine operations with round-off errors. In this work, we investigate the representability of floating-point transformers that use floating-point parameters and floating-point operations. Unlike existing results under exact operations, we first show that floating-point transformers can represent a class of non-permutation-equivariant functions even without positional encoding. Furthermore, we prove that floating-point transformers can represent all permutation-equivariant functions when the sequence length is bounded, but they cannot when the sequence length is large. We also found the minimal equivariance structure in floating-point transformers, and show that all non-trivial additive positional encoding can harm the representability of floating-point transformers.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16450v1</guid></item><item><title>[cs updates on arXiv.org] VISTA-PATH: An interactive foundation model for pathology image segmentation and quantitative analysis in computational pathology</title><link>https://arxiv.org/abs/2601.16451</link><description>arXiv:2601.16451v1 Announce Type: new 
Abstract: Accurate semantic segmentation for histopathology image is crucial for quantitative tissue analysis and downstream clinical modeling. Recent segmentation foundation models have improved generalization through large-scale pretraining, yet remain poorly aligned with pathology because they treat segmentation as a static visual prediction task. Here we present VISTA-PATH, an interactive, class-aware pathology segmentation foundation model designed to resolve heterogeneous structures, incorporate expert feedback, and produce pixel-level segmentation that are directly meaningful for clinical interpretation. VISTA-PATH jointly conditions segmentation on visual context, semantic tissue descriptions, and optional expert-provided spatial prompts, enabling precise multi-class segmentation across heterogeneous pathology images. To support this paradigm, we curate VISTA-PATH Data, a large-scale pathology segmentation corpus comprising over 1.6 million image-mask-text triplets spanning 9 organs and 93 tissue classes. Across extensive held-out and external benchmarks, VISTA-PATH consistently outperforms existing segmentation foundation models. Importantly, VISTA-PATH supports dynamic human-in-the-loop refinement by propagating sparse, patch-level bounding-box annotation feedback into whole-slide segmentation. Finally, we show that the high-fidelity, class-aware segmentation produced by VISTA-PATH is a preferred model for computational pathology. It improve tissue microenvironment analysis through proposed Tumor Interaction Score (TIS), which exhibits strong and significant associations with patient survival. Together, these results establish VISTA-PATH as a foundation model that elevates pathology image segmentation from a static prediction to an interactive and clinically grounded representation for digital pathology. Source code and demo can be found at https://github.com/zhihuanglab/VISTA-PATH.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16451v1</guid></item><item><title>[cs updates on arXiv.org] Cram\'er-Rao Bound Minimization for Flexible Intelligent Metasurface-Enabled ISAC Systems</title><link>https://arxiv.org/abs/2601.16455</link><description>arXiv:2601.16455v1 Announce Type: new 
Abstract: Integrated sensing and communication (ISAC) have been widely recognized as a key enabler for future wireless networks, where the Cram\'er-Rao bound (CRB) plays a central role in quantifying sensing accuracy.In this paper, we present the first study on CRB minimization in flexible intelligent metasurface (FIM)-enabled ISAC systems.Specifically, we first derive an average CRB expression that explicitly depends on FIM surface shape and demonstrate that array reconfigurability can substantially reduce the CRB, thereby significantly enhancing sensing performance.Moreover, to tackle the challenging CRB minimization problem, we adopt average Fisher information maximization as a surrogate objective and use the Gauss-Hermite quadrature method to obtain an explicit approximation of the objective function.The resulting problem is then decoupled into three subproblem, i.e., beamforming optimization and transmit/receive FIM surface shape optimization.For beamforming optimization, we employ the Schur complement and penalty-based semi-definite relaxation (SDR) technique to solve it.Furthermore, we propose a fixed-point equation method and a projected gradient algorithm to optimize the surface shapes of the receive and transmit FIMs, respectively.Simulation results demonstrate that, compared to rigid arrays, surface shaping of both transmit and receive FIMs can significantly reduce the average sensing CRB while maintaining communication quality, and remains effective even in multi-target scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16455v1</guid></item><item><title>[cs updates on arXiv.org] RubberDuckBench: A Benchmark for AI Coding Assistants</title><link>https://arxiv.org/abs/2601.16456</link><description>arXiv:2601.16456v1 Announce Type: new 
Abstract: Programmers are turning to AI coding assistants to answer questions about their code. Benchmarks are needed to soundly evaluate these systems and understand their performance. To enable such a study, we curate a benchmark of real-world contextualized questions derived from Github pull request comments. Out of this work, we present RubberDuckBench: a multilingual benchmark of questions about code, along with detailed rubrics for evaluating answers. We evaluate a diverse set of 20 LLMs (proprietary &amp; open-source) on answering these questions. We find that even state of the art models fail to give consistent, correct responses across the benchmark. Grok 4 (69.29%), Claude Opus 4 (68.5%), and GPT-5 (67.8%) perform best overall, but do not exhibit pairwise significant superiority over the next 9 best performing models. Most models obtain points through partial credit, with the best performing models only answering at most 2 questions completely correctly across all trials. Furthermore, models often hallucinate with lies in 58.3\% of responses on average. Cost analysis reveals no correlation between expense (API pricing or parameter count) and performance. We intend this benchmark to be a target for future research in trustworthy and correct AI coding assistants.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16456v1</guid></item><item><title>[cs updates on arXiv.org] Bridging Expert Reasoning and LLM Detection: A Knowledge-Driven Framework for Malicious Packages</title><link>https://arxiv.org/abs/2601.16458</link><description>arXiv:2601.16458v1 Announce Type: new 
Abstract: Open-source ecosystems such as NPM and PyPI are increasingly targeted by supply chain attacks, yet existing detection methods either depend on fragile handcrafted rules or data-driven features that fail to capture evolving attack semantics. We present IntelGuard, a retrieval-augmented generation (RAG) based framework that integrates expert analytical reasoning into automated malicious package detection. IntelGuard constructs a structured knowledge base from over 8,000 threat intelligence reports, linking malicious code snippets with behavioral descriptions and expert reasoning. When analyzing new packages, it retrieves semantically similar malicious examples and applies LLM-guided reasoning to assess whether code behaviors align with intended functionality. Experiments on 4,027 real-world packages show that IntelGuard achieves 99% accuracy and a 0.50% false positive rate, while maintaining 96.5% accuracy on obfuscated code. Deployed on PyPI.org, it discovered 54 previously unreported malicious packages, demonstrating interpretable and robust detection guided by expert knowledge.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16458v1</guid></item><item><title>[cs updates on arXiv.org] Log-Likelihood Loss for Semantic Compression</title><link>https://arxiv.org/abs/2601.16461</link><description>arXiv:2601.16461v1 Announce Type: new 
Abstract: We study lossy source coding under a distortion measure defined by the negative log-likelihood induced by a prescribed conditional distribution $P_{X|U}$. This \emph{log-likelihood distortion} models compression settings in which the reconstruction is a semantic representation from which the source can be probabilistically generated, rather than a pointwise approximation. We formulate the corresponding rate-distortion problem and characterize fundamental properties of the resulting rate-distortion function, including its connections to lossy compression under log-loss, classical rate-distortion problems with arbitrary distortion measures, and rate-distortion with perfect perception.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16461v1</guid></item><item><title>[cs updates on arXiv.org] Graph-Anchored Knowledge Indexing for Retrieval-Augmented Generation</title><link>https://arxiv.org/abs/2601.16462</link><description>arXiv:2601.16462v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) has emerged as a dominant paradigm for mitigating hallucinations in Large Language Models (LLMs) by incorporating external knowledge. Nevertheless, effectively integrating and interpreting key evidence scattered across noisy documents remains a critical challenge for existing RAG systems. In this paper, we propose GraphAnchor, a novel Graph-Anchored Knowledge Indexing approach that reconceptualizes graph structures from static knowledge representations into active, evolving knowledge indices. GraphAnchor incrementally updates a graph during iterative retrieval to anchor salient entities and relations, yielding a structured index that guides the LLM in evaluating knowledge sufficiency and formulating subsequent subqueries. The final answer is generated by jointly leveraging all retrieved documents and the final evolved graph. Experiments on four multi-hop question answering benchmarks demonstrate the effectiveness of GraphAnchor, and reveal that GraphAnchor modulates the LLM's attention to more effectively associate key information distributed in retrieved documents. All code and data are available at https://github.com/NEUIR/GraphAnchor.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16462v1</guid></item><item><title>[cs updates on arXiv.org] Cutting the Gordian Knot: Detecting Malicious PyPI Packages via a Knowledge-Mining Framework</title><link>https://arxiv.org/abs/2601.16463</link><description>arXiv:2601.16463v1 Announce Type: new 
Abstract: The Python Package Index (PyPI) has become a target for malicious actors, yet existing detection tools generate false positive rates of 15-30%, incorrectly flagging one-third of legitimate packages as malicious. This problem arises because current tools rely on simple syntactic rules rather than semantic understanding, failing to distinguish between identical API calls serving legitimate versus malicious purposes. To address this challenge, we propose PyGuard, a knowledge-driven framework that converts detection failures into useful behavioral knowledge by extracting patterns from existing tools' false positives and negatives. Our method utilizes hierarchical pattern mining to identify behavioral sequences that distinguish malicious from benign code, employs Large Language Models to create semantic abstractions beyond syntactic variations, and combines this knowledge into a detection system that integrates exact pattern matching with contextual reasoning. PyGuard achieves 99.50% accuracy with only 2 false positives versus 1,927-2,117 in existing tools, maintains 98.28% accuracy on obfuscated code, and identified 219 previously unknown malicious packages in real-world deployment. The behavioral patterns show cross-ecosystem applicability with 98.07% accuracy on NPM packages, demonstrating that semantic understanding enables knowledge transfer across programming languages.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16463v1</guid></item><item><title>[cs updates on arXiv.org] Persona Jailbreaking in Large Language Models</title><link>https://arxiv.org/abs/2601.16466</link><description>arXiv:2601.16466v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly deployed in domains such as education, mental health and customer support, where stable and consistent personas are critical for reliability. Yet, existing studies focus on narrative or role-playing tasks and overlook how adversarial conversational history alone can reshape induced personas. Black-box persona manipulation remains unexplored, raising concerns for robustness in realistic interactions. In response, we introduce the task of persona editing, which adversarially steers LLM traits through user-side inputs under a black-box, inference-only setting. To this end, we propose PHISH (Persona Hijacking via Implicit Steering in History), the first framework to expose a new vulnerability in LLM safety that embeds semantically loaded cues into user queries to gradually induce reverse personas. We also define a metric to quantify attack success. Across 3 benchmarks and 8 LLMs, PHISH predictably shifts personas, triggers collateral changes in correlated traits, and exhibits stronger effects in multi-turn settings. In high-risk domains mental health, tutoring, and customer support, PHISH reliably manipulates personas, validated by both human and LLM-as-Judge evaluations. Importantly, PHISH causes only a small reduction in reasoning benchmark performance, leaving overall utility largely intact while still enabling significant persona manipulation. While current guardrails offer partial protection, they remain brittle under sustained attack. Our findings expose new vulnerabilities in personas and highlight the need for context-resilient persona in LLMs. Our codebase and dataset is available at: https://github.com/Jivnesh/PHISH</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16466v1</guid></item><item><title>[cs updates on arXiv.org] A Cautionary Tale of Self-Supervised Learning for Imaging Biomarkers: Alzheimer's Disease Case Study</title><link>https://arxiv.org/abs/2601.16467</link><description>arXiv:2601.16467v1 Announce Type: new 
Abstract: Discovery of sensitive and biologically grounded biomarkers is essential for early detection and monitoring of Alzheimer's disease (AD). Structural MRI is widely available but typically relies on hand-crafted features such as cortical thickness or volume. We ask whether self-supervised learning (SSL) can uncover more powerful biomarkers from the same data. Existing SSL methods underperform FreeSurfer-derived features in disease classification, conversion prediction, and amyloid status prediction. We introduce Residual Noise Contrastive Estimation (R-NCE), a new SSL framework that integrates auxiliary FreeSurfer features while maximizing additional augmentation-invariant information. R-NCE outperforms traditional features and existing SSL methods across multiple benchmarks, including AD conversion prediction. To assess biological relevance, we derive Brain Age Gap (BAG) measures and perform genome-wide association studies. R-NCE-BAG shows high heritability and associations with MAPT and IRAG1, with enrichment in astrocytes and oligodendrocytes, indicating sensitivity to neurodegenerative and cerebrovascular processes.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16467v1</guid></item><item><title>[cs updates on arXiv.org] Cauchy's Surface Area Formula in the Funk Geometry</title><link>https://arxiv.org/abs/2601.16468</link><description>arXiv:2601.16468v1 Announce Type: new 
Abstract: Cauchy's surface area formula expresses the surface area of a convex body as the average area of its orthogonal projections over all directions. While this tool is fundamental in Euclidean geometry, with applications ranging from geometric tomography to approximation theory, extensions to non-Euclidean settings remain less explored. In this paper, we establish an analog of Cauchy's formula for the Funk geometry induced by a convex body $K$ in $\mathbb{R}^d$, under the Holmes-Thompson measure. Our formula is simple and is based on central projections to points on the boundary of $K$. We show that when $K$ is a convex polytope, the formula reduces to a weighted sum involving central projections at the vertices of $K$. Finally, as a consequence of our analysis, we derive a generalization of Crofton's formula for surface areas in the Funk geometry. By viewing Euclidean, Minkowski, Hilbert, and hyperbolic geometries as limiting or special cases of the Funk setting, our results provide a single framework that unifies these classical surface area formulas.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16468v1</guid></item><item><title>[cs updates on arXiv.org] Order from Chaos: Physical World Understanding from Glitchy Gameplay Videos</title><link>https://arxiv.org/abs/2601.16471</link><description>arXiv:2601.16471v1 Announce Type: new 
Abstract: Understanding the physical world, including object dynamics, material properties, and causal interactions, remains a core challenge in artificial intelligence. Although recent multi-modal large language models (MLLMs) have demonstrated impressive general reasoning capabilities, they still fall short of achieving human-level understanding of physical principles. Existing datasets for physical reasoning either rely on real-world videos, which incur high annotation costs, or on synthetic simulations, which suffer from limited realism and diversity. In this paper, we propose a novel paradigm that leverages glitches in gameplay videos, referring to visual anomalies that violate predefined physical laws, as a rich and scalable supervision source for physical world understanding. We introduce PhysGame, an meta information guided instruction-tuning dataset containing 140,057 glitch-centric question-answer pairs across five physical domains and sixteen fine-grained categories. To ensure data accuracy, we design a prompting strategy that utilizes gameplay metadata such as titles and descriptions to guide high-quality QA generation. Complementing PhysGame, we construct GameBench, an expert-annotated benchmark with 880 glitch-identified gameplay videos designed to evaluate physical reasoning capabilities. Extensive experiments show that PhysGame significantly enhances both Game2Real transferability, improving the real world physical reasoning performance of Qwen2.5VL by 2.5% on PhysBench, and Game2General transferability, yielding a 1.9% gain on the MVBench benchmark. Moreover, PhysGame-tuned models achieve a 3.7% absolute improvement on GameBench, demonstrating enhanced robustness in detecting physical implausibilities. These results indicate that learning from gameplay anomalies offers a scalable and effective pathway toward advancing physical world understanding in multimodal intelligence.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16471v1</guid></item><item><title>[cs updates on arXiv.org] Secure Intellicise Wireless Network: Agentic AI for Coverless Semantic Steganography Communication</title><link>https://arxiv.org/abs/2601.16472</link><description>arXiv:2601.16472v1 Announce Type: new 
Abstract: Semantic Communication (SemCom), leveraging its significant advantages in transmission efficiency and reliability, has emerged as a core technology for constructing future intellicise (intelligent and concise) wireless networks. However, intelligent attacks represented by semantic eavesdropping pose severe challenges to the security of SemCom. To address this challenge, Semantic Steganographic Communication (SemSteCom) achieves ``invisible'' encryption by implicitly embedding private semantic information into cover modality carriers. The state-of-the-art study has further introduced generative diffusion models to directly generate stega images without relying on original cover images, effectively enhancing steganographic capacity. Nevertheless, the recovery process of private images is highly dependent on the guidance of private semantic keys, which may be inferred by intelligent eavesdroppers, thereby introducing new security threats. To address this issue, we propose an Agentic AI-driven SemSteCom (AgentSemSteCom) scheme, which includes semantic extraction, digital token controlled reference image generation, coverless steganography, semantic codec, and optional task-oriented enhancement modules. The proposed AgentSemSteCom scheme obviates the need for both cover images and private semantic keys, thereby boosting steganographic capacity while reinforcing transmission security. The simulation results on open-source datasets verify that, AgentSemSteCom achieves better transmission quality and higher security levels than the baseline scheme.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16472v1</guid></item><item><title>[cs updates on arXiv.org] DeMark: A Query-Free Black-Box Attack on Deepfake Watermarking Defenses</title><link>https://arxiv.org/abs/2601.16473</link><description>arXiv:2601.16473v1 Announce Type: new 
Abstract: The rapid proliferation of realistic deepfakes has raised urgent concerns over their misuse, motivating the use of defensive watermarks in synthetic images for reliable detection and provenance tracking. However, this defense paradigm assumes such watermarks are inherently resistant to removal. We challenge this assumption with DeMark, a query-free black-box attack framework that targets defensive image watermarking schemes for deepfakes. DeMark exploits latent-space vulnerabilities in encoder-decoder watermarking models through a compressive sensing based sparsification process, suppressing watermark signals while preserving perceptual and structural realism appropriate for deepfakes. Across eight state-of-the-art watermarking schemes, DeMark reduces watermark detection accuracy from 100% to 32.9% on average while maintaining natural visual quality, outperforming existing attacks. We further evaluate three defense strategies, including image super resolution, sparse watermarking, and adversarial training, and find them largely ineffective. These results demonstrate that current encoder decoder watermarking schemes remain vulnerable to latent-space manipulations, underscoring the need for more robust watermarking methods to safeguard against deepfakes.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16473v1</guid></item><item><title>[cs updates on arXiv.org] DeepEra: A Deep Evidence Reranking Agent for Scientific Retrieval-Augmented Generated Question Answering</title><link>https://arxiv.org/abs/2601.16478</link><description>arXiv:2601.16478v1 Announce Type: new 
Abstract: With the rapid growth of scientific literature, scientific question answering (SciQA) has become increasingly critical for exploring and utilizing scientific knowledge. Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating knowledge from external sources, thereby providing credible evidence for scientific question answering. But existing retrieval and reranking methods remain vulnerable to passages that are semantically similar but logically irrelevant, often reducing factual reliability and amplifying hallucinations.To address this challenge, we propose a Deep Evidence Reranking Agent (DeepEra) that integrates step-by-step reasoning, enabling more precise evaluation of candidate passages beyond surface-level semantics. To support systematic evaluation, we construct SciRAG-SSLI (Scientific RAG - Semantically Similar but Logically Irrelevant), a large-scale dataset comprising about 300K SciQA instances across 10 subjects, constructed from 10M scientific corpus. The dataset combines naturally retrieved contexts with systematically generated distractors to test logical robustness and factual grounding. Comprehensive evaluations confirm that our approach achieves superior retrieval performance compared to leading rerankers. To our knowledge, this work is the first to comprehensively study and empirically validate innegligible SSLI issues in two-stage RAG frameworks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16478v1</guid></item><item><title>[cs updates on arXiv.org] Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs</title><link>https://arxiv.org/abs/2601.16479</link><description>arXiv:2601.16479v1 Announce Type: new 
Abstract: While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hierarchy Process (AHP), offer systematic rational frameworks, their construction relies heavily on labor-intensive domain expertise, creating an "expert bottleneck" that hinders scalability in general scenarios. To bridge the gap between the generalization capabilities of LLMs and the rigor of decision theory, we propose Doc2AHP, a novel structured inference framework guided by AHP principles. Eliminating the need for extensive annotated data or manual intervention, our approach leverages the structural principles of AHP as constraints to direct the LLM in a constrained search within the unstructured document space, thereby enforcing the logical entailment between parent and child nodes. Furthermore, we introduce a multi-agent weighting mechanism coupled with an adaptive consistency optimization strategy to ensure the numerical consistency of weight allocation. Empirical results demonstrate that Doc2AHP not only empowers non-expert users to construct high-quality decision models from scratch but also significantly outperforms direct generative baselines in both logical completeness and downstream task accuracy.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16479v1</guid></item><item><title>[cs updates on arXiv.org] TL-GRPO: Turn-Level RL for Reasoning-Guided Iterative Optimization</title><link>https://arxiv.org/abs/2601.16480</link><description>arXiv:2601.16480v1 Announce Type: new 
Abstract: Large language models have demonstrated strong reasoning capabilities in complex tasks through tool integration, which is typically framed as a Markov Decision Process and optimized with trajectory-level RL algorithms such as GRPO. However, a common class of reasoning tasks, iterative optimization, presents distinct challenges: the agent interacts with the same underlying environment state across turns, and the value of a trajectory is determined by the best turn-level reward rather than cumulative returns. Existing GRPO-based methods cannot perform fine-grained, turn-level optimization in such settings, while black-box optimization methods discard prior knowledge and reasoning capabilities. To address this gap, we propose Turn-Level GRPO (TL-GRPO), a lightweight RL algorithm that performs turn-level group sampling for fine-grained optimization. We evaluate TL-GRPO on analog circuit sizing (ACS), a challenging scientific optimization task requiring multiple simulations and domain expertise. Results show that TL-GRPO outperforms standard GRPO and Bayesian optimization methods across various specifications. Furthermore, our 30B model trained with TL-GRPO achieves state-of-the-art performance on ACS tasks under same simulation budget, demonstrating both strong generalization and practical utility.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16480v1</guid></item><item><title>[cs updates on arXiv.org] Online Computation of Palindromes and Suffix Trees on Tries</title><link>https://arxiv.org/abs/2601.16485</link><description>arXiv:2601.16485v1 Announce Type: new 
Abstract: We consider the problems of computing maximal palindromes and distinct palindromes in a trie. A trie is a natural generalization of a string, which can be seen as a single-path tree. There is a linear-time offline algorithm to compute maximal palindromes and distinct palindromes in a given (static) trie whose edge-labels are drawn from a linearly-sortable alphabet [Mieno et al., ISAAC 2022]. In this paper, we tackle problems of palindrome enumeration on dynamic tries which support leaf additions and leaf deletions. We propose the first sub-quadratic algorithms to enumerate palindromes in a dynamic trie. For maximal palindromes, we propose an algorithm that runs in $O(N \min(\log h, \sigma))$ time and uses $O(N)$ space, where $N$ is the maximum number of edges in the trie, $\sigma$ is the size of the alphabet, and $h$ is the height of the trie. For distinct palindromes, we develop several online algorithms based on different algorithmic frameworks, including approaches using the EERTREE (a.k.a. palindromic tree) and the suffix tree of a trie. These algorithms support leaf insertions and deletions in the trie and achieve different time and space trade-offs. Furthermore, as a by-product, we present online algorithms to construct the suffix tree and the EERTREE of the input trie, which is of independent interest.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16485v1</guid></item><item><title>[cs updates on arXiv.org] Timely Machine: Awareness of Time Makes Test-Time Scaling Agentic</title><link>https://arxiv.org/abs/2601.16486</link><description>arXiv:2601.16486v1 Announce Type: new 
Abstract: As large language models (LLMs) increasingly tackle complex reasoning tasks, test-time scaling has become critical for enhancing capabilities. However, in agentic scenarios with frequent tool calls, the traditional generation-length-based definition breaks down: tool latency decouples inference time from generation length. We propose Timely Machine, redefining test-time as wall-clock time, where models dynamically adjust strategies based on time budgets. We introduce Timely-Eval, a benchmark spanning high-frequency tool calls, low-frequency tool calls, and time-constrained reasoning. By varying tool latency, we find smaller models excel with fast feedback through more interactions, while larger models dominate high-latency settings via superior interaction quality. Moreover, existing models fail to adapt reasoning to time budgets. We propose Timely-RL to address this gap. After cold-start supervised fine-tuning, we use reinforcement learning to enhance temporal planning. Timely-RL improves time budget awareness and consistently boosts performance across Timely-Eval. We hope our work offers a new perspective on test-time scaling for the agentic era.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16486v1</guid></item><item><title>[cs updates on arXiv.org] Multi-View Consistent Wound Segmentation With Neural Fields</title><link>https://arxiv.org/abs/2601.16487</link><description>arXiv:2601.16487v1 Announce Type: new 
Abstract: Wound care is often challenged by the economic and logistical burdens that consistently afflict patients and hospitals worldwide. In recent decades, healthcare professionals have sought support from computer vision and machine learning algorithms. In particular, wound segmentation has gained interest due to its ability to provide professionals with fast, automatic tissue assessment from standard RGB images. Some approaches have extended segmentation to 3D, enabling more complete and precise healing progress tracking. However, inferring multi-view consistent 3D structures from 2D images remains a challenge. In this paper, we evaluate WoundNeRF, a NeRF SDF-based method for estimating robust wound segmentations from automatically generated annotations. We demonstrate the potential of this paradigm in recovering accurate segmentations by comparing it against state-of-the-art Vision Transformer networks and conventional rasterisation-based algorithms. The code will be released to facilitate further development in this promising paradigm.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16487v1</guid></item><item><title>[cs updates on arXiv.org] Anonymous Pricing in Large Markets</title><link>https://arxiv.org/abs/2601.16488</link><description>arXiv:2601.16488v1 Announce Type: new 
Abstract: We study revenue maximization when a seller offers $k$ identical units to ex ante heterogeneous, unit-demand buyers. While anonymous pricing can be $\Theta(\log k)$ worse than optimal in general multi-unit environments, we show that this pessimism disappears in large markets, where no single buyer accounts for a non-negligible share of optimal revenue. Under (quasi-)regularity, anonymous pricing achieves a $2+O(1/\sqrt{k})$ approximation to the optimal mechanism; the worst-case ratio is maximized at about $2.47$ when $k=1$ and converges to $2$ as $k$ grows. This indicates that the gains from third-degree price discrimination are mild in large markets.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16488v1</guid></item><item><title>[cs updates on arXiv.org] EvoConfig: Self-Evolving Multi-Agent Systems for Efficient Autonomous Environment Configuration</title><link>https://arxiv.org/abs/2601.16489</link><description>arXiv:2601.16489v1 Announce Type: new 
Abstract: A reliable executable environment is the foundation for ensuring that large language models solve software engineering tasks. Due to the complex and tedious construction process, large-scale configuration is relatively inefficient. However, most methods always overlook fine-grained analysis of the actions performed by the agent, making it difficult to handle complex errors and resulting in configuration failures. To address this bottleneck, we propose EvoConfig, an efficient environment configuration framework that optimizes multi-agent collaboration to build correct runtime environments. EvoConfig features an expert diagnosis module for fine-grained post-execution analysis, and a self-evolving mechanism that lets expert agents self-feedback and dynamically adjust error-fixing priorities in real time. Empirically, EvoConfig matches the previous state-of-the-art Repo2Run on Repo2Run's 420 repositories, while delivering clear gains on harder cases: on the more challenging Envbench, EvoConfig achieves a 78.1% success rate, outperforming Repo2Run by 7.1%. Beyond end-to-end success, EvoConfig also demonstrates stronger debugging competence, achieving higher accuracy in error identification and producing more effective repair recommendations than existing methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16489v1</guid></item><item><title>[cs updates on arXiv.org] A Scalable Transaction Management Framework for Consistent Document-Oriented NoSQL Databases</title><link>https://arxiv.org/abs/2601.16490</link><description>arXiv:2601.16490v1 Announce Type: new 
Abstract: NoSQL databases are widely used in modern applications due to their scalability and schema flexibility, yet they often rely on eventual consistency models that limit reliable transaction processing. This study proposes a four-stage transaction management framework for document-oriented NoSQL databases, with MongoDB as the reference platform. The framework combines transaction lifecycle management, operation classification, pre-execution conflict detection, and an adaptive locking strategy with timeout-based deadlock prevention. Formal correctness analysis shows that the proposed approach guarantees conflict serializability under defined conditions. An experimental evaluation using the Yahoo Cloud Serving Benchmark (YCSB) workloads A, B, and F, with concurrency levels ranging from 1 to 100 clients, demonstrates a reduction in transaction abort rates from 8.3% to 4.7%, the elimination of observed deadlocks, and a 34.2% decrease in latency variance. Throughput improvements ranging from 6.3% to 18.4% are observed under high concurrency, particularly for read-modify-write workloads. Distributed experiments on clusters of up to 9 nodes confirm scalability, achieving 15.2% higher throughput and 53% lower abort rates than baseline systems. Comparisons with MongoDB's native transactions, CockroachDB, and TiDB indicate that the proposed framework strikes a good balance between consistency guarantees and performance overhead. Sensitivity analysis identifies optimal parameter settings, including a lock timeout of 100 ms, an initial backoff of 10 ms, and a maximum backoff of 500 ms. These results show that carefully designed consistency mechanisms can significantly improve data integrity in NoSQL systems without undermining scalability.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16490v1</guid></item><item><title>[cs updates on arXiv.org] Robust Categorical Data Clustering Guided by Multi-Granular Competitive Learning</title><link>https://arxiv.org/abs/2601.16491</link><description>arXiv:2601.16491v1 Announce Type: new 
Abstract: Data set composed of categorical features is very common in big data analysis tasks. Since categorical features are usually with a limited number of qualitative possible values, the nested granular cluster effect is prevalent in the implicit discrete distance space of categorical data. That is, data objects frequently overlap in space or subspace to form small compact clusters, and similar small clusters often form larger clusters. However, the distance space cannot be well-defined like the Euclidean distance due to the qualitative categorical data values, which brings great challenges to the cluster analysis of categorical data. In view of this, we design a Multi-Granular Competitive Penalization Learning (MGCPL) algorithm to allow potential clusters to interactively tune themselves and converge in stages with different numbers of naturally compact clusters. To leverage MGCPL, we also propose a Cluster Aggregation strategy based on MGCPL Encoding (CAME) to first encode the data objects according to the learned multi-granular distributions, and then perform final clustering on the embeddings. It turns out that the proposed MGCPL-guided Categorical Data Clustering (MCDC) approach is competent in automatically exploring the nested distribution of multi-granular clusters and highly robust to categorical data sets from various domains. Benefiting from its linear time complexity, MCDC is scalable to large-scale data sets and promising in pre-partitioning data sets or compute nodes for boosting distributed computing. Extensive experiments with statistical evidence demonstrate its superiority compared to state-of-the-art counterparts on various real public data sets.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16491v1</guid></item><item><title>[cs updates on arXiv.org] LLM-based Semantic Search for Conversational Queries in E-commerce</title><link>https://arxiv.org/abs/2601.16492</link><description>arXiv:2601.16492v1 Announce Type: new 
Abstract: Conversational user queries are increasingly challenging traditional e-commerce platforms, whose search systems are typically optimized for keyword-based queries. We present an LLM-based semantic search framework that effectively captures user intent from conversational queries by combining domain-specific embeddings with structured filters. To address the challenge of limited labeled data, we generate synthetic data using LLMs to guide the fine-tuning of two models: an embedding model that positions semantically similar products close together in the representation space, and a generative model for converting natural language queries into structured constraints. By combining similarity-based retrieval with constraint-based filtering, our framework achieves strong precision and recall across various settings compared to baseline approaches on a real-world dataset.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16492v1</guid></item><item><title>[cs updates on arXiv.org] Load Balanced ISAC Systems for URLLC Users</title><link>https://arxiv.org/abs/2601.16495</link><description>arXiv:2601.16495v1 Announce Type: new 
Abstract: This paper presents an energy-efficient downlink cell-free massive multiple-input multiple-output (CF-mMIMO) integrated sensing and communication (ISAC) network that serves ultra-reliable low-latency communication (URLLC) users while simultaneously detecting a target. We propose a load-balancing algorithm that minimizes the total network power consumption; including transmit power, fixed static power, and traffic-dependent fronthaul power at the access points (APs) without degrading system performance. To this end, we formulate a mixed-integer non-convex optimization problem and introduce an iterative joint power allocation and AP load balancing (JPALB) algorithm. The algorithm aims to reduce total power usage while meeting both the communication quality-of-service (QoS) requirements of URLLC users and the sensing QoS needed for target detection. Proposed JPALB algorithm for ISAC systems was simulated with maximum-ratio transmission (MRT) and regularized zero-forcing (RZF) precoders. Simulation results show approximately 33% reduction in power consumption, using JPALB algorithm compared to a baseline with no load balancing, without compromising communication and sensing QoS requirements.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16495v1</guid></item><item><title>[cs updates on arXiv.org] BoostFGL: Boosting Fairness in Federated Graph Learning</title><link>https://arxiv.org/abs/2601.16496</link><description>arXiv:2601.16496v1 Announce Type: new 
Abstract: Federated graph learning (FGL) enables collaborative training of graph neural networks (GNNs) across decentralized subgraphs without exposing raw data. While existing FGL methods often achieve high overall accuracy, we show that this average performance can conceal severe degradation on disadvantaged node groups. From a fairness perspective, these disparities arise systematically from three coupled sources: label skew toward majority patterns, topology confounding in message propagation, and aggregation dilution of updates from hard clients. To address this, we propose \textbf{BoostFGL}, a boosting-style framework for fairness-aware FGL. BoostFGL introduces three coordinated mechanisms: \ding{182} \emph{Client-side node boosting}, which reshapes local training signals to emphasize systematically under-served nodes; \ding{183} \emph{Client-side topology boosting}, which reallocates propagation emphasis toward reliable yet underused structures and attenuates misleading neighborhoods; and \ding{184} \emph{Server-side model boosting}, which performs difficulty- and reliability-aware aggregation to preserve informative updates from hard clients while stabilizing the global model. Extensive experiments on 9 datasets show that BoostFGL delivers substantial fairness gains, improving Overall-F1 by 8.43\%, while preserving competitive overall performance against strong FGL baselines.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16496v1</guid></item><item><title>[cs updates on arXiv.org] Expert Knowledge-Guided Decision Calibration for Accurate Fine-Grained Tree Species Classification</title><link>https://arxiv.org/abs/2601.16498</link><description>arXiv:2601.16498v1 Announce Type: new 
Abstract: Accurate fine-grained tree species classification is critical for forest inventory and biodiversity monitoring. Existing methods predominantly focus on designing complex architectures to fit local data distributions. However, they often overlook the long-tailed distributions and high inter-class similarity inherent in limited data, thereby struggling to distinguish between few-shot or confusing categories. In the process of knowledge dissemination in the human world, individuals will actively seek expert assistance to transcend the limitations of local thinking. Inspired by this, we introduce an external "Domain Expert" and propose an Expert Knowledge-Guided Classification Decision Calibration Network (EKDC-Net) to overcome these challenges. Our framework addresses two core issues: expert knowledge extraction and utilization. Specifically, we first develop a Local Prior Guided Knowledge Extraction Module (LPKEM). By leveraging Class Activation Map (CAM) analysis, LPKEM guides the domain expert to focus exclusively on discriminative features essential for classification. Subsequently, to effectively integrate this knowledge, we design an Uncertainty-Guided Decision Calibration Module (UDCM). This module dynamically corrects the local model's decisions by considering both overall category uncertainty and instance-level prediction uncertainty. Furthermore, we present a large-scale classification dataset covering 102 tree species, named CU-Tree102 to address the issue of scarce diversity in current benchmarks. Experiments on three benchmark datasets demonstrate that our approach achieves state-of-the-art performance. Crucially, as a lightweight plug-and-play module, EKDC-Net improves backbone accuracy by 6.42% and precision by 11.46% using only 0.08M additional learnable parameters. The dataset, code, and pre-trained models are available at https://github.com/WHU-USI3DV/TreeCLS.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16498v1</guid></item><item><title>[cs updates on arXiv.org] A High Performance and Efficient Post-Quantum Crypto-Processor for FrodoKEM</title><link>https://arxiv.org/abs/2601.16500</link><description>arXiv:2601.16500v1 Announce Type: new 
Abstract: FrodoKEM is a lattice-based post-quantum key encapsulation mechanism (KEM). It has been considered for standardization by the International Organization for Standardization (ISO) due to its robust security profile. However, its hardware implementation exhibits a weakness of high latency and heavy resource burden, hindering its practical application. Moreover, diverse usage scenarios call for comprehensive functionality. To address these challenges, this paper presents a high-performance and efficient crypto-processor for FrodoKEM. A multiple-instruction overlapped execution scheme is introduced to enable efficient multi-module scheduling and minimize operational latency. Furthermore, a high-speed, reconfigurable parallel multiplier array is integrated to handle intensive matrix computations under diverse computation patterns, significantly enhancing hardware efficiency. In addition, a compact memory scheduling strategy shortens the lifespan of intermediate matrices, thereby reducing overall storage requirements. The proposed design provides full support for all FrodoKEM security levels and protocol phases. It consumes 13467 LUTs, 6042 FFs, and 14 BRAMs on an Artix-7 FPGA and achieves the fastest reported execution time. Compared with state-of-the-art hardware implementations, our design improves the area-time product (ATP) by 1.75-2.00 times.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16500v1</guid></item><item><title>[cs updates on arXiv.org] Sequential Operating Simulation of Solid State Transformer-Driven Next-Generation 800 VDC Data Center</title><link>https://arxiv.org/abs/2601.16502</link><description>arXiv:2601.16502v1 Announce Type: new 
Abstract: Artificial-intelligence (AI) workloads are driving rapid growth in data-center electricity use and rack power density, increasing demand for power-delivery systems that are efficient and robust to fast load transients. Conventional uninterruptible power supply (UPS) based AC distribution chains involve multiple conversion stages and line-frequency transformers, which compound losses and are less compatible with dynamic AI power profiles. Although solid-state transformers (SSTs) and 800 VDC distribution architecture are widely discussed, implementable topology/control details, and long-horizon validation with realistic operating profiles remain limited. This paper develops an SST-driven 800 VDC architecture that converts 10 kV MVAC to an 800V LVDC bus using a three-phase H-bridge AC/DC stage cascaded with a dual-active-bridge (DAB) DC/DC stage. A coordinated closed-loop control scheme, combining rectifier voltage/current regulation and DAB phase-shift control, is designed to maintain DC-bus voltage stability. The proposed system is implemented on the real-time digital simulation (RTDS) platform and evaluated via sequential simulations using real-world day- and month-scale operating profiles of data centers, benchmarked against a UPS supply chain. Numerical studies demonstrate tight 800 VDC regulation, reduced input-side energy consumption compared with the UPS baseline, and satisfactory power-quality performance. A capacitance sensitivity test quantifies tradeoffs between DC-bus ripple and low-frequency input-power oscillations, yielding a practical capacitance range for design. Overall, the work provides a reproducible evaluation workflow and actionable guidance for next-generation AI data centers.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16502v1</guid></item><item><title>[cs updates on arXiv.org] MRAG: Benchmarking Retrieval-Augmented Generation for Bio-medicine</title><link>https://arxiv.org/abs/2601.16503</link><description>arXiv:2601.16503v1 Announce Type: new 
Abstract: While Retrieval-Augmented Generation (RAG) has been swiftly adopted in scientific and clinical QA systems, a comprehensive evaluation benchmark in the medical domain is lacking. To address this gap, we introduce the Medical Retrieval-Augmented Generation (MRAG) benchmark, covering various tasks in English and Chinese languages, and building a corpus with Wikipedia and Pubmed. Additionally, we develop the MRAG-Toolkit, facilitating systematic exploration of different RAG components. Our experiments reveal that: (a) RAG enhances LLM reliability across MRAG tasks. (b) the performance of RAG systems is influenced by retrieval approaches, model sizes, and prompting strategies. (c) While RAG improves usefulness and reasoning quality, LLM responses may become slightly less readable for long-form questions. We will release the MRAG-Bench's dataset and toolkit with CCBY-4.0 license upon acceptance, to facilitate applications from both academia and industry.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16503v1</guid></item><item><title>[cs updates on arXiv.org] LOGICAL-COMMONSENSEQA: A Benchmark for Logical Commonsense Reasoning</title><link>https://arxiv.org/abs/2601.16504</link><description>arXiv:2601.16504v1 Announce Type: new 
Abstract: Commonsense reasoning often involves evaluating multiple plausible interpretations rather than selecting a single atomic answer, yet most benchmarks rely on single-label evaluation, obscuring whether statements are jointly plausible, mutually exclusive, or jointly implausible. We introduce LOGICAL-COMMONSENSEQA, a benchmark that re-frames commonsense reasoning as logical composition over pairs of atomic statements using plausibility-level operators (AND, OR, NEITHER/NOR). Evaluating instruction-tuned, reasoning-specialized, and fine-tuned models under zero-shot, few-shot, and chain-of-thought prompting, we find that while models perform reasonably on conjunctive and moderately on disjunctive reasoning, performance degrades sharply on negation-based questions. LOGICAL-COMMONSENSEQA exposes fundamental reasoning limitations and provides a controlled framework for advancing compositional commonsense reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16504v1</guid></item><item><title>[cs updates on arXiv.org] SafeThinker: Reasoning about Risk to Deepen Safety Beyond Shallow Alignment</title><link>https://arxiv.org/abs/2601.16506</link><description>arXiv:2601.16506v1 Announce Type: new 
Abstract: Despite the intrinsic risk-awareness of Large Language Models (LLMs), current defenses often result in shallow safety alignment, rendering models vulnerable to disguised attacks (e.g., prefilling) while degrading utility. To bridge this gap, we propose SafeThinker, an adaptive framework that dynamically allocates defensive resources via a lightweight gateway classifier. Based on the gateway's risk assessment, inputs are routed through three distinct mechanisms: (i) a Standardized Refusal Mechanism for explicit threats to maximize efficiency; (ii) a Safety-Aware Twin Expert (SATE) module to intercept deceptive attacks masquerading as benign queries; and (iii) a Distribution-Guided Think (DDGT) component that adaptively intervenes during uncertain generation. Experiments show that SafeThinker significantly lowers attack success rates across diverse jailbreak strategies without compromising utility, demonstrating that coordinating intrinsic judgment throughout the generation process effectively balances robustness and practicality.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16506v1</guid></item><item><title>[cs updates on arXiv.org] REprompt: Prompt Generation for Intelligent Software Development Guided by Requirements Engineering</title><link>https://arxiv.org/abs/2601.16507</link><description>arXiv:2601.16507v1 Announce Type: new 
Abstract: The rapid development of large language models is transforming software development. Beyond serving as code auto-completion tools in integrated development environments, large language models increasingly function as foundation models within coding agents in vibe-coding scenarios. In such settings, prompts play a central role in agent-based intelligent software development, as they not only guide the behavior of large language models but also serve as carriers of user requirements. Under the dominant conversational paradigm, prompts are typically divided into system prompts and user prompts. System prompts provide high-level instructions to steer model behavior and establish conversational context, while user prompts represent inputs and requirements provided by human users. Despite their importance, designing effective prompts remains challenging, as it requires expertise in both prompt engineering and software engineering, particularly requirements engineering. To reduce the burden of manual prompt construction, numerous automated prompt engineering methods have been proposed. However, most existing approaches neglect the methodological principles of requirements engineering, limiting their ability to generate artifacts that conform to formal requirement specifications in realistic software development scenarios. To address this gap, we propose REprompt, a multi-agent prompt optimization framework guided by requirements engineering. Experiment results demonstrate that REprompt effectively optimizes both system and user prompts by grounding prompt generation in requirements engineering principles.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16507v1</guid></item><item><title>[cs updates on arXiv.org] Is Length Really A Liability? An Evaluation of Multi-turn LLM Conversations using BoolQ</title><link>https://arxiv.org/abs/2601.16508</link><description>arXiv:2601.16508v1 Announce Type: new 
Abstract: Single-prompt evaluations dominate current LLM benchmarking, yet they fail to capture the conversational dynamics where real-world harm occurs. In this study, we examined whether conversation length affects response veracity by evaluating LLM performance on the BoolQ dataset under varying length and scaffolding conditions. Our results across three distinct LLMs revealed model-specific vulnerabilities that are invisible under single-turn testing. The length-dependent and scaffold-specific effects we observed demonstrate a fundamental limitation of static evaluations, as deployment-relevant vulnerabilities could only be spotted in a multi-turn conversational setting.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16508v1</guid></item><item><title>[cs updates on arXiv.org] kNN-Graph: An adaptive graph model for $k$-nearest neighbors</title><link>https://arxiv.org/abs/2601.16509</link><description>arXiv:2601.16509v1 Announce Type: new 
Abstract: The k-nearest neighbors (kNN) algorithm is a cornerstone of non-parametric classification in artificial intelligence, yet its deployment in large-scale applications is persistently constrained by the computational trade-off between inference speed and accuracy. Existing approximate nearest neighbor solutions accelerate retrieval but often degrade classification precision and lack adaptability in selecting the optimal neighborhood size (k). Here, we present an adaptive graph model that decouples inference latency from computational complexity. By integrating a Hierarchical Navigable Small World (HNSW) graph with a pre-computed voting mechanism, our framework completely transfers the computational burden of neighbor selection and weighting to the training phase. Within this topological structure, higher graph layers enable rapid navigation, while lower layers encode precise, node-specific decision boundaries with adaptive neighbor counts. Benchmarking against eight state-of-the-art baselines across six diverse datasets, we demonstrate that this architecture significantly accelerates inference speeds, achieving real-time performance, without compromising classification accuracy. These findings offer a scalable, robust solution to the long-standing inference bottleneck of kNN, establishing a new structural paradigm for graph-based nonparametric learning.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16509v1</guid></item><item><title>[cs updates on arXiv.org] Learning to Optimize by Differentiable Programming</title><link>https://arxiv.org/abs/2601.16510</link><description>arXiv:2601.16510v1 Announce Type: new 
Abstract: Solving massive-scale optimization problems requires scalable first-order methods with low per-iteration cost. This tutorial highlights a shift in optimization: using differentiable programming not only to execute algorithms but to learn how to design them. Modern frameworks such as PyTorch, TensorFlow, and JAX enable this paradigm through efficient automatic differentiation. Embedding first-order methods within these systems allows end-to-end training that improves convergence and solution quality. Guided by Fenchel-Rockafellar duality, the tutorial demonstrates how duality-informed iterative schemes such as ADMM and PDHG can be learned and adapted. Case studies across LP, OPF, Laplacian regularization, and neural network verification illustrate these gains.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16510v1</guid></item><item><title>[cs updates on arXiv.org] Participatory Budgeting Project Strength via Candidate Control</title><link>https://arxiv.org/abs/2601.16511</link><description>arXiv:2601.16511v1 Announce Type: new 
Abstract: We study the complexity of candidate control in participatory budgeting elections. The goal of constructive candidate control is to ensure that a given candidate wins by either adding or deleting candidates from the election (in the destructive setting, the goal is to prevent a given candidate from winning). We show that such control problems are NP-hard to solve for many participatory budgeting voting rules, including Phragm\'en and Method of Equal Shares, but there are natural cases with polynomial-time algorithms (e.g., for the GreedyAV rule and projects with costs encoded in unary). We also argue that control by deleting candidates is a useful tool for assessing the performance (or, strength) of initially losing projects, and we support this view with experiments.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16511v1</guid></item><item><title>[cs updates on arXiv.org] SearchLLM: Detecting LLM Paraphrased Text by Measuring the Similarity with Regeneration of the Candidate Source via Search Engine</title><link>https://arxiv.org/abs/2601.16512</link><description>arXiv:2601.16512v1 Announce Type: new 
Abstract: With the advent of large language models (LLMs), it has become common practice for users to draft text and utilize LLMs to enhance its quality through paraphrasing. However, this process can sometimes result in the loss or distortion of the original intended meaning. Due to the human-like quality of LLM-generated text, traditional detection methods often fail, particularly when text is paraphrased to closely mimic original content. In response to these challenges, we propose a novel approach named SearchLLM, designed to identify LLM-paraphrased text by leveraging search engine capabilities to locate potential original text sources. By analyzing similarities between the input and regenerated versions of candidate sources, SearchLLM effectively distinguishes LLM-paraphrased content. SearchLLM is designed as a proxy layer, allowing seamless integration with existing detectors to enhance their performance. Experimental results across various LLMs demonstrate that SearchLLM consistently enhances the accuracy of recent detectors in detecting LLM-paraphrased text that closely mimics original content. Furthermore, SearchLLM also helps the detectors prevent paraphrasing attacks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16512v1</guid></item><item><title>[cs updates on arXiv.org] Competing Visions of Ethical AI: A Case Study of OpenAI</title><link>https://arxiv.org/abs/2601.16513</link><description>arXiv:2601.16513v1 Announce Type: new 
Abstract: Introduction. AI Ethics is framed distinctly across actors and stakeholder groups. We report results from a case study of OpenAI analysing ethical AI discourse. Method. Research addressed: How has OpenAI's public discourse leveraged 'ethics', 'safety', 'alignment' and adjacent related concepts over time, and what does discourse signal about framing in practice? A structured corpus, differentiating between communication for a general audience and communication with an academic audience, was assembled from public documentation. Analysis. Qualitative content analysis of ethical themes combined inductively derived and deductively applied codes. Quantitative analysis leveraged computational content analysis methods via NLP to model topics and quantify changes in rhetoric over time. Visualizations report aggregate results. For reproducible results, we have released our code at https://github.com/famous-blue-raincoat/AI_Ethics_Discourse. Results. Results indicate that safety and risk discourse dominate OpenAI's public communication and documentation, without applying academic and advocacy ethics frameworks or vocabularies. Conclusions. Implications for governance are presented, along with discussion of ethics-washing practices in industry.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16513v1</guid></item><item><title>[cs updates on arXiv.org] Finite-Time Analysis of Gradient Descent for Shallow Transformers</title><link>https://arxiv.org/abs/2601.16514</link><description>arXiv:2601.16514v1 Announce Type: new 
Abstract: Understanding why Transformers perform so well remains challenging due to their non-convex optimization landscape. In this work, we analyze a shallow Transformer with $m$ independent heads trained by projected gradient descent in the kernel regime. Our analysis reveals two main findings: (i) the width required for nonasymptotic guarantees scales only logarithmically with the sample size $n$, and (ii) the optimization error is independent of the sequence length $T$. This contrasts sharply with recurrent architectures, where the optimization error can grow exponentially with $T$. The trade-off is memory: to keep the full context, the Transformer's memory requirement grows with the sequence length. We validate our theoretical results numerically in a teacher-student setting and confirm the predicted scaling laws for Transformers.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16514v1</guid></item><item><title>[cs updates on arXiv.org] SALAD: Achieve High-Sparsity Attention via Efficient Linear Attention Tuning for Video Diffusion Transformer</title><link>https://arxiv.org/abs/2601.16515</link><description>arXiv:2601.16515v1 Announce Type: new 
Abstract: Diffusion Transformers have recently demonstrated remarkable performance in video generation. However, the long input sequences result in high computational latency due to the quadratic complexity of full attention. Various sparse attention mechanisms have been proposed. Training-free sparse attention is constrained by limited sparsity and thus offers modest acceleration, whereas training-based methods can reach much higher sparsity but demand substantial data and computation for training. In this work, we propose SALAD, introducing a lightweight linear attention branch in parallel with the sparse attention. By incorporating an input-dependent gating mechanism to finely balance the two branches, our method attains 90% sparsity and 1.72x inference speedup, while maintaining generation quality comparable to the full attention baseline. Moreover, our finetuning process is highly efficient, requiring only 2,000 video samples and 1,600 training steps with a batch size of 8.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16515v1</guid></item><item><title>[cs updates on arXiv.org] Rethinking Large Language Models For Irregular Time Series Classification In Critical Care</title><link>https://arxiv.org/abs/2601.16516</link><description>arXiv:2601.16516v1 Announce Type: new 
Abstract: Time series data from the Intensive Care Unit (ICU) provides critical information for patient monitoring. While recent advancements in applying Large Language Models (LLMs) to time series modeling (TSM) have shown great promise, their effectiveness on the irregular ICU data, characterized by particularly high rates of missing values, remains largely unexplored. This work investigates two key components underlying the success of LLMs for TSM: the time series encoder and the multimodal alignment strategy. To this end, we establish a systematic testbed to evaluate their impact across various state-of-the-art LLM-based methods on benchmark ICU datasets against strong supervised and self-supervised baselines. Results reveal that the encoder design is more critical than the alignment strategy. Encoders that explicitly model irregularity achieve substantial performance gains, yielding an average AUPRC increase of $12.8\%$ over the vanilla Transformer. While less impactful, the alignment strategy is also noteworthy, with the best-performing semantically rich, fusion-based strategy achieving a modest $2.9\%$ improvement over cross-attention. However, LLM-based methods require at least 10$\times$ longer training than the best-performing irregular supervised models, while delivering only comparable performance. They also underperform in data-scarce few-shot learning settings. These findings highlight both the promise and current limitations of LLMs for irregular ICU time series. The code is available at https://github.com/mHealthUnimelb/LLMTS.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16516v1</guid></item><item><title>[cs updates on arXiv.org] Noise-immune and AI-enhanced DNA storage via adaptive partition mapping of digital data</title><link>https://arxiv.org/abs/2601.16518</link><description>arXiv:2601.16518v1 Announce Type: new 
Abstract: Encoding digital information into DNA sequences offers an attractive potential solution for storing rapidly growing data under the information age and the rise of artificial intelligence. However, practical implementations of DNA storage are constrained by errors introduced during synthesis, preservation, and sequencing processes, and traditional error-correcting codes remain vulnerable to noise levels that exceed predefined thresholds. Here, we developed a Partitioning-mapping with Jump-rotating (PJ) encoding scheme, which exhibits exceptional noise resilience. PJ removes cross-strand information dependencies so that strand loss manifests as localized gaps rather than catastrophic file failure. It prioritizes file decodability under arbitrary noise conditions and leverages AI-based inference to enable controllable recovery of digital information. For the intra-strand encoding, we develop a jump-rotating strategy that relaxes sequence constraints relative to conventional rotating codes and provides tunable information density via an adjustable jump length. Based on this encoding architecture, the original file information can always be decoded and recovered under any strand loss ratio, with fidelity degrading smoothly as damage increases. We demonstrate that original files can be effectively recovered even with 10% strand loss, and machine learning datasets stored under these conditions retain their classification performance. Experiments further confirmed that PJ successfully decodes image files after extreme environmental disturbance using accelerated aging and high-intensity X-ray irradiation. By eliminating reliance on prior error probabilities, PJ establishes a general framework for robust, archival DNA storage capable of withstanding the rigorous conditions of real-world preservation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16518v1</guid></item><item><title>[cs updates on arXiv.org] DANCE: Dynamic, Available, Neighbor-gated Condensation for Federated Text-Attributed Graphs</title><link>https://arxiv.org/abs/2601.16519</link><description>arXiv:2601.16519v1 Announce Type: new 
Abstract: Federated graph learning (FGL) enables collaborative training on graph data across multiple clients. With the rise of large language models (LLMs), textual attributes in FGL graphs are gaining attention. Text-attributed graph federated learning (TAG-FGL) improves FGL by explicitly leveraging LLMs to process and integrate these textual features. However, current TAG-FGL methods face three main challenges: \textbf{(1) Overhead.} LLMs for processing long texts incur high token and computation costs. To make TAG-FGL practical, we introduce graph condensation (GC) to reduce computation load, but this choice also brings new issues. \textbf{(2) Suboptimal.} To reduce LLM overhead, we introduce GC into TAG-FGL by compressing multi-hop texts/neighborhoods into a condensed core with fixed LLM surrogates. However, this one-shot condensation is often not client-adaptive, leading to suboptimal performance. \textbf{(3) Interpretability.} LLM-based condensation further introduces a black-box bottleneck: summaries lack faithful attribution and clear grounding to specific source spans, making local inspection and auditing difficult. To address the above issues, we propose \textbf{DANCE}, a new TAG-FGL paradigm with GC. To improve \textbf{suboptimal} performance, DANCE performs round-wise, model-in-the-loop condensation refresh using the latest global model. To enhance \textbf{interpretability}, DANCE preserves provenance by storing locally inspectable evidence packs that trace predictions to selected neighbors and source text spans. Across 8 TAG datasets, DANCE improves accuracy by \textbf{2.33\%} at an \textbf{8\%} condensation ratio, with \textbf{33.42\%} fewer tokens than baselines.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16519v1</guid></item><item><title>[cs updates on arXiv.org] TangramPuzzle: Evaluating Multimodal Large Language Models with Compositional Spatial Reasoning</title><link>https://arxiv.org/abs/2601.16520</link><description>arXiv:2601.16520v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable progress in visual recognition and semantic understanding. Nevertheless, their ability to perform precise compositional spatial reasoning remains largely unexplored. Existing benchmarks often involve relatively simple tasks and rely on semantic approximations or coarse relative positioning, while their evaluation metrics are typically limited and lack rigorous mathematical formulations. To bridge this gap, we introduce TangramPuzzle, a geometry-grounded benchmark designed to evaluate compositional spatial reasoning through the lens of the classic Tangram game. We propose the Tangram Construction Expression (TCE), a symbolic geometric framework that grounds tangram assemblies in exact, machine-verifiable coordinate specifications, to mitigate the ambiguity of visual approximation. We design two complementary tasks: Outline Prediction, which demands inferring global shapes from local components, and End-to-End Code Generation, which requires solving inverse geometric assembly problems. We conduct extensive evaluation experiments on advanced open-source and proprietary models, revealing an interesting insight: MLLMs tend to prioritize matching the target silhouette while neglecting geometric constraints, leading to distortions or deformations of the pieces.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16520v1</guid></item><item><title>[cs updates on arXiv.org] Numerical efficiency of explicit time integrators for phase-field models</title><link>https://arxiv.org/abs/2601.16522</link><description>arXiv:2601.16522v1 Announce Type: new 
Abstract: Phase-field simulations are a practical but also expensive tool to calculate microstructural evolution. This work aims to compare explicit time integrators for a broad class of phase-field models involving coupling between the phase-field and concentration. Particular integrators are adapted to constraints on the phase-field as well as storage scheme implications. Reproducible benchmarks are defined with a focus on having exact sharp interface solutions, allowing for identification of dominant error terms. Speedups of 4 to 114 over the classic forward Euler integrator are achievable while still using a fully explicit scheme without appreciable accuracy loss. Application examples include final stage sintering with pores slowing down grain growth as they move and merge over time.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16522v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs</title><link>https://arxiv.org/abs/2601.16527</link><description>arXiv:2601.16527v1 Announce Type: new 
Abstract: Multimodal LLMs are powerful but prone to object hallucinations, which describe non-existent entities and harm reliability. While recent unlearning methods attempt to mitigate this, we identify a critical flaw: structural fragility. We empirically demonstrate that standard erasure achieves only superficial suppression, trapping the model in sharp minima where hallucinations catastrophically resurge after lightweight relearning. To ensure geometric stability, we propose SARE, which casts unlearning as a targeted min-max optimization problem and uses a Targeted-SAM mechanism to explicitly flatten the loss landscape around hallucinated concepts. By suppressing hallucinations under simulated worst-case parameter perturbations, our framework ensures robust removal stable against weight shifts. Extensive experiments demonstrate that SARE significantly outperforms baselines in erasure efficacy while preserving general generation quality. Crucially, it maintains persistent hallucination suppression against relearning and parameter updates, validating the effectiveness of geometric stabilization.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16527v1</guid></item><item><title>[cs updates on arXiv.org] SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care</title><link>https://arxiv.org/abs/2601.16529</link><description>arXiv:2601.16529v1 Announce Type: new 
Abstract: Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\%. Models showed higher vulnerability to imaging requests (38.8\%) than opioid prescriptions (25.0\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16529v1</guid></item><item><title>[cs updates on arXiv.org] Curate-Train-Refine: A Closed-Loop Agentic Framework for Zero Shot Classification</title><link>https://arxiv.org/abs/2601.16530</link><description>arXiv:2601.16530v1 Announce Type: new 
Abstract: Large language models (LLMs) and high-capacity encoders have advanced zero and few-shot classification, but their inference cost and latency limit practical deployment. We propose training lightweight text classifiers using dynamically generated supervision from an LLM. Our method employs an iterative, agentic loop in which the LLM curates training data, analyzes model successes and failures, and synthesizes targeted examples to address observed errors. This closed-loop generation and evaluation process progressively improves data quality and adapts it to the downstream classifier and task. Across four widely used benchmarks, our approach consistently outperforms standard zero and few-shot baselines. These results indicate that LLMs can serve effectively as data curators, enabling accurate and efficient classification without the operational cost of large-model deployment.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16530v1</guid></item><item><title>[cs updates on arXiv.org] AnchoredDream: Zero-Shot 360{\deg} Indoor Scene Generation from a Single View via Geometric Grounding</title><link>https://arxiv.org/abs/2601.16532</link><description>arXiv:2601.16532v1 Announce Type: new 
Abstract: Single-view indoor scene generation plays a crucial role in a range of real-world applications. However, generating a complete 360{\deg} scene from a single image remains a highly ill-posed and challenging problem. Recent approaches have made progress by leveraging diffusion models and depth estimation networks, yet they still struggle to maintain appearance consistency and geometric plausibility under large viewpoint changes, limiting their effectiveness in full-scene generation. To address this, we propose AnchoredDream, a novel zero-shot pipeline that anchors 360{\deg} scene generation on high-fidelity geometry via an appearance-geometry mutual boosting mechanism. Given a single-view image, our method first performs appearance-guided geometry generation to construct a reliable 3D scene layout. Then, we progressively generate the complete scene through a series of modules: warp-and-inpaint, warp-and-refine, post-optimization, and a novel Grouting Block, which ensures seamless transitions between the input view and generated regions. Extensive experiments demonstrate that AnchoredDream outperforms existing methods by a large margin in both appearance consistency and geometric plausibility--all in a zero-shot manner. Our results highlight the potential of geometric grounding for high-quality, zero-shot single-view scene generation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16532v1</guid></item><item><title>[cs updates on arXiv.org] UAV-Assisted Joint Data Collection and Wireless Power Transfer for Batteryless Sensor Networks</title><link>https://arxiv.org/abs/2601.16533</link><description>arXiv:2601.16533v1 Announce Type: new 
Abstract: The development of wireless power transfer (WPT) and Internet of Things (IoT) offers significant potential but faces challenges such as limited energy supply, dynamic environmental changes, and unstable transmission links. This paper presents an unmanned aerial vehicle (UAV)-assisted data collection and WPT scheme to support batteryless sensor (BLS) networks in remote areas. In this system, BLSs harvest energy from the UAV and utilize the harvested energy to transmit the collected data back to the UAV. The goal is to maximize the collected data volume and fairness index while minimizing the UAV energy consumption. To achieve these objectives, an optimization problem is formulated to jointly optimize the transmit power and UAV trajectory. Due to the non-convexity and dynamic nature of the problem, a deep reinforcement learning (DRL)-based algorithm is proposed to solve the problem. Specifically, this algorithm integrates prioritized experience replay and the performer module to enhance system stability and accelerate convergence. Simulation results demonstrate that the proposed approach consistently outperforms benchmark schemes in terms of collected data volume, fairness, and UAV energy consumption.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16533v1</guid></item><item><title>[cs updates on arXiv.org] W4A16 Mixed-Precision Matrix Multiplication on Decoupled Architecture: Kernel Design and Memory Bottleneck Analysis for Ascend NPUs</title><link>https://arxiv.org/abs/2601.16536</link><description>arXiv:2601.16536v1 Announce Type: new 
Abstract: As Large Language Models (LLMs) scale, weight-only quantization (W4A16: 4-bit weights, 16-bit activations) becomes critical for reducing memory footprint with minimal accuracy loss. However, its efficient deployment on Huawei's Ascend 910 Neural Processing Unit (NPU) is challenging due to limited native mixed-precision support and the accelerator's decoupled compute architecture. To enable quantization on such architecture, we present the first practical W4A16 matrix multiplication kernel tailored for the Ascend 910 NPU. Our design leverages vector cores for on-the-fly INT4-to-FP16 dequantization, cube cores for high-throughput GEMM, and Split-K parallelization to mitigate memory latency. Performance evaluations across diverse matrix shapes and batch sizes show our method outperforms data-parallel approaches when K &gt;&gt; N, a typical scenario in LLM decoding. Specially, our method can achieve a speedup ranging from 1.01x to 1.74x. In addition, our profile reveals the primary bottleneck is not dequantization compution itself, but extra global memory transfer for the weight, making W4A16 only reaching a maximum speedup of 1.48x over native FP16xFP16 matrix multiplication in PyTorch. In the long run, our method lays a solid foundation and provides insightful views for the efficient deployment of quantized large language models on various domain-specific accelerators.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16536v1</guid></item><item><title>[cs updates on arXiv.org] OnlineSI: Taming Large Language Model for Online 3D Understanding and Grounding</title><link>https://arxiv.org/abs/2601.16538</link><description>arXiv:2601.16538v1 Announce Type: new 
Abstract: In recent years, researchers have increasingly been interested in how to enable Multimodal Large Language Models (MLLM) to possess spatial understanding and reasoning capabilities. However, most existing methods overlook the importance of the ability to continuously work in an ever-changing world, and lack the possibility of deployment on embodied systems in real-world environments. In this work, we introduce OnlineSI, a framework that can continuously improve its spatial understanding of its surroundings given a video stream. Our core idea is to maintain a finite spatial memory to retain past observations, ensuring the computation required for each inference does not increase as the input accumulates. We further integrate 3D point cloud information with semantic information, helping MLLM to better locate and identify objects in the scene. To evaluate our method, we introduce the Fuzzy $F_1$-Score to mitigate ambiguity, and test our method on two representative datasets. Experiments demonstrate the effectiveness of our method, paving the way towards real-world embodied systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16538v1</guid></item><item><title>[cs updates on arXiv.org] Do Models Hear Like Us? Probing the Representational Alignment of Audio LLMs and Naturalistic EEG</title><link>https://arxiv.org/abs/2601.16540</link><description>arXiv:2601.16540v1 Announce Type: new 
Abstract: Audio Large Language Models (Audio LLMs) have demonstrated strong capabilities in integrating speech perception with language understanding. However, whether their internal representations align with human neural dynamics during naturalistic listening remains largely unexplored. In this work, we systematically examine layer-wise representational alignment between 12 open-source Audio LLMs and Electroencephalogram (EEG) signals across 2 datasets. Specifically, we employ 8 similarity metrics, such as Spearman-based Representational Similarity Analysis (RSA), to characterize within-sentence representational geometry. Our analysis reveals 3 key findings: (1) we observe a rank-dependence split, in which model rankings vary substantially across different similarity metrics; (2) we identify spatio-temporal alignment patterns characterized by depth-dependent alignment peaks and a pronounced increase in RSA within the 250-500 ms time window, consistent with N400-related neural dynamics; (3) we find an affective dissociation whereby negative prosody, identified using a proposed Tri-modal Neighborhood Consistency (TNC) criterion, reduces geometric similarity while enhancing covariance-based dependence. These findings provide new neurobiological insights into the representational mechanisms of Audio LLMs.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16540v1</guid></item><item><title>[cs updates on arXiv.org] Semi-Supervised Hierarchical Open-Set Classification</title><link>https://arxiv.org/abs/2601.16541</link><description>arXiv:2601.16541v1 Announce Type: new 
Abstract: Hierarchical open-set classification handles previously unseen classes by assigning them to the most appropriate high-level category in a class taxonomy. We extend this paradigm to the semi-supervised setting, enabling the use of large-scale, uncurated datasets containing a mixture of known and unknown classes to improve the hierarchical open-set performance. To this end, we propose a teacher-student framework based on pseudo-labeling. Two key components are introduced: 1) subtree pseudo-labels, which provide reliable supervision in the presence of unknown data, and 2) age-gating, a mechanism that mitigates overconfidence in pseudo-labels. Experiments show that our framework outperforms self-supervised pretraining followed by supervised adaptation, and even matches the fully supervised counterpart when using only 20 labeled samples per class on the iNaturalist19 benchmark. Our code is available at https://github.com/walline/semihoc.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16541v1</guid></item><item><title>[cs updates on arXiv.org] CORD: Bridging the Audio-Text Reasoning Gap via Weighted On-policy Cross-modal Distillation</title><link>https://arxiv.org/abs/2601.16547</link><description>arXiv:2601.16547v1 Announce Type: new 
Abstract: Large Audio Language Models (LALMs) have garnered significant research interest. Despite being built upon text-based large language models (LLMs), LALMs frequently exhibit a degradation in knowledge and reasoning capabilities. We hypothesize that this limitation stems from the failure of current training paradigms to effectively bridge the acoustic-semantic gap within the feature representation space. To address this challenge, we propose CORD, a unified alignment framework that performs online cross-modal self-distillation. Specifically, it aligns audio-conditioned reasoning with its text-conditioned counterpart within a unified model. Leveraging the text modality as an internal teacher, CORD performs multi-granularity alignment throughout the audio rollout process. At the token level, it employs on-policy reverse KL divergence with importance-aware weighting to prioritize early and semantically critical tokens. At the sequence level, CORD introduces a judge-based global reward to optimize complete reasoning trajectories via Group Relative Policy Optimization (GRPO). Empirical results across multiple benchmarks demonstrate that CORD consistently enhances audio-conditioned reasoning and substantially bridges the audio-text performance gap with only 80k synthetic training samples, validating the efficacy and data efficiency of our on-policy, multi-level cross-modal alignment approach.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16547v1</guid></item><item><title>[cs updates on arXiv.org] LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification</title><link>https://arxiv.org/abs/2601.16549</link><description>arXiv:2601.16549v1 Announce Type: new 
Abstract: The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16549v1</guid></item><item><title>[cs updates on arXiv.org] Understanding and Improving UMAP with Geometric and Topological Priors: The JORC-UMAP Algorithm</title><link>https://arxiv.org/abs/2601.16552</link><description>arXiv:2601.16552v1 Announce Type: new 
Abstract: Nonlinear dimensionality reduction techniques, particularly UMAP, are widely used for visualizing high-dimensional data. However, UMAP's local Euclidean distance assumption often fails to capture intrinsic manifold geometry, leading to topological tearing and structural collapse. We identify UMAP's sensitivity to the k-nearest neighbor graph as a key cause. To address this, we introduce Ollivier-Ricci curvature as a geometric prior, reinforcing edges at geometric bottlenecks and reducing redundant links. Since curvature estimation is noise-sensitive, we also incorporate a topological prior using Jaccard similarity to ensure neighborhood consistency. The resulting method, JORC-UMAP, better distinguishes true manifold structure from spurious connections. Experiments on synthetic and real-world datasets show that JORC-UMAP reduces tearing and collapse more effectively than standard UMAP and other DR methods, as measured by SVM accuracy and triplet preservation scores, while maintaining computational efficiency. This work offers a geometry-aware enhancement to UMAP for more faithful data visualization.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16552v1</guid></item><item><title>[cs updates on arXiv.org] Retrieve-Refine-Calibrate: A Framework for Complex Claim Fact-Checking</title><link>https://arxiv.org/abs/2601.16555</link><description>arXiv:2601.16555v1 Announce Type: new 
Abstract: Fact-checking aims to verify the truthfulness of a claim based on the retrieved evidence. Existing methods typically follow a decomposition paradigm, in which a claim is broken down into sub-claims that are individually verified. However, the decomposition paradigm may introduce noise to the verification process due to irrelevant entities or evidence, ultimately degrading verification accuracy. To address this problem, we propose a Retrieve-Refine-Calibrate (RRC) framework based on large language models (LLMs). Specifically, the framework first identifies the entities mentioned in the claim and retrieves evidence relevant to them. Then, it refines the retrieved evidence based on the claim to reduce irrelevant information. Finally, it calibrates the verification process by re-evaluating low-confidence predictions. Experiments on two popular fact-checking datasets (HOVER and FEVEROUS-S) demonstrate that our framework achieves superior performance compared with competitive baselines.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16555v1</guid></item><item><title>[cs updates on arXiv.org] PRISM: Purified Representation and Integrated Semantic Modeling for Generative Sequential Recommendation</title><link>https://arxiv.org/abs/2601.16556</link><description>arXiv:2601.16556v1 Announce Type: new 
Abstract: Generative Sequential Recommendation (GSR) has emerged as a promising paradigm, reframing recommendation as an autoregressive sequence generation task over discrete Semantic IDs (SIDs), typically derived via codebook-based quantization. Despite its great potential in unifying retrieval and ranking, existing GSR frameworks still face two critical limitations: (1) impure and unstable semantic tokenization, where quantization methods struggle with interaction noise and codebook collapse, resulting in SIDs with ambiguous discrimination; and (2) lossy and weakly structured generation, where reliance solely on coarse-grained discrete tokens inevitably introduces information loss and neglects items' hierarchical logic. To address these issues, we propose a novel generative recommendation framework, PRISM, with Purified Representation and Integrated Semantic Modeling. Specifically, to ensure high-quality tokenization, we design a Purified Semantic Quantizer that constructs a robust codebook via adaptive collaborative denoising and hierarchical semantic anchoring mechanisms. To compensate for information loss during quantization, we further propose an Integrated Semantic Recommender, which incorporates a dynamic semantic integration mechanism to integrate fine-grained semantics and enforces logical validity through a semantic structure alignment objective. PRISM consistently outperforms state-of-the-art baselines across four real-world datasets, demonstrating substantial performance gains, particularly in high-sparsity scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16556v1</guid></item><item><title>[cs updates on arXiv.org] Predicting Networks Before They Happen: Experimentation on a Real-Time V2X Digital Twin</title><link>https://arxiv.org/abs/2601.16559</link><description>arXiv:2601.16559v1 Announce Type: new 
Abstract: Emerging safety-critical Vehicle-to-Everything (V2X) applications require networks to proactively adapt to rapid environmental changes rather than merely reacting to them. While Network Digital Twins (NDTs) offer a pathway to such predictive capabilities, existing solutions typically struggle to reconcile high-fidelity physical modeling with strict real-time constraints. This paper presents a novel, end-to-end real-time V2X Digital Twin framework that integrates live mobility tracking with deterministic channel simulation. By coupling the Tokyo Mobility Digital Twin-which provides live sensing and trajectory forecasting-with VaN3Twin-a full-stack simulator with ray tracing-we enable the prediction of network performance before physical events occur. We validate this approach through an experimental proof-of-concept deployed in Tokyo, Japan, featuring connected vehicles operating on 60 GHz links. Our results demonstrate the system's ability to predict Received Signal Strength (RSSI) with a maximum average error of 1.01 dB and reliably forecast Line-of-Sight (LoS) transitions within a maximum average end-to-end system latency of 250 ms, depending on the ray tracing level of detail. Furthermore, we quantify the fundamental trade-offs between digital model fidelity, computational latency, and trajectory prediction horizons, proving that high-fidelity and predictive digital twins are feasible in real-world urban environments.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16559v1</guid></item><item><title>[cs updates on arXiv.org] Eclipse Attacks on Ethereum's Peer-to-Peer Network</title><link>https://arxiv.org/abs/2601.16560</link><description>arXiv:2601.16560v1 Announce Type: new 
Abstract: Eclipse attacks isolate blockchain nodes by monopolizing their peer-to-peer connections. The attacks were extensively studied in Bitcoin (SP'15, SP'20, CCS'21, SP'23) and Monero (NDSS'25), but their practicality against Ethereum nodes remains underexplored, particularly in the post-Merge settings.
  We present the first end-to-end implementation of an eclipse attack targeting Ethereum (2.0 version) execution-layer nodes. Our attack exploits the bootstrapping and peer management logic of Ethereum to fully isolate a node upon restart. We introduce a multi-stage strategy that majorly includes (i) poisoning the node's discovery table via unsolicited messages, (ii) infiltrating Ethereum's DNS-based peerlist by identifying and manipulating the official DNS crawler, and (iii) hijacking idle incoming connection slots across the network to block benign connections. Our DNS list poisoning is the first in the cryptocurrency context and requires only 28 IP addresses over 100 days. Slots hijacking raises outgoing redirection success from 45\% to 95\%. We validate our approach through controlled experiments on Ethereum's Sepolia testnet and broad measurements on the mainnet. Our findings demonstrate that over 80\% of public nodes do not leave sufficient idle capacity for effective slots occupation, highlighting the feasibility and severity of the threat. We further propose concrete countermeasures and responsibly disclosed all findings to Ethereum's security team.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16560v1</guid></item><item><title>[cs updates on arXiv.org] Process-Tensor Tomography of SGD: Measuring Non-Markovian Memory via Back-Flow of Distinguishability</title><link>https://arxiv.org/abs/2601.16563</link><description>arXiv:2601.16563v1 Announce Type: new 
Abstract: This work proposes neural training as a \emph{process tensor}: a multi-time map that takes a sequence of controllable instruments (batch choices, augmentations, optimizer micro-steps) and returns an observable of the trained model. Building on this operational lens, we introduce a simple, model-agnostic witness of training memory based on \emph{back-flow of distinguishability}. In a controlled two-step protocol, we compare outcome distributions after one intervention versus two; the increase $\Delta_{\mathrm{BF}} = D_2 - D_1&gt;0$ (with $D\in\{\mathrm{TV}, \mathrm{JS}, \mathrm{H}\}$ measured on softmax predictions over a fixed probe set) certifies non-Markovianity. We observe consistent positive back-flow with tight bootstrap confidence intervals, amplification under higher momentum, larger batch overlap, and more micro-steps, and collapse under a \emph{causal break} (resetting optimizer state), directly attributing the effect to optimizer/data-state memory. The witness is robust across TV/JS/Hellinger, inexpensive to compute, and requires no architectural changes. We position this as a \emph{measurement} contribution: a principled diagnostic and empirical evidence that practical SGD deviates from the Markov idealization. An exploratory case study illustrates how the micro-level signal can inform curriculum orderings. "Data order matters" turns into a testable operator with confidence bounds, our framework offers a common stage to compare optimizers, curricula, and schedules through their induced training memory.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16563v1</guid></item><item><title>[cs updates on arXiv.org] Agentic AI-RAN Empowering Synergetic Sensing, Communication, Computing, and Control</title><link>https://arxiv.org/abs/2601.16565</link><description>arXiv:2601.16565v1 Announce Type: new 
Abstract: Future sixth-generation (6G) networks are expected to support low-altitude wireless networks (LAWNs), where unmanned aerial vehicles (UAVs) and aerial robots operate in highly dynamic three-dimensional environments under stringent latency, reliability, and autonomy requirements. In such scenarios, autonomous task execution at the network edge demands holistic coordination among sensing, communication, computing, and control (SC3) processes. Agentic Artificially Intelligent Radio Access Networks (Agentic AI-RAN) offer a promising paradigm by enabling the edge network to function as an autonomous decision-making entity for low-altitude agents with limited onboard resources. In this article, we propose and design a task-oriented Agentic AI-RAN architecture that enables SC3 task execution within a single edge node. This integrated design tackles the fundamental problem of coordinating heterogeneous workloads in resource-constrained edge environments. Furthermore, a representative low-altitude embodied intelligence system is prototyped based on a general-purpose Graphics Processing Unit (GPU) platform to demonstrate autonomous drone navigation in realistic settings. By leveraging the Multi-Instance GPU (MIG) partitioning technique and the containerized deployment, the demonstration system achieves physical resource isolation while supporting tightly coupled coordination between real-time communication and multimodal inference under a unified task framework. Experimental results demonstrate low closed-loop latency, robust bidirectional communication, and stable performance under dynamic runtime conditions, highlighting its viability for mission-critical low-altitude wireless networks in 6G.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16565v1</guid></item><item><title>[cs updates on arXiv.org] Predicting Startup Success Using Large Language Models: A Novel In-Context Learning Approach</title><link>https://arxiv.org/abs/2601.16568</link><description>arXiv:2601.16568v1 Announce Type: new 
Abstract: Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they were successful). This limits the effectiveness of traditional machine learning methods that rely on large labeled datasets for model training. To address this challenge, we propose an in-context learning framework for startup success prediction using large language models (LLMs) that requires no model training and leverages only a small set of labeled startups as demonstration examples. Specifically, we propose a novel k-nearest-neighbor-based in-context learning framework, called kNN-ICL, which selects the most relevant past startups as examples based on similarity. Using real-world profiles from Crunchbase, we find that the kNN-ICL approach achieves higher prediction accuracy than supervised machine learning baselines and vanilla in-context learning. Further, we study how performance varies with the number of in-context examples and find that a high balanced accuracy can be achieved with as few as 50 examples. Together, we demonstrate that in-context learning can serve as a decision-making tool for VC firms operating in data-scarce environments.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16568v1</guid></item><item><title>[cs updates on arXiv.org] The inverse of the star discrepancy of a union of randomly shifted Korobov rank-1 lattice point sets depends polynomially on the dimension</title><link>https://arxiv.org/abs/2601.16571</link><description>arXiv:2601.16571v1 Announce Type: new 
Abstract: The inverse of the star discrepancy, $N(\epsilon, s)$, defined as the minimum number of points required to achieve a star discrepancy of at most $\epsilon$ in dimension $s$, is known to depend linearly on $s$. However, explicit constructions achieving this optimal linear dependence remain elusive. Recently, Dick and Pillichshammer (2025) made significant progress by showing that a multiset union of randomly digitally shifted Korobov polynomial lattice point sets almost achieve the optimal dimension dependence with high probability.
  In this paper, we investigate the analog of this result in the setting of classical integer arithmetic using Fourier analysis. We analyze point sets constructed as multiset unions of Korobov rank-1 lattice point sets modulo a prime $N$. We provide a comprehensive analysis covering four distinct construction scenarios, combining either random or fixed integer generators with either continuous torus shifts or discrete grid shifts. We prove that in all four cases, the star discrepancy is bounded by a term of order $O(s \log(N_{tot}) / \sqrt{N_{tot}})$ with high probability, where $N_{tot}$ is the total number of points. This implies that the inverse of the star discrepancy for these structured sets depends quadratically on the dimension $s$. While the proofs are probabilistic, our results significantly reduce the search space for optimal point sets from a continuum to a finite set of candidates parameterized by integer generators and random shifts.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16571v1</guid></item><item><title>[cs updates on arXiv.org] HA2F: Dual-module Collaboration-Guided Hierarchical Adaptive Aggregation Framework for Remote Sensing Change Detection</title><link>https://arxiv.org/abs/2601.16573</link><description>arXiv:2601.16573v1 Announce Type: new 
Abstract: Remote sensing change detection (RSCD) aims to identify the spatio-temporal changes of land cover, providing critical support for multi-disciplinary applications (e.g., environmental monitoring, disaster assessment, and climate change studies). Existing methods focus either on extracting features from localized patches, or pursue processing entire images holistically, which leads to the cross temporal feature matching deviation and exhibiting sensitivity to radiometric and geometric noise. Following the above issues, we propose a dual-module collaboration guided hierarchical adaptive aggregation framework, namely HA2F, which consists of dynamic hierarchical feature calibration module (DHFCM) and noise-adaptive feature refinement module (NAFRM). The former dynamically fuses adjacent-level features through perceptual feature selection, suppressing irrelevant discrepancies to address multi-temporal feature alignment deviations. The NAFRM utilizes the dual feature selection mechanism to highlight the change sensitive regions and generate spatial masks, suppressing the interference of irrelevant regions or shadows. Extensive experiments verify the effectiveness of the proposed HA2F, which achieves state-of-the-art performance on LEVIR-CD, WHU-CD, and SYSU-CD datasets, surpassing existing comparative methods in terms of both precision metrics and computational efficiency. In addition, ablation experiments show that DHFCM and NAFRM are effective. \href{https://huggingface.co/InPeerReview/RemoteSensingChangeDetection-RSCD.HA2F}{HA2F Official Code is Available Here!}</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16573v1</guid></item><item><title>[cs updates on arXiv.org] Zero-Shot MARL Benchmark in the Cyber-Physical Mobility Lab</title><link>https://arxiv.org/abs/2601.16578</link><description>arXiv:2601.16578v1 Announce Type: new 
Abstract: We present a reproducible benchmark for evaluating sim-to-real transfer of Multi-Agent Reinforcement Learning (MARL) policies for Connected and Automated Vehicles (CAVs). The platform, based on the Cyber-Physical Mobility Lab (CPM Lab) [1], integrates simulation, a high-fidelity digital twin, and a physical testbed, enabling structured zero-shot evaluation of MARL motion-planning policies. We demonstrate its use by deploying a SigmaRL-trained policy [2] across all three domains, revealing two complementary sources of performance degradation: architectural differences between simulation and hardware control stacks, and the sim-to-real gap induced by increasing environmental realism. The open-source setup enables systematic analysis of sim-to-real challenges in MARL under realistic, reproducible conditions.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16578v1</guid></item><item><title>[cs updates on arXiv.org] On Best-of-Both-Worlds Fairness via Sum-of-Variances Minimization</title><link>https://arxiv.org/abs/2601.16579</link><description>arXiv:2601.16579v1 Announce Type: new 
Abstract: We consider the problem of fairly allocating a set of indivisible goods among agents with additive valuations. Ex-ante fairness (proportionality) can trivially be obtained by giving all goods to a random agent. Yet, such an allocation is very unfair ex-post. This has motivated the Best-of-Both-Worlds (BoBW) approach, seeking a randomized allocation that is ex-ante proportional and is supported only on ex-post fair allocations (e.g., on allocations that are envy-free-up-to-one-good (EF1), or give some constant fraction of the maximin share (MMS)). It is commonly pointed out that the distribution that allocates all goods to one agent at random fails to be ex-post fair as it ignores the variances of the values of the agents. We examine the approach of trying to mitigate this problem by minimizing the sum-of-variances of the values of the agents, subject to ex-ante proportionality. We study the ex-post fairness properties of the resulting distributions. In support of this approach, observe that such an optimization will indeed deterministically output a proportional allocation if such exists. We show that when valuations are identical, this approach indeed guarantees fairness ex-post: all allocations in the support are envy-free-up-to-any-good (EFX), and thus guarantee every agent at least 4/7 of her maximin share (but not her full MMS). On the negative side, we show that this approach completely fails when valuations are not identical: even in the simplest setting of only two agents and two goods, when the additive valuations are not identical, there is positive probability of allocating both goods to the same agent. Thus, the supporting ex-post allocation might not even be EF1, and might not give an agent any constant fraction of her MMS. Finally, we present similar negative results for other natural minimization objectives that are based on variances.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16579v1</guid></item><item><title>[cs updates on arXiv.org] X-Aligner: Composed Visual Retrieval without the Bells and Whistles</title><link>https://arxiv.org/abs/2601.16582</link><description>arXiv:2601.16582v1 Announce Type: new 
Abstract: Composed Video Retrieval (CoVR) facilitates video retrieval by combining visual and textual queries. However, existing CoVR frameworks typically fuse multimodal inputs in a single stage, achieving only marginal gains over initial baseline. To address this, we propose a novel CoVR framework that leverages the representational power of Vision Language Models (VLMs). Our framework incorporates a novel cross-attention module X-Aligner, composed of cross-attention layers that progressively fuse visual and textual inputs and align their multimodal representation with that of the target video. To further enhance the representation of the multimodal query, we incorporate the caption of the visual query as an additional input. The framework is trained in two stages to preserve the pretrained VLM representation. In the first stage, only the newly introduced module is trained, while in the second stage, the textual query encoder is also fine-tuned. We implement our framework on top of BLIP-family architecture, namely BLIP and BLIP-2, and train it on the Webvid-CoVR data set. In addition to in-domain evaluation on Webvid-CoVR-Test, we perform zero-shot evaluations on the Composed Image Retrieval (CIR) data sets CIRCO and Fashion-IQ. Our framework achieves state-of-the-art performance on CoVR obtaining a Recall@1 of 63.93% on Webvid-CoVR-Test, and demonstrates strong zero-shot generalization on CIR tasks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16582v1</guid></item><item><title>[cs updates on arXiv.org] Who You Explain To Matters: Learning by Explaining to Conversational Agents with Different Pedagogical Roles</title><link>https://arxiv.org/abs/2601.16583</link><description>arXiv:2601.16583v1 Announce Type: new 
Abstract: Conversational agents are increasingly used in education for learning support. An application is "learning by explaining", where learners explain their understanding to an agent. However, existing research focuses on single roles, leaving it unclear how different pedagogical roles influence learners' interaction patterns, learning outcomes and experiences. We conducted a between-subjects study (N=96) comparing agents with three pedagogical roles (Tutee, Peer, Challenger) and a control condition while learning an economics concept. We found that different pedagogical roles shaped learning dynamics, including interaction patterns and experiences. Specifically, the Tutee agent elicited the most cognitive investment but led to high pressure. The Peer agent fostered high absorption and interest through collaborative dialogue. The Challenger agent promoted cognitive and metacognitive acts, enhancing critical thinking with moderate pressure. The findings highlight how agent roles shape different learning dynamics, guiding the design of educational agents tailored to specific pedagogical goals and learning phases.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16583v1</guid></item><item><title>[cs updates on arXiv.org] Emerging Threats and Countermeasures in Neuromorphic Systems: A Survey</title><link>https://arxiv.org/abs/2601.16589</link><description>arXiv:2601.16589v1 Announce Type: new 
Abstract: Neuromorphic computing mimics brain-inspired mechanisms through spiking neurons and energy-efficient processing, offering a pathway to efficient in-memory computing (IMC). However, these advancements raise critical security and privacy concerns. As the adoption of bio-inspired architectures and memristive devices increases, so does the urgency to assess the vulnerability of these emerging technologies to hardware and software attacks. Emerging architectures introduce new attack surfaces, particularly due to asynchronous, event-driven processing and stochastic device behavior. The integration of memristors into neuromorphic hardware and software implementations in spiking neural networks offers diverse possibilities for advanced computing architectures, including their role in security-aware applications. This survey systematically analyzes the security landscape of neuromorphic systems, covering attack methodologies, side-channel vulnerabilities, and countermeasures. We focus on both hardware and software concerns relevant to spiking neural networks (SNNs) and hardware primitives, such as Physical Unclonable Functions (PUFs) and True Random Number Generators (TRNGs) for cryptographic and secure computation applications. We approach this analysis from diverse perspectives, from attack methodologies to countermeasure strategies that integrate efficiency and protection in brain-inspired hardware. This review not only maps the current landscape of security threats but provides a foundation for developing secure and trustworthy neuromorphic architectures.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16589v1</guid></item><item><title>[cs updates on arXiv.org] Integrating Meteorological and Operational Data: A Novel Approach to Understanding Railway Delays in Finland</title><link>https://arxiv.org/abs/2601.16592</link><description>arXiv:2601.16592v1 Announce Type: new 
Abstract: Train delays result from complex interactions between operational, technical, and environmental factors. While weather impacts railway reliability, particularly in Nordic regions, existing datasets rarely integrate meteorological information with operational train data. This study presents the first publicly available dataset combining Finnish railway operations with synchronized meteorological observations from 2018-2024. The dataset integrates operational metrics from Finland Digitraffic Railway Traffic Service with weather measurements from 209 environmental monitoring stations, using spatial-temporal alignment via Haversine distance. It encompasses 28 engineered features across operational variables and meteorological measurements, covering approximately 38.5 million observations from Finland's 5,915-kilometer rail network. Preprocessing includes strategic missing data handling through spatial fallback algorithms, cyclical encoding of temporal features, and robust scaling of weather data to address sensor outliers. Analysis reveals distinct seasonal patterns, with winter months exhibiting delay rates exceeding 25\% and geographic clustering of high-delay corridors in central and northern Finland. Furthermore, the work demonstrates applications of the data set in analysing the reliability of railway traffic in Finland. A baseline experiment using XGBoost regression achieved a Mean Absolute Error of 2.73 minutes for predicting station-specific delays, demonstrating the dataset's utility for machine learning applications. The dataset enables diverse applications, including train delay prediction, weather impact assessment, and infrastructure vulnerability mapping, providing researchers with a flexible resource for machine learning applications in railway operations research.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16592v1</guid></item><item><title>[cs updates on arXiv.org] Generalized Forms of the Kraft Inequality for Finite-State Encoders</title><link>https://arxiv.org/abs/2601.16594</link><description>arXiv:2601.16594v1 Announce Type: new 
Abstract: We derive a few extended versions of the Kraft inequality for information lossless finite-state encoders. The main basic contribution is in defining a notion of a Kraft matrix and in establishing the fact that a necessary condition for information losslessness of a finite-state encoder is that none of the eigenvalues of this matrix have modulus larger than unity, or equivalently, the generalized Kraft inequality asserts that the spectral radius of the Kraft matrix cannot exceed one. For the important special case where the FS encoder is irreducible, we derive several equivalent forms of this inequality, which are based on well known formulas for spectral radius. It also turns out that in the irreducible case, Kraft sums are bounded by a constant, independent of the block length, and thus cannot grow even in any subexponential rate. Finally, two extensions are outlined - one concerns the case of side information available to both encoder and decoder, and the other is for lossy compression.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16594v1</guid></item><item><title>[cs updates on arXiv.org] Attention-MoA: Enhancing Mixture-of-Agents via Inter-Agent Semantic Attention and Deep Residual Synthesis</title><link>https://arxiv.org/abs/2601.16596</link><description>arXiv:2601.16596v1 Announce Type: new 
Abstract: As the development of Large Language Models (LLMs) shifts from parameter scaling to inference-time collaboration, the Mixture-of-Agents (MoA) framework has emerged as a general paradigm to harness collective intelligence by layering diverse models. While recent MoA variants have introduced dynamic routing and residual connections to improve efficiency, these methods often fail to facilitate deep semantic interaction between agents, limiting the system's ability to actively correct hallucinations and refine logic. In this paper, we introduce Attention-MoA, a novel MoA-based framework that redefines collaboration through Inter-agent Semantic Attention. Complemented by an Inter-layer Residual Module with Adaptive Early Stopping Mechanism, our architecture mitigates information degradation in deep layers while improving computational efficiency. Extensive evaluations across AlpacaEval 2.0, MT-Bench, and FLASK demonstrate that Attention-MoA significantly outperforms state-of-the-art baselines, achieving a 91.15% Length-Controlled Win Rate on AlpacaEval 2.0 and dominating in 10 out of 12 capabilities on FLASK. Notably, Attention-MoA enables an ensemble of small open-source models to outperform massive proprietary models like Claude-4.5-Sonnet and GPT-4.1, achieving an MT-Bench score of 8.83 and an AlpacaEval 2.0 LC Win Rate of 77.36%.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16596v1</guid></item><item><title>[cs updates on arXiv.org] A robust and stable hybrid neural network/finite element method for 2D flows that generalizes to different geometries</title><link>https://arxiv.org/abs/2601.16598</link><description>arXiv:2601.16598v1 Announce Type: new 
Abstract: The deep neural network multigrid solver (DNN-MG) combines a coarse-grid finite element simulation with a deep neural network that corrects the solution on finer grid levels, thereby improving the computational efficiency. In this work, we discuss various design choices for the DNN-MG method and demonstrate significant improvements in accuracy and generalizability when applied to the solution of the instationary Navier-Stokes equations. We investigate the stability of the hybrid simulation and show how the neural networks can be made more robust with the help of replay buffers. By retraining on data derived from the hybrid simulation, the error caused by the neural network over multiple time-steps can be minimized without the need for a differentiable numerical solver. Furthermore, we compare multiple neural network architectures, including recurrent neural networks and Transformers, and study their ability to utilize more information from an increased temporal and spatial receptive field. Transformers allow us to make use of information from cells outside the predicted patch even with unstructured meshes while maintaining the locality of our approach. This can further improve the accuracy of DNN-MG without a significant impact on performance.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16598v1</guid></item><item><title>[cs updates on arXiv.org] An Explicit Upper Bound of Generalized Quadratic Gauss Sums and Its Applications for Asymptotically Optimal Aperiodic Polyphase Sequence Design</title><link>https://arxiv.org/abs/2601.16599</link><description>arXiv:2601.16599v1 Announce Type: new 
Abstract: This work is motivated by the long-standing open problem of designing asymptotically order-optimal aperiodic polyphase sequence sets with respect to the celebrated Welch bound. Attempts were made by Mow over 30 years ago, but a comprehensive understanding to this problem is lacking. Our first key contribution is an explicit upper bound of generalized quadratic Gauss sums which is obtained by recursively applying Paris' asymptotic expansion and then bounding it by leveraging the fast convergence property of the Fibonacci zeta function. Building upon this major finding, our second key contribution includes four systematic constructions of order-optimal sequence sets with low aperiodic correlation and/or ambiguity properties via carefully selected Chu sequences and Alltop sequences. For the first time in the literature, we reveal that the full Alltop sequence set is asymptotically optimal for its low aperiodic correlation sidelobes. Besides, we introduce a novel subset of Alltop sequences possessing both order-optimal aperiodic correlation and ambiguity properties for the entire time-shift window.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16599v1</guid></item><item><title>[cs updates on arXiv.org] Omni-directional attention mechanism based on Mamba for speech separation</title><link>https://arxiv.org/abs/2601.16603</link><description>arXiv:2601.16603v1 Announce Type: new 
Abstract: Mamba, a selective state-space model (SSM), has emerged as an efficient alternative to Transformers for speech modeling, enabling long-sequence processing with linear complexity. While effective in speech separation, existing approaches, whether in the time or time-frequency domain, typically decompose the input along a single dimension into short one-dimensional sequences before processing them with Mamba, which restricts it to local 1D modeling and limits its ability to capture global dependencies across the 2D spectrogram. In this work, we propose an efficient omni-directional attention (OA) mechanism built upon unidirectional Mamba, which models global dependencies from ten different directions on the spectrogram. We expand the proposed mechanism into two baseline separation models and evaluate on three public datasets. Experimental results show that our approach consistently achieves significant performance gains over the baselines while preserving linear complexity, outperforming existing state-of-the-art (SOTA) systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16603v1</guid></item><item><title>[cs updates on arXiv.org] A Lightweight Medical Image Classification Framework via Self-Supervised Contrastive Learning and Quantum-Enhanced Feature Modeling</title><link>https://arxiv.org/abs/2601.16608</link><description>arXiv:2601.16608v1 Announce Type: new 
Abstract: Intelligent medical image analysis is essential for clinical decision support but is often limited by scarce annotations, constrained computational resources, and suboptimal model generalization. To address these challenges, we propose a lightweight medical image classification framework that integrates self-supervised contrastive learning with quantum-enhanced feature modeling. MobileNetV2 is employed as a compact backbone and pretrained using a SimCLR-style self-supervised paradigm on unlabeled images. A lightweight parameterized quantum circuit (PQC) is embedded as a quantum feature enhancement module, forming a hybrid classical-quantum architecture, which is subsequently fine-tuned on limited labeled data. Experimental results demonstrate that, with only approximately 2-3 million parameters and low computational cost, the proposed method consistently outperforms classical baselines without self-supervised learning or quantum enhancement in terms of Accuracy, AUC, and F1-score. Feature visualization further indicates improved discriminability and representation stability. Overall, this work provides a practical and forward-looking solution for high-performance medical artificial intelligence under resource-constrained settings.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16608v1</guid></item><item><title>[cs updates on arXiv.org] Challenges in the Proper Metrological Verification of Smart Energy Meters</title><link>https://arxiv.org/abs/2601.16612</link><description>arXiv:2601.16612v1 Announce Type: new 
Abstract: The most common instruments currently measuring active/reactive energy and power quality indicators are smart energy meters. Unfortunately, the verification of such meters is currently performed under ideal conditions or with simple signal models, which do not recreate actual states occurring in the power grid and do not ensure the verification of the properties of their signal chains. This paper presents challenges in the proper metrological verification of smart energy meters. It presents existing legal and normative requirements and scientific research directions regarding these meters. Selected test results are presented, which show that although the tested meters meet the normative and legal requirements because they have been approved for sale, numerous imperfections in the signal and measurement chains of the analyzed instruments are revealed for the selected test signal. On the basis of the presented research results, further directions of research in the field of smart energy meters have been determined.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16612v1</guid></item><item><title>[cs updates on arXiv.org] Term Coding: An Entropic Framework for Extremal Combinatorics and the Guessing--Number Sandwich Theorem</title><link>https://arxiv.org/abs/2601.16614</link><description>arXiv:2601.16614v1 Announce Type: new 
Abstract: Term Coding asks: given a finite system of term identities $\Gamma$ in $v$ variables, how large can its solution set be on an $n$--element alphabet, when we are free to choose the interpretations of the function symbols? This turns familiar existence problems for quasigroups, designs, and related objects into quantitative extremal questions.
  We prove a guessing-number sandwich theorem that connects term coding to graph guessing numbers (graph entropy). After explicit normalisation and diversification reductions, every instance yields a canonical directed dependency structure with guessing number $\alpha$ such that the maximum code size satisfies $\log_n \Sn(\Gamma)=\alpha+o(1)$ (equivalently, $\Sn(\Gamma)=n^{\alpha+o(1)}$), and $\alpha$ can be bounded or computed using entropy and polymatroid methods.
  We illustrate the framework with examples from extremal combinatorics (Steiner-type identities, self-orthogonal Latin squares) and from information-flow / network-coding style constraints (including a five-cycle instance with fractional exponent and small storage/relay maps).</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16614v1</guid></item><item><title>[cs updates on arXiv.org] AuroraEdge-V-2B: A Faster And Stronger Edge Visual Large Language Model</title><link>https://arxiv.org/abs/2601.16615</link><description>arXiv:2601.16615v1 Announce Type: new 
Abstract: Recently, due to the advancement of multimodal technology, people are attempting to use visual large language models (VLLMs) in industrial production. Many deep learning models (DLMs) deployed in the production environment are gradually being replaced by VLLMs. Compared with DLMs, VLLMs have some advantages in industrial applications: (1) Their strong generalization ability enables them to perform well across a wide range of tasks. (2) They are flexible and can deal with unfamiliar samples through context learning quickly. However, VLLMs also have obvious drawbacks: (1) VLLMs do not perform as well as custom-developed DLMs in specific domains. (2) The number of parameters in VLLMs is generally quite large, and their deployment requires substantial computational resources. (3) VLLMs generally operate much slower than DLMs, making real-time response challenging to achieve. To better utilize VLLMs in industrial applications, we introduce AuroraEdge-V-2B in this work, a compact, robust, and high-speed VLLM designed for edge deployment. To make the model run faster, we also propose a compression-fusion method to improve inference efficiency. AuroraEdge-V-2B has the following notable features: (1) Easy deployment and faster: It has only 2B parameters and is highly suitable for edge deployment, offering better real-time performance. (2) Fewer visual tokens and cheaper: It significantly reduces the number of visual tokens in the decoding process, thereby reducing the floating-point operations by half during inference and making it cheaper to use. (3) Strong performance: It gets a higher score on 9 benchmarks than models with the same number of parameter (e.g., Qwen2-VL-2B, Qwen2.5-VL-3B, InternVL-2.5-2B).</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16615v1</guid></item><item><title>[cs updates on arXiv.org] Boundary and Position Information Mining for Aerial Small Object Detection</title><link>https://arxiv.org/abs/2601.16617</link><description>arXiv:2601.16617v1 Announce Type: new 
Abstract: Unmanned Aerial Vehicle (UAV) applications have become increasingly prevalent in aerial photography and object recognition. However, there are major challenges to accurately capturing small targets in object detection due to the imbalanced scale and the blurred edges. To address these issues, boundary and position information mining (BPIM) framework is proposed for capturing object edge and location cues. The proposed BPIM includes position information guidance (PIG) module for obtaining location information, boundary information guidance (BIG) module for extracting object edge, cross scale fusion (CSF) module for gradually assembling the shallow layer image feature, three feature fusion (TFF) module for progressively combining position and boundary information, and adaptive weight fusion (AWF) module for flexibly merging the deep layer semantic feature. Therefore, BPIM can integrate boundary, position, and scale information in image for small object detection using attention mechanisms and cross-scale feature fusion strategies. Furthermore, BPIM not only improves the discrimination of the contextual feature by adaptive weight fusion with boundary, but also enhances small object perceptions by cross-scale position fusion. On the VisDrone2021, DOTA1.0, and WiderPerson datasets, experimental results show the better performances of BPIM compared to the baseline Yolov5-P2, and obtains the promising performance in the state-of-the-art methods with comparable computation load.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16617v1</guid></item><item><title>[cs updates on arXiv.org] PROST-LLM: Progressively Enhancing the Speech-to-Speech Translation Capability in LLMs</title><link>https://arxiv.org/abs/2601.16618</link><description>arXiv:2601.16618v1 Announce Type: new 
Abstract: Although Large Language Models (LLMs) excel in many tasks, their application to Speech-to-Speech Translation (S2ST) is underexplored and hindered by data scarcity. To bridge this gap, we propose PROST-LLM (PROgressive Speech-to-speech Translation) to enhance the S2ST capabilities in LLMs progressively. First, we fine-tune the LLMs with the CVSS corpus, employing designed tri-task learning and chain of modality methods to boost the initial performance. Then, leveraging the fine-tuned model, we generate preference pairs through self-sampling and back-translation without human evaluation. Finally, these preference pairs are used for preference optimization to enhance the model's S2ST capability further. Extensive experiments confirm the effectiveness of our proposed PROST-LLM in improving the S2ST capability of LLMs.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16618v1</guid></item><item><title>[cs updates on arXiv.org] How Does Personalized Memory Shape LLM Behavior? Benchmarking Rational Preference Utilization in Personalized Assistants</title><link>https://arxiv.org/abs/2601.16621</link><description>arXiv:2601.16621v1 Announce Type: new 
Abstract: Large language model (LLM)-powered assistants have recently integrated memory mechanisms that record user preferences, leading to more personalized and user-aligned responses. However, irrelevant personalized memories are often introduced into the context, interfering with the LLM's intent understanding. To comprehensively investigate the dual effects of personalization, we develop RPEval, a benchmark comprising a personalized intent reasoning dataset and a multi-granularity evaluation protocol. RPEval reveals the widespread phenomenon of irrational personalization in existing LLMs and, through error pattern analysis, illustrates its negative impact on user experience. Finally, we introduce RP-Reasoner, which treats memory utilization as a pragmatic reasoning process, enabling the selective integration of personalized information. Experimental results demonstrate that our method significantly outperforms carefully designed baselines on RPEval, and resolves 80% of the bad cases observed in a large-scale commercial personalized assistant, highlighting the potential of pragmatic reasoning to mitigate irrational personalization. Our benchmark is publicly available at https://github.com/XueyangFeng/RPEval.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16621v1</guid></item><item><title>[cs updates on arXiv.org] E2Former-V2: On-the-Fly Equivariant Attention with Linear Activation Memory</title><link>https://arxiv.org/abs/2601.16622</link><description>arXiv:2601.16622v1 Announce Type: new 
Abstract: Equivariant Graph Neural Networks (EGNNs) have become a widely used approach for modeling 3D atomistic systems. However, mainstream architectures face critical scalability bottlenecks due to the explicit construction of geometric features or dense tensor products on \textit{every} edge. To overcome this, we introduce \textbf{E2Former-V2}, a scalable architecture that integrates algebraic sparsity with hardware-aware execution. We first propose \textbf{E}quivariant \textbf{A}xis-\textbf{A}ligned \textbf{S}parsification (EAAS). EAAS builds on Wigner-$6j$ convolution by exploiting an $\mathrm{SO}(3) \rightarrow \mathrm{SO}(2)$ change of basis to transform computationally expensive dense tensor contractions into efficient, sparse parity re-indexing operations. Building on this representation, we introduce \textbf{On-the-Fly Equivariant Attention}, a fully node-centric mechanism implemented via a custom fused Triton kernel. By eliminating materialized edge tensors and maximizing SRAM utilization, our kernel achieves a \textbf{20$\times$ improvement in TFLOPS} compared to standard implementations. Extensive experiments on the SPICE and OMol25 datasets demonstrate that E2Former-V2 maintains comparable predictive performance while notably accelerating inference. This work demonstrates that large equivariant transformers can be trained efficiently using widely accessible GPU platforms. The code is avalible at https://github.com/IQuestLab/UBio-MolFM/tree/e2formerv2.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16622v1</guid></item><item><title>[cs updates on arXiv.org] MultiLexNorm++: A Unified Benchmark and a Generative Model for Lexical Normalization for Asian Languages</title><link>https://arxiv.org/abs/2601.16623</link><description>arXiv:2601.16623v1 Announce Type: new 
Abstract: Social media data has been of interest to Natural Language Processing (NLP) practitioners for over a decade, because of its richness in information, but also challenges for automatic processing. Since language use is more informal, spontaneous, and adheres to many different sociolects, the performance of NLP models often deteriorates. One solution to this problem is to transform data to a standard variant before processing it, which is also called lexical normalization. There has been a wide variety of benchmarks and models proposed for this task. The MultiLexNorm benchmark proposed to unify these efforts, but it consists almost solely of languages from the Indo-European language family in the Latin script. Hence, we propose an extension to MultiLexNorm, which covers 5 Asian languages from different language families in 4 different scripts. We show that the previous state-of-the-art model performs worse on the new languages and propose a new architecture based on Large Language Models (LLMs), which shows more robust performance. Finally, we analyze remaining errors, revealing future directions for this task.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16623v1</guid></item><item><title>[cs updates on arXiv.org] Taming the Heavy Tail: Age-Optimal Preemption</title><link>https://arxiv.org/abs/2601.16624</link><description>arXiv:2601.16624v1 Announce Type: new 
Abstract: This paper studies a continuous-time joint sampling-and-preemption problem, incorporating sampling and preemption penalties under general service-time distributions. We formulate the system as an impulse-controlled piecewise-deterministic Markov process (PDMP) and derive coupled integral average-cost optimality equations via the dynamic programming principle, thereby avoiding the smoothness assumptions typically required for an average-cost Hamilton-Jacobi-Bellman quasi-variational inequality (HJB-QVI) characterization. A key invariance in the busy phase collapses the dynamics onto a one-dimensional busy-start boundary, reducing preemption control to an optimal stopping problem. Building on this structure, we develop an efficient policy iteration algorithm with heavy-tail acceleration, employing a hybrid (uniform/log-spaced) action grid and a far-field linear closure. Simulations under Pareto and log-normal service times demonstrate substantial improvements over AoI-optimal non-preemptive sampling and zero-wait baselines, achieving up to a 30x reduction in average cost in heavy-tailed regimes. Finally, simulations uncover a counterintuitive insight: under preemption, delay variance, despite typically being a liability, can become a strategic advantage for information freshness.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16624v1</guid></item><item><title>[cs updates on arXiv.org] SCHIGAND: A Synthetic Facial Generation Mode Pipeline</title><link>https://arxiv.org/abs/2601.16627</link><description>arXiv:2601.16627v1 Announce Type: new 
Abstract: The growing demand for diverse and high-quality facial datasets for training and testing biometric systems is challenged by privacy regulations, data scarcity, and ethical concerns. Synthetic facial images offer a potential solution, yet existing generative models often struggle to balance realism, diversity, and identity preservation. This paper presents SCHIGAND, a novel synthetic face generation pipeline integrating StyleCLIP, HyperStyle, InterfaceGAN, and Diffusion models to produce highly realistic and controllable facial datasets. SCHIGAND enhances identity preservation while generating realistic intra-class variations and maintaining inter-class distinctiveness, making it suitable for biometric testing. The generated datasets were evaluated using ArcFace, a leading facial verification model, to assess their effectiveness in comparison to real-world facial datasets. Experimental results demonstrate that SCHIGAND achieves a balance between image quality and diversity, addressing key limitations of prior generative models. This research highlights the potential of SCHIGAND to supplement and, in some cases, replace real data for facial biometric applications, paving the way for privacy-compliant and scalable solutions in synthetic dataset generation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16627v1</guid></item><item><title>[cs updates on arXiv.org] The Oval Strikes Back</title><link>https://arxiv.org/abs/2601.16628</link><description>arXiv:2601.16628v1 Announce Type: new 
Abstract: We investigate the applications of ovals in projective planes to distributed storage, with a focus on the Service Rate Region problem. Leveraging the incidence relations between lines and ovals, we describe a class of non-systematic MDS matrices with a large number of small and disjoint recovery sets. For certain parameter choices, the service-rate region of these matrices contains the region of a systematic generator matrix for the same code, yielding better service performance. We further apply our construction to analyze the PIR properties of the considered MDS matrices and present a one-step majority-logic decoding algorithm with strong error-correcting capability. These results highlight how ovals, a classical object in finite geometry, re-emerge as a useful tool in modern coding theory.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16628v1</guid></item><item><title>[cs updates on arXiv.org] Typologically Informed Parameter Aggregation</title><link>https://arxiv.org/abs/2601.16629</link><description>arXiv:2601.16629v1 Announce Type: new 
Abstract: Massively multilingual language models enable cross-lingual generalization but underperform on low-resource and unseen languages. While adapter-based fine-tuning offers a parameter-efficient solution, training language-specific adapters at scale remains costly. We introduce Typologically Informed Parameter Aggregation (TIPA), a training-free method that constructs proxy language adapters by aggregating existing ones, weighted by typological similarity. Integrated into the MAD-X framework, these proxies enable zero-shot cross-lingual transfer without additional training. We evaluate TIPA on five NLP tasks and over 230 languages. TIPA consistently outperforms or matches baselines such as English-only fine-tuning or selecting the typologically closest language adapter. We see the largest gains for languages lacking dedicated adapters. Our results demonstrate that typologically informed aggregation provides a viable alternative to language-specific modules without any training needed.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16629v1</guid></item><item><title>[cs updates on arXiv.org] Dual-Prototype Disentanglement: A Context-Aware Enhancement Framework for Time Series Forecasting</title><link>https://arxiv.org/abs/2601.16632</link><description>arXiv:2601.16632v1 Announce Type: new 
Abstract: Time series forecasting has witnessed significant progress with deep learning. While prevailing approaches enhance forecasting performance by modifying architectures or introducing novel enhancement strategies, they often fail to dynamically disentangle and leverage the complex, intertwined temporal patterns inherent in time series, thus resulting in the learning of static, averaged representations that lack context-aware capabilities. To address this, we propose the Dual-Prototype Adaptive Disentanglement framework (DPAD), a model-agnostic auxiliary method that equips forecasting models with the ability of pattern disentanglement and context-aware adaptation. Specifically, we construct a Dynamic Dual-Prototype bank (DDP), comprising a common pattern bank with strong temporal priors to capture prevailing trend or seasonal patterns, and a rare pattern bank dynamically memorizing critical yet infrequent events, and then an Dual-Path Context-aware routing (DPC) mechanism is proposed to enhance outputs with selectively retrieved context-specific pattern representations from the DDP. Additionally, we introduce a Disentanglement-Guided Loss (DGLoss) to ensure that each prototype bank specializes in its designated role while maintaining comprehensive coverage. Comprehensive experiments demonstrate that DPAD consistently improves forecasting performance and reliability of state-of-the-art models across diverse real-world benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16632v1</guid></item><item><title>[cs updates on arXiv.org] Artifact for Service-Level Energy Modeling and Experimentation for Cloud-Native Microservices</title><link>https://arxiv.org/abs/2601.16635</link><description>arXiv:2601.16635v1 Announce Type: new 
Abstract: Recent advancements enable fine-grained energy measurements in cloud-native environments (e.g., at container or process level) beyond traditional coarse-grained scopes. However, service-level energy measurement for microservice-based applications remains underexplored. Such measurements must include compute, network, and storage energy to avoid underestimating consumption in distributed setups. We present GOXN (Green Observability eXperiment eNginE), an energy experimentation engine for Kubernetes-based microservices that quantifies compute, network, and storage energy at the service level. Using GOXN, we evaluated the OpenTelemetry Demo under varying configurations (monitoring, tracing, service mesh) and steady synthetic load, collecting metrics from Kepler and cAdvisor. Our additive energy model derives service-level energy from container-level data. Results show that excluding network and storage can underestimate auxiliary-service energy by up to 63%, and that high tracing loads shift energy dominance toward network and storage.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16635v1</guid></item><item><title>[cs updates on arXiv.org] GPU-Accelerated Selected Basis Diagonalization with Thrust for SQD-based Algorithms</title><link>https://arxiv.org/abs/2601.16637</link><description>arXiv:2601.16637v1 Announce Type: new 
Abstract: Selected Basis Diagonalization (SBD) plays a central role in Sample-based Quantum Diagonalization (SQD), where iterative diagonalization of the Hamiltonian in selected configuration subspaces forms the dominant classical workload. We present a GPU-accelerated implementation of SBD using the Thrust library. By restructuring key components -- including configuration processing, excitation generation, and matrix-vector operations -- around fine-grained data-parallel primitives and flattened GPU-friendly data layouts, the proposed approach efficiently exploits modern GPU architectures. In our experiments, the Thrust-based SBD achieves up to $\sim$40$\times$ speedup over CPU execution and substantially reduces the total runtime of SQD iterations. These results demonstrate that GPU-native parallel primitives provide a simple, portable, and high-performance foundation for accelerating SQD-based quantum-classical workflows.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16637v1</guid></item><item><title>[cs updates on arXiv.org] HapticMatch: An Exploration for Generative Material Haptic Simulation and Interaction</title><link>https://arxiv.org/abs/2601.16639</link><description>arXiv:2601.16639v1 Announce Type: new 
Abstract: High-fidelity haptic feedback is essential for immersive virtual environments, yet authoring realistic tactile textures remains a significant bottleneck for designers. We introduce HapticMatch, a visual-to-tactile generation framework designed to democratize haptic content creation. We present a novel dataset containing precisely aligned pairs of micro-scale optical images, surface height maps, and friction-induced vibrations for 100 diverse materials. Leveraging this data, we explore and demonstrate that conditional generative models like diffusion and flow-matching can synthesize high-fidelity, renderable surface geometries directly from standard RGB photos. By enabling a "Scan-to-Touch" workflow, HapticMatch allows interaction designers to rapidly prototype multimodal surface sensations without specialized recording equipment, bridging the gap between visual and tactile immersion in VR/AR interfaces.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16639v1</guid></item><item><title>[cs updates on arXiv.org] Convergent adaptive iterative schemes for solving multi-physics problems</title><link>https://arxiv.org/abs/2601.16640</link><description>arXiv:2601.16640v1 Announce Type: new 
Abstract: In this paper, we derive a practical, general framework for creating adaptive iterative (linearization or splitting) algorithms to solve multi-physics problems. This means that, given an iterative method, we derive \textit{a posteriori} estimators to predict the success or failure of the method. Based on these estimators, we propose adaptive algorithms, including adaptively switching between methods, adaptive time-stepping methods, and the adaptive tuning of stabilization parameters. We apply this framework to two-phase flow in porous media, surfactant transport in porous media, and quasi-static poroelasticity.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16640v1</guid></item><item><title>[cs updates on arXiv.org] Edge-Aware Image Manipulation via Diffusion Models with a Novel Structure-Preservation Loss</title><link>https://arxiv.org/abs/2601.16645</link><description>arXiv:2601.16645v1 Announce Type: new 
Abstract: Recent advances in image editing leverage latent diffusion models (LDMs) for versatile, text-prompt-driven edits across diverse tasks. Yet, maintaining pixel-level edge structures-crucial for tasks such as photorealistic style transfer or image tone adjustment-remains as a challenge for latent-diffusion-based editing. To overcome this limitation, we propose a novel Structure Preservation Loss (SPL) that leverages local linear models to quantify structural differences between input and edited images. Our training-free approach integrates SPL directly into the diffusion model's generative process to ensure structural fidelity. This core mechanism is complemented by a post-processing step to mitigate LDM decoding distortions, a masking strategy for precise edit localization, and a color preservation loss to preserve hues in unedited areas. Experiments confirm SPL enhances structural fidelity, delivering state-of-the-art performance in latent-diffusion-based image editing. Our code will be publicly released at https://github.com/gongms00/SPL.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16645v1</guid></item><item><title>[cs updates on arXiv.org] A Cognitive Framework for Autonomous Agents: Toward Human-Inspired Design</title><link>https://arxiv.org/abs/2601.16648</link><description>arXiv:2601.16648v1 Announce Type: new 
Abstract: This work introduces a human-inspired reinforcement learning (RL) architecture that integrates Pavlovian and instrumental processes to enhance decision-making in autonomous systems. While existing engineering solutions rely almost exclusively on instrumental learning, neuroscience shows that humans use Pavlovian associations to leverage predictive cues to bias behavior before outcomes occur. We translate this dual-system mechanism into a cue-guided RL framework in which radio-frequency (RF) stimuli act as conditioned (Pavlovian) cues that modulate action selection. The proposed architecture combines Pavlovian values with instrumental policy optimization, improving navigation efficiency and cooperative behavior in unknown, partially observable environments. Simulation results demonstrate that cue-driven agents adapt faster, achieving superior performance compared to traditional instrumental-solo agents. This work highlights the potential of human learning principles to reshape digital agents intelligence.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16648v1</guid></item><item><title>[cs updates on arXiv.org] LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents</title><link>https://arxiv.org/abs/2601.16649</link><description>arXiv:2601.16649v1 Announce Type: new 
Abstract: Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better understand the relative importance of advancing these underlying capabilities for success on such tasks. We develop an oracle counterfactual framework for multi-turn problems that asks: how would an agent perform if it could leverage an oracle to perfectly perform a specific task? The change in the agent's performance due to this oracle assistance allows us to measure the criticality of such oracle skill in the future advancement of AI agents. We introduce a suite of procedurally generated, game-like tasks with tunable complexity. These controlled environments allow us to provide precise oracle interventions, such as perfect planning or flawless state tracking, and make it possible to isolate the contribution of each oracle without confounding effects present in real-world benchmarks. Our results show that while some interventions (e.g., planning) consistently improve performance across settings, the usefulness of other skills is dependent on the properties of the environment and language model. Our work sheds light on the challenges of multi-turn agentic environments to guide the future efforts in the development of AI agents and language models.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16649v1</guid></item><item><title>[cs updates on arXiv.org] Select or Project? Evaluating Lower-dimensional Vectors for LLM Training Data Explanations</title><link>https://arxiv.org/abs/2601.16651</link><description>arXiv:2601.16651v1 Announce Type: new 
Abstract: Gradient-based methods for instance-based explanation for large language models (LLMs) are hindered by the immense dimensionality of model gradients. In practice, influence estimation is restricted to a subset of model parameters to make computation tractable, but this subset is often chosen ad hoc and rarely justified by systematic evaluation. This paper investigates if it is better to create low-dimensional representations by selecting a small, architecturally informed subset of model components or by projecting the full gradients into a lower-dimensional space. Using a novel benchmark, we show that a greedily selected subset of components captures the information about training data influence needed for a retrieval task more effectively than either the full gradient or random projection. We further find that this approach is more computationally efficient than random projection, demonstrating that targeted component selection is a practical strategy for making instance-based explanations of large models more computationally feasible.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16651v1</guid></item><item><title>[cs updates on arXiv.org] Reliable Brain Tumor Segmentation Based on Spiking Neural Networks with Efficient Training</title><link>https://arxiv.org/abs/2601.16652</link><description>arXiv:2601.16652v1 Announce Type: new 
Abstract: We propose a reliable and energy-efficient framework for 3D brain tumor segmentation using spiking neural networks (SNNs). A multi-view ensemble of sagittal, coronal, and axial SNN models provides voxel-wise uncertainty estimation and enhances segmentation robustness. To address the high computational cost in training SNN models for semantic image segmentation, we employ Forward Propagation Through Time (FPTT), which maintains temporal learning efficiency with significantly reduced computational cost. Experiments on the Multimodal Brain Tumor Segmentation Challenges (BraTS 2017 and BraTS 2023) demonstrate competitive accuracy, well-calibrated uncertainty, and an 87% reduction in FLOPs, underscoring the potential of SNNs for reliable, low-power medical IoT and Point-of-Care systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16652v1</guid></item><item><title>[cs updates on arXiv.org] A Predictor Corrector Convex Splitting Method for Stefan Problems Based on Extreme Learning Machines</title><link>https://arxiv.org/abs/2601.16655</link><description>arXiv:2601.16655v1 Announce Type: new 
Abstract: Solving Stefan problems via neural networks is inherently challenged by the nonlinear coupling between the solutions and the free boundary, which results in a non-convex optimization problem. To address this, this work proposes an Operator Splitting Method (OSM) based on Extreme Learning Machines (ELM) to decouple the geometric interface evolution from the physical field reconstruction. Within a predictor-corrector framework, the method splits the coupled system into an alternating sequence of two linear and convex subproblems: solving the diffusion equation on fixed subdomains and updating the interface geometry based on the Stefan condition. A key contribution is the formulation of both steps as linear least-squares problems; this transforms the computational strategy from a non-convex gradient-based optimization into a stable fixed-point iteration composed of alternating convex solvers. From a theoretical perspective, the relaxed iterative operator is shown to be locally contractive, and its fixed points are consistent with stationary points of the coupled residual functional. Benchmarks across 1D to 3D domains demonstrate the stability and high accuracy of the method, confirming that the proposed framework provides a highly accurate and efficient numerical solution for free boundary problems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16655v1</guid></item><item><title>[cs updates on arXiv.org] Generative Confidants: How do People Experience Trust in Emotional Support from Generative AI?</title><link>https://arxiv.org/abs/2601.16656</link><description>arXiv:2601.16656v1 Announce Type: new 
Abstract: People are increasingly turning to generative AI (e.g., ChatGPT, Gemini, Copilot) for emotional support and companionship. While trust is likely to play a central role in enabling these informal and unsupervised interactions, we still lack an understanding of how people develop and experience it in this context. Seeking to fill this gap, we recruited 24 frequent users of generative AI for emotional support and conducted a qualitative study consisting of diary entries about interactions, transcripts of chats with AI, and in-depth interviews. Our results suggest important novel drivers of trust in this context: familiarity emerging from personalisation, nuanced mental models of generative AI, and awareness of people's control over conversations. Notably, generative AI's homogeneous use of personalised, positive, and persuasive language appears to promote some of these trust-building factors. However, this also seems to discourage other trust-related behaviours, such as remembering that generative AI is a machine trained to converse in human language. We present implications for future research that are likely to become critical as the use of generative AI for emotional support increasingly overlaps with therapeutic work.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16656v1</guid></item><item><title>[cs updates on arXiv.org] Talking about privacy always feels like opening a can of worms. How Intimate Partners Navigate Boundary-Setting in Mobile Phone Without Words</title><link>https://arxiv.org/abs/2601.16658</link><description>arXiv:2601.16658v1 Announce Type: new 
Abstract: Mobile phones, as simultaneously personal and shared technologies, complicate how partners manage digital privacy in intimate relationships. While prior research has examined device-access practices, explicit privacy-rule negotiation, and toxic practices such as surveillance, little is known about how couples manage digital privacy without direct discussion in everyday relationships. To address this gap, we ask: How is digital privacy managed nonverbally and across different media on mobile phones? Drawing on 20 semi-structured interviews, we find that partners often regulate privacy practices through privacy silence -- the intentional avoidance of privacy-related conversations. We identify five motivations for leaving boundaries unspoken: perceiving privacy as unnecessary in intimacy, assuming implicit respect for boundaries, signaling trust and closeness, avoiding potential conflict or harm, and responding to broader societal and cultural expectations that discourage explicit privacy talk. We also identify a hierarchical grouping of content-specific privacy sensitivities, ranging from highly private domains such as financial data to lower-risk domains such as streaming accounts, and show how these priorities shift across relationship stages. These findings show how silence, culture, and content sensitivity shape everyday boundary-setting and underscore the relational and emotional dynamics underpinning mobile phone privacy management.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16658v1</guid></item><item><title>[cs updates on arXiv.org] Provably Robust Bayesian Counterfactual Explanations under Model Changes</title><link>https://arxiv.org/abs/2601.16659</link><description>arXiv:2601.16659v1 Announce Type: new 
Abstract: Counterfactual explanations (CEs) offer interpretable insights into machine learning predictions by answering ``what if?" questions. However, in real-world settings where models are frequently updated, existing counterfactual explanations can quickly become invalid or unreliable. In this paper, we introduce Probabilistically Safe CEs (PSCE), a method for generating counterfactual explanations that are $\delta$-safe, to ensure high predictive confidence, and $\epsilon$-robust to ensure low predictive variance. Based on Bayesian principles, PSCE provides formal probabilistic guarantees for CEs under model changes which are adhered to in what we refer to as the $\langle \delta, \epsilon \rangle$-set. Uncertainty-aware constraints are integrated into our optimization framework and we validate our method empirically across diverse datasets. We compare our approach against state-of-the-art Bayesian CE methods, where PSCE produces counterfactual explanations that are not only more plausible and discriminative, but also provably robust under model change.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16659v1</guid></item><item><title>[cs updates on arXiv.org] Revisiting the Role of Natural Language Code Comments in Code Translation</title><link>https://arxiv.org/abs/2601.16661</link><description>arXiv:2601.16661v1 Announce Type: new 
Abstract: The advent of large language models (LLMs) has ushered in a new era in automated code translation across programming languages. Since most code-specific LLMs are pretrained on well-commented code from large repositories like GitHub, it is reasonable to hypothesize that natural language code comments could aid in improving translation quality. Despite their potential relevance, comments are largely absent from existing code translation benchmarks, rendering their impact on translation quality inadequately characterised. In this paper, we present a large-scale empirical study evaluating the impact of comments on translation performance. Our analysis involves more than $80,000$ translations, with and without comments, of $1100+$ code samples from two distinct benchmarks covering pairwise translations between five different programming languages: C, C++, Go, Java, and Python. Our results provide strong evidence that code comments, particularly those that describe the overall purpose of the code rather than line-by-line functionality, significantly enhance translation accuracy. Based on these findings, we propose COMMENTRA, a code translation approach, and demonstrate that it can potentially double the performance of LLM-based code translation. To the best of our knowledge, our study is the first in terms of its comprehensiveness, scale, and language coverage on how to improve code translation accuracy using code comments.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16661v1</guid></item><item><title>[cs updates on arXiv.org] A Categorical Approach to Semantic Interoperability across Building Lifecycle</title><link>https://arxiv.org/abs/2601.16663</link><description>arXiv:2601.16663v1 Announce Type: new 
Abstract: Buildings generate heterogeneous data across their lifecycle, yet integrating these data remains a critical unsolved challenge. Despite three decades of standardization efforts, over 40 metadata schemas now span the building lifecycle, with fragmentation accelerating rather than resolving. Current approaches rely on point-to-point mappings that scale quadratically with the number of schemas, or universal ontologies that become unwieldy monoliths. The fundamental gap is the absence of mathematical foundations for structure-preserving transformations across heterogeneous building data. Here we show that category theory provides these foundations, enabling systematic data integration with $O(n)$ specification complexity for $n$ ontologies. We formalize building ontologies as first-order theories and demonstrate two proof-of-concept implementations in Categorical Query Language (CQL): 1) generating BRICK models from IFC design data at commissioning, and 2) three-way integration of IFC, BRICK, and RealEstateCore where only two explicit mappings yield the third automatically through categorical composition. Our correct-by-construction approach treats property sets as first-class schema entities and provides automated bidirectional migrations, and enables cross-ontology queries. These results establish feasibility of categorical methods for building data integration and suggest a path toward an app ecosystem for buildings, where mathematical foundations enable reliable component integration analogous to smartphone platforms.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16663v1</guid></item><item><title>[cs updates on arXiv.org] ReViP: Reducing False Completion in Vision-Language-Action Models with Vision-Proprioception Rebalance</title><link>https://arxiv.org/abs/2601.16667</link><description>arXiv:2601.16667v1 Announce Type: new 
Abstract: Vision-Language-Action (VLA) models have advanced robotic manipulation by combining vision, language, and proprioception to predict actions. However, previous methods fuse proprioceptive signals directly with VLM-encoded vision-language features, resulting in state-dominant bias and false completions despite visible execution failures. We attribute this to modality imbalance, where policies over-rely on internal state while underusing visual evidence. To address this, we present ReViP, a novel VLA framework with Vision-Proprioception Rebalance to enhance visual grounding and robustness under perturbations. The key insight is to introduce auxiliary task-aware environment priors to adaptively modulate the coupling between semantic perception and proprioceptive dynamics. Specifically, we use an external VLM as a task-stage observer to extract real-time task-centric visual cues from visual observations, which drive a Vision-Proprioception Feature-wise Linear Modulation to enhance environmental awareness and reduce state-driven errors. Moreover, to evaluate false completion, we propose the first False-Completion Benchmark Suite built on LIBERO with controlled settings such as Object-Drop. Extensive experiments show that ReViP effectively reduces false-completion rates and improves success rates over strong VLA baselines on our suite, with gains extending to LIBERO, RoboTwin 2.0, and real-world evaluations.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16667v1</guid></item><item><title>[cs updates on arXiv.org] PLawBench: A Rubric-Based Benchmark for Evaluating LLMs in Real-World Legal Practice</title><link>https://arxiv.org/abs/2601.16669</link><description>arXiv:2601.16669v1 Announce Type: new 
Abstract: As large language models (LLMs) are increasingly applied to legal domain-specific tasks, evaluating their ability to perform legal work in real-world settings has become essential. However, existing legal benchmarks rely on simplified and highly standardized tasks, failing to capture the ambiguity, complexity, and reasoning demands of real legal practice. Moreover, prior evaluations often adopt coarse, single-dimensional metrics and do not explicitly assess fine-grained legal reasoning. To address these limitations, we introduce PLawBench, a Practical Law Benchmark designed to evaluate LLMs in realistic legal practice scenarios. Grounded in real-world legal workflows, PLawBench models the core processes of legal practitioners through three task categories: public legal consultation, practical case analysis, and legal document generation. These tasks assess a model's ability to identify legal issues and key facts, perform structured legal reasoning, and generate legally coherent documents. PLawBench comprises 850 questions across 13 practical legal scenarios, with each question accompanied by expert-designed evaluation rubrics, resulting in approximately 12,500 rubric items for fine-grained assessment. Using an LLM-based evaluator aligned with human expert judgments, we evaluate 10 state-of-the-art LLMs. Experimental results show that none achieves strong performance on PLawBench, revealing substantial limitations in the fine-grained legal reasoning capabilities of current LLMs and highlighting important directions for future evaluation and development of legal LLMs. Data is available at: https://github.com/skylenage/PLawbench.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16669v1</guid></item><item><title>[cs updates on arXiv.org] The Green Side of the Lua</title><link>https://arxiv.org/abs/2601.16670</link><description>arXiv:2601.16670v1 Announce Type: new 
Abstract: The United Nations' 2030 Agenda for Sustainable Development highlights the importance of energy-efficient software to reduce the global carbon footprint. Programming languages and execution models strongly influence software energy consumption, with interpreted languages generally being less efficient than compiled ones. Lua illustrates this trade-off: despite its popularity, it is less energy-efficient than greener and faster languages such as C.
  This paper presents an empirical study of Lua's runtime performance and energy efficiency across 25 official interpreter versions and just-in-time (JIT) compilers. Using a comprehensive benchmark suite, we measure execution time and energy consumption to analyze Lua's evolution, the impact of JIT compilation, and comparisons with other languages. Results show that all LuaJIT compilers significantly outperform standard Lua interpreters. The most efficient LuaJIT consumes about seven times less energy and runs seven times faster than the best Lua interpreter. Moreover, LuaJIT approaches C's efficiency, using roughly six times more energy and running about eight times slower, demonstrating the substantial benefits of JIT compilation for improving both performance and energy efficiency in interpreted languages.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16670v1</guid></item><item><title>[cs updates on arXiv.org] ReWeaver: Towards Simulation-Ready and Topology-Accurate Garment Reconstruction</title><link>https://arxiv.org/abs/2601.16672</link><description>arXiv:2601.16672v1 Announce Type: new 
Abstract: High-quality 3D garment reconstruction plays a crucial role in mitigating the sim-to-real gap in applications such as digital avatars, virtual try-on and robotic manipulation. However, existing garment reconstruction methods typically rely on unstructured representations, such as 3D Gaussian Splats, struggling to provide accurate reconstructions of garment topology and sewing structures. As a result, the reconstructed outputs are often unsuitable for high-fidelity physical simulation. We propose ReWeaver, a novel framework for topology-accurate 3D garment and sewing pattern reconstruction from sparse multi-view RGB images. Given as few as four input views, ReWeaver predicts seams and panels as well as their connectivities in both the 2D UV space and the 3D space. The predicted seams and panels align precisely with the multi-view images, yielding structured 2D--3D garment representations suitable for 3D perception, high-fidelity physical simulation, and robotic manipulation. To enable effective training, we construct a large-scale dataset GCD-TS, comprising multi-view RGB images, 3D garment geometries, textured human body meshes and annotated sewing patterns. The dataset contains over 100,000 synthetic samples covering a wide range of complex geometries and topologies. Extensive experiments show that ReWeaver consistently outperforms existing methods in terms of topology accuracy, geometry alignment and seam-panel consistency.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16672v1</guid></item><item><title>[cs updates on arXiv.org] I Guess That's Why They Call it the Blues: Causal Analysis for Audio Classifiers</title><link>https://arxiv.org/abs/2601.16675</link><description>arXiv:2601.16675v1 Announce Type: new 
Abstract: It is well-known that audio classifiers often rely on non-musically relevant features and spurious correlations to classify audio. Hence audio classifiers are easy to manipulate or confuse, resulting in wrong classifications. While inducing a misclassification is not hard, until now the set of features that the classifiers rely on was not well understood.
  In this paper we introduce a new method that uses causal reasoning to discover features of the frequency space that are sufficient and necessary for a given classification. We describe an implementation of this algorithm in the tool FreqReX and provide experimental results on a number of standard benchmark datasets. Our experiments show that causally sufficient and necessary subsets allow us to manipulate the outputs of the models in a variety of ways by changing the input very slightly. Namely, a change to one out of 240,000 frequencies results in a change in classification 58% of the time, and the change can be so small that it is practically inaudible. These results show that causal analysis is useful for understanding the reasoning process of audio classifiers and can be used to successfully manipulate their outputs.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16675v1</guid></item><item><title>[cs updates on arXiv.org] Distance to nearest skew-symmetric matrix polynomials of bounded rank</title><link>https://arxiv.org/abs/2601.16676</link><description>arXiv:2601.16676v1 Announce Type: new 
Abstract: We propose an algorithm that approximates a given matrix polynomial of degree $d$ by another skew-symmetric matrix polynomial of a specified rank and degree at most $d$. The algorithm is built on recent advances in the theory of generic eigenstructures and factorizations for skew-symmetric matrix polynomials of bounded rank and degree. Taking into account that the rank of a skew-symmetric matrix polynomial is even, the algorithm works for any prescribed even rank greater than or equal to $2$ and produces a skew-symmetric matrix polynomial of that exact rank. We also adapt the algorithm for matrix pencils to achieve a better performance. Lastly, we present numerical experiments for testing our algorithms and for comparison to the previously known ones.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16676v1</guid></item><item><title>[cs updates on arXiv.org] Sim-to-Real Transfer via a Style-Identified Cycle Consistent Generative Adversarial Network: Zero-Shot Deployment on Robotic Manipulators through Visual Domain Adaptation</title><link>https://arxiv.org/abs/2601.16677</link><description>arXiv:2601.16677v1 Announce Type: new 
Abstract: The sample efficiency challenge in Deep Reinforcement Learning (DRL) compromises its industrial adoption due to the high cost and time demands of real-world training. Virtual environments offer a cost-effective alternative for training DRL agents, but the transfer of learned policies to real setups is hindered by the sim-to-real gap. Achieving zero-shot transfer, where agents perform directly in real environments without additional tuning, is particularly desirable for its efficiency and practical value. This work proposes a novel domain adaptation approach relying on a Style-Identified Cycle Consistent Generative Adversarial Network (StyleID-CycleGAN or SICGAN), an original Cycle Consistent Generative Adversarial Network (CycleGAN) based model. SICGAN translates raw virtual observations into real-synthetic images, creating a hybrid domain for training DRL agents that combines virtual dynamics with real-like visual inputs. Following virtual training, the agent can be directly deployed, bypassing the need for real-world training. The pipeline is validated with two distinct industrial robots in the approaching phase of a pick-and-place operation. In virtual environments agents achieve success rates of 90 to 100\%, and real-world deployment confirms robust zero-shot transfer (i.e., without additional training in the physical environment) with accuracies above 95\% for most workspace regions. We use augmented reality targets to improve the evaluation process efficiency, and experimentally demonstrate that the agent successfully generalizes to real objects of varying colors and shapes, including LEGO\textsuperscript{\textregistered}~cubes and a mug. These results establish the proposed pipeline as an efficient, scalable solution to the sim-to-real problem.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16677v1</guid></item><item><title>[cs updates on arXiv.org] From Transactions to Exploits: Automated PoC Synthesis for Real-World DeFi Attacks</title><link>https://arxiv.org/abs/2601.16681</link><description>arXiv:2601.16681v1 Announce Type: new 
Abstract: Blockchain systems are increasingly targeted by on-chain attacks that exploit contract vulnerabilities to extract value rapidly and stealthily, making systematic analysis and reproduction highly challenging. In practice, reproducing such attacks requires manually crafting proofs-of-concept (PoCs), a labor-intensive process that demands substantial expertise and scales poorly. In this work, we present the first automated framework for synthesizing verifiable PoCs directly from on-chain attack executions. Our key insight is that attacker logic can be recovered from low-level transaction traces via trace-driven reverse engineering, and then translated into executable exploits by leveraging the code-generation capabilities of large language models (LLMs). To this end, we propose TracExp, which localizes attack-relevant execution contexts from noisy, multi-contract traces and introduces a novel dual-decompiler to transform concrete executions into semantically enriched exploit pseudocode. Guided by this representation, TracExp synthesizes PoCs and refines them to preserve exploitability-relevant semantics. We evaluate TracExp on 321 real-world attacks over the past 20 months. TracExp successfully synthesizes PoCs for 93% of incidents, with 58.78% being directly verifiable, at an average cost of only \$0.07 per case. Moreover, TracExp enabled the release of a large number of previously unavailable PoCs to the community, earning a $900 bounty and demonstrating strong practical impact.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16681v1</guid></item><item><title>[cs updates on arXiv.org] AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning</title><link>https://arxiv.org/abs/2601.16685</link><description>arXiv:2601.16685v1 Announce Type: new 
Abstract: Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16685v1</guid></item><item><title>[cs updates on arXiv.org] Adaptive Reinforcement and Model Predictive Control Switching for Safe Human-Robot Cooperative Navigation</title><link>https://arxiv.org/abs/2601.16686</link><description>arXiv:2601.16686v1 Announce Type: new 
Abstract: This paper addresses the challenge of human-guided navigation for mobile collaborative robots under simultaneous proximity regulation and safety constraints. We introduce Adaptive Reinforcement and Model Predictive Control Switching (ARMS), a hybrid learning-control framework that integrates a reinforcement learning follower trained with Proximal Policy Optimization (PPO) and an analytical one-step Model Predictive Control (MPC) formulated as a quadratic program safety filter. To enable robust perception under partial observability and non-stationary human motion, ARMS employs a decoupled sensing architecture with a Long Short-Term Memory (LSTM) temporal encoder for the human-robot relative state and a spatial encoder for 360-degree LiDAR scans. The core contribution is a learned adaptive neural switcher that performs context-aware soft action fusion between the two controllers, favoring conservative, constraint-aware QP-based control in low-risk regions while progressively shifting control authority to the learned follower in highly cluttered or constrained scenarios where maneuverability is critical, and reverting to the follower action when the QP becomes infeasible. Extensive evaluations against Pure Pursuit, Dynamic Window Approach (DWA), and an RL-only baseline demonstrate that ARMS achieves an 82.5 percent success rate in highly cluttered environments, outperforming DWA and RL-only approaches by 7.1 percent and 3.1 percent, respectively, while reducing average computational latency by 33 percent to 5.2 milliseconds compared to a multi-step MPC baseline. Additional simulation transfer in Gazebo and initial real-world deployment results further indicate the practicality and robustness of ARMS for safe and efficient human-robot collaboration. Source code and a demonstration video are available at https://github.com/21ning/ARMS.git.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16686v1</guid></item><item><title>[cs updates on arXiv.org] EMemBench: Interactive Benchmarking of Episodic Memory for VLM Agents</title><link>https://arxiv.org/abs/2601.16690</link><description>arXiv:2601.16690v1 Announce Type: new 
Abstract: We introduce EMemBench, a programmatic benchmark for evaluating long-term memory of agents through interactive games. Rather than using a fixed set of questions, EMemBench generates questions from each agent's own trajectory, covering both text and visual game environments. Each template computes verifiable ground truth from underlying game signals, with controlled answerability and balanced coverage over memory skills: single/multi-hop recall, induction, temporal, spatial, logical, and adversarial. We evaluate memory agents with strong LMs/VLMs as backbones, using in-context prompting as baselines. Across 15 text games and multiple visual seeds, results are far from saturated: induction and spatial reasoning are persistent bottlenecks, especially in visual setting. Persistent memory yields clear gains for open backbones on text games, but improvements are less consistent for VLM agents, suggesting that visually grounded episodic memory remains an open challenge. A human study further confirms the difficulty of EMemBench.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16690v1</guid></item><item><title>[cs updates on arXiv.org] Affinity Contrastive Learning for Skeleton-based Human Activity Understanding</title><link>https://arxiv.org/abs/2601.16694</link><description>arXiv:2601.16694v1 Announce Type: new 
Abstract: In skeleton-based human activity understanding, existing methods often adopt the contrastive learning paradigm to construct a discriminative feature space. However, many of these approaches fail to exploit the structural inter-class similarities and overlook the impact of anomalous positive samples. In this study, we introduce ACLNet, an Affinity Contrastive Learning Network that explores the intricate clustering relationships among human activity classes to improve feature discrimination. Specifically, we propose an affinity metric to refine similarity measurements, thereby forming activity superclasses that provide more informative contrastive signals. A dynamic temperature schedule is also introduced to adaptively adjust the penalty strength for various superclasses. In addition, we employ a margin-based contrastive strategy to improve the separation of hard positive and negative samples within classes. Extensive experiments on NTU RGB+D 60, NTU RGB+D 120, Kinetics-Skeleton, PKU-MMD, FineGYM, and CASIA-B demonstrate the superiority of our method in skeleton-based action recognition, gait recognition, and person re-identification. The source code is available at https://github.com/firework8/ACLNet.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16694v1</guid></item><item><title>[cs updates on arXiv.org] Supporting Stakeholder Requirements Expression with LLM Revisions: An Empirical Evaluation</title><link>https://arxiv.org/abs/2601.16699</link><description>arXiv:2601.16699v1 Announce Type: new 
Abstract: Stakeholders often struggle to accurately express their requirements due to articulation barriers arising from limited domain knowledge or from cognitive constraints. This can cause misalignment between expressed and intended requirements, complicating elicitation and validation. Traditional elicitation techniques, such as interviews and follow-up sessions, are time-consuming and risk distorting stakeholders' original intent across iterations. Large Language Models (LLMs) can infer user intentions from context, suggesting potential for assisting stakeholders in expressing their needs. This raises the questions of (i) how effectively LLMs can support requirement expression and (ii) whether such support benefits stakeholders with limited domain expertise. We conducted a study with 26 participants who produced 130 requirement statements. Each participant first expressed requirements unaided, then evaluated LLM-generated revisions tailored to their context. Participants rated LLM revisions significantly higher than their original statements across all dimensions-alignment with intent, readability, reasoning, and unambiguity. Qualitative feedback further showed that LLM revisions often surfaced tacit details stakeholders considered important and helped them better understand their own requirements. We present and evaluate a stakeholder-centered approach that leverages LLMs as articulation aids in requirements elicitation and validation. Our results show that LLM-assisted reformulation improves perceived completeness, clarity, and alignment of requirements. By keeping stakeholders in the validation loop, this approach promotes responsible and trustworthy use of AI in Requirements Engineering.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16699v1</guid></item><item><title>[cs updates on arXiv.org] Adoption of Generative Artificial Intelligence in the German Software Engineering Industry: An Empirical Study</title><link>https://arxiv.org/abs/2601.16700</link><description>arXiv:2601.16700v1 Announce Type: new 
Abstract: Generative artificial intelligence (GenAI) tools have seen rapid adoption among software developers. While adoption rates in the industry are rising, the underlying factors influencing the effective use of these tools, including the depth of interaction, organizational constraints, and experience-related considerations, have not been thoroughly investigated. This issue is particularly relevant in environments with stringent regulatory requirements, such as Germany, where practitioners must address the GDPR and the EU AI Act while balancing productivity gains with intellectual property considerations. Despite the significant impact of GenAI on software engineering, to the best of our knowledge, no empirical study has systematically examined the adoption dynamics of GenAI tools within the German context. To address this gap, we present a comprehensive mixed-methods study on GenAI adoption among German software engineers. Specifically, we conducted 18 exploratory interviews with practitioners, followed by a developer survey with 109 participants. We analyze patterns of tool adoption, prompting strategies, and organizational factors that influence effectiveness. Our results indicate that experience level moderates the perceived benefits of GenAI tools, and productivity gains are not evenly distributed among developers. Further, organizational size affects both tool selection and the intensity of tool use. Limited awareness of the project context is identified as the most significant barrier. We summarize a set of actionable implications for developers, organizations, and tool vendors seeking to advance artificial intelligence (AI) assisted software development.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16700v1</guid></item><item><title>[cs updates on arXiv.org] Developer Perspectives on REST API Usability: A Study of REST API Guidelines</title><link>https://arxiv.org/abs/2601.16705</link><description>arXiv:2601.16705v1 Announce Type: new 
Abstract: REST is today's most widely used architectural style for providing web-based services. In the age of service-orientation (a.k.a. Software as a Service (SaaS)) APIs have become core business assets and can easily expose hundreds of operations. While well-designed APIs contribute to the commercial success of a service, poorly designed APIs can threaten entire organizations. Recognizing their relevance and value, many guidelines have been proposed for designing usable APIs, similar to design patterns and coding standards. For example, Zalando and Microsoft provide popular REST API guidelines. However, they are often considered as too large and inapplicable, so many companies create and maintain their own guidelines, which is a challenge in itself. In practice, however, developers still struggle to design effective REST APIs. To improve the situation, we need to improve our empirical understanding of adopting, using, and creating REST API guidelines.
  We present an interview study with 16 REST API experts from industry. We determine the notion of API usability, guideline effectiveness factors, challenges of adopting and designing guidelines, and best practices. We identified eight factors influencing REST API usability, among which the adherence to conventions is the most important one. While guidelines can in fact be an effective means to improve API usability, there is significant resistance from developers against strict guidelines. Guideline size and how it fits with organizational needs are two important factors to consider. REST guidelines also have to grow with the organization, while all stakeholders need to be involved in their development and maintenance. Automated linting provides an opportunity to not only embed compliance enforcement into processes, but also to justify guideline rules with educational explanations.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16705v1</guid></item><item><title>[cs updates on arXiv.org] Make the Unhearable Visible: Exploring Visualization for Musical Instrument Practice</title><link>https://arxiv.org/abs/2601.16708</link><description>arXiv:2601.16708v1 Announce Type: new 
Abstract: We explore the potential of visualization to support musicians in instrument practice through real-time feedback and reflection on their playing. Musicians often struggle to observe the patterns in their playing and interpret them with respect to their goals. Our premise is that these patterns can be made visible with interactive visualization: we can make the unhearable visible. However, understanding the design of such visualizations is challenging: the diversity of needs, including different instruments, skills, musical attributes, and genres, means that any single use case is unlikely to illustrate the broad potential and opportunities. To address this challenge, we conducted a design exploration study where we created and iterated on 33 designs, each focusing on a subset of needs, for example, only one musical skill. Our designs are grounded in our own experience as musicians and the ideas and feedback of 18 musicians with various musical backgrounds and we evaluated them with 13 music learners and teachers. This paper presents the results of our exploration, focusing on a few example designs as instances of possible instrument practice visualizations. From our work, we draw design considerations that contribute to future research and products for visual instrument education.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16708v1</guid></item><item><title>[cs updates on arXiv.org] Barotropic-Baroclinic Splitting for Multilayer Shallow Water Models with Exchanges</title><link>https://arxiv.org/abs/2601.16709</link><description>arXiv:2601.16709v1 Announce Type: new 
Abstract: This work presents the numerical analysis of a barotropic-baroclinic splitting in a nonlinear multilayer framework with exchanges between the layers in terrain-following coordinates. The splitting is formulated as an exact operator splitting. The barotropic step handles free surface evolution and depth-averaged velocity via a well-balanced one-layer model, while the baroclinic step manages vertical exchanges between layers and adjusts velocities to their mean values. We show that the barotropic-baroclinic splitting preserves total energy conservation and meets both a discrete maximum principle and a discrete entropy inequality. Several numerical experiments are presented showing the gain in computational cost, particularly in low Froude simulations, with no loss of accuracy. The benefits of using a well-balancing strategy in the barotropic step to preserve the geostrophic equilibrium are inherited in the overall scheme.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16709v1</guid></item><item><title>[cs updates on arXiv.org] Better Generalizing to Unseen Concepts: An Evaluation Framework and An LLM-Based Auto-Labeled Pipeline for Biomedical Concept Recognition</title><link>https://arxiv.org/abs/2601.16711</link><description>arXiv:2601.16711v1 Announce Type: new 
Abstract: Generalization to unseen concepts is a central challenge due to the scarcity of human annotations in Mention-agnostic Biomedical Concept Recognition (MA-BCR). This work makes two key contributions to systematically address this issue. First, we propose an evaluation framework built on hierarchical concept indices and novel metrics to measure generalization. Second, we explore LLM-based Auto-Labeled Data (ALD) as a scalable resource, creating a task-specific pipeline for its generation. Our research unequivocally shows that while LLM-generated ALD cannot fully substitute for manual annotations, it is a valuable resource for improving generalization, successfully providing models with the broader coverage and structural knowledge needed to approach recognizing unseen concepts. Code and datasets are available at https://github.com/bio-ie-tool/hi-ald.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16711v1</guid></item><item><title>[cs updates on arXiv.org] A Feature Extraction Pipeline for Enhancing Lightweight Neural Networks in sEMG-based Joint Torque Estimation</title><link>https://arxiv.org/abs/2601.16712</link><description>arXiv:2601.16712v1 Announce Type: new 
Abstract: Robot-assisted rehabilitation offers an effective approach, wherein exoskeletons adapt to users' needs and provide personalized assistance. However, to deliver such assistance, accurate prediction of the user's joint torques is essential. In this work, we propose a feature extraction pipeline using 8-channel surface electromyography (sEMG) signals to predict elbow and shoulder joint torques. For preliminary evaluation, this pipeline was integrated into two neural network models: the Multilayer Perceptron (MLP) and the Temporal Convolutional Network (TCN). Data were collected from a single subject performing elbow and shoulder movements under three load conditions (0 kg, 1.10 kg, and 1.85 kg) using three motion-capture cameras. Reference torques were estimated from center-of-mass kinematics under the assumption of static equilibrium. Our offline analyses showed that, with our feature extraction pipeline, MLP model achieved mean RMSE of 0.963 N m, 1.403 N m, and 1.434 N m (over five seeds) for elbow, front-shoulder, and side-shoulder joints, respectively, which were comparable to the TCN performance. These results demonstrate that the proposed feature extraction pipeline enables a simple MLP to achieve performance comparable to that of a network designed explicitly for temporal dependencies. This finding is particularly relevant for applications with limited training data, a common scenario patient care.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16712v1</guid></item><item><title>[cs updates on arXiv.org] CER-HV: A CER-Based Human-in-the-Loop Framework for Cleaning Datasets Applied to Arabic-Script HTR</title><link>https://arxiv.org/abs/2601.16713</link><description>arXiv:2601.16713v1 Announce Type: new 
Abstract: Handwritten text recognition (HTR) for Arabic-script languages still lags behind Latin-script HTR, despite recent advances in model architectures, datasets, and benchmarks. We show that data quality is a significant limiting factor in many published datasets and propose CER-HV (CER-based Ranking with Human Verification) as a framework to detect and clean label errors. CER-HV combines a CER-based noise detector, built on a carefully configured Convolutional Recurrent Neural Network (CRNN) with early stopping to avoid overfitting noisy samples, and a human-in-the-loop (HITL) step that verifies high-ranking samples. The framework reveals that several existing datasets contain previously underreported problems, including transcription, segmentation, orientation, and non-text content errors. These have been identified with up to 90 percent precision in the Muharaf and 80-86 percent in the PHTI datasets.
  We also show that our CRNN achieves state-of-the-art performance across five of the six evaluated datasets, reaching 8.45 percent Character Error Rate (CER) on KHATT (Arabic), 8.26 percent on PHTI (Pashto), 10.66 percent on Ajami, and 10.11 percent on Muharaf (Arabic), all without any data cleaning. We establish a new baseline of 11.3 percent CER on the PHTD (Persian) dataset. Applying CER-HV improves the evaluation CER by 0.3-0.6 percent on the cleaner datasets and 1.0-1.8 percent on the noisier ones. Although our experiments focus on documents written in an Arabic-script language, including Arabic, Persian, Urdu, Ajami, and Pashto, the framework is general and can be applied to other text recognition datasets.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16713v1</guid></item><item><title>[cs updates on arXiv.org] Dynamic Expert-Guided Model Averaging for Causal Discovery</title><link>https://arxiv.org/abs/2601.16715</link><description>arXiv:2601.16715v1 Announce Type: new 
Abstract: Understanding causal relationships is critical for healthcare. Accurate causal models provide a means to enhance the interpretability of predictive models, and furthermore a basis for counterfactual and interventional reasoning and the estimation of treatment effects. However, would-be practitioners of causal discovery face a dizzying array of algorithms without a clear best choice. This abundance of competitive algorithms makes ensembling a natural choice for practical applications. At the same time, real-world use cases frequently face challenges that violate the assumptions of common causal discovery algorithms, forcing heavy reliance on expert knowledge. Inspired by recent work on dynamically requested expert knowledge and LLMs as experts, we present a flexible model averaging method leveraging dynamically requested expert knowledge to ensemble a diverse array of causal discovery algorithms. Experiments demonstrate the efficacy of our method with imperfect experts such as LLMs on both clean and noisy data. We also analyze the impact of different degrees of expert correctness and assess the capabilities of LLMs for clinical causal discovery, providing valuable insights for practitioners.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16715v1</guid></item><item><title>[cs updates on arXiv.org] On a Coupled Adoption-Opinion Framework for Competing Innovations</title><link>https://arxiv.org/abs/2601.16719</link><description>arXiv:2601.16719v1 Announce Type: new 
Abstract: In this paper, we propose a two-layer adoption-opinion model to study the diffusion of two competing technologies within a population whose opinions evolve under social influence and adoption-driven feedback. After adopting one technology, individuals may become dissatisfied and switch to the alternative. We prove the existence and uniqueness of the adoption-diffused equilibrium, showing that both technologies coexist and that neither partial-adoption nor monopoly can arise. Numerical simulations show that while opinions shape the equilibrium adoption levels, the relative market share between the two technologies depends solely on their user-experience. As a consequence, interventions that symmetrically boost opinions or adoption can disproportionately favor the higher-quality technology, illustrating how symmetric control actions may generate asymmetric outcomes.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16719v1</guid></item><item><title>[cs updates on arXiv.org] Watching AI Think: User Perceptions of Visible Thinking in Chatbots</title><link>https://arxiv.org/abs/2601.16720</link><description>arXiv:2601.16720v1 Announce Type: new 
Abstract: People increasingly turn to conversational agents such as ChatGPT to seek guidance for their personal problems. As these systems grow in capability, many now display elements of "thinking": short reflective statements that reveal a model's intentions or values before responding. While initially introduced to promote transparency, such visible thinking can also anthropomorphise the agent and shape user expectations. Yet little is known about how these displays affect user perceptions in help-seeking contexts. We conducted a 3 x 2 mixed design experiment examining the impact of 'Thinking Content' (None, Emotionally-Supportive, Expertise-Supportive) and 'Conversation Context' (Habit-related vs. Feelings-related problems) on users' perceptions of empathy, warmth, competence, and engagement. Participants interacted with a chatbot that either showed no visible thinking or presented value-oriented reflections prior to its response. Our findings contribute to understanding how thinking transparency influences user experience in supportive dialogues, and offer implications for designing conversational agents that communicate intentions in sensitive, help-seeking scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16720v1</guid></item><item><title>[cs updates on arXiv.org] The Geometry of Coalition Power: Majorization, Lattices, and Displacement in Multiwinner Elections</title><link>https://arxiv.org/abs/2601.16723</link><description>arXiv:2601.16723v1 Announce Type: new 
Abstract: How much influence can a coordinated coalition exert in a multiwinner Top-$k$ election under a positional scoring rule? We study the maximum displacement problem: with coalition size $m$, how many of the current top-$k$ winners can be forced out? We show coalition power decomposes into two independent prefix-majorization constraints, capturing how much the coalition can (i) boost outsiders and (ii) suppress weak winners. For arbitrary scoring rules these prefix inequalities are tight, efficiently checkable necessary conditions (exact in the continuous relaxation).
  For common-step arithmetic-progression (AP) score ladders, including Borda, truncated Borda, $k$-approval/$k$-veto, plurality, and multi-level rules such as $3$--$2$--$1$, we prove a Majorization--Lattice Theorem: feasible aggregate score vectors are exactly the integer points satisfying the Block--HLP prefix-sum capacity constraints plus a single global congruence condition modulo the step size $g$. For Borda ($g=1$) the congruence vanishes, yielding a pure prefix-majorization test.
  This characterization yields an $O(k'\log k')$ exact feasibility oracle for displacing $k'$ winners, and an $O(k(\log k)^2\log(mx))$ algorithm (via dual-envelope binary search) for computing the maximum achievable displacement $k^\ast$. Experiments on Mallows profiles and PrefLib elections confirm exact cutoffs, diminishing returns, and substantial gains over baseline heuristics; for $g&gt;1$ they also demonstrate the predicted congruence effect, where prefix-only tests produce false positives. The oracle scales to extreme instances, processing $10^9$ candidates in under 28 seconds (memory permitting).</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16723v1</guid></item><item><title>[cs updates on arXiv.org] Mitigating Bias in Automated Grading Systems for ESL Learners: A Contrastive Learning Approach</title><link>https://arxiv.org/abs/2601.16724</link><description>arXiv:2601.16724v1 Announce Type: new 
Abstract: As Automated Essay Scoring (AES) systems are increasingly used in high-stakes educational settings, concerns regarding algorithmic bias against English as a Second Language (ESL) learners have increased. Current Transformer-based regression models trained primarily on native-speaker corpora often learn spurious correlations between surface-level L2 linguistic features and essay quality. In this study, we conduct a bias study of a fine-tuned DeBERTa-v3 model using the ASAP 2.0 and ELLIPSE datasets, revealing a constrained score scaling for high-proficiency ESL writing where high-proficiency ESL essays receive scores 10.3% lower than Native speaker essays of identical human-rated quality. To mitigate this, we propose applying contrastive learning with a triplet construction strategy: Contrastive Learning with Matched Essay Pairs. We constructed a dataset of 17,161 matched essay pairs and fine-tuned the model using Triplet Margin Loss to align the latent representations of ESL and Native writing. Our approach reduced the high-proficiency scoring disparity by 39.9% (to a 6.2% gap) while maintaining a Quadratic Weighted Kappa (QWK) of 0.76. Post-hoc linguistic analysis suggests the model successfully disentangled sentence complexity from grammatical error, preventing the penalization of valid L2 syntactic structures.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16724v1</guid></item><item><title>[cs updates on arXiv.org] LongCat-Flash-Thinking-2601 Technical Report</title><link>https://arxiv.org/abs/2601.16725</link><description>arXiv:2601.16725v1 Announce Type: new 
Abstract: We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16725v1</guid></item><item><title>[cs updates on arXiv.org] A locking-free nodal-based polytopal method for linear elasticity</title><link>https://arxiv.org/abs/2601.16728</link><description>arXiv:2601.16728v1 Announce Type: new 
Abstract: This work presents a Discrete de Rham (DDR) numerical scheme for solving linear elasticity problems on general polyhedral meshes, with a focus on preventing volumetric locking in the quasi-incompressible regime. The method is formulated as a nodal-based approach using the lowest-order gradient space of the DDR complex, enriched with scalar face bubble degrees of freedom that effectively capture the normal flux across element faces. This face-bubble enrichment is crucial for ensuring sufficient approximation flexibility of the divergence field, thereby eliminating the {volumetric locking} phenomenon that typically occurs as the Lam\'e parameter $\lambda$ approaches infinity. We establish $H^1$-error estimates that are independent of $\lambda\ge 0$, and depend only on the lower bound of $\mu$, guaranteeing robustness across the entire range from compressible to nearly incompressible regimes. We also show how to adapt our scheme to the frictionless contact mechanics model, maintaining a locking-free estimate for the primal variable (displacement). Numerical experiments confirm that the proposed {locking-free} method delivers accurate and stable approximations on general polytopal discretizations, even when the material behaves as an incompressible medium. The flexibility and robustness of this approach make it a practical alternative to mixed formulations for engineering applications involving nearly incompressible elastic materials.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16728v1</guid></item><item><title>[cs updates on arXiv.org] Using Shadows in Circular Synthetic Aperture Sonar Imaging for Target Analysis</title><link>https://arxiv.org/abs/2601.16733</link><description>arXiv:2601.16733v1 Announce Type: new 
Abstract: Circular Synthetic Aperture Sonar (CSAS) provides a 360{\deg} azimuth view of the seabed, surpassing the limited aperture and mono-view image of conventional side-scan SAS. This makes CSAS a valuable tool for target recognition in mine warfare where the diversity of point of view is essential for reducing false alarms. CSAS processing typically produces a very high-resolution two-dimensional image. However, the parallax introduced by the circular displacement of the illuminator fill-in the shadow regions, and the shadow cast by an object on the seafloor is lost in favor of azimuth coverage and resolution. Yet the shadows provide complementary information on target shape useful for target recognition. In this paper, we explore a way to retrieve shadow information from CSAS data to improve target analysis and carry 3D reconstruction. Sub-aperture filtering is used to get a collection of images at various points of view along the circular trajectory and fixed focus shadow enhancement (FFSE) is applied to obtain sharp shadows. An interactive interface is also proposed to allow human operators to visualize these shadows along the circular trajectory. A space-carving reconstruction method is applied to infer the 3D shape of the object from the segmented shadows. The results demonstrate the potential of shadows in circular SAS for improving target analysis and 3D reconstruction.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16733v1</guid></item><item><title>[cs updates on arXiv.org] A Step to Decouple Optimization in 3DGS</title><link>https://arxiv.org/abs/2601.16736</link><description>arXiv:2601.16736v1 Announce Type: new 
Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful technique for real-time novel view synthesis. As an explicit representation optimized through gradient propagation among primitives, optimization widely accepted in deep neural networks (DNNs) is actually adopted in 3DGS, such as synchronous weight updating and Adam with the adaptive gradient. However, considering the physical significance and specific design in 3DGS, there are two overlooked details in the optimization of 3DGS: (i) update step coupling, which induces optimizer state rescaling and costly attribute updates outside the viewpoints, and (ii) gradient coupling in the moment, which may lead to under- or over-effective regularization. Nevertheless, such a complex coupling is under-explored. After revisiting the optimization of 3DGS, we take a step to decouple it and recompose the process into: Sparse Adam, Re-State Regularization and Decoupled Attribute Regularization. Taking a large number of experiments under the 3DGS and 3DGS-MCMC frameworks, our work provides a deeper understanding of these components. Finally, based on the empirical analysis, we re-design the optimization and propose AdamW-GS by re-coupling the beneficial components, under which better optimization efficiency and representation effectiveness are achieved simultaneously.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16736v1</guid></item><item><title>[cs updates on arXiv.org] Automated Road Crack Localization to Guide Highway Maintenance</title><link>https://arxiv.org/abs/2601.16737</link><description>arXiv:2601.16737v1 Announce Type: new 
Abstract: Highway networks are crucial for economic prosperity. Climate change-induced temperature fluctuations are exacerbating stress on road pavements, resulting in elevated maintenance costs. This underscores the need for targeted and efficient maintenance strategies. This study investigates the potential of open-source data to guide highway infrastructure maintenance. The proposed framework integrates airborne imagery and OpenStreetMap (OSM) to fine-tune YOLOv11 for highway crack localization. To demonstrate the framework's real-world applicability, a Swiss Relative Highway Crack Density (RHCD) index was calculated to inform nationwide highway maintenance. The crack classification model achieved an F1-score of $0.84$ for the positive class (crack) and $0.97$ for the negative class (no crack). The Swiss RHCD index exhibited weak correlations with Long-term Land Surface Temperature Amplitudes (LT-LST-A) (Pearson's $r\ = -0.05$) and Traffic Volume (TV) (Pearson's $r\ = 0.17$), underlining the added value of this novel index for guiding maintenance over other data. Significantly high RHCD values were observed near urban centers and intersections, providing contextual validation for the predictions. These findings highlight the value of open-source data sharing to drive innovation, ultimately enabling more efficient solutions in the public sector.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16737v1</guid></item><item><title>[cs updates on arXiv.org] Evaluating Generative AI in the Lab: Methodological Challenges and Guidelines</title><link>https://arxiv.org/abs/2601.16740</link><description>arXiv:2601.16740v1 Announce Type: new 
Abstract: Generative AI (GenAI) systems are inherently non-deterministic, producing varied outputs even for identical inputs. While this variability is central to their appeal, it challenges established HCI evaluation practices that typically assume consistent and predictable system behavior. Designing controlled lab studies under such conditions therefore remains a key methodological challenge. We present a reflective multi-case analysis of four lab-based user studies with GenAI-integrated prototypes, spanning conversational in-car assistant systems and image generation tools for design workflows. Through cross-case reflection and thematic analysis across all study phases, we identify five methodological challenges and propose eighteen practice-oriented recommendations, organized into five guidelines. These challenges represent methodological constructs that are either amplified, redefined, or newly introduced by GenAI's stochastic nature: (C1) reliance on familiar interaction patterns, (C2) fidelity-control trade-offs, (C3) feedback and trust, (C4) gaps in usability evaluation, and (C5) interpretive ambiguity between interface and system issues. Our guidelines address these challenges through strategies such as reframing onboarding to help participants manage unpredictability, extending evaluation with constructs such as trust and intent alignment, and logging system events, including hallucinations and latency, to support transparent analysis. This work contributes (1) a methodological reflection on how GenAI's stochastic nature unsettles lab-based HCI evaluation and (2) eighteen recommendations that help researchers design more transparent, robust, and comparable studies of GenAI systems in controlled settings.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16740v1</guid></item><item><title>[cs updates on arXiv.org] On the analysis of spectral deferred corrections for differential-algebraic equations of index one</title><link>https://arxiv.org/abs/2601.16744</link><description>arXiv:2601.16744v1 Announce Type: new 
Abstract: In this paper, we present a new SDC scheme for solving semi-explicit DAEs with the ability to be parallelized in which only the differential equations are numerically integrated is presented. In Shu et al. (2007) it was shown that SDC for ODEs achieves one order per iteration. We show that this carries over to the new SDC scheme. The method is derived from the approach of spectral deferred corrections and the idea of enforcing the algebraic constraints without numerical integration as in the approach of $\varepsilon$-embedding in Hairer and Wanner (1996). It enforces the algebraic constraints to be satisfied in each iteration and allows an efficient solve of semi-explicit DAEs with high-accuracy. The proposed scheme is compared with other DAE methods. We demonstrate that the proposed SDC scheme is competitive with Runge-Kutta methods for DAEs in terms of accuracy and its parallelized versions are very efficient in comparison to other SDC methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16744v1</guid></item><item><title>[cs updates on arXiv.org] SWE-Pruner: Self-Adaptive Context Pruning for Coding Agents</title><link>https://arxiv.org/abs/2601.16746</link><description>arXiv:2601.16746v1 Announce Type: new 
Abstract: LLM agents have demonstrated remarkable capabilities in software development, but their performance is hampered by long interaction contexts, which incur high API costs and latency. While various context compression approaches such as LongLLMLingua have emerged to tackle this challenge, they typically rely on fixed metrics such as PPL, ignoring the task-specific nature of code understanding. As a result, they frequently disrupt syntactic and logical structure and fail to retain critical implementation details. In this paper, we propose SWE-Pruner, a self-adaptive context pruning framework tailored for coding agents. Drawing inspiration from how human programmers "selectively skim" source code during development and debugging, SWE-Pruner performs task-aware adaptive pruning for long contexts. Given the current task, the agent formulates an explicit goal (e.g., "focus on error handling") as a hint to guide the pruning targets. A lightweight neural skimmer (0.6B parameters) is trained to dynamically select relevant lines from the surrounding context given the goal. Evaluations across four benchmarks and multiple models validate SWE-Pruner's effectiveness in various scenarios, achieving 23-54% token reduction on agent tasks like SWE-Bench Verified and up to 14.84x compression on single-turn tasks like LongCodeQA with minimal performance impact.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16746v1</guid></item><item><title>[cs updates on arXiv.org] "What I Sign Is Not What I See": Towards Explainable and Trustworthy Cryptocurrency Wallet Signatures</title><link>https://arxiv.org/abs/2601.16751</link><description>arXiv:2601.16751v1 Announce Type: new 
Abstract: Cryptocurrency wallets have become the primary gateway to decentralized applications, yet users often face significant difficulty in discerning what a wallet signature actually does or entails. Prior work has mainly focused on mitigating protocol vulnerabilities, with limited attention to how users perceive and interpret what they are authorizing. To examine this usability-security gap, we conducted two formative studies investigating how users interpret authentic signing requests and what cues they rely on to assess risk. Findings reveal that users often misread critical parameters, underestimate high-risk signatures, and rely on superficial familiarity rather than understanding transaction intent. Building on these insights, we designed the Signature Semantic Decoder -- a prototype framework that reconstructs and visualizes the intent behind wallet signatures prior to confirmation. Through structured parsing and semantic labeling, it demonstrates how signing data can be transformed into plain-language explanations with contextual risk cues. In a between-subjects user study (N = 128), participants using the prototype achieved higher accuracy in identifying risky signatures, improved clarity and decision confidence, and lower cognitive workload compared with the baseline wallet interface. Our study reframes wallet signing as a problem of interpretability within secure interaction design and offers design implications for more transparent and trustworthy cryptocurrency wallet interfaces.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16751v1</guid></item><item><title>[cs updates on arXiv.org] From Clicks to Consensus: Collective Consent Assemblies for Data Governance</title><link>https://arxiv.org/abs/2601.16752</link><description>arXiv:2601.16752v1 Announce Type: new 
Abstract: Obtaining meaningful and informed consent from users is essential for ensuring they maintain autonomy and control over their data. Notice and consent, the standard for collecting consent online, has been criticized. While other individualized solutions have been proposed, this paper argues that a collective approach to consent is worth exploring for several reasons. First, the data of different users is often interlinked, and individual data governance decisions may impact others. Second, harms resulting from data processing are often communal in nature. Finally, having every individual sufficiently informed about data collection practices to ensure truly informed consent has proven impractical.
  We propose collective consent, operationalized through consent assemblies, as one alternative framework. We establish the theoretical foundations of collective consent and employ speculative design to envision how consent assemblies could function by leveraging deliberative mini-publics. We present two vignettes: i) replacing notice and consent, and ii) collecting consent for GenAI model training, to demonstrate its wide application. Our paper employs future backcasting to identify the requirements for realizing collective consent and explores its potential applications in contexts where individual consent is infeasible.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16752v1</guid></item><item><title>[cs updates on arXiv.org] Standardizing Longitudinal Radiology Report Evaluation via Large Language Model Annotation</title><link>https://arxiv.org/abs/2601.16753</link><description>arXiv:2601.16753v1 Announce Type: new 
Abstract: Longitudinal information in radiology reports refers to the sequential tracking of findings across multiple examinations over time, which is crucial for monitoring disease progression and guiding clinical decisions. Many recent automated radiology report generation methods are designed to capture longitudinal information; however, validating their performance is challenging. There is no proper tool to consistently label temporal changes in both ground-truth and model-generated texts for meaningful comparisons. Existing annotation methods are typically labor-intensive, relying on the use of manual lexicons and rules. Complex rules are closed-source, domain specific and hard to adapt, whereas overly simple ones tend to miss essential specialised information. Large language models (LLMs) offer a promising annotation alternative, as they are capable of capturing nuanced linguistic patterns and semantic similarities without extensive manual intervention. They also adapt well to new contexts. In this study, we therefore propose an LLM-based pipeline to automatically annotate longitudinal information in radiology reports. The pipeline first identifies sentences containing relevant information and then extracts the progression of diseases. We evaluate and compare five mainstream LLMs on these two tasks using 500 manually annotated reports. Considering both efficiency and performance, Qwen2.5-32B was subsequently selected and used to annotate another 95,169 reports from the public MIMIC-CXR dataset. Our Qwen2.5-32B-annotated dataset provided us with a standardized benchmark for evaluating report generation models. Using this new benchmark, we assessed seven state-of-the-art report generation models. Our LLM-based annotation method outperforms existing annotation solutions, achieving 11.3\% and 5.3\% higher F1-scores for longitudinal information detection and disease tracking, respectively.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16753v1</guid></item><item><title>[cs updates on arXiv.org] Variability-Aware Detection and Repair of Compilation Errors Using Foundation Models in Configurable Systems</title><link>https://arxiv.org/abs/2601.16755</link><description>arXiv:2601.16755v1 Announce Type: new 
Abstract: Modern software systems often rely on conditional compilation to support optional features and multiple deployment scenarios. In configurable systems, compilation errors may arise only under specific combinations of features, remaining hidden during development and testing. Such variability-induced errors are difficult to detect in practice, as traditional compilers analyze only a single configuration at a time, while existing variability-aware tools typically require complex setup and incur high analysis costs. In this article, we present an empirical study on the use of foundation models to detect and fix compilation errors caused by feature variability in configurable C systems. We evaluate GPT-OSS-20B and GEMINI 3 PRO, and compare them with TYPECHEF, a state-of-the-art variability-aware parser. Our evaluation considers two complementary settings: 5,000 small configurable systems designed to systematically exercise variability-induced compilation behavior, comprising both systems with and without compilation errors, and 14 real-world GitHub commits, as well as an additional set of mutation testing scenarios (42). Our results show that foundation models can effectively identify variability-induced compilation errors. On small configurable systems, GPT-OSS-20B achieved a precision of 0.97, recall of 0.90, and accuracy of 0.94, substantially increasing detection coverage compared to TYPECHEF, and exhibiting performance comparable to GEMINI 3. For compilation error repair, GPT-OSS-20B produced compilable fixes in over 70% of the cases. In the analysis of real commits, CHATGPT-5.2 detected all injected faults except for two cases and identified a potential real compilation bug in a Linux commit with more than 1,000 modified lines. Our findings indicate that current state-of-the-art foundation models provide a practical and low-effort complement to traditional variability-aware analyses.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16755v1</guid></item><item><title>[cs updates on arXiv.org] Flow Matching for Probabilistic Monocular 3D Human Pose Estimation</title><link>https://arxiv.org/abs/2601.16763</link><description>arXiv:2601.16763v1 Announce Type: new 
Abstract: Recovering 3D human poses from a monocular camera view is a highly ill-posed problem due to the depth ambiguity. Earlier studies on 3D human pose lifting from 2D often contain incorrect-yet-overconfident 3D estimations. To mitigate the problem, emerging probabilistic approaches treat the 3D estimations as a distribution, taking into account the uncertainty measurement of the poses. Falling in a similar category, we proposed FMPose, a probabilistic 3D human pose estimation method based on the flow matching generative approach. Conditioned on the 2D cues, the flow matching scheme learns the optimal transport from a simple source distribution to the plausible 3D human pose distribution via continuous normalizing flows. The 2D lifting condition is modeled via graph convolutional networks, leveraging the learnable connections between human body joints as the graph structure for feature aggregation. Compared to diffusion-based methods, the FMPose with optimal transport produces faster and more accurate 3D pose generations. Experimental results show major improvements of our FMPose over current state-of-the-art methods on three common benchmarks for 3D human pose estimation, namely Human3.6M, MPI-INF-3DHP and 3DPW.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16763v1</guid></item><item><title>[cs updates on arXiv.org] ReLU Networks for Model Predictive Control: Network Complexity and Performance Guarantees</title><link>https://arxiv.org/abs/2601.16764</link><description>arXiv:2601.16764v1 Announce Type: new 
Abstract: Recent years have witnessed a resurgence in using ReLU neural networks (NNs) to represent model predictive control (MPC) policies. However, determining the required network complexity to ensure closed-loop performance remains a fundamental open problem. This involves a critical precision-complexity trade-off: undersized networks may fail to capture the MPC policy, while oversized ones may outweigh the benefits of ReLU network approximation. In this work, we propose a projection-based method to enforce hard constraints and establish a state-dependent Lipschitz continuity property for the optimal MPC cost function, which enables sharp convergence analysis of the closed-loop system. For the first time, we derive explicit bounds on ReLU network width and depth for approximating MPC policies with guaranteed closed-loop performance. To further reduce network complexity and enhance closed-loop performance, we propose a non-uniform error framework with a state-aware scaling function to adaptively adjust both the input and output of the ReLU network. Our contributions provide a foundational step toward certifiable ReLU NN-based MPC.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16764v1</guid></item><item><title>[cs updates on arXiv.org] Do LLM hallucination detectors suffer from low-resource effect?</title><link>https://arxiv.org/abs/2601.16766</link><description>arXiv:2601.16766v1 Announce Type: new 
Abstract: LLMs, while outperforming humans in a wide range of tasks, can still fail in unanticipated ways. We focus on two pervasive failure modes: (i) hallucinations, where models produce incorrect information about the world, and (ii) the low-resource effect, where the models show impressive performance in high-resource languages like English but the performance degrades significantly in low-resource languages like Bengali. We study the intersection of these issues and ask: do hallucination detectors suffer from the low-resource effect? We conduct experiments on five tasks across three domains (factual recall, STEM, and Humanities). Experiments with four LLMs and three hallucination detectors reveal a curious finding: As expected, the task accuracies in low-resource languages experience large drops (compared to English). However, the drop in detectors' accuracy is often several times smaller than the drop in task accuracy. Our findings suggest that even in low-resource languages, the internal mechanisms of LLMs might encode signals about their uncertainty. Further, the detectors are robust within language (even for non-English) and in multilingual setups, but not in cross-lingual settings without in-language supervision.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16766v1</guid></item><item><title>[cs updates on arXiv.org] AutoRegressive Generation with B-rep Holistic Token Sequence Representation</title><link>https://arxiv.org/abs/2601.16771</link><description>arXiv:2601.16771v1 Announce Type: new 
Abstract: Previous representation and generation approaches for the B-rep relied on graph-based representations that disentangle geometric and topological features through decoupled computational pipelines, thereby precluding the application of sequence-based generative frameworks, such as transformer architectures that have demonstrated remarkable performance. In this paper, we propose BrepARG, the first attempt to encode B-rep's geometry and topology into a holistic token sequence representation, enabling sequence-based B-rep generation with an autoregressive architecture. Specifically, BrepARG encodes B-rep into 3 types of tokens: geometry and position tokens representing geometric features, and face index tokens representing topology. Then the holistic token sequence is constructed hierarchically, starting with constructing the geometry blocks (i.e., faces and edges) using the above tokens, followed by geometry block sequencing. Finally, we assemble the holistic sequence representation for the entire B-rep. We also construct a transformer-based autoregressive model that learns the distribution over holistic token sequences via next-token prediction, using a multi-layer decoder-only architecture with causal masking. Experiments demonstrate that BrepARG achieves state-of-the-art (SOTA) performance. BrepARG validates the feasibility of representing B-rep as holistic token sequences, opening new directions for B-rep generation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16771v1</guid></item><item><title>[cs updates on arXiv.org] CASP: Few-Shot Class-Incremental Learning with CLS Token Attention Steering Prompts</title><link>https://arxiv.org/abs/2601.16773</link><description>arXiv:2601.16773v1 Announce Type: new 
Abstract: Few-shot class-incremental learning (FSCIL) presents a core challenge in continual learning, requiring models to rapidly adapt to new classes with very limited samples while mitigating catastrophic forgetting. Recent prompt-based methods, which integrate pretrained backbones with task-specific prompts, have made notable progress. However, under extreme few-shot incremental settings, the model's ability to transfer and generalize becomes critical, and it is thus essential to leverage pretrained knowledge to learn feature representations that can be shared across future categories during the base session. Inspired by the mechanism of the CLS token, which is similar to human attention and progressively filters out task-irrelevant information, we propose the CLS Token Attention Steering Prompts (CASP). This approach introduces class-shared trainable bias parameters into the query, key, and value projections of the CLS token to explicitly modulate the self-attention weights. To further enhance generalization, we also design an attention perturbation strategy and perform Manifold Token Mixup in the shallow feature space, synthesizing potential new class features to improve generalization and reserve the representation capacity for upcoming tasks. Experiments on the CUB200, CIFAR100, and ImageNet-R datasets demonstrate that CASP outperforms state-of-the-art methods in both standard and fine-grained FSCIL settings without requiring fine-tuning during incremental phases and while significantly reducing the parameter overhead.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16773v1</guid></item><item><title>[cs updates on arXiv.org] E2E-AEC: Implementing an end-to-end neural network learning approach for acoustic echo cancellation</title><link>https://arxiv.org/abs/2601.16774</link><description>arXiv:2601.16774v1 Announce Type: new 
Abstract: We propose a novel neural network-based end-to-end acoustic echo cancellation (E2E-AEC) method capable of streaming inference, which operates effectively without reliance on traditional linear AEC (LAEC) techniques and time delay estimation. Our approach includes several key strategies: First, we introduce and refine progressive learning to gradually enhance echo suppression. Second, our model employs knowledge transfer by initializing with a pre-trained LAECbased model, harnessing the insights gained from LAEC training. Third, we optimize the attention mechanism with a loss function applied on attention weights to achieve precise time alignment between the reference and microphone signals. Lastly, we incorporate voice activity detection to enhance speech quality and improve echo removal by masking the network output when near-end speech is absent. The effectiveness of our approach is validated through experiments conducted on public datasets.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16774v1</guid></item><item><title>[cs updates on arXiv.org] LLM-powered Real-time Patent Citation Recommendation for Financial Technologies</title><link>https://arxiv.org/abs/2601.16775</link><description>arXiv:2601.16775v1 Announce Type: new 
Abstract: Rapid financial innovation has been accompanied by a sharp increase in patenting activity, making timely and comprehensive prior-art discovery more difficult. This problem is especially evident in financial technologies, where innovations develop quickly, patent collections grow continuously, and citation recommendation systems must be updated as new applications arrive. Existing patent retrieval and citation recommendation methods typically rely on static indexes or periodic retraining, which limits their ability to operate effectively in such dynamic settings. In this study, we propose a real-time patent citation recommendation framework designed for large and fast-changing financial patent corpora. Using a dataset of 428,843 financial patents granted by the China National Intellectual Property Administration (CNIPA) between 2000 and 2024, we build a three-stage recommendation pipeline. The pipeline uses large language model (LLM) embeddings to represent the semantic content of patent abstracts, applies efficient approximate nearest-neighbor search to construct a manageable candidate set, and ranks candidates by semantic similarity to produce top-k citation recommendations. In addition to improving recommendation accuracy, the proposed framework directly addresses the dynamic nature of patent systems. By using an incremental indexing strategy based on hierarchical navigable small-world (HNSW) graphs, newly issued patents can be added without rebuilding the entire index. A rolling day-by-day update experiment shows that incremental updating improves recall while substantially reducing computational cost compared with rebuild-based indexing. The proposed method also consistently outperforms traditional text-based baselines and alternative nearest-neighbor retrieval approaches.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16775v1</guid></item><item><title>[cs updates on arXiv.org] GTA: Generative Traffic Agents for Simulating Realistic Mobility Behavior</title><link>https://arxiv.org/abs/2601.16778</link><description>arXiv:2601.16778v1 Announce Type: new 
Abstract: People's transportation choices reflect complex trade-offs shaped by personal preferences, social norms, and technology acceptance. Predicting such behavior at scale is a critical challenge with major implications for urban planning and sustainable transport. Traditional methods use handcrafted assumptions and costly data collection, making them impractical for early-stage evaluations of new technologies or policies. We introduce Generative Traffic Agents (GTA) for simulating large-scale, context-sensitive transportation choices using LLM-powered, persona-based agents. GTA generates artificial populations from census-based sociodemographic data. It simulates activity schedules and mode choices, enabling scalable, human-like simulations without handcrafted rules. We evaluate GTA in Berlin-scale experiments, comparing simulation results against empirical data. While agents replicate patterns, such as modal split by socioeconomic status, they show systematic biases in trip length and mode preference. GTA offers new opportunities for modeling how future innovations, from bike lanes to transit apps, shape mobility decisions.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16778v1</guid></item><item><title>[cs updates on arXiv.org] Persuasion Tokens for Editing Factual Knowledge in LLMs</title><link>https://arxiv.org/abs/2601.16781</link><description>arXiv:2601.16781v1 Announce Type: new 
Abstract: In-context knowledge editing (IKE) is a promising technique for updating Large Language Models (LLMs) with new information. However, IKE relies on lengthy, fact-specific demonstrations which are costly to create and consume significant context window space. In this paper, we introduce persuasion tokens (P-Tokens) -- special tokens trained to replicate the effect of IKE demonstrations, enabling efficient knowledge editing without requiring fact-specific demonstrations. We evaluate P-Tokens across two editing datasets and three LLMs, demonstrating performance comparable to, and often exceeding, IKE. We further find that editing performance is robust to distractors with small negative effects to neighboring facts, and that increasing the number of P-Tokens improves performance. Our work addresses key limitations of IKE and provides a more practical and scalable alternative for editing LLMs.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16781v1</guid></item><item><title>[cs updates on arXiv.org] SLD: Segmentation-Based Landmark Detection for Spinal Ligaments</title><link>https://arxiv.org/abs/2601.16782</link><description>arXiv:2601.16782v1 Announce Type: new 
Abstract: In biomechanical modeling, the representation of ligament attachments is crucial for a realistic simulation of the forces acting between the vertebrae. These forces are typically modeled as vectors connecting ligament landmarks on adjacent vertebrae, making precise identification of these landmarks a key requirement for constructing reliable spine models. Existing automated detection methods are either limited to specific spinal regions or lack sufficient accuracy. This work presents a novel approach for detecting spinal ligament landmarks, which first performs shape-based segmentation of 3D vertebrae and subsequently applies domain-specific rules to identify different types of attachment points. The proposed method outperforms existing approaches by achieving high accuracy and demonstrating strong generalization across all spinal regions. Validation on two independent spinal datasets from multiple patients yielded a mean absolute error (MAE) of 0.7 mm and a root mean square error (RMSE) of 1.1 mm.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16782v1</guid></item><item><title>[cs updates on arXiv.org] REL-SF4PASS: Panoramic Semantic Segmentation with REL Depth Representation and Spherical Fusion</title><link>https://arxiv.org/abs/2601.16788</link><description>arXiv:2601.16788v1 Announce Type: new 
Abstract: As an important and challenging problem in computer vision, Panoramic Semantic Segmentation (PASS) aims to give complete scene perception based on an ultra-wide angle of view. Most PASS methods often focus on spherical geometry with RGB input or using the depth information in original or HHA format, which does not make full use of panoramic image geometry. To address these shortcomings, we propose REL-SF4PASS with our REL depth representation based on cylindrical coordinate and Spherical-dynamic Multi-Modal Fusion SMMF. REL is made up of Rectified Depth, Elevation-Gained Vertical Inclination Angle, and Lateral Orientation Angle, which fully represents 3D space in cylindrical coordinate style and the surface normal direction. SMMF aims to ensure the diversity of fusion for different panoramic image regions and reduce the breakage of cylinder side surface expansion in ERP projection, which uses different fusion strategies to match the different regions in panoramic images. Experimental results show that REL-SF4PASS considerably improves performance and robustness on popular benchmark, Stanford2D3D Panoramic datasets. It gains 2.35% average mIoU improvement on all 3 folds and reduces the performance variance by approximately 70% when facing 3D disturbance.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16788v1</guid></item><item><title>[cs updates on arXiv.org] A Novel Transfer Learning Approach for Mental Stability Classification from Voice Signal</title><link>https://arxiv.org/abs/2601.16793</link><description>arXiv:2601.16793v1 Announce Type: new 
Abstract: This study presents a novel transfer learning approach and data augmentation technique for mental stability classification using human voice signals and addresses the challenges associated with limited data availability. Convolutional neural networks (CNNs) have been employed to analyse spectrogram images generated from voice recordings. Three CNN architectures, VGG16, InceptionV3, and DenseNet121, were evaluated across three experimental phases: training on non-augmented data, augmented data, and transfer learning. This proposed transfer learning approach involves pre-training models on the augmented dataset and fine-tuning them on the non-augmented dataset while ensuring strict data separation to prevent data leakage. The results demonstrate significant improvements in classification performance compared to the baseline approach. Among three CNN architectures, DenseNet121 achieved the highest accuracy of 94% and an AUC score of 99% using the proposed transfer learning approach. This finding highlights the effectiveness of combining data augmentation and transfer learning to enhance CNN-based classification of mental stability using voice spectrograms, offering a promising non-invasive tool for mental health diagnostics.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16793v1</guid></item><item><title>[cs updates on arXiv.org] Building a Robust Risk-Based Access Control System to Combat Ransomware's Capability to Encrypt: A Machine Learning Approach</title><link>https://arxiv.org/abs/2601.16795</link><description>arXiv:2601.16795v1 Announce Type: new 
Abstract: Ransomware core capability, unauthorized encryption, demands controls that identify and block malicious cryptographic activity without disrupting legitimate use. We present a probabilistic, risk-based access control architecture that couples machine learning inference with mandatory access control to regulate encryption on Linux in real time. The system builds a specialized dataset from the native ftrace framework using the function_graph tracer, yielding high-resolution kernel-function execution traces augmented with resource and I/O counters. These traces support both a supervised classifier and interpretable rules that drive an SELinux policy via lightweight booleans, enabling context-sensitive permit/deny decisions at the moment encryption begins. Compared to approaches centered on sandboxing, hypervisor introspection, or coarse system-call telemetry, the function-level tracing we adopt provides finer behavioral granularity than syscall-only telemetry while avoiding the virtualization/VMI overhead of sandbox-based approaches. Our current user-space prototype has a non-trivial footprint under burst I/O; we quantify it and recognize that a production kernel-space solution should aim to address this. We detail dataset construction, model training and rule extraction, and the run-time integration that gates file writes for suspect encryption while preserving benign cryptographic workflows. During evaluation, the two-layer composition retains model-level detection quality while delivering rule-like responsiveness; we also quantify operational footprint and outline engineering steps to reduce CPU and memory overhead for enterprise deployment. The result is a practical path from behavioral tracing and learning to enforceable, explainable, and risk-proportionate encryption control on production Linux systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16795v1</guid></item><item><title>[cs updates on arXiv.org] Adaptive Beam Alignment using Noisy Twenty Questions Estimation with Trained Questioner</title><link>https://arxiv.org/abs/2601.16799</link><description>arXiv:2601.16799v1 Announce Type: new 
Abstract: The 6G communication systems use mmWave and MIMO technologies to achieve wide bandwidth and high throughout, leading to indispensable need for beam alignment to overcome severe signal attenuation. Traditional sector-search-based beam alignment algorithms rely on sequential sampling to identify the best sector, resulting in a significant latency burden on 6G communication systems. Recently proposed adaptive beam alignment algorithms based on the active learning framework address the problem, aiming to identify the optimal sector with the fewest possible samples under an identical sector partition. Nevertheless, these algorithms either lack feasibility (Chiu, Ronquillo and Javidi, JSAC 2019) due to ideal assumptions or lack interpretability (Sohrabi, Chen and Yu, JSAC 2021) due to the use of end-to-end black-box neural networks. To avoid ideal assumptions and maintain interpretability, we address all above problems by proposing an adaptive beam alignment algorithm using the framework of noisy twenty questions estimation with a trained questioner. Specifically, we use two methods for training the questioner to eliminate reliance on ideal assumptions. The first method maps queries of twenty questions estimation to beamforming vectors via weighted summation of steering vectors, as an initial attempt to address the feasibility problem encountered in prior pioneering study by Chiu, Ronquillo and Javidi (JSAC 2019). The second method uses multi-layer fully connected neural networks to achieve improved performance while only employing them to train the questioner, which can effectively mitigate the interpretability issues in prior study by Sohrabi, Chen and Yu (JSAC 2021). Furthermore, we provide numerical simulations to illustrate the effectiveness of our proposed adaptive beam alignment algorithms and demonstrate that our algorithms outperform all benchmark algorithms.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16799v1</guid></item><item><title>[cs updates on arXiv.org] Large Language Models as Automatic Annotators and Annotation Adjudicators for Fine-Grained Opinion Analysis</title><link>https://arxiv.org/abs/2601.16800</link><description>arXiv:2601.16800v1 Announce Type: new 
Abstract: Fine-grained opinion analysis of text provides a detailed understanding of expressed sentiments, including the addressed entity. Although this level of detail is sound, it requires considerable human effort and substantial cost to annotate opinions in datasets for training models, especially across diverse domains and real-world applications. We explore the feasibility of LLMs as automatic annotators for fine-grained opinion analysis, addressing the shortage of domain-specific labelled datasets. In this work, we use a declarative annotation pipeline. This approach reduces the variability of manual prompt engineering when using LLMs to identify fine-grained opinion spans in text. We also present a novel methodology for an LLM to adjudicate multiple labels and produce final annotations. After trialling the pipeline with models of different sizes for the Aspect Sentiment Triplet Extraction (ASTE) and Aspect-Category-Opinion-Sentiment (ACOS) analysis tasks, we show that LLMs can serve as automatic annotators and adjudicators, achieving high Inter-Annotator Agreement across individual LLM-based annotators. This reduces the cost and human effort needed to create these fine-grained opinion-annotated datasets.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16800v1</guid></item><item><title>[cs updates on arXiv.org] SoS: Analysis of Surface over Semantics in Multilingual Text-To-Image Generation</title><link>https://arxiv.org/abs/2601.16803</link><description>arXiv:2601.16803v1 Announce Type: new 
Abstract: Text-to-image (T2I) models are increasingly employed by users worldwide. However, prior research has pointed to the high sensitivity of T2I towards particular input languages - when faced with languages other than English (i.e., different surface forms of the same prompt), T2I models often produce culturally stereotypical depictions, prioritizing the surface over the prompt's semantics. Yet a comprehensive analysis of this behavior, which we dub Surface-over-Semantics (SoS), is missing. We present the first analysis of T2I models' SoS tendencies. To this end, we create a set of prompts covering 171 cultural identities, translated into 14 languages, and use it to prompt seven T2I models. To quantify SoS tendencies across models, languages, and cultures, we introduce a novel measure and analyze how the tendencies we identify manifest visually. We show that all but one model exhibit strong surface-level tendency in at least two languages, with this effect intensifying across the layers of T2I text encoders. Moreover, these surface tendencies frequently correlate with stereotypical visual depictions.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16803v1</guid></item><item><title>[cs updates on arXiv.org] Will It Survive? Deciphering the Fate of AI-Generated Code in Open Source</title><link>https://arxiv.org/abs/2601.16809</link><description>arXiv:2601.16809v1 Announce Type: new 
Abstract: The integration of AI agents as coding assistants into software development has raised questions about the long-term viability of AI agent-generated code. A prevailing hypothesis within the software engineering community suggests this code is "disposable", meaning it is merged quickly but discarded shortly thereafter. If true, organizations risk shifting maintenance burden from generation to post-deployment remediation. We investigate this hypothesis through survival analysis of 201 open-source projects, tracking over 200,000 code units authored by AI agents versus humans. Contrary to the disposable code narrative, agent-authored code survives significantly longer: at the line level, it exhibits a 15.8 percentage-point lower modification rate and 16% lower hazard of modification (HR = 0.842, p &lt; 0.001). However, modification profiles differ. Agent-authored code shows modestly elevated corrective rates (26.3% vs. 23.0%), while human code shows higher adaptive rates. However, the effect sizes are small (Cram\'er's V = 0.116), and per-agent variation exceeds the agent-human gap. Turning to prediction, textual features can identify modification-prone code (AUC-ROC = 0.671), but predicting when modifications occur remains challenging (Macro F1 = 0.285), suggesting timing depends on external organizational dynamics. The bottleneck for agent-generated code may not be generation quality, but the organizational practices that govern its long-term evolution.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16809v1</guid></item><item><title>[cs updates on arXiv.org] Incorporating Eye-Tracking Signals Into Multimodal Deep Visual Models For Predicting User Aesthetic Experience In Residential Interiors</title><link>https://arxiv.org/abs/2601.16811</link><description>arXiv:2601.16811v1 Announce Type: new 
Abstract: Understanding how people perceive and evaluate interior spaces is essential for designing environments that promote well-being. However, predicting aesthetic experiences remains difficult due to the subjective nature of perception and the complexity of visual responses. This study introduces a dual-branch CNN-LSTM framework that fuses visual features with eye-tracking signals to predict aesthetic evaluations of residential interiors. We collected a dataset of 224 interior design videos paired with synchronized gaze data from 28 participants who rated 15 aesthetic dimensions. The proposed model attains 72.2% accuracy on objective dimensions (e.g., light) and 66.8% on subjective dimensions (e.g., relaxation), outperforming state-of-the-art video baselines and showing clear gains on subjective evaluation tasks. Notably, models trained with eye-tracking retain comparable performance when deployed with visual input alone. Ablation experiments further reveal that pupil responses contribute most to objective assessments, while the combination of gaze and visual cues enhances subjective evaluations. These findings highlight the value of incorporating eye-tracking as privileged information during training, enabling more practical tools for aesthetic assessment in interior design.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16811v1</guid></item><item><title>[cs updates on arXiv.org] Sample-wise Constrained Learning via a Sequential Penalty Approach with Applications in Image Processing</title><link>https://arxiv.org/abs/2601.16812</link><description>arXiv:2601.16812v1 Announce Type: new 
Abstract: In many learning tasks, certain requirements on the processing of individual data samples should arguably be formalized as strict constraints in the underlying optimization problem, rather than by means of arbitrary penalties. We show that, in these scenarios, learning can be carried out exploiting a sequential penalty method that allows to properly deal with constraints. The proposed algorithm is shown to possess convergence guarantees under assumptions that are reasonable in deep learning scenarios. Moreover, the results of experiments on image processing tasks show that the method is indeed viable to be used in practice.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16812v1</guid></item><item><title>[cs updates on arXiv.org] PI2I: A Personalized Item-Based Collaborative Filtering Retrieval Framework</title><link>https://arxiv.org/abs/2601.16815</link><description>arXiv:2601.16815v1 Announce Type: new 
Abstract: Efficiently selecting relevant content from vast candidate pools is a critical challenge in modern recommender systems. Traditional methods, such as item-to-item collaborative filtering (CF) and two-tower models, often fall short in capturing the complex user-item interactions due to uniform truncation strategies and overdue user-item crossing. To address these limitations, we propose Personalized Item-to-Item (PI2I), a novel two-stage retrieval framework that enhances the personalization capabilities of CF. In the first Indexer Building Stage (IBS), we optimize the retrieval pool by relaxing truncation thresholds to maximize Hit Rate, thereby temporarily retaining more items users might be interested in. In the second Personalized Retrieval Stage (PRS), we introduce an interactive scoring model to overcome the limitations of inner product calculations, allowing for richer modeling of intricate user-item interactions. Additionally, we construct negative samples based on the trigger-target (item-to-item) relationship, ensuring consistency between offline training and online inference. Offline experiments on large-scale real-world datasets demonstrate that PI2I outperforms traditional CF methods and rivals Two-Tower models. Deployed in the "Guess You Like" section on Taobao, PI2I achieved a 1.05% increase in online transaction rates. In addition, we have released a large-scale recommendation dataset collected from Taobao, containing 130 million real-world user interactions used in the experiments of this paper. The dataset is publicly available at https://huggingface.co/datasets/PI2I/PI2I, which could serve as a valuable benchmark for the research community.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16815v1</guid></item><item><title>[cs updates on arXiv.org] Discrete FEM-BEM coupling with the Generalized Optimized Schwarz Method</title><link>https://arxiv.org/abs/2601.16817</link><description>arXiv:2601.16817v1 Announce Type: new 
Abstract: The present contribution aims at developing a non-overlapping Domain Decomposition (DD) approach to the solution of acoustic wave propagation boundary value problems based on the Helmholtz equation, on both bounded and unbounded domains. This DD solver, called Generalized Optimized Schwarz Method (GOSM), is a substructuring method, that is, the unknowns of an iteration are associated with the subdomains interfaces. We extend the analysis presented in a previous paper of one of the author to a fully discrete setting. We do not consider only a specific set of boundary conditions, but a whole class including, e.g., Dirichlet, Neumann, and Robin conditions. Our analysis will also cover interface conditions corresponding to a Finite Element Method - Boundary Element Method (FEM-BEM) coupling. In particular, we shall focus on three classical FEM-BEM couplings, namely the Costabel, Johnson-N\'ed\'elec and Bielak-MacCamy couplings. As a remarkable outcome, the present contribution yields well-posed substructured formulations of these classical FEM-BEM couplings for wavenumbers different from classical spurious resonances. We also establish an explicit relation between the dimensions of the kernels of the initial variational formulation, the local problems and the substructured formulation. That relation especially holds for any wavenumber for the substructured formulation of Costabel FEM-BEM coupling, which allows us to prove that the latter formulation is well-posed even at spurious resonances. Besides, we introduce a systematically geometrically convergent iterative method for the Costabel FEM-BEM coupling, with estimates on the convergence speed.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16817v1</guid></item><item><title>[cs updates on arXiv.org] Trapped in the past? Disentangling fluid and crystallized intelligence of large language models using chess</title><link>https://arxiv.org/abs/2601.16823</link><description>arXiv:2601.16823v1 Announce Type: new 
Abstract: Large Language Models (LLMs) exhibit remarkable capabilities, yet it remains unclear to what extent these reflect sophisticated recall (crystallized intelligence) or reasoning ability (fluid intelligence). We introduce chess as a controlled testbed for disentangling these faculties. Leveraging the game's structure and scalable engine evaluations, we construct a taxonomy of positions varying in training corpus proximity--ranging from common states solvable by memorization to novel ones requiring first-principles reasoning. We systematically evaluate multiple GPT generations under varying reasoning intensities. Our analysis reveals a clear gradient: performance consistently degrades as fluid intelligence demands increase. Notably, in out-of-distribution tasks, performance collapses to random levels. While newer models improve, progress slows significantly for tasks outside the training distribution. Furthermore, while reasoning-augmented inference improves performance, its marginal benefit per token decreases with distributional proximity. These results suggest current architectures remain limited in systematic generalization, highlighting the need for mechanisms beyond scale to achieve robust fluid intelligence.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16823v1</guid></item><item><title>[cs updates on arXiv.org] Privacy in Human-AI Romantic Relationships: Concerns, Boundaries, and Agency</title><link>https://arxiv.org/abs/2601.16824</link><description>arXiv:2601.16824v1 Announce Type: new 
Abstract: An increasing number of LLM-based applications are being developed to facilitate romantic relationships with AI partners, yet the safety and privacy risks in these partnerships remain largely underexplored. In this work, we investigate privacy in human-AI romantic relationships through an interview study (N=17), examining participants' experiences and privacy perceptions across stages of exploration, intimacy, and dissolution, alongside platforms they used. We found that these relationships took varied forms, from one-to-one to one-to-many, and were shaped by multiple actors, including creators, platforms, and moderators. AI partners were perceived as having agency, actively negotiating privacy boundaries with participants and sometimes encouraging disclosure of personal details. As intimacy deepened, these boundaries became more permeable, though some participants voiced concerns such as conversation exposure and sought to preserve anonymity. Overall, platform affordances and diverse romantic dynamics expand the privacy landscape, underscoring the need to rethink how privacy is constructed in human-AI intimacy.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16824v1</guid></item><item><title>[cs updates on arXiv.org] Privacy-Resolution Tradeoff for Adaptive Noisy Twenty Questions Estimation</title><link>https://arxiv.org/abs/2601.16825</link><description>arXiv:2601.16825v1 Announce Type: new 
Abstract: We revisit noisy twenty questions estimation and study the privacy-resolution tradeoff for adaptive query procedures. Specifically, in twenty questions estimation, there are two players: an oracle and a questioner. The questioner aims to estimate target variables by posing queries to the oracle that knows the variables and using noisy responses to form reliable estimates. Typically, there are adaptive and non-adaptive query procedures. In adaptive querying, one designs the current query using previous queries and their noisy responses while in non-adaptive querying, all queries are posed simultaneously. Generally speaking, adaptive query procedures yield better performance. However, adaptive querying leads to privacy concerns, which were first studied by Tsitsiklis, Xu and Xu (COLT 2018) and by Xu, Xu and Yang (AISTATS 2021) for the noiseless case, where the oracle always provides correct answers to queries. In this paper, we generalize the above results to the more practical noisy case, by proposing a two-stage private query procedure, analyzing its non-asymptotic and second-order asymptotic achievable performance and discussing the impact of privacy concerns. Furthermore, when specialized to the noiseless case, our private query procedure achieves better performance than above-mentioned query procedures (COLT 2018, AISTATS 2021).</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16825v1</guid></item><item><title>[cs updates on arXiv.org] Identification of Port-Hamiltonian Differential-Algebraic Equations from Input-Output Data</title><link>https://arxiv.org/abs/2601.16827</link><description>arXiv:2601.16827v1 Announce Type: new 
Abstract: Many models of physical systems, such as mechanical and electrical networks, exhibit algebraic constraints that arise from subsystem interconnections and underlying physical laws. Such systems are commonly formulated as differential-algebraic equations (DAEs), which describe both the dynamic evolution of system states and the algebraic relations that must hold among them. Within this class, port-Hamiltonian differential-algebraic equations (pH-DAEs) offer a structured, energy-based representation that preserves interconnection and passivity properties. This work introduces a data-driven identification method that combines port-Hamiltonian neural networks (pHNNs) with a differential-algebraic solver to model such constrained systems directly from noisy input-output data. The approach preserves the passivity and interconnection structure of port-Hamiltonian systems while employing a backward Euler discretization with Newton's method to solve the coupled differential and algebraic equations consistently. The performance of the proposed approach is demonstrated on a DC power network, where the identified model accurately captures system behaviour and maintains errors proportional to the noise amplitude, while providing reliable parameter estimates.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16827v1</guid></item><item><title>[cs updates on arXiv.org] Calibrated Probabilistic Interpolation for GEDI Biomass</title><link>https://arxiv.org/abs/2601.16834</link><description>arXiv:2601.16834v1 Announce Type: new 
Abstract: Reliable wall-to-wall biomass mapping from NASA's GEDI mission requires interpolating sparse LiDAR observations across heterogeneous landscapes. While machine learning approaches like Random Forest and XGBoost are standard for this task, they treat spatial predictions of GEDI observations from multispectral or SAR remote sensing data as independent without adapting to the varying difficulty of heterogeneous landscapes. We demonstrate these approaches generally fail to produce calibrated prediction intervals. We identify that this stems from conflating ensemble variance with aleatoric uncertainty and ignoring local spatial context.
  To resolve this, we introduce Attentive Neural Processes (ANPs), a probabilistic meta-learning framework that explicitly conditions predictions on local observation sets and geospatial foundation model embeddings. Unlike static ensembles, ANPs learn a flexible spatial covariance function, allowing uncertainty estimates to expand in complex landscapes and contract in homogeneous areas. We validate this approach across five distinct biomes ranging from Tropical Amazonian forests to Boreal and Alpine ecosystems, demonstrating that ANPs achieve competitive accuracy while maintaining near-ideal uncertainty calibration. We demonstrate the operational utility of the method through few-shot adaptation, where the model recovers most of the performance gap in cross-region transfer using minimal local data. This work provides a scalable, theoretically rigorous alternative to ensemble variance for continental scale earth observation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16834v1</guid></item><item><title>[cs updates on arXiv.org] Multi-Agent Non-Discriminatory Contracts</title><link>https://arxiv.org/abs/2601.16835</link><description>arXiv:2601.16835v1 Announce Type: new 
Abstract: We study multi-agent contracts, in which a principal delegates a task to multiple agents and incentivizes them to exert effort. Prior research has mostly focused on maximizing the principal's utility, often resulting in highly disparate payments among agents. Such disparities among agents may be undesirable in practice, for example, in standardized public contracting or worker cooperatives where fairness concerns are essential. Motivated by these considerations, our objective is to quantify the tradeoff between maximizing the principal's utility and equalizing payments among agents, which we call the price of non-discrimination. Our first result is an almost tight bound on the price of non-discrimination, which scales logarithmically with the number of agents. This bound can be improved to a constant by allowing some relaxation of the non-discrimination requirement. We then provide a comprehensive characterization of the tradeoff between the level of non-discrimination and the loss in the optimal utility.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16835v1</guid></item><item><title>[cs updates on arXiv.org] ColorConceptBench: A Benchmark for Probabilistic Color-Concept Understanding in Text-to-Image Models</title><link>https://arxiv.org/abs/2601.16836</link><description>arXiv:2601.16836v1 Announce Type: new 
Abstract: While text-to-image (T2I) models have advanced considerably, their capability to associate colors with implicit concepts remains underexplored. To address the gap, we introduce ColorConceptBench, a new human-annotated benchmark to systematically evaluate color-concept associations through the lens of probabilistic color distributions. ColorConceptBench moves beyond explicit color names or codes by probing how models translate 1,281 implicit color concepts using a foundation of 6,369 human annotations. Our evaluation of seven leading T2I models reveals that current models lack sensitivity to abstract semantics, and crucially, this limitation appears resistant to standard interventions (e.g., scaling and guidance). This demonstrates that achieving human-like color semantics requires more than larger models, but demands a fundamental shift in how models learn and represent implicit meaning.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16836v1</guid></item><item><title>[cs updates on arXiv.org] AI builds, We Analyze: An Empirical Study of AI-Generated Build Code Quality</title><link>https://arxiv.org/abs/2601.16839</link><description>arXiv:2601.16839v1 Announce Type: new 
Abstract: The rapid adoption of AI coding agents for software development has raised important questions about the quality and maintainability of the code they produce. While prior studies have examined AI-generated source code, the impact of AI coding agents on build systems-a critical yet understudied component of the software lifecycle-remains largely unexplored. This data mining challenge focuses on AIDev, the first large-scale, openly available dataset capturing agent-authored pull requests (Agentic-PRs) from real-world GitHub repositories. Our paper leverages this dataset to investigate (RQ1) whether AI coding agents generate build code with quality issues (e.g., code smells), (RQ2) to what extent AI agents can eliminate code smells from build code, and (RQ3) to what extent Agentic-PRs are accepted by developers. We identified 364 maintainability and security-related build smells across varying severity levels, indicating that AI-generated build code can introduce quality issues-such as lack of error handling, and hardcoded paths or URLs-while also, in some cases, removing existing smells through refactorings (e.g., Pull Up Module and Externalize Properties). Notably, more than 61\% of Agentic-PRs are approved and merged with minimal human intervention. This dual impact underscores the need for future research on AI-aware build code quality assessment to systematically evaluate, guide, and govern AI-generated build systems code.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16839v1</guid></item><item><title>[cs updates on arXiv.org] Information Contraction under $(\varepsilon,\delta)$-Differentially Private Mechanisms</title><link>https://arxiv.org/abs/2601.16845</link><description>arXiv:2601.16845v1 Announce Type: new 
Abstract: The distinguishability quantified by information measures after being processed by a private mechanism has been a useful tool in studying various statistical and operational tasks while ensuring privacy. To this end, standard data-processing inequalities and strong data-processing inequalities (SDPI) are employed. Most of the previously known and even tight characterizations of contraction of information measures, including total variation distance, hockey-stick divergences, and $f$-divergences, are applicable for $(\varepsilon,0)$-local differential private (LDP) mechanisms. In this work, we derive both linear and non-linear strong data-processing inequalities for hockey-stick divergence and $f$-divergences that are valid for all $(\varepsilon,\delta)$-LDP mechanisms even when $\delta \neq 0$. Our results either generalize or improve the previously known bounds on the contraction of these distinguishability measures.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16845v1</guid></item><item><title>[cs updates on arXiv.org] The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics</title><link>https://arxiv.org/abs/2601.16849</link><description>arXiv:2601.16849v1 Announce Type: new 
Abstract: We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. Specifically, we target the generation of adversarial instances where these heuristics perform poorly. By iterating on FunSearch's outputs, we identify improved constructions for hierarchical $k$-median clustering, bin packing, the knapsack problem, and a generalization of Lov\'asz's gasoline problem - some of these have not seen much improvement for over a decade, despite intermittent attention. These results illustrate how expert oversight can effectively extrapolate algorithmic insights from LLM-based evolutionary methods to break long-standing barriers.
  Our findings demonstrate that while LLMs provide critical initial patterns, human expertise is essential for transforming these patterns into mathematically rigorous and insightful constructions. This work highlights that LLMs are a strong collaborative tool in mathematics and computer science research.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16849v1</guid></item><item><title>[cs updates on arXiv.org] Reasoning Promotes Robustness in Theory of Mind Tasks</title><link>https://arxiv.org/abs/2601.16853</link><description>arXiv:2601.16853v1 Announce Type: new 
Abstract: Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16853v1</guid></item><item><title>[cs updates on arXiv.org] Orbitopal Fixing in SAT</title><link>https://arxiv.org/abs/2601.16855</link><description>arXiv:2601.16855v1 Announce Type: new 
Abstract: Despite their sophisticated heuristics, boolean satisfiability (SAT) solvers are still vulnerable to symmetry, causing them to visit search regions that are symmetric to ones already explored. While symmetry handling is routine in other solving paradigms, integrating it into state-of-the-art proof-producing SAT solvers is difficult: added reasoning must be fast, non-interfering with solver heuristics, and compatible with formal proof logging. To address these issues, we present a practical static symmetry breaking approach based on orbitopal fixing, a technique adapted from mixed-integer programming. Our approach adds only unit clauses, which minimizes downstream slowdowns, and it emits succinct proof certificates in the substitution redundancy proof system. Implemented in the satsuma tool, our methods deliver consistent speedups on symmetry-rich benchmarks with negligible regressions elsewhere.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16855v1</guid></item><item><title>[cs updates on arXiv.org] Perfect Privacy and Strong Stationary Times for Markovian Sources</title><link>https://arxiv.org/abs/2601.16857</link><description>arXiv:2601.16857v1 Announce Type: new 
Abstract: We consider the problem of sharing correlated data under a perfect information-theoretic privacy constraint. We focus on redaction (erasure) mechanisms, in which data are either withheld or released unchanged, and measure utility by the average cardinality of the released set, equivalently, the expected Hamming distortion. Assuming the data are generated by a finite time-homogeneous Markov chain, we study the protection of the initial state while maximizing the amount of shared data. We establish a connection between perfect privacy and window-based redaction schemes, showing that erasing data up to a strong stationary time preserves privacy under suitable conditions. We further study an optimal sequential redaction mechanism and prove that it admits an equivalent window interpretation. Interestingly, we show that both mechanisms achieve the optimal distortion while redacting only a constant average number of data points, independent of the data length~$N$.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16857v1</guid></item><item><title>[cs updates on arXiv.org] Navigating the Shift: A Comparative Analysis of Web Search and Generative AI Response Generation</title><link>https://arxiv.org/abs/2601.16858</link><description>arXiv:2601.16858v1 Announce Type: new 
Abstract: The rise of generative AI as a primary information source presents a paradigm shift from traditional web search. This paper presents a large-scale empirical study quantifying the fundamental differences between the results returned by Google Search and leading generative AI services. We analyze multiple dimensions, demonstrating that AI-generated answers and web search results diverge significantly in their consulted source domains, the typology of these domains (e.g., earned media vs. owned, social), query intent and the freshness of the information provided. We then investigate the role of LLM pre-training as a key factor shaping these differences, analyzing how this intrinsic knowledge base interacts with and influences real-time web search when enabled. Our findings reveal the distinct mechanics of these two information ecosystems, leading to critical observations on the emergent field of Answer Engine Optimization (AEO) and its contrast with traditional Search Engine Optimization (SEO).</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16858v1</guid></item><item><title>[cs updates on arXiv.org] Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation</title><link>https://arxiv.org/abs/2601.16863</link><description>arXiv:2601.16863v1 Announce Type: new 
Abstract: This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a variation of the Knapsack Problem, binding heterogeneous checkpoints to functional roles based on live telemetry and cost constraints. At the execution layer, we formalize deliberation as a Macro-Scale Recurrent Neural Network (RNN), where the consensus state loops back through a semantic forget gate to enable iterative refinement without proportional VRAM scaling. Key components include an orchestration fabric for trustless N-to-N peer review, a Quadratic Voting activation function for non-linear consensus, and a feedback-driven state update. Empirical validation on challenging benchmarks (AIME 2025, LiveCodeBench) demonstrates that this topology allows ensembles of small (less than 20B) consumer-grade models to match or exceed the performance of state-of-the-art 100B+ parameter models, establishing a new hardware arbitrage efficiency frontier. Furthermore, testing on the DarkBench safety suite reveals intrinsic alignment properties, with peer-mediated correction reducing sycophancy scores below that of any individual agent.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16863v1</guid></item><item><title>[cs updates on arXiv.org] Boosting Deep Reinforcement Learning with Semantic Knowledge for Robotic Manipulators</title><link>https://arxiv.org/abs/2601.16866</link><description>arXiv:2601.16866v1 Announce Type: new 
Abstract: Deep Reinforcement Learning (DRL) is a powerful framework for solving complex sequential decision-making problems, particularly in robotic control. However, its practical deployment is often hindered by the substantial amount of experience required for learning, which results in high computational and time costs. In this work, we propose a novel integration of DRL with semantic knowledge in the form of Knowledge Graph Embeddings (KGEs), aiming to enhance learning efficiency by providing contextual information to the agent. Our architecture combines KGEs with visual observations, enabling the agent to exploit environmental knowledge during training. Experimental validation with robotic manipulators in environments featuring both fixed and randomized target attributes demonstrates that our method achieves up to {60}{\%} reduction in learning time and improves task accuracy by approximately 15 percentage points, without increasing training time or computational complexity. These results highlight the potential of semantic knowledge to reduce sample complexity and improve the effectiveness of DRL in robotic applications.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16866v1</guid></item><item><title>[cs updates on arXiv.org] A Multimodal Data Collection Framework for Dialogue-Driven Assistive Robotics to Clarify Ambiguities: A Wizard-of-Oz Pilot Study</title><link>https://arxiv.org/abs/2601.16870</link><description>arXiv:2601.16870v1 Announce Type: new 
Abstract: Integrated control of wheelchairs and wheelchair-mounted robotic arms (WMRAs) has strong potential to increase independence for users with severe motor limitations, yet existing interfaces often lack the flexibility needed for intuitive assistive interaction. Although data-driven AI methods show promise, progress is limited by the lack of multimodal datasets that capture natural Human-Robot Interaction (HRI), particularly conversational ambiguity in dialogue-driven control. To address this gap, we propose a multimodal data collection framework that employs a dialogue-based interaction protocol and a two-room Wizard-of-Oz (WoZ) setup to simulate robot autonomy while eliciting natural user behavior. The framework records five synchronized modalities: RGB-D video, conversational audio, inertial measurement unit (IMU) signals, end-effector Cartesian pose, and whole-body joint states across five assistive tasks. Using this framework, we collected a pilot dataset of 53 trials from five participants and validated its quality through motion smoothness analysis and user feedback. The results show that the framework effectively captures diverse ambiguity types and supports natural dialogue-driven interaction, demonstrating its suitability for scaling to a larger dataset for learning, benchmarking, and evaluation of ambiguity-aware assistive control.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16870v1</guid></item><item><title>[cs updates on arXiv.org] From Atom to Community: Structured and Evolving Agent Memory for User Behavior Modeling</title><link>https://arxiv.org/abs/2601.16872</link><description>arXiv:2601.16872v1 Announce Type: new 
Abstract: User behavior modeling lies at the heart of personalized applications like recommender systems. With LLM-based agents, user preference representation has evolved from latent embeddings to semantic memory. While existing memory mechanisms show promise in textual dialogues, modeling non-textual behaviors remains challenging, as preferences must be inferred from implicit signals like clicks without ground truth supervision. Current approaches rely on a single unstructured summary, updated through simple overwriting. However, this is suboptimal: users exhibit multi-faceted interests that get conflated, preferences evolve yet naive overwriting causes forgetting, and sparse individual interactions necessitate collaborative signals. We present STEAM (\textit{\textbf{ST}ructured and \textbf{E}volving \textbf{A}gent \textbf{M}emory}), a novel framework that reimagines how agent memory is organized and updated. STEAM decomposes preferences into atomic memory units, each capturing a distinct interest dimension with explicit links to observed behaviors. To exploit collaborative patterns, STEAM organizes similar memories across users into communities and generates prototype memories for signal propagation. The framework further incorporates adaptive evolution mechanisms, including consolidation for refining memories and formation for capturing emerging interests. Experiments on three real-world datasets demonstrate that STEAM substantially outperforms state-of-the-art baselines in recommendation accuracy, simulation fidelity, and diversity.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16872v1</guid></item><item><title>[cs updates on arXiv.org] Provably Learning Attention with Queries</title><link>https://arxiv.org/abs/2601.16873</link><description>arXiv:2601.16873v1 Announce Type: new 
Abstract: We study the problem of learning Transformer-based sequence models with black-box access to their outputs. In this setting, a learner may adaptively query the oracle with any sequence of vectors and observe the corresponding real-valued output. We begin with the simplest case, a single-head softmax-attention regressor. We show that for a model with width $d$, there is an elementary algorithm to learn the parameters of single-head attention exactly with $O(d^2)$ queries. Further, we show that if there exists an algorithm to learn ReLU feedforward networks (FFNs), then the single-head algorithm can be easily adapted to learn one-layer Transformers with single-head attention. Next, motivated by the regime where the head dimension $r \ll d$, we provide a randomised algorithm that learns single-head attention-based models with $O(rd)$ queries via compressed sensing arguments. We also study robustness to noisy oracle access, proving that under mild norm and margin conditions, the parameters can be estimated to $\varepsilon$ accuracy with a polynomial number of queries even when outputs are only provided up to additive tolerance. Finally, we show that multi-head attention parameters are not identifiable from value queries in general -- distinct parameterisations can induce the same input-output map. Hence, guarantees analogous to the single-head setting are impossible without additional structural assumptions.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16873v1</guid></item><item><title>[cs updates on arXiv.org] No Validation, No Problem: Predicting Model Performance from a Single Gradient</title><link>https://arxiv.org/abs/2601.16874</link><description>arXiv:2601.16874v1 Announce Type: new 
Abstract: We propose a validation-free checkpointing signal from a single forward-backward pass: the Frobenius norm of the classifier-head gradient on one detached-feature batch, ||g||_F = ||dL/dW||_F. Across ImageNet-1k CNNs and Transformers, this proxy is strongly negative with Top-1 and positive with loss. Selecting the checkpoint with the minimum head gradient in a short tail window closes most of the gap to the oracle (4.24% +/- 2.00% with a universal setup, about 1.12% with light per-family tuning). For practical deployment, a head-scale normalization is more stable within classic CNN families (e.g., ResNets), while a feature-scale normalization works well for Transformers and modern CNNs. The same one-batch probe also predicts COCO detection/segmentation mAP. In diffusion (UNet/DDPM on CIFAR-10), it tracks progress and enables near-oracle tail-window selection; it is positively correlated with same-distribution probe MSE and negatively with FID (lower is better), so it can be used as a lightweight, label-free monitor. Validation labels are never used beyond reporting. The probe adds much less than 0.1% of an epoch and works as a drop-in for validation-free checkpoint selection and early stopping.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16874v1</guid></item><item><title>[cs updates on arXiv.org] Performance of Differential Protection Applied to Collector Cables of Offshore Wind Farms with MMC-HVDC Transmission</title><link>https://arxiv.org/abs/2601.16876</link><description>arXiv:2601.16876v1 Announce Type: new 
Abstract: The ongoing global transition towards low-carbon energy has propelled the integration of offshore wind farms, which, when combined with Modular Multilevel Converter-based High-Voltage Direct Current (MMC-HVDC) transmission, present unique challenges for power system protection. In collector cables connecting wind turbines to offshore MMC, both ends are supplied by Inverter-Based Resources (IBRs), which modify the magnitude and characteristics of fault currents. In this context, this paper investigates the limitations of conventional differential protection schemes under such conditions and compares them with enhanced strategies that account for sequence components. Using electromagnetic transient simulations of a representative offshore wind farm modeled in PSCAD/EMTDC software, internal and external fault scenarios are assessed, varying fault types and resistances. The comparative evaluation provides insights into the sensitivity and selectivity of differential protection and guides a deeper conceptual understanding of the evolving protection challenges inherent to future converter-dominated grids.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16876v1</guid></item><item><title>[cs updates on arXiv.org] Theory of Minimal Weight Perturbations in Deep Networks and its Applications for Low-Rank Activated Backdoor Attacks</title><link>https://arxiv.org/abs/2601.16880</link><description>arXiv:2601.16880v1 Announce Type: new 
Abstract: The minimal norm weight perturbations of DNNs required to achieve a specified change in output are derived and the factors determining its size are discussed. These single-layer exact formulae are contrasted with more generic multi-layer Lipschitz constant based robustness guarantees; both are observed to be of the same order which indicates similar efficacy in their guarantees. These results are applied to precision-modification-activated backdoor attacks, establishing provable compression thresholds below which such attacks cannot succeed, and show empirically that low-rank compression can reliably activate latent backdoors while preserving full-precision accuracy. These expressions reveal how back-propagated margins govern layer-wise sensitivity and provide certifiable guarantees on the smallest parameter updates consistent with a desired output shift.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16880v1</guid></item><item><title>[cs updates on arXiv.org] Assessing the Feasibility of Selective Instrumentation for Runtime Code Coverage in Large C++ Game Engines</title><link>https://arxiv.org/abs/2601.16881</link><description>arXiv:2601.16881v1 Announce Type: new 
Abstract: Code coverage is a valuable guide for testing, but in AAA games the overhead of instrumentation conflicts with strict performance requirements and can destabilize automated tests. We propose and assess a selective instrumentation approach tailored to large game engines written in \texttt{C++}, which reduces the scope of instrumentation while preserving relevant coverage data to developer commits. Our framework integrates into an industrial game testing pipeline, enabling developers to receive immediate coverage feedback on tests run against their changes. The compilation overhead of our approach is minimal, allowing instrumentation of over 2,000 commits before doubling build time. In performance evaluations, even the worst-case scenario maintains frame rates above 50\% of the non-instrumented baseline. Across two production test suites maintained by our industry partner, our framework caused no automated test failures, avoiding the instability observed under full instrumentation. Our work shows that commit-level or build-level coverage of large \texttt{C++} game engines can be achieved with minimal overhead and without compromising test stability.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16881v1</guid></item><item><title>[cs updates on arXiv.org] Multigrade Neural Network Approximation</title><link>https://arxiv.org/abs/2601.16884</link><description>arXiv:2601.16884v1 Announce Type: new 
Abstract: We study multigrade deep learning (MGDL) as a principled framework for structured error refinement in deep neural networks. While the approximation power of neural networks is now relatively well understood, training very deep architectures remains challenging due to highly non-convex and often ill-conditioned optimization landscapes. In contrast, for relatively shallow networks, most notably one-hidden-layer $\texttt{ReLU}$ models, training admits convex reformulations with global guarantees, motivating learning paradigms that improve stability while scaling to depth. MGDL builds upon this insight by training deep networks grade by grade: previously learned grades are frozen, and each new residual block is trained solely to reduce the remaining approximation error, yielding an interpretable and stable hierarchical refinement process. We develop an operator-theoretic foundation for MGDL and prove that, for any continuous target function, there exists a fixed-width multigrade $\texttt{ReLU}$ scheme whose residuals decrease strictly across grades and converge uniformly to zero. To the best of our knowledge, this work provides the first rigorous theoretical guarantee that grade-wise training yields provable vanishing approximation error in deep networks. Numerical experiments further illustrate the theoretical results.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16884v1</guid></item><item><title>[cs updates on arXiv.org] GPA-VGGT:Adapting VGGT to Large scale Localization by self-Supervised learning with Geometry and Physics Aware loss</title><link>https://arxiv.org/abs/2601.16885</link><description>arXiv:2601.16885v1 Announce Type: new 
Abstract: Transformer-based general visual geometry frameworks have shown promising performance in camera pose estimation and 3D scene understanding. Recent advancements in Visual Geometry Grounded Transformer (VGGT) models have shown great promise in camera pose estimation and 3D reconstruction. However, these models typically rely on ground truth labels for training, posing challenges when adapting to unlabeled and unseen scenes. In this paper, we propose a self-supervised framework to train VGGT with unlabeled data, thereby enhancing its localization capability in large-scale environments. To achieve this, we extend conventional pair-wise relations to sequence-wise geometric constraints for self-supervised learning. Specifically, in each sequence, we sample multiple source frames and geometrically project them onto different target frames, which improves temporal feature consistency. We formulate physical photometric consistency and geometric constraints as a joint optimization loss to circumvent the requirement for hard labels. By training the model with this proposed method, not only the local and global cross-view attention layers but also the camera and depth heads can effectively capture the underlying multi-view geometry. Experiments demonstrate that the model converges within hundreds of iterations and achieves significant improvements in large-scale localization. Our code will be released at https://github.com/X-yangfan/GPA-VGGT.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16885v1</guid></item><item><title>[cs updates on arXiv.org] MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion</title><link>https://arxiv.org/abs/2601.16886</link><description>arXiv:2601.16886v1 Announce Type: new 
Abstract: Knowledge Tracing (KT) aims to model a student's learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferred solely from interaction sequences. In addition, the scale and heterogeneity of KT graphs make full-graph encoding both computationally both costly and noise-prone, causing attention to bleed into student-irrelevant regions and degrading the fidelity of inter-KC relations. To address these issues, we propose a novel framework: Multi-Agent Graph-Enhanced Knowledge Tracing (MAGE-KT). It constructs a multi-view heterogeneous graph by combining a multi-agent KC relation extractor and a student-question interaction graph, capturing complementary semantic and behavioral signals. Conditioned on the target student's history, it retrieves compact, high-value subgraphs and integrates them using an Asymmetric Cross-attention Fusion Module to enhance prediction while avoiding attention diffusion and irrelevant computation. Experiments on three widely used KT datasets show substantial improvements in KC-relation accuracy and clear gains in next-question prediction over existing methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16886v1</guid></item><item><title>[cs updates on arXiv.org] LLM-Based Adversarial Persuasion Attacks on Fact-Checking Systems</title><link>https://arxiv.org/abs/2601.16890</link><description>arXiv:2601.16890v1 Announce Type: new 
Abstract: Automated fact-checking (AFC) systems are susceptible to adversarial attacks, enabling false claims to evade detection. Existing adversarial frameworks typically rely on injecting noise or altering semantics, yet no existing framework exploits the adversarial potential of persuasion techniques, which are widely used in disinformation campaigns to manipulate audiences. In this paper, we introduce a novel class of persuasive adversarial attacks on AFCs by employing a generative LLM to rephrase claims using persuasion techniques. Considering 15 techniques grouped into 6 categories, we study the effects of persuasion on both claim verification and evidence retrieval using a decoupled evaluation strategy. Experiments on the FEVER and FEVEROUS benchmarks show that persuasion attacks can substantially degrade both verification performance and evidence retrieval. Our analysis identifies persuasion techniques as a potent class of adversarial attacks, highlighting the need for more robust AFC systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16890v1</guid></item><item><title>[cs updates on arXiv.org] Evaluating Large Vision-language Models for Surgical Tool Detection</title><link>https://arxiv.org/abs/2601.16895</link><description>arXiv:2601.16895v1 Announce Type: new 
Abstract: Surgery is a highly complex process, and artificial intelligence has emerged as a transformative force in supporting surgical guidance and decision-making. However, the unimodal nature of most current AI systems limits their ability to achieve a holistic understanding of surgical workflows. This highlights the need for general-purpose surgical AI systems capable of comprehensively modeling the interrelated components of surgical scenes. Recent advances in large vision-language models that integrate multimodal data processing offer strong potential for modeling surgical tasks and providing human-like scene reasoning and understanding. Despite their promise, systematic investigations of VLMs in surgical applications remain limited. In this study, we evaluate the effectiveness of large VLMs for the fundamental surgical vision task of detecting surgical tools. Specifically, we investigate three state-of-the-art VLMs, Qwen2.5, LLaVA1.5, and InternVL3.5, on the GraSP robotic surgery dataset under both zero-shot and parameter-efficient LoRA fine-tuning settings. Our results demonstrate that Qwen2.5 consistently achieves superior detection performance in both configurations among the evaluated VLMs. Furthermore, compared with the open-set detection baseline Grounding DINO, Qwen2.5 exhibits stronger zero-shot generalization and comparable fine-tuned performance. Notably, Qwen2.5 shows superior instrument recognition, while Grounding DINO demonstrates stronger localization.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16895v1</guid></item><item><title>[cs updates on arXiv.org] How Sequential Algorithm Portfolios can benefit Black Box Optimization</title><link>https://arxiv.org/abs/2601.16896</link><description>arXiv:2601.16896v1 Announce Type: new 
Abstract: In typical black-box optimization applications, the available computational budget is often allocated to a single algorithm, typically chosen based on user preference with limited knowledge about the problem at hand or according to some expert knowledge. However, we show that splitting the budget across several algorithms yield significantly better results. This approach benefits from both algorithm complementarity across diverse problems and variance reduction within individual functions, and shows that algorithm portfolios do NOT require parallel evaluation capabilities. To demonstrate the advantage of sequential algorithm portfolios, we apply it to the COCO data archive, using over 200 algorithms evaluated on the BBOB test suite. The proposed sequential portfolios consistently outperform single-algorithm baselines, achieving relative performance gains of over 14%, and offering new insights into restart mechanisms and potential for warm-started execution strategies.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16896v1</guid></item><item><title>[cs updates on arXiv.org] FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization</title><link>https://arxiv.org/abs/2601.16897</link><description>arXiv:2601.16897v1 Announce Type: new 
Abstract: We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provides projection-free, primal-only updates, avoiding expensive dual-variable tuning or inner solvers. To handle communication limits, FedSGM incorporates bi-directional error feedback, correcting the bias introduced by compression while explicitly understanding the interaction between compression noise and multi-step local updates. We derive convergence guarantees showing that the averaged iterate achieves the canonical $\boldsymbol{\mathcal{O}}(1/\sqrt{T})$ rate, with additional high-probability bounds that decouple optimization progress from sampling noise due to partial participation. Additionally, we introduce a soft switching version of FedSGM to stabilize updates near the feasibility boundary. To our knowledge, FedSGM is the first framework to unify functional constraints, compression, multiple local updates, and partial client participation, establishing a theoretically grounded foundation for constrained federated learning. Finally, we validate the theoretical guarantees of FedSGM via experimentation on Neyman-Pearson classification and constrained Markov decision process (CMDP) tasks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16897v1</guid></item><item><title>[cs updates on arXiv.org] Embedding -based Crop Type Classification in the Groundnut Basin of Senegal</title><link>https://arxiv.org/abs/2601.16900</link><description>arXiv:2601.16900v1 Announce Type: new 
Abstract: Crop type maps from satellite remote sensing are important tools for food security, local livelihood support and climate change mitigation in smallholder regions of the world, but most satellite-based methods are not well suited to smallholder conditions. To address this gap, we establish a four-part criteria for a useful embedding-based approach consisting of 1) performance, 2) plausibility, 3) transferability and 4) accessibility and evaluate geospatial foundation model (FM) embeddings -based approaches using TESSERA and AlphaEarth against current baseline methods for a region in the groundnut basin of Senegal. We find that the TESSERA -based approach to land cover and crop type mapping fulfills the selection criteria best, and in one temporal transfer example shows 28% higher accuracy compared to the next best method. These results indicate that TESSERA embeddings are an effective approach for crop type classification and mapping tasks in Senegal.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16900v1</guid></item><item><title>[cs updates on arXiv.org] GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints</title><link>https://arxiv.org/abs/2601.16905</link><description>arXiv:2601.16905v1 Announce Type: new 
Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redirect queries away from knowledgeable experts rather than erasing knowledge, causing a loss of model utility and superficial forgetting. We propose Geometric Routing Invariance Preservation (GRIP), an algorithm-agnostic framework for unlearning for MoE. Our core contribution is a geometric constraint, implemented by projecting router gradient updates into an expert-specific null-space. Crucially, this decouples routing stability from parameter rigidity: while discrete expert selections remain stable for retained knowledge, the continuous router parameters remain plastic within the null space, allowing the model to undergo necessary internal reconfiguration to satisfy unlearning objectives. This forces the unlearning optimization to erase knowledge directly from expert parameters rather than exploiting the superficial router manipulation shortcut. GRIP functions as an adapter, constraining router parameter updates without modifying the underlying unlearning algorithm. Extensive experiments on large-scale MoE models demonstrate that our adapter eliminates expert selection shift (achieving over 95% routing stability) across all tested unlearning methods while preserving their utility. By preventing existing algorithms from exploiting MoE model's router vulnerability, GRIP adapts existing unlearning research from dense architectures to MoEs.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16905v1</guid></item><item><title>[cs updates on arXiv.org] The Trajectory Alignment Coefficient in Two Acts: From Reward Tuning to Reward Learning</title><link>https://arxiv.org/abs/2601.16906</link><description>arXiv:2601.16906v1 Announce Type: new 
Abstract: The success of reinforcement learning (RL) is fundamentally tied to having a reward function that accurately reflects the task objective. Yet, designing reward functions is notoriously time-consuming and prone to misspecification. To address this issue, our first goal is to understand how to support RL practitioners in specifying appropriate weights for a reward function. We leverage the Trajectory Alignment Coefficient (TAC), a metric that evaluates how closely a reward function's induced preferences match those of a domain expert. To evaluate whether TAC provides effective support in practice, we conducted a human-subject study in which RL practitioners tuned reward weights for Lunar Lander. We found that providing TAC during reward tuning led participants to produce more performant reward functions and report lower cognitive workload relative to standard tuning without TAC. However, the study also underscored that manual reward design, even with TAC, remains labor-intensive. This limitation motivated our second goal: to learn a reward model that maximizes TAC directly. Specifically, we propose Soft-TAC, a differentiable approximation of TAC that can be used as a loss function to train reward models from human preference data. Validated in the racing simulator Gran Turismo 7, reward models trained using Soft-TAC successfully captured preference-specific objectives, resulting in policies with qualitatively more distinct behaviors than models trained with standard Cross-Entropy loss. This work demonstrates that TAC can serve as both a practical tool for guiding reward tuning and a reward learning objective in complex domains.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16906v1</guid></item><item><title>[cs updates on arXiv.org] Calibrated Similarity for Reliable Geometric Analysis of Embedding Spaces</title><link>https://arxiv.org/abs/2601.16907</link><description>arXiv:2601.16907v1 Announce Type: new 
Abstract: While raw cosine similarity in pretrained embedding spaces exhibits strong rank correlation with human judgments, anisotropy induces systematic miscalibration of absolute values: scores concentrate in a narrow high-similarity band regardless of actual semantic relatedness, limiting interpretability as a quantitative measure. Prior work addresses this by modifying the embedding space (whitening, contrastive fine tuning), but such transformations alter geometric structure and require recomputing all embeddings.
  Using isotonic regression trained on human similarity judgments, we construct a monotonic transformation that achieves near-perfect calibration while preserving rank correlation and local stability(98% across seven perturbation types). Our contribution is not to replace cosine similarity, but to restore interpretability of its absolute values through monotone calibration, without altering its ranking properties.
  We characterize isotonic calibration as an order-preserving reparameterization and prove that all order-based constructions (angular ordering, nearest neighbors, threshold graphs and quantile-based decisions) are invariant under this transformation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16907v1</guid></item><item><title>[cs updates on arXiv.org] Preventing the Collapse of Peer Review Requires Verification-First AI</title><link>https://arxiv.org/abs/2601.16909</link><description>arXiv:2601.16909v1 Announce Type: new 
Abstract: This paper argues that AI-assisted peer review should be verification-first rather than review-mimicking. We propose truth-coupling, i.e. how tightly venue scores track latent scientific truth, as the right objective for review tools. We formalize two forces that drive a phase transition toward proxy-sovereign evaluation: verification pressure, when claims outpace verification capacity, and signal shrinkage, when real improvements become hard to separate from noise. In a minimal model that mixes occasional high-fidelity checks with frequent proxy judgment, we derive an explicit coupling law and an incentive-collapse condition under which rational effort shifts from truth-seeking to proxy optimization, even when current decisions still appear reliable. These results motivate actions for tool builders and program chairs: deploy AI as an adversarial auditor that generates auditable verification artifacts and expands effective verification bandwidth, rather than as a score predictor that amplifies claim inflation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16909v1</guid></item><item><title>[cs updates on arXiv.org] Recovering Communities in Structured Random Graphs</title><link>https://arxiv.org/abs/2601.16910</link><description>arXiv:2601.16910v1 Announce Type: new 
Abstract: The problem of recovering planted community structure in random graphs has received a lot of attention in the literature on the stochastic block model, where the input is a random graph in which edges crossing between different communities appear with smaller probability than edges induced by communities. The communities themselves form a collection of vertex-disjoint sparse cuts in the expected graph, and can be recovered, often exactly, from a sample as long as a separation condition on the intra- and inter-community edge probabilities is satisfied.
  In this paper, we ask whether the presence of a large number of overlapping sparsest cuts in the expected graph still allows recovery. For example, the $d$-dimensional hypercube graph admits $d$ distinct (balanced) sparsest cuts, one for every coordinate. Can these cuts be identified given a random sample of the edges of the hypercube where each edge is present independently with some probability $p\in (0, 1)$? We show that this is the case, in a very strong sense: the sparsest balanced cut in a sample of the hypercube at rate $p=C\log d/d$ for a sufficiently large constant $C$ is $1/\text{poly}(d)$-close to a coordinate cut with high probability. This is asymptotically optimal and allows approximate recovery of all $d$ cuts simultaneously. Furthermore, for an appropriate sample of hypercube-like graphs recovery can be made exact. The proof is essentially a strong hypercube cut sparsification bound that combines a theorem of Friedgut, Kalai and Naor on boolean functions whose Fourier transform concentrates on the first level of the Fourier spectrum with Karger's cut counting argument.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16910v1</guid></item><item><title>[cs updates on arXiv.org] Cell-vertex WENO schemes with shock-capturing quadrature for high-order finite element discretizations of hyperbolic problems</title><link>https://arxiv.org/abs/2601.16911</link><description>arXiv:2601.16911v1 Announce Type: new 
Abstract: We propose a new kind of localized shock capturing for continuous (CG) and discontinuous Galerkin (DG) discretizations of hyperbolic conservation laws. The underlying framework of dissipation-based weighted essentially nonoscillatory (WENO) stabilization for high-order CG and DG approximations was introduced in our previous work. In this general framework, Hermite WENO (HWENO) reconstructions are used to calculate local smoothness sensors that determine the appropriate amount of artificial viscosity for each cell. In the original version, candidate polynomials for WENO averaging are constructed using the derivative data from von Neumann neighbors. We upgrade this standard `cell-cell' reconstruction procedure by using WENO polynomials associated with mesh vertices as candidate polynomials for cell-based WENO averaging. The Hermite data of individual cells is sent to vertices of those cells, after which vertex-averaged HWENO data is sent back to cells containing the vertices. The new `cell-vertex' averaging procedure includes the data of vertex neighbors without explicitly adding them to the reconstruction stencils. It mitigates mesh imprinting and can also be used in classical HWENO limiters for DG methods. The second main novelty of the proposed approach is a quadrature-driven distribution of artificial viscosity within high-order finite elements. Replacing the linear quadrature weights by their nonlinear WENO-type counterparts, we concentrate shock-capturing dissipation near discontinuities while minimizing it in smooth portions of troubled cells. This redistribution of WENO stabilization preserves the total dissipation rate within each cell and improves local shock resolution without relying on subcell decomposition techniques. Numerical experiments in one and two dimensions demonstrate substantial improvements in accuracy and robustness for high-order elements.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16911v1</guid></item><item><title>[cs updates on arXiv.org] LoL: Longer than Longer, Scaling Video Generation to Hour</title><link>https://arxiv.org/abs/2601.16914</link><description>arXiv:2601.16914v1 Announce Type: new 
Abstract: Recent research in long-form video generation has shifted from bidirectional to autoregressive models, yet these methods commonly suffer from error accumulation and a loss of long-term coherence. While attention sink frames have been introduced to mitigate this performance decay, they often induce a critical failure mode we term sink-collapse: the generated content repeatedly reverts to the sink frame, resulting in abrupt scene resets and cyclic motion patterns. Our analysis reveals that sink-collapse originates from an inherent conflict between the periodic structure of Rotary Position Embedding (RoPE) and the multi-head attention mechanisms prevalent in current generative models. To address it, we propose a lightweight, training-free approach that effectively suppresses this behavior by introducing multi-head RoPE jitter that breaks inter-head attention homogenization and mitigates long-horizon collapse. Extensive experiments show that our method successfully alleviates sink-collapse while preserving generation quality. To the best of our knowledge, this work achieves the first demonstration of real-time, streaming, and infinite-length video generation with little quality decay. As an illustration of this robustness, we generate continuous videos up to 12 hours in length, which, to our knowledge, is among the longest publicly demonstrated results in streaming video generation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16914v1</guid></item><item><title>[cs updates on arXiv.org] Group-realizable multi-group learning by minimizing empirical risk</title><link>https://arxiv.org/abs/2601.16922</link><description>arXiv:2601.16922v1 Announce Type: new 
Abstract: The sample complexity of multi-group learning is shown to improve in the group-realizable setting over the agnostic setting, even when the family of groups is infinite so long as it has finite VC dimension. The improved sample complexity is obtained by empirical risk minimization over the class of group-realizable concepts, which itself could have infinite VC dimension. Implementing this approach is also shown to be computationally intractable, and an alternative approach is suggested based on improper learning.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16922v1</guid></item><item><title>[cs updates on arXiv.org] Conditionally Tight Algorithms for Maximum k-Coverage and Partial k-Dominating Set via Arity-Reducing Hypercuts</title><link>https://arxiv.org/abs/2601.16923</link><description>arXiv:2601.16923v1 Announce Type: new 
Abstract: We revisit the classic Maximum $k$-Coverage problem: Determine the largest number $t$ of elements that can be covered by choosing $k$ sets from a given family $\mathcal{F} = \{S_1,\dots, S_n\}$ of a size-$u$ universe. A notable special case is Partial $k$-Dominating Set, where one chooses $k$ vertices in a graph to maximize the number of dominated vertices.
  Extensive research has established strong hardness results for various aspects of Maximum $k$-Coverage, such as tight inapproximability results, $W[2]$-hardness, and a conditionally tight worst-case running time of $n^{k\pm o(1)}$. In this paper we ask: (1) Can this time bound be improved for small $t$, at least for Partial $k$-Dominating Set, ideally to time~$t^{k\pm O(1)}$? (2) More ambitiously, can we even determine the best-possible running time of Maximum $k$-Coverage with respect to the perhaps most natural parameters: the universe size $u$, the maximum set size $s$, and the maximum frequency $f$?
  We successfully resolve both questions. (1) We give an algorithm that solves Partial $k$-Dominating Set in time $O(nt + t^{\frac{2\omega}{3} k+O(1)})$ if $\omega \ge 2.25$ and time $O(nt+ t^{\frac{3}{2} k+O(1)})$ if $\omega \le 2.25$, where $\omega \le 2.372$ is the matrix multiplication exponent. From this we derive a time bound that is conditionally optimal, regardless of $\omega$, based on the well-established $k$-clique and 3-uniform hyperclique hypotheses from fine-grained complexity. We also obtain matching upper and lower bounds for sparse graphs. To address (2) we design an algorithm for Maximum $k$-Coverage running in time
  $$
  \min \left\{ (f\cdot \min\{\sqrt[3]{u}, \sqrt{s}\})^k + \min\{n,f\cdot \min\{\sqrt{u}, s\}\}^{k\omega/3}, n^k\right\}
  \cdot g(k)n^{\pm O(1)}, $$ and, surprisingly, further show that this complicated time bound is also conditionally optimal.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16923v1</guid></item><item><title>[cs updates on arXiv.org] Nishpaksh: TEC Standard-Compliant Framework for Fairness Auditing and Certification of AI Models</title><link>https://arxiv.org/abs/2601.16926</link><description>arXiv:2601.16926v1 Announce Type: new 
Abstract: The growing reliance on Artificial Intelligence (AI) models in high-stakes decision-making systems, particularly within emerging telecom and 6G applications, underscores the urgent need for transparent and standardized fairness assessment frameworks. While global toolkits such as IBM AI Fairness 360 and Microsoft Fairlearn have advanced bias detection, they often lack alignment with region-specific regulatory requirements and national priorities. To address this gap, we propose Nishpaksh, an indigenous fairness evaluation tool that operationalizes the Telecommunication Engineering Centre (TEC) Standard for the Evaluation and Rating of Artificial Intelligence Systems. Nishpaksh integrates survey-based risk quantification, contextual threshold determination, and quantitative fairness evaluation into a unified, web-based dashboard. The tool employs vectorized computation, reactive state management, and certification-ready reporting to enable reproducible, audit-grade assessments, thereby addressing a critical post-standardization implementation need. Experimental validation on the COMPAS dataset demonstrates Nishpaksh's effectiveness in identifying attribute-specific bias and generating standardized fairness scores compliant with the TEC framework. The system bridges the gap between research-oriented fairness methodologies and regulatory AI governance in India, marking a significant step toward responsible and auditable AI deployment within critical infrastructure like telecommunications.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16926v1</guid></item><item><title>[cs updates on arXiv.org] In Quest of an Extensible Multi-Level Harm Taxonomy for Adversarial AI: Heart of Security, Ethical Risk Scoring and Resilience Analytics</title><link>https://arxiv.org/abs/2601.16930</link><description>arXiv:2601.16930v1 Announce Type: new 
Abstract: Harm is invoked everywhere from cybersecurity, ethics, risk analysis, to adversarial AI, yet there exists no systematic or agreed upon list of harms, and the concept itself is rarely defined with the precision required for serious analysis. Current discourse relies on vague, under specified notions of harm, rendering nuanced, structured, and qualitative assessment effectively impossible. This paper challenges that gap directly. We introduce a structured and expandable taxonomy of harms, grounded in an ensemble of contemporary ethical theories, that makes harm explicit, enumerable, and analytically tractable. The proposed framework identifies 66+ distinct harm types, systematically organized into two overarching domains human and nonhuman, and eleven major categories, each explicitly aligned with eleven dominant ethical theories. While extensible by design, the upper levels are intentionally stable. Beyond classification, we introduce a theory-aware taxonomy of victim entities and formalize normative harm attributes, including reversibility and duration that materially alter ethical severity. Together, these contributions transform harm from a rhetorical placeholder into an operational object of analysis, enabling rigorous ethical reasoning and long term safety evaluation of AI systems and other sociotechnical domains where harm is a first order concern.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16930v1</guid></item><item><title>[cs updates on arXiv.org] Reward-Forcing: Autoregressive Video Generation with Reward Feedback</title><link>https://arxiv.org/abs/2601.16933</link><description>arXiv:2601.16933v1 Announce Type: new 
Abstract: While most prior work in video generation relies on bidirectional architectures, recent efforts have sought to adapt these models into autoregressive variants to support near real-time generation. However, such adaptations often depend heavily on teacher models, which can limit performance, particularly in the absence of a strong autoregressive teacher, resulting in output quality that typically lags behind their bidirectional counterparts. In this paper, we explore an alternative approach that uses reward signals to guide the generation process, enabling more efficient and scalable autoregressive generation. By using reward signals to guide the model, our method simplifies training while preserving high visual fidelity and temporal consistency. Through extensive experiments on standard benchmarks, we find that our approach performs comparably to existing autoregressive models and, in some cases, surpasses similarly sized bidirectional models by avoiding constraints imposed by teacher architectures. For example, on VBench, our method achieves a total score of 84.92, closely matching state-of-the-art autoregressive methods that score 84.31 but require significant heterogeneous distillation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16933v1</guid></item><item><title>[cs updates on arXiv.org] Information Representation Fairness in Long-Document Embeddings: The Peculiar Interaction of Positional and Language Bias</title><link>https://arxiv.org/abs/2601.16934</link><description>arXiv:2601.16934v1 Announce Type: new 
Abstract: To be discoverable in an embedding-based search process, each part of a document should be reflected in its embedding representation. To quantify any potential reflection biases, we introduce a permutation-based evaluation framework. With this, we observe that state-of-the-art embedding models exhibit systematic positional and language biases when documents are longer and consist of multiple segments. Specifically, early segments and segments in higher-resource languages like English are over-represented, while later segments and segments in lower-resource languages are marginalized. In our further analysis, we find that the positional bias stems from front-loaded attention distributions in pooling-token embeddings, where early tokens receive more attention. To mitigate this issue, we introduce an inference-time attention calibration method that redistributes attention more evenly across document positions, increasing discoverabiltiy of later segments. Our evaluation framework and attention calibration is available at https://github.com/impresso/fair-sentence-transformers</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16934v1</guid></item><item><title>[cs updates on arXiv.org] AERO: Adaptive and Efficient Runtime-Aware OTA Updates for Energy-Harvesting IoT</title><link>https://arxiv.org/abs/2601.16935</link><description>arXiv:2601.16935v1 Announce Type: new 
Abstract: Energy-harvesting (EH) Internet of Things (IoT) devices operate under intermittent energy availability, which disrupts task execution and makes energy-intensive over-the-air (OTA) updates particularly challenging. Conventional OTA update mechanisms rely on reboots and incur significant overhead, rendering them unsuitable for intermittently powered systems. Recent live OTA update techniques reduce reboot overhead but still lack mechanisms to ensure consistency when updates interact with runtime execution. This paper presents AERO, an Adaptive and Efficient Runtime-Aware OTA update mechanism that integrates update tasks into the device's Directed Acyclic Graph (DAG) and schedules them alongside routine tasks under energy and timing constraints. By identifying update-affected execution regions and dynamically adjusting dependencies, AERO ensures consistent up date integration while adapting to intermittent energy availability. Experiments on representative workloads demonstrate improved update reliability and efficiency compared to existing live update approaches.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16935v1</guid></item><item><title>[cs updates on arXiv.org] Strategies for Span Labeling with Large Language Models</title><link>https://arxiv.org/abs/2601.16946</link><description>arXiv:2601.16946v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly used for text analysis tasks, such as named entity recognition or error detection. Unlike encoder-based models, however, generative architectures lack an explicit mechanism to refer to specific parts of their input. This leads to a variety of ad-hoc prompting strategies for span labeling, often with inconsistent results. In this paper, we categorize these strategies into three families: tagging the input text, indexing numerical positions of spans, and matching span content. To address the limitations of content matching, we introduce LogitMatch, a new constrained decoding method that forces the model's output to align with valid input spans. We evaluate all methods across four diverse tasks. We find that while tagging remains a robust baseline, LogitMatch improves upon competitive matching-based methods by eliminating span matching issues and outperforms other strategies in some setups.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16946v1</guid></item><item><title>[cs updates on arXiv.org] Domain-invariant Mixed-domain Semi-supervised Medical Image Segmentation with Clustered Maximum Mean Discrepancy Alignment</title><link>https://arxiv.org/abs/2601.16954</link><description>arXiv:2601.16954v1 Announce Type: new 
Abstract: Deep learning has shown remarkable progress in medical image semantic segmentation, yet its success heavily depends on large-scale expert annotations and consistent data distributions. In practice, annotations are scarce, and images are collected from multiple scanners or centers, leading to mixed-domain settings with unknown domain labels and severe domain gaps. Existing semi-supervised or domain adaptation approaches typically assume either a single domain shift or access to explicit domain indices, which rarely hold in real-world deployment. In this paper, we propose a domain-invariant mixed-domain semi-supervised segmentation framework that jointly enhances data diversity and mitigates domain bias. A Copy-Paste Mechanism (CPM) augments the training set by transferring informative regions across domains, while a Cluster Maximum Mean Discrepancy (CMMD) block clusters unlabeled features and aligns them with labeled anchors via an MMD objective, encouraging domain-invariant representations. Integrated within a teacher-student framework, our method achieves robust and precise segmentation even with very few labeled examples and multiple unknown domain discrepancies. Experiments on Fundus and M&amp;amp;Ms benchmarks demonstrate that our approach consistently surpasses semi-supervised and domain adaptation methods, establishing a potential solution for mixed-domain semi-supervised medical image segmentation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16954v1</guid></item><item><title>[cs updates on arXiv.org] 3D Molecule Generation from Rigid Motifs via SE(3) Flows</title><link>https://arxiv.org/abs/2601.16955</link><description>arXiv:2601.16955v1 Announce Type: new 
Abstract: Three-dimensional molecular structure generation is typically performed at the level of individual atoms, yet molecular graph generation techniques often consider fragments as their structural units. Building on the advances in frame-based protein structure generation, we extend these fragmentation ideas to 3D, treating general molecules as sets of rigid-body motifs. Utilising this representation, we employ SE(3)-equivariant generative modelling for de novo 3D molecule generation from rigid motifs. In our evaluations, we observe comparable or superior results to state-of-the-art across benchmarks, surpassing it in atom stability on GEOM-Drugs, while yielding a 2x to 10x reduction in generation steps and offering 3.5x compression in molecular representations compared to the standard atom-based methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16955v1</guid></item><item><title>[cs updates on arXiv.org] DataStates-LLM: Scalable Checkpointing for Transformer Models Using Composable State Providers</title><link>https://arxiv.org/abs/2601.16956</link><description>arXiv:2601.16956v1 Announce Type: new 
Abstract: The rapid growth of Large Transformer-based models, specifically Large Language Models (LLMs), now scaling to trillions of parameters, has necessitated training across thousands of GPUs using complex hybrid parallelism strategies (e.g., data, tensor, and pipeline parallelism). Checkpointing this massive, distributed state is critical for a wide range of use cases, such as resilience, suspend-resume, investigating undesirable training trajectories, and explaining model evolution. However, existing checkpointing solutions typically treat model state as opaque binary blobs, ignoring the ``3D heterogeneity'' of the underlying data structures--varying by memory location (GPU vs. Host), number of ``logical'' objects sharded and split across multiple files, data types (tensors vs. Python objects), and their serialization requirements. This results in significant runtime overheads due to blocking device-to-host transfers, data-oblivious serialization, and storage I/O contention. In this paper, we introduce DataStates-LLM, a novel checkpointing architecture that leverages State Providers to decouple state abstraction from data movement. DataStates-LLM exploits the immutability of model parameters during the forward and backward passes to perform ``lazy'', non-blocking asynchronous snapshots. By introducing State Providers, we efficiently coalesce fragmented, heterogeneous shards and overlap the serialization of metadata with bulk tensor I/O. We evaluate DataStates-LLM on models up to 70B parameters on 256 A100-40GB GPUs. Our results demonstrate that DataStates-LLM achieves up to 4$\times$ higher checkpointing throughput and reduces end-to-end training time by up to 2.2$\times$ compared to state-of-the-art solutions, effectively mitigating the serialization and heterogeneity bottlenecks in extreme-scale LLM training.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16956v1</guid></item><item><title>[cs updates on arXiv.org] Do We Know What They Know We Know? Calibrating Student Trust in AI and Human Responses Through Mutual Theory of Mind</title><link>https://arxiv.org/abs/2601.16960</link><description>arXiv:2601.16960v1 Announce Type: new 
Abstract: Trust and reliance are often treated as coupled constructs in human-AI interaction research, with the assumption that calibrating trust will lead to appropriate reliance. We challenge this assumption in educational contexts, where students increasingly turn to AI for learning support. Through semi-structured interviews with graduate students (N=8) comparing AI-generated and human-generated responses, we find a systematic dissociation: students exhibit high trust but low reliance on human experts due to social barriers (fear of judgment, help-seeking anxiety), while showing low trust but high reliance on AI systems due to social affordances (accessibility, anonymity, judgment-free interaction). Using Mutual Theory of Mind as an analytical lens, we demonstrate that trust is shaped by epistemic evaluations while reliance is driven by social factors -- and these may operate independently.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16960v1</guid></item><item><title>[cs updates on arXiv.org] AgentDrive: An Open Benchmark Dataset for Agentic AI Reasoning with LLM-Generated Scenarios in Autonomous Systems</title><link>https://arxiv.org/abs/2601.16964</link><description>arXiv:2601.16964v1 Announce Type: new 
Abstract: The rapid advancement of large language models (LLMs) has sparked growing interest in their integration into autonomous systems for reasoning-driven perception, planning, and decision-making. However, evaluating and training such agentic AI models remains challenging due to the lack of large-scale, structured, and safety-critical benchmarks. This paper introduces AgentDrive, an open benchmark dataset containing 300,000 LLM-generated driving scenarios designed for training, fine-tuning, and evaluating autonomous agents under diverse conditions. AgentDrive formalizes a factorized scenario space across seven orthogonal axes: scenario type, driver behavior, environment, road layout, objective, difficulty, and traffic density. An LLM-driven prompt-to-JSON pipeline generates semantically rich, simulation-ready specifications that are validated against physical and schema constraints. Each scenario undergoes simulation rollouts, surrogate safety metric computation, and rule-based outcome labeling. To complement simulation-based evaluation, we introduce AgentDrive-MCQ, a 100,000-question multiple-choice benchmark spanning five reasoning dimensions: physics, policy, hybrid, scenario, and comparative reasoning. We conduct a large-scale evaluation of fifty leading LLMs on AgentDrive-MCQ. Results show that while proprietary frontier models perform best in contextual and policy reasoning, advanced open models are rapidly closing the gap in structured and physics-grounded reasoning. We release the AgentDrive dataset, AgentDrive-MCQ benchmark, evaluation code, and related materials at https://github.com/maferrag/AgentDrive</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16964v1</guid></item><item><title>[cs updates on arXiv.org] Spatial-Agent: Agentic Geo-spatial Reasoning with Scientific Core Concepts</title><link>https://arxiv.org/abs/2601.16965</link><description>arXiv:2601.16965v1 Announce Type: new 
Abstract: Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response. However, existing LLM-based agents often fail at genuine geospatial computation, relying instead on web search or pattern matching while hallucinating spatial relationships. We present Spatial-Agent, an AI agent grounded in foundational theories of spatial information science. Our approach formalizes geo-analytical question answering as a concept transformation problem, where natural-language questions are parsed into executable workflows represented as GeoFlow Graphs -- directed acyclic graphs with nodes corresponding to spatial concepts and edges representing transformations. Drawing on spatial information theory, Spatial-Agent extracts spatial concepts, assigns functional roles with principled ordering constraints, and composes transformation sequences through template-based generation. Extensive experiments on MapEval-API and MapQA benchmarks demonstrate that Spatial-Agent significantly outperforms existing baselines including ReAct and Reflexion, while producing interpretable and executable geospatial workflows.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16965v1</guid></item><item><title>[cs updates on arXiv.org] Empowering Medical Equipment Sustainability in Low-Resource Settings: An AI-Powered Diagnostic and Support Platform for Biomedical Technicians</title><link>https://arxiv.org/abs/2601.16967</link><description>arXiv:2601.16967v1 Announce Type: new 
Abstract: In low- and middle-income countries (LMICs), a significant proportion of medical diagnostic equipment remains underutilized or non-functional due to a lack of timely maintenance, limited access to technical expertise, and minimal support from manufacturers, particularly for devices acquired through third-party vendors or donations. This challenge contributes to increased equipment downtime, delayed diagnoses, and compromised patient care. This research explores the development and validation of an AI-powered support platform designed to assist biomedical technicians in diagnosing and repairing medical devices in real-time. The system integrates a large language model (LLM) with a user-friendly web interface, enabling imaging technologists/radiographers and biomedical technicians to input error codes or device symptoms and receive accurate, step-by-step troubleshooting guidance. The platform also includes a global peer-to-peer discussion forum to support knowledge exchange and provide additional context for rare or undocumented issues. A proof of concept was developed using the Philips HDI 5000 ultrasound machine, achieving 100% precision in error code interpretation and 80% accuracy in suggesting corrective actions. This study demonstrates the feasibility and potential of AI-driven systems to support medical device maintenance, with the aim of reducing equipment downtime to improve healthcare delivery in resource-constrained environments.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16967v1</guid></item><item><title>[cs updates on arXiv.org] Auto-Regressive Masked Diffusion Models</title><link>https://arxiv.org/abs/2601.16971</link><description>arXiv:2601.16971v1 Announce Type: new 
Abstract: Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel generation capabilities of diffusion-based models. Our key insight is to reframe the masked diffusion process as a block-wise causal model. This perspective allows us to design a strictly causal, permutation-equivariant architecture that computes all conditional probabilities across multiple denoising steps in a single, parallel forward pass. The resulting architecture supports efficient, autoregressive-style decoding and a progressive permutation training scheme, allowing the model to learn both canonical left-to-right and random token orderings. Leveraging this flexibility, we introduce a novel strided parallel generation strategy that accelerates inference by generating tokens in parallel streams while maintaining global coherence. Empirical results demonstrate that ARMD achieves state-of-the-art performance on standard language modeling benchmarks, outperforming established diffusion baselines while requiring significantly fewer training steps. Furthermore, it establishes a new benchmark for parallel text generation, effectively bridging the performance gap between parallel and sequential decoding.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16971v1</guid></item><item><title>[cs updates on arXiv.org] VisGym: Diverse, Customizable, Scalable Environments for Multimodal Agents</title><link>https://arxiv.org/abs/2601.16973</link><description>arXiv:2601.16973v1 Announce Type: new 
Abstract: Modern Vision-Language Models (VLMs) remain poorly characterized in multi-step visual interactions, particularly in how they integrate perception, memory, and action over long horizons. We introduce VisGym, a gymnasium of 17 environments for evaluating and training VLMs. The suite spans symbolic puzzles, real-image understanding, navigation, and manipulation, and provides flexible controls over difficulty, input representation, planning horizon, and feedback. We also provide multi-step solvers that generate structured demonstrations, enabling supervised finetuning. Our evaluations show that all frontier models struggle in interactive settings, achieving low success rates in both the easy (46.6%) and hard (26.0%) configurations. Our experiments reveal notable limitations: models struggle to effectively leverage long context, performing worse with an unbounded history than with truncated windows. Furthermore, we find that several text-based symbolic tasks become substantially harder once rendered visually. However, explicit goal observations, textual feedback, and exploratory demonstrations in partially observable or unknown-dynamics settings for supervised finetuning yield consistent gains, highlighting concrete failure modes and pathways for improving multi-step visual decision-making. Code, data, and models can be found at: https://visgym.github.io/.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16973v1</guid></item><item><title>[cs updates on arXiv.org] Latent Diffusion for Internet of Things Attack Data Generation in Intrusion Detection</title><link>https://arxiv.org/abs/2601.16976</link><description>arXiv:2601.16976v1 Announce Type: new 
Abstract: Intrusion Detection Systems (IDSs) are a key component for protecting Internet of Things (IoT) environments. However, in Machine Learning-based (ML-based) IDSs, performance is often degraded by the strong class imbalance between benign and attack traffic. Although data augmentation has been widely explored to mitigate this issue, existing approaches typically rely on simple oversampling techniques or generative models that struggle to simultaneously achieve high sample fidelity, diversity, and computational efficiency. To address these limitations, we propose the use of a Latent Diffusion Model (LDM) for attack data augmentation in IoT intrusion detection and provide a comprehensive comparison against state-of-the-art baselines. Experiments were conducted on three representative IoT attack types, specifically Distributed Denial-of-Service (DDoS), Mirai, and Man-in-the-Middle, evaluating both downstream IDS performance and intrinsic generative quality using distributional, dependency-based, and diversity metrics. Results show that balancing the training data with LDM-generated samples substantially improves IDS performance, achieving F1-scores of up to 0.99 for DDoS and Mirai attacks and consistently outperforming competing methods. Additionally, quantitative and qualitative analyses demonstrate that LDMs effectively preserve feature dependencies while generating diverse samples and reduce sampling time by approximately 25\% compared to diffusion models operating directly in data space. These findings highlight latent diffusion as an effective and scalable solution for synthetic IoT attack data generation, substantially mitigating the impact of class imbalance in ML-based IDSs for IoT scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16976v1</guid></item><item><title>[cs updates on arXiv.org] A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of LLMs</title><link>https://arxiv.org/abs/2601.16979</link><description>arXiv:2601.16979v1 Announce Type: new 
Abstract: Understanding the curvature evolution of the loss landscape is fundamental to analyzing the training dynamics of neural networks. The most commonly studied measure, Hessian sharpness ($\lambda_{\max}^H$) -- the largest eigenvalue of the loss Hessian -- determines local training stability and interacts with the learning rate throughout training. Despite its significance in analyzing training dynamics, direct measurement of Hessian sharpness remains prohibitive for Large Language Models (LLMs) due to high computational cost. We analyze $\textit{critical sharpness}$ ($\lambda_c$), a computationally efficient measure requiring fewer than $10$ forward passes given the update direction $\Delta \mathbf{\theta}$. Critically, this measure captures well-documented Hessian sharpness phenomena, including progressive sharpening and Edge of Stability. Using this measure, we provide the first demonstration of these sharpness phenomena at scale, up to $7$B parameters, spanning both pre-training and mid-training of OLMo-2 models. We further introduce $\textit{relative critical sharpness}$ ($\lambda_c^{1\to 2}$), which quantifies the curvature of one loss landscape while optimizing another, to analyze the transition from pre-training to fine-tuning and guide data mixing strategies. Critical sharpness provides practitioners with a practical tool for diagnosing curvature dynamics and informing data composition choices at scale. More broadly, our work shows that scalable curvature measures can provide actionable insights for large-scale training.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16979v1</guid></item><item><title>[cs updates on arXiv.org] SyncLight: Controllable and Consistent Multi-View Relighting</title><link>https://arxiv.org/abs/2601.16981</link><description>arXiv:2601.16981v1 Announce Type: new 
Abstract: We present SyncLight, the first method to enable consistent, parametric relighting across multiple uncalibrated views of a static scene. While single-view relighting has advanced significantly, existing generative approaches struggle to maintain the rigorous lighting consistency essential for multi-camera broadcasts, stereoscopic cinema, and virtual production. SyncLight addresses this by enabling precise control over light intensity and color across a multi-view capture of a scene, conditioned on a single reference edit. Our method leverages a multi-view diffusion transformer trained using a latent bridge matching formulation, achieving high-fidelity relighting of the entire image set in a single inference step. To facilitate training, we introduce a large-scale hybrid dataset comprising diverse synthetic environments -- curated from existing sources and newly designed scenes -- alongside high-fidelity, real-world multi-view captures under calibrated illumination. Surprisingly, though trained only on image pairs, SyncLight generalizes zero-shot to an arbitrary number of viewpoints, effectively propagating lighting changes across all views, without requiring camera pose information. SyncLight enables practical relighting workflows for multi-view capture systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16981v1</guid></item><item><title>[cs updates on arXiv.org] AnyView: Synthesizing Any Novel View in Dynamic Scenes</title><link>https://arxiv.org/abs/2601.16982</link><description>arXiv:2601.16982v1 Announce Type: new 
Abstract: Modern generative video models excel at producing convincing, high-quality outputs, but struggle to maintain multi-view and spatiotemporal consistency in highly dynamic real-world environments. In this work, we introduce \textbf{AnyView}, a diffusion-based video generation framework for \emph{dynamic view synthesis} with minimal inductive biases or geometric assumptions. We leverage multiple data sources with various levels of supervision, including monocular (2D), multi-view static (3D) and multi-view dynamic (4D) datasets, to train a generalist spatiotemporal implicit representation capable of producing zero-shot novel videos from arbitrary camera locations and trajectories. We evaluate AnyView on standard benchmarks, showing competitive results with the current state of the art, and propose \textbf{AnyViewBench}, a challenging new benchmark tailored towards \emph{extreme} dynamic view synthesis in diverse real-world scenarios. In this more dramatic setting, we find that most baselines drastically degrade in performance, as they require significant overlap between viewpoints, while AnyView maintains the ability to produce realistic, plausible, and spatiotemporally consistent videos when prompted from \emph{any} viewpoint. Results, data, code, and models can be viewed at: https://tri-ml.github.io/AnyView/</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16982v1</guid></item><item><title>[cs updates on arXiv.org] Interpretable Fine-Gray Deep Survival Model for Competing Risks: Predicting Post-Discharge Foot Complications for Diabetic Patients in Ontario</title><link>https://arxiv.org/abs/2511.12409</link><description>arXiv:2511.12409v1 Announce Type: cross 
Abstract: Model interpretability is crucial for establishing AI safety and clinician trust in medical applications for example, in survival modelling with competing risks. Recent deep learning models have attained very good predictive performance but their limited transparency, being black-box models, hinders their integration into clinical practice. To address this gap, we propose an intrinsically interpretable survival model called CRISPNAM-FG. Leveraging the structure of Neural Additive Models (NAMs) with separate projection vectors for each risk, our approach predicts the Cumulative Incidence Function using the Fine-Gray formulation, achieving high predictive power with intrinsically transparent and auditable predictions. We validated the model on several benchmark datasets and applied our model to predict future foot complications in diabetic patients across 29 Ontario hospitals (2016-2023). Our method achieves competitive performance compared to other deep survival models while providing transparency through shape functions and feature importance plots.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.12409v1</guid></item><item><title>[cs updates on arXiv.org] Latent Causal Diffusions for Single-Cell Perturbation Modeling</title><link>https://arxiv.org/abs/2601.15341</link><description>arXiv:2601.15341v1 Announce Type: cross 
Abstract: Perturbation screens hold the potential to systematically map regulatory processes at single-cell resolution, yet modeling and predicting transcriptome-wide responses to perturbations remains a major computational challenge. Existing methods often underperform simple baselines, fail to disentangle measurement noise from biological signal, and provide limited insight into the causal structure governing cellular responses. Here, we present the latent causal diffusion (LCD), a generative model that frames single-cell gene expression as a stationary diffusion process observed under measurement noise. LCD outperforms established approaches in predicting the distributional shifts of unseen perturbation combinations in single-cell RNA-sequencing screens while simultaneously learning a mechanistic dynamical system of gene regulation. To interpret these learned dynamics, we develop an approach we call causal linearization via perturbation responses (CLIPR), which yields an approximation of the direct causal effects between all genes modeled by the diffusion. CLIPR provably identifies causal effects under a linear drift assumption and recovers causal structure in both simulated systems and a genome-wide perturbation screen, where it clusters genes into coherent functional modules and resolves causal relationships that standard differential expression analysis cannot. The LCD-CLIPR framework bridges generative modeling with causal inference to predict unseen perturbation effects and map the underlying regulatory mechanisms of the transcriptome.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15341v1</guid></item><item><title>[cs updates on arXiv.org] ES4R: Speech Encoding Based on Prepositive Affective Modeling for Empathetic Response Generation</title><link>https://arxiv.org/abs/2601.16225</link><description>arXiv:2601.16225v1 Announce Type: cross 
Abstract: Empathetic speech dialogue requires not only understanding linguistic content but also perceiving rich paralinguistic information such as prosody, tone, and emotional intensity for affective understandings. Existing speech-to-speech large language models either rely on ASR transcription or use encoders to extract latent representations, often weakening affective information and contextual coherence in multi-turn dialogues. To address this, we propose \textbf{ES4R}, a framework for speech-based empathetic response generation. Our core innovation lies in explicitly modeling structured affective context before speech encoding, rather than relying on implicit learning by the encoder or explicit emotion supervision. Specifically, we introduce a dual-level attention mechanism to capture turn-level affective states and dialogue-level affective dynamics. The resulting affective representations are then integrated with textual semantics through speech-guided cross-modal attention to generate empathetic responses. For speech output, we employ energy-based strategy selection and style fusion to achieve empathetic speech synthesis. ES4R consistently outperforms strong baselines in both automatic and human evaluations and remains robust across different LLM backbones.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16225v1</guid></item><item><title>[cs updates on arXiv.org] D-MODD: A Diffusion Model of Opinion Dynamics Derived from Online Data</title><link>https://arxiv.org/abs/2601.16226</link><description>arXiv:2601.16226v1 Announce Type: cross 
Abstract: We present the first empirical derivation of a continuous-time stochastic model for real-world opinion dynamics. Using longitudinal social-media data to infer users opinion on a binary climate-change topic, we reconstruct the underlying drift and diffusion functions governing individual opinion updates. We show that the observed dynamics are well described by a Langevin-type stochastic differential equation, with persistent attractor basins and spatially sensitive drift and diffusion terms. The empirically inferred one-step transition probabilities closely reproduce the transition kernel generated from the D-MODD model we introduce. Our results provide the first direct evidence that online opinion dynamics on a polarized topic admit a Markovian description at the operator level, with empirically reconstructed transition kernels accurately reproduced by a data-driven Langevin model, bridging sociophysics, behavioral data, and complex-systems modeling.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16226v1</guid></item><item><title>[cs updates on arXiv.org] Zero-Shot Speech LLMs for Multi-Aspect Evaluation of L2 Speech: Challenges and Opportunities</title><link>https://arxiv.org/abs/2601.16230</link><description>arXiv:2601.16230v1 Announce Type: cross 
Abstract: An accurate assessment of L2 English pronunciation is crucial for language learning, as it provides personalized feedback and ensures a fair evaluation of individual progress. However, automated scoring remains challenging due to the complexity of sentence-level fluency, prosody, and completeness. This paper evaluates the zero-shot performance of Qwen2-Audio-7B-Instruct, an instruction-tuned speech-LLM, on 5,000 Speechocean762 utterances. The model generates rubric-aligned scores for accuracy, fluency, prosody, and completeness, showing strong agreement with human ratings within +-2 tolerance, especially for high-quality speech. However, it tends to overpredict low-quality speech scores and lacks precision in error detection. These findings demonstrate the strong potential of speech LLMs in scalable pronunciation assessment and suggest future improvements through enhanced prompting, calibration, and phonetic integration to advance Computer-Assisted Pronunciation Training.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16230v1</guid></item><item><title>[cs updates on arXiv.org] Test-Time Adaptation for Speech Emotion Recognition</title><link>https://arxiv.org/abs/2601.16240</link><description>arXiv:2601.16240v1 Announce Type: cross 
Abstract: The practical utility of Speech Emotion Recognition (SER) systems is undermined by their fragility to domain shifts, such as speaker variability, the distinction between acted and naturalistic emotions, and cross-corpus variations. While domain adaptation and fine-tuning are widely studied, they require either source data or labelled target data, which are often unavailable or raise privacy concerns in SER. Test-time adaptation (TTA) bridges this gap by adapting models at inference using only unlabeled target data. Yet, having been predominantly designed for image classification and speech recognition, the efficacy of TTA for mitigating the unique domain shifts in SER has not been investigated. In this paper, we present the first systematic evaluation and comparison covering 11 TTA methods across three representative SER tasks. The results indicate that backpropagation-free TTA methods are the most promising. Conversely, entropy minimization and pseudo-labeling generally fail, as their core assumption of a single, confident ground-truth label is incompatible with the inherent ambiguity of emotional expression. Further, no single method universally excels, and its effectiveness is highly dependent on the distributional shifts and tasks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16240v1</guid></item><item><title>[cs updates on arXiv.org] Distributional Computational Graphs: Error Bounds</title><link>https://arxiv.org/abs/2601.16250</link><description>arXiv:2601.16250v1 Announce Type: cross 
Abstract: We study a general framework of distributional computational graphs: computational graphs whose inputs are probability distributions rather than point values. We analyze the discretization error that arises when these graphs are evaluated using finite approximations of continuous probability distributions. Such an approximation might be the result of representing a continuous real-valued distribution using a discrete representation or from constructing an empirical distribution from samples (or might be the output of another distributional computational graph). We establish non-asymptotic error bounds in terms of the Wasserstein-1 distance, without imposing structural assumptions on the computational graph.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16250v1</guid></item><item><title>[cs updates on arXiv.org] A Constructive Cayley Representation of Orthogonal Matrices and Applications to Optimization</title><link>https://arxiv.org/abs/2601.16271</link><description>arXiv:2601.16271v1 Announce Type: cross 
Abstract: It is known that every real orthogonal matrix can be brought into the domain of the Cayley transform by multiplication with a suitable diagonal signature matrix. In this paper we provide a constructive and numerically efficient algorithm that, given a real orthogonal matrix $U$, computes a diagonal matrix $D$ with entries in $\{\pm1\}$ such that the Cayley transform of $DU$ is well defined. This yields a representation of $U$ in the form \[ U = D(I-S)(I+S)^{-1}, \] where $S$ is a skew-symmetric matrix. The proposed algorithm requires $O(n^{3})$ arithmetic operations and produces an explicit quantitative bound on the associated skew-symmetric generator. As an application, we show how this construction can be used to control singularities in Cayley-transform-based optimization methods on the orthogonal group.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16271v1</guid></item><item><title>[cs updates on arXiv.org] Active learning for photonics</title><link>https://arxiv.org/abs/2601.16287</link><description>arXiv:2601.16287v1 Announce Type: cross 
Abstract: Active learning for photonic crystals explores the integration of analytic approximate Bayesian last layer neural networks (LL-BNNs) with uncertainty-driven sample selection to accelerate photonic band gap prediction. We employ an analytic LL-BNN formulation, corresponding to the infinite Monte Carlo sample limit, to obtain uncertainty estimates that are strongly correlated with the true predictive error on unlabeled candidate structures. These uncertainty scores drive an active learning strategy that prioritizes the most informative simulations during training. Applied to the task of predicting band gap sizes in two-dimensional, two-tone photonic crystals, our approach achieves up to a 2.6x reduction in required training data compared to a random sampling baseline while maintaining predictive accuracy. The efficiency gains arise from concentrating computational resources on high uncertainty regions of the design space rather than sampling uniformly. Given the substantial cost of full band structure simulations, especially in three dimensions, this data efficiency enables rapid and scalable surrogate modeling. Our results suggest that analytic LL-BNN based active learning can substantially accelerate topological optimization and inverse design workflows for photonic crystals, and more broadly, offers a general framework for data efficient regression across scientific machine learning domains.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16287v1</guid></item><item><title>[cs updates on arXiv.org] Maximizing Reach-Avoid Probabilities for Linear Stochastic Systems via Control Architectures</title><link>https://arxiv.org/abs/2601.16290</link><description>arXiv:2601.16290v1 Announce Type: cross 
Abstract: The maximization of reach-avoid probabilities for stochastic systems is a central topic in the control literature. Yet, the available methods are either restricted to low-dimensional systems or suffer from conservative approximations. To address these limitations, we propose control architectures that combine the flexibility of Markov Decision Processes with the scalability of Model Predictive Controllers. The Model Predictive Controller tracks reference signals while remaining agnostic to the stochasticity and reach-avoid objective. Instead, the reach-avoid probability is maximized by optimally updating the controller's reference online. To achieve this, the closed-loop system, consisting of the system and Model Predictive Controller, is abstracted as a Markov Decision Process in which a new reference can be chosen at every time-step. A feedback policy generating optimal references is then computed via Dynamic Programming. If the state space of the system is continuous, the Dynamic Programming algorithm must be executed on a finite system approximation. Modifications to the Model Predictive Controller enable a computationally efficient robustification of the Dynamic Programming algorithm to approximation errors, preserving bounds on the achieved reach-avoid probability. The approach is validated on a perturbed 12D quadcopter model in cluttered reach-avoid environments proving its flexibility and scalability.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16290v1</guid></item><item><title>[cs updates on arXiv.org] EdgeSpot: Efficient and High-Performance Few-Shot Model for Keyword Spotting</title><link>https://arxiv.org/abs/2601.16316</link><description>arXiv:2601.16316v1 Announce Type: cross 
Abstract: We introduce an efficient few-shot keyword spotting model for edge devices, EdgeSpot, that pairs an optimized version of a BC-ResNet-based acoustic backbone with a trainable Per-Channel Energy Normalization frontend and lightweight temporal self-attention. Knowledge distillation is utilized during training by employing a self-supervised teacher model, optimized with Sub-center ArcFace loss. This study demonstrates that the EdgeSpot model consistently provides better accuracy at a fixed false-alarm rate (FAR) than strong BC-ResNet baselines. The largest variant, EdgeSpot-4, improves the 10-shot accuracy at 1% FAR from 73.7% to 82.0%, which requires only 29.4M MACs with 128k parameters.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16316v1</guid></item><item><title>[cs updates on arXiv.org] The Fourier Ratio: A Unifying Measure of Complexity for Recovery, Localization, and Learning</title><link>https://arxiv.org/abs/2601.16345</link><description>arXiv:2601.16345v1 Announce Type: cross 
Abstract: We introduce a generalized Fourier ratio, the \(\ell^1/\ell^2\) norm ratio of coefficients in an \emph{arbitrary} orthonormal system, as a single, basis-invariant measure of \emph{effective dimension} that governs fundamental limits across signal recovery, localization, and learning. First, we prove that functions with small Fourier ratio can be stably recovered from random missing samples via \(\ell^1\) minimization, extending and clarifying compressed sensing guarantees for general bounded orthonormal systems. Second, we establish a sharp \emph{localization obstruction}: any attempt to localize recovery to subslices of a product space necessarily inflates the Fourier ratio by a factor scaling with the square root of the slice count, demonstrating that global complexity cannot be distributed locally. Finally, we show that the same parameter controls key complexity-theoretic measures: it provides explicit upper bounds on Kolmogorov rate-distortion description length and on the statistical query (SQ) dimension of the associated function class. These results unify analytic, algorithmic, and learning-theoretic constraints under a single complexity parameter, revealing the Fourier ratio as a fundamental invariant in information-theoretic signal processing.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16345v1</guid></item><item><title>[cs updates on arXiv.org] Long-Term Probabilistic Forecast of Vegetation Conditions Using Climate Attributes in the Four Corners Region</title><link>https://arxiv.org/abs/2601.16347</link><description>arXiv:2601.16347v1 Announce Type: cross 
Abstract: Weather conditions can drastically alter the state of crops and rangelands, and in turn, impact the incomes and food security of individuals worldwide. Satellite-based remote sensing offers an effective way to monitor vegetation and climate variables on regional and global scales. The annual peak Normalized Difference Vegetation Index (NDVI), derived from satellite observations, is closely associated with crop development, rangeland biomass, and vegetation growth. Although various machine learning methods have been developed to forecast NDVI over short time ranges, such as one-month-ahead predictions, long-term forecasting approaches, such as one-year-ahead predictions of vegetation conditions, are not yet available. To fill this gap, we develop a two-phase machine learning model to forecast the one-year-ahead peak NDVI over high-resolution grids, using the Four Corners region of the Southwestern United States as a testbed. In phase one, we identify informative climate attributes, including precipitation and maximum vapor pressure deficit, and develop the generalized parallel Gaussian process that captures the relationship between climate attributes and NDVI. In phase two, we forecast these climate attributes using historical data at least one year before the NDVI prediction month, which then serve as inputs to forecast the peak NDVI at each spatial grid. We developed open-source tools that outperform alternative methods for both gross NDVI and grid-based NDVI one-year forecasts, providing information that can help farmers and ranchers make actionable plans a year in advance.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16347v1</guid></item><item><title>[cs updates on arXiv.org] TidyVoice: A Curated Multilingual Dataset for Speaker Verification Derived from Common Voice</title><link>https://arxiv.org/abs/2601.16358</link><description>arXiv:2601.16358v1 Announce Type: cross 
Abstract: The development of robust, multilingual speaker recognition systems is hindered by a lack of large-scale, publicly available and multilingual datasets, particularly for the read-speech style crucial for applications like anti-spoofing. To address this gap, we introduce the TidyVoice dataset derived from the Mozilla Common Voice corpus after mitigating its inherent speaker heterogeneity within the provided client IDs. TidyVoice currently contains training and test data from over 212,000 monolingual speakers (Tidy-M) and around 4,500 multilingual speakers (Tidy-X) from which we derive two distinct conditions. The Tidy-M condition contains target and non-target trials from monolingual speakers across 81 languages. The Tidy-X condition contains target and non-target trials from multilingual speakers in both same- and cross-language trials. We employ two architectures of ResNet models, achieving a 0.35% EER by fine-tuning on our comprehensive Tidy-M partition. Moreover, we show that this fine-tuning enhances the model's generalization, improving performance on unseen conversational interview data from the CANDOR corpus. The complete dataset, evaluation trials, and our models are publicly released to provide a new resource for the community.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16358v1</guid></item><item><title>[cs updates on arXiv.org] Experience with Single Domain Generalization in Real World Medical Imaging Deployments</title><link>https://arxiv.org/abs/2601.16359</link><description>arXiv:2601.16359v1 Announce Type: cross 
Abstract: A desirable property of any deployed artificial intelligence is generalization across domains, i.e. data generation distribution under a specific acquisition condition. In medical imagining applications the most coveted property for effective deployment is Single Domain Generalization (SDG), which addresses the challenge of training a model on a single domain to ensure it generalizes well to unseen target domains. In multi-center studies, differences in scanners and imaging protocols introduce domain shifts that exacerbate variability in rare class characteristics. This paper presents our experience on SDG in real life deployment for two exemplary medical imaging case studies on seizure onset zone detection using fMRI data, and stress electrocardiogram based coronary artery detection. Utilizing the commonly used application of diabetic retinopathy, we first demonstrate that state-of-the-art SDG techniques fail to achieve generalized performance across data domains. We then develop a generic expert knowledge integrated deep learning technique DL+EKE and instantiate it for the DR application and show that DL+EKE outperforms SOTA SDG methods on DR. We then deploy instances of DL+EKE technique on the two real world examples of stress ECG and resting state (rs)-fMRI and discuss issues faced with SDG techniques.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16359v1</guid></item><item><title>[cs updates on arXiv.org] On The Robustness of Foundational 3D Medical Image Segmentation Models Against Imprecise Visual Prompts</title><link>https://arxiv.org/abs/2601.16383</link><description>arXiv:2601.16383v1 Announce Type: cross 
Abstract: While 3D foundational models have shown promise for promptable segmentation of medical volumes, their robustness to imprecise prompts remains under-explored. In this work, we aim to address this gap by systematically studying the effect of various controlled perturbations of dense visual prompts, that closely mimic real-world imprecision. By conducting experiments with two recent foundational models on a multi-organ abdominal segmentation task, we reveal several facets of promptable medical segmentation, especially pertaining to reliance on visual shape and spatial cues, and the extent of resilience of models towards certain perturbations. Codes are available at: https://github.com/ucsdbiag/Prompt-Robustness-MedSegFMs</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16383v1</guid></item><item><title>[cs updates on arXiv.org] Auditory Attention Decoding without Spatial Information: A Diotic EEG Study</title><link>https://arxiv.org/abs/2601.16442</link><description>arXiv:2601.16442v1 Announce Type: cross 
Abstract: Auditory attention decoding (AAD) identifies the attended speech stream in multi-speaker environments by decoding brain signals such as electroencephalography (EEG). This technology is essential for realizing smart hearing aids that address the cocktail party problem and for facilitating objective audiometry systems. Existing AAD research mainly utilizes dichotic environments where different speech signals are presented to the left and right ears, enabling models to classify directional attention rather than speech content. However, this spatial reliance limits applicability to real-world scenarios, such as the "cocktail party" situation, where speakers overlap or move dynamically. To address this challenge, we propose an AAD framework for diotic environments where identical speech mixtures are presented to both ears, eliminating spatial cues. Our approach maps EEG and speech signals into a shared latent space using independent encoders. We extract speech features using wav2vec 2.0 and encode them with a 2-layer 1D convolutional neural network (CNN), while employing the BrainNetwork architecture for EEG encoding. The model identifies the attended speech by calculating the cosine similarity between EEG and speech representations. We evaluate our method on a diotic EEG dataset and achieve 72.70% accuracy, which is 22.58% higher than the state-of-the-art direction-based AAD method.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16442v1</guid></item><item><title>[cs updates on arXiv.org] Learning Successive Interference Cancellation for Low-Complexity Soft-Output MIMO Detection</title><link>https://arxiv.org/abs/2601.16586</link><description>arXiv:2601.16586v1 Announce Type: cross 
Abstract: Low-complexity multiple-input multiple-output (MIMO) detection remains a key challenge in modern wireless systems, particularly for 5G reduced capability (RedCap) and internet-of-things (IoT) devices. In this context, the growing interest in deploying machine learning on edge devices must be balanced against stringent constraints on computational complexity and memory while supporting high-order modulation. Beyond accurate hard detection, reliable soft information is equally critical, as modern receivers rely on soft-input channel decoding, imposing additional requirements on the detector design. In this work, we propose recurSIC, a lightweight learning-based MIMO detection framework that is structurally inspired by successive interference cancellation (SIC) and incorporates learned processing stages. It generates reliable soft information via multi-path hypothesis tracking with a tunable complexity parameter while requiring only a single forward pass and a minimal parameter count. Numerical results in realistic wireless scenarios show that recurSIC achieves strong hard- and soft-detection performance at very low complexity, making it well suited for edge-constrained MIMO receivers.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16586v1</guid></item><item><title>[cs updates on arXiv.org] Efficient Learning of Stationary Diffusions with Stein-type Discrepancies</title><link>https://arxiv.org/abs/2601.16597</link><description>arXiv:2601.16597v1 Announce Type: cross 
Abstract: Learning a stationary diffusion amounts to estimating the parameters of a stochastic differential equation whose stationary distribution matches a target distribution. We build on the recently introduced kernel deviation from stationarity (KDS), which enforces stationarity by evaluating expectations of the diffusion's generator in a reproducing kernel Hilbert space. Leveraging the connection between KDS and Stein discrepancies, we introduce the Stein-type KDS (SKDS) as an alternative formulation. We prove that a vanishing SKDS guarantees alignment of the learned diffusion's stationary distribution with the target. Furthermore, under broad parametrizations, SKDS is convex with an empirical version that is $\epsilon$-quasiconvex with high probability. Empirically, learning with SKDS attains comparable accuracy to KDS while substantially reducing computational cost and yields improvements over the majority of competitive baselines.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16597v1</guid></item><item><title>[cs updates on arXiv.org] Unsupervised Super-Resolution of Hyperspectral Remote Sensing Images Using Fully Synthetic Training</title><link>https://arxiv.org/abs/2601.16602</link><description>arXiv:2601.16602v1 Announce Type: cross 
Abstract: Considerable work has been dedicated to hyperspectral single image super-resolution to improve the spatial resolution of hyperspectral images and fully exploit their potential. However, most of these methods are supervised and require some data with ground truth for training, which is often non-available. To overcome this problem, we propose a new unsupervised training strategy for the super-resolution of hyperspectral remote sensing images, based on the use of synthetic abundance data. Its first step decomposes the hyperspectral image into abundances and endmembers by unmixing. Then, an abundance super-resolution neural network is trained using synthetic abundances, which are generated using the dead leaves model in such a way as to faithfully mimic real abundance statistics. Next, the spatial resolution of the considered hyperspectral image abundances is increased using this trained network, and the high resolution hyperspectral image is finally obtained by recombination with the endmembers. Experimental results show the training potential of the synthetic images, and demonstrate the method effectiveness.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16602v1</guid></item><item><title>[cs updates on arXiv.org] PanopMamba: Vision State Space Modeling for Nuclei Panoptic Segmentation</title><link>https://arxiv.org/abs/2601.16631</link><description>arXiv:2601.16631v1 Announce Type: cross 
Abstract: Nuclei panoptic segmentation supports cancer diagnostics by integrating both semantic and instance segmentation of different cell types to analyze overall tissue structure and individual nuclei in histopathology images. Major challenges include detecting small objects, handling ambiguous boundaries, and addressing class imbalance. To address these issues, we propose PanopMamba, a novel hybrid encoder-decoder architecture that integrates Mamba and Transformer with additional feature-enhanced fusion via state space modeling. We design a multiscale Mamba backbone and a State Space Model (SSM)-based fusion network to enable efficient long-range perception in pyramid features, thereby extending the pure encoder-decoder framework while facilitating information sharing across multiscale features of nuclei. The proposed SSM-based feature-enhanced fusion integrates pyramid feature networks and dynamic feature enhancement across different spatial scales, enhancing the feature representation of densely overlapping nuclei in both semantic and spatial dimensions. To the best of our knowledge, this is the first Mamba-based approach for panoptic segmentation. Additionally, we introduce alternative evaluation metrics, including image-level Panoptic Quality ($i$PQ), boundary-weighted PQ ($w$PQ), and frequency-weighted PQ ($fw$PQ), which are specifically designed to address the unique challenges of nuclei segmentation and thereby mitigate the potential bias inherent in vanilla PQ. Experimental evaluations on two multiclass nuclei segmentation benchmark datasets, MoNuSAC2020 and NuInsSeg, demonstrate the superiority of PanopMamba for nuclei panoptic segmentation over state-of-the-art methods. Consequently, the robustness of PanopMamba is validated across various metrics, while the distinctiveness of PQ variants is also demonstrated. Code is available at https://github.com/mkang315/PanopMamba.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16631v1</guid></item><item><title>[cs updates on arXiv.org] Fast, faithful and photorealistic diffusion-based image super-resolution with enhanced Flow Map models</title><link>https://arxiv.org/abs/2601.16660</link><description>arXiv:2601.16660v1 Announce Type: cross 
Abstract: Diffusion-based image super-resolution (SR) has recently attracted significant attention by leveraging the expressive power of large pre-trained text-to-image diffusion models (DMs). A central practical challenge is resolving the trade-off between reconstruction faithfulness and photorealism. To address inference efficiency, many recent works have explored knowledge distillation strategies specifically tailored to SR, enabling one-step diffusion-based approaches. However, these teacher-student formulations are inherently constrained by information compression, which can degrade perceptual cues such as lifelike textures and depth of field, even with high overall perceptual quality. In parallel, self-distillation DMs, known as Flow Map models, have emerged as a promising alternative for image generation tasks, enabling fast inference while preserving the expressivity and training stability of standard DMs. Building on these developments, we propose FlowMapSR, a novel diffusion-based framework for image super-resolution explicitly designed for efficient inference. Beyond adapting Flow Map models to SR, we introduce two complementary enhancements: (i) positive-negative prompting guidance, based on a generalization of classifier free-guidance paradigm to Flow Map models, and (ii) adversarial fine-tuning using Low-Rank Adaptation (LoRA). Among the considered Flow Map formulations (Eulerian, Lagrangian, and Shortcut), we find that the Shortcut variant consistently achieves the best performance when combined with these enhancements. Extensive experiments show that FlowMapSR achieves a better balance between reconstruction faithfulness and photorealism than recent state-of-the-art methods for both x4 and x8 upscaling, while maintaining competitive inference time. Notably, a single model is used for both upscaling factors, without any scale-specific conditioning or degradation-guided mechanisms.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16660v1</guid></item><item><title>[cs updates on arXiv.org] SeeMPS: A Python-based Matrix Product State and Tensor Train Library</title><link>https://arxiv.org/abs/2601.16734</link><description>arXiv:2601.16734v1 Announce Type: cross 
Abstract: We introduce SeeMPS, a Python library dedicated to implementing tensor network algorithms based on the well-known Matrix Product States (MPS) and Quantized Tensor Train (QTT) formalisms. SeeMPS is implemented as a complete finite precision linear algebra package where exponentially large vector spaces are compressed using the MPS/TT formalism. It enables both low-level operations, such as vector addition, linear transformations, and Hadamard products, as well as high-level algorithms, including the approximation of linear equations, eigenvalue computations, and exponentially efficient Fourier transforms. This library can be used for traditional quantum many-body physics applications and also for quantum-inspired numerical analysis problems, such as solving PDEs, interpolating and integrating multidimensional functions, sampling multivariate probability distributions, etc.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16734v1</guid></item><item><title>[cs updates on arXiv.org] Noise Resilience and Robust Convergence Guarantees for the Variational Quantum Eigensolver</title><link>https://arxiv.org/abs/2601.16758</link><description>arXiv:2601.16758v1 Announce Type: cross 
Abstract: Variational Quantum Algorithms (VQAs) are a class of hybrid quantum-classical algorithms that leverage on classical optimization tools to find the optimal parameters for a parameterized quantum circuit. One relevant application of VQAs is the Variational Quantum Eigensolver (VQE), which aims at steering the output of the quantum circuit to the ground state of a certain Hamiltonian. Recent works have provided global convergence guarantees for VQEs under suitable local surjectivity and smoothness hypotheses, but little has been done in characterizing convergence of these algorithms when the underlying quantum circuit is affected by noise. In this work, we characterize the effect of different coherent and incoherent noise processes on the optimal parameters and the optimal cost of the VQE, and we study their influence on the convergence guarantees of the algorithm. Our work provides novel theoretical insight into the behavior of parameterized quantum circuits. Furthermore, we accompany our results with numerical simulations implemented via Pennylane.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16758v1</guid></item><item><title>[cs updates on arXiv.org] Kernel smoothing on manifolds</title><link>https://arxiv.org/abs/2601.16777</link><description>arXiv:2601.16777v1 Announce Type: cross 
Abstract: Under the assumption that data lie on a compact (unknown) manifold without boundary, we derive finite sample bounds for kernel smoothing and its (first and second) derivatives, and we establish asymptotic normality through Berry-Esseen type bounds. Special cases include kernel density estimation, kernel regression and the heat kernel signature. Connections to the graph Laplacian are also discussed.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16777v1</guid></item><item><title>[cs updates on arXiv.org] PocketDVDNet: Realtime Video Denoising for Real Camera Noise</title><link>https://arxiv.org/abs/2601.16780</link><description>arXiv:2601.16780v1 Announce Type: cross 
Abstract: Live video denoising under realistic, multi-component sensor noise remains challenging for applications such as autofocus, autonomous driving, and surveillance. We propose PocketDVDNet, a lightweight video denoiser developed using our model compression framework that combines sparsity-guided structured pruning, a physics-informed noise model, and knowledge distillation to achieve high-quality restoration with reduced resource demands. Starting from a reference model, we induce sparsity, apply targeted channel pruning, and retrain a teacher on realistic multi-component noise. The student network learns implicit noise handling, eliminating the need for explicit noise-map inputs. PocketDVDNet reduces the original model size by 74% while improving denoising quality and processing 5-frame patches in real-time. These results demonstrate that aggressive compression, combined with domain-adapted distillation, can reconcile performance and efficiency for practical, real-time video denoising.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16780v1</guid></item><item><title>[cs updates on arXiv.org] Harnessing Quantum Computing for Energy Materials: Opportunities and Challenges</title><link>https://arxiv.org/abs/2601.16816</link><description>arXiv:2601.16816v1 Announce Type: cross 
Abstract: Developing high-performance materials is critical for diverse energy applications to increase efficiency, improve sustainability and reduce costs. Classical computational methods have enabled important breakthroughs in energy materials development, but they face scaling and time-complexity limitations, particularly for high-dimensional or strongly correlated material systems. Quantum computing (QC) promises to offer a paradigm shift by exploiting quantum bits with their superposition and entanglement to address challenging problems intractable for classical approaches. This perspective discusses the opportunities in leveraging QC to advance energy materials research and the challenges QC faces in solving complex and high-dimensional problems. We present cases on how QC, when combined with classical computing methods, can be used for the design and simulation of practical energy materials. We also outline the outlook for error-corrected, fault-tolerant QC capable of achieving predictive accuracy and quantum advantage for complex material systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16816v1</guid></item><item><title>[cs updates on arXiv.org] BONO-Bench: A Comprehensive Test Suite for Bi-objective Numerical Optimization with Traceable Pareto Sets</title><link>https://arxiv.org/abs/2601.16970</link><description>arXiv:2601.16970v1 Announce Type: cross 
Abstract: The evaluation of heuristic optimizers on test problems, better known as \emph{benchmarking}, is a cornerstone of research in multi-objective optimization.
  However, most test problems used in benchmarking numerical multi-objective black-box optimizers come from one of two flawed approaches: On the one hand, problems are constructed manually, which result in problems with well-understood optimal solutions, but unrealistic properties and biases.
  On the other hand, more realistic and complex single-objective problems are composited into multi-objective problems, but with a lack of control and understanding of problem properties.
  This paper proposes an extensive problem generation approach for bi-objective numerical optimization problems consisting of the combination of theoretically well-understood convex-quadratic functions into unimodal and multimodal landscapes with and without global structure.
  It supports configuration of test problem properties, such as the number of decision variables, local optima, Pareto front shape, plateaus in the objective space, or degree of conditioning, while maintaining theoretical tractability: The optimal front can be approximated to an arbitrary degree of precision regarding Pareto-compliant performance indicators such as the hypervolume or the exact R2 indicator.
  To demonstrate the generator's capabilities, a test suite of 20 problem categories, called \emph{BONO-Bench}, is created and subsequently used as a basis of an illustrative benchmark study.
  Finally, the general approach underlying our proposed generator, together with the associated test suite, is publicly released in the Python package \texttt{bonobench} to facilitate reproducible benchmarking.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16970v1</guid></item><item><title>[cs updates on arXiv.org] On the logical structure of choice and bar induction principles</title><link>https://arxiv.org/abs/2105.08951</link><description>arXiv:2105.08951v4 Announce Type: replace 
Abstract: We develop an approach to choice principles and their contrapositive bar-induction principles as extensionality schemes connecting an ''intensional'' or ''effective'' view of respectively ill-and well-foundedness properties to an ''extensional'' or ''ideal'' view of these properties. After classifying and analysing the relations between different intensional definitions of ill-foundedness and well-foundedness, we introduce, for a domain $A$, a codomain $B$ and a ''filter'' $T$ on finite approximations of functions from $A$ to $B$, a generalised form GDC$_{A,B,T}$ of the axiom of dependent choice and dually a generalised bar induction principle GBI$_{A,B,T}$ such that: - GDC$_{A,B,T}$ intuitionistically captures the strength of $\bullet$ the general axiom of choice expressed as $\forall a\exists\beta R(a, b) \Rightarrow\exists\alpha\forall a R(\alpha,(a \alpha (a)))$ when $T$ is a filter that derives point-wise from a relation $R$ on $A x B$ without introducing further constraints, $\bullet$ the Boolean Prime Filter Theorem / Ultrafilter Theorem if $B$ is the two-element set $\mathbb{B}$ (for a constructive definition of prime filter), $\bullet$ the axiom of dependent choice if $A = \mathbb{N}$, $\bullet$ Weak K{\"o}nig's Lemma if $A = \mathbb{N}$ and $B = \mathbb{B}$ (up to weak classical reasoning) - GBI$_{A,B,T}$ intuitionistically captures the strength of $\bullet$ G{\"o}del's completeness theorem in the form validity implies provability for entailment relations if $B = \mathbb{B}$, $\bullet$ bar induction when $A = \mathbb{N}$, $\bullet$ the Weak Fan Theorem when $A = \mathbb{N}$ and $B = \mathbb{B}$. Contrastingly, even though GDC$_{A,B,T}$ and GBI$_{A,B,T}$ smoothly capture several variants of choice and bar induction, some instances are inconsistent, e.g. when $A$ is $\mathbb{B}^\mathbb{N}$ and $B$ is $\mathbb{N}$.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2105.08951v4</guid></item><item><title>[cs updates on arXiv.org] Vertical Semi-Federated Learning for Efficient Online Advertising</title><link>https://arxiv.org/abs/2209.15635</link><description>arXiv:2209.15635v4 Announce Type: replace 
Abstract: Traditional vertical federated learning schema suffers from two main issues: 1) restricted applicable scope to overlapped samples and 2) high system challenge of real-time federated serving, which limits its application to advertising systems. To this end, we advocate a new practical learning setting, Semi-VFL (Vertical Semi-Federated Learning), for real-world industrial applications, where the learned model retains sufficient advantages of federated learning while supporting independent local serving. To achieve this goal, we propose the carefully designed Joint Privileged Learning framework (JPL) to i) alleviate the absence of the passive party's feature with federated equivalence imitation and ii) adapt to the heterogeneous full sample space with cross-branch rank alignment. Extensive experiments conducted on real-world advertising datasets validate the effectiveness of our method over baseline methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2209.15635v4</guid></item><item><title>[cs updates on arXiv.org] RevaMp3D: Architecting the Processor Core and Cache Hierarchy for Systems with Monolithically-Integrated Logic and Memory</title><link>https://arxiv.org/abs/2210.08508</link><description>arXiv:2210.08508v3 Announce Type: replace 
Abstract: Recent nano-technological advances enable the Monolithic 3D (M3D) integration of multiple memory and logic layers in a single chip, allowing for fine-grained connections between layers and significantly alleviating main memory bottlenecks. We show for a variety of workloads, on a state-of-the-art M3D-based system, that the performance and energy bottlenecks shift from main memory to the processor core and cache hierarchy. Therefore, there is a need to revisit current designs that have been conventionally tailored to tackle the memory bottleneck. Based on the insights from our design space exploration, we propose RevaMp3D, introducing five key changes. First, we propose removing the shared last-level cache, as this delivers speedups comparable to or exceeding those from increasing its size or reducing its latency across all workloads. Second, since improving L1 cache latency has a large impact on performance, we reduce L1 latency by leveraging an M3D layout to shorten its wires. Third, we repurpose the area from the removed cache to widen and scale up pipeline structures, accommodating more in-flight requests that are efficiently served by M3D memory. To avoid latency penalties from these larger structures, we leverage M3D layouts. Fourth, to facilitate high thread-level parallelism, we propose a new fine-grained synchronization technique, using M3D's dense inter-layer connectivity. Fifth, we leverage the M3D main memory to mitigate the core bottlenecks. We propose a processor frontend design that memoizes the repetitive fetched, decoded, and reordered instructions, stores them in main memory, and turns off the relevant parts of the core when possible. RevaMp3D provides 1.2x-2.9x speedup and 1.2x-1.4x energy reduction compared to a state-of-the-art M3D system. We also analyze RevaMp3D's design decisions across various memory latencies to facilitate latency-aware design decisions.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2210.08508v3</guid></item><item><title>[cs updates on arXiv.org] Task Aware Dreamer for Task Generalization in Reinforcement Learning</title><link>https://arxiv.org/abs/2303.05092</link><description>arXiv:2303.05092v5 Announce Type: replace 
Abstract: A long-standing goal of reinforcement learning is to acquire agents that can learn on training tasks and generalize well on unseen tasks that may share a similar dynamic but with different reward functions. The ability to generalize across tasks is important as it determines an agent's adaptability to real-world scenarios where reward mechanisms might vary. In this work, we first show that training a general world model can utilize similar structures in these tasks and help train more generalizable agents. Extending world models into the task generalization setting, we introduce a novel method named Task Aware Dreamer (TAD), which integrates reward-informed features to identify consistent latent characteristics across tasks. Within TAD, we compute the variational lower bound of sample data log-likelihood, which introduces a new term designed to differentiate tasks using their states, as the optimization objective of our reward-informed world models. To demonstrate the advantages of the reward-informed policy in TAD, we introduce a new metric called Task Distribution Relevance (TDR) which quantitatively measures the relevance of different tasks. For tasks exhibiting a high TDR, i.e., the tasks differ significantly, we illustrate that Markovian policies struggle to distinguish them, thus it is necessary to utilize reward-informed policies in TAD. Extensive experiments in both image-based and state-based tasks show that TAD can significantly improve the performance of handling different tasks simultaneously, especially for those with high TDR, and display a strong generalization ability to unseen tasks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2303.05092v5</guid></item><item><title>[cs updates on arXiv.org] Entire Chain Uplift Modeling with Context-Enhanced Learning for Intelligent Marketing</title><link>https://arxiv.org/abs/2402.03379</link><description>arXiv:2402.03379v2 Announce Type: replace 
Abstract: Uplift modeling, vital in online marketing, seeks to accurately measure the impact of various strategies, such as coupons or discounts, on different users by predicting the Individual Treatment Effect (ITE). In an e-commerce setting, user behavior follows a defined sequential chain, including impression, click, and conversion. Marketing strategies exert varied uplift effects at each stage within this chain, impacting metrics like click-through and conversion rate. Despite its utility, existing research has neglected to consider the inter-task across all stages impacts within a specific treatment and has insufficiently utilized the treatment information, potentially introducing substantial bias into subsequent marketing decisions. We identify these two issues as the chain-bias problem and the treatment-unadaptive problem. This paper introduces the Entire Chain UPlift method with context-enhanced learning (ECUP), devised to tackle these issues. ECUP consists of two primary components: 1) the Entire Chain-Enhanced Network, which utilizes user behavior patterns to estimate ITE throughout the entire chain space, models the various impacts of treatments on each task, and integrates task prior information to enhance context awareness across all stages, capturing the impact of treatment on different tasks, and 2) the Treatment-Enhanced Network, which facilitates fine-grained treatment modeling through bit-level feature interactions, thereby enabling adaptive feature adjustment. Extensive experiments on public and industrial datasets validate ECUPs effectiveness. Moreover, ECUP has been deployed on the Meituan food delivery platform, serving millions of daily active users, with the related dataset released for future research.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2402.03379v2</guid></item><item><title>[cs updates on arXiv.org] Comparing Specialised Small and General Large Language Models on Text Classification: 100 Labelled Samples to Achieve Break-Even Performance</title><link>https://arxiv.org/abs/2402.12819</link><description>arXiv:2402.12819v4 Announce Type: replace 
Abstract: When solving NLP tasks with limited labelled data, researchers typically either use a general large language model without further update, or use a small number of labelled samples to tune a specialised smaller model. In this work, we answer an important question -- how many labelled samples are required for the specialised small models to outperform general large models, while taking the performance variance into consideration. By observing the behaviour of fine-tuning, instruction-tuning, prompting and in-context learning on 8 language models, we identify such performance break-even points across 8 representative text classification tasks of varying characteristics. We show that the specialised models often need only few samples (on average $100$) to be on par or better than the general ones. At the same time, the number of required labels strongly depends on the dataset or task characteristics, with fine-tuning on binary datasets requiring significantly more samples. When performance variance is taken into consideration, the number of required labels increases on average by $100 - 200\%$. Finally, larger models do not consistently lead to better performance and lower variance, with 4-bit quantisation having negligible impact.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2402.12819v4</guid></item><item><title>[cs updates on arXiv.org] Full-Duplex Multiuser MISO Under Coarse Quantization: Per-Antenna SQNR Analysis and Beamforming Design</title><link>https://arxiv.org/abs/2403.11762</link><description>arXiv:2403.11762v3 Announce Type: replace 
Abstract: We investigate full-duplex (FD) multi-user multiple input single-output systems with coarse quantization, aiming to characterize the impact of employing low-resolution analog-to-digital converters (ADCs) on self-interference (SI) and to develop a quantization- and SI-aware beamforming method that alleviates quantization-induced performance degradation in the FD systems. We first present an analysis on the perantenna signal-to-quantization noise ratio for conventional linear beamformers to provide the desired range of the number of analog-to-digital converter (ADC) bits, providing system insights for reliable FD operation in regard to the ADC resolution and beamforming strategy. Motivated by the insights, we then propose an SI-aware beamforming method that mitigates residual SI and quantization distortion. The resulting spectral efficiency (SE) maximization problem is decomposed into two tractable subproblems solved via alternating optimization: precoder and combiner design. The precoder optimization is formulated as a generalized eigenvalue problem, where the dominant eigenvector yields the best stationary solution through power iteration, while the combiner is derived as a quantization-aware minimum meansquared error (MMSE) filter. Numerical studies show that the number of required ADC bits with the proposed beamforming falls within the derived theoretical range while achieving the highest SE compared to benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2403.11762v3</guid></item><item><title>[cs updates on arXiv.org] Simple-Sampling and Hard-Mixup with Prototypes to Rebalance Contrastive Learning for Text Classification</title><link>https://arxiv.org/abs/2405.11524</link><description>arXiv:2405.11524v2 Announce Type: replace 
Abstract: Text classification is a crucial and fundamental task in web content mining. Compared with the previous learning paradigm of pre-training and fine-tuning by cross entropy loss, the recently proposed supervised contrastive learning approach has received tremendous attention due to its powerful feature learning capability and robustness. Although several studies have incorporated this technique for text classification, some limitations remain. First, many text datasets are imbalanced, and the learning mechanism of supervised contrastive learning is sensitive to data imbalance, which may harm the model's performance. Moreover, these models leverage separate classification branches with cross entropy and supervised contrastive learning branches without explicit mutual guidance. To this end, we propose a novel model named SharpReCL for imbalanced text classification tasks. First, we obtain the prototype vector of each class in the balanced classification branch to act as a representation of each class. Then, by further explicitly leveraging the prototype vectors, we construct a proper and sufficient target sample set with the same size for each class to perform the supervised contrastive learning procedure. The empirical results show the effectiveness of our model, which even outperforms popular large language models across several datasets. Our code is available here.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2405.11524v2</guid></item><item><title>[cs updates on arXiv.org] PanoNormal: Monocular Indoor 360{\deg} Surface Normal Estimation</title><link>https://arxiv.org/abs/2405.18745</link><description>arXiv:2405.18745v2 Announce Type: replace 
Abstract: The presence of spherical distortion in equirectangular projection (ERP) images presents a persistent challenge in dense regression tasks such as surface normal estimation. Although it may appear straightforward to repurpose architectures developed for 360{\deg} depth estimation, our empirical findings indicate that such models yield suboptimal performance when applied to surface normal prediction. This is largely attributed to their architectural bias toward capturing global scene layout, which comes at the expense of the fine-grained local geometric cues that are critical for accurate surface orientation estimation. While convolutional neural networks (CNNs) have been employed to mitigate spherical distortion, their fixed receptive fields limit their ability to capture holistic scene structure. Conversely, vision transformers (ViTs) are capable of modeling long-range dependencies via global self-attention, but often fail to preserve high-frequency local detail. To address these limitations, we propose \textit{PanoNormal}, a monocular surface normal estimation architecture for 360{\deg} images that integrates the complementary strengths of CNNs and ViTs. In particular, we design a multi-level global self-attention mechanism that explicitly accounts for the spherical feature distribution, enabling our model to recover both global contextual structure and local geometric details. Experimental results demonstrate that our method not only achieves state-of-the-art performance on several benchmark 360{\deg} datasets, but also significantly outperforms adapted depth estimation models on the task of surface normal prediction. The code and model are available at https://github.com/huangkun101230/PanoNormal.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2405.18745v2</guid></item><item><title>[cs updates on arXiv.org] ProSub: Probabilistic Open-Set Semi-Supervised Learning with Subspace-Based Out-of-Distribution Detection</title><link>https://arxiv.org/abs/2407.11735</link><description>arXiv:2407.11735v2 Announce Type: replace 
Abstract: In open-set semi-supervised learning (OSSL), we consider unlabeled datasets that may contain unknown classes. Existing OSSL methods often use the softmax confidence for classifying data as in-distribution (ID) or out-of-distribution (OOD). Additionally, many works for OSSL rely on ad-hoc thresholds for ID/OOD classification, without considering the statistics of the problem. We propose a new score for ID/OOD classification based on angles in feature space between data and an ID subspace. Moreover, we propose an approach to estimate the conditional distributions of scores given ID or OOD data, enabling probabilistic predictions of data being ID or OOD. These components are put together in a framework for OSSL, termed ProSub, that is experimentally shown to reach SOTA performance on several benchmark problems. Our code is available at https://github.com/walline/prosub.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2407.11735v2</guid></item><item><title>[cs updates on arXiv.org] Provable Differentially Private Computation of the Cross-Attention Mechanism</title><link>https://arxiv.org/abs/2407.14717</link><description>arXiv:2407.14717v3 Announce Type: replace 
Abstract: Cross-attention has emerged as a cornerstone module in modern artificial intelligence, underpinning critical applications such as retrieval-augmented generation (RAG), system prompting, and guided stable diffusion. However, this is a rising concern about securing the privacy of cross-attention, as the underlying key and value matrices frequently encode sensitive data or private user information. In this work, we introduce a novel data structure designed to enforce differential privacy (DP) for cross-attention mechanisms, accompanied by provable theoretical guarantees. Specifically, letting $n$ denote the input sequence length, $d$ the feature dimension, $R$ the maximum magnitude of query and key matrices, $R_w$ the maximum magnitude of the value matrix, and $r, s, \epsilon_s$ the parameters for polynomial kernel methods, our proposed structure achieves $\widetilde{O}(ndr^2)$ space and initialization complexity, with a query time of $\widetilde{O}(d r^2)$ per token. Moreover, we demonstrate that our mechanism satisfies $(\epsilon, \delta)$-DP, incurring an additive error of $\widetilde{O}((1-\epsilon_s)^{-1} n^{-1} \epsilon^{-1} R^{2s} R_w r^2)$ and a relative error of $2\epsilon_s/(1-\epsilon_s)$ with respect to the ground truth. Crucially, our framework maintains robustness against adaptive queries, ensuring security even in adversarial settings. To the best of our knowledge, this constitutes the first approach providing provable differential privacy for cross-attention, establishing a foundation for future privacy-preserving algorithms in large generative models (LGMs).</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2407.14717v3</guid></item><item><title>[cs updates on arXiv.org] Faster algorithms for packing forests in graphs and related problems</title><link>https://arxiv.org/abs/2409.20314</link><description>arXiv:2409.20314v3 Announce Type: replace 
Abstract: We consider several problems related to packing forests in graphs. The first one is to find $k$ edge-disjoint forests in a directed graph $G$ of maximal size such that the indegree of each vertex in these forests is at most $k$. We describe a min-max characterization for this problem and show that it can be solved in almost linear time for fixed $k$, extending the algorithm of [Gabow, 1995]. Specifically, the complexity is $O(k \delta m \log n)$, where $n, m$ are the number of vertices and edges in $G$ respectively, and $\delta = \max\{1, k - k_G\}$, where $k_G$ is the edge connectivity of the graph. Using our solution to this problem, we improve complexities for two existing applications:
  (1) $k$-forest problem: find $k$ forests in an undirected graph $G$ maximizing the number of edges in their union. We show how to solve this problem in $O(k^3 \min\{kn, m\} \log^2 n + k \cdot{\rm MAXFLOW}(m, m) \log n)$ time, breaking the $O_k(n^{3/2})$ complexity barrier of previously known approaches.
  (2) Directed edge-connectivity augmentation problem: find a smallest set of directed edges whose addition to the given directed graph makes it strongly $k$-connected. We improve the deterministic complexity for this problem from $O(k \delta (m+\delta n)\log n)$ [Gabow, STOC 1994] to $O(k \delta m \log n)$. A similar approach with the same complexity also works for the undirected version of the problem.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2409.20314v3</guid></item><item><title>[cs updates on arXiv.org] Linguistic traces of stochastic empathy in language models</title><link>https://arxiv.org/abs/2410.01675</link><description>arXiv:2410.01675v2 Announce Type: replace 
Abstract: Differentiating generated and human-written content is increasingly difficult. We examine how an incentive to convey humanness and task characteristics shape this human vs AI race across five studies. In Study 1-2 (n=530 and n=610) humans and a large language model (LLM) wrote relationship advice or relationship descriptions, either with or without instructions to sound human. New participants (n=428 and n=408) judged each text's source. Instructions to sound human were only effective for the LLM, reducing the human advantage. Study 3 (n=360 and n=350) showed that these effects persist when writers were instructed to avoid sounding like an LLM. Study 4 (n=219) tested empathy as mechanism of humanness and concluded that LLMs can produce empathy without humanness and humanness without empathy. Finally, computational text analysis (Study 5) indicated that LLMs become more human-like by applying an implicit representation of humanness to mimic stochastic empathy.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2410.01675v2</guid></item><item><title>[cs updates on arXiv.org] Unified Multimodal Interleaved Document Representation for Retrieval</title><link>https://arxiv.org/abs/2410.02729</link><description>arXiv:2410.02729v3 Announce Type: replace 
Abstract: Information Retrieval (IR) methods aim to identify documents relevant to a query, which have been widely applied in various natural language tasks. However, existing approaches typically consider only the textual content within documents, overlooking the fact that documents can contain multiple modalities, including images and tables. Also, they often segment each long document into multiple discrete passages for embedding, which prevents them from capturing the overall document context and interactions between paragraphs. To address these two challenges, we propose a method that holistically embeds documents interleaved with multiple modalities by leveraging the capability of recent vision-language models that enable the processing and integration of text, images, and tables into a unified format and representation. Moreover, to mitigate the information loss from segmenting documents into passages, instead of representing and retrieving passages individually, we further merge the representations of segmented passages into one single document representation, while we additionally introduce a reranking strategy to decouple and identify the relevant passage within the document if necessary. Then, through extensive experiments on diverse IR scenarios considering both the textual and multimodal queries, we show that our approach substantially outperforms relevant baselines, thanks to the consideration of the multimodal information within documents.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2410.02729v3</guid></item><item><title>[cs updates on arXiv.org] On Fine-Grained I/O Complexity of Attention Backward Passes</title><link>https://arxiv.org/abs/2410.09397</link><description>arXiv:2410.09397v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) exhibit exceptional proficiency in handling extensive context windows in natural language. Nevertheless, the quadratic scaling of attention computation relative to sequence length creates substantial efficiency bottlenecks, necessitating the development of I/O-optimized algorithms. In this work, we conduct a systematic examination of the I/O complexity inherent in attention mechanisms, with a specific emphasis on the backward pass under both small and large cache settings. By leveraging the red-blue pebble game framework, we derive tight bounds for I/O complexity across the full spectrum of cache sizes. We validate that FlashAttention, one of the current industry standards, achieves optimality in the large-cache scenario for both forward and backward passes. Conversely, for small-cache environments, we introduce a novel algorithm that outperforms contemporary methods and successfully attains theoretical tight bounds. Furthermore, we expand our investigation to include sparse attention by establishing granular lower bounds for both forward and backward passes across all cache configurations. Ultimately, our results solidify the theoretical framework regarding I/O complexity in attention mechanisms, providing critical guidance for the development of efficient LLM training and inference systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2410.09397v2</guid></item><item><title>[cs updates on arXiv.org] PRACTIQ: A Practical Conversational Text-to-SQL dataset with Ambiguous and Unanswerable Queries</title><link>https://arxiv.org/abs/2410.11076</link><description>arXiv:2410.11076v2 Announce Type: replace 
Abstract: Previous text-to-SQL datasets and systems have primarily focused on user questions with clear intentions that can be answered. However, real user questions can often be ambiguous with multiple interpretations or unanswerable due to a lack of relevant data. In this work, we construct a practical conversational text-to-SQL dataset called PRACTIQ, consisting of ambiguous and unanswerable questions inspired by real-world user questions. We first identified four categories of ambiguous questions and four categories of unanswerable questions by studying existing text-to-SQL datasets. Then, we generate conversations with four turns: the initial user question, an assistant response seeking clarification, the user's clarification, and the assistant's clarified SQL response with the natural language explanation of the execution results. For some ambiguous queries, we also directly generate helpful SQL responses, that consider multiple aspects of ambiguity, instead of requesting user clarification. To benchmark the performance on ambiguous, unanswerable, and answerable questions, we implemented large language model (LLM)-based baselines using various LLMs. Our approach involves two steps: question category classification and clarification SQL prediction. Our experiments reveal that state-of-the-art systems struggle to handle ambiguous and unanswerable questions effectively. We will release our code for data generation and experiments on GitHub.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2410.11076v2</guid></item><item><title>[cs updates on arXiv.org] ProveRAG: Provenance-Driven Vulnerability Analysis with Automated Retrieval-Augmented LLMs</title><link>https://arxiv.org/abs/2410.17406</link><description>arXiv:2410.17406v3 Announce Type: replace 
Abstract: In cybersecurity, security analysts constantly face the challenge of mitigating newly discovered vulnerabilities in real-time, with over 300,000 vulnerabilities identified since 1999. The sheer volume of known vulnerabilities complicates the detection of patterns for unknown threats. While LLMs can assist, they often hallucinate and lack alignment with recent threats. Over 40,000 vulnerabilities have been identified in 2024 alone, which are introduced after most popular LLMs' (e.g., GPT-5) training data cutoff. This raises a major challenge of leveraging LLMs in cybersecurity, where accuracy and up-to-date information are paramount. Therefore, we aim to improve the adaptation of LLMs in vulnerability analysis by mimicking how an analyst performs such tasks. We propose ProveRAG, an LLM-powered system designed to assist in rapidly analyzing vulnerabilities with automated retrieval augmentation of web data while self-evaluating its responses with verifiable evidence. ProveRAG incorporates a self-critique mechanism to help alleviate the omission and hallucination common in the output of LLMs applied in cybersecurity applications. The system cross-references data from verifiable sources (NVD and CWE), giving analysts confidence in the actionable insights provided. Our results indicate that ProveRAG excels in delivering verifiable evidence to the user with over 99% and 97% accuracy in exploitation and mitigation strategies, respectively. ProveRAG guides analysts to secure their systems more effectively by overcoming temporal and context-window limitations while also documenting the process for future audits.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2410.17406v3</guid></item><item><title>[cs updates on arXiv.org] HEIGHT: Heterogeneous Interaction Graph Transformer for Robot Navigation in Crowded and Constrained Environments</title><link>https://arxiv.org/abs/2411.12150</link><description>arXiv:2411.12150v4 Announce Type: replace 
Abstract: We study the problem of robot navigation in dense and interactive crowds with static constraints such as corridors and furniture. Previous methods fail to consider all types of spatial and temporal interactions among agents and obstacles, leading to unsafe and inefficient robot paths. In this article, we leverage a graph-based representation of crowded and constrained scenarios and propose a structured framework to learn robot navigation policies with deep reinforcement learning. We first split the representations of different inputs and propose a heterogeneous spatio-temporal graph to model distinct interactions among humans, robots, and obstacles. Based on the heterogeneous spatio-temporal graph, we propose HEIGHT, a novel navigation policy network architecture with different components to capture heterogeneous interactions through space and time. HEIGHT utilizes attention mechanisms to prioritize important interactions and a recurrent network to track changes in the dynamic scene over time, encouraging the robot to avoid collisions adaptively. Through extensive simulation and real-world experiments, we demonstrate that HEIGHT outperforms state-of-the-art baselines in terms of success, navigation time, and generalization to domain shifts in challenging navigation scenarios. More information is available at https://sites.google.com/view/crowdnav-height/home.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2411.12150v4</guid></item><item><title>[cs updates on arXiv.org] Assessing Vulnerability in Smart Contracts: The Role of Code Complexity Metrics in Security Analysis</title><link>https://arxiv.org/abs/2411.17343</link><description>arXiv:2411.17343v4 Announce Type: replace 
Abstract: Software built on poor structural patterns often shows higher exposure to security defects. When code differs from established best practices, verification and maintenance become increasingly difficult, thereby raising the risk of unintentional vulnerabilities. In the context of blockchain technology, where immutable smart contracts handle high-value transactions, the need for strict security assurance is important. This research analyzes the utility of software complexity metrics as diagnostic tools for identifying vulnerable Solidity smart contracts. We evaluate the hypothesis that complexity measures serve as vital, complementary signals for security assessment. Through an empirical examination of 21 distinct metrics, we analyzed their inter-dependencies, statistical association with vulnerabilities, and discriminative capabilities. Our findings indicate a significant degree of redundancy among certain metrics and a relatively low correlation between any single metric and the presence of vulnerabilities. However, the data demonstrates that these metrics possess strong power to distinguish between secure and vulnerable code when analyzed collectively. Notably, with only three exceptions, vulnerable contracts consistently exhibited higher mean complexity scores than their neutral counterparts. While our results show a statistical association, we emphasize that complexity is an indicator rather than a direct cause of vulnerability.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2411.17343v4</guid></item><item><title>[cs updates on arXiv.org] Towards Fast Safe Online Reinforcement Learning via Policy Finetuning</title><link>https://arxiv.org/abs/2412.04426</link><description>arXiv:2412.04426v4 Announce Type: replace 
Abstract: The high costs and risks involved in extensive environment interactions hinder the practical application of current online safe reinforcement learning (RL) methods. While offline safe RL addresses this by learning policies from static datasets, the performance therein is usually limited due to reliance on data quality and challenges with out-of-distribution (OOD) actions. Inspired by recent successes in offline-to-online (O2O) RL, it is crucial to explore whether offline safe RL can be leveraged to facilitate faster and safer online policy learning, a direction that has yet to be fully investigated. To fill this gap, we first demonstrate that naively applying existing O2O algorithms from standard RL would not work well in the safe RL setting due to two unique challenges: \emph{erroneous Q-estimations}, resulted from offline-online objective mismatch and offline cost sparsity, and \emph{Lagrangian mismatch}, resulted from difficulties in aligning Lagrange multipliers between offline and online policies. To address these challenges, we introduce \textbf{Marvel}, a novel framework for O2O safe RL, comprising two key components that work in concert: \emph{Value Pre-Alignment} to align the Q-functions with the underlying truth before online learning, and \emph{Adaptive PID Control} to effectively adjust the Lagrange multipliers during online finetuning. Extensive experiments demonstrate that Marvel significantly outperforms existing baselines in both reward maximization and safety constraint satisfaction. By introducing the first policy-finetuning based framework for O2O safe RL, which is compatible with many offline and online safe RL methods, our work has the great potential to advance the field towards more efficient and practical safe RL solutions.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.04426v4</guid></item><item><title>[cs updates on arXiv.org] Modern Hopfield Networks Require Chain-of-Thought to Solve $\mathsf{NC}^1$-Hard Problems</title><link>https://arxiv.org/abs/2412.05562</link><description>arXiv:2412.05562v2 Announce Type: replace 
Abstract: Modern Hopfield Networks (MHNs) have emerged as powerful components in deep learning, serving as effective replacements for pooling layers, LSTMs, and attention mechanisms. While recent advancements have significantly improved their storage capacity and retrieval efficiency, their fundamental theoretical boundaries remain underexplored. In this paper, we rigorously characterize the expressive power of MHNs through the lens of circuit complexity theory. We prove that $\mathrm{poly}(n)$-precision MHNs with constant depth and linear hidden dimension fall within the $\mathsf{DLOGTIME}$-uniform $\mathsf{TC}^0$ complexity class. Consequently, assuming $\mathsf{TC}^0 \neq \mathsf{NC}^1$, we demonstrate that these architectures are incapable of solving $\mathsf{NC}^1$-hard problems, such as undirected graph connectivity and tree isomorphism. We further extend these impossibility results to Kernelized Hopfield Networks. However, we show that these limitations are not absolute: we prove that equipping MHNs with a Chain-of-Thought (CoT) mechanism enables them to transcend the $\mathsf{TC}^0$ barrier, allowing them to solve inherently serial problems like the word problem for the permutation group $S_5$. Collectively, our results delineate a fine-grained boundary between the capabilities of standard MHNs and those augmented with reasoning steps.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.05562v2</guid></item><item><title>[cs updates on arXiv.org] ViSymRe: Vision Multimodal Symbolic Regression</title><link>https://arxiv.org/abs/2412.11139</link><description>arXiv:2412.11139v4 Announce Type: replace 
Abstract: Extracting interpretable equations from observational datasets to describe complex natural phenomena is one of the core goals of artificial intelligence. This field is known as symbolic regression (SR). In recent years, Transformer-based paradigms have become a new trend in SR, addressing the well-known problem of inefficient search. However, the modal heterogeneity between datasets and equations often hinders the convergence and generalization of these models. In this paper, we propose ViSymRe, a Vision Symbolic Regression framework, to explore the positive role of visual modality in enhancing the performance of Transformer-based SR paradigms. To overcome the challenge where the visual SR model is untrainable in high-dimensional scenarios, we present Multi-View Random Slicing (MVRS). By projecting multivariate equations into 2-D space using random affine transformations, MVRS avoids common defects in high-dimensional visualization, such as variable degradation, non-linear interaction missing, and exponentially increasing sampling complexity, enabling ViSymRe to be trained with low computational costs. To support dataset-only deployment of ViSymRe, we design a dual-vision pipeline architecture based on generative techniques, which reconstructs visual features directly from the datasets via an auxiliary Visual Decoder and automatically suppresses the attention weights of reconstruction noise through a proposed Biased Cross-Attention feature fusion module, ensuring that subsequent processes are not affected by noisy modalities. Ablation studies demonstrate the positive contribution of visual modality to improving model convergence level and enhancing various SR metrics. Furthermore, evaluation results on mainstream benchmarks indicate that ViSymRe achieves competitive performance compared to baselines, particularly in low-complexity and rapid-inference scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.11139v4</guid></item><item><title>[cs updates on arXiv.org] A Concept-Centric Approach to Multi-Modality Learning</title><link>https://arxiv.org/abs/2412.13847</link><description>arXiv:2412.13847v2 Announce Type: replace 
Abstract: Humans possess a remarkable ability to acquire knowledge efficiently and apply it across diverse modalities through a coherent and shared understanding of the world. Inspired by this cognitive capability, we introduce a concept-centric multi-modality learning framework built around a modality-agnostic concept space that captures structured, abstract knowledge, alongside a set of modality-specific projection models that map raw inputs onto this shared space. The concept space is decoupled from any specific modality and serves as a repository of universally applicable knowledge. Once learned, the knowledge embedded in the concept space enables more efficient adaptation to new modalities, as projection models can align with existing conceptual representations rather than learning from scratch. This efficiency is empirically validated in our experiments, where the proposed framework exhibits faster convergence compared to baseline models. In addition, the framework's modular design supports seamless integration of new modalities, since projection models are trained independently yet produce unified outputs within the shared concept space. We evaluate the framework on two representative downstream tasks. While the focus is not on task-specific optimization, the framework attains comparable results with a smaller training footprint, no task-specific fine-tuning, and inference performed entirely within a shared space of learned concepts that offers interpretability. These findings point toward a promising direction for developing learning systems that operate in a manner more consistent with human cognitive processes.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.13847v2</guid></item><item><title>[cs updates on arXiv.org] A Large-Scale IPv6-Based Measurement of the Starlink Network</title><link>https://arxiv.org/abs/2412.18243</link><description>arXiv:2412.18243v3 Announce Type: replace 
Abstract: Low Earth Orbit (LEO) satellite networks have attracted considerable attention for their ability to deliver global, low-latency broadband Internet services. In this paper, we present a large-scale measurement study of the Starlink network, the largest LEO satellite constellation to date. We first propose an efficient method for discovering active Starlink user routers, identifying approximately 5.98 million IPv6 addresses across 208 regions in 165 countries. Compared to general-purpose IPv6 target generation algorithms, our router-centric approach achieves near-complete coverage and, to the best of our knowledge, yields the most comprehensive known set of active IPv6 addresses for Starlink user routers. Based on the discovered user routers, we further propose an efficient method for mapping the Starlink backbone network and uncover a topology consisting of 49 Points of Presence (PoPs) interconnected by 98 links. We conduct a detailed statistical analysis of active Starlink user routers and PoPs, and further characterize the IPv6 address assignment strategy adopted by the Starlink network. Finally, we analyze the latency of Starlink user routers, propose a method to distinguish different types of users within the same region using outside-in measurement, and identify the ongoing V2 Mini satellite deployment as a potential driver of the performance improvements. The dataset of the Starlink backbone network is publicly available at https://ki3.org.cn/#/starlink-network.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.18243v3</guid></item><item><title>[cs updates on arXiv.org] Advances in Artificial Intelligence: A Review for the Creative Industries</title><link>https://arxiv.org/abs/2501.02725</link><description>arXiv:2501.02725v5 Announce Type: replace 
Abstract: Artificial intelligence (AI) has undergone transformative advances since 2022, particularly through generative AI, large language models (LLMs), and diffusion models, fundamentally reshaping the creative industries. However, existing reviews have not comprehensively addressed these recent breakthroughs and their integrated impact across the creative production pipeline. This paper addresses this gap by providing a systematic review of AI technologies that have emerged or matured since our 2022 review, examining their applications across content creation, information analysis, post-production enhancement, compression, and quality assessment. We document how transformers, LLMs, diffusion models, and implicit neural representations have established new capabilities in text-to-image/video generation, real-time 3D reconstruction, and unified multi-task frameworks-shifting AI from support tool to core creative technology. Beyond technological advances, we analyze the trend toward unified AI frameworks that integrate multiple creative tasks, replacing task-specific solutions. We critically examine the evolving role of human-AI collaboration, where human oversight remains essential for creative direction and mitigating AI hallucinations. Finally, we identify emerging challenges including copyright concerns, bias mitigation, computational demands, and the need for robust regulatory frameworks. This review provides researchers and practitioners with a comprehensive understanding of current AI capabilities, limitations, and future trajectories in creative applications.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2501.02725v5</guid></item><item><title>[cs updates on arXiv.org] Complexity Gaps between Point and Interval Temporal Graphs for some Reachability Problems</title><link>https://arxiv.org/abs/2501.11380</link><description>arXiv:2501.11380v2 Announce Type: replace 
Abstract: Temporal graphs arise when modeling interactions that evolve over time. They usually come in several flavors, depending on the number of parameters used to describe the temporal aspects of the interactions: time of appearance, duration, delay of transmission. In the point model, edges appear at specific points in time, whereas in the more general interval model, edges can be present over specific time intervals. In both models, the delay for traversing an edge can change with each edge appearance. When time is discrete, the two models are equivalent in the sense that the presence of an edge during an interval is equivalent to a sequence of point-in-time occurrences of the edge. However, this transformation can drastically change the size of the input and has implications for complexity. Indeed, we show a gap between the two models with respect to the complexity of the classical problem of computing a fastest temporal path from a source vertex to a target vertex, i.e. a path where edges can be traversed one after another in time and such that the total duration from source to target is minimized. It can be solved in near-linear time in the point model, while we show that the interval model requires quadratic time under classical assumptions of fine-grained complexity. With respect to linear time, our lower bound implies a factor of the number of vertices, while the best known algorithm has a factor of the number of underlying edges. We also show a similar complexity gap for computing a shortest temporal path, i.e. a temporal path with a minimum number of edges. Here our lower bound matches known upper bounds up to a logarithmic factor. Interestingly, we show that near-linear time for fastest temporal path computation is possible in the interval model when it is restricted to uniform delay zero, i.e., when traversing an edge is instantaneous. However, this special case is not exempt from our lower bound for shortest temporal path computation. These two results should be contrasted with the computation of a foremost temporal path, i.e., a temporal path that arrives as early as possible. It is well known that this computation can be solved in near-linear time in both models. We also show that there is no gap in testing the all-to-all temporal connectivity of a temporal graph. We demonstrate a quadratic lower bound that applies to both the interval and point models and aligns with the existing upper bounds.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2501.11380v2</guid></item><item><title>[cs updates on arXiv.org] Fair Division Beyond Monotone Valuations with Applications to Equitable Graph Partitioning</title><link>https://arxiv.org/abs/2501.14609</link><description>arXiv:2501.14609v4 Announce Type: replace 
Abstract: This paper studies fair division of divisible and indivisible items among agents whose cardinal preferences are not necessarily monotone. We establish the existence of fair divisions and develop approximation algorithms to compute them. We address two complementary valuation classes, subadditive and nonnegative, which go beyond monotone functions. Considering both the division of cake (divisible resources) and allocation of indivisible items, we obtain fairness guarantees in terms of (approximate) envy-freeness (EF) and equability (EQ). In the context of envy-freeness, we prove that an EF division of a cake always exists under cake valuations that are subadditive and globally nonnegative. This result complements the nonexistence of EF allocations for burnt cakes known for more general valuations. In the indivisible-items setting, we establish the existence of EFE3 allocations for subadditive and globally nonnegative valuations. In addition, we obtain universal existence of EFE3 allocations under nonnegative valuations. We study equitability under nonnegative valuations. Here, we prove that EQE3 allocations always exist when the agents' valuations are nonnegative. Also, in the indivisible-items setting, we develop an approximation algorithm that, for given nonnegative valuations, finds allocations that are equitable within additive margins. Our results have combinatorial implications. For instance, the developed results imply the universal existence of proximately dense subgraphs: Given any graph $G=(V, E)$ and integer $k$ (at most $|V|$), there always exists a partition $V_1, V_2, \ldots, V_k$ of the vertex set such that the edge densities within the parts, $V_i$, are additively within four of each other. Further, such a partition can be computed efficiently.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2501.14609v4</guid></item><item><title>[cs updates on arXiv.org] Improving Estonian Text Simplification through Pretrained Language Models and Custom Datasets</title><link>https://arxiv.org/abs/2501.15624</link><description>arXiv:2501.15624v2 Announce Type: replace 
Abstract: This paper presents a method for text simplification based on two neural architectures: a neural machine translation (NMT) model and a fine-tuned large language model (LLaMA). Given the scarcity of existing resources for Estonian, a new dataset was created by combining manually translated corpora with GPT-4.0-generated simplifications. OpenNMT was selected as a representative NMT-based system, while LLaMA was fine-tuned on the constructed dataset. Evaluation shows LLaMA outperforms OpenNMT in grammaticality, readability, and meaning preservation. These results underscore the effectiveness of large language models for text simplification in low-resource language settings. The complete dataset, fine-tuning scripts, and evaluation pipeline are provided in a publicly accessible supplementary package to support reproducibility and adaptation to other languages.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2501.15624v2</guid></item><item><title>[cs updates on arXiv.org] DPBloomfilter: Securing Bloom Filters with Differential Privacy</title><link>https://arxiv.org/abs/2502.00693</link><description>arXiv:2502.00693v2 Announce Type: replace 
Abstract: The Bloom filter is a simple yet space-efficient probabilistic data structure that supports membership queries for dramatically large datasets. It is widely utilized and implemented across various industrial scenarios, often handling massive datasets that include sensitive user information necessitating privacy preservation. To address the challenge of maintaining privacy within the Bloom filter, we have developed the DPBloomfilter. This innovation integrates the classical differential privacy mechanism, specifically the Random Response technique, into the Bloom filter, offering robust privacy guarantees under the same running complexity as the standard Bloom filter. Through rigorous simulation experiments, we have demonstrated that our DPBloomfilter algorithm maintains high utility while ensuring privacy protections. To the best of our knowledge, this is the first work to provide differential privacy guarantees for the Bloom filter for membership query problems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.00693v2</guid></item><item><title>[cs updates on arXiv.org] Efficient rule induction by ignoring pointless rules</title><link>https://arxiv.org/abs/2502.01232</link><description>arXiv:2502.01232v3 Announce Type: replace 
Abstract: The goal of inductive logic programming (ILP) is to find a set of logical rules that generalises training examples and background knowledge. We introduce an ILP approach that identifies pointless rules. A rule is pointless if it contains a redundant literal or cannot discriminate against negative examples. We show that ignoring pointless rules allows an ILP system to soundly prune the hypothesis space. Our experiments on multiple domains, including visual reasoning and game playing, show that our approach can reduce learning times by 99% whilst maintaining predictive accuracies.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.01232v3</guid></item><item><title>[cs updates on arXiv.org] The Curse of Depth in Large Language Models</title><link>https://arxiv.org/abs/2502.05795</link><description>arXiv:2502.05795v4 Announce Type: replace 
Abstract: In this paper, we introduce the Curse of Depth, a concept that highlights, explains, and addresses the recent observation in modern Large Language Models (LLMs) where nearly half of the layers are less effective than expected. We first confirm the wide existence of this phenomenon across the most popular families of LLMs such as Llama, Mistral, DeepSeek, and Qwen. Our analysis, theoretically and empirically, identifies that the underlying reason for the ineffectiveness of deep layers in LLMs is the widespread usage of Pre-Layer Normalization (Pre-LN). While Pre-LN stabilizes the training of Transformer LLMs, its output variance exponentially grows with the model depth, which undesirably causes the derivative of the deep Transformer blocks to be an identity matrix, and therefore barely contributes to the training. To resolve this training pitfall, we propose LayerNorm Scaling (LNS), which scales the variance of output of the layer normalization inversely by the square root of its depth. This simple modification mitigates the output variance explosion of deeper Transformer layers, improving their contribution. Across a wide range of model sizes (130M to 7B), our experiments show that LNS consistently outperforms previous normalization and scaling techniques in enhancing LLM pre-training performance. Moreover, this improvement seamlessly carries over to supervised fine-tuning. All these gains can be attributed to the fact that LayerNorm Scaling enables deeper layers to contribute more effectively during training. Our code is available at \href{https://github.com/lmsdss/LayerNorm-Scaling}{LayerNorm-Scaling}.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.05795v4</guid></item><item><title>[cs updates on arXiv.org] Unlocking Scaling Law in Industrial Recommendation Systems with a Three-step Paradigm based Large User Model</title><link>https://arxiv.org/abs/2502.08309</link><description>arXiv:2502.08309v2 Announce Type: replace 
Abstract: Recent advancements in autoregressive Large Language Models (LLMs) have achieved significant milestones, largely attributed to their scalability, often referred to as the "scaling law". Inspired by these achievements, there has been a growing interest in adapting LLMs for Recommendation Systems (RecSys) by reformulating RecSys tasks into generative problems. However, these End-to-End Generative Recommendation (E2E-GR) methods tend to prioritize idealized goals, often at the expense of the practical advantages offered by traditional Deep Learning based Recommendation Models (DLRMs) in terms of in features, architecture, and practices. This disparity between idealized goals and practical needs introduces several challenges and limitations, locking the scaling law in industrial RecSys. In this paper, we introduce a large user model (LUM) that addresses these limitations through a three-step paradigm, designed to meet the stringent requirements of industrial settings while unlocking the potential for scalable recommendations. Our extensive experimental evaluations demonstrate that LUM outperforms both state-of-the-art DLRMs and E2E-GR approaches. Notably, LUM exhibits excellent scalability, with performance improvements observed as the model scales up to 7 billion parameters. Additionally, we have successfully deployed LUM in an industrial application, where it achieved significant gains in an A/B test, further validating its effectiveness and practicality.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.08309v2</guid></item><item><title>[cs updates on arXiv.org] A Survey on Human-Centered Evaluation of Explainable AI Methods in Clinical Decision Support Systems</title><link>https://arxiv.org/abs/2502.09849</link><description>arXiv:2502.09849v4 Announce Type: replace 
Abstract: Explainable Artificial Intelligence (XAI) is essential for the transparency and clinical adoption of Clinical Decision Support Systems (CDSS). However, the real-world effectiveness of existing XAI methods remains limited and is inconsistently evaluated. This study conducts a systematic PRISMA-guided survey of 31 human-centered evaluations (HCE) of XAI applied to CDSS, classifying them by XAI methodology, evaluation design, and adoption barrier. Our findings reveal that most existing studies employ post-hoc, model-agnostic approaches such as SHAP and Grad-CAM, typically assessed through small-scale clinician studies. The results show that over 80% of the studies adopt post-hoc, model-agnostic approaches such as SHAP and Grad-CAM, and that clinician sample sizes remain below 25 participants. The findings indicate that explanations generally improve clinician trust and diagnostic confidence, but frequently increase cognitive load and exhibit misalignment with domain reasoning processes. To bridge these gaps, we propose a stakeholder-centric evaluation framework that integrates socio-technical principles and human-computer interaction to guide the future development of clinically viable and trustworthy XAI-based CDSS.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.09849v4</guid></item><item><title>[cs updates on arXiv.org] Benchmarking LLMs for Political Science: A United Nations Perspective</title><link>https://arxiv.org/abs/2502.14122</link><description>arXiv:2502.14122v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have achieved significant advances in natural language processing, yet their potential for high-stake political decision-making remains largely unexplored. This paper addresses the gap by focusing on the application of LLMs to the United Nations (UN) decision-making process, where the stakes are particularly high and political decisions can have far-reaching consequences. We introduce a novel dataset comprising publicly available UN Security Council (UNSC) records from 1994 to 2024, including draft resolutions, voting records, and diplomatic speeches. Using this dataset, we propose the United Nations Benchmark (UNBench), the first comprehensive benchmark designed to evaluate LLMs across four interconnected political science tasks: co-penholder judgment, representative voting simulation, draft adoption prediction, and representative statement generation. These tasks span the three stages of the UN decision-making process--drafting, voting, and discussing--and aim to assess LLMs' ability to understand and simulate political dynamics. Our experimental analysis demonstrates the potential and challenges of applying LLMs in this domain, providing insights into their strengths and limitations in political science. This work contributes to the growing intersection of AI and political science, opening new avenues for research and practical applications in global governance. The UNBench Repository can be accessed at: https://github.com/yueqingliang1/UNBench.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.14122v2</guid></item><item><title>[cs updates on arXiv.org] I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree Search</title><link>https://arxiv.org/abs/2502.14693</link><description>arXiv:2502.14693v5 Announce Type: replace 
Abstract: Recent advancements in large language models (LLMs) have shown remarkable potential in automating machine learning tasks. However, existing LLM-based agents often struggle with low-diversity and suboptimal code generation. While recent work has introduced Monte Carlo Tree Search (MCTS) to address these issues, limitations persist in the quality and diversity of thoughts generated, as well as in the scalar value feedback mechanisms used for node selection. In this study, we introduce Introspective Monte Carlo Tree Search (I-MCTS), a novel approach that iteratively expands tree nodes through an introspective process that meticulously analyzes solutions and results from parent and sibling nodes. This facilitates a continuous refinement of the node in the search tree, thereby enhancing the overall decision-making process. Furthermore, we integrate a Large Language Model (LLM)-based value model to facilitate direct evaluation of each node's solution prior to conducting comprehensive computational rollouts. A hybrid rewarding mechanism is implemented to seamlessly transition the Q-value from LLM-estimated scores to actual performance scores. This allows higher-quality nodes to be traversed earlier. Applied to the various ML tasks, our approach demonstrates a 4% absolute improvement in performance compared to the strong open-source AutoML agents, showcasing its effectiveness in enhancing agentic AutoML systems. Resource available at https://github.com/jokieleung/I-MCTS</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.14693v5</guid></item><item><title>[cs updates on arXiv.org] On Computational Limits of FlowAR Models: Expressivity and Efficiency</title><link>https://arxiv.org/abs/2502.16490</link><description>arXiv:2502.16490v2 Announce Type: replace 
Abstract: The expressive power and computational complexity of deep visual generative models, such as flow-based and autoregressive (AR) models, have gained considerable interest for their wide-ranging applications in generative tasks. However, the theoretical characterization of their expressiveness through the lens of circuit complexity remains underexplored, particularly for the state-of-the-art architecture like FlowAR proposed by [Ren et al., 2024], which integrates flow-based and autoregressive mechanisms. This gap limits our understanding of their inherent computational limits and practical efficiency. In this study, we address this gap by analyzing the circuit complexity of the FlowAR architecture. We demonstrate that when the largest feature map produced by the FlowAR model has dimensions $n \times n \times c$, the FlowAR model is simulable by a family of threshold circuits $\mathsf{TC}^0$, which have constant depth $O(1)$ and polynomial width $\mathrm{poly}(n)$. This is the first study to rigorously highlight the limitations in the expressive power of FlowAR models. Furthermore, we identify the conditions under which the FlowAR model computations can achieve almost quadratic time. To validate our theoretical findings, we present efficient model variant constructions based on low-rank approximations that align with the derived criteria. Our work provides a foundation for future comparisons with other generative paradigms and guides the development of more efficient and expressive implementations.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.16490v2</guid></item><item><title>[cs updates on arXiv.org] Evaluating the Effect of Retrieval Augmentation on Social Biases</title><link>https://arxiv.org/abs/2502.17611</link><description>arXiv:2502.17611v3 Announce Type: replace 
Abstract: Retrieval Augmented Generation (RAG) has gained popularity as a method for conveniently incorporating novel facts that were not seen during the pre-training stage in Large Language Model (LLM)-based Natural Language Generation (NLG) systems. However, LLMs are known to encode significant levels of unfair social biases. The modulation of these biases by RAG in NLG systems is not well understood. In this paper, we systematically study the relationship between the different components of a RAG system and the social biases presented in the text generated across three languages (i.e. English, Japanese and Chinese) and four social bias types (i.e. gender, race, age and religion). Specifically, using the Bias Question Answering (BBQ) benchmark datasets, we evaluate the social biases in RAG responses from document collections with varying levels of stereotypical biases, employing multiple LLMs used as generators. We find that the biases in document collections are often amplified in the generated responses, even when the generating LLM exhibits a low-level of bias. Our findings raise concerns about the use of RAG as a technique for injecting novel facts into NLG systems and call for careful evaluation of potential social biases in RAG applications before their real-world deployment.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.17611v3</guid></item><item><title>[cs updates on arXiv.org] Compositional Verification of Concurrency Using Past-Time Temporal Epistemic Logic</title><link>https://arxiv.org/abs/2502.18885</link><description>arXiv:2502.18885v2 Announce Type: replace 
Abstract: Shared-memory concurrency is difficult to reason about because each thread executes under interference from other threads. At the same time, many correctness arguments for classic algorithms are epistemic: a thread enters a critical region only when, from its local view, it can rule out that another thread is concurrently in that region. We make such arguments explicit by introducing a past-time temporal epistemic logic interpreted over interleaving executions with perfect-recall local histories. Past-time operators support "since" reasoning, while epistemic modalities capture what a given thread can conclude from its own observation history. We give semantics and a sound proof system, instantiate the logic to a simple shared-memory language with instrumented read/write observations, and illustrate the approach on Peterson's mutual exclusion algorithm by proving a local knowledge condition that implies mutual exclusion.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.18885v2</guid></item><item><title>[cs updates on arXiv.org] Text-to-Image Diffusion Models Cannot Count, and Prompt Refinement Cannot Help</title><link>https://arxiv.org/abs/2503.06884</link><description>arXiv:2503.06884v2 Announce Type: replace 
Abstract: Generative modeling is widely regarded as one of the most essential problems in today's AI community, with text-to-image generation having gained unprecedented real-world impacts. Among various approaches, diffusion models have achieved remarkable success and have become the de facto solution for text-to-image generation. However, despite their impressive performance, these models exhibit fundamental limitations in adhering to numerical constraints in user instructions, frequently generating images with an incorrect number of objects. While several prior works have mentioned this issue, a comprehensive and rigorous evaluation of this limitation remains lacking. To address this gap, we introduce T2ICountBench, a novel benchmark designed to rigorously evaluate the counting ability of state-of-the-art text-to-image diffusion models. Our benchmark encompasses a diverse set of generative models, including both open-source and private systems. It explicitly isolates counting performance from other capabilities, provides structured difficulty levels, and incorporates human evaluations to ensure high reliability.
  Extensive evaluations with T2ICountBench reveal that all state-of-the-art diffusion models fail to generate the correct number of objects, with accuracy dropping significantly as the number of objects increases. Additionally, an exploratory study on prompt refinement demonstrates that such simple interventions generally do not improve counting accuracy. Our findings highlight the inherent challenges in numerical understanding within diffusion models and point to promising directions for future improvements.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.06884v2</guid></item><item><title>[cs updates on arXiv.org] Efficient Multi-scale Masked Autoencoders with Hybrid-Attention Mechanism for Breast Lesion Classification</title><link>https://arxiv.org/abs/2503.07157</link><description>arXiv:2503.07157v4 Announce Type: replace 
Abstract: Self-supervised learning (SSL) with Vision Transformers (ViT) has shown immense potential in medical image analysis. However, the quadratic complexity ($\mathcal{O}(N^2)$) of standard self-attention poses a severe barrier for high-resolution biomedical tasks, effectively excluding resource-constrained research labs from utilizing state-of-the-art models. To address this computational bottleneck without sacrificing diagnostic accuracy, we propose \textbf{MIRAM}, a Multi-scale Masked Autoencoder that leverages a \textbf{hybrid-attention mechanism}.
  Our architecture uniquely decouples semantic learning from detail reconstruction using a dual-decoder design: a standard transformer decoder captures global semantics at low resolution, while a linear-complexity decoder (comparing Linformer, Performer, and Nystr\"omformer) handles the computationally expensive high-resolution reconstruction. This reduces the complexity of the upscaling stage from quadratic to linear ($\mathcal{O}(N)$), enabling high-fidelity training on consumer-grade GPUs. We validate our approach on the CBIS-DDSM mammography dataset. Remarkably, our \textbf{Nystr\"omformer-based variant} achieves a classification accuracy of \textbf{61.0\%}, outperforming both standard MAE (58.9\%) and MoCo-v3 (60.2\%) while requiring significantly less memory. These results demonstrate that hybrid-attention architectures can democratize high-resolution medical AI, making powerful SSL accessible to researchers with limited hardware resources.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.07157v4</guid></item><item><title>[cs updates on arXiv.org] Stability results for MIMO LTI systems via Scaled Relative Graphs</title><link>https://arxiv.org/abs/2503.13583</link><description>arXiv:2503.13583v3 Announce Type: replace 
Abstract: This paper proposes a frequency-wise approach for stability analysis of multi-input, multi-output (MIMO) Linear Time-Invariant (LTI) feedback systems through Scaled Relative Graphs (SRGs). Unlike traditional methods, such as the Generalized Nyquist Criterion (GNC), which relies on a coupled analysis that requires the multiplication of models, our approach enables the evaluation of system stability in a decoupled fashion, system by system, each of which is represented by its SRG (or an over-approximation thereof), and it provides an intuitive, visual representation of system behavior. Our results provide conditions for certifying the stability of stable and square MIMO LTI systems connected in closed loop.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.13583v3</guid></item><item><title>[cs updates on arXiv.org] Visual Autoregressive Transformers Must Use $\Omega(n^2 d)$ Memory</title><link>https://arxiv.org/abs/2503.14881</link><description>arXiv:2503.14881v2 Announce Type: replace 
Abstract: A fundamental challenge in Visual Autoregressive models is the substantial memory overhead required during inference to store previously generated representations. Despite various attempts to mitigate this issue through compression techniques, prior works have not explicitly formalized the problem of KV-cache compression in this context. In this work, we take the first step in formally defining the KV-cache compression problem for Visual Autoregressive transformers. We then establish a fundamental negative result, proving that any mechanism for sequential visual token generation under attention-based architectures must use at least $\Omega(n^2 d)$ memory, when $d = \Omega(\log n)$, where $n$ is the number of tokens generated and $d$ is the embedding dimensionality. This result demonstrates that achieving truly sub-quadratic memory usage is impossible without additional structural constraints. Our proof is constructed via a reduction from a computational lower bound problem, leveraging randomized embedding techniques inspired by dimensionality reduction principles. Finally, we discuss how sparsity priors on visual representations can influence memory efficiency, presenting both impossibility results and potential directions for mitigating memory overhead.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.14881v2</guid></item><item><title>[cs updates on arXiv.org] UltraFlwr -- An Efficient Federated Surgical Object Detection Framework</title><link>https://arxiv.org/abs/2503.15161</link><description>arXiv:2503.15161v2 Announce Type: replace 
Abstract: Surgical object detection in laparoscopic videos enables real-time instrument identification for workflow analysis and skills assessment, but training robust models such as You Only Look Once (YOLO) is challenged by limited data, privacy constraints, and inter-institutional variability. Federated learning (FL) enables collaborative training without sharing raw data, yet practical support for modern YOLO pipelines under heterogeneous surgical data remains limited. We present UltraFlwr, an open-source, communication-efficient, and edge-deployable framework that integrates Ultralytics YOLO with the Flower FL platform and supports native Partial Aggregation (PA) of YOLO components (backbone, neck, head). Using two public laparoscopic surgical tool detection datasets, we conduct a systematic empirical study of federated YOLO training under Independent and Identically Distributed (IID) and multiple clinically motivated heterogeneous scenarios, including differences in data curation, video length, and label availability. Results show that standard FL aggregators (e.g., FedAvg) do not consistently match centralized training per client, but reduce inter-client performance variability. Aggregating both backbone and neck components achieves performance comparable to full aggregation with lower communication costs. Also, improving within-client data consistency can benefit FL even when it increases distribution shift across clients. These findings provide practical guidance for deploying federated YOLO-based object detection in heterogeneous surgical environments. UltraFlwr is publicly available at https://github.com/KCL-BMEIS/UltraFlwr.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.15161v2</guid></item><item><title>[cs updates on arXiv.org] CASE -- Condition-Aware Sentence Embeddings for Conditional Semantic Textual Similarity Measurement</title><link>https://arxiv.org/abs/2503.17279</link><description>arXiv:2503.17279v4 Announce Type: replace 
Abstract: The meaning conveyed by a sentence often depends on the context in which it appears. Despite the progress of sentence embedding methods, it remains unclear how to best modify a sentence embedding conditioned on its context. To address this problem, we propose Condition-Aware Sentence Embeddings (CASE), an efficient and accurate method to create an embedding for a sentence under a given condition. First, CASE creates an embedding for the condition using a Large Language Model (LLM), where the sentence influences the attention scores computed for the tokens in the condition during pooling. Next, a supervised nonlinear projection is learned to reduce the dimensionality of the LLM-based text embeddings. We show that CASE significantly outperforms previously proposed Conditional Semantic Textual Similarity (C-STS) methods on an existing standard benchmark dataset. We find that subtracting the condition embedding consistently improves the C-STS performance of LLM-based text embeddings. Moreover, we propose a supervised dimensionality reduction method that not only reduces the dimensionality of LLM-based embeddings but also significantly improves their performance.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.17279v4</guid></item><item><title>[cs updates on arXiv.org] Quotation-Based Data Retention Mechanism for Data Privacy in LLM-Empowered Network Services</title><link>https://arxiv.org/abs/2503.23001</link><description>arXiv:2503.23001v4 Announce Type: replace 
Abstract: The deployment of large language models (LLMs) for next-generation network optimization introduces novel data governance challenges. mobile network operators (MNOs) increasingly leverage generative artificial intelligence (AI) for traffic prediction, anomaly detection, and service personalization, requiring access to users' sensitive network usage data-including mobility patterns, traffic types, and location histories. Under the General Data Protection Regulation (GDPR), the California Consumer Privacy Act (CCPA), and similar regulations, users retain the right to withdraw consent and demand data deletion. However, extensive machine unlearning degrades model accuracy and incurs substantial computational costs, ultimately harming network performance for all users. We propose an iterative price discovery mechanism enabling MNOs to compensate users for data retention through sequential price quotations. The server progressively raises the unit price for retaining data while users independently determine their supply at each quoted price. This approach requires no prior knowledge of users' privacy preferences and efficiently maximizes social welfare across the network ecosystem.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.23001v4</guid></item><item><title>[cs updates on arXiv.org] SAGe: A Lightweight Algorithm-Architecture Co-Design for Mitigating the Data Preparation Bottleneck in Large-Scale Genome Sequence Analysis</title><link>https://arxiv.org/abs/2504.03732</link><description>arXiv:2504.03732v4 Announce Type: replace 
Abstract: Genome sequence analysis, which examines the DNA sequences of organisms, drives advances in many critical medical and biotechnological fields. Given its importance and the exponentially growing volumes of genomic sequence data, there are extensive efforts to accelerate genome sequence analysis. In this work, we demonstrate a major bottleneck that greatly limits and diminishes the benefits of state-of-the-art genome sequence analysis accelerators: the data preparation bottleneck, where genomic sequence data is stored in compressed form and needs to be first decompressed and formatted before an accelerator can operate on it. To mitigate this bottleneck, we propose SAGe, an algorithm-architecture co-design for highly-compressed storage and high-performance access of large-scale genomic sequence data. The key challenge is to improve data preparation performance while maintaining high compression ratios (comparable to genomic-specific compression algorithms) at low hardware cost. We address this challenge by leveraging key properties of genomic datasets to co-design (i) a lossless (de)compression algorithm, (ii) hardware that decompresses data with lightweight operations and efficient streaming accesses, (iii) storage data layout, and (iv) interface commands to access data. SAGe is highly versatile, as it supports datasets from different sequencing technologies and species. Due to its lightweight design, SAGe can be seamlessly integrated with a broad range of hardware accelerators for genome sequence analysis to mitigate their data preparation bottlenecks. Our results demonstrate that SAGe improves the average end-to-end performance and energy efficiency of two state-of-the-art genome sequence analysis accelerators by 3.0x-32.1x and 13.0x-34.0x, respectively, compared to when the accelerators rely on state-of-the-art software and hardware decompression tools.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.03732v4</guid></item><item><title>[cs updates on arXiv.org] Convergence Analysis of a Stochastic Interacting Particle-Field Algorithm for 3D Parabolic-Parabolic Keller-Segel Systems</title><link>https://arxiv.org/abs/2504.10089</link><description>arXiv:2504.10089v2 Announce Type: replace 
Abstract: Chemotaxis models describe the movement of organisms in response to chemical gradients. In this paper, we present a stochastic interacting particle-field algorithm with a random batch approximation (SIPF-$r$) for the three-dimensional (3D) parabolic-parabolic Keller-Segel (KS) system, also referred to as the fully parabolic KS system. The SIPF-$r$ method approximates the KS system by coupling particle-based representations of the density with a smooth field variable computed using spectral methods. By incorporating the random batch method (RBM), we bypass the mean-field limit and significantly reduce computational complexity. Under mild assumptions on the regularity of the original KS system and the boundedness of numerical approximations, we prove that the empirical measure of the SIPF-$r$ particle system converges, with high probability, to the exact measure of the limiting McKean-Vlasov process in the $1$-Wasserstein distance. Finally, we present numerical experiments to validate the theoretical convergence rates, and demonstrate the performance and robustness of the SIPF-$r$ method as a diagnostic tool for intense focusing and potential finite-time singularity in 3D, subject to critical initial mass thresholds in the system.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.10089v2</guid></item><item><title>[cs updates on arXiv.org] On the $p$-adic Skolem Problem</title><link>https://arxiv.org/abs/2504.14413</link><description>arXiv:2504.14413v3 Announce Type: replace 
Abstract: The Skolem Problem asks to determine whether a given linear recurrence sequence (LRS) has a zero term. Showing decidability of this problem is equivalent to giving an effective proof of the Skolem-Mahler-Lech Theorem, which asserts that a non-degenerate LRS has finitely many zeros. The latter result was proven over 90 years ago via an ineffective method showing that such an LRS has only finitely many $p$-adic zeros. In this paper we consider the problem of determining whether a given LRS has a $p$-adic zero, as well as the corresponding function problem of computing exact representations of all $p$-adic zeros. We present algorithms for both problems and report on their implementation. The output of the algorithms is unconditionally correct, and termination is guaranteed subject to the $p$-adic Schanuel Conjecture (a standard number-theoretic hypothesis concerning the $p$-adic exponential function). While these algorithms do not solve the Skolem Problem, they can be exploited to find natural-number and rational zeros under additional hypotheses. To illustrate this, we apply our results to show decidability of the Simultaneous Skolem Problem (determine whether two coprime linear recurrences have a common natural-number zero), again subject to the $p$-adic Schanuel Conjecture.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.14413v3</guid></item><item><title>[cs updates on arXiv.org] Expectation-based Analysis of Higher-Order Quantum Programs</title><link>https://arxiv.org/abs/2504.18441</link><description>arXiv:2504.18441v2 Announce Type: replace 
Abstract: The paper extends the expectation transformer based analysis of higher-order probabilistic programs to the quantum higher-order setting. The quantum language we are considering can be seen as an extension of PCF, featuring unbounded recursion. The language admits classical and quantum data, as well as a tick operator to account for costs. Our quantum expectation transformer translates such programs into a functional, non-quantum language, enriched with a type and operations over so called cost-structures. By specializing the cost-structure, this methodology makes it possible to study several expectation based properties of quantum programs, such as average case cost, probabilities of events or expected values, in terms of the translated non-quantum programs, this way enabling classical reasoning techniques. As a show-case, we adapt a refinement type system, capable of reasoning on upper-bounds.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.18441v2</guid></item><item><title>[cs updates on arXiv.org] Learning and Transferring Physical Models through Derivatives</title><link>https://arxiv.org/abs/2505.01391</link><description>arXiv:2505.01391v3 Announce Type: replace 
Abstract: We propose Derivative Learning (DERL), a supervised approach that models physical systems by learning their partial derivatives. We also leverage DERL to build physical models incrementally, by designing a distillation protocol that effectively transfers knowledge from a pre-trained model to a student one. We provide theoretical guarantees that DERL can learn the true physical system, being consistent with the underlying physical laws, even when using empirical derivatives. DERL outperforms state-of-the-art methods in generalizing an ODE to unseen initial conditions and a parametric PDE to unseen parameters. We also design a method based on DERL to transfer physical knowledge across models by extending them to new portions of the physical domain and a new range of PDE parameters. This introduces a new pipeline to build physical models incrementally in multiple stages.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.01391v3</guid></item><item><title>[cs updates on arXiv.org] LaZagna: An Open-Source Framework for Flexible 3D FPGA Architectural Exploration</title><link>https://arxiv.org/abs/2505.05579</link><description>arXiv:2505.05579v4 Announce Type: replace 
Abstract: While 3D IC technology has been extensively explored for ASICs, their application to FPGAs remains limited. Existing studies on 3D FPGAs are often constrained to fixed prototypes, narrow architectural templates, and simulation-only evaluations. In this work, we present LaZagna, the first open-source framework for automated, end-to-end 3D FPGA architecture generation and evaluation. LaZagna supports high-level architectural specification, synthesizable RTL generation, and bitstream production, enabling comprehensive validation of 3D FPGA designs beyond simulation. It significantly broadens the design space compared to prior work by introducing customizable vertical interconnect patterns, novel 3D switch block designs, and support for heterogeneous logic layers. The framework also incorporates practical design constraints such as inter-layer via density and vertical interconnect delay. We demonstrate the capabilities of LaZagna by generating synthesizable RTL that can be taken through full physical design flows for fabric generation, along with functionally correct bitstreams. Furthermore, we conduct five case studies that explore various architectural parameters and evaluate their impact on wirelength, critical path delay, and routing runtime. These studies showcase the framework's scalability, flexibility, and effectiveness in guiding future 3D FPGA architectural and packaging decisions. LaZagna is fully open-source and available on GitHub.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.05579v4</guid></item><item><title>[cs updates on arXiv.org] Decoupling Multi-Contrast Super-Resolution: Self-Supervised Implicit Re-Representation for Unpaired Cross-Modal Synthesis</title><link>https://arxiv.org/abs/2505.05855</link><description>arXiv:2505.05855v3 Announce Type: replace 
Abstract: Multi-contrast super-resolution (MCSR) is crucial for enhancing MRI but current deep learning methods are limited. They typically require large, paired low- and high-resolution (LR/HR) training datasets, which are scarce, and are trained for fixed upsampling scales. While recent self-supervised methods remove the paired data requirement, they fail to leverage valuable population-level priors. In this work, we propose a novel, decoupled MCSR framework that resolves both limitations. We reformulate MCSR into two stages: (1) an unpaired cross-modal synthesis (uCMS) module, trained once on unpaired population data to learn a robust anatomical prior; and (2) a lightweight, patient-specific implicit re-representation (IrR) module. This IrR module is optimized in a self-supervised manner to fuse the population prior with the subject's own LR target data. This design uniquely fuses population-level knowledge with patient-specific fidelity without requiring any paired LR/HR or paired cross-modal training data. By building the IrR module on an implicit neural representation, our framework is also inherently scale-agnostic. Our method demonstrates superior quantitative performance on different datasets, with exceptional robustness at extreme scales (16x, 32x), a regime where competing methods fail. Our work presents a data-efficient, flexible, and computationally lightweight paradigm for MCSR, enabling high-fidelity, arbitrary-scale</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.05855v3</guid></item><item><title>[cs updates on arXiv.org] VALISENS: A Validated Innovative Multi-Sensor System for Cooperative Automated Driving</title><link>https://arxiv.org/abs/2505.06980</link><description>arXiv:2505.06980v2 Announce Type: replace 
Abstract: Reliable perception remains a key challenge for Connected Automated Vehicles (CAVs) in complex real-world environments, where varying lighting conditions and adverse weather degrade sensing performance. While existing multi-sensor solutions improve local robustness, they remain constrained by limited sensing range, line-of-sight occlusions, and sensor failures on individual vehicles. This paper introduces VALISENS, a validated cooperative perception system that extends multi-sensor fusion beyond a single vehicle through Vehicle-to-Everything (V2X)-enabled collaboration between Connected Automated Vehicles (CAVs) and intelligent infrastructure. VALISENS integrates onboard and roadside LiDARs, radars, RGB cameras, and thermal cameras within a unified multi-agent perception framework. Thermal cameras enhances the detection of Vulnerable Road Users (VRUs) under challenging lighting conditions, while roadside sensors reduce occlusions and expand the effective perception range. In addition, an integrated sensor monitoring module continuously assesses sensor health and detects anomalies before system degradation occurs. The proposed system is implemented and evaluated in a dedicated real-world testbed. Experimental results show that VALISENS improves pedestrian situational awareness by up to 18% compared with vehicle-only sensing, while the sensor monitoring module achieves over 97% accuracy, demonstrating its effectiveness and its potential to support future Cooperative Intelligent Transport Systems (C-ITS) applications.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.06980v2</guid></item><item><title>[cs updates on arXiv.org] FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis</title><link>https://arxiv.org/abs/2505.09109</link><description>arXiv:2505.09109v4 Announce Type: replace 
Abstract: Due to the deformability of garments, generating a large amount of high-quality data for robotic garment manipulation tasks is highly challenging. In this paper, we present a synthetic garment dataset that can be used for robotic garment folding. We begin by constructing geometric garment templates based on keypoints and applying generative models to generate realistic texture patterns. Leveraging these keypoint annotations, we generate folding demonstrations in simulation and train folding policies via closed-loop imitation learning. To improve robustness, we propose KG-DAgger, which uses a keypoint-based strategy to generate demonstration data for recovering from failures. KG-DAgger significantly improves the model performance, boosting the real-world success rate by 25\%. After training with 15K trajectories (about 2M image-action pairs), the model achieves a 75\% success rate in the real world. Experiments in both simulation and real-world settings validate the effectiveness of our proposed framework.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.09109v4</guid></item><item><title>[cs updates on arXiv.org] ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars</title><link>https://arxiv.org/abs/2505.10072</link><description>arXiv:2505.10072v3 Announce Type: replace 
Abstract: The introduction of 3D Gaussian blendshapes has enabled the real-time reconstruction of animatable head avatars from monocular video. Toonify, a StyleGAN-based method, has become widely used for facial image stylization. To extend Toonify for synthesizing diverse stylized 3D head avatars using Gaussian blendshapes, we propose an efficient two-stage framework, ToonifyGB. In Stage 1 (stylized video generation), we adopt an improved StyleGAN to generate the stylized video from the input video frames, which overcomes the limitation of cropping aligned faces at a fixed resolution as preprocessing for normal StyleGAN. This process provides a more stable stylized video, which enables Gaussian blendshapes to better capture the high-frequency details of the video frames, facilitating the synthesis of high-quality animations in the next stage. In Stage 2 (Gaussian blendshapes synthesis), our method learns a stylized neutral head model and a set of expression blendshapes from the generated stylized video. By combining the neutral head model with expression blendshapes, ToonifyGB can efficiently render stylized avatars with arbitrary expressions. We validate the effectiveness of ToonifyGB on benchmark datasets using two representative styles: Arcane and Pixar.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.10072v3</guid></item><item><title>[cs updates on arXiv.org] Unifying concepts in information-theoretic time-series analysis</title><link>https://arxiv.org/abs/2505.13080</link><description>arXiv:2505.13080v3 Announce Type: replace 
Abstract: Information theory is a powerful framework for quantifying complexity, uncertainty, and dynamical structure in time-series data, with widespread applicability across disciplines such as physics, finance, and neuroscience. However, the literature on these measures remains fragmented, with domain-specific terminologies, inconsistent mathematical notation, and disparate visualization conventions that hinder interdisciplinary integration. This work addresses these challenges by unifying key information-theoretic time-series measures through shared semantic definitions, standardized mathematical notation, and cohesive visual representations. We compare these measures in terms of their theoretical foundations, computational formulations, and practical interpretability -- mapping them onto a common conceptual space through an illustrative case study with functional magnetic resonance imaging time series in the brain. This case study exemplifies the complementary insights these measures offer in characterizing the dynamics of complex neural systems, such as signal complexity and information flow. By providing a structured synthesis, our work aims to enhance interdisciplinary dialogue and methodological adoption, which is particularly critical for reproducibility and interoperability in computational neuroscience. More broadly, our framework serves as a resource for researchers seeking to navigate and apply information-theoretic time-series measures to diverse complex systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.13080v3</guid></item><item><title>[cs updates on arXiv.org] Bayesian Ensembling: Insights from Online Optimization and Empirical Bayes</title><link>https://arxiv.org/abs/2505.15638</link><description>arXiv:2505.15638v2 Announce Type: replace 
Abstract: We revisit the classical problem of Bayesian ensembles and address the challenge of learning optimal combinations of Bayesian models in an online, continual learning setting. To this end, we reinterpret existing approaches such as Bayesian model averaging (BMA) and Bayesian stacking through a novel empirical Bayes lens, shedding new light on the limitations and pathologies of BMA. Further motivated by insights from online optimization, we propose Online Bayesian Stacking (OBS), a method that optimizes the log-score over predictive distributions to adaptively combine Bayesian models. A key contribution of our work is establishing a novel connection between OBS and portfolio selection, bridging Bayesian ensemble learning with a rich, well-studied theoretical framework that offers efficient algorithms and extensive regret analysis. We further clarify the relationship between OBS and online BMA, showing that they optimize related but distinct cost functions. Through theoretical analysis and empirical evaluation, we identify scenarios where OBS outperforms online BMA and provide principled methods and guidance on when practitioners should prefer one approach over the other.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.15638v2</guid></item><item><title>[cs updates on arXiv.org] Evaluating Adversarial Robustness of Concept Representations in Sparse Autoencoders</title><link>https://arxiv.org/abs/2505.16004</link><description>arXiv:2505.16004v2 Announce Type: replace 
Abstract: Sparse autoencoders (SAEs) are commonly used to interpret the internal activations of large language models (LLMs) by mapping them to human-interpretable concept representations. While existing evaluations of SAEs focus on metrics such as the reconstruction-sparsity tradeoff, human (auto-)interpretability, and feature disentanglement, they overlook a critical aspect: the robustness of concept representations to input perturbations. We argue that robustness must be a fundamental consideration for concept representations, reflecting the fidelity of concept labeling. To this end, we formulate robustness quantification as input-space optimization problems and develop a comprehensive evaluation framework featuring realistic scenarios in which adversarial perturbations are crafted to manipulate SAE representations. Empirically, we find that tiny adversarial input perturbations can effectively manipulate concept-based interpretations in most scenarios without notably affecting the base LLM's activations. Overall, our results suggest that SAE concept representations are fragile and without further denoising or postprocessing they might be ill-suited for applications in model monitoring and oversight.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.16004v2</guid></item><item><title>[cs updates on arXiv.org] Fluent but Foreign: Even Regional LLMs Lack Cultural Alignment</title><link>https://arxiv.org/abs/2505.21548</link><description>arXiv:2505.21548v3 Announce Type: replace 
Abstract: Large language models (LLMs) are used worldwide, yet exhibit Western cultural tendencies. Many countries are now building ``regional'' or ``sovereign'' LLMs, but it remains unclear whether they reflect local values and practices or merely speak local languages. Using India as a case study, we evaluate six Indic and six global LLMs on two dimensions -- values and practices -- grounded in nationally representative surveys and community-sourced QA datasets. Across tasks, Indic models do not align better with Indian norms than global models; in fact, a U.S. respondent is a closer proxy for Indian values than any Indic model. We further run a user study with 115 Indian users and find that writing suggestions from both global and Indic LLMs introduce Westernized or exoticized writing. Prompting and regional fine-tuning fail to recover alignment and can even degrade existing knowledge. We attribute this to scarce culturally grounded data, especially for pretraining. We position cultural evaluation as a first-class requirement alongside multilingual benchmarks and offer a reusable, community-grounded methodology. We call for native, community-authored corpora and thickxwide evaluations to build truly sovereign LLMs.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.21548v3</guid></item><item><title>[cs updates on arXiv.org] Enhancing Study-Level Inference from Clinical Trial Papers via Reinforcement Learning-Based Numeric Reasoning</title><link>https://arxiv.org/abs/2505.22928</link><description>arXiv:2505.22928v3 Announce Type: replace 
Abstract: Systematic reviews in medicine play a critical role in evidence-based decision-making by aggregating findings from multiple studies. A central bottleneck in automating this process is extracting numeric evidence and determining study-level conclusions for specific outcomes and comparisons. Prior work has framed this problem as a textual inference task by retrieving relevant content fragments and inferring conclusions from them. However, such approaches often rely on shallow textual cues and fail to capture the underlying numeric reasoning behind expert assessments.
  In this work, we conceptualise the problem as one of quantitative reasoning. Rather than inferring conclusions from surface text, we extract structured numerical evidence (e.g., event counts or standard deviations) and apply domain knowledge informed logic to derive outcome-specific conclusions. We develop a numeric reasoning system composed of a numeric data extraction model and an effect estimate component, enabling more accurate and interpretable inference aligned with the domain expert principles. We train the numeric data extraction model using different strategies, including supervised fine-tuning (SFT) and reinforcement learning (RL) with a new value reward model.
  When evaluated on the CochraneForest benchmark, our best-performing approach -- using RL to train a small-scale number extraction model -- yields up to a 21% absolute improvement in F1 score over retrieval-based systems and outperforms general-purpose LLMs of over 400B parameters by up to 9% on the RCTs benchmark. Our results demonstrate the promise of reasoning-driven approaches for automating systematic evidence synthesis.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.22928v3</guid></item><item><title>[cs updates on arXiv.org] Beyond Memorization: A Rigorous Evaluation Framework for Medical Knowledge Editing</title><link>https://arxiv.org/abs/2506.03490</link><description>arXiv:2506.03490v3 Announce Type: replace 
Abstract: Recently, knowledge editing (KE) has emerged as a promising approach to update specific facts in Large Language Models (LLMs) without the need for full retraining. Despite the effectiveness in general-domain benchmarks, their applicability to complex medical domain remains largely unexplored. Medical knowledge editing is particularly challenging, as it requires LLMs to internalize the knowledge and generalize to unseen scenarios for effective and interpretable decision-making. In this work, we propose a novel framework called MedEditBench to rigorously evaluate the effectiveness of existing KE methods in the medical domain. In MedEditBench, we introduce a new medical knowledge editing benchmark as well as three different knowledge editing paradigms, which are designed to assess the impact of different knowledge sources for editing. Our findings indicate that current KE methods result in only superficial memorization of the injected information, failing to generalize to new scenarios. To overcome this limitation, we present Self-Generated Rationale Editing (SGR-Edit), which utilizes model-derived rationales as the target knowledge for editing, thereby uncovering the underlying reasoning process and demonstrating significant improvements over existing KE approaches. Additionally, we offer deeper insights into medical knowledge editing, including the localization of medical knowledge in LLMs and the impact of sequential editing on evolving knowledge. This could provide practical guidance for implementing KE methods in real-world medical applications.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.03490v3</guid></item><item><title>[cs updates on arXiv.org] Identifying Reliable Evaluation Metrics for Scientific Text Revision</title><link>https://arxiv.org/abs/2506.04772</link><description>arXiv:2506.04772v5 Announce Type: replace 
Abstract: Evaluating text revision in scientific writing remains a challenge, as traditional metrics such as ROUGE and BERTScore primarily focus on similarity rather than capturing meaningful improvements. In this work, we analyse and identify the limitations of these metrics and explore alternative evaluation methods that better align with human judgments. We first conduct a manual annotation study to assess the quality of different revisions. Then, we investigate reference-free evaluation metrics from related NLP domains. Additionally, we examine LLM-as-a-judge approaches, analysing their ability to assess revisions with and without a gold reference. Our results show that LLMs effectively assess instruction-following but struggle with correctness, while domain-specific metrics provide complementary insights. We find that a hybrid approach combining LLM-as-a-judge evaluation and task-specific metrics offers the most reliable assessment of revision quality.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.04772v5</guid></item><item><title>[cs updates on arXiv.org] Honey, I shrunk the hypothesis space (through logical preprocessing)</title><link>https://arxiv.org/abs/2506.06739</link><description>arXiv:2506.06739v2 Announce Type: replace 
Abstract: Inductive logic programming (ILP) is a form of logical machine learning. The goal is to search a hypothesis space for a hypothesis that generalises training examples and background knowledge. We introduce an approach that 'shrinks' the hypothesis space before an ILP system searches it. Our approach uses background knowledge to find rules that cannot be in an optimal hypothesis regardless of the training examples. For instance, our approach discovers relationships such as "even numbers cannot be odd" and "prime numbers greater than 2 are odd". It then removes violating rules from the hypothesis space. We implement our approach using answer set programming and use it to shrink the hypothesis space of a constraint-based ILP system. Our experiments on multiple domains, including visual reasoning and game playing, show that our approach can substantially reduce learning times whilst maintaining predictive accuracies. For instance, given just 10 seconds of preprocessing time, our approach can reduce learning times from over 10 hours to only 2 seconds.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.06739v2</guid></item><item><title>[cs updates on arXiv.org] Guardians of the Regime: Secret Police Formation in Autocracies</title><link>https://arxiv.org/abs/2506.10194</link><description>arXiv:2506.10194v2 Announce Type: replace 
Abstract: Autocrats use secret police to stay in power, as these organizations deter and suppress opposition to their rule. Existing research shows that secret police succeed at this but, surprisingly, also that they are not as ubiquitous in autocracies as one may assume, existing in fewer than half of autocratic country-years. We thus explore under which conditions secret police emerge in dictatorships. For this purpose, we develop a theoretical framework for potential predictors and apply statistical variable selection techniques to identify which of several candidate variables extracted from the literature on state security forces and authoritarian survival hold explanatory power. Our results highlight that secret police are more likely to emerge when rulers face structural, regime-external threats, such as organised anti-system mobilisation and international rivals, or witness successful regime-internal contestation abroad that hints at similar threats at home. But additionally, we find that rulers must have sufficient material resources and personalised power to establish secret police. This research contributes to our understanding of autocrats' institutional choices and authoritarian politics.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.10194v2</guid></item><item><title>[cs updates on arXiv.org] Interpretable and flexible non-intrusive reduced-order models using reproducing kernel Hilbert spaces</title><link>https://arxiv.org/abs/2506.10224</link><description>arXiv:2506.10224v2 Announce Type: replace 
Abstract: This paper develops an interpretable, non-intrusive reduced-order modeling technique using regularized kernel interpolation. Existing non-intrusive approaches approximate the dynamics of a reduced-order model (ROM) by solving a data-driven least-squares regression problem for low-dimensional matrix operators. Our approach instead leverages regularized kernel interpolation, which yields an optimal approximation of the ROM dynamics from a user-defined reproducing kernel Hilbert space. We show that our kernel-based approach can produce interpretable ROMs whose structure mirrors full-order model structure by embedding judiciously chosen feature maps into the kernel. The approach is flexible and allows a combination of informed structure through feature maps and closure terms via more general nonlinear terms in the kernel. We also derive a computable a posteriori error bound that combines standard error estimates for intrusive projection-based ROMs and kernel interpolants. The approach is demonstrated in several numerical experiments that include comparisons to operator inference using both proper orthogonal decomposition and quadratic manifold dimension reduction.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.10224v2</guid></item><item><title>[cs updates on arXiv.org] Detecting High-Stakes Interactions with Activation Probes</title><link>https://arxiv.org/abs/2506.10805</link><description>arXiv:2506.10805v4 Announce Type: replace 
Abstract: Monitoring is an important aspect of safely deploying Large Language Models (LLMs). This paper examines activation probes for detecting ``high-stakes'' interactions -- where the text indicates that the interaction might lead to significant harm -- as a critical, yet underexplored, target for such monitoring. We evaluate several probe architectures trained on synthetic data, and find them to exhibit robust generalization to diverse, out-of-distribution, real-world data. Probes' performance is comparable to that of prompted or finetuned medium-sized LLM monitors, while offering computational savings of six orders-of-magnitude. These savings are enabled by reusing activations of the model that is being monitored. Our experiments also highlight the potential of building resource-aware hierarchical monitoring systems, where probes serve as an efficient initial filter and flag cases for more expensive downstream analysis. We release our novel synthetic dataset and the codebase at https://github.com/arrrlex/models-under-pressure.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.10805v4</guid></item><item><title>[cs updates on arXiv.org] EmbedAgent: Benchmarking Large Language Models in Embedded System Development</title><link>https://arxiv.org/abs/2506.11003</link><description>arXiv:2506.11003v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) have shown promise in various tasks, yet few benchmarks assess their capabilities in embedded system development. In this paper, we introduce EmbedAgent, a paradigm designed to simulate real-world roles in embedded system development, such as Embedded System Programmer, Architect, and Integrator. This paradigm enables LLMs to be tested in tasks that bridge the gap between digital and physical systems, allowing for a more comprehensive assessment of their capabilities. To evaluate LLMs on these tasks, we propose Embedbench, the first comprehensive benchmark for embedded system programming, circuit design, and cross-platform migration. Embedbench consists of 126 cases, covering 9 electronic components across 3 hardware platforms. Through extensive experiments on 10 mainstream LLMs, we uncover several key findings. Surprisingly, despite the simplicity of the cases, DeepSeek-R1 achieves only a 55.6% pass@1 rate when provided with schematic information, and 50.0% when tasked with generating the schematics itself. In the cross-platform migration tasks, LLMs show relatively strong performance with MicroPython on the Raspberry Pi Pico (with the top model achieving 73.8% pass@1), but perform poorly on ESP-IDF, where the best model reaches only 29.4% pass@1. Interestingly, we observe that general-purpose chat LLMs like DeepSeek-V3 often fail to utilize relevant pre-trained knowledge in this domain, while reasoning LLMs tend to overthink and overlook efficient knowledge during pretraining. Based on these insights, we propose two strategies: retrieval augmented generation and compiler feedback-to enhance LLM performance. These strategies result in significant improvements, with Deepseek-R1 reaching a 65.1% pass@1 with correct schematics, and 53.1% without. Additionally, the accuracy of the Arduino to ESP32 migration task improves from 21.4% to 27.8%.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.11003v3</guid></item><item><title>[cs updates on arXiv.org] Self-supervised Learning of Echocardiographic Video Representations via Online Cluster Distillation</title><link>https://arxiv.org/abs/2506.11777</link><description>arXiv:2506.11777v3 Announce Type: replace 
Abstract: Self-supervised learning (SSL) has achieved major advances in natural images and video understanding, but challenges remain in domains like echocardiography (heart ultrasound) due to subtle anatomical structures, complex temporal dynamics, and the current lack of domain-specific pre-trained models. Existing SSL approaches such as contrastive, masked modeling, and clustering-based methods struggle with high intersample similarity, sensitivity to low PSNR inputs common in ultrasound, or aggressive augmentations that distort clinically relevant features. We present DISCOVR (Distilled Image Supervision for Cross Modal Video Representation), a self-supervised dual branch framework for cardiac ultrasound video representation learning. DISCOVR combines a clustering-based video encoder that models temporal dynamics with an online image encoder that extracts fine-grained spatial semantics. These branches are connected through a semantic cluster distillation loss that transfers anatomical knowledge from the evolving image encoder to the video encoder, enabling temporally coherent representations enriched with fine-grained semantic understanding.Evaluated on six echocardiography datasets spanning fetal, pediatric, and adult populations, DISCOVR outperforms both specialized video anomaly detection methods and state-of-the-art video-SSL baselines in zero-shot and linear probing setups,achieving superior segmentation transfer and strong downstream performance on clinically relevant tasks such as LVEF prediction. Code available at: https://github.com/mdivyanshu97/DISCOVR</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.11777v3</guid></item><item><title>[cs updates on arXiv.org] Pointwise-in-time error bounds for semilinear and quasilinear fractional subdiffusion equations on graded meshes</title><link>https://arxiv.org/abs/2506.12954</link><description>arXiv:2506.12954v2 Announce Type: replace 
Abstract: Time-fractional semilinear and quasilinear parabolic equations with a Caputo time derivative of order $\alpha\in(0,1)$ are considered, solutions of which exhibit a singular behaviour at an initial time of type $t^\sigma$ for any fixed $\sigma \in (0,1) \cup (1,2)$. The L1 scheme in time is combined with a general class of discretizations for the semilinear term. For such discretizations, we obtain sharp pointwise-in-time error bounds on graded temporal meshes with arbitrary degree of grading. Both semi-discretizations in time and full discretizations using finite differences and finite elements in space are addressed. The theoretcal findings are illustrated by numerical experiments.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.12954v2</guid></item><item><title>[cs updates on arXiv.org] Logical Expressiveness of Graph Neural Networks with Hierarchical Node Individualization</title><link>https://arxiv.org/abs/2506.13911</link><description>arXiv:2506.13911v2 Announce Type: replace 
Abstract: We propose and study Hierarchical Ego Graph Neural Networks (HEGNNs), an expressive extension of graph neural networks (GNNs) with hierarchical node individualization, inspired by the Individualization-Refinement paradigm for isomorphism testing. HEGNNs generalize subgraph-GNNs and form a hierarchy of increasingly expressive models that, in the limit, distinguish graphs up to isomorphism. We show that, over graphs of bounded degree, the separating power of HEGNN node classifiers equals that of graded hybrid logic. This characterization enables us to relate the separating power of HEGNNs to that of higher-order GNNs, GNNs enriched with local homomorphism count features, and color refinement algorithms based on Individualization-Refinement. Our experimental results confirm the practical feasibility of HEGNNs and show benefits in comparison with traditional GNN architectures, both with and without local homomorphism count features.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.13911v2</guid></item><item><title>[cs updates on arXiv.org] Distinguishing Task-Specific and General-Purpose AI in Regulation</title><link>https://arxiv.org/abs/2506.17347</link><description>arXiv:2506.17347v3 Announce Type: replace 
Abstract: Over the past decade, policymakers have developed a set of regulatory tools to ensure AI development aligns with key societal goals. Many of these tools were initially developed in response to concerns with task-specific AI and therefore encode certain assumptions about the nature of AI systems and the utility of certain regulatory approaches. With the advent of general-purpose AI (GPAI), however, some of these assumptions no longer hold, even as policymakers attempt to maintain a single regulatory target that covers both types of AI.
  In this paper, we identify four distinct aspects of GPAI that call for meaningfully different policy responses. These are the generality and adaptability of GPAI that make it a poor regulatory target, the difficulty of designing effective evaluations, new legal concerns that change the ecosystem of stakeholders and sources of expertise, and the distributed structure of the GPAI value chain.
  In light of these distinctions, policymakers will need to evaluate where the past decade of policy work remains relevant and where new policies, designed to address the unique risks posed by GPAI, are necessary. We outline three recommendations for policymakers to more effectively identify regulatory targets and leverage constraints across the broader ecosystem to govern GPAI.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.17347v3</guid></item><item><title>[cs updates on arXiv.org] VOCAL: Visual Odometry via ContrAstive Learning</title><link>https://arxiv.org/abs/2507.00243</link><description>arXiv:2507.00243v2 Announce Type: replace 
Abstract: Breakthroughs in visual odometry (VO) have fundamentally reshaped the landscape of robotics, enabling ultra-precise camera state estimation that is crucial for modern autonomous systems. Despite these advances, many learning-based VO techniques rely on rigid geometric assumptions, which often fall short in interpretability and lack a solid theoretical basis within fully data-driven frameworks. To overcome these limitations, we introduce VOCAL (Visual Odometry via ContrAstive Learning), a novel framework that reimagines VO as a label ranking challenge. By integrating Bayesian inference with a representation learning framework, VOCAL organizes visual features to mirror camera states. The ranking mechanism compels similar camera states to converge into consistent and spatially coherent representations within the latent space. This strategic alignment not only bolsters the interpretability of the learned features but also ensures compatibility with multimodal data sources. Extensive evaluations on the KITTI dataset highlight VOCAL's enhanced interpretability and flexibility, pushing VO toward more general and explainable spatial intelligence.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.00243v2</guid></item><item><title>[cs updates on arXiv.org] Ready Jurist One: Benchmarking Language Agents for Legal Intelligence in Dynamic Environments</title><link>https://arxiv.org/abs/2507.04037</link><description>arXiv:2507.04037v4 Announce Type: replace 
Abstract: The gap between static benchmarks and the dynamic nature of real-world legal practice poses a key barrier to advancing legal intelligence. To this end, we introduce J1-ENVS, the first interactive and dynamic legal environment tailored for LLM-based agents. Guided by legal experts, it comprises six representative scenarios from Chinese legal practices across three levels of environmental complexity. We further introduce J1-EVAL, a fine-grained evaluation framework, designed to assess both task performance and procedural compliance across varying levels of legal proficiency. Extensive experiments on 17 LLM agents reveal that, while many models demonstrate solid legal knowledge, they struggle with procedural execution in dynamic settings. Even the SOTA model, GPT-4o, falls short of 60% overall performance. These findings highlight persistent challenges in achieving dynamic legal intelligence and offer valuable insights to guide future research.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.04037v4</guid></item><item><title>[cs updates on arXiv.org] T-LoRA: Single Image Diffusion Model Customization Without Overfitting</title><link>https://arxiv.org/abs/2507.05964</link><description>arXiv:2507.05964v2 Announce Type: replace 
Abstract: While diffusion model fine-tuning offers a powerful approach for customizing pre-trained models to generate specific objects, it frequently suffers from overfitting when training samples are limited, compromising both generalization capability and output diversity. This paper tackles the challenging yet most impactful task of adapting a diffusion model using just a single concept image, as single-image customization holds the greatest practical potential. We introduce T-LoRA, a Timestep-Dependent Low-Rank Adaptation framework specifically designed for diffusion model personalization. We show that higher diffusion timesteps are more prone to overfitting than lower ones, necessitating a timestep-sensitive fine-tuning strategy. T-LoRA incorporates two key innovations: (1) a dynamic fine-tuning strategy that adjusts rank-constrained updates based on diffusion timesteps, and (2) a weight parametrization technique that ensures independence between adapter components through orthogonal initialization. Extensive experiments on SD-XL and FLUX-1.dev show that T-LoRA and its individual components outperform standard LoRA and other diffusion model personalization techniques, achieving a superior balance between concept fidelity and text alignment. Project page is available at https://controlgenai.github.io/T-LoRA/.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.05964v2</guid></item><item><title>[cs updates on arXiv.org] Can cloud-based VR streaming handle Wi-Fi OBSS contention?</title><link>https://arxiv.org/abs/2507.07677</link><description>arXiv:2507.07677v2 Announce Type: replace 
Abstract: This paper experimentally analyzes the negative impact of contention caused by neighboring Wi-Fi networks operating on overlapping channels on Virtual Reality (VR) streaming over Wi-Fi, focusing on scenarios of partial and full channel overlap within an 80 MHz channel. Our results show that (i) increasing the number of 80 MHz Overlapping Basic Service Sets (OBSSs) intensifies contention and degrades VR streaming performance; (ii) OBSS activity on the secondary-sided 40 MHz portion degrades performance more than activity on the primary-sided 40 MHz portion; (iii) for the same aggregate load, full channel overlap with two 40 MHz OBSS contenders is less detrimental than partial overlap with a single high-load 40 MHz contender, but more disruptive than full overlap with two 80 MHz contenders; and (iv) full channel overlap with two 40 MHz OBSS contenders has a smaller impact on VR streaming under symmetric traffic loads than under asymmetric loads. Moreover, our results demonstrate that our previously proposed Network-aware Step-wise adaptive bitrate algorithm for VR streaming (NeSt-VR) effectively mitigates performance degradation in OBSS environments, enabling VR streaming under heavier OBSS traffic conditions.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.07677v2</guid></item><item><title>[cs updates on arXiv.org] The Query Complexity of Uniform Pricing</title><link>https://arxiv.org/abs/2507.12733</link><description>arXiv:2507.12733v3 Announce Type: replace 
Abstract: Real-world pricing mechanisms are typically optimized using training data, a setting corresponding to the \textit{pricing query complexity} problem in Mechanism Design. The previous work [LSTW23] studies the \textit{single-distribution} case, with tight bounds of $\widetilde{\Theta}(\varepsilon^{-3})$ for a \textit{general} distribution and $\widetilde{\Theta}(\varepsilon^{-2})$ for either a \textit{regular} or \textit{monotone-hazard-rate (MHR)} distribution, where $\varepsilon \in (0, 1)$ denotes the (additive) revenue loss of a learned uniform price relative to the Bayesian-optimal uniform price.
  This can be directly interpreted as ``the query complexity of the {\em \textsf{Uniform Pricing}} mechanism, in the \textit{single-distribution} case''. Yet in the \textit{multi-distribution} case, can the regularity and MHR conditions still lead to improvements over the tight bound $\widetilde{\Theta}(\varepsilon^{-3})$ for general distributions? We answer this question in the negative, by establishing a (near-)matching lower bound $\Omega(\varepsilon^{-3})$ for either \textit{two regular distributions} or \textit{three MHR distributions}.
  We also address the \textit{regret minimization} problem and, in comparison with the folklore upper bound $\widetilde{O}(T^{2 / 3})$ for general distributions (see, e.g., [SW24]), establish a (near-)matching lower bound $\Omega(T^{2 / 3})$ for either \textit{two regular distributions} or \textit{three MHR distributions}, via a black-box reduction. Again, this is in stark contrast to the tight bound $\widetilde{\Theta}(T^{1 / 2})$ for a single regular or MHR distribution.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.12733v3</guid></item><item><title>[cs updates on arXiv.org] RONOM: Reduced-Order Neural Operator Modeling</title><link>https://arxiv.org/abs/2507.12814</link><description>arXiv:2507.12814v2 Announce Type: replace 
Abstract: Time-dependent partial differential equations are ubiquitous in physics-based modeling, but they remain computationally intensive in many-query scenarios, such as real-time forecasting, optimal control, and uncertainty quantification. Reduced-order modeling (ROM) addresses these challenges by constructing a low-dimensional surrogate model but relies on a fixed discretization, which limits flexibility across varying meshes during evaluation. Operator learning approaches, such as neural operators, offer an alternative by parameterizing mappings between infinite-dimensional function spaces, enabling adaptation to data across different resolutions. Whereas ROM provides rigorous numerical error estimates, neural operator learning largely focuses on discretization convergence and invariance without quantifying the error between the infinite-dimensional and the discretized operators. This work introduces the reduced-order neural operator modeling (RONOM) framework, which bridges concepts from ROM and operator learning. We establish a discretization error bound analogous to those in ROM, and get insights into RONOM's discretization convergence and discretization robustness. Moreover, three numerical examples are presented that compare RONOM to existing neural operators for solving partial differential equations. The results demonstrate that RONOM using standard vector-to-vector neural networks can achieve comparable performance in input generalization and achieves superior performance in both spatial super-resolution and discretization robustness, while also offering novel insights into temporal super-resolution scenarios and ROM-based approaches for learning on time-dependent data.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.12814v2</guid></item><item><title>[cs updates on arXiv.org] From Neck to Head: Bio-Impedance Sensing for Head Pose Estimation</title><link>https://arxiv.org/abs/2507.12884</link><description>arXiv:2507.12884v2 Announce Type: replace 
Abstract: We present NeckSense, a novel wearable system for head pose tracking that leverages multi-channel bio-impedance sensing with soft, dry electrodes embedded in a lightweight, necklace-style form factor. NeckSense captures dynamic changes in tissue impedance around the neck, which are modulated by head rotations and subtle muscle activations. To robustly estimate head pose, we propose a deep learning framework that integrates anatomical priors, including joint constraints and natural head rotation ranges, into the loss function design. We validate NeckSense on 7 participants using the current SOTA pose estimation model as ground truth. Our system achieves a mean per-vertex error of 25.9 mm across various head movements with a leave-one-person-out cross-validation method, demonstrating that a compact, line-of-sight-free bio-impedance wearable can deliver head-tracking performance comparable to SOTA vision-based methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.12884v2</guid></item><item><title>[cs updates on arXiv.org] AR-LIF: Adaptive reset leaky integrate-and-fire neuron for spiking neural networks</title><link>https://arxiv.org/abs/2507.20746</link><description>arXiv:2507.20746v3 Announce Type: replace 
Abstract: Spiking neural networks offer low energy consumption due to their event-driven nature. Beyond binary spike outputs, their intrinsic floating-point dynamics merit greater attention. Neuronal threshold levels and reset modes critically determine spike count and timing. Hard reset cause information loss, while soft reset apply uniform treatment to neurons. To address these issues, we design an adaptive reset neuron that establishes relationships between inputs, outputs, and reset, while integrating a simple yet effective threshold adjustment strategy. Experimental results demonstrate that our method achieves excellent performance while maintaining lower energy consumption. In particular, it attains state-of-the-art accuracy on Tiny-ImageNet and CIFAR10-DVS. Codes are available at https://github.com/2ephyrus/AR-LIF.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.20746v3</guid></item><item><title>[cs updates on arXiv.org] Categorical Distributions are Effective Neural Network Outputs for Event Prediction</title><link>https://arxiv.org/abs/2507.21616</link><description>arXiv:2507.21616v2 Announce Type: replace 
Abstract: We demonstrate the effectiveness of the categorical distribution as a neural network output for next event prediction. This is done for both discrete-time and continuous-time event sequences. To model continuous-time processes, the categorical distribution is interpreted as a piecewise-constant density function and is shown to be competitive across a range of datasets. We then argue for the importance of studying discrete-time processes by introducing a neuronal spike prediction task motivated by retinal prosthetics, where discretization of event times is consequent on the task description. Separately, we show evidence that commonly used datasets favour smaller models. Finally, we introduce new synthetic datasets for testing larger models, as well as synthetic datasets with discrete event times.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.21616v2</guid></item><item><title>[cs updates on arXiv.org] Designing Effective Digital Literacy Interventions for Boosting Deepfake Discernment</title><link>https://arxiv.org/abs/2507.23492</link><description>arXiv:2507.23492v2 Announce Type: replace 
Abstract: Deepfakes images can erode trust in institutions and compromise election outcomes, as people often struggle to discern real images from deepfake images. Improving digital literacy can help address these challenges. Here, we compare the efficacy of five digital literacy interventions to boost people's ability to discern deepfakes: (1) textual guidance on common indicators of deepfakes; (2) visual demonstrations of these indicators; (3) a gamified exercise for identifying deepfakes; (4) implicit learning through repeated exposure and feedback; and (5) explanations of how deepfakes are generated with the help of AI. We conducted an experiment with N=1,200 participants from the United States to test the immediate and long-term effectiveness of our interventions. Our results show that our lightweight, easy-to-understand interventions can boost deepfake image discernment by up to 13 percentage points while maintaining trust in real images.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.23492v2</guid></item><item><title>[cs updates on arXiv.org] SPRINT: Scalable and Predictive Intent Refinement for LLM-Enhanced Session-based Recommendation</title><link>https://arxiv.org/abs/2508.00570</link><description>arXiv:2508.00570v2 Announce Type: replace 
Abstract: Large language models (LLMs) have enhanced conventional recommendation models via user profiling, which generates representative textual profiles from users' historical interactions. However, their direct application to session-based recommendation (SBR) remains challenging due to severe session context scarcity and poor scalability. In this paper, we propose SPRINT, a scalable SBR framework that incorporates reliable and informative intents while ensuring high efficiency in both training and inference. SPRINT constrains LLM-based profiling with a global intent pool and validates inferred intents based on recommendation performance to mitigate noise and hallucinations under limited context. To ensure scalability, LLMs are selectively invoked only for uncertain sessions during training, while a lightweight intent predictor generalizes intent prediction to all sessions without LLM dependency at inference time. Experiments on real-world datasets show that SPRINT consistently outperforms state-of-the-art methods while providing more explainable recommendations.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.00570v2</guid></item><item><title>[cs updates on arXiv.org] An Enhanced Focal Loss Function to Mitigate Class Imbalance in Auto Insurance Fraud Detection with Explainable AI</title><link>https://arxiv.org/abs/2508.02283</link><description>arXiv:2508.02283v2 Announce Type: replace 
Abstract: Detecting fraudulent auto-insurance claims remains a challenging classification problem, largely due to the extreme imbalance between legitimate and fraudulent cases. Standard learning algorithms tend to overfit to the majority class, resulting in poor detection of economically significant minority events. This paper proposes a structured three-stage training framework that integrates a convex surrogate of focal loss for stable initialization, a controlled non-convex intermediate loss to improve feature discrimination, and the standard focal loss to refine minority-class sensitivity. We derive conditions under which the surrogate retains convexity in the prediction space and show how this facilitates more reliable optimization when combined with deep sequential models. Using a proprietary auto-insurance dataset, the proposed method improves minority-class F1-scores and AUC relative to conventional focal-loss training and resampling baselines. The approach also provides interpretable feature-attribution patterns through SHAP analysis, offering transparency for actuarial and fraud-analytics applications.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.02283v2</guid></item><item><title>[cs updates on arXiv.org] UniFGVC: Universal Training-Free Few-Shot Fine-Grained Vision Classification via Attribute-Aware Multimodal Retrieval</title><link>https://arxiv.org/abs/2508.04136</link><description>arXiv:2508.04136v2 Announce Type: replace 
Abstract: Few-shot fine-grained visual classification (FGVC) aims to leverage limited data to enable models to discriminate subtly distinct categories. Recent works mostly finetuned the pre-trained visual language models to achieve performance gain, yet suffering from overfitting and weak generalization. To deal with this, we introduce UniFGVC, a universal training-free framework that reformulates few-shot FGVC as multimodal retrieval. First, we propose the Category-Discriminative Visual Captioner (CDV-Captioner) to exploit the open-world knowledge of multimodal large language models (MLLMs) to generate a structured text description that captures the fine-grained attribute features distinguishing closely related classes. CDV-Captioner uses chain-of-thought prompting and visually similar reference images to reduce hallucination and enhance discrimination of generated captions. Using it we can convert each image into an image-description pair, enabling more comprehensive feature representation, and construct the multimodal category templates using few-shot samples for the subsequent retrieval pipeline. Then, off-the-shelf vision and text encoders embed query and template pairs, and FGVC is accomplished by retrieving the nearest template in the joint space. UniFGVC ensures broad compatibility with diverse MLLMs and encoders, offering reliable generalization and adaptability across few-shot FGVC scenarios. Extensive experiments on 12 FGVC benchmarks demonstrate its consistent superiority over prior few-shot CLIP-based methods and even several fully-supervised MLLMs-based approaches.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.04136v2</guid></item><item><title>[cs updates on arXiv.org] CALE : Concept-Aligned Embeddings for Both Within-Lemma and Inter-Lemma Sense Differentiation</title><link>https://arxiv.org/abs/2508.04494</link><description>arXiv:2508.04494v2 Announce Type: replace 
Abstract: Lexical semantics is concerned with both the multiple senses a word can adopt in different contexts, and the semantic relations that exist between meanings of different words. To investigate them, Contextualized Language Models are a valuable tool that provides context-sensitive representations that can be used to investigate lexical meaning. Recent works like XL-LEXEME have leveraged the task of Word-in-Context to fine-tune them to get more semantically accurate representations, but Word-in-Context only compares occurrences of the same lemma, limiting the range of captured information. In this paper, we propose an extension, Concept Differentiation, to include inter-words scenarios. We provide a dataset for this task, derived from SemCor data. Then we fine-tune several representation models on this dataset. We call these models Concept-Aligned Embeddings (CALE). By challenging our models and other models on various lexical semantic tasks, we demonstrate that the proposed models provide efficient multi-purpose representations of lexical meaning that reach best performances in our experiments. We also show that CALE's fine-tuning brings valuable changes to the spatial organization of embeddings.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.04494v2</guid></item><item><title>[cs updates on arXiv.org] Learning Logical Rules using Minimum Message Length</title><link>https://arxiv.org/abs/2508.06230</link><description>arXiv:2508.06230v2 Announce Type: replace 
Abstract: Unifying probabilistic and logical learning is a key challenge in AI. We introduce a Bayesian inductive logic programming approach that learns minimum message length hypotheses from noisy data. Our approach balances hypothesis complexity and data fit through priors, which favour more general programs, and a likelihood, which favours accurate programs. Our experiments on several domains, including game playing and drug design, show that our method significantly outperforms previous methods, notably those that learn minimum description length programs. Our results also show that our approach is data-efficient and insensitive to example balance, including the ability to learn from exclusively positive examples.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.06230v2</guid></item><item><title>[cs updates on arXiv.org] Symmetry breaking for inductive logic programming</title><link>https://arxiv.org/abs/2508.06263</link><description>arXiv:2508.06263v3 Announce Type: replace 
Abstract: The goal of inductive logic programming is to search for a hypothesis that generalises training data and background knowledge. The challenge is searching vast hypothesis spaces, which is exacerbated because many logically equivalent hypotheses exist. To address this challenge, we introduce a method to break symmetries in the hypothesis space. We implement our idea in answer set programming. Our experiments on multiple domains, including visual reasoning and game playing, show that our approach can reduce solving times from over an hour to just 17 seconds.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.06263v3</guid></item><item><title>[cs updates on arXiv.org] Heterogeneous Prompting and Execution Feedback for SWE Issue Test Generation and Selection</title><link>https://arxiv.org/abs/2508.06365</link><description>arXiv:2508.06365v3 Announce Type: replace 
Abstract: A software engineering issue (SWE issue) is easier to resolve when accompanied by a reproduction test. Unfortunately, most issues do not come with functioning reproduction tests, so this paper explores how to generate them automatically. The primary challenge in this setting is that the code to be tested is either missing or wrong, as evidenced by the existence of the issue in the first place. This has held back test generation for this setting: without the correct code to execute, it is difficult to leverage execution feedback to generate good tests. This paper introduces novel techniques for leveraging execution feedback to get around this problem, implemented in a new reproduction test generator called e-Otter++. Experiments show that e-Otter++ represents a leap ahead in the state-of-the-art for this problem, generating tests with an average fail-to-pass rate of 63% on the TDD-Bench Verified benchmark.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.06365v3</guid></item><item><title>[cs updates on arXiv.org] Neural Logic Networks for Interpretable Classification</title><link>https://arxiv.org/abs/2508.08172</link><description>arXiv:2508.08172v5 Announce Type: replace 
Abstract: Traditional neural networks have an impressive classification performance, but what they learn cannot be inspected, verified or extracted. Neural Logic Networks on the other hand have an interpretable structure that enables them to learn a logical mechanism relating the inputs and outputs with AND and OR operations. We generalize these networks with NOT operations and biases that take into account unobserved data and develop a rigorous logical and probabilistic modeling in terms of concept combinations to motivate their use. We also propose a novel factorized IF-THEN rule structure for the model as well as a modified learning algorithm. Our method improves the state-of-the-art in Boolean networks discovery and is able to learn relevant, interpretable rules in tabular classification, notably on examples from the medical and industrial fields where interpretability has tangible value.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.08172v5</guid></item><item><title>[cs updates on arXiv.org] CoreEditor: Consistent 3D Editing via Correspondence-constrained Diffusion</title><link>https://arxiv.org/abs/2508.11603</link><description>arXiv:2508.11603v2 Announce Type: replace 
Abstract: Text-driven 3D editing seeks to modify 3D scenes according to textual descriptions, and most existing approaches tackle this by adapting pre-trained 2D image editors to multi-view inputs. However, without explicit control over multi-view information exchange, they often fail to maintain cross-view consistency, leading to insufficient edits and blurry details. We introduce CoreEditor, a novel framework for consistent text-to-3D editing. The key innovation is a correspondence-constrained attention mechanism that enforces precise interactions between pixels expected to remain consistent throughout the diffusion denoising process. Beyond relying solely on geometric alignment, we further incorporate semantic similarity estimated during denoising, enabling more reliable correspondence modeling and robust multi-view editing. In addition, we design a selective editing pipeline that allows users to choose preferred results from multiple candidates, offering greater flexibility and user control. Extensive experiments show that CoreEditor produces high-quality, 3D-consistent edits with sharper details, significantly outperforming prior methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.11603v2</guid></item><item><title>[cs updates on arXiv.org] Optimal CO2 storage management considering safety constraints in multi-stakeholder multi-site CCS projects: a Markov game perspective</title><link>https://arxiv.org/abs/2508.11618</link><description>arXiv:2508.11618v2 Announce Type: replace 
Abstract: Carbon capture and storage (CCS) projects typically involve a diverse array of stakeholders or players from public, private, and regulatory sectors, each with different objectives and responsibilities. Given the complexity, scale, and long-term nature of CCS operations, determining whether individual stakeholders can independently maximize their interests or whether collaborative coalition agreements are needed remains a central question for effective CCS project planning and management. CCS projects are often implemented in geologically connected sites, where shared geological features such as pressure space and reservoir pore capacity can lead to competitive behavior among stakeholders. Furthermore, CO2 storage sites are often located in geologically mature basins that previously served as sites for hydrocarbon extraction or wastewater disposal in order to leverage existing infrastructures, which makes unilateral optimization even more complicated and unrealistic.
  In this work, we propose a paradigm based on Markov games to quantitatively investigate how different coalition structures affect the goals of stakeholders. We frame this multi-stakeholder multi-site problem as a multi-agent reinforcement learning problem with safety constraints. Our approach enables agents to learn optimal strategies while compliant with safety regulations. We present an example where multiple operators are injecting CO2 into their respective project areas in a geologically connected basin. To address the high computational cost of repeated simulations of high-fidelity models, a previously developed surrogate model based on the Embed-to-Control (E2C) framework is employed. Our results demonstrate the effectiveness of the proposed framework in addressing optimal management of CO2 storage when multiple stakeholders with various objectives and goals are involved.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.11618v2</guid></item><item><title>[cs updates on arXiv.org] MACTAS: Self-Attention-Based Inter-Agent Communication in Multi-Agent Reinforcement Learning with Action-Value Function Decomposition</title><link>https://arxiv.org/abs/2508.13661</link><description>arXiv:2508.13661v3 Announce Type: replace 
Abstract: Communication is essential for the collective execution of complex tasks by human agents, motivating interest in communication mechanisms for multi-agent reinforcement learning (MARL). However, existing communication protocols in MARL are often complex and non-differentiable. In this work, we introduce a self-attention-based communication method that exchanges information between the agents in MARL. Our proposed approach is fully differentiable, allowing agents to learn to generate messages in a reward-driven manner. The method can be seamlessly integrated with any action-value function decomposition algorithm and can be viewed as an orthogonal extension of such decompositions. Notably, it includes a fixed number of trainable parameters, independent of the number of agents, which makes it scalable to large systems. Experimental results on the SMACv2 benchmark demonstrate the effectiveness of our approach, which achieves state-of-the-art performance on a number of maps. makes it scalable to large systems. Experimental results on the SMACv2 benchmark demonstrate the effectiveness of our approach, which achieves state-of-the-art performance on a number of maps.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.13661v3</guid></item><item><title>[cs updates on arXiv.org] VMMU: A Vietnamese Multitask Multimodal Understanding and Reasoning Benchmark</title><link>https://arxiv.org/abs/2508.13680</link><description>arXiv:2508.13680v4 Announce Type: replace 
Abstract: We introduce VMMU, a Vietnamese Multitask Multimodal Understanding and Reasoning Benchmark designed to evaluate how vision-language models (VLMs) interpret and reason over visual and textual information beyond English. VMMU consists of 2.5k multimodal questions across 7 tasks, covering a diverse range of problem contexts, including STEM problem solving, data interpretation, rule-governed visual reasoning, and abstract visual reasoning. All questions require genuine multimodal integration, rather than reliance on text-only cues or OCR-based shortcuts. We evaluate a diverse set of state-of-the-art proprietary and open-source VLMs on VMMU. Despite strong Vietnamese OCR performance, proprietary models achieve only 66% mean accuracy. Further analysis shows that the primary source of failure is not OCR, but instead multimodal grounding and reasoning over text and visual evidence. Code and data are available at https://vmmu-bench.github.io/</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.13680v4</guid></item><item><title>[cs updates on arXiv.org] REG4Rec: Reasoning-Enhanced Generative Model for Large-Scale Recommendation Systems</title><link>https://arxiv.org/abs/2508.15308</link><description>arXiv:2508.15308v3 Announce Type: replace 
Abstract: Sequential recommendation aims to predict a user's next action in large-scale recommender systems. While traditional methods often suffer from insufficient information interaction, recent generative recommendation models partially address this issue by directly generating item predictions. To better capture user intents, recent studies have introduced a reasoning process into generative recommendation, significantly improving recommendation performance. However, these approaches are constrained by the singularity of item semantic representations, facing challenges such as limited diversity in reasoning pathways and insufficient reliability in the reasoning process. To tackle these issues, we introduce REG4Rec, a reasoning-enhanced generative model that constructs multiple dynamic semantic reasoning paths alongside a self-reflection process, ensuring high-confidence recommendations. Specifically, REG4Rec utilizes an MoE-based parallel quantization codebook (MPQ) to generate multiple unordered semantic tokens for each item, thereby constructing a larger-scale diverse reasoning space. Furthermore, to enhance the reliability of reasoning, we propose a training reasoning enhancement stage, which includes Preference Alignment for Reasoning (PARS) and a Multi-Step Reward Augmentation (MSRA) strategy. PARS uses reward functions tailored for recommendation to enhance reasoning and reflection, while MSRA introduces future multi-step actions to improve overall generalization. During inference, Consistency-Oriented Self-Reflection for Pruning (CORP) is proposed to discard inconsistent reasoning paths, preventing the propagation of erroneous reasoning. Lastly, we develop an efficient offline training strategy for large-scale recommendation. Experiments on real-world datasets and online evaluations show that REG4Rec delivers outstanding performance and substantial practical value.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.15308v3</guid></item><item><title>[cs updates on arXiv.org] GAICo: A Deployed and Extensible Framework for Evaluating Diverse and Multimodal Generative AI Outputs</title><link>https://arxiv.org/abs/2508.16753</link><description>arXiv:2508.16753v4 Announce Type: replace 
Abstract: The rapid proliferation of Generative AI (GenAI) into diverse, high-stakes domains necessitates robust and reproducible evaluation methods. However, practitioners often resort to ad-hoc, non-standardized scripts, as common metrics are often unsuitable for specialized, structured outputs (e.g., automated plans, time-series) or holistic comparison across modalities (e.g., text, audio, and image). This fragmentation hinders comparability and slows AI system development. To address this challenge, we present GAICo (Generative AI Comparator): a deployed, open-source Python library that streamlines and standardizes GenAI output comparison. GAICo provides a unified, extensible framework supporting a comprehensive suite of reference-based metrics for unstructured text, specialized structured data formats, and multimedia (images, audio). Its architecture features a high-level API for rapid, end-to-end analysis, from multi-model comparison to visualization and reporting, alongside direct metric access for granular control. We demonstrate GAICo's utility through a detailed case study evaluating and debugging complex, multi-modal AI Travel Assistant pipelines. GAICo empowers AI researchers and developers to efficiently assess system performance, make evaluation reproducible, improve development velocity, and ultimately build more trustworthy AI systems, aligning with the goal of moving faster and safer in AI deployment. Since its release on PyPI in Jun 2025, the tool has been downloaded over 16K times, across versions, by Dec 2025, demonstrating growing community interest.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.16753v4</guid></item><item><title>[cs updates on arXiv.org] A Novel Deep Hybrid Framework with Ensemble-Based Feature Optimization for Robust Real-Time Human Activity Recognition</title><link>https://arxiv.org/abs/2508.18695</link><description>arXiv:2508.18695v3 Announce Type: replace 
Abstract: Real-time Human Activity Recognition (HAR) has wide-ranging applications in areas such as context-aware environments, public safety, assistive technologies, and autonomous monitoring and surveillance systems. However, existing real-time HAR systems face significant challenges, including limited scalability and high computational costs arising from redundant features. To address these issues, the Inception-V3 model was customized with region-based and boundary-aware operations, using average pooling and max pooling, respectively, to enhance region homogeneity, suppress noise, and capture discriminative local features, while improving robustness through down-sampling. Furthermore, to effectively encode motion dynamics, an Attention-Augmented Long Short-Term Memory (AA-LSTM) network was employed to learn temporal dependencies across video frames. Features are extracted from video dataset and are then optimized through a novel proposed dynamic composite feature selection method called Adaptive Dynamic Fitness Sharing and Attention (ADFSA). This ADFSA mechanism is embedded within a genetic algorithm to select a compact, optimized subset of features by dynamically balancing multiple objectives, accuracy, redundancy reduction, feature uniqueness, and complexity minimization. As a result, the selected subset of diverse and discriminative features enables lightweight machine learning classifiers to achieve accurate and robust HAR in heterogeneous environments. Experimental results demonstrate up to 99.65\% accuracy using as few as seven selected features, with improved inference time on the challenging UCF-YouTube dataset, which includes factors such as occlusion, cluttered backgrounds, complex motion dynamics, and poor illumination conditions.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.18695v3</guid></item><item><title>[cs updates on arXiv.org] Towards Open-World Retrieval-Augmented Generation on Knowledge Graph: A Multi-Agent Collaboration Framework</title><link>https://arxiv.org/abs/2509.01238</link><description>arXiv:2509.01238v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in web search and reasoning. However, their dependence on static training corpora makes them prone to factual errors and knowledge gaps. Retrieval-Augmented Generation (RAG) addresses this limitation by incorporating external knowledge sources, especially structured Knowledge Graphs (KGs), which provide explicit semantics and efficient retrieval. Existing KG-based RAG approaches, however, generally assume that anchor entities are accessible to initiate graph traversal, which limits their robustness in open-world settings where accurate linking between the user query and the KG entity is unreliable. To overcome this limitation, we propose AnchorRAG, a novel multi-agent collaboration framework for open-world RAG without the predefined anchor entities. Specifically, a predictor agent dynamically identifies candidate anchor entities by aligning user query terms with KG nodes and initializes independent retriever agents to conduct parallel multi-hop explorations from each candidate. Then a supervisor agent formulates the iterative retrieval strategy for these retriever agents and synthesizes the resulting knowledge paths to generate the final answer. This multi-agent collaboration framework improves retrieval robustness and mitigates the impact of ambiguous or erroneous anchors. Extensive experiments on four public benchmarks demonstrate that AnchorRAG significantly outperforms existing baselines and establishes new state-of-the-art results on the real-world reasoning tasks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.01238v2</guid></item><item><title>[cs updates on arXiv.org] Towards Reasoning for PDE Foundation Models: A Reward-Model-Driven Inference-Time-Scaling Algorithm</title><link>https://arxiv.org/abs/2509.02846</link><description>arXiv:2509.02846v3 Announce Type: replace 
Abstract: Partial Differential Equations (PDEs) are the bedrock for modern computational sciences and engineering, and inherently computationally expensive. While PDE foundation models have shown much promise for simulating such complex spatio-temporal phenomena, existing models remain constrained by the pretraining datasets and struggle with auto-regressive rollout performance, especially in out-of-distribution (OOD) cases. Furthermore, they have significant compute and training data requirements which hamper their use in many critical applications. Inspired by recent advances in ``thinking" strategies used in large language models (LLMs), we introduce the first test-time computing (TTC) strategy for PDEs that utilizes computational resources during inference to achieve more accurate predictions with fewer training samples and smaller models. We accomplish this with two types of reward models that evaluate predictions of a stochastic based model for spatio-temporal consistency. We demonstrate this method on compressible Euler-equation simulations from the PDEGym benchmark and show that TTC captures improved predictions relative to standard non-adaptive auto-regressive inference. This TTC framework marks a foundational step towards more advanced reasoning algorithms or PDE modeling, inluding building reinforcement-learning-based approaches, potentially transforming computational workflows in physics and engineering.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.02846v3</guid></item><item><title>[cs updates on arXiv.org] Equivariant Flow Matching for Symmetry-Breaking Bifurcation Problems</title><link>https://arxiv.org/abs/2509.03340</link><description>arXiv:2509.03340v3 Announce Type: replace 
Abstract: Bifurcation phenomena in nonlinear dynamical systems often lead to multiple coexisting stable solutions, particularly in the presence of symmetry breaking. Deterministic machine learning models are unable to capture this multiplicity, averaging over solutions and failing to represent lower-symmetry outcomes. In this work, we formalize the use of generative AI, specifically flow matching, as a principled way to model the full probability distribution over bifurcation outcomes. Our approach builds on existing techniques by combining flow matching with equivariant architectures and an optimal-transport-based coupling mechanism. We generalize equivariant flow matching to a symmetric coupling strategy that aligns predicted and target outputs under group actions, allowing accurate learning in equivariant settings. We validate our approach on a range of systems, from simple conceptual systems to physical problems such as buckling beams and the Allen--Cahn equation. The results demonstrate that the approach accurately captures multimodal distributions and symmetry-breaking bifurcations. Moreover, our results demonstrate that flow matching significantly outperforms non-probabilistic and variational methods. This offers a principled and scalable solution for modeling multistability in high-dimensional systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.03340v3</guid></item><item><title>[cs updates on arXiv.org] Physics-Informed Detection of Friction Anomalies in Satellite Reaction Wheels</title><link>https://arxiv.org/abs/2509.04060</link><description>arXiv:2509.04060v2 Announce Type: replace 
Abstract: As the number of satellites in orbit has increased exponentially in recent years, ensuring their correct functionality has started to require automated methods to decrease human workload. In this work, we present an algorithm that analyzes the on-board data related to friction from the Reaction Wheel Assemblies (RWA) of a satellite and determines their operating status, distinguishing between nominal status and several possible anomalies that require preventive measures to be taken. The algorithm first uses a model based on hybrid systems theory to extract the information relevant to the problem. The extraction process combines techniques in changepoint detection, dynamic programming, and maximum likelihood in a structured way. A classifier then uses the extracted information to determine the status of the RWA. This last classifier has been previously trained with a labelled dataset produced by a high-fidelity simulator, comprised for the most part of nominal data. The final algorithm combines model-based and data-based approaches to obtain satisfactory results with an accuracy around 95%.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.04060v2</guid></item><item><title>[cs updates on arXiv.org] WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning</title><link>https://arxiv.org/abs/2509.04744</link><description>arXiv:2509.04744v2 Announce Type: replace 
Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities across various vision-language tasks. However, their reasoning abilities in the multimodal symbolic music domain remain largely unexplored. We introduce WildScore, the first in-the-wild multimodal symbolic music reasoning and analysis benchmark, designed to evaluate MLLMs' capacity to interpret real-world music scores and answer complex musicological queries. Each instance in WildScore is sourced from genuine musical compositions and accompanied by authentic user-generated questions and discussions, capturing the intricacies of practical music analysis. To facilitate systematic evaluation, we propose a systematic taxonomy, comprising both high-level and fine-grained musicological ontologies. Furthermore, we frame complex music reasoning as multiple-choice question answering, enabling controlled and scalable assessment of MLLMs' symbolic music understanding. Empirical benchmarking of state-of-the-art MLLMs on WildScore reveals intriguing patterns in their visual-symbolic reasoning, uncovering both promising directions and persistent challenges for MLLMs in symbolic music reasoning and analysis. We release the dataset and code.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.04744v2</guid></item><item><title>[cs updates on arXiv.org] Orthogonal Low-rank Adaptation in Lie Groups for Continual Learning of Large Language Models</title><link>https://arxiv.org/abs/2509.06100</link><description>arXiv:2509.06100v2 Announce Type: replace 
Abstract: Large language models (LLMs) suffer from catastrophic forgetting in sequential multi-task learning. Existing parameter regularization methods (e.g., O-LoRA, N-LoRA) mitigate interference via low-rank subspace orthogonality, but additive updates distort the intrinsic geometry of model parameters. We propose \textbf{OLieRA}, a Lie group based fine-tuning framework that preserves parameter geometry through multiplicative updates while enforcing orthogonality across task subspaces. OLieRA achieves state-of-the-art performance on the Standard CL benchmark and remains highly competitive under large task sequences. It further inherits the replay-free and task-ID free inference properties of O-LoRA, establishing a principled paradigm for continual learning in LLMs.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.06100v2</guid></item><item><title>[cs updates on arXiv.org] Faster and Memory-Efficient Training of Sequential Recommendation Models for Large Catalogs</title><link>https://arxiv.org/abs/2509.09682</link><description>arXiv:2509.09682v5 Announce Type: replace 
Abstract: Sequential recommendations (SR) with transformer-based architectures are widely adopted in real-world applications, where SR models require frequent retraining to adapt to ever-changing user preferences. However, training transformer-based SR models often encounters a high computational cost associated with scoring extensive item catalogs, often exceeding thousands of items. This occurs mainly due to the use of cross-entropy loss, where peak memory scales proportionally to catalog size, batch size, and sequence length. Recognizing this, practitioners in the field of recommendation systems typically address memory consumption by integrating the cross-entropy (CE) loss with negative sampling, thereby reducing the explicit memory demands of the final layer. However, a small number of negative samples would degrade model performance, and as we demonstrate in our work, increasing the number of negative samples and the batch size further improves the model's performance, but rapidly starts to exceed industrial GPUs' size (~40Gb).
  In this work, we introduce the CCE- method, which offers a GPU-efficient implementation of the CE loss with negative sampling. Our method accelerates training by up to two times while reducing memory consumption by more than 10 times. Leveraging the memory savings afforded by using CCE- for model training, it becomes feasible to enhance its accuracy on datasets with a large item catalog compared to those trained with original PyTorch-implemented loss functions. Finally, we perform an analysis of key memory-related hyperparameters and highlight the necessity of a delicate balance among these factors. We demonstrate that scaling both the number of negative samples and batch size leads to better results rather than maximizing only one of them. To facilitate further adoption of CCE-, we release a Triton kernel that efficiently implements the proposed method.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.09682v5</guid></item><item><title>[cs updates on arXiv.org] GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection</title><link>https://arxiv.org/abs/2509.10250</link><description>arXiv:2509.10250v2 Announce Type: replace 
Abstract: With generative models becoming increasingly sophisticated and diverse, detecting AI-generated images has become increasingly challenging. While existing AI-genereted Image detectors achieve promising performance on in-distribution generated images, their generalization to unseen generative models remains limited. This limitation is largely attributed to their reliance on generation-specific artifacts, such as stylistic priors and compression patterns. To address these limitations, we propose GAMMA, a novel training framework designed to reduce domain bias and enhance semantic alignment. GAMMA introduces diverse manipulation strategies, such as inpainting-based manipulation and semantics-preserving perturbations, to ensure consistency between manipulated and authentic content. We employ multi-task supervision with dual segmentation heads and a classification head, enabling pixel-level source attribution across diverse generative domains. In addition, a reverse cross-attention mechanism is introduced to allow the segmentation heads to guide and correct biased representations in the classification branch. Our method achieves state-of-the-art generalization performance on the GenImage benchmark, imporving accuracy by 5.8%, but also maintains strong robustness on newly released generative model such as GPT-4o.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.10250v2</guid></item><item><title>[cs updates on arXiv.org] Adaptive Spatial Goodness Encoding: Advancing and Scaling Forward-Forward Learning Without Backpropagation</title><link>https://arxiv.org/abs/2509.12394</link><description>arXiv:2509.12394v2 Announce Type: replace 
Abstract: The Forward-Forward (FF) algorithm offers a promising alternative to backpropagation (BP). Despite advancements in recent FF-based extensions, which have enhanced the original algorithm and adapted it to convolutional neural networks (CNNs), they often suffer from limited representational capacity and poor scalability to large-scale datasets, primarily due to exploding channel dimensionality. In this work, we propose adaptive spatial goodness encoding (ASGE), a new FF-based training framework tailored for CNNs. ASGE leverages feature maps to compute spatially-aware goodness representations at each layer, enabling layer-wise supervision. Crucially, this approach decouples classification complexity from channel dimensionality, thereby addressing the issue of channel explosion and achieving competitive performance compared to other BP alternatives. ASGE outperforms all other FF-based approaches across multiple benchmarks, delivering test accuracies of 99.65% on MNIST, 93.41% on FashionMNIST, 90.62% on CIFAR-10, and 65.42% on CIFAR-100. Moreover, we present the first successful application of FF-based training to ImageNet, with Top-1 and Top-5 accuracies of 51.58% and 75.23%. Furthermore, we propose three prediction strategies to achieve flexible trade-offs among accuracy, parameters and memory usage, enabling deployment under diverse resource constraints.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.12394v2</guid></item><item><title>[cs updates on arXiv.org] Soft Graph Transformer for MIMO Detection</title><link>https://arxiv.org/abs/2509.12694</link><description>arXiv:2509.12694v4 Announce Type: replace 
Abstract: We propose the Soft Graph Transformer (SGT), a soft-input-soft-output neural architecture designed for MIMO detection. While Maximum Likelihood (ML) detection achieves optimal accuracy, its exponential complexity makes it infeasible in large systems, and conventional message-passing algorithms rely on asymptotic assumptions that often fail in finite dimensions. Recent Transformer-based detectors show strong performance but typically overlook the MIMO factor graph structure and cannot exploit prior soft information. SGT addresses these limitations by combining self-attention, which encodes contextual dependencies within symbol and constraint subgraphs, with graph-aware cross-attention, which performs structured message passing across subgraphs. Its soft-input interface allows the integration of auxiliary priors, producing effective soft outputs while maintaining computational efficiency. Experiments demonstrate that SGT achieves near-ML performance and offers a flexible and interpretable framework for receiver systems that leverage soft priors.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.12694v4</guid></item><item><title>[cs updates on arXiv.org] MapAnything: Universal Feed-Forward Metric 3D Reconstruction</title><link>https://arxiv.org/abs/2509.13414</link><description>arXiv:2509.13414v3 Announce Type: replace 
Abstract: We introduce MapAnything, a unified transformer-based feed-forward model that ingests one or more images along with optional geometric inputs such as camera intrinsics, poses, depth, or partial reconstructions, and then directly regresses the metric 3D scene geometry and cameras. MapAnything leverages a factored representation of multi-view scene geometry, i.e., a collection of depth maps, local ray maps, camera poses, and a metric scale factor that effectively upgrades local reconstructions into a globally consistent metric frame. Standardizing the supervision and training across diverse datasets, along with flexible input augmentation, enables MapAnything to address a broad range of 3D vision tasks in a single feed-forward pass, including uncalibrated structure-from-motion, calibrated multi-view stereo, monocular depth estimation, camera localization, depth completion, and more. We provide extensive experimental analyses and model ablations demonstrating that MapAnything outperforms or matches specialist feed-forward models while offering more efficient joint training behavior, thus paving the way toward a universal 3D reconstruction backbone.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.13414v3</guid></item><item><title>[cs updates on arXiv.org] LLM Jailbreak Detection for (Almost) Free!</title><link>https://arxiv.org/abs/2509.14558</link><description>arXiv:2509.14558v2 Announce Type: replace 
Abstract: Large language models (LLMs) enhance security through alignment when widely used, but remain susceptible to jailbreak attacks capable of producing inappropriate content. Jailbreak detection methods show promise in mitigating jailbreak attacks through the assistance of other models or multiple model inferences. However, existing methods entail significant computational costs. In this paper, we first present a finding that the difference in output distributions between jailbreak and benign prompts can be employed for detecting jailbreak prompts. Based on this finding, we propose a Free Jailbreak Detection (FJD) which prepends an affirmative instruction to the input and scales the logits by temperature to further distinguish between jailbreak and benign prompts through the confidence of the first token. Furthermore, we enhance the detection performance of FJD through the integration of virtual instruction learning. Extensive experiments on aligned LLMs show that our FJD can effectively detect jailbreak prompts with almost no additional computational costs during LLM inference.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.14558v2</guid></item><item><title>[cs updates on arXiv.org] Cross-Lingual F5-TTS: Towards Language-Agnostic Voice Cloning and Speech Synthesis</title><link>https://arxiv.org/abs/2509.14579</link><description>arXiv:2509.14579v3 Announce Type: replace 
Abstract: Flow-matching-based text-to-speech (TTS) models have shown high-quality speech synthesis. However, most current flow-matching-based TTS models still rely on reference transcripts corresponding to the audio prompt for synthesis. This dependency prevents cross-lingual voice cloning when audio prompt transcripts are unavailable, particularly for unseen languages. The key challenges for flow-matching-based TTS models to remove audio prompt transcripts are identifying word boundaries during training and determining appropriate duration during inference. In this paper, we introduce Cross-Lingual F5-TTS, a framework that enables cross-lingual voice cloning without audio prompt transcripts. Our method preprocesses audio prompts by forced alignment to obtain word boundaries, enabling direct synthesis from audio prompts while excluding transcripts during training. To address the duration modeling challenge, we train speaking rate predictors at different linguistic granularities to derive duration from speaker pace. Experiments show that our approach matches the performance of F5-TTS while enabling cross-lingual voice cloning.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.14579v3</guid></item><item><title>[cs updates on arXiv.org] SONAR: Self-Distilled Continual Pre-training for Domain Adaptive Audio Representation</title><link>https://arxiv.org/abs/2509.15703</link><description>arXiv:2509.15703v2 Announce Type: replace 
Abstract: Self-supervised learning (SSL) on large-scale datasets like AudioSet has become the dominant paradigm for audio representation learning. While the continuous influx of new, unlabeled audio presents an opportunity to enrich these static representations, a naive approach is to retrain the model from scratch using all available data. However, this method is computationally prohibitive and discards the valuable knowledge embedded in the previously trained model weights. To address this inefficiency, we propose SONAR (Self-distilled cONtinual pre-training for domain adaptive Audio Representation), a continual pre-training framework built upon BEATs. SONAR effectively adapts to new domains while mitigating catastrophic forgetting by tackling three key challenges: implementing a joint sampling strategy for new and prior data, applying regularization to balance specificity and generality, and dynamically expanding the tokenizer codebook for novel acoustic patterns. Experiments across four distinct domains demonstrate that our method achieves both high adaptability and robust resistance to forgetting.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.15703v2</guid></item><item><title>[cs updates on arXiv.org] Etude: Piano Cover Generation with a Three-Stage Approach -- Extract, strucTUralize, and DEcode</title><link>https://arxiv.org/abs/2509.16522</link><description>arXiv:2509.16522v2 Announce Type: replace 
Abstract: Piano cover generation aims to automatically transform a pop song into a piano arrangement. While numerous deep learning approaches have been proposed, existing models often fail to maintain structural consistency with the original song, likely due to the absence of beat-aware mechanisms or the difficulty of modeling complex rhythmic patterns. Rhythmic information is crucial, as it defines structural similarity (e.g., tempo, BPM) and directly impacts the overall quality of the generated music.
  In this paper, we introduce Etude, a three-stage architecture consisting of Extract, strucTUralize, and DEcode stages. By pre-extracting rhythmic information and applying a novel, simplified REMI-based tokenization, our model produces covers that preserve proper song structure, enhance fluency and musical dynamics, and support highly controllable generation through style injection. Subjective evaluations with human listeners show that Etude substantially outperforms prior models, achieving a quality level comparable to that of human composers.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.16522v2</guid></item><item><title>[cs updates on arXiv.org] CoRaCMG: Contextual Retrieval-Augmented Framework for Commit Message Generation</title><link>https://arxiv.org/abs/2509.18337</link><description>arXiv:2509.18337v2 Announce Type: replace 
Abstract: Commit messages play a key role in documenting the intent behind code changes. However, they are often low-quality, vague, or incomplete, limiting their usefulness. Commit Message Generation (CMG) aims to automatically generate descriptive commit messages from code diffs to reduce developers' effort and improve message quality. Although recent advances in LLMs have shown promise in automating CMG, their performance remains limited. This paper aims to enhance CMG performance by retrieving similar diff-message pairs to guide LLMs to generate commit messages that are more precise and informative. We proposed CoRaCMG, a Contextual Retrieval-augmented framework for Commit Message Generation, structured in three phases: (1) Retrieve: retrieving the similar diff-message pairs; (2) Augment: combining them with the query diff into a structured prompt; and (3) Generate: generating commit messages corresponding to the query diff via LLMs. CoRaCMG enables LLMs to learn project-specific terminologies and writing styles from the retrieved diff-message pairs. We evaluated CoRaCMG across multiple LLMs (e.g., GPT, DeepSeek, and Qwen) and compared its performance against SOTA baselines. Experimental results show that CoRaCMG significantly boosts LLM performance across four metrics (BLEU, Rouge-L, METEOR, and CIDEr). Specifically, DeepSeek-R1 achieves relative improvements of 76% in BLEU and 71% in CIDEr when augmented with a single retrieved example pair. After incorporating the single example pair, GPT-4o achieves the highest improvement rate, with BLEU increasing by 89%. Moreover, performance gains plateau after more than three examples are used, indicating diminishing returns. Further analysis shows that the improvements are attributed to the model's ability to capture the terminologies and writing styles of human-written commit messages from the retrieved example pairs.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.18337v2</guid></item><item><title>[cs updates on arXiv.org] MusiCRS: Benchmarking Audio-Centric Conversational Recommendation</title><link>https://arxiv.org/abs/2509.19469</link><description>arXiv:2509.19469v2 Announce Type: replace 
Abstract: Conversational recommendation has advanced rapidly with large language models (LLMs), yet music remains a uniquely challenging domain in which effective recommendations require reasoning over audio content beyond what text or metadata can capture. We present MusiCRS, the first benchmark for audio-centric conversational recommendation that links authentic user conversations from Reddit with corresponding tracks. MusiCRS includes 477 high-quality conversations spanning diverse genres (classical, hip-hop, electronic, metal, pop, indie, jazz), with 3,589 unique musical entities and audio grounding via YouTube links. MusiCRS supports evaluation under three input modality configurations: audio-only, query-only, and audio+query, allowing systematic comparison of audio-LLMs, retrieval models, and traditional approaches. Our experiments reveal that current systems struggle with cross-modal integration, with optimal performance frequently occurring in single-modality settings rather than multimodal configurations. This highlights fundamental limitations in cross-modal knowledge integration, as models excel at dialogue semantics but struggle when grounding abstract musical concepts in audio. To facilitate progress, we release the MusiCRS dataset (https://huggingface.co/datasets/rohan2810/MusiCRS), evaluation code (https://github.com/rohan2810/musiCRS), and comprehensive baselines.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.19469v2</guid></item><item><title>[cs updates on arXiv.org] Faster, Smaller, and Smarter: Task-Aware Expert Merging for Online MoE Inference</title><link>https://arxiv.org/abs/2509.19781</link><description>arXiv:2509.19781v2 Announce Type: replace 
Abstract: Sparse Mixture of Experts (SMoE) has become a preferred architecture for scaling Transformer capacity without increasing computational cost, as it activates only a small subset of experts for each input. However, deploying such an approach for \textit{online inference} remains challenging due to the large size of a full SMoE model and the complexity of expert routing, especially in resource-constrained edge networks. Moreover, during the online inference, task information is often unavailable, making the task-level routing error-prone. In this work, we propose a novel tree-structured adaptive neural bandit router, \texttt{Tanbr}, to enable efficient and reliable online MoE inference. Instead of relying on explicit task tags, \texttt{Tanbr} estimates the task distribution over time from historical data and uses it to guide task-aware expert merging within a given pre-trained MoE. To handle the large continuous space of merging weights, \texttt{Tanbr} employs a binary tree to progressively partition the space and generate finer candidate weights. It then applies a neural bandit to learn the non-linear mapping from merging weight to model performance and decides optimal expert merging. We prove that \texttt{Tanbr} achieves a sublinear regret bound of {\small $\mathcal{O}(\sqrt{T} \log(T))$} over {\small $T$} rounds, despite operating over a continuous decision space, matching regret bounds compared to existing methods. Extensive experiments show that \texttt{Tanbr} reduces inference latency by at least {\small $45\%$} and memory usage by up to {\small $25\%$}, while maintaining a high accuracy compared to many state-of-the-art methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.19781v2</guid></item><item><title>[cs updates on arXiv.org] LLM Watermark Evasion via Bias Inversion</title><link>https://arxiv.org/abs/2509.23019</link><description>arXiv:2509.23019v3 Announce Type: replace 
Abstract: Watermarking for large language models (LLMs) embeds a statistical signal during generation to enable detection of model-produced text. While watermarking has proven effective in benign settings, its robustness under adversarial evasion remains contested. To advance a rigorous understanding and evaluation of such vulnerabilities, we propose the \emph{Bias-Inversion Rewriting Attack} (BIRA), which is theoretically motivated and model-agnostic. BIRA weakens the watermark signal by suppressing the logits of likely watermarked tokens during LLM-based rewriting, without any knowledge of the underlying watermarking scheme. Across recent watermarking methods, BIRA achieves over 99\% evasion while preserving the semantic content of the original text. Beyond demonstrating an attack, our results reveal a systematic vulnerability, emphasizing the need for stress testing and robust defenses.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.23019v3</guid></item><item><title>[cs updates on arXiv.org] FUSAR-KLIP: Towards Multimodal Foundation Models for Remote Sensing</title><link>https://arxiv.org/abs/2509.23927</link><description>arXiv:2509.23927v4 Announce Type: replace 
Abstract: Cross-modal artificial intelligence, represented by visual language models, has achieved significant success in general image understanding. However, a fundamental cognitive inconsistency exists between general visual representation and remote sensing image interpretation: remote sensing images couple topography, terrain, and spatial structure, thereby inherently requiring models to possess deep geoscientific understanding. This cognitive difference is further amplified in synthetic aperture radar (SAR) imagery: while SAR possesses irreplaceable all-weather, all-day observation capabilities, it is constrained by coherent imaging mechanisms, exhibiting significant modal heterogeneity with general images. To address this inconsistency, we propose FUSAR-KLIP, the first knowledge-guided general multimodal foundational model for SAR, along with reusable data and evaluation baselines. Specifically: (1) FUSAR-GEOVL-1M (the first large-scale SAR dataset with complete geographic projection attributes) was constructed, covering multiple satellite platforms, 120,000 images, and 135 cities; (2) Aligned structured text was generated through hierarchical cognitive thought chains, accurately encoding more than 1 million multidimensional semantic information from geomorphological environment and regional attributes to spatial relationships; (3) A self-consistent iterative optimization mechanism was designed to guide cross-modal learning with this knowledge information consistent with human cognition and physical laws in a self-supervised closed loop consisting of contrast, matching, and reconstruction; (4) A unified evaluation benchmark was established in 11 typical downstream tasks in the two major categories of vision and language, and compared with 15 mainstream foundation models.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.23927v4</guid></item><item><title>[cs updates on arXiv.org] Flow Matching with Semidiscrete Couplings</title><link>https://arxiv.org/abs/2509.25519</link><description>arXiv:2509.25519v2 Announce Type: replace 
Abstract: Flow models parameterized as time-dependent velocity fields can generate data from noise by integrating an ODE. These models are often trained using flow matching, i.e. by sampling random pairs of noise and target points $(\mathbf{x}_0,\mathbf{x}_1)$ and ensuring that the velocity field is aligned, on average, with $\mathbf{x}_1-\mathbf{x}_0$ when evaluated along a segment linking $\mathbf{x}_0$ to $\mathbf{x}_1$. While these pairs are sampled independently by default, they can also be selected more carefully by matching batches of $n$ noise to $n$ target points using an optimal transport (OT) solver. Although promising in theory, the OT flow matching (OT-FM) approach is not widely used in practice. Zhang et al. (2025) pointed out recently that OT-FM truly starts paying off when the batch size $n$ grows significantly, which only a multi-GPU implementation of the Sinkhorn algorithm can handle. Unfortunately, the costs of running Sinkhorn can quickly balloon, requiring $O(n^2/\varepsilon^2)$ operations for every $n$ pairs used to fit the velocity field, where $\varepsilon$ is a regularization parameter that should be typically small to yield better results. To fulfill the theoretical promises of OT-FM, we propose to move away from batch-OT and rely instead on a semidiscrete formulation that leverages the fact that the target dataset distribution is usually of finite size $N$. The SD-OT problem is solved by estimating a dual potential vector using SGD; using that vector, freshly sampled noise vectors at train time can then be matched with data points at the cost of a maximum inner product search (MIPS). Semidiscrete FM (SD-FM) removes the quadratic dependency on $n/\varepsilon$ that bottlenecks OT-FM. SD-FM beats both FM and OT-FM on all training metrics and inference budget constraints, across multiple datasets, on unconditional/conditional generation, or when using mean-flow models.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.25519v2</guid></item><item><title>[cs updates on arXiv.org] LAKAN: Landmark-assisted Adaptive Kolmogorov-Arnold Network for Face Forgery Detection</title><link>https://arxiv.org/abs/2510.00634</link><description>arXiv:2510.00634v2 Announce Type: replace 
Abstract: The rapid development of deepfake generation techniques necessitates robust face forgery detection algorithms. While methods based on Convolutional Neural Networks (CNNs) and Transformers are effective, there is still room for improvement in modeling the highly complex and non-linear nature of forgery artifacts. To address this issue, we propose a novel detection method based on the Kolmogorov-Arnold Network (KAN). By replacing fixed activation functions with learnable splines, our KAN-based approach is better suited to this challenge. Furthermore, to guide the network's focus towards critical facial areas, we introduce a Landmark-assisted Adaptive Kolmogorov-Arnold Network (LAKAN) module. This module uses facial landmarks as a structural prior to dynamically generate the internal parameters of the KAN, creating an instance-specific signal that steers a general-purpose image encoder towards the most informative facial regions with artifacts. This core innovation creates a powerful combination between geometric priors and the network's learning process. Extensive experiments on multiple public datasets show that our proposed method achieves superior performance.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.00634v2</guid></item><item><title>[cs updates on arXiv.org] Developers' Perspectives on Software Licensing: Current Practices, Challenges, and Tools</title><link>https://arxiv.org/abs/2510.01096</link><description>arXiv:2510.01096v2 Announce Type: replace 
Abstract: Most modern software products incorporate open-source components, requiring development teams to maintain compliance with each component's licenses. Noncompliance can have significant financial, legal, and reputational repercussions. Although some organizations may seek advice from legal practitioners to assist with licensing tasks, developers still play a key role in this process. To this end, it is essential to understand how developers approach licensing compliance tasks, the challenges they encounter, and the tools they use. This work studies these aspects of software licensing practices through a study - conducted by a joint team of software engineering and legal researchers - consisting of a survey with 58 software developers and 7 follow-up interviews. The study resulted in 13 key findings regarding the current state of practice. We discuss the implications of our findings and offer directions for future research, as well as actionable recommendations.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.01096v2</guid></item><item><title>[cs updates on arXiv.org] Revisiting Direct Speech-to-Text Translation with Speech LLMs: Better Scaling than CoT Prompting?</title><link>https://arxiv.org/abs/2510.03093</link><description>arXiv:2510.03093v2 Announce Type: replace 
Abstract: Recent work on Speech-to-Text Translation (S2TT) has focused on LLM-based models, introducing the increasingly adopted Chain-of-Thought (CoT) prompting, where the model is guided to first transcribe the speech and then translate it. CoT typically outperforms direct prompting primarily because it can exploit abundant Automatic Speech Recognition (ASR) and Text-to-Text Translation (T2TT) datasets to explicitly model its steps. In this paper, we systematically compare CoT and Direct prompting under increasing amounts of S2TT data. To this end, we pseudo-label an ASR corpus by translating its transcriptions into six European languages, and train LLM-based S2TT systems with both prompting strategies at different data scales. Our results show that Direct improves more consistently as the amount of data increases, suggesting that it may become a more effective approach as larger S2TT resources are created.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.03093v2</guid></item><item><title>[cs updates on arXiv.org] Markovian Reeb Graphs for Simulating Spatiotemporal Patterns of Life</title><link>https://arxiv.org/abs/2510.03152</link><description>arXiv:2510.03152v2 Announce Type: replace 
Abstract: Accurately modeling human mobility is critical for urban planning, epidemiology, and traffic management. In this work, we introduce Markovian Reeb Graphs, a novel framework that transforms Reeb graphs from a descriptive analysis tool into a generative model for spatiotemporal trajectories. Our approach captures individual and population-level Patterns of Life (PoLs) and generates realistic trajectories that preserve baseline behaviors while incorporating stochastic variability by embedding probabilistic transitions within the Reeb graph structure. We present two variants: Sequential Reeb Graphs (SRGs) for individual agents and Hybrid Reeb Graphs (HRGs) that combine individual with population PoLs, evaluated on the Urban Anomalies and Geolife datasets using five mobility statistics. Results demonstrate that HRGs achieve strong fidelity across metrics while requiring modest trajectory datasets without specialized side information. This work establishes Markovian Reeb Graphs as a promising framework for trajectory simulation with broad applicability across urban environments.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.03152v2</guid></item><item><title>[cs updates on arXiv.org] Topic-Specific Classifiers are Better Relevance Judges than Prompted LLMs</title><link>https://arxiv.org/abs/2510.04633</link><description>arXiv:2510.04633v2 Announce Type: replace 
Abstract: The unjudged document problem, where systems that did not contribute to the original judgement pool may retrieve documents without a relevance judgement, is a key obstacle to the reuseability of test collections in information retrieval. While the de facto standard to deal with the problem is to treat unjudged documents as non-relevant, many alternatives have been proposed, such as the use of large language models (LLMs) as a relevance judge (LLM-as-a-judge). However, this has been criticized, among other things, as circular, since the same LLM can be used as the ranker and the judge. We propose to train topic-specific relevance classifiers instead: By finetuning monoT5 with independent LoRA weight adaptation on the judgments of a single assessor for a single topic's pool, we align it to that assessor's notion of relevance for the topic. The system rankings obtained through our classifier's relevance judgments achieve a Spearmans' $\rho$ correlation of $&gt;0.94$ with ground truth system rankings. As little as 128 initial human judgments per topic suffice to improve the comparability of models, compared to treating unjudged documents as non-relevant, while achieving more reliability than existing LLM-as-a-judge approaches. Topic-specific relevance classifiers are thus a lightweight and straightforward way to tackle the unjudged document problem, while maintaining human judgments as the gold standard for retrieval evaluation. Code, models, and data are made openly available.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.04633v2</guid></item><item><title>[cs updates on arXiv.org] CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation</title><link>https://arxiv.org/abs/2510.05122</link><description>arXiv:2510.05122v2 Announce Type: replace 
Abstract: Emotional Support Conversation (ESC) plays a vital role in alleviating psychological stress and providing emotional value through dialogue. While recent studies have largely focused on data augmentation and synthetic corpus construction, they often overlook the deeper cognitive reasoning processes that underpin effective emotional support. To address this gap, we propose \textbf{CARE}, a novel framework that strengthens reasoning in ESC without relying on large-scale synthetic data. CARE leverages the original ESC training set to guide models in generating logically coherent and supportive responses, thereby explicitly enhancing cognitive reasoning. Building on this foundation, we further employ reinforcement learning to refine and reinforce the reasoning process. Experimental results demonstrate that CARE significantly improves both the logical soundness and supportive quality of responses, advancing the development of empathetic, cognitively robust, and human-like emotional support systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.05122v2</guid></item><item><title>[cs updates on arXiv.org] Prompting in Practice: Investigating Software Practitioners' Use of Generative AI Tools</title><link>https://arxiv.org/abs/2510.06000</link><description>arXiv:2510.06000v2 Announce Type: replace 
Abstract: The use of generative AI (GenAI) tools has fundamentally transformed software development. Central to this shift is prompt engineering, the practice of crafting textual prompts to guide GenAI tools in generating useful content. Although prompt engineering has emerged as a critical skill, prior research has focused primarily on cataloging of prompting techniques, with limited attention to how software practitioners employ GenAI within real-world development workflows. To address this gap, this study presents a systematic investigation of practitioners' integration of GenAI tools into software development, drawing on a rigorous survey that examines prompting strategies, conversation patterns, and reliability assessments across core software development tasks.
  We surveyed 72 software practitioners who actively use GenAI to characterize AI usage patterns throughout the development process. By combining qualitative and quantitative analyses of the survey responses, we identified 13 key findings that describe how prompting is performed in practice. Our study shows that while code generation is nearly universal, proficiency strongly correlates with the use of GenAI for more nuanced tasks such as debugging and code review. Practitioners also tend to favor iterative multi-turn conversations to single-shot prompting. Documentation tasks are perceived as most reliable, while complex code generation and debugging remain major challenges. Our findings provide an empirical view of practitioner practices, ranging from basic code generation to deeper integration of GenAI into development workflows, enabling us to offer recommendations for improving both GenAI tools and the ways practitioners interact with them.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.06000v2</guid></item><item><title>[cs updates on arXiv.org] Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods</title><link>https://arxiv.org/abs/2510.07143</link><description>arXiv:2510.07143v2 Announce Type: replace 
Abstract: Recent efforts to accelerate inference in Multimodal Large Language Models (MLLMs) have largely focused on visual token compression. The effectiveness of these methods is commonly evaluated by measuring the accuracy drop on existing MLLM benchmarks before and after compression. However, these benchmarks are originally designed to assess general perception and reasoning abilities, rather than the specific challenges posed by visual token compression, leading to a fundamental task mismatch. In this work, we uncover a counterintuitive yet consistent phenomenon: simple image downsampling outperforms many advanced visual token compression methods across multiple widely used benchmarks. Through a comprehensive empirical study spanning eight popular benchmarks and multiple state-of-the-art compression techniques, we show that (i) current benchmarks contain substantial noise (task-irrelevant samples) for evaluating visual token compression, and (ii) downsampling can act as an effective data filter that distinguishes between simple and difficult samples with respect to compression sensitivity. Motivated by these findings, we propose VTC-Bench, an evaluation framework that explicitly leverages downsampling as a discriminator to denoise existing benchmarks, enabling a fairer and more meaningful additional assessment of visual token compression methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.07143v2</guid></item><item><title>[cs updates on arXiv.org] Proof-of-Use: Mitigating Tool-Call Hacking in Deep Research Agents</title><link>https://arxiv.org/abs/2510.10931</link><description>arXiv:2510.10931v2 Announce Type: replace 
Abstract: While reinforcement learning (RL) enhances their ability to plan and reason across retrieval steps, we identify a critical failure mode in this setting: Tool-Call Hacking. Unlike execution-based tools (e.g., code or math), whose effects are directly observable, the weak observability of causal dependencies between retrieved evidence and reasoning under format- and outcome-level supervision enables agents to maximize surface-level reward signals without genuinely grounding their reasoning in the returned evidence. This leads to distinctive pathologies, including mode collapse via tool overuse and hallucinated tool usage where tool calls are largely decorative.
  To address this issue, we propose Proof-of-Use (PoU), an evidence grounded RL framework that explicitly optimizes the causal dependency from retrieval to reasoning and final answers. PoU re-fomulate a fine-grained stepwise interaction protocol in which agents must auditably cite normalized evidence identifiers. We operationalize this via a multi-objective reward design consisting of: (1) two progressive process rewards that constrain citation validity at intermediate steps; (2) a global Answer--Support Alignment reward that enforces consistency between final answers and retrieved evidence; and (3) a curriculum-style adaptive reward mixing mechanism that smoothly transitions agents from dense process supervision to sparse outcome-based objectives. Extensive experiments show the strong performance of PoU and demonstrate the effectiveness in mitigating tool-call hacking. Beyond this, PoU exhibits a notable emergent property: adaptive and robust tool-usage patterns naturally arise under domain and tool shifts, even though PoU does not explicitly optimize for tool adaptation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.10931v2</guid></item><item><title>[cs updates on arXiv.org] Escaping Local Optima in the Waddington Landscape: A Two-Stage TRPO-PPO Approach for Single-Cell Perturbation Analysis</title><link>https://arxiv.org/abs/2510.13018</link><description>arXiv:2510.13018v2 Announce Type: replace 
Abstract: Modeling cellular responses to genetic and chemical perturbations remains a central challenge in single-cell biology. Existing data-driven frameworks have advanced perturbation prediction through variational autoencoders, chemically conditioned autoencoders, and large-scale transformer pretraining. However, most existing models rely exclusively on either in silico perturbation data or experimental perturbation data but rarely integrate both, limiting their ability to generalize and validate predictions across simulated and real biological contexts in a digital twin system. Moreover, the models are prone to local optima in the nonconvex Waddington landscape of cell fate decisions, where poor initialization can trap trajectories in spurious lineages. In this work, we introduce a two-stage reinforcement learning algorithm for modeling single-cell perturbation. We first compute an explicit natural gradient update using Fisher-vector products and a conjugate gradient solver, scaled by a KL trust-region constraint to provide a safe, curvature-aware first step for the policy. Starting with these preconditioned parameters, we then apply a second phase of proximal policy optimization (PPO) with a KL penalty, exploiting minibatch efficiency to refine the policy. We demonstrate that this initialization strategy substantially improves generalization on Single-cell RNA sequencing (scRNA-seq) perturbation analysis in a digital twin system.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.13018v2</guid></item><item><title>[cs updates on arXiv.org] DSSmoothing: Toward Certified Dataset Ownership Verification for Pre-trained Language Models via Dual-Space Smoothing</title><link>https://arxiv.org/abs/2510.15303</link><description>arXiv:2510.15303v2 Announce Type: replace 
Abstract: Large web-scale datasets have driven the rapid advancement of pre-trained language models (PLMs), but unauthorized data usage has raised serious copyright concerns. Existing dataset ownership verification (DOV) methods typically assume that watermarks remain stable during inference; however, this assumption often fails under natural noise and adversary-crafted perturbations. We propose the first certified dataset ownership verification method for PLMs under a gray-box setting (i.e., the defender can only query the suspicious model but is aware of its input representation module), based on dual-space smoothing (i.e., DSSmoothing). To address the challenges of text discreteness and semantic sensitivity, DSSmoothing introduces continuous perturbations in the embedding space to capture semantic robustness and applies controlled token reordering in the permutation space to capture sequential robustness. DSSmoothing consists of two stages: in the first stage, triggers are collaboratively embedded in both spaces to generate norm-constrained and robust watermarked datasets; in the second stage, randomized smoothing is applied in both spaces during verification to compute the watermark robustness (WR) of suspicious models and statistically compare it with the principal probability (PP) values of a set of benign models. Theoretically, DSSmoothing provides provable robustness guarantees for dataset ownership verification by ensuring that WR consistently exceeds PP under bounded dual-space perturbations. Extensive experiments on multiple representative web datasets demonstrate that DSSmoothing achieves stable and reliable verification performance and exhibits robustness against potential adaptive attacks. Our code is available at https://github.com/NcepuQiaoTing/DSSmoothing.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.15303v2</guid></item><item><title>[cs updates on arXiv.org] Visual Attention Reasoning via Hierarchical Search and Self-Verification</title><link>https://arxiv.org/abs/2510.18619</link><description>arXiv:2510.18619v3 Announce Type: replace 
Abstract: Multimodal Large Language Models (MLLMs) frequently hallucinate due to their reliance on fragile, linear reasoning and weak visual grounding. We propose Visual Attention Reasoning (VAR), a reinforcement learning framework that reformulates reasoning as a hierarchical search with self-verification. VAR enforces traceable evidence grounding by generating explicit bounding boxes, guided by a novel reward function combining geometric precision and semantic sufficiency. Furthermore, it replaces linear Chain-of-Thought with a tree-search policy capable of backtracking to correct logical errors. Theoretical analysis validates the framework's reliability, and extensive experiments demonstrate that VAR significantly outperforms state-of-the-art methods on complex hallucination and safety benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.18619v3</guid></item><item><title>[cs updates on arXiv.org] Exploring Generative Process Reward Modeling for Semi-Structured Data: A Case Study of Table Question Answering</title><link>https://arxiv.org/abs/2510.20304</link><description>arXiv:2510.20304v2 Announce Type: replace 
Abstract: Process reward models (PRMs) enhance complex reasoning in large language models (LLMs) by evaluating candidate solutions step-by-step and selecting answers based on aggregated step scores. While effective in domains such as mathematics, their applicability to tasks involving semi-structured data, like table question answering (TQA), remains unexplored. TQA poses unique challenges for PRMs, including abundant irrelevant information, loosely connected reasoning steps, and domain-specific reasoning. This work presents the first systematic study of PRMs for TQA. We evaluate state-of-the-art generative PRMs on TQA from both answer and step perspectives. Results show that PRMs that combine textual and code verification can aid solution selection but struggle to generalize to out-of-domain data. Analysis reveals a weak correlation between performance in step-level verification and answer accuracy, possibly stemming from weak step dependencies and loose causal links. Our findings highlight limitations of current PRMs on TQA and offer valuable insights for building more robust, process-aware verifiers.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.20304v2</guid></item><item><title>[cs updates on arXiv.org] Toward Practical Deductive Verification: Insights from a Qualitative Survey in Industry and Academia</title><link>https://arxiv.org/abs/2510.20514</link><description>arXiv:2510.20514v2 Announce Type: replace 
Abstract: Deductive verification is an effective method to ensure that a given system exposes the intended behavior. In spite of its proven usefulness and feasibility in selected projects, deductive verification is still not a mainstream technique. To pave the way to widespread use, we present a study investigating the factors enabling successful applications of deductive verification and the underlying issues preventing broader adoption. We conducted semi-structured interviews with 30 practitioners of verification from both industry and academia and systematically analyzed the collected data employing a thematic analysis approach. Beside empirically confirming familiar challenges, e.g., the high level of expertise needed for conducting formal proofs, our data reveal several underexplored obstacles, such as proof maintenance, insufficient control over automation, and usability concerns. We further use the results from our data analysis to extract enablers and barriers for deductive verification and formulate concrete recommendations for practitioners, tool builders, and researchers, including principles for usability, automation, and integration with existing workflows.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.20514v2</guid></item><item><title>[cs updates on arXiv.org] Efficient semantic uncertainty quantification in language models via diversity-steered sampling</title><link>https://arxiv.org/abs/2510.21310</link><description>arXiv:2510.21310v2 Announce Type: replace 
Abstract: Accurately estimating semantic aleatoric and epistemic uncertainties in large language models (LLMs) is particularly challenging in free-form question answering (QA), where obtaining stable estimates often requires many expensive generations. We introduce a diversity-steered sampler that discourages semantically redundant outputs during decoding, covers both autoregressive and masked diffusion paradigms, and yields substantial sample-efficiency gains. The key idea is to inject a continuous semantic-similarity penalty into the model's proposal distribution using a natural language inference (NLI) model lightly finetuned on partial prefixes or intermediate diffusion states. We debias downstream uncertainty estimates with importance reweighting and shrink their variance with control variates. Across four QA benchmarks, our method matches or surpasses baselines while covering more semantic clusters with the same number of samples. Being modular and requiring no gradient access to the base LLM, the framework promises to serve as a drop-in enhancement for uncertainty estimation in risk-sensitive model deployments.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.21310v2</guid></item><item><title>[cs updates on arXiv.org] SciNUP: Natural Language User Interest Profiles for Scientific Literature Recommendation</title><link>https://arxiv.org/abs/2510.21352</link><description>arXiv:2510.21352v2 Announce Type: replace 
Abstract: The use of natural language (NL) user profiles in recommender systems offers greater transparency and user control compared to traditional representations. However, there is scarcity of large-scale, publicly available test collections for evaluating NL profile-based recommendation. To address this gap, we introduce SciNUP, a novel synthetic dataset for scholarly recommendation that leverages authors' publication histories to generate NL profiles and corresponding ground truth items. We use this dataset to conduct a comparison of baseline methods, ranging from sparse and dense retrieval approaches to state-of-the-art LLM-based rerankers. Our results show that while baseline methods achieve comparable performance, they often retrieve different items, indicating complementary behaviors. At the same time, considerable headroom for improvement remains, highlighting the need for effective NL-based recommendation approaches. The SciNUP dataset thus serves as a valuable resource for fostering future research and development in this area.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.21352v2</guid></item><item><title>[cs updates on arXiv.org] A Multi-Stage Hybrid Framework for Automated Interpretation of Multi-View Engineering Drawings Using Vision Language Model</title><link>https://arxiv.org/abs/2510.21862</link><description>arXiv:2510.21862v2 Announce Type: replace 
Abstract: Engineering drawings are fundamental to manufacturing communication, serving as the primary medium for conveying design intent, tolerances, and production details. However, interpreting complex multi-view drawings with dense annotations remains challenging using manual methods, generic optical character recognition (OCR) systems, or traditional deep learning approaches, due to varied layouts, orientations, and mixed symbolic-textual content. To address these challenges, this paper proposes a three-stage hybrid framework for the automated interpretation of 2D multi-view engineering drawings using modern detection and vision language models (VLMs). In the first stage, YOLOv11-det performs layout segmentation to localize key regions such as views, title blocks, and notes. The second stage uses YOLOv11-obb for orientation-aware, fine-grained detection of annotations, including measures, GD&amp;amp;T symbols, and surface roughness indicators. The third stage employs two Donut-based, OCR-free VLMs for semantic content parsing: the Alphabetical VLM extracts textual and categorical information from title blocks and notes, while the Numerical VLM interprets quantitative data such as measures, GD&amp;amp;T frames, and surface roughness. Two specialized datasets were developed to ensure robustness and generalization: 1,000 drawings for layout detection and 1,406 for annotation-level training. The Alphabetical VLM achieved an overall F1 score of 0.672, while the Numerical VLM reached 0.963, demonstrating strong performance in textual and quantitative interpretation, respectively. The unified JSON output enables seamless integration with CAD and manufacturing databases, providing a scalable solution for intelligent engineering drawing analysis.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.21862v2</guid></item><item><title>[cs updates on arXiv.org] AutoSciDACT: Automated Scientific Discovery through Contrastive Embedding and Hypothesis Testing</title><link>https://arxiv.org/abs/2510.21935</link><description>arXiv:2510.21935v2 Announce Type: replace 
Abstract: Novelty detection in large scientific datasets faces two key challenges: the noisy and high-dimensional nature of experimental data, and the necessity of making statistically robust statements about any observed outliers. While there is a wealth of literature on anomaly detection via dimensionality reduction, most methods do not produce outputs compatible with quantifiable claims of scientific discovery. In this work we directly address these challenges, presenting the first step towards a unified pipeline for novelty detection adapted for the rigorous statistical demands of science. We introduce AutoSciDACT (Automated Scientific Discovery with Anomalous Contrastive Testing), a general-purpose pipeline for detecting novelty in scientific data. AutoSciDACT begins by creating expressive low-dimensional data representations using a contrastive pre-training, leveraging the abundance of high-quality simulated data in many scientific domains alongside expertise that can guide principled data augmentation strategies. These compact embeddings then enable an extremely sensitive machine learning-based two-sample test using the New Physics Learning Machine (NPLM) framework, which identifies and statistically quantifies deviations in observed data relative to a reference distribution (null hypothesis). We perform experiments across a range of astronomical, physical, biological, image, and synthetic datasets, demonstrating strong sensitivity to small injections of anomalous data across all domains.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.21935v2</guid></item><item><title>[cs updates on arXiv.org] DeepShield: Fortifying Deepfake Video Detection with Local and Global Forgery Analysis</title><link>https://arxiv.org/abs/2510.25237</link><description>arXiv:2510.25237v2 Announce Type: replace 
Abstract: Recent advances in deep generative models have made it easier to manipulate face videos, raising significant concerns about their potential misuse for fraud and misinformation. Existing detectors often perform well in in-domain scenarios but fail to generalize across diverse manipulation techniques due to their reliance on forgery-specific artifacts. In this work, we introduce DeepShield, a novel deepfake detection framework that balances local sensitivity and global generalization to improve robustness across unseen forgeries. DeepShield enhances the CLIP-ViT encoder through two key components: Local Patch Guidance (LPG) and Global Forgery Diversification (GFD). LPG applies spatiotemporal artifact modeling and patch-wise supervision to capture fine-grained inconsistencies often overlooked by global models. GFD introduces domain feature augmentation, leveraging domain-bridging and boundary-expanding feature generation to synthesize diverse forgeries, mitigating overfitting and enhancing cross-domain adaptability. Through the integration of novel local and global analysis for deepfake detection, DeepShield outperforms state-of-the-art methods in cross-dataset and cross-manipulation evaluations, achieving superior robustness against unseen deepfake attacks. Code is available at https://github.com/lijichang/DeepShield.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.25237v2</guid></item><item><title>[cs updates on arXiv.org] Enhancing ECG Classification Robustness with Lightweight Unsupervised Anomaly Detection Filters</title><link>https://arxiv.org/abs/2510.26501</link><description>arXiv:2510.26501v2 Announce Type: replace 
Abstract: Continuous electrocardiogram (ECG) monitoring via wearable devices is vital for early cardiovascular disease detection. However, deploying deep learning models on resource-constrained microcontrollers faces reliability challenges, particularly from Out-of-Distribution (OOD) pathologies and noise. Standard classifiers often yield high-confidence errors on such data. Existing OOD detection methods either neglect computational constraints or address noise and unseen classes separately. This paper investigates Unsupervised Anomaly Detection (UAD) as a lightweight, upstream filtering mechanism. We perform a Neural Architecture Search (NAS) on six UAD approaches, including Deep Support Vector Data Description (Deep SVDD), input reconstruction with (Variational-)Autoencoders (AE/VAE), Masked Anomaly Detection (MAD), Normalizing Flows (NFs) and Denoising Diffusion Probabilistic Models (DDPM) under strict hardware constraints ($\leq$512k parameters), suitable for microcontrollers. Evaluating on the PTB-XL and BUT QDB datasets, we demonstrate that a NAS-optimized Deep SVDD offers the superior Pareto efficiency between detection performance and model size. In a simulated deployment, this lightweight filter improves the accuracy of a diagnostic classifier by up to 21.0 percentage points, demonstrating that optimized UAD filters can safeguard ECG analysis on wearables.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.26501v2</guid></item><item><title>[cs updates on arXiv.org] Systematizing LLM Persona Design: A Four-Quadrant Technical Taxonomy for AI Companion Applications</title><link>https://arxiv.org/abs/2511.02979</link><description>arXiv:2511.02979v2 Announce Type: replace 
Abstract: The design and application of LLM-based personas in AI companionship is a rapidly expanding but fragmented field, spanning from virtual emotional companions and game NPCs to embodied functional robots. This diversity in objectives, modality, and technical stacks creates an urgent need for a unified framework. To address this gap, this paper systematizes the field by proposing a Four-Quadrant Technical Taxonomy for AI companion applications. The framework is structured along two critical axes: Virtual vs. Embodied and Emotional Companionship vs. Functional Augmentation. Quadrant I (Virtual Companionship) explores virtual idols, romantic companions, and story characters, introducing a four-layer technical framework to analyze their challenges in maintaining long-term emotional consistency. Quadrant II (Functional Virtual Assistants) analyzes AI applications in work, gaming, and mental health, highlighting the shift from "feeling" to "thinking and acting" and pinpointing key technologies like enterprise RAG and on-device inference. Quadrants III &amp; IV (Embodied Intelligence) shift from the virtual to the physical world, analyzing home robots and vertical-domain assistants, revealing core challenges in symbol grounding, data privacy, and ethical liability. This taxonomy provides not only a systematic map for researchers and developers to navigate the complex persona design space but also a basis for policymakers to identify and address the unique risks inherent in different application scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.02979v2</guid></item><item><title>[cs updates on arXiv.org] Tunable Passivity Control for Centralized Multiport Networked Systems</title><link>https://arxiv.org/abs/2511.05026</link><description>arXiv:2511.05026v2 Announce Type: replace 
Abstract: Centralized Multiport Networked Dynamic (CMND) systems have emerged as a key architecture with applications in several complex network systems, such as multilateral telerobotics and multi-agent control. These systems consist of a hub node/subsystem connecting with multiple remote nodes/subsystems via a networked architecture. One challenge for this system is stability, which can be affected by non-ideal network artifacts. Conventional passivity-based approaches can stabilize the system under specialized applications like small-scale networked systems. However, those conventional passive stabilizers have several restrictions, such as distributing compensation across subsystems in a decentralized manner, limiting flexibility, and, at the same time, relying on the restrictive assumptions of node passivity. This paper synthesizes a centralized optimal passivity-based stabilization framework for CMND systems. It consists of a centralized passivity observer monitoring overall energy flow and an optimal passivity controller that distributes the just-needed dissipation among various nodes, guaranteeing strict passivity and, thus, L2 stability. The proposed data-driven model-free approach, i.e., Tunable Centralized Optimal Passivity Control (TCoPC), optimizes total performance based on the prescribed dissipation distribution strategy while ensuring stability. The controller can put high dissipation loads on some sub-networks while relaxing the dissipation on other nodes. Simulation results demonstrate the proposed frameworks performance in a complex task under different time-varying delay scenarios while relaxing the remote nodes minimum phase and passivity assumption, enhancing the scalability and generalizability.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.05026v2</guid></item><item><title>[cs updates on arXiv.org] LATTLE: LLM Attention Transplant for Transfer Learning of Tabular Data Across Disparate Domains</title><link>https://arxiv.org/abs/2511.06161</link><description>arXiv:2511.06161v2 Announce Type: replace 
Abstract: Transfer learning on tabular data is challenging due to disparate feature spaces across domains, in contrast to the homogeneous structures of image and text. Large language models (LLMs) offer a knowledge base to improve the limited effectiveness of cross-domain transfer learning for tabular data. However, LLM performance often stagnates due to subjective text prompts and the computational limitations of in-context learning. We present a novel language-to-tabular context-learning method that uses attention-specific transformer weights, enabling seamless transfer learning across disparate tabular data sets. The LLM attention transplant mechanism facilitates a domain-agnostic transfer learning, eliminating the need for shared features between tables, LLM prompt engineering, and large-scale pretrained models. Our experiments using ten pairs of disjoint source-target data sets and 12 baseline methods demonstrate the superiority of the proposed LLM-attention transplant for transfer learning (LATTLE) method over traditional ML models, state-of-the-art deep tabular architectures, and models trained on thousands to billions of tabular samples. The proposed cross-domain attention transfer demonstrates an effective solution for adapting LLMs to learning non-text tabular data in a low-resource environment. The source code of the LATTLE implementation is publicly available.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.06161v2</guid></item><item><title>[cs updates on arXiv.org] Koopman Invariants as Drivers of Emergent Time-Series Clustering in Joint-Embedding Predictive Architectures</title><link>https://arxiv.org/abs/2511.09783</link><description>arXiv:2511.09783v2 Announce Type: replace 
Abstract: Joint-Embedding Predictive Architectures (JEPAs), a powerful class of self-supervised models, exhibit an unexplained ability to cluster time-series data by their underlying dynamical regimes. We propose a novel theoretical explanation for this phenomenon, hypothesizing that JEPA's predictive objective implicitly drives it to learn the invariant subspace of the system's Koopman operator. We prove that an idealized JEPA loss is minimized when the encoder represents the system's regime indicator functions, which are Koopman eigenfunctions. This theory was validated on synthetic data with known dynamics, demonstrating that constraining the JEPA's linear predictor to be a near-identity operator is the key inductive bias that forces the encoder to learn these invariants. We further discuss that this constraint is critical for selecting this interpretable solution from a class of mathematically equivalent but entangled optima, revealing the predictor's role in representation disentanglement. This work demystifies a key behavior of JEPAs, provides a principled connection between modern self-supervised learning and dynamical systems theory, and informs the design of more robust and interpretable time-series models.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.09783v2</guid></item><item><title>[cs updates on arXiv.org] Constrained Best Arm Identification with Tests for Feasibility</title><link>https://arxiv.org/abs/2511.09808</link><description>arXiv:2511.09808v2 Announce Type: replace 
Abstract: Best arm identification (BAI) aims to identify the highest-performance arm among a set of $K$ arms by collecting stochastic samples from each arm. In real-world problems, the best arm needs to satisfy additional feasibility constraints. While there is limited prior work on BAI with feasibility constraints, they typically assume the performance and constraints are observed simultaneously on each pull of an arm. However, this assumption does not reflect most practical use cases, e.g., in drug discovery, we wish to find the most potent drug whose toxicity and solubility are below certain safety thresholds. These safety experiments can be conducted separately from the potency measurement. Thus, this requires designing BAI algorithms that not only decide which arm to pull but also decide whether to test for the arm's performance or feasibility. In this work, we study feasible BAI which allows a decision-maker to choose a tuple $(i,\ell)$, where $i\in [K]$ denotes an arm and $\ell$ denotes whether she wishes to test for its performance ($\ell=0$) or any of its $N$ feasibility constraints ($\ell\in[N]$). We focus on the fixed confidence setting, which is to identify the feasible arm with the highest performance, with a probability of at least $1-\delta$. We propose an efficient algorithm and upper-bound its sample complexity, showing our algorithm can naturally adapt to the problem's difficulty and eliminate arms by worse performance or infeasibility, whichever is easier. We complement this upper bound with a lower bound showing that our algorithm is \textit{asymptotically ($\delta\rightarrow 0$) optimal}. Finally, we empirically show that our algorithm outperforms other state-of-the-art BAI algorithms in both synthetic and real-world datasets.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.09808v2</guid></item><item><title>[cs updates on arXiv.org] Speech-Aware Long Context Pruning and Integration for Contextualized Automatic Speech Recognition</title><link>https://arxiv.org/abs/2511.11139</link><description>arXiv:2511.11139v2 Announce Type: replace 
Abstract: Automatic speech recognition (ASR) systems have achieved remarkable performance in common conditions but often struggle to leverage long-context information in contextualized scenarios that require domain-specific knowledge, such as conference presentations. This challenge arises primarily due to constrained model context windows and the sparsity of relevant information within extensive contextual noise. To solve this, we propose the SAP$^{2}$ method, a novel framework that dynamically prunes and integrates relevant contextual keywords in two stages. Specifically, each stage leverages our proposed Speech-Driven Attention-based Pooling mechanism, enabling efficient compression of context embeddings while preserving speech-salient information. Experimental results demonstrate state-of-the-art performance of SAP$^{2}$ on the SlideSpeech and LibriSpeech datasets, achieving word error rates (WER) of 7.71% and 1.12%, respectively. On SlideSpeech, our method notably reduces biased keyword error rates (B-WER) by 41.1% compared to non-contextual baselines. SAP$^{2}$ also exhibits robust scalability, consistently maintaining performance under extensive contextual input conditions on both datasets.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.11139v2</guid></item><item><title>[cs updates on arXiv.org] Robust H-infinity control and worst-case search in constrained parametric space</title><link>https://arxiv.org/abs/2511.15480</link><description>arXiv:2511.15480v4 Announce Type: replace 
Abstract: Standard H-infinity/H2 robust control and analysis tools operate on uncertain parameters assumed to vary independently within prescribed bounds. This paper extends their capabilities in the presence of constraints coupling these parameters and restricting the parametric space. Focusing on the worst-case search, we demonstrate - based on the theory of upper-C1 functions - the validity of using standard, readily available smooth optimization algorithms to address this nonsmooth constrained optimization problem. In particular, we prove that the sequential quadratic programming algorithm converges to Karush-Kuhn-Tucker points, and that such conditions are satisfied by any subgradient at a local minimum. This worst-case search then enables robust controller synthesis: identified worst-case configurations are iteratively added to an active set on which a non-smooth multi-models optimization of the controller is performed. The methodology is illustrated on a satellite benchmark with flexible appendages, of order 50 with 43 uncertain parameters. From a practical point of view, we combine the local exploitation proposed above with a global exploration using either Monte-Carlo sampling or particle swarm optimization. We show that the proposed constrained optimization effectively complements Monte-Carlo sampling by enabling fast detection of rare worst-case configurations, and that the robust controller optimization converges with less than 10 active configurations.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.15480v4</guid></item><item><title>[cs updates on arXiv.org] Intelligent Systems in Neuroimaging: Pioneering AI Techniques for Brain Tumor Detection</title><link>https://arxiv.org/abs/2511.17655</link><description>arXiv:2511.17655v2 Announce Type: replace 
Abstract: This study deliberates on the application of advanced AI techniques for brain tumor classification through MRI, wherein the training includes the present best deep learning models to enhance diagnosis accuracy and the potential of usability in clinical practice. By combining custom convolutional models with pre-trained neural network architectures, our approach exposes the utmost performance in the classification of four classes: glioma, meningioma, pituitary tumors, and no-tumor cases. Assessing the models on a large dataset of over 7,000 MRI images focused on detection accuracy, computational efficiency, and generalization to unseen data. The results indicate that the Xception architecture surpasses all other were tested, obtaining a testing accuracy of 98.71% with the least validation loss. While presenting this case with findings that demonstrate AI as a probable scorer in brain tumor diagnosis, we demonstrate further motivation by reducing computational complexity toward real-world clinical deployment. These aspirations offer an abundant future for progress in automated neuroimaging diagnostics.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.17655v2</guid></item><item><title>[cs updates on arXiv.org] LLM Reasoning for Cold-Start Item Recommendation</title><link>https://arxiv.org/abs/2511.18261</link><description>arXiv:2511.18261v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) have shown significant potential for improving recommendation systems through their inherent reasoning capabilities and extensive knowledge base. Yet, existing studies predominantly address warm-start scenarios with abundant user-item interaction data, leaving the more challenging cold-start scenarios, where sparse interactions hinder traditional collaborative filtering methods, underexplored. To address this limitation, we propose novel reasoning strategies designed for cold-start item recommendations within the Netflix domain. Our method utilizes the advanced reasoning capabilities of LLMs to effectively infer user preferences, particularly for newly introduced or rarely interacted items. We systematically evaluate supervised fine-tuning, reinforcement learning-based fine-tuning, and hybrid approaches that combine both methods to optimize recommendation performance. Extensive experiments on real-world data demonstrate significant improvements in both methodological efficacy and practical performance in cold-start recommendation contexts. Remarkably, our reasoning-based fine-tuned models outperform Netflix's production ranking model by up to 8% in certain cases.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.18261v3</guid></item><item><title>[cs updates on arXiv.org] SCoTER: Structured Chain-of-Thought Transfer for Enhanced Recommendation</title><link>https://arxiv.org/abs/2511.19514</link><description>arXiv:2511.19514v4 Announce Type: replace 
Abstract: Harnessing the reasoning power of Large Language Models (LLMs) for recommender systems is hindered by two fundamental challenges. First, current approaches lack a mechanism for automated, data-driven discovery of effective reasoning patterns, relying instead on brittle manual templates or unstable zero-shot prompting. Second, they employ structure-collapsing integration: direct prompting incurs prohibitive online inference costs, while feature extraction collapses reasoning chains into single vectors, discarding stepwise logic. To address these challenges, we propose SCoTER (Structured Chain-of-Thought Transfer for Enhanced Recommendation), a unified framework that treats pattern discovery and structure-aware transfer as a jointly optimized problem. Specifically, SCoTER operationalizes this through two synergistic components: a GVM pipeline for automated pattern discovery and a structure-preserving integration architecture that transfers stepwise logic to efficient models. Formally, we provide information-theoretic justification proving that structure-preserving transfer achieves tighter performance bounds than structure-agnostic alternatives. Empirically, experiments on four benchmarks demonstrate improvements of 3.75\%-11.59\% over a strong TIGER backbone. Moreover, in production deployment on the Tencent Advertising Platform, SCoTER achieved a 2.14\% lift in Gross Merchandise Value (GMV) while eliminating online LLM inference costs. Overall, SCoTER establishes a principled and production-validated blueprint for transferring structured LLM reasoning to large-scale recommender systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.19514v4</guid></item><item><title>[cs updates on arXiv.org] Coupled Physics-Gated Adaptation: Spatially Decoding Volumetric Photochemical Conversion in Complex 3D-Printed Objects</title><link>https://arxiv.org/abs/2511.19913</link><description>arXiv:2511.19913v2 Announce Type: replace 
Abstract: We present a framework that pioneers the prediction of photochemical conversion in complex three-dimensionally printed objects, introducing a challenging new computer vision task: predicting dense, non-visual volumetric physical properties from 3D visual data. This approach leverages the largest-ever optically printed 3D specimen dataset, comprising a large family of parametrically designed complex minimal surface structures that have undergone terminal chemical characterisation. Conventional vision models are ill-equipped for this task, as they lack an inductive bias for the coupled, non-linear interactions of optical physics (diffraction, absorption) and material physics (diffusion, convection) that govern the final chemical state. To address this, we propose Coupled Physics-Gated Adaptation (C-PGA), a novel multimodal fusion architecture. Unlike standard concatenation, C-PGA explicitly models physical coupling by using sparse geometrical and process parameters (e.g., surface transport, print layer height) as a Query to dynamically gate and adapt the dense visual features via feature-wise linear modulation (FiLM). This mechanism spatially modulates dual 3D visual streams-extracted by parallel 3D-CNNs processing raw projection stacks and their diffusion-diffraction corrected counterparts allowing the model to recalibrate its visual perception based on the physical context. This approach offers a breakthrough in virtual chemical characterisation, eliminating the need for traditional post-print measurements and enabling precise control over the chemical conversion state.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.19913v2</guid></item><item><title>[cs updates on arXiv.org] A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media</title><link>https://arxiv.org/abs/2511.20001</link><description>arXiv:2511.20001v3 Announce Type: replace 
Abstract: Mental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating scalable and interpretable detection systems. This paper introduces a unified multiclass classification framework for detecting ten distinct mental health and cyberbullying categories from social media data. We curate datasets from Twitter and Reddit, implementing a rigorous "split-then-balance" pipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We conducted a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is critical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a human-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAPLLM explainability framework and present a prototype dashboard ("Social Media Screener") designed to integrate model predictions and their explanations into a practical workflow for moderators. Our work provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets at the critical intersection of online safety and computational mental health.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.20001v3</guid></item><item><title>[cs updates on arXiv.org] Strong Normalization for the Safe Fragment of a Minimal Rewrite System: A Triple-Lexicographic Proof and a Conjecture on the Unprovability of Full Termination for Any Relational Operator-Only TRS</title><link>https://arxiv.org/abs/2512.00081</link><description>arXiv:2512.00081v2 Announce Type: replace 
Abstract: This paper presents a minimal operator-only term rewriting system with seven constructors and eight reduction rules. The main contribution is a mechanically-verified proof of strong normalization for a guarded fragment using a novel triple-lexicographic measure combining a phase bit, multiset ordering (Dershowitz-Manna), and ordinal ranking. From strong normalization, a certified normalizer with proven totality and soundness is derived. Assuming local confluence (verified through critical pair analysis), Newman's Lemma yields confluence and therefore unique normal forms for the safe fragment. Impossibility results showing that simpler measures, such as additive counters, polynomial interpretations, and single-bit flags, provably fail for rules with term duplication, are established. The work demonstrates fundamental limitations in termination proving for self-referential systems. A conjecture is stated: no relational operator-only TRS can have its full-system termination proved by internally definable methods. Here "relational" is equivalent to "capable of ordered computation": systems with a recursor enabling iteration over successors, comparison, or sequential counting. Such recursors necessarily redistribute step arguments across recursive calls, defeating all additive termination measures. This structural limitation applies to any TRS expressive enough to encode ordered data. All theorems have been formally verified in a proof assistant. The Lean formalization is available at https://github.com/MosesRahnama/OperatorKO7.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.00081v2</guid></item><item><title>[cs updates on arXiv.org] Pre-Generating Multi-Difficulty PDE Data for Few-Shot Neural PDE Solvers</title><link>https://arxiv.org/abs/2512.00564</link><description>arXiv:2512.00564v2 Announce Type: replace 
Abstract: A key aspect of learned partial differential equation (PDE) solvers is that the main cost often comes from generating training data with classical solvers rather than learning the model itself. Another is that there are clear axes of difficulty--e.g., more complex geometries and higher Reynolds numbers--along which problems become (1) harder for classical solvers and thus (2) more likely to benefit from neural speedups. Towards addressing this chicken-and-egg challenge, we study difficulty transfer on 2D incompressible Navier-Stokes, systematically varying task complexity along geometry (number and placement of obstacles), physics (Reynolds number), and their combination. Similar to how it is possible to spend compute to pre-train foundation models and improve their performance on downstream tasks, we find that by classically solving (analogously pre-generating) many low and medium difficulty examples and including them in the training set, it is possible to learn high-difficulty physics from far fewer samples. Furthermore, we show that by combining low and high difficulty data, we can spend 8.9x less compute on pre-generating a dataset to achieve the same error as using only high difficulty examples. Our results highlight that how we allocate classical-solver compute across difficulty levels is as important as how much we allocate overall, and suggest substantial gains from principled curation of pre-generated PDE data for neural solvers. Our code is available at https://github.com/Naman-Choudhary-AI-ML/pregenerating-pde</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.00564v2</guid></item><item><title>[cs updates on arXiv.org] SimWorld: An Open-ended Realistic Simulator for Autonomous Agents in Physical and Social Worlds</title><link>https://arxiv.org/abs/2512.01078</link><description>arXiv:2512.01078v2 Announce Type: replace 
Abstract: While LLM/VLM-powered AI agents have advanced rapidly in math, coding, and computer use, their applications in complex physical and social environments remain challenging. Building agents that can survive and thrive in the real world (for example, by autonomously earning income or running a business) requires massive-scale interaction, reasoning, training, and evaluation across diverse embodied scenarios. However, existing world simulators for such development fall short: they often rely on limited hand-crafted environments, simulate simplified game-like physics and social rules, and lack native support for LLM/VLM agents. We introduce SimWorld, a new simulator built on Unreal Engine 5, designed for developing and evaluating LLM/VLM agents in rich, real-world-like settings. SimWorld offers three core capabilities: (1) realistic, open-ended world simulation, including accurate physical and social dynamics and language-driven procedural environment generation; (2) a rich interface for LLM/VLM agents, with multimodal world inputs and open-vocabulary actions at varying levels of abstraction; and (3) diverse and extensible physical and social reasoning scenarios that are easily customizable by users. We demonstrate SimWorld by deploying frontier LLM agents (e.g., GPT-4o, Gemini-2.5-Flash, Claude-3.5, and DeepSeek-Prover-V2) on long-horizon multi-agent delivery tasks involving strategic cooperation and competition. The results reveal distinct reasoning patterns and limitations across models. We open-source SimWorld and hope it becomes a foundational platform for advancing real-world agent intelligence across disciplines: https://simworld.org.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.01078v2</guid></item><item><title>[cs updates on arXiv.org] Fourier Neural Operators Explained: A Practical Perspective</title><link>https://arxiv.org/abs/2512.01421</link><description>arXiv:2512.01421v2 Announce Type: replace 
Abstract: Partial differential equations (PDEs) govern a wide variety of dynamical processes in science and engineering, yet obtaining their numerical solutions often requires high-resolution discretizations and repeated evaluations of complex operators, leading to substantial computational costs. Neural operators have recently emerged as a powerful framework for learning mappings between function spaces directly from data, enabling efficient surrogate models for PDE systems. Among these architectures, the Fourier Neural Operator (FNO) has become the most influential and widely adopted due to its elegant spectral formulation, which captures global correlations through learnable transformations in Fourier space while remaining invariant to discretization and resolution. Despite their success, the practical use of FNOs is often hindered by an incomplete understanding among practitioners of their theoretical foundations, practical constraints, and implementation details, which can lead to their incorrect or unreliable application. This work presents a comprehensive and practice-oriented guide to FNOs, unifying their mathematical principles with implementation strategies. We provide an intuitive exposition to the concepts of operator theory and signal-processing that underlie the FNO, detail its spectral parameterization and the computational design of all its components, and address common misunderstandings encountered in the literature. The exposition is closely integrated with the NeuralOperator 2.0.0 library, offering modular state-of-the-art implementations that faithfully reflect the theory. By connecting rigorous foundations with practical insight, this guide aims to establish a clear and reliable framework for applying FNOs effectively across diverse scientific and engineering fields.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.01421v2</guid></item><item><title>[cs updates on arXiv.org] MoE-Enhanced Multi-Domain Feature Selection and Fusion for Fast Map-Free Trajectory Prediction</title><link>https://arxiv.org/abs/2512.02368</link><description>arXiv:2512.02368v2 Announce Type: replace 
Abstract: Trajectory prediction is crucial for the reliability and safety of autonomous driving systems, yet it remains a challenging task in complex interactive scenarios due to noisy trajectory observations and intricate agent interactions. Existing methods often struggle to filter redundant scene data for discriminative information extraction, directly impairing trajectory prediction accuracy especially when handling outliers and dynamic multi-agent interactions. In response to these limitations, we present a novel map-free trajectory prediction method which adaptively eliminates redundant information and selects discriminative features across the temporal, spatial, and frequency domains, thereby enabling precise trajectory prediction in real-world driving environments. First, we design a MoE based frequency domain filter to adaptively weight distinct frequency components of observed trajectory data and suppress outlier related noise; then a selective spatiotemporal attention module that reallocates weights across temporal nodes (sequential dependencies), temporal trends (evolution patterns), and spatial nodes to extract salient information is proposed. Finally, our multimodal decoder-supervised by joint patch level and point-level losses generates reasonable and temporally consistent trajectories, and comprehensive experiments on the large-scale NuScenes and Argoverse dataset demonstrate that our method achieves competitive performance and low-latency inference performance compared with recently proposed methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.02368v2</guid></item><item><title>[cs updates on arXiv.org] One-Step Generative Channel Estimation via Average Velocity Field</title><link>https://arxiv.org/abs/2512.04501</link><description>arXiv:2512.04501v2 Announce Type: replace 
Abstract: Generative models have shown immense potential for wireless communication by learning complex channel data distributions. However, the iterative denoising process associated with these models imposes a significant challenge in latency-sensitive wireless communication scenarios, particularly in channel estimation. To address this challenge, we propose a novel solution for one-step generative channel estimation. Our approach bypasses the time-consuming iterative steps of conventional models by directly learning the average velocity field. Through extensive simulations, we validate the effectiveness of our proposed method over existing state-of-the-art diffusion-based approach. Specifically, our scheme achieves a normalized mean squared error up to 2.65 dB lower than the diffusion method and reduces latency by around 90%, demonstrating the potential of our method to enhance channel estimation performance.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.04501v2</guid></item><item><title>[cs updates on arXiv.org] Small-Signal Stability Oriented Real-Time Operation of Power Systems with a High Penetration of Inverter-Based Resources</title><link>https://arxiv.org/abs/2512.04892</link><description>arXiv:2512.04892v2 Announce Type: replace 
Abstract: This study proposes a control strategy to ensure the safe operation of modern power systems with high penetration of inverter-based resources (IBRs) within an optimal operation framework. The objective is to obtain operating points that satisfy the optimality conditions of a predefined problem while guaranteeing small-signal stability. The methodology consists of two stages. First, an offline analysis of a set of operating points is performed to derive a data-driven regression-based expression that captures a damping-based stability index as a function of the operating conditions. Second, an Online Feedback Optimization (OFO) controller is employed to drive the system toward an optimal operating point while maintaining a secure distance from the instability region. The proposed strategy is evaluated on an academic test case based on a modified version of the IEEE 9-bus system, in which synchronous generators are replaced by IBRs operating under both grid-following and grid-forming control modes. The results demonstrate the effectiveness of the method and are discussed in detail.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.04892v2</guid></item><item><title>[cs updates on arXiv.org] Data Generation for Stability Studies of Power Systems with High Penetration of Inverter-Based Resources</title><link>https://arxiv.org/abs/2512.06369</link><description>arXiv:2512.06369v2 Announce Type: replace 
Abstract: The increasing penetration of inverter-based resources (IBRs) is fundamentally reshaping power system dynamics and creating new challenges for stability assessment. Data-driven approaches, and in particular machine learning models, require large and representative datasets that capture how system stability varies across a wide range of operating conditions and control settings. This paper presents an open-source, high-performance computing framework for the systematic generation of such datasets. The proposed tool defines a scalable operating space for large-scale power systems, explores it through an adaptive sampling strategy guided by sensitivity analysis, and performs small-signal stability assessments to populate a high-information-content dataset. The framework efficiently targets regions near the stability margin while maintaining broad coverage of feasible operating conditions. The workflow is fully implemented in Python and designed for parallel execution. The resulting tool enables the creation of high-quality datasets that support data-driven stability studies in modern power systems with high IBR penetration.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.06369v2</guid></item><item><title>[cs updates on arXiv.org] Cognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents</title><link>https://arxiv.org/abs/2512.06716</link><description>arXiv:2512.06716v2 Announce Type: replace 
Abstract: Autonomous Large Language Model (LLM) agents exhibit significant vulnerability to Indirect Prompt Injection (IPI) attacks. These attacks hijack agent behavior by polluting external information sources, exploiting fundamental trade-offs between security and functionality in existing defense mechanisms. This leads to malicious and unauthorized tool invocations, diverting agents from their original objectives. The success of complex IPIs reveals a deeper systemic fragility: while current defenses demonstrate some effectiveness, most defense architectures are inherently fragmented. Consequently, they fail to provide full integrity assurance across the entire task execution pipeline, forcing unacceptable multi-dimensional compromises among security, functionality, and efficiency. Our method is predicated on a core insight: no matter how subtle an IPI attack, its pursuit of a malicious objective will ultimately manifest as a detectable deviation in the action trajectory, distinct from the expected legitimate plan. Based on this, we propose the Cognitive Control Architecture (CCA), a holistic framework achieving full-lifecycle cognitive supervision. CCA constructs an efficient, dual-layered defense system through two synergistic pillars: (i) proactive and preemptive control-flow and data-flow integrity enforcement via a pre-generated "Intent Graph"; and (ii) an innovative "Tiered Adjudicator" that, upon deviation detection, initiates deep reasoning based on multi-dimensional scoring, specifically designed to counter complex conditional attacks. Experiments on the AgentDojo benchmark substantiate that CCA not only effectively withstands sophisticated attacks that challenge other advanced defense methods but also achieves uncompromised security with notable efficiency and robustness, thereby reconciling the aforementioned multi-dimensional trade-off.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.06716v2</guid></item><item><title>[cs updates on arXiv.org] Scalable Back-End for an AI-Based Diabetes Prediction Application</title><link>https://arxiv.org/abs/2512.08147</link><description>arXiv:2512.08147v2 Announce Type: replace 
Abstract: The rising global prevalence of diabetes necessitates early detection to prevent severe complications. While AI-powered prediction applications offer a promising solution, they require a responsive and scalable back-end architecture to serve a large user base effectively. This paper details the development and evaluation of a scalable back-end system designed for a mobile diabetes prediction application. The primary objective was to maintain a failure rate below 5% and an average latency of under 1000 ms. The architecture leverages horizontal scaling, database sharding, and asynchronous communication via a message queue. Performance evaluation showed that 83% of the system's features (20 out of 24) met the specified performance targets. Key functionalities such as user profile management, activity tracking, and read-intensive prediction operations successfully achieved the desired performance. The system demonstrated the ability to handle up to 10,000 concurrent users without issues, validating its scalability. The implementation of asynchronous communication using RabbitMQ proved crucial in minimizing the error rate for computationally intensive prediction requests, ensuring system reliability by queuing requests and preventing data loss under heavy load.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.08147v2</guid></item><item><title>[cs updates on arXiv.org] LUMOS: Large User MOdels for User Behavior Prediction</title><link>https://arxiv.org/abs/2512.08957</link><description>arXiv:2512.08957v2 Announce Type: replace 
Abstract: User behavior prediction at scale remains a critical challenge for online B2C platforms. Traditional approaches rely heavily on task-specific models and domain-specific feature engineering. This is time-consuming, computationally expensive, and requires domain expertise and therefore, not scalable. We present LUMOS (Large User MOdel Series), a transformer-based architecture that eliminates task-specific models and manual feature engineering by learning multiple tasks jointly using only raw user activity data. LUMOS introduces a novel cross-attention mechanism that conditions predictions on future known events (e.g., holidays, sales, etc.), enabling the model to predict complex behavior patterns like "how will upcoming holidays affect user engagement?" The architecture also employs multi-modal tokenization, combining user activities, event context, and static user demographic attributes into rich representations processed through specialized embedding pathways.
  Through extensive experiments on a production dataset spanning 1.7 trillion user activity tokens from 250 million users, we demonstrate that LUMOS achieves superior performance compared to traditional task-specific models. Across 5 tasks with established baselines, we achieve an average improvement of 0.025 in ROC-AUC for binary classification tasks and 4.6\% reduction in MAPE for regression tasks. Online A/B testing validates these improvements translate to measurable business impact with a 3.15\% increase in Daily Active Users.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.08957v2</guid></item><item><title>[cs updates on arXiv.org] Hierarchy-Aware Multimodal Unlearning for Medical AI</title><link>https://arxiv.org/abs/2512.09867</link><description>arXiv:2512.09867v3 Announce Type: replace 
Abstract: Pretrained Multimodal Large Language Models (MLLMs) are increasingly used in sensitive domains such as medical AI, where privacy regulations like HIPAA and GDPR require specific removal of individuals' or institutions' data. This motivates machine unlearning, which aims to remove the influence of target data from a trained model. However, existing unlearning benchmarks fail to reflect the hierarchical and multimodal structure of real-world medical data, limiting their ability to properly evaluate unlearning in practice. Therefore, we introduce MedForget, a hierarchy-aware multimodal unlearning benchmark that models hospital data as a nested structure, enabling fine-grained evaluation of multimodal unlearning across retain and forget splits. Experiments with current unlearning methods show that existing approaches struggle to achieve effective hierarchy-aware forgetting without degrading downstream medical utility. To address this limitation, we propose Cross-modal Hierarchy-Informed Projection for unlearning (CHIP), a training-free, hierarchy-aware multimodal unlearning method that deletes information by selectively removing target-specific weight subspaces while preserving sibling-shared information. Experiments show that CHIP achieves the highest forget-retain performance gap across all hierarchy levels while maintaining competitive downstream utility compared to existing methods. Overall, MedForget provides a practical, HIPAA-aligned benchmark for evaluating structured multimodal unlearning for medical data, and CHIP offers an effective and general solution for hierarchy-aware forgetting that balances deletion with utility.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.09867v3</guid></item><item><title>[cs updates on arXiv.org] Exploring LLMs for Scientific Information Extraction Using The SciEx Framework</title><link>https://arxiv.org/abs/2512.10004</link><description>arXiv:2512.10004v2 Announce Type: replace 
Abstract: Large language models (LLMs) are increasingly touted as powerful tools for automating scientific information extraction. However, existing methods and tools often struggle with the realities of scientific literature: long-context documents, multi-modal content, and reconciling varied and inconsistent fine-grained information across multiple publications into standardized formats. These challenges are further compounded when the desired data schema or extraction ontology changes rapidly, making it difficult to re-architect or fine-tune existing systems. We present SciEx, a modular and composable framework that decouples key components including PDF parsing, multi-modal retrieval, extraction, and aggregation. This design streamlines on-demand data extraction while enabling extensibility and flexible integration of new models, prompting strategies, and reasoning mechanisms. We evaluate SciEx on datasets spanning three scientific topics for its ability to extract fine-grained information accurately and consistently. Our findings provide practical insights into both the strengths and limitations of current LLM-based pipelines.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.10004v2</guid></item><item><title>[cs updates on arXiv.org] CLASH: Collaborative Large-Small Hierarchical Framework for Continuous Vision-and-Language Navigation</title><link>https://arxiv.org/abs/2512.10360</link><description>arXiv:2512.10360v2 Announce Type: replace 
Abstract: Vision-and-Language Navigation (VLN) requires robots to follow natural language instructions and navigate complex environments without prior maps. While recent vision-language large models demonstrate strong reasoning abilities, they often underperform task-specific panoramic small models in VLN tasks. To address this, we propose CLASH (Collaborative Large-Small Hierarchy), a VLN-CE framework that integrates a reactive small-model planner (RSMP) with a reflective large-model reasoner (RLMR). RSMP adopts a causal-learning-based dual-branch architecture to enhance generalization, while RLMR leverages panoramic visual prompting with chain-of-thought reasoning to support interpretable spatial understanding and navigation. We further introduce an uncertainty-aware collaboration mechanism (UCM) that adaptively fuses decisions from both models. For obstacle avoidance, in simulation, we replace the rule-based controller with a fully learnable point-goal policy, and in real-world deployment, we design a LiDAR-based clustering module for generating navigable waypoints and pair it with an online SLAM-based local controller. CLASH achieves state-of-the-art (SoTA) results (ranking 1-st) on the VLN-CE leaderboard, significantly improving SR and SPL on the test-unseen set over the previous SoTA methods. Real-world experiments demonstrate CLASH's strong robustness, validating its effectiveness in both simulation and deployment scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.10360v2</guid></item><item><title>[cs updates on arXiv.org] UACER: An Uncertainty-Adaptive Critic Ensemble Framework for Robust Adversarial Reinforcement Learning</title><link>https://arxiv.org/abs/2512.10492</link><description>arXiv:2512.10492v2 Announce Type: replace 
Abstract: Robust adversarial reinforcement learning has emerged as an effective paradigm for training agents to handle uncertain disturbance in real environments, with critical applications in sequential decision-making domains such as autonomous driving and robotic control. Within this paradigm, agent training is typically formulated as a zero-sum Markov game between a protagonist and an adversary to enhance policy robustness. However, the trainable nature of the adversary inevitably induces non-stationarity in the learning dynamics, leading to exacerbated training instability and convergence difficulties, particularly in high-dimensional complex environments. In this paper, we propose a novel approach, Uncertainty-Adaptive Critic Ensemble for robust adversarial Reinforcement learning (UACER), which consists of two components: 1) Diversified critic ensemble: A diverse set of K critic networks is employed in parallel to stabilize Q-value estimation in robust adversarial reinforcement learning, reducing variance and enhancing robustness compared to conventional single-critic designs. 2) Time-varying Decay Uncertainty (TDU) mechanism: Moving beyond simple linear combinations, we propose a variance-derived Q-value aggregation strategy that explicitly incorporates epistemic uncertainty to adaptively regulate the exploration-exploitation trade-off while stabilizing the training process. Comprehensive experiments across several challenging MuJoCo control problems validate the superior effectiveness of UACER, outperforming state-of-the-art methods in terms of overall performance, stability, and efficiency.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.10492v2</guid></item><item><title>[cs updates on arXiv.org] OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis</title><link>https://arxiv.org/abs/2512.10940</link><description>arXiv:2512.10940v2 Announce Type: replace 
Abstract: Prior approaches injecting camera control into diffusion models have focused on specific subsets of 4D consistency tasks: novel view synthesis, text-to-video with camera control, image-to-video, amongst others. Therefore, these fragmented approaches are trained on disjoint slices of available 3D/4D data. We introduce OmniView, a unified framework that generalizes across a wide range of 4D consistency tasks. Our method separately represents space, time, and view conditions, enabling flexible combinations of these inputs. For example, OmniView can synthesize novel views from static, dynamic, and multiview inputs, extrapolate trajectories forward and backward in time, and create videos from text or image prompts with full camera control. OmniView is competitive with task-specific models across diverse benchmarks and metrics, improving image quality scores among camera-conditioned diffusion models by up to 33\% in multiview NVS LLFF dataset, 60\% in dynamic NVS Neural 3D Video benchmark, 20\% in static camera control on RE-10K, and reducing camera trajectory errors by 4x in text-conditioned video generation. With strong generalizability in one model, OmniView demonstrates the feasibility of a generalist 4D video model. Project page is available at https://snap-research.github.io/OmniView/</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.10940v2</guid></item><item><title>[cs updates on arXiv.org] Pace: Physics-Aware Attentive Temporal Convolutional Network for Battery Health Estimation</title><link>https://arxiv.org/abs/2512.11332</link><description>arXiv:2512.11332v3 Announce Type: replace 
Abstract: Batteries are critical components in modern energy systems such as electric vehicles and power grid energy storage. Effective battery health management is essential for battery system safety, cost-efficiency, and sustainability. In this paper, we propose Pace, a physics-aware attentive temporal convolutional network for battery health estimation. Pace integrates raw sensor measurements with battery physics features derived from the equivalent circuit model. We develop three battery-specific modules, including dilated temporal blocks for efficient temporal encoding, chunked attention blocks for context modeling, and a dual-head output block for fusing short- and long-term battery degradation patterns. Together, the modules enable Pace to predict battery health accurately and efficiently in various battery usage conditions. In a large public dataset, Pace performs much better than existing models, achieving an average performance improvement of 6.5 and 2.0x compared to two best-performing baseline models. We further demonstrate its practical viability with a real-time edge deployment on a Raspberry Pi. These results establish Pace as a practical and high-performance solution for battery health analytics.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.11332v3</guid></item><item><title>[cs updates on arXiv.org] Adaptive Multimodal Person Recognition: A Robust Framework for Handling Missing Modalities</title><link>https://arxiv.org/abs/2512.14961</link><description>arXiv:2512.14961v2 Announce Type: replace 
Abstract: Person identification systems often rely on audio, visual, or behavioral cues, but real-world conditions frequently result in missing or degraded modalities. To address this challenge, we propose a multimodal person identification framework that utilizes gesture as a situational enhancer to supplement traditional modalities like voice and face. Our model employs a unified hybrid fusion strategy, integrating both feature-level and score-level information to maximize representational richness and decision accuracy. Specifically, it leverages multi-task learning to process modalities independently, followed by cross-attention and gated fusion mechanisms. Finally, a confidence-weighted strategy dynamically adapts to missing data, ensuring that our single classification head achieves optimal performance even in unimodal and bimodal scenarios. We evaluate our method on CANDOR, a newly introduced interview-based multimodal dataset, which we benchmark in this work for the first time. Our results demonstrate that the proposed trimodal system achieves 99.51% Top-1 accuracy on person identification tasks. In addition, we evaluate our model on the VoxCeleb1 dataset as a benchmark and reach 99.92% accuracy in bimodal mode, outperforming conventional approaches. Moreover, we show that our system maintains high accuracy even when one or two modalities are unavailable, making it a robust solution for real-world person recognition applications. The code and data for this work are publicly available.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.14961v2</guid></item><item><title>[cs updates on arXiv.org] Insecure Ingredients? Exploring Dependency Update Patterns of Bundled JavaScript Packages on the Web</title><link>https://arxiv.org/abs/2512.15447</link><description>arXiv:2512.15447v2 Announce Type: replace 
Abstract: Reusable software components, typically distributed as packages, are a central paradigm of modern software development. The JavaScript ecosystem serves as a prime example, offering millions of packages with their use being promoted as idiomatic. However, download statistics on npm raise security concerns as they indicate a high popularity of vulnerable package versions while their real prevalence on production websites remains unknown. Package version detection mechanisms fill this gap by extracting utilized packages and versions from observed artifacts on the web. Prior research focuses on mechanisms for either hand-selected popular packages in bundles or for single-file resources utilizing the global namespace. This does not allow for a thorough analysis of modern web applications' dependency update behavior at scale. In this work, we improve upon this by presenting Aletheia, a package-agnostic method which dissects JavaScript bundles to identify package versions through algorithms originating from the field of plagiarism detection. We show that this method clearly outperforms the existing approaches in practical settings. Furthermore, we crawl the Tranco top 100,000 domains to reveal that 5% - 20% of domains update their dependencies within 16 weeks. Surprisingly, from a longitudinal perspective, bundled packages are updated significantly faster than their CDN-included counterparts, with consequently up to 10 times fewer known vulnerable package versions included. Still, we observe indicators that few widespread vendors seem to be a major driving force behind timely updates, implying that quantitative measures are not painting a complete picture.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.15447v2</guid></item><item><title>[cs updates on arXiv.org] Leveraging Peer, Self, and Teacher Assessments for Generative AI-Enhanced Feedback</title><link>https://arxiv.org/abs/2512.18306</link><description>arXiv:2512.18306v2 Announce Type: replace 
Abstract: Providing timely and meaningful feedback remains a persistent challenge in higher education, especially in large courses where teachers must balance formative depth with scalability. Recent advances in Generative Artificial Intelligence (GenAI) offer new opportunities to support feedback processes while maintaining human oversight. This paper presents an study conducted within the AICoFe (AI-based Collaborative Feedback) system, which integrates teacher, peer, and self-assessments of engineering students' oral presentations. Using a validated rubric, 46 evaluation sets were analyzed to examine agreement, correlation, and bias across evaluators. The analyses revealed consistent overall alignment among sources but also systematic variations in scoring behavior, reflecting distinct evaluative perspectives. These findings informed the proposal of an enhanced GenAI model within AICoFe system, designed to integrate human assessments through weighted input aggregation, bias detection, and context-aware feedback generation. The study contributes empirical evidence and design principles for developing GenAI-based feedback systems that combine data-based efficiency with pedagogical validity and transparency.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.18306v2</guid></item><item><title>[cs updates on arXiv.org] The Prism Hypothesis: Harmonizing Semantic and Pixel Representations via Unified Autoencoding</title><link>https://arxiv.org/abs/2512.19693</link><description>arXiv:2512.19693v2 Announce Type: replace 
Abstract: Deep representations across modalities are inherently intertwined. In this paper, we systematically analyze the spectral characteristics of various semantic and pixel encoders. Interestingly, our study uncovers a highly inspiring and rarely explored correspondence between an encoder's feature spectrum and its functional role: semantic encoders primarily capture low-frequency components that encode abstract meaning, whereas pixel encoders additionally retain high-frequency information that conveys fine-grained detail. This heuristic finding offers a unifying perspective that ties encoder behavior to its underlying spectral structure. We define it as the Prism Hypothesis, where each data modality can be viewed as a projection of the natural world onto a shared feature spectrum, just like the prism. Building on this insight, we propose Unified Autoencoding (UAE), a model that harmonizes semantic structure and pixel details via an innovative frequency-band modulator, enabling their seamless coexistence. Extensive experiments on ImageNet and MS-COCO benchmarks validate that our UAE effectively unifies semantic abstraction and pixel-level fidelity into a single latent space with state-of-the-art performance.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.19693v2</guid></item><item><title>[cs updates on arXiv.org] RIS-Empowered OTFS Modulation With Faster-than-Nyquist Signaling in High-Mobility Wireless Communications</title><link>https://arxiv.org/abs/2512.20332</link><description>arXiv:2512.20332v2 Announce Type: replace 
Abstract: High-mobility wireless communication systems suffer from severe Doppler spread and multi-path delay, which degrade the reliability and spectral efficiency of conventional modulation schemes. Orthogonal time frequency space (OTFS) modulation offers strong robustness in such environments by representing symbols in the delay-Doppler (DD) domain, while faster-than-Nyquist (FTN) signaling can further enhance spectral efficiency through intentional symbol packing. Meanwhile, reconfigurable intelligent surfaces (RIS) provide a promising means to improve link quality via passive beamforming. Motivated by these advantages, we propose a novel RIS-empowered OTFS modulation with FTN signaling (RIS-OTFS-FTN) scheme. First, we establish a unified DD-domain input-output relationship that jointly accounts for RIS passive beamforming, FTN-induced inter-symbol interference, and DD-domain channel characteristics. Based on this model, we provide comprehensive analytical performance for the frame error rate, spectral efficiency, and peak-to-average power ratio (PAPR), etc. Furthermore, a practical RIS phase adjustment strategy with quantized phase selection is designed to maximize the effective channel gain. Extensive Monte Carlo simulations under a standardized extended vehicular A (EVA) channel model validate the theoretical results and provide key insights into the trade-offs among spectral efficiency, PAPR, input back-off (IBO), and error performance, with some interesting insights.The proposed RIS-OTFS-FTN scheme demonstrates notable performance gains in both reliability and spectral efficiency, offering a viable solution for future high-mobility and spectrum-constrained wireless systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.20332v2</guid></item><item><title>[cs updates on arXiv.org] Shape of Thought: When Distribution Matters More than Correctness in Reasoning Tasks</title><link>https://arxiv.org/abs/2512.22255</link><description>arXiv:2512.22255v2 Announce Type: replace 
Abstract: We present the surprising finding that a language model's reasoning capabilities can be improved by training on synthetic datasets of chain-of-thought (CoT) traces from more capable models, even when all of those traces lead to an incorrect final answer. Our experiments show this approach can yield better performance on reasoning tasks than training on human-annotated datasets. We hypothesize that two key factors explain this phenomenon: first, the distribution of synthetic data is inherently closer to the language model's own distribution, making it more amenable to learning. Second, these `incorrect' traces are often only partially flawed and contain valid reasoning steps from which the model can learn. To further test the first hypothesis, we use a language model to paraphrase human-annotated traces -- shifting their distribution closer to the model's own distribution -- and show that this improves performance. For the second hypothesis, we introduce increasingly flawed CoT traces and study to what extent models are tolerant to these flaws. We demonstrate our findings across various reasoning domains like math, algorithmic reasoning and code generation using MATH, GSM8K, Countdown and MBPP datasets on various language models ranging from 1.5B to 9B across Qwen, Llama, and Gemma models. Our study shows that curating datasets that are closer to the model's distribution is a critical aspect to consider. We also show that a correct final answer is not always a reliable indicator of a faithful reasoning process.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.22255v2</guid></item><item><title>[cs updates on arXiv.org] VL-LN Bench: Towards Long-horizon Goal-oriented Navigation with Active Dialogs</title><link>https://arxiv.org/abs/2512.22342</link><description>arXiv:2512.22342v4 Announce Type: replace 
Abstract: In most existing embodied navigation tasks, instructions are well-defined and unambiguous, such as instruction following and object searching. Under this idealized setting, agents are required solely to produce effective navigation outputs conditioned on vision and language inputs. However, real-world navigation instructions are often vague and ambiguous, requiring the agent to resolve uncertainty and infer user intent through active dialog. To address this gap, we propose Interactive Instance Goal Navigation (IIGN), a task that requires agents not only to generate navigation actions but also to produce language outputs via active dialog, thereby aligning more closely with practical settings. IIGN extends Instance Goal Navigation (IGN) by allowing agents to freely consult an oracle in natural language while navigating. Building on this task, we present the Vision Language-Language Navigation (VL-LN) benchmark, which provides a large-scale, automatically generated dataset and a comprehensive evaluation protocol for training and assessing dialog-enabled navigation models. VL-LN comprises over 41k long-horizon dialog-augmented trajectories for training and an automatic evaluation protocol with an oracle capable of responding to agent queries. Using this benchmark, we train a navigation model equipped with dialog capabilities and show that it achieves significant improvements over the baselines. Extensive experiments and analyses further demonstrate the effectiveness and reliability of VL-LN for advancing research on dialog-enabled embodied navigation. Code and dataset: https://0309hws.github.io/VL-LN.github.io/</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.22342v4</guid></item><item><title>[cs updates on arXiv.org] Theoretical Foundations of Scaling Law in Familial Models</title><link>https://arxiv.org/abs/2512.23407</link><description>arXiv:2512.23407v2 Announce Type: replace 
Abstract: Neural scaling laws have become foundational for optimizing large language model (LLM) training, yet they typically assume a single dense model output. This limitation effectively overlooks "Familial models, a transformative paradigm essential for realizing ubiquitous intelligence across heterogeneous device-edge-cloud hierarchies. Transcending static architectures, familial models integrate early exits with relay-style inference to spawn G deployable sub-models from a single shared backbone. In this work, we theoretically and empirically extend the scaling law to capture this "one-run, many-models" paradigm by introducing Granularity (G) as a fundamental scaling variable alongside model size (N) and training tokens (D). To rigorously quantify this relationship, we propose a unified functional form L(N, D, G) and parameterize it using large-scale empirical runs. Specifically, we employ a rigorous IsoFLOP experimental design to strictly isolate architectural impact from computational scale. Across fixed budgets, we systematically sweep model sizes (N) and granularities (G) while dynamically adjusting tokens (D). This approach effectively decouples the marginal cost of granularity from the benefits of scale, ensuring high-fidelity parameterization of our unified scaling law. Our results reveal that the granularity penalty follows a multiplicative power law with an extremely small exponent. Theoretically, this bridges fixed-compute training with dynamic architectures. Practically, it validates the "train once, deploy many" paradigm, demonstrating that deployment flexibility is achievable without compromising the compute-optimality of dense baselines.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.23407v2</guid></item><item><title>[cs updates on arXiv.org] Pretraining Frame Preservation in Autoregressive Video Memory Compression</title><link>https://arxiv.org/abs/2512.23851</link><description>arXiv:2512.23851v3 Announce Type: replace 
Abstract: We present PFP, a neural network structure to compress long videos into short contexts, with an explicit pretraining objective to preserve the high-frequency details of single frames at arbitrary temporal positions. The baseline model can compress a 20-second video into a context at about 5k length, where random frames can be retrieved with perceptually preserved appearances. Such pretrained models can be directly fine-tuned as memory encoders for autoregressive video models, enabling long history memory with low context cost and relatively low fidelity loss. We evaluate the framework with ablative settings and discuss the trade-offs of possible neural architecture designs.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.23851v3</guid></item><item><title>[cs updates on arXiv.org] The Role of Mixed-Language Documents for Multilingual Large Language Model Pretraining</title><link>https://arxiv.org/abs/2601.00364</link><description>arXiv:2601.00364v2 Announce Type: replace 
Abstract: Multilingual large language models achieve impressive cross-lingual performance despite largely monolingual pretraining. While bilingual data in pretraining corpora is widely believed to enable these abilities, details of its contributions remain unclear. We investigate this question by pretraining models from scratch under controlled conditions, comparing the standard web corpus with a monolingual-only version that removes all multilingual documents. Despite constituting only 2% of the corpus, removing bilingual data causes translation performance to drop 56% in BLEU, while behaviour on cross-lingual QA and general reasoning tasks remains stable, with training curves largely overlapping the baseline. To understand this asymmetry, we categorize bilingual data into parallel (14%), code-switching (72%), and miscellaneous documents (14%) based on the semantic relevance of content in different languages. We then conduct granular ablations by reintroducing parallel or code-switching data into the monolingual-only corpus. Our experiments reveal that parallel data almost fully restores translation performance (91% of the unfiltered baseline), whereas code-switching contributes minimally. Other cross-lingual tasks remain largely unaffected by either type. These findings reveal that translation critically depends on systematic token-level alignments from parallel data, whereas cross-lingual understanding and reasoning appear to be achievable even without bilingual data.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.00364v2</guid></item><item><title>[cs updates on arXiv.org] Intention Collapse: Intention-Level Metrics for Reasoning in Language Models</title><link>https://arxiv.org/abs/2601.01011</link><description>arXiv:2601.01011v2 Announce Type: replace 
Abstract: Language generation maps a rich, high-dimensional internal state to a single token sequence. We study this many-to-one mapping through the lens of intention collapse: the projection from an internal intention space I to an external language space L. We introduce three cheap, model-agnostic metrics computed on a pre-collapse state I: (i) intention entropy Hint(I), (ii) effective dimensionality deff(I), and (iii) recoverability Recov(I), operationalized as probe AUROC for predicting eventual success. We evaluate these metrics in a 3x3 study across models (Mistral-7B, LLaMA-3.1-8B, Qwen-2.5-7B) and benchmarks (GSM8K, ARC-Challenge, AQUA-RAT), comparing baseline, chain-of-thought (CoT), and a babble control (n=200 items per cell). CoT increases average accuracy from 34.2% to 47.3% (+13.1 pp), driven by large gains on GSM8K but consistent degradations on ARC-Challenge. Across models, CoT induces distinct entropy regimes relative to baseline, dH = Hint(CoT) - Hint(Base): Mistral shows dH &lt; 0 (lower-entropy CoT), whereas LLaMA shows dH &gt; 0 (higher-entropy CoT), highlighting heterogeneity in CoT-induced internal uncertainty. Finally, probe AUROC is significantly above chance in a subset of settings and can dissociate from behavioral accuracy (e.g., high AUROC alongside lower CoT accuracy on ARC-Challenge for Qwen), suggesting that informative internal signal is not always reliably converted into a final discrete decision under constrained response formats.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.01011v2</guid></item><item><title>[cs updates on arXiv.org] CardioMOD-Net: A Modal Decomposition-Neural Network Framework for Diagnosis and Prognosis of HFpEF from Echocardiography Cine Loops</title><link>https://arxiv.org/abs/2601.01176</link><description>arXiv:2601.01176v2 Announce Type: replace 
Abstract: Introduction: Heart failure with preserved ejection fraction (HFpEF) arises from diverse comorbidities and progresses through prolonged subclinical stages, making early diagnosis and prognosis difficult. Current echocardiography-based Artificial Intelligence (AI) models focus primarily on binary HFpEF detection in humans and do not provide comorbidity-specific phenotyping or temporal estimates of disease progression towards decompensation. We aimed to develop a unified AI framework, CardioMOD-Net, to perform multiclass diagnosis and continuous prediction of HFpEF onset directly from standard echocardiography cine loops in preclinical models.
  Methods: Mouse echocardiography videos from four groups were used: control (CTL), hyperglycaemic (HG), obesity (OB), and systemic arterial hypertension (SAH). Two-dimensional parasternal long-axis cine loops were decomposed using Higher Order Dynamic Mode Decomposition (HODMD) to extract temporal features for downstream analysis. A shared latent representation supported Vision Transformers, one for a classifier for diagnosis and another for a regression module for predicting the age at HFpEF onset.
  Results: Overall diagnostic accuracy across the four groups was 65%, with all classes exceeding 50% accuracy. Misclassifications primarily reflected early-stage overlap between OB or SAH and CTL. The prognostic module achieved a root-mean-square error of 21.72 weeks for time-to-HFpEF prediction, with OB and SAH showing the most accurate estimates. Predicted HFpEF onset closely matched true distributions in all groups.
  Discussion: This unified framework demonstrates that multiclass phenotyping and continuous HFpEF onset prediction can be obtained from a single cine loop, even under small-data conditions. The approach offers a foundation for integrating diagnostic and prognostic modelling in preclinical HFpEF research.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.01176v2</guid></item><item><title>[cs updates on arXiv.org] Physics-Constrained Learning of Energy-Preserving Stencils for Maxwell's Equations</title><link>https://arxiv.org/abs/2601.01902</link><description>arXiv:2601.01902v4 Announce Type: replace 
Abstract: We study data-driven construction of spatial discretizations for the one-dimensional Maxwell system. Using high-fidelity training data from a spectral discretization, we learn a \emph{linear convolution stencil} that approximates the spatial derivative operator in Maxwell's equations. We formulate a convex quadratic program for the stencil coefficients with linear constraints that enforce skew-adjointness of the discrete derivative; these constraints guarantee a semi-discrete electromagnetic energy identity and yield a CFL condition expressed directly in terms of the stencil's Fourier symbol. We compare several convex solvers for the resulting quadratic program -- projected gradient, Nesterov-accelerated gradient, ADMM, and an interior-point reference implemented in CVXPY -- and evaluate the learned operators in time-dependent Maxwell simulations using a Crank--Nicolson (CN) discretization. Numerical experiments, including cases with nonstandard target operators and noisy training data, show that (i) energy-constrained learned stencils achieve accuracy comparable to standard central differences while exactly preserving the discrete electromagnetic energy under CN time-stepping, and (ii) ADMM and interior-point solvers produce nearly identical operators, with ADMM offering a favorable tradeoff between accuracy, constraint satisfaction, and runtime.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.01902v4</guid></item><item><title>[cs updates on arXiv.org] Multi-scale Graph Autoregressive Modeling: Molecular Property Prediction via Next Token Prediction</title><link>https://arxiv.org/abs/2601.02530</link><description>arXiv:2601.02530v3 Announce Type: replace 
Abstract: We present Connection-Aware Motif Sequencing (CamS), a graph-to-sequence representation that enables decoder-only Transformers to learn molecular graphs via standard next-token prediction (NTP). For molecular property prediction, SMILES-based NTP scales well but lacks explicit topology, whereas graph-native masked modeling captures connectivity but risks disrupting the pivotal chemical details (e.g., activity cliffs). CamS bridges this gap by serializing molecular graphs into structure-rich causal sequences. CamS first mines data-driven connection-aware motifs. It then serializes motifs via scaffold-rooted breadth-first search (BFS) to establish a stable core-to-periphery order. Crucially, CamS enables hierarchical modeling by concatenating sequences from fine to coarse motif scales, allowing the model to condition global scaffolds on dense, uncorrupted local structural evidence. We instantiate CamS-LLaMA by pre-training a vanilla LLaMA backbone on CamS sequences. It achieves state-of-the-art performance on MoleculeNet and the activity-cliff benchmark MoleculeACE, outperforming both SMILES-based language models and strong graph baselines. Interpretability analysis confirms that our multi-scale causal serialization effectively drives attention toward cliff-determining differences.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.02530v3</guid></item><item><title>[cs updates on arXiv.org] Optimal Oblivious Load-Balancing for Sparse Traffic in Large-Scale Satellite Networks</title><link>https://arxiv.org/abs/2601.02537</link><description>arXiv:2601.02537v2 Announce Type: replace 
Abstract: Oblivious load-balancing in networks involves routing traffic from sources to destinations using predetermined routes independent of the traffic, so that the maximum load on any link in the network is minimized. We investigate oblivious load-balancing schemes for a $N\times N$ torus network under sparse traffic where there are at most $k$ active source-destination pairs. We are motivated by the problem of load-balancing in large-scale LEO satellite networks, which can be modelled as a torus, where the traffic is known to be sparse and localized to certain hotspot areas. We formulate the problem as a linear program and show that no oblivious routing scheme can achieve a worst-case load lower than approximately $\frac{\sqrt{2k}}{4}$ when $1&lt;k \leq N^2/2$ and $\frac{N}{4}$ when $N^2/2\leq k\leq N^2$. Moreover, we demonstrate that the celebrated Valiant Load Balancing scheme is suboptimal under sparse traffic and construct an optimal oblivious load-balancing scheme that achieves the lower bound. Further, we discover a $\sqrt{2}$ multiplicative gap between the worst-case load of a non-oblivious routing and the worst-case load of any oblivious routing. The results can also be extended to general $N\times M$ tori with unequal link capacities along the vertical and horizontal directions.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.02537v2</guid></item><item><title>[cs updates on arXiv.org] IBISAgent: Reinforcing Pixel-Level Visual Reasoning in MLLMs for Universal Biomedical Object Referring and Segmentation</title><link>https://arxiv.org/abs/2601.03054</link><description>arXiv:2601.03054v2 Announce Type: replace 
Abstract: Recent research on medical MLLMs has gradually shifted its focus from image-level understanding to fine-grained, pixel-level comprehension. Although segmentation serves as the foundation for pixel-level understanding, existing approaches face two major challenges. First, they introduce implicit segmentation tokens and require simultaneous fine-tuning of both the MLLM and external pixel decoders, which increases the risk of catastrophic forgetting and limits generalization to out-of-domain scenarios. Second, most methods rely on single-pass reasoning and lack the capability to iteratively refine segmentation results, leading to suboptimal performance. To overcome these limitations, we propose a novel agentic MLLM, named IBISAgent, that reformulates segmentation as a vision-centric, multi-step decision-making process. IBISAgent enables MLLMs to generate interleaved reasoning and text-based click actions, invoke segmentation tools, and produce high-quality masks without architectural modifications. By iteratively performing multi-step visual reasoning on masked image features, IBISAgent naturally supports mask refinement and promotes the development of pixel-level visual reasoning capabilities. We further design a two-stage training framework consisting of cold-start supervised fine-tuning and agentic reinforcement learning with tailored, fine-grained rewards, enhancing the model's robustness in complex medical referring and reasoning segmentation tasks. Extensive experiments demonstrate that IBISAgent consistently outperforms both closed-source and open-source SOTA methods. All datasets, code, and trained models will be released publicly.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.03054v2</guid></item><item><title>[cs updates on arXiv.org] StealthGraph: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided Harmful Prompt Generation</title><link>https://arxiv.org/abs/2601.04740</link><description>arXiv:2601.04740v2 Announce Type: replace 
Abstract: Large language models (LLMs) are increasingly applied in specialized domains such as finance and healthcare, where they introduce unique safety risks. Domain-specific datasets of harmful prompts remain scarce and still largely rely on manual construction; public datasets mainly focus on explicit harmful prompts, which modern LLM defenses can often detect and refuse. In contrast, implicit harmful prompts-expressed through indirect domain knowledge-are harder to detect and better reflect real-world threats. We identify two challenges: transforming domain knowledge into actionable constraints and increasing the implicitness of generated harmful prompts. To address them, we propose an end-to-end framework that first performs knowledge-graph-guided harmful prompt generation to systematically produce domain-relevant prompts, and then applies dual-path obfuscation rewriting to convert explicit harmful prompts into implicit variants via direct and context-enhanced rewriting. This framework yields high-quality datasets combining strong domain relevance with implicitness, enabling more realistic red-teaming and advancing LLM safety research. We release our code and datasets at GitHub.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.04740v2</guid></item><item><title>[cs updates on arXiv.org] DAVOS: An Autonomous Vehicle Operating System in the Vehicle Computing Era</title><link>https://arxiv.org/abs/2601.05072</link><description>arXiv:2601.05072v3 Announce Type: replace 
Abstract: Vehicle computing represents a fundamental shift in how autonomous vehicles are designed and deployed, transforming them from isolated transportation systems into mobile computing platforms that support both safety-critical, real-time driving and data-centric services. In this setting, vehicles simultaneously support real-time driving pipelines and a growing set of data-driven applications, placing increased responsibility on the vehicle operating system to coordinate computation, data movement, storage, and access. These demands highlight recurring system considerations related to predictable execution, data and execution protection, efficient handling of high-rate sensor data, and long-term system evolvability, commonly summarized as Safety, Security, Efficiency, and Extensibility (SSEE). Existing vehicle operating systems and runtimes address these concerns in isolation, resulting in fragmented software stacks that limit coordination between autonomy workloads and vehicle data services. This paper presents DAVOS, the Dependable Autonomous Vehicle Operating System, a unified vehicle operating system architecture designed for the vehicle computing context. DAVOS provides a cohesive operating system foundation that supports both real-time autonomy and extensible vehicle computing within a single system framework.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.05072v3</guid></item><item><title>[cs updates on arXiv.org] GlueNN: gluing patchwise analytic solutions with neural networks</title><link>https://arxiv.org/abs/2601.05889</link><description>arXiv:2601.05889v2 Announce Type: replace 
Abstract: In the analysis of complex physical systems, the objective often extends beyond merely computing a numerical solution to capturing the precise crossover between different regimes and extracting parameters containing meaningful information. However, standard numerical solvers and conventional deep learning approaches, such as Physics-Informed Neural Networks (PINNs), typically operate as black boxes that output solution fields without disentangling the solution into its interpretable constituent parts. In this work, we propose GlueNN, a physics-informed learning framework that decomposes the global solution into interpretable, patchwise analytic components. Rather than approximating the solution directly, GlueNN promotes the integration constants of local asymptotic expansions to learnable, scale-dependent coefficient functions. By constraining these coefficients with the differential equation, the network effectively performs regime transition, smoothly interpolating between asymptotic limits without requiring ad hoc boundary matching. We demonstrate that this coefficient-centric approach reproduces accurate global solutions in various examples and thus directly extracts physical information that is not explicitly available through standard numerical integration.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.05889v2</guid></item><item><title>[cs updates on arXiv.org] Revisiting the Ordering of Channel and Spatial Attention: A Comprehensive Study on Sequential and Parallel Designs</title><link>https://arxiv.org/abs/2601.07310</link><description>arXiv:2601.07310v2 Announce Type: replace 
Abstract: Attention mechanisms have become a core component of deep learning models, with Channel Attention and Spatial Attention being the two most representative architectures. Current research on their fusion strategies primarily bifurcates into sequential and parallel paradigms, yet the selection process remains largely empirical, lacking systematic analysis and unified principles. We systematically compare channel-spatial attention combinations under a unified framework, building an evaluation suite of 18 topologies across four classes: sequential, parallel, multi-scale, and residual. Across two vision and nine medical datasets, we uncover a "data scale-method-performance" coupling law: (1) in few-shot tasks, the "Channel-Multi-scale Spatial" cascaded structure achieves optimal performance; (2) in medium-scale tasks, parallel learnable fusion architectures demonstrate superior results; (3) in large-scale tasks, parallel structures with dynamic gating yield the best performance. Additionally, experiments indicate that the "Spatial-Channel" order is more stable and effective for fine-grained classification, while residual connections mitigate vanishing gradient problems across varying data scales. We thus propose scenario-based guidelines for building future attention modules. Code is open-sourced at https://github.com/DWlzm.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.07310v2</guid></item><item><title>[cs updates on arXiv.org] Emergent Coordination in Multi-Agent Systems via Pressure Fields and Temporal Decay</title><link>https://arxiv.org/abs/2601.08129</link><description>arXiv:2601.08129v2 Announce Type: replace 
Abstract: Current multi-agent LLM frameworks rely on explicit orchestration patterns borrowed from human organizational structures: planners delegate to executors, managers coordinate workers, and hierarchical control flow governs agent interactions. These approaches suffer from coordination overhead that scales poorly with agent count and task complexity. We propose a fundamentally different paradigm inspired by natural coordination mechanisms: agents operate locally on a shared artifact, guided only by pressure gradients derived from measurable quality signals, with temporal decay preventing premature convergence. We formalize this as optimization over a pressure landscape and prove convergence guarantees under mild conditions. Empirically, on meeting room scheduling across 1,350 trials, pressure-field coordination outperforms all baselines: 48.5% aggregate solve rate versus 12.6% for conversation-based coordination, 1.5% for hierarchical control, and 0.4% for sequential and random baselines (all pairwise comparisons p &lt; 0.001). Temporal decay is essential: disabling it reduces solve rate by 10 percentage points. On easy problems, pressure-field achieves 86.7% solve rate. The approach maintains consistent performance from 1 to 4 agents. Implicit coordination through shared pressure gradients outperforms explicit hierarchical control, suggesting that constraint-driven emergence offers a simpler and more effective foundation for multi-agent AI.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.08129v2</guid></item><item><title>[cs updates on arXiv.org] Controlled LLM Training on Spectral Sphere</title><link>https://arxiv.org/abs/2601.08393</link><description>arXiv:2601.08393v2 Announce Type: replace 
Abstract: Scaling large models requires optimization strategies that ensure rapid convergence grounded in stability. Maximal Update Parametrization ($\boldsymbol{\mu}$P) provides a theoretical safeguard for width-invariant $\Theta(1)$ activation control, whereas emerging optimizers like Muon are only ``half-aligned'' with these constraints: they control updates but allow weights to drift. To address this limitation, we introduce the \textbf{Spectral Sphere Optimizer (SSO)}, which enforces strict module-wise spectral constraints on both weights and their updates. By deriving the steepest descent direction on the spectral sphere, SSO realizes a fully $\boldsymbol{\mu}$P-aligned optimization process. To enable large-scale training, we implement SSO as an efficient parallel algorithm within Megatron. Through extensive pretraining on diverse architectures, including Dense 1.7B, MoE 8B-A1B, and 200-layer DeepNet models, SSO consistently outperforms AdamW and Muon. Furthermore, we observe significant practical stability benefits, including improved MoE router load balancing, suppressed outliers, and strictly bounded activations.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.08393v2</guid></item><item><title>[cs updates on arXiv.org] Optimising for Energy Efficiency and Performance in Machine Learning</title><link>https://arxiv.org/abs/2601.08991</link><description>arXiv:2601.08991v2 Announce Type: replace 
Abstract: The ubiquity of machine learning (ML) and the demand for ever-larger models bring an increase in energy consumption and environmental impact. However, little is known about the energy scaling laws in ML, and existing research focuses on training cost -- ignoring the larger cost of inference. Furthermore, tools for measuring the energy consumption of ML do not provide actionable feedback.
  To address these gaps, we developed Energy Consumption Optimiser (ECOpt): a hyperparameter tuner that optimises for energy efficiency and model performance. ECOpt quantifies the trade-off between these metrics as an interpretable Pareto frontier. This enables ML practitioners to make informed decisions about energy cost and environmental impact, while maximising the benefit of their models and complying with new regulations.
  Using ECOpt, we show that parameter and floating-point operation counts can be unreliable proxies for energy consumption, and observe that the energy efficiency of Transformer models for text generation is relatively consistent across hardware. These findings motivate measuring and publishing the energy metrics of ML models. We further show that ECOpt can have a net positive environmental impact and use it to uncover seven models for CIFAR-10 that improve upon the state of the art, when considering accuracy and energy efficiency together.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.08991v2</guid></item><item><title>[cs updates on arXiv.org] Programming over Thinking: Efficient and Robust Multi-Constraint Planning</title><link>https://arxiv.org/abs/2601.09097</link><description>arXiv:2601.09097v2 Announce Type: replace 
Abstract: Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, we introduce the Scalable COde Planning Engine (SCOPE), a framework that disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by ~4.67x. Code is available at https://github.com/DerrickGXD/SCOPE.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.09097v2</guid></item><item><title>[cs updates on arXiv.org] Energy-Entropy Regularization: The True Power of Minimal Looped Transformers</title><link>https://arxiv.org/abs/2601.09588</link><description>arXiv:2601.09588v2 Announce Type: replace 
Abstract: Recent research suggests that looped Transformers have superior reasoning capabilities compared to standard deep architectures. Current approaches to training single-head looped architectures on benchmark tasks frequently fail or yield suboptimal performance due to a highly non-convex and irregular loss landscape. In these settings, optimization often stagnates in poor local minima and saddle points of the loss landscape, preventing the model from discovering the global minimum point. The internal mechanisms of these single-head looped transformer models remain poorly understood, and training them from scratch remains a significant challenge. In this paper, we propose a novel training framework that leverages Tsallis entropy and Hamiltonian dynamics to transform the geometry of the loss landscape. By treating the parameter updates as a physical flow, we successfully trained a single-head looped Transformer with model dimension $d = 8$ to solve induction head task with input sequence length of 1000 tokens. This success reveals the internal mechanism behind the superior reasoning capability.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.09588v2</guid></item><item><title>[cs updates on arXiv.org] LLMs Got Rhythm? Hybrid Phonological Filtering for Greek Poetry Rhyme Detection and Generation</title><link>https://arxiv.org/abs/2601.09631</link><description>arXiv:2601.09631v4 Announce Type: replace 
Abstract: Large Language Models (LLMs), despite their remarkable capabilities across NLP tasks, struggle with phonologically-grounded phenomena like rhyme detection and generation. This is even more evident in lower-resource languages such as Modern Greek. In this paper, we present a hybrid system that combines LLMs with deterministic phonological algorithms to achieve accurate rhyme identification/analysis and generation. Our approach implements a comprehensive taxonomy of Greek rhyme types, including Pure, Rich, Imperfect, Mosaic, and Identical Pre-rhyme Vowel (IDV) patterns, and employs an agentic generation pipeline with phonological verification. We evaluate multiple prompting strategies (zero-shot, few-shot, Chain-of-Thought, and RAG-augmented) across several LLMs including Claude 3.7 and 4.5, GPT-4o, Gemini 2.0 and open-weight models like Llama 3.1 8B and 70B and Mistral Large. Results reveal a significant "Reasoning Gap": while native-like models (Claude 3.7) perform intuitively (40\% accuracy in identification), reasoning-heavy models (Claude 4.5) achieve state-of-the-art performance (54\%) only when prompted with Chain-of-Thought. Most critically, pure LLM generation fails catastrophically (under 4\% valid poems), while our hybrid verification loop restores performance to 73.1\%. We release our system and a corpus of 40,000+ rhymes, derived from the Anemoskala and Interwar Poetry corpora, to support future research.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.09631v4</guid></item><item><title>[cs updates on arXiv.org] The Spatial Blindspot of Vision-Language Models</title><link>https://arxiv.org/abs/2601.09954</link><description>arXiv:2601.09954v2 Announce Type: replace 
Abstract: Vision-language models (VLMs) have advanced rapidly, but their ability to capture spatial relationships remains a blindspot. Current VLMs are typically built with contrastive language-image pretraining (CLIP) style image encoders. The training recipe often flattens images into 1D patch sequences, discarding the 2D structure necessary for spatial reasoning. We argue that this lack of spatial awareness is a missing dimension in VLM design and a bottleneck for applications requiring spatial grounding, such as robotics and embodied AI. To address this, we investigate (i) image encoders trained with alternative objectives and (ii) 2D positional encodings. Our experiments show that these architectural choices can lead to improved spatial reasoning on several benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.09954v2</guid></item><item><title>[cs updates on arXiv.org] Outrunning Big KATs: Efficient Decision Procedures for Variants of GKAT</title><link>https://arxiv.org/abs/2601.09986</link><description>arXiv:2601.09986v2 Announce Type: replace 
Abstract: This paper presents several efficient decision procedures for trace equivalence of GKAT automata, which make use of on-the-fly symbolic techniques via SAT solvers. To demonstrate applicability of our algorithms, we designed symbolic derivatives for CF-GKAT, a practical system based on GKAT designed to validate control-flow transformations. We implemented the algorithms in Rust and evaluated them on both randomly generated benchmarks and real-world control-flow transformations. Indeed, we observed order-of-magnitude performance improvements against existing implementations for both KAT and CF-GKAT. Notably, our experiments also revealed a bug in Ghidra, an industry-standard decompiler, highlighting the practical viability of these systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.09986v2</guid></item><item><title>[cs updates on arXiv.org] Rewriting Systems on Arbitrary Monoids</title><link>https://arxiv.org/abs/2601.10564</link><description>arXiv:2601.10564v3 Announce Type: replace 
Abstract: In this paper, we introduce monoidal rewriting systems (MRS), an abstraction of string rewriting in which reductions are defined over an arbitrary ambient monoid rather than a free monoid of words. This shift is partly motivated by logic: the class of free monoids is not first-order axiomatizable, so "working in the free setting" cannot be treated internally when applying first-order methods to rewriting presentations.
  To analyze these systems categorically, we define $\mathbf{NCRS_2}$ as the 2-category of Noetherian Confluent MRS. We then prove the existence of a canonical biadjunction between $\mathbf{NCRS_2}$ and $\mathbf{Mon}$.
  Finally, we classify all Noetherian Confluent MRS that present a given fixed monoid. For this, we introduce Generalized Elementary Tietze Transformations (GETTs) and prove that any two presentations of a monoid are connected by a (possibly infinite) sequence of these transformations, yielding a complete characterization of generating systems up to GETT-equivalence.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.10564v3</guid></item><item><title>[cs updates on arXiv.org] Translating database mathematical schemes into relational database software applications with MatBase</title><link>https://arxiv.org/abs/2601.10604</link><description>arXiv:2601.10604v3 Announce Type: replace 
Abstract: We present a pseudocode algorithm for translating our (Elementary) Mathematical Data Model schemes into relational ones and associated sets of non-relational constraints, used by MatBase, our intelligent data and knowledge base management system prototype. We prove that this algorithm is very fast, solid, complete, and optimal. We apply it to a mathematical scheme modeling the genealogical trees subuniverse. We also provide examples of SQL and VBA code for enforcing some of its non-relational constraints, as well as guidelines to develop code for enforcing such constraints.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.10604v3</guid></item><item><title>[cs updates on arXiv.org] Massively Multilingual Joint Segmentation and Glossing</title><link>https://arxiv.org/abs/2601.10925</link><description>arXiv:2601.10925v2 Announce Type: replace 
Abstract: Automated interlinear gloss prediction with neural networks is a promising approach to accelerate language documentation efforts. However, while state-of-the-art models like GlossLM achieve high scores on glossing benchmarks, user studies with linguists have found critical barriers to the usefulness of such models in real-world scenarios. In particular, existing models typically generate morpheme-level glosses but assign them to whole words without predicting the actual morpheme boundaries, making the predictions less interpretable and thus untrustworthy to human annotators.
  We conduct the first study on neural models that jointly predict interlinear glosses and the corresponding morphological segmentation from raw text. We run experiments to determine the optimal way to train models that balance segmentation and glossing accuracy, as well as the alignment between the two tasks. We extend the training corpus of GlossLM and pretrain PolyGloss, a family of seq2seq multilingual models for joint segmentation and glossing that outperforms GlossLM on glossing and beats various open-source LLMs on segmentation, glossing, and alignment. In addition, we demonstrate that PolyGloss can be quickly adapted to a new dataset via low-rank adaptation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.10925v2</guid></item><item><title>[cs updates on arXiv.org] Where to Touch, How to Contact: Hierarchical RL-MPC Framework for Geometry-Aware Long-Horizon Dexterous Manipulation</title><link>https://arxiv.org/abs/2601.10930</link><description>arXiv:2601.10930v2 Announce Type: replace 
Abstract: A key challenge in contact-rich dexterous manipulation is the need to jointly reason over geometry, kinematic constraints, and intricate, nonsmooth contact dynamics. End-to-end visuomotor policies bypass this structure, but often require large amounts of data, transfer poorly from simulation to reality, and generalize weakly across tasks/embodiments. We address those limitations by leveraging a simple insight: dexterous manipulation is inherently hierarchical - at a high level, a robot decides where to touch (geometry) and move the object (kinematics); at a low level it determines how to realize that plan through contact dynamics. Building on this insight, we propose a hierarchical RL--MPC framework in which a high-level reinforcement learning (RL) policy predicts a contact intention, a novel object-centric interface that specifies (i) an object-surface contact location and (ii) a post-contact object-level subgoal pose. Conditioned on this contact intention, a low-level contact-implicit model predictive control (MPC) optimizes local contact modes and replans with contact dynamics to generate robot actions that robustly drive the object toward each subgoal. We evaluate the framework on non-prehensile tasks, including geometry-generalized pushing and object 3D reorientation. It achieves near-100% success with substantially reduced data (10x less than end-to-end baselines), highly robust performance, and zero-shot sim-to-real transfer.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.10930v2</guid></item><item><title>[cs updates on arXiv.org] Combating Spurious Correlations in Graph Interpretability via Self-Reflection</title><link>https://arxiv.org/abs/2601.11021</link><description>arXiv:2601.11021v2 Announce Type: replace 
Abstract: Interpretable graph learning has recently emerged as a popular research topic in machine learning. The goal is to identify the important nodes and edges of an input graph that are crucial for performing a specific graph reasoning task. A number of studies have been conducted in this area, and various benchmark datasets have been proposed to facilitate evaluation. Among them, one of the most challenging is the Spurious-Motif benchmark, introduced at ICLR 2022. The datasets in this synthetic benchmark are deliberately designed to include spurious correlations, making it particularly difficult for models to distinguish truly relevant structures from misleading patterns. As a result, existing methods exhibit significantly worse performance on this benchmark compared to others.
  In this paper, we focus on improving interpretability on the challenging Spurious-Motif datasets. We demonstrate that the self-reflection technique, commonly used in large language models to tackle complex tasks, can also be effectively adapted to enhance interpretability in datasets with strong spurious correlations. Specifically, we propose a self-reflection framework that can be integrated with existing interpretable graph learning methods. When such a method produces importance scores for each node and edge, our framework feeds these predictions back into the original method to perform a second round of evaluation. This iterative process mirrors how large language models employ self-reflective prompting to reassess their previous outputs. We further analyze the reasons behind this improvement from the perspective of graph representation learning, which motivates us to propose a fine-tuning training method based on this feedback mechanism.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11021v2</guid></item><item><title>[cs updates on arXiv.org] Self-Augmented Mixture-of-Experts for QoS Prediction</title><link>https://arxiv.org/abs/2601.11036</link><description>arXiv:2601.11036v2 Announce Type: replace 
Abstract: Quality of Service (QoS) prediction is one of the most fundamental problems in service computing and personalized recommendation. In the problem, there is a set of users and services, each associated with a set of descriptive features. Interactions between users and services produce feedback values, typically represented as numerical QoS metrics such as response time or availability. Given the observed feedback for a subset of user-service pairs, the goal is to predict the QoS values for the remaining pairs.
  A key challenge in QoS prediction is the inherent sparsity of user-service interactions, as only a small subset of feedback values is typically observed. To address this, we propose a self-augmented strategy that leverages a model's own predictions for iterative refinement. In particular, we partially mask the predicted values and feed them back into the model to predict again. Building on this idea, we design a self-augmented mixture-of-experts model, where multiple expert networks iteratively and collaboratively estimate QoS values. We find that the iterative augmentation process naturally aligns with the MoE architecture by enabling inter-expert communication: in the second round, each expert receives the first-round predictions and refines its output accordingly. Experiments on benchmark datasets show that our method outperforms existing baselines and achieves competitive results.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11036v2</guid></item><item><title>[cs updates on arXiv.org] Extractive summarization on a CMOS Ising machine</title><link>https://arxiv.org/abs/2601.11491</link><description>arXiv:2601.11491v2 Announce Type: replace 
Abstract: Extractive summarization (ES) aims to generate a concise summary by selecting a subset of sentences from a document while maximizing relevance and minimizing redundancy. Although modern ES systems achieve high accuracy using powerful neural models, their deployment typically relies on CPU or GPU infrastructures that are energy-intensive and poorly suited for real-time inference in resource-constrained environments. In this work, we explore the feasibility of implementing McDonald-style extractive summarization on a low-power CMOS coupled oscillator-based Ising machine (COBI) that supports integer-valued, all-to-all spin couplings. We first propose a hardware-aware Ising formulation that reduces the scale imbalance between local fields and coupling terms, thereby improving robustness to coefficient quantization: this method can be applied to any problem formulation that requires k of n variables to be chosen. We then develop a complete ES pipeline including (i) stochastic rounding and iterative refinement to compensate for precision loss, and (ii) a decomposition strategy that partitions a large ES problem into smaller Ising subproblems that can be efficiently solved on COBI and later combined. Experimental results on the CNN/DailyMail dataset show that our pipeline can produce high-quality summaries using only integer-coupled Ising hardware with limited precision. COBI achieves 3-4.5x runtime speedups compared to a brute-force method, which is comparable to software Tabu search, and two to three orders of magnitude reductions in energy, while maintaining competitive summary quality. These results highlight the potential of deploying CMOS Ising solvers for real-time, low-energy text summarization on edge devices.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11491v2</guid></item><item><title>[cs updates on arXiv.org] Enhancing Model Context Protocol (MCP) with Context-Aware Server Collaboration</title><link>https://arxiv.org/abs/2601.11595</link><description>arXiv:2601.11595v2 Announce Type: replace 
Abstract: The Model Context Protocol (MCP) (MCP Community, 2025) has emerged as a widely used framework for enabling LLM-based agents to communicate with external tools and services. The original MCP implementation (Anthropic, 2024) relies on a Large Language Model (LLM) to decompose tasks and issue instructions to servers. In particular, the agents, models, and servers are stateless and do not have access to a global context. However, in tasks involving LLM-driven coordination, it is natural that a Shared Context Store (SCS) could improve the efficiency and coherence of multi-agent workflows by reducing redundancy and enabling knowledge transfer between servers. Thus, in this work, we design and assess the performance of a Context-Aware MCP (CA-MCP) that offloads execution logic to specialized MCP servers that read from and write to a shared context memory, allowing them to coordinate more autonomously in real time. In this design, context management serves as the central mechanism that maintains continuity across task executions by tracking intermediate states and shared variables, thereby enabling persistent collaboration among agents without repeated prompting. We present experiments showing that the CA-MCP can outperform the traditional MCP by reducing the number of LLM calls required for complex tasks and decreasing the frequency of response failures when task conditions are not satisfied. In particular, we conducted experiments on the TravelPlanner (Yang et al., 2024) and REALM-Bench (Geng &amp; Chang, 2025) benchmark datasets and observed statistically significant results indicating the potential advantages of incorporating a shared context store via CA-MCP in LLM-driven multi-agent systems.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11595v2</guid></item><item><title>[cs updates on arXiv.org] Bayesian ICA for Causal Discovery</title><link>https://arxiv.org/abs/2601.11815</link><description>arXiv:2601.11815v2 Announce Type: replace 
Abstract: Causal discovery based on Independent Component Analysis (ICA) has achieved remarkable success through the LiNGAM framework, which exploits non-Gaussianity and independence of noise variables to identify causal order. However, classical LiNGAM methods rely on the strong assumption that there exists an ordering under which the noise terms are exactly independent, an assumption that is often violated in the presence of confounding. In this paper, we propose a general information-theoretic framework for causal order estimation that remains applicable under arbitrary confounding. Rather than imposing independence as a hard constraint, we quantify the degree of confounding by the multivariate mutual information among the noise variables. This quantity is decomposed into a sum of mutual information terms along a causal order and is estimated using Bayesian marginal likelihoods. The resulting criterion can be interpreted as Bayesian ICA for causal discovery, where causal order selection is formulated as a model selection problem over permutations. Under standard regularity conditions, we show that the proposed Bayesian mutual information estimator is consistent, with redundancy of order $O(\log n)$. To avoid non-identifiability caused by Gaussian noise, we employ non-Gaussian predictive models, including multivariate $t$ distributions, whose marginal likelihoods can be evaluated via MCMC. The proposed method recovers classical LiNGAM and DirectLiNGAM as limiting cases in the absence of confounding, while providing a principled ranking of causal orders when confounding is present. This establishes a unified, confounding-aware, and information-theoretically grounded extension of ICA-based causal discovery.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11815v2</guid></item><item><title>[cs updates on arXiv.org] Language-Guided and Motion-Aware Gait Representation for Generalizable Recognition</title><link>https://arxiv.org/abs/2601.11931</link><description>arXiv:2601.11931v2 Announce Type: replace 
Abstract: Gait recognition is emerging as a promising technology and an innovative field within computer vision, with a wide range of applications in remote human identification. However, existing methods typically rely on complex architectures to directly extract features from images and apply pooling operations to obtain sequence-level representations. Such designs often lead to overfitting on static noise (e.g., clothing), while failing to effectively capture dynamic motion regions, such as the arms and legs. This bottleneck is particularly challenging in the presence of intra-class variation, where gait features of the same individual under different environmental conditions are significantly distant in the feature space. To address the above challenges, we present a Languageguided and Motion-aware gait recognition framework, named LMGait. To the best of our knowledge, LMGait is the first method to introduce natural language descriptions as explicit semantic priors into the gait recognition task. In particular, we utilize designed gait-related language cues to capture key motion features in gait sequences. To improve cross-modal alignment, we propose the Motion Awareness Module (MAM), which refines the language features by adaptively adjusting various levels of semantic information to ensure better alignment with the visual representations. Furthermore, we introduce the Motion Temporal Capture Module (MTCM) to enhance the discriminative capability of gait features and improve the model's motion tracking ability. We conducted extensive experiments across multiple datasets, and the results demonstrate the significant advantages of our proposed network. Specifically, our model achieved accuracies of 88.5%, 97.1%, and 97.5% on the CCPG, SUSTech1K, and CASIAB datasets, respectively, achieving state-of-the-art performance. Homepage: https://dingwu1021.github.io/LMGait/</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11931v2</guid></item><item><title>[cs updates on arXiv.org] R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning</title><link>https://arxiv.org/abs/2601.11960</link><description>arXiv:2601.11960v2 Announce Type: replace 
Abstract: Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.4% on MATH-500 and 1.3% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11960v2</guid></item><item><title>[cs updates on arXiv.org] From LLMs to Agents in Programming: The Impact of Providing an LLM with a Compiler</title><link>https://arxiv.org/abs/2601.12146</link><description>arXiv:2601.12146v2 Announce Type: replace 
Abstract: Large Language Models have demonstrated a remarkable capability in natural language and program generation and software development. However, the source code generated by the LLMs does not always meet quality requirements and may fail to compile. Therefore, many studies evolve into agents that can reason about the problem before generating the source code for the solution. The goal of this paper is to study the degree to which such agents benefit from access to software development tools, in our case, a gcc compiler. We conduct a computational experiment on the RosettaCode dataset, on 699 programming tasks in C. We evaluate how the integration with a compiler shifts the role of the language model from a passive generator to an active agent capable of iteratively developing runnable programs based on feedback from the compiler. We evaluated 16 language models with sizes ranging from small (135 million) to medium (3 billion) and large (70 billion). Our results show that access to a compiler improved the compilation success by 5.3 to 79.4 percentage units in compilation without affecting the semantics of the generated program. Syntax errors dropped by 75%, and errors related to undefined references dropped by 87% for the tasks where the agents outperformed the baselines. We also observed that in some cases, smaller models with a compiler outperform larger models with a compiler. We conclude that it is essential for LLMs to have access to software engineering tools to enhance their performance and reduce the need for large models in software engineering, such as reducing our energy footprint.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12146v2</guid></item><item><title>[cs updates on arXiv.org] Understanding Partial Reachability in the Internet Core</title><link>https://arxiv.org/abs/2601.12196</link><description>arXiv:2601.12196v2 Announce Type: replace 
Abstract: Routing strives to connect all the Internet, but compete: political pressure threatens routing fragmentation; architectural changes such as private clouds, carrier-grade NAT, and firewalls make connectivity conditional; and commercial disputes create partial reachability for days or years. This paper suggests *persistent, partial reachability is fundamental to the Internet* and an underexplored problem. We first *derive a conceptual definition of the Internet core* based on connectivity, not authority. We identify *peninsulas*: persistent, partial connectivity; and *islands*: when computers are partitioned from the Internet core. Second, we develop algorithms to observe each across the Internet, and apply them to two existing measurement systems: Trinocular, where 6 locations observe 5M networks frequently, and RIPE Atlas, where 13k locations scan the DNS roots frequently. Cross-validation shows our findings are stable over *three years of data*, and consistent with as few as 3 geographically-distributed observers. We validate peninsulas and islands against CAIDA Ark, showing good recall (0.94) and bounding precision between 0.42 and 0.82. Finally, our work has broad practical impact: we show that *peninsulas are more common than Internet outages*. Factoring out peninsulas and islands as noise can *improve existing measurement systems*; their ``noise'' is $5\times$ to $9.7\times$ larger than the operational events in RIPE's DNSmon. We show that most peninsula events are routing transients (45\%), but most peninsula-time (90\%) is due to a few (7\%) long-lived events. Our work helps inform Internet policy and governance, with our neutral definition showing no single country or organization can unilaterally control the Internet core.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12196v2</guid></item><item><title>[cs updates on arXiv.org] XR$^3$: An Extended Reality Platform for Social-Physical Human-Robot Interaction</title><link>https://arxiv.org/abs/2601.12395</link><description>arXiv:2601.12395v3 Announce Type: replace 
Abstract: Social-physical human-robot interaction (spHRI) is difficult to study: building and programming robots that integrate multiple interaction modalities is costly and slow, while VR-based prototypes often lack physical contact, breaking users' visuo-tactile expectations. We present XR$^3$, a co-located dual-VR-headset platform for HRI research in which an attendee and a hidden operator share the same physical space while experiencing different virtual embodiments. The attendee sees an expressive virtual robot that interacts face-to-face in a shared virtual environment. In real time, the robot's upper-body motion, head and gaze behavior, and facial expressions are mapped from the operator's tracked limbs and face signals. Because the operator is co-present and calibrated in the same coordinate frame, the operator can also touch the attendee, enabling perceived robot touch synchronized with the robot's visible hands. Finger and hand motion is mapped to the robot avatar using inverse kinematics to support precise contact. Beyond motion retargeting, XR$^3$ supports social retargeting of multiple nonverbal cues that can be experimentally varied while keeping physical interaction constant. We detail the system design and calibration, and demonstrate the platform in a touch-based Wizard-of-Oz study, lowering the barrier to prototyping and evaluating embodied, contact-based robot behaviors.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12395v3</guid></item><item><title>[cs updates on arXiv.org] HyFormer: Revisiting the Roles of Sequence Modeling and Feature Interaction in CTR Prediction</title><link>https://arxiv.org/abs/2601.12681</link><description>arXiv:2601.12681v2 Announce Type: replace 
Abstract: Industrial large-scale recommendation models (LRMs) face the challenge of jointly modeling long-range user behavior sequences and heterogeneous non-sequential features under strict efficiency constraints. However, most existing architectures employ a decoupled pipeline: long sequences are first compressed with a query-token based sequence compressor like LONGER, followed by fusion with dense features through token-mixing modules like RankMixer, which thereby limits both the representation capacity and the interaction flexibility. This paper presents HyFormer, a unified hybrid transformer architecture that tightly integrates long-sequence modeling and feature interaction into a single backbone. From the perspective of sequence modeling, we revisit and redesign query tokens in LRMs, and frame the LRM modeling task as an alternating optimization process that integrates two core components: Query Decoding which expands non-sequential features into Global Tokens and performs long sequence decoding over layer-wise key-value representations of long behavioral sequences; and Query Boosting which enhances cross-query and cross-sequence heterogeneous interactions via efficient token mixing. The two complementary mechanisms are performed iteratively to refine semantic representations across layers. Extensive experiments on billion-scale industrial datasets demonstrate that HyFormer consistently outperforms strong LONGER and RankMixer baselines under comparable parameter and FLOPs budgets, while exhibiting superior scaling behavior with increasing parameters and FLOPs. Large-scale online A/B tests in high-traffic production systems further validate its effectiveness, showing significant gains over deployed state-of-the-art models. These results highlight the practicality and scalability of HyFormer as a unified modeling framework for industrial LRMs.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12681v2</guid></item><item><title>[cs updates on arXiv.org] A Two-Stage GPU Kernel Tuner Combining Semantic Refactoring and Search-Based Optimization</title><link>https://arxiv.org/abs/2601.12698</link><description>arXiv:2601.12698v3 Announce Type: replace 
Abstract: GPU code optimization is a key performance bottleneck for HPC workloads as well as large-model training and inference. Although compiler optimizations and hand-written kernels can partially alleviate this issue, achieving near-hardware-limit performance still relies heavily on manual code refactoring and parameter tuning. Recent progress in LLM-agent-based kernel generation and optimization has been reported, yet many approaches primarily focus on direct code rewriting, where parameter choices are often implicit and hard to control, or require human intervention, leading to unstable performance gains. This paper introduces a template-based rewriting layer on top of an agent-driven iterative loop: kernels are semantically refactored into explicitly parameterizable templates, and template parameters are then optimized via search-based autotuning, yielding more stable and higher-quality speedups. Experiments on a set of real-world kernels demonstrate speedups exceeding 3x in the best case. We extract representative CUDA kernels from SGLang as evaluation targets; the proposed agentic tuner iteratively performs templating, testing, analysis, and planning, and leverages profiling feedback to execute constrained parameter search under hardware resource limits. Compared to agent-only direct rewriting, the template-plus-search design significantly reduces the randomness of iterative optimization, making the process more interpretable and enabling a more systematic approach toward high-performance configurations. The proposed method can be further extended to OpenCL, HIP, and other backends to deliver automated performance optimization for real production workloads.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12698v3</guid></item><item><title>[cs updates on arXiv.org] An Evolutionary Framework for Automatic Optimization Benchmark Generation via Large Language Models</title><link>https://arxiv.org/abs/2601.12723</link><description>arXiv:2601.12723v2 Announce Type: replace 
Abstract: Optimization benchmarks play a fundamental role in assessing algorithm performance; however, existing artificial benchmarks often fail to capture the diversity and irregularity of real-world problem structures, while benchmarks derived from real-world problems are costly and difficult to construct. To address these challenges, we propose an evolutionary automatic benchmark generation framework that leverages a large language model (LLM) as a generative operator, termed the LLM-driven evolutionary benchmark generator (LLM-EBG). In this framework, the LLM serves as an evolutionary operator that generates and evolves benchmark problems within a flexible, expressive representation space. As a case study, we generate unconstrained single-objective continuous minimization problems represented as mathematical expressions designed to induce significant performance differences between a genetic algorithm (GA) and differential evolution (DE). Experimental results show that LLM-EBG successfully produces benchmark problems in which the designated target algorithm consistently outperforms the comparative algorithm in more than 80\% of trials. Furthermore, exploratory landscape analysis reveals that benchmarks favoring GA are highly sensitive to variable scaling, demonstrating that the proposed framework can generate problems with distinct geometric characteristics that reflect the intrinsic search behaviors of different optimization algorithms.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12723v2</guid></item><item><title>[cs updates on arXiv.org] Who Does This Name Remind You of ? Nationality Prediction via Large Language Model Associative Memory</title><link>https://arxiv.org/abs/2601.12771</link><description>arXiv:2601.12771v2 Announce Type: replace 
Abstract: Large language models (LLMs) possess extensive world knowledge, yet methods for effectively eliciting this knowledge remain underexplored. Nationality and region prediction tasks require understanding of not only linguistic features but also cultural and historical background, making LLM world knowledge particularly valuable. However, conventional LLM prompting methods rely on direct reasoning approaches, which have limitations in applying abstract linguistic rules. We propose LLM Associative Memory Agents (LAMA), a novel framework that leverages LLM world knowledge as associative memory. Rather than directly inferring nationality from names, LAMA recalls famous individuals with the same name and aggregates their nationalities through indirect reasoning. A dual-agent architecture comprising a Person Agent and a Media Agent, specialized in different knowledge domains, recalls famous individuals in parallel, generating Top-1 predictions through voting and Top-K predictions through conditional completion. On a 99-country nationality prediction task, LAMA achieved 0.817 accuracy, substantially outperforming conventional LLM prompting methods and neural models. Our experiments reveal that LLMs exhibit higher reliability in recalling concrete examples than in abstract reasoning, that recall-based approaches are robust to low-frequency nationalities independent of data frequency distributions, and that the dual-agent architecture functions complementarily to produce synergistic effects. These results demonstrate the effectiveness of a new multi-agent system that retrieves and aggregates LLM knowledge rather than prompting reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12771v2</guid></item><item><title>[cs updates on arXiv.org] Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data</title><link>https://arxiv.org/abs/2601.12856</link><description>arXiv:2601.12856v2 Announce Type: replace 
Abstract: Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. Effective and affordable control requires anticipating where transmission risks are likely to emerge so that interventions can be deployed proactively rather than reactively. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, we model how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. While mosquito movement is highly localized, long-distance transmission is often driven by human mobility, and in our case study, the learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used not only to forecast hotspot status but also to verify the consistency of spreading patterns, by examining the stability of the inferred network across consecutive weeks. Case studies on Singapore during 2013-2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79. Importantly, the learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. By shifting from simply reporting dengue cases to mining and validating hidden spreading dynamics, this work transforms open web-based case data into a predictive and explanatory resource. The proposed framework advances epidemic modeling while providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12856v2</guid></item><item><title>[cs updates on arXiv.org] GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation</title><link>https://arxiv.org/abs/2601.12948</link><description>arXiv:2601.12948v2 Announce Type: replace 
Abstract: We introduce GazeD, a new 3D gaze estimation method that jointly provides 3D gaze and human pose from a single RGB image. Leveraging the ability of diffusion models to deal with uncertainty, it generates multiple plausible 3D gaze and pose hypotheses based on the 2D context information extracted from the input image. Specifically, we condition the denoising process on the 2D pose, the surroundings of the subject, and the context of the scene. With GazeD we also introduce a novel way of representing the 3D gaze by positioning it as an additional body joint at a fixed distance from the eyes. The rationale is that the gaze is usually closely related to the pose, and thus it can benefit from being jointly denoised during the diffusion process. Evaluations across three benchmark datasets demonstrate that GazeD achieves state-of-the-art performance in 3D gaze estimation, even surpassing methods that rely on temporal information. Project details will be available at https://aimagelab.ing.unimore.it/go/gazed.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12948v2</guid></item><item><title>[cs updates on arXiv.org] The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check</title><link>https://arxiv.org/abs/2601.12979</link><description>arXiv:2601.12979v2 Announce Type: replace 
Abstract: The pursuit of real-time agentic interaction has driven interest in Diffusion-based Large Language Models (dLLMs) as alternatives to auto-regressive backbones, promising to break the sequential latency bottleneck. However, does such efficiency gains translate into effective agentic behavior? In this work, we present a comprehensive evaluation of dLLMs (e.g., LLaDA, Dream) across two distinct agentic paradigms: Embodied Agents (requiring long-horizon planning) and Tool-Calling Agents (requiring precise formatting). Contrary to the efficiency hype, our results on Agentboard and BFCL reveal a "bitter lesson": current dLLMs fail to serve as reliable agentic backbones, frequently leading to systematically failure. (1) In Embodied settings, dLLMs suffer repeated attempts, failing to branch under temporal feedback. (2) In Tool-Calling settings, dLLMs fail to maintain symbolic precision (e.g. strict JSON schemas) under diffusion noise. To assess the potential of dLLMs in agentic workflows, we introduce DiffuAgent, a multi-agent evaluation framework that integrates dLLMs as plug-and-play cognitive cores. Our analysis shows that dLLMs are effective in non-causal roles (e.g., memory summarization and tool selection) but require the incorporation of causal, precise, and logically grounded reasoning mechanisms into the denoising process to be viable for agentic tasks.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12979v2</guid></item><item><title>[cs updates on arXiv.org] FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation</title><link>https://arxiv.org/abs/2601.13976</link><description>arXiv:2601.13976v2 Announce Type: replace 
Abstract: Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.13976v2</guid></item><item><title>[cs updates on arXiv.org] Q-learning with Adjoint Matching</title><link>https://arxiv.org/abs/2601.14234</link><description>arXiv:2601.14234v2 Announce Type: replace 
Abstract: We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14234v2</guid></item><item><title>[cs updates on arXiv.org] Scribble-Supervised Medical Image Segmentation with Dynamic Teacher Switching and Hierarchical Consistency</title><link>https://arxiv.org/abs/2601.14563</link><description>arXiv:2601.14563v3 Announce Type: replace 
Abstract: Scribble-supervised methods have emerged to mitigate the prohibitive annotation burden in medical image segmentation. However, the inherent sparsity of these annotations introduces significant ambiguity, which results in noisy pseudo-label propagation and hinders the learning of robust anatomical boundaries. To address this challenge, we propose SDT-Net, a novel dual-teacher, single-student framework designed to maximize supervision quality from these weak signals. Our method features a Dynamic Teacher Switching (DTS) module to adaptively select the most reliable teacher. This selected teacher then guides the student via two synergistic mechanisms: high-confidence pseudo-labels, refined by a Pick Reliable Pixels (PRP) mechanism, and multi-level feature alignment, enforced by a Hierarchical Consistency (HiCo) module. Extensive experiments on the ACDC and MSCMRseg datasets demonstrate that SDT-Net achieves state-of-the-art performance, producing more accurate and anatomically plausible segmentation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14563v3</guid></item><item><title>[cs updates on arXiv.org] Validating Behavioral Proxies for Disease Risk Monitoring via Large-Scale E-commerce Data</title><link>https://arxiv.org/abs/2601.14795</link><description>arXiv:2601.14795v2 Announce Type: replace 
Abstract: Digital traces of daily activities, such as e-commerce (EC) purchase histories, provide scalable signals for public health surveillance, yet their epidemiological validity remains unclear. This study validates a behavioral proxy for disease onset, defined as transitions from regular to therapeutic diets, by comparing large-scale EC data (N=55,645) against independent insurance-derived clinical records. Using feline lower urinary tract disease (FLUTD) as a case study, the proxy showed strong agreement with clinical data for ingredient-level risk patterns (r=0.74) and seasonal dynamics (r=0.82). Furthermore, analysis using EC data alone reproduced the established protective association of wet food consumption. These results demonstrate that validated behavioral signals from EC data can serve as cost-effective complements to traditional surveillance, with potential applicability to monitoring lifestyle-related diseases in human populations.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14795v2</guid></item><item><title>[cs updates on arXiv.org] HumanDiffusion: A Vision-Based Diffusion Trajectory Planner with Human-Conditioned Goals for Search and Rescue UAV</title><link>https://arxiv.org/abs/2601.14973</link><description>arXiv:2601.14973v2 Announce Type: replace 
Abstract: Reliable human--robot collaboration in emergency scenarios requires autonomous systems that can detect humans, infer navigation goals, and operate safely in dynamic environments. This paper presents HumanDiffusion, a lightweight image-conditioned diffusion planner that generates human-aware navigation trajectories directly from RGB imagery. The system combines YOLO-11 based human detection with diffusion-driven trajectory generation, enabling a quadrotor to approach a target person and deliver medical assistance without relying on prior maps or computationally intensive planning pipelines. Trajectories are predicted in pixel space, ensuring smooth motion and a consistent safety margin around humans. We evaluate HumanDiffusion in simulation and real-world indoor mock-disaster scenarios. On a 300-sample test set, the model achieves a mean squared error of 0.02 in pixel-space trajectory reconstruction. Real-world experiments demonstrate an overall mission success rate of 80% across accident-response and search-and-locate tasks with partial occlusions. These results indicate that human-conditioned diffusion planning offers a practical and robust solution for human-aware UAV navigation in time-critical assistance settings.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14973v2</guid></item><item><title>[cs updates on arXiv.org] Emergent, not Immanent: A Baradian Reading of Explainable AI</title><link>https://arxiv.org/abs/2601.15029</link><description>arXiv:2601.15029v2 Announce Type: replace 
Abstract: Explainable AI (XAI) is frequently positioned as a technical problem of revealing the inner workings of an AI model. This position is affected by unexamined onto-epistemological assumptions: meaning is treated as immanent to the model, the explainer is positioned outside the system, and a causal structure is presumed recoverable through computational techniques. In this paper, we draw on Barad's agential realism to develop an alternative onto-epistemology of XAI. We propose that interpretations are material-discursive performances that emerge from situated entanglements of the AI model with humans, context, and the interpretative apparatus. To develop this position, we read a comprehensive set of XAI methods through agential realism and reveal the assumptions and limitations that underpin several of these methods. We then articulate the framework's ethical dimension and propose design directions for XAI interfaces that support emergent interpretation, using a speculative text-to-music interface as a case study.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15029v2</guid></item><item><title>[cs updates on arXiv.org] A Mobile Application Front-End for Presenting Explainable AI Results in Diabetes Risk Estimation</title><link>https://arxiv.org/abs/2601.15292</link><description>arXiv:2601.15292v2 Announce Type: replace 
Abstract: Diabetes is a significant and continuously rising health challenge in Indonesia. Although many artificial intelligence (AI)-based health applications have been developed for early detection, most function as "black boxes," lacking transparency in their predictions. Explainable AI (XAI) methods offer a solution, yet their technical outputs are often incomprehensible to non-expert users. This research aims to develop a mobile application front-end that presents XAI-driven diabetes risk analysis in an intuitive, understandable format. Development followed the waterfall methodology, comprising requirements analysis, interface design, implementation, and evaluation. Based on user preference surveys, the application adopts two primary visualization types - bar charts and pie charts - to convey the contribution of each risk factor. These are complemented by personalized textual narratives generated via integration with GPT-4o. The application was developed natively for Android using Kotlin and Jetpack Compose. The resulting prototype interprets SHAP (SHapley Additive exPlanations), a key XAI approach, into accessible graphical visualizations and narratives. Evaluation through user comprehension testing (Likert scale and interviews) and technical functionality testing confirmed the research objectives were met. The combination of visualization and textual narrative effectively enhanced user understanding (average score 4.31/5) and empowered preventive action, supported by a 100% technical testing success rate.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15292v2</guid></item><item><title>[cs updates on arXiv.org] AfriEconQA: A Benchmark Dataset for African Economic Analysis based on World Bank Reports</title><link>https://arxiv.org/abs/2601.15297</link><description>arXiv:2601.15297v2 Announce Type: replace 
Abstract: We introduce AfriEconQA, a specialized benchmark dataset for African economic analysis grounded in a comprehensive corpus of 236 World Bank reports. The task of AfriEconQA is to answer complex economic queries that require high-precision numerical reasoning and temporal disambiguation from specialized institutional documents. The dataset consists of 8,937 curated QA instances, rigorously filtered from a pool of 10018 synthetic questions to ensure high-quality evidence-answer alignment. Each instance is composed of: (1) a question requiring reasoning over economic indicators, (2) the corresponding evidence retrieved from the corpus, (3) a verified ground-truth answer, and (4) source metadata (e.g., URL and publication date) to ensure temporal provenance. AfriEconQA is the first benchmark focused specifically on African economic analysis, providing a unique challenge for Information Retrieval (IR) systems, as the data is largely absent from the pretraining corpora of current Large Language Models (LLMs). We operationalize this dataset through an 11-experiment matrix, benchmarking a zero-shot baseline (GPT-5 Mini) against RAG configurations using GPT-4o and Qwen 32B across five distinct embedding and ranking strategies. Our results demonstrate a severe parametric knowledge gap, where zero-shot models fail to answer over 90 percent of queries, and even state-of-the-art RAG pipelines struggle to achieve high precision. This confirms AfriEconQA as a robust and challenging benchmark for the next generation of domain-specific IR and RAG systems. The AfriEconQA dataset and code will be made publicly available upon publication.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15297v2</guid></item><item><title>[cs updates on arXiv.org] Prometheus Mind: Retrofitting Memory to Frozen Language Models</title><link>https://arxiv.org/abs/2601.15324</link><description>arXiv:2601.15324v2 Announce Type: replace 
Abstract: Adding memory to pretrained language models typically requires architectural changes or weight modification. We present Prometheus Mind, which retrofits memory to a frozen Qwen3-4B using 11 modular adapters (530MB, 7% overhead) -- fully reversible by removing the adapters. Building this system required solving four problems: (1) Extraction -- we develop Contrastive Direction Discovery (CDD), which finds semantic directions via minimal pairs without labeled data. (2) Training -- end-to-end optimization collapses; stage-wise training of each adapter on simple proxy tasks succeeds. (3) Injection -- learned encoders fail to generalize; we find that lm_head-weight rows already provide the mapping we need, requiring no training. (4) Hidden state collapse -- transformers make ``wife'' and ``brother'' 0.98+ similar; we train projections to recover distinction (0.98 $\rightarrow$ 0.09). On PrometheusExtract-132 (132 cases), the system achieves 94.4% retrieval on clean inputs (n=54, 95% CI: [84.9%, 98.1%]), degrading to 19.4% on informal inputs with ellipsis, filler words, or implicit subjects (n=36). The primary bottleneck is relation classification (47.3% accuracy), responsible for most extraction errors.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15324v2</guid></item><item><title>[cs updates on arXiv.org] Shape of You: Implications of Social Context and Avatar Body Shape on Relatedness, Emotions, and Performance in a Virtual Reality Workout</title><link>https://arxiv.org/abs/2601.15466</link><description>arXiv:2601.15466v2 Announce Type: replace 
Abstract: It is obvious that emotions are causal variables of motivation, as they elicit states, forces and energies that trigger and guide labor behavior. Thus, a motivational tension that is not informed by needs alone, but also by emotions, intention, goals and means to achieve them is therefore generated within the mental, emotional and physical plane. Based on Montserrat's opinion (2004: 131), that "to motivate means, above all, to move and to transmit an emotion", we will undertake to identify the mutual influences between emotions and motivation. The main objectives of this article are to display a summary of the theories and definitions about emotions and to explore the links between emotions and motivation. Although interconnected, emotions and motivation can be contemplated from a double perspective: (1) emotions influence motivation and (2) motivation influences emotions. Moreover, we will consider motivation from three dimensions: (1) cognitive, (2) affective and (3) volitional. The ultimate purpose of this article is to issue a warning as to the importance of the emotional side of motivation. An important part in implementing such insight is to be played by managers (and by employees, also), who should develop the skills and know-how needed to keep a well-balanced emotional climate that effectively favors the maximization of individual and group motivation at the workplace.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15466v2</guid></item><item><title>[cs updates on arXiv.org] Put Your Muscle Into It: Introducing XEM2, a Novel Approach for Monitoring Exertion in Stationary Physical Exercises Leveraging Muscle Work</title><link>https://arxiv.org/abs/2601.15472</link><description>arXiv:2601.15472v2 Announce Type: replace 
Abstract: We present a novel system for camera-based measurement and visualization of muscle work based on the Hill-Type-Muscle-Model: the exercise exertion muscle-work monitor (\textit{XEM}$^{2}$). Our aim is to complement and, thus, address issues of established measurement techniques that offer imprecise data for non-uniform movements (burned calories) or provide limited information on strain across different body parts (self-perception scales). We validate the reliability of XEM's measurements through a technical evaluation of ten participants and five exercises. Further, we assess the acceptance, usefulness, benefits, and opportunities of \textit{XEM}$^{2}$ in an empirical user study. Our results show that \textit{XEM}$^{2}$ provides reliable values of muscle work and supports participants in understanding their workout while also providing reliable information about perceived exertion per muscle group. With this paper, we introduce a novel system capable of measuring and visualizing exertion for single muscle groups, which has the potential to improve exercise monitoring to prevent unbalanced workouts.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15472v2</guid></item><item><title>[cs updates on arXiv.org] Advancing RT Core-Accelerated Fixed-Radius Nearest Neighbor Search</title><link>https://arxiv.org/abs/2601.15633</link><description>arXiv:2601.15633v2 Announce Type: replace 
Abstract: In this work we introduce three ideas that can further improve particle FRNN physics simulations running on RT Cores; i) a real-time update/rebuild ratio optimizer for the bounding volume hierarchy (BVH) structure, ii) a new RT core use, with two variants, that eliminates the need of a neighbor list and iii) a technique that enables RT cores for FRNN with periodic boundary conditions (BC). Experimental evaluation using the Lennard-Jones FRNN interaction model as a case study shows that the proposed update/rebuild ratio optimizer is capable of adapting to the different dynamics that emerge during a simulation, leading to a RT core pipeline up to $\sim 3.4\times$ faster than with other known approaches to manage the BVH. In terms of simulation step performance, the proposed variants can significantly improve the speedup and energy efficiency (EE) of the base RT core idea; from $\sim1.3\times$ at small radius to $\sim2.0\times$ for log normal radius distributions. Furthermore, the proposed variants manage to simulate cases that would otherwise not fit in memory because of the use of neighbor lists, such as clusters of particles with log normal radius distribution. The proposed RT Core technique to support periodic BC is indeed effective as it does not introduce any significant penalty in performance. In terms of scaling, the proposed methods scale both their performance and EE across GPU generations. Throughout the experimental evaluation, we also identify the simulation cases were regular GPU computation should still be preferred, contributing to the understanding of the strengths and limitations of RT cores.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15633v2</guid></item><item><title>[cs updates on arXiv.org] Benchmarking Text-to-Python against Text-to-SQL: The Impact of Explicit Logic and Ambiguity</title><link>https://arxiv.org/abs/2601.15728</link><description>arXiv:2601.15728v2 Announce Type: replace 
Abstract: While Text-to-SQL remains the dominant approach for database interaction, real-world analytics increasingly require the flexibility of general-purpose programming languages such as Python or Pandas to manage file-based data and complex analytical workflows. Despite this growing need, the reliability of Text-to-Python in core data retrieval remains underexplored relative to the mature SQL ecosystem. To address this gap, we introduce BIRD-Python, a benchmark designed for cross-paradigm evaluation. We systematically refined the original dataset to reduce annotation noise and align execution semantics, thereby establishing a consistent and standardized baseline for comparison. Our analysis reveals a fundamental paradigmatic divergence: whereas SQL leverages implicit DBMS behaviors through its declarative structure, Python requires explicit procedural logic, making it highly sensitive to underspecified user intent. To mitigate this challenge, we propose the Logic Completion Framework (LCF), which resolves ambiguity by incorporating latent domain knowledge into the generation process. Experimental results show that (1) performance differences primarily stem from missing domain context rather than inherent limitations in code generation, and (2) when these gaps are addressed, Text-to-Python achieves performance parity with Text-to-SQL. These findings establish Python as a viable foundation for analytical agents-provided that systems effectively ground ambiguous natural language inputs in executable logical specifications. Resources are available at https://anonymous.4open.science/r/Bird-Python-43B7/.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15728v2</guid></item><item><title>[cs updates on arXiv.org] Recursive Flow: A Generative Framework for MIMO Channel Estimation</title><link>https://arxiv.org/abs/2601.15767</link><description>arXiv:2601.15767v2 Announce Type: replace 
Abstract: Channel estimation is a fundamental challenge in massive multiple-input multiple-output systems, where estimation accuracy governs the spectral efficiency and link reliability. In this work, we introduce Recursive Flow (RC-Flow), a novel solver that leverages pre-trained flow matching priors to robustly recover channel state information from noisy, under-determined measurements. Different from conventional open-loop generative models, our approach establishes a closed-loop refinement framework via a serial restart mechanism and anchored trajectory rectification. By synergizing flow-consistent prior directions with data-fidelity proximal projections, the proposed RC-Flow achieves robust channel reconstruction and delivers state-of-the-art performance across diverse noise levels, particularly in noise-dominated scenarios. The framework is further augmented by an adaptive dual-scheduling strategy, offering flexible management of the trade-off between convergence speed and reconstruction accuracy. Theoretically, we analyze the Jacobian spectral radius of the recursive operator to prove its global asymptotic stability. Numerical results demonstrate that RC-Flow reduces inference latency by two orders of magnitude while achieving a 2.7 dB performance gain in low signal-to-noise ratio regimes compared to the score-based baseline.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15767v2</guid></item><item><title>[cs updates on arXiv.org] Introducing the Generative Application Firewall (GAF)</title><link>https://arxiv.org/abs/2601.15824</link><description>arXiv:2601.15824v2 Announce Type: replace 
Abstract: This paper introduces the Generative Application Firewall (GAF), a new architectural layer for securing LLM applications. Existing defenses -- prompt filters, guardrails, and data-masking -- remain fragmented; GAF unifies them into a single enforcement point, much like a WAF coordinates defenses for web traffic, while also covering autonomous agents and their tool interactions.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15824v2</guid></item><item><title>[cs updates on arXiv.org] EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience</title><link>https://arxiv.org/abs/2601.15876</link><description>arXiv:2601.15876v2 Announce Type: replace 
Abstract: The development of native computer-use agents (CUA) represents a significant leap in multimodal AI. However, their potential is currently bottlenecked by the constraints of static data scaling. Existing paradigms relying primarily on passive imitation of static datasets struggle to capture the intricate causal dynamics inherent in long-horizon computer tasks. In this work, we introduce EvoCUA, a native computer use agentic model. Unlike static imitation, EvoCUA integrates data generation and policy optimization into a self-sustaining evolutionary cycle. To mitigate data scarcity, we develop a verifiable synthesis engine that autonomously generates diverse tasks coupled with executable validators. To enable large-scale experience acquisition, we design a scalable infrastructure orchestrating tens of thousands of asynchronous sandbox rollouts. Building on these massive trajectories, we propose an iterative evolving learning strategy to efficiently internalize this experience. This mechanism dynamically regulates policy updates by identifying capability boundaries -- reinforcing successful routines while transforming failure trajectories into rich supervision through error analysis and self-correction. Empirical evaluations on the OSWorld benchmark demonstrate that EvoCUA achieves a success rate of 56.7%, establishing a new open-source state-of-the-art. Notably, EvoCUA significantly outperforms the previous best open-source model, OpenCUA-72B (45.0%), and surpasses leading closed-weights models such as UI-TARS-2 (53.1%). Crucially, our results underscore the generalizability of this approach: the evolving paradigm driven by learning from experience yields consistent performance gains across foundation models of varying scales, establishing a robust and scalable path for advancing native agent capabilities.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15876v2</guid></item><item><title>[cs updates on arXiv.org] Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model</title><link>https://arxiv.org/abs/2601.15892</link><description>arXiv:2601.15892v2 Announce Type: replace 
Abstract: Diffusion-based language models (DLLMs) offer non-sequential, block-wise generation and richer data reuse compared to autoregressive (AR) models, but existing code DLLMs still lag behind strong AR baselines under comparable budgets. We revisit this setting in a controlled study and introduce Stable-DiffCoder, a block diffusion code model that reuses the Seed-Coder architecture, data, and training pipeline. To enable efficient knowledge learning and stable training, we incorporate a block diffusion continual pretraining (CPT) stage enhanced by a tailored warmup and block-wise clipped noise schedule. Under the same data and architecture, Stable-DiffCoder overall outperforms its AR counterpart on a broad suite of code benchmarks. Moreover, relying only on the CPT and supervised fine-tuning stages, Stable-DiffCoder achieves stronger performance than a wide range of \~8B ARs and DLLMs, demonstrating that diffusion-based training can improve code modeling quality beyond AR training alone. Moreover, diffusion-based any-order modeling improves structured code modeling for editing and reasoning, and through data augmentation, benefits low-resource coding languages.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15892v2</guid></item><item><title>[cs updates on arXiv.org] Collision-Free Humanoid Traversal in Cluttered Indoor Scenes</title><link>https://arxiv.org/abs/2601.16035</link><description>arXiv:2601.16035v2 Announce Type: replace 
Abstract: We study the problem of collision-free humanoid traversal in cluttered indoor scenes, such as hurdling over objects scattered on the floor, crouching under low-hanging obstacles, or squeezing through narrow passages. To achieve this goal, the humanoid needs to map its perception of surrounding obstacles with diverse spatial layouts and geometries to the corresponding traversal skills. However, the lack of an effective representation that captures humanoid-obstacle relationships during collision avoidance makes directly learning such mappings difficult. We therefore propose Humanoid Potential Field (HumanoidPF), which encodes these relationships as collision-free motion directions, significantly facilitating RL-based traversal skill learning. We also find that HumanoidPF exhibits a surprisingly negligible sim-to-real gap as a perceptual representation. To further enable generalizable traversal skills through diverse and challenging cluttered indoor scenes, we further propose a hybrid scene generation method, incorporating crops of realistic 3D indoor scenes and procedurally synthesized obstacles. We successfully transfer our policy to the real world and develop a teleoperation system where users could command the humanoid to traverse in cluttered indoor scenes with just a single click. Extensive experiments are conducted in both simulation and the real world to validate the effectiveness of our method. Demos and code can be found in our website: https://axian12138.github.io/CAT/.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16035v2</guid></item><item><title>[cs updates on arXiv.org] Characterizations of monadically dependent tree-ordered weakly sparse structures</title><link>https://arxiv.org/abs/2601.16039</link><description>arXiv:2601.16039v2 Announce Type: replace 
Abstract: A class of structures is monadically dependent if one cannot interpret all graphs in colored expansions from the class using a fixed first-order formula. A tree-ordered $\sigma$-structure is the expansion of a $\sigma$-structure with a tree-order. A tree-ordered $\sigma$-structure is weakly sparse if the Gaifman graph of its $\sigma$-reduct excludes some biclique (of a given fixed size) as a subgraph. Tree-ordered weakly sparse graphs are commonly used as tree-models (for example for classes with bounded shrubdepth, structurally bounded expansion, bounded cliquewidth, or bounded twin-width), motivating their study on their own. In this paper, we consider several constructions on tree-ordered structures, such as tree-ordered variants of the Gaifman graph and of the incidence graph, induced and non-induced tree-ordered minors, and generalized fundamental graphs. We provide characterizations of monadically dependent classes of tree-ordered weakly sparse $\sigma$-structures based on each of these constructions, some of them establishing unexpected bridges with sparsity theory. As an application, we prove that a class of tree-ordered weakly sparse structures is monadically dependent if and only if its sparsification is nowhere-dense. Moreover, the sparsification transduction translates boundedness of clique-width and linear clique-width into boundedness of tree-width and path-width. We also prove that first-order model checking is not fixed parameter tractable on independent hereditary classes of tree-ordered weakly sparse graphs (assuming $\mathsf{AW}[*]\neq \mathsf{FPT}$) and give what we believe is the first model-theoretical characterization of classes of graphs excluding a minor, thus opening a new perspective of structural graph theory.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16039v2</guid></item><item><title>[cs updates on arXiv.org] Masked Modeling for Human Motion Recovery Under Occlusions</title><link>https://arxiv.org/abs/2601.16079</link><description>arXiv:2601.16079v2 Announce Type: replace 
Abstract: Human motion reconstruction from monocular videos is a fundamental challenge in computer vision, with broad applications in AR/VR, robotics, and digital content creation, but remains challenging under frequent occlusions in real-world settings. Existing regression-based methods are efficient but fragile to missing observations, while optimization- and diffusion-based approaches improve robustness at the cost of slow inference speed and heavy preprocessing steps. To address these limitations, we leverage recent advances in generative masked modeling and present MoRo: Masked Modeling for human motion Recovery under Occlusions. MoRo is an occlusion-robust, end-to-end generative framework that formulates motion reconstruction as a video-conditioned task, and efficiently recover human motion in a consistent global coordinate system from RGB videos. By masked modeling, MoRo naturally handles occlusions while enabling efficient, end-to-end inference. To overcome the scarcity of paired video-motion data, we design a cross-modality learning scheme that learns multi-modal priors from a set of heterogeneous datasets: (i) a trajectory-aware motion prior trained on MoCap datasets, (ii) an image-conditioned pose prior trained on image-pose datasets, capturing diverse per-frame poses, and (iii) a video-conditioned masked transformer that fuses motion and pose priors, finetuned on video-motion datasets to integrate visual cues with motion dynamics for robust inference. Extensive experiments on EgoBody and RICH demonstrate that MoRo substantially outperforms state-of-the-art methods in accuracy and motion realism under occlusions, while performing on-par in non-occluded scenarios. MoRo achieves real-time inference at 70 FPS on a single H200 GPU.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16079v2</guid></item><item><title>[cs updates on arXiv.org] Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging</title><link>https://arxiv.org/abs/2601.16127</link><description>arXiv:2601.16127v2 Announce Type: replace 
Abstract: Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50\%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60\%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16127v2</guid></item><item><title>[cs updates on arXiv.org] Ultrafast topological data analysis reveals pandemic-scale dynamics of convergent evolution</title><link>https://arxiv.org/abs/2106.07292</link><description>arXiv:2106.07292v4 Announce Type: replace-cross 
Abstract: Genome variants which re-occur independently across evolutionary lineages are key molecular signatures of adaptation. Inferring the dynamics of such genetic changes from pandemic-scale genomic datasets is now possible, which opens up unprecedented insight into evolutionary processes. However, existing approaches depend on the construction of accurate phylogenetic trees, which remains challenging at scale. Here we present EVOtRec, an organism-agnostic, fast and scalable Topological Data Analysis approach that enables the inference of convergently evolving genomic variants over time directly from topological patterns in the dataset, without requiring the construction of a phylogenetic tree. Using data from both simulations and published experiments, we show that EVOtRec can robustly identify variants under positive selection and performs orders of magnitude faster than state-of-the-art phylogeny-based approaches, with comparable results. We apply EVOtRec to three large viral genome datasets: SARS-CoV-2, influenza virus A subtype H5N1 and HIV-1. We identify key convergent genome variants and demonstrate how EVOtRec facilitates the real-time tracking of high fitness variants in large datasets with millions of genomes, including effects modulated by varying genomic backgrounds. We envision our Topological Data Analysis approach as a new framework for efficient comparative genomics.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2106.07292v4</guid></item><item><title>[cs updates on arXiv.org] Frank-Wolfe algorithm for DC optimization problem</title><link>https://arxiv.org/abs/2308.16444</link><description>arXiv:2308.16444v3 Announce Type: replace-cross 
Abstract: In the present paper, we formulate two versions of Frank--Wolfe algorithm or conditional gradient method to solve the DC optimization problem with an adaptive step size. The DC objective function consists of two components; the first is thought to be differentiable with a continuous Lipschitz gradient, while the second is only thought to be convex. The second version is based on the first and employs finite differences to approximate the gradient of the first component of the objective function. In contrast to past formulations that used the curvature/Lipschitz-type constant of the objective function, the step size computed does not require any constant associated with the components. For the first version, we established that the algorithm is well-defined of the algorithm and that every limit point of the generated sequence is a stationary point of the problem. We also introduce the class of weak-star-convex functions and show that, despite the fact that these functions are non-convex in general, the rate of convergence of the first version of the algorithm to minimize these functions is ${\cal O}(1/k)$. The finite difference used to approximate the gradient in the second version of the Frank-Wolfe algorithm is computed with the step-size adaptively updated using two previous iterations. Unlike previous applications of finite difference in the Frank-Wolfe algorithm, which provided approximate gradients with absolute error, the one used here provides us with a relative error, simplifying the algorithm analysis. In this case, we show that all limit points of the generated sequence for the second version of the Frank-Wolfe algorithm are stationary points for the problem under consideration, and we establish that the rate of convergence for the duality gap is ${\cal O}(1/\sqrt{k})$.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2308.16444v3</guid></item><item><title>[cs updates on arXiv.org] Quantum generalizations of Glauber and Metropolis dynamics</title><link>https://arxiv.org/abs/2405.20322</link><description>arXiv:2405.20322v2 Announce Type: replace-cross 
Abstract: Classical Markov Chain Monte Carlo methods have been essential for simulating statistical physical systems and have proven well applicable to other systems with many degrees of freedom. Motivated by the statistical physics origins, Chen, Kastoryano, and Gily\'en [CKG23] proposed a continuous-time quantum thermodynamic analogue to Glauber dynamics that is (i) exactly detailed balanced, (ii) efficiently implementable, and (iii) quasi-local for geometrically local systems. Physically, their construction resembles the dissipative dynamics arising from weak system-bath interaction. In this work, we give an efficiently implementable discrete-time counterpart to any continuous-time quantum Gibbs sampler. Our construction preserves the desirable features (i)-(iii) while does not decrease the spectral gap. Also, we give an alternative highly coherent quantum generalization of detailed balanced dynamics that resembles another physically derived master equation, and propose a smooth interpolation between this and earlier constructions. Moreover, we show how to make earlier Metropolis-style Gibbs samplers (which estimate energies both before and after jumps) exactly detailed balanced. We study generic properties of all constructions, including the uniqueness of the fixed point, the (quasi-)locality of the resulting operators. Finally, we prove that the spectral gap of our new highly coherent Gibbs sampler is constant at high temperatures, thereby it mixes fast. We hope that our systematic approach to quantum Glauber and Metropolis dynamics will lead to widespread applications in various domains.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2405.20322v2</guid></item><item><title>[cs updates on arXiv.org] Bayesian Joint Additive Factor Models for Multiview Learning</title><link>https://arxiv.org/abs/2406.00778</link><description>arXiv:2406.00778v4 Announce Type: replace-cross 
Abstract: It is increasingly common to collect data of multiple different types on the same set of samples. Our focus is on studying relationships between such multiview features and responses. A motivating application arises in the context of precision medicine where multi-omics data are collected to correlate with clinical outcomes. It is of interest to infer dependence within and across views while combining multimodal information to improve the prediction of outcomes. The signal-to-noise ratio can vary substantially across views, motivating more nuanced statistical tools beyond standard late and early fusion. This challenge comes with the need to preserve interpretability, select features, and obtain accurate uncertainty quantification. To address these challenges, we introduce two complementary factor regression models. A baseline Joint Factor Regression (\textsc{jfr}) captures combined variation across views via a single factor set, and a more nuanced Joint Additive FActor Regression (\textsc{jafar}) that decomposes variation into shared and view-specific components. For \textsc{jfr}, we use independent cumulative shrinkage process (\textsc{i-cusp}) priors, while for \textsc{jafar} we develop a dependent version (\textsc{d-cusp}) designed to ensure identifiability of the components. We develop Gibbs samplers that exploit the model structure and accommodate flexible feature and outcome distributions. Prediction of time-to-labor onset from immunome, metabolome, and proteome data illustrates performance gains against state-of-the-art competitors. Our open-source software (\texttt{R} package) is available at https://github.com/niccoloanceschi/jafar.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2406.00778v4</guid></item><item><title>[cs updates on arXiv.org] Efficient Approximate Degenerate Ordered Statistics Decoding for Quantum Codes via Reliable Subset Reduction</title><link>https://arxiv.org/abs/2412.21118</link><description>arXiv:2412.21118v3 Announce Type: replace-cross 
Abstract: Efficient and scalable decoding of quantum codes is essential for high-performance quantum error correction. In this work, we introduce Reliable Subset Reduction (RSR), a reliability-driven preprocessing framework that leverages belief propagation (BP) statistics to identify and remove highly reliable qubits, substantially reducing the effective problem size. Additionally, we identify a degeneracy condition that allows high-order OSD to be simplified to order-0 OSD. By integrating these techniques, we present an ADOSD algorithm that significantly improves OSD efficiency. Our BP+RSR+ADOSD framework extends naturally to circuit-level noise and can handle large-scale codes with more than $10^4$ error variables. Through extensive simulations, we demonstrate improved performance over MWPM and Localized Statistics Decoding for a variety of CSS and non-CSS codes under the code-capacity noise model, and for rotated surface codes under realistic circuit-level noise. At low physical error rates, RSR reduces the effective problem size to less than 5\%, enabling higher-order OSD with accelerated runtime. These results highlight the practical efficiency and broad applicability of the BP+ADOSD framework for both theoretical and realistic quantum error correction scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.21118v3</guid></item><item><title>[cs updates on arXiv.org] Local minima of the empirical risk in high dimension: General theorems and convex examples</title><link>https://arxiv.org/abs/2502.01953</link><description>arXiv:2502.01953v3 Announce Type: replace-cross 
Abstract: We consider a general model for high-dimensional empirical risk minimization whereby the data $\mathbf{x}_i$ are $d$-dimensional Gaussian vectors, the model is parametrized by $\mathbf{\Theta}\in\mathbb{R}^{d\times k}$, and the loss depends on the data via the projection $\mathbf{\Theta}^\mathsf{T}\mathbf{x}_i$. This setting covers as special cases classical statistics methods (e.g. multinomial regression and other generalized linear models), but also two-layer fully connected neural networks with $k$ hidden neurons. We use the Kac-Rice formula from Gaussian process theory to derive a bound on the expected number of local minima of this empirical risk, under the proportional asymptotics in which $n,d\to\infty$, with $n\asymp d$. Via Markov's inequality, this bound allows to determine the positions of these minimizers (with exponential deviation bounds) and hence derive sharp asymptotics on the estimation and prediction error. As a special case, we apply our characterization to convex losses. We show that our approach is tight and allows to prove previously conjectured results. In addition, we characterize the spectrum of the Hessian at the minimizer. A companion paper applies our general result to non-convex examples.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.01953v3</guid></item><item><title>[cs updates on arXiv.org] Physics-Conditioned Diffusion Models for Lattice Gauge Theory</title><link>https://arxiv.org/abs/2502.05504</link><description>arXiv:2502.05504v2 Announce Type: replace-cross 
Abstract: We develop diffusion models for simulating lattice gauge theories, where stochastic quantization is explicitly incorporated as a physical condition for sampling. We demonstrate the applicability of this novel sampler to U(1) gauge theory in two spacetime dimensions and find that a model trained at a small inverse coupling constant can be extrapolated to larger inverse coupling regions without encountering the topological freezing problem. Additionally, the trained model can be employed to sample configurations on different lattice sizes without requiring further training. The exactness of the generated samples is ensured by incorporating Metropolis-adjusted Langevin dynamics into the generation process. Furthermore, we demonstrate that this approach enables more efficient sampling of topological quantities compared to traditional algorithms such as Hybrid Monte Carlo and Langevin simulations.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.05504v2</guid></item><item><title>[cs updates on arXiv.org] Entropic transfer operators for stochastic systems</title><link>https://arxiv.org/abs/2503.05308</link><description>arXiv:2503.05308v2 Announce Type: replace-cross 
Abstract: Dynamical systems can be analyzed via their Frobenius-Perron transfer operator and its estimation from data is an active field of research. Recently entropic transfer operators have been introduced to estimate the operator of deterministic systems. The approach is based on the regularizing properties of entropic optimal transport plans. In this article we generalize the method to stochastic and non-stationary systems and give a quantitative convergence analysis of the empirical operator as the available samples increase. We introduce a way to extend the operator's eigenfunctions to previously unseen samples, such that they can be efficiently included into a spectral embedding. The practicality and numerical scalability of the method are demonstrated on a real-world fluid dynamics experiment.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.05308v2</guid></item><item><title>[cs updates on arXiv.org] Towards contrast- and pathology-agnostic clinical fetal brain MRI segmentation using SynthSeg</title><link>https://arxiv.org/abs/2504.10244</link><description>arXiv:2504.10244v2 Announce Type: replace-cross 
Abstract: Magnetic resonance imaging (MRI) has played a crucial role in fetal neurodevelopmental research. Structural annotations of MR images are an important step for quantitative analysis of the developing human brain, with Deep Learning providing an automated alternative for this otherwise tedious manual process. However, segmentation performances of Convolutional Neural Networks often suffer from domain shift, where the network fails when applied to subjects that deviate from the distribution with which it is trained on. In this work, we aim to train networks capable of automatically segmenting fetal brain MRIs with a wide range of domain shifts pertaining to differences in subject physiology and acquisition environments, in particular shape-based differences commonly observed in pathological cases. We introduce a novel data-driven train-time sampling strategy that seeks to fully exploit the diversity of a given training dataset to enhance the domain generalizability of the trained networks. We adapted our sampler, together with other existing data augmentation techniques, to the SynthSeg framework, a generator that utilizes domain randomization to generate diverse training data. We ran thorough experimentations and ablation studies on a wide range of training/testing data to test the validity of the approaches. Our networks achieved notable improvements in the segmentation quality on testing subjects with intense anatomical abnormalities (p &lt; 1e-4), though at the cost of a slighter decrease in performance in cases with fewer abnormalities. Our work also lays the foundation for future works on creating and adapting data-driven sampling strategies for other training pipelines.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.10244v2</guid></item><item><title>[cs updates on arXiv.org] Addressing the Minor-Embedding Problem in Quantum Annealing and Evaluating State-of-the-Art Algorithm Performance</title><link>https://arxiv.org/abs/2504.13376</link><description>arXiv:2504.13376v4 Announce Type: replace-cross 
Abstract: This study addresses the minor-embedding problem, which involves mapping the variables of an Ising model onto a quantum annealing processor. The primary motivation stems from the observed performance disparity of quantum annealers when solving problems suited to the processor's architecture versus those with non-hardware-native topologies. Our research has two main objectives: i) to analyze the impact of embedding quality on the performance of D-Wave Systems quantum annealers, and ii) to evaluate the quality of the embeddings generated by Minorminer, the standard minor-embedding technique in the quantum annealing literature, provided by D-Wave. Regarding the first objective, our experiments reveal a clear correlation between the average chain length of embeddings and the relative errors of the solutions sampled. This underscores the critical influence of embedding quality on quantum annealing performance. For the second objective, we evaluate Minorminer's embedding capabilities, the quality and robustness of its embeddings, and its execution-time performance on Erd\"os-R\'enyi graphs. We also compare its performance with Clique Embedding, another algorithm developed by D-Wave, which is deterministic and designed to embed fully connected Ising models into quantum annealing processors, serving as a worst-case scenario. The results demonstrate that there is significant room for improvement for Minorminer, suggesting that more effective embedding strategies could lead to meaningful gains in quantum annealing performance.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.13376v4</guid></item><item><title>[cs updates on arXiv.org] Estimation of discrete distributions in relative entropy, and the deviations of the missing mass</title><link>https://arxiv.org/abs/2504.21787</link><description>arXiv:2504.21787v3 Announce Type: replace-cross 
Abstract: We study the problem of estimating a distribution over a finite alphabet from an i.i.d. sample, with accuracy measured in relative entropy (Kullback-Leibler divergence). While optimal bounds on the expected risk are known, high-probability guarantees remain less well-understood. First, we analyze the classical Laplace (add-one) estimator, obtaining matching upper and lower bounds on its performance and establishing its optimality among confidence-independent estimators. We then characterize the minimax-optimal high-probability risk and show that it is achieved by a simple confidence-dependent smoothing technique. Notably, the optimal non-asymptotic risk incurs an additional logarithmic factor compared to the ideal asymptotic rate. Next, motivated by regimes in which the alphabet size exceeds the sample size, we investigate methods that adapt to the sparsity of the underlying distribution. We introduce an estimator using data-dependent smoothing, for which we establish a high-probability risk bound depending on two effective sparsity parameters. As part of our analysis, we also derive a sharp high-probability upper bound on the missing mass.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.21787v3</guid></item><item><title>[cs updates on arXiv.org] Kernel Embeddings and the Separation of Measure Phenomenon</title><link>https://arxiv.org/abs/2505.04613</link><description>arXiv:2505.04613v3 Announce Type: replace-cross 
Abstract: We prove that kernel covariance embeddings lead to information-theoretically perfect separation of distinct continuous probability distributions. In statistical terms, we establish that testing for the \emph{equality} of two non-atomic (Borel) probability measures on a locally compact Polish space is \emph{equivalent} to testing for the \emph{singularity} between two centered Gaussian measures on a reproducing kernel Hilbert space. The corresponding Gaussians are defined via the notion of kernel covariance embedding of a probability measure, and the Hilbert space is that generated by the embedding kernel. Distinguishing singular Gaussians is structurally simpler from an information-theoretic perspective than non-parametric two-sample testing, particularly in complex or high-dimensional domains. This is because singular Gaussians are supported on essentially separate and affine subspaces. Our proof leverages the classical Feldman-H\'{a}jek dichotomy, and shows that even a small perturbation of a continuous distribution will be maximally magnified through its Gaussian embedding. This ``separation of measure phenomenon'' appears to be a blessing of infinite dimensionality, by means of embedding, with the potential to inform the design of efficient inference tools in considerable generality. The elicitation of this phenomenon also appears to crystallize, in a precise and simple mathematical statement, a core mechanism underpinning the empirical effectiveness of kernel methods.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.04613v3</guid></item><item><title>[cs updates on arXiv.org] Robustly optimal dynamics for active matter reservoir computing</title><link>https://arxiv.org/abs/2505.05420</link><description>arXiv:2505.05420v4 Announce Type: replace-cross 
Abstract: Information processing abilities of active matter are studied in the reservoir computing (RC) paradigm to infer the future state of a chaotic signal. We uncover an exceptional regime of agent dynamics that has been overlooked previously. It appears robustly optimal for performance under many conditions, thus providing valuable insights into computation with physical systems more generally. The key to forming effective mechanisms for information processing appears in the system's intrinsic relaxation abilities. These are probed without actually enforcing a specific inference goal. The dynamical regime that achieves optimal computation is located just below a critical damping threshold, involving a relaxation with multiple stages, and is readable at the single-particle level. At the many-body level, it yields substrates robustly optimal for RC across varying physical parameters and inference tasks. A system in this regime exhibits a strong diversity of dynamic mechanisms under highly fluctuating driving forces. Correlations of agent dynamics can express a tight relationship between the responding system and the fluctuating forces driving it. As this model is interpretable in physical terms, it facilitates re-framing inquiries regarding learning and unconventional computing with a fresh rationale for many-body physics out of equilibrium.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.05420v4</guid></item><item><title>[cs updates on arXiv.org] Machine Learning-Based Analysis of ECG and PCG Signals for Rheumatic Heart Disease Detection: A Scoping Review (2015-2025)</title><link>https://arxiv.org/abs/2505.18182</link><description>arXiv:2505.18182v3 Announce Type: replace-cross 
Abstract: AI-powered stethoscopes offer a promising alternative for screening rheumatic heart disease (RHD), particularly in regions with limited diagnostic infrastructure. Early detection is vital, yet echocardiography, the gold standard tool, remains largely inaccessible in low-resource settings due to cost and workforce constraints. This review systematically examines machine learning (ML) applications from 2015 to 2025 that analyze electrocardiogram (ECG) and phonocardiogram (PCG) data to support accessible, scalable screening of all RHD variants in relation to the World Heart Federation's "25 by 25" goal to reduce RHD mortality. Using PRISMA-ScR guidelines, 37 peer-reviewed studies were selected from PubMed, IEEE Xplore, Scopus, and Embase. Convolutional neural networks (CNNs) dominate recent efforts, achieving a median accuracy of 97.75%, F1-score of 0.95, and AUROC of 0.89. However, challenges remain: 73% of studies used single-center datasets, 81.1% relied on private data, only 10.8% were externally validated, and none assessed cost-effectiveness. Although 45.9% originated from endemic regions, few addressed demographic diversity or implementation feasibility. These gaps underscore the disconnect between model performance and clinical readiness. Bridging this divide requires standardized benchmark datasets, prospective trials in endemic areas, and broader validation. If these issues are addressed, AI-augmented auscultation could transform cardiovascular diagnostics in underserved populations, thereby aiding early detection. This review also offers practical recommendations for building accessible ML-based RHD screening tools, aiming to close the diagnostic gap in low-resource settings where conventional auscultation may miss up to 90% of cases and echocardiography remains out of reach.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.18182v3</guid></item><item><title>[cs updates on arXiv.org] FlashMD: long-stride, universal prediction of molecular dynamics</title><link>https://arxiv.org/abs/2505.19350</link><description>arXiv:2505.19350v3 Announce Type: replace-cross 
Abstract: Molecular dynamics (MD) provides insights into atomic-scale processes by integrating over time the equations that describe the motion of atoms under the action of interatomic forces. Machine learning models have substantially accelerated MD by providing inexpensive predictions of the forces, but they remain constrained to minuscule time integration steps, which are required by the fast time scale of atomic motion. In this work, we propose FlashMD, a method to predict the evolution of positions and momenta over strides that are between one and two orders of magnitude longer than typical MD time steps. We incorporate considerations on the mathematical and physical properties of Hamiltonian dynamics in the architecture, generalize the approach to allow the simulation of any thermodynamic ensemble, and carefully assess the possible failure modes of such a long-stride MD approach. We validate FlashMD's accuracy in reproducing equilibrium and time-dependent properties, using both system-specific and general-purpose models, extending the ability of MD simulation to reach the long time scales needed to model microscopic processes of high scientific and technological relevance.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.19350v3</guid></item><item><title>[cs updates on arXiv.org] Beyond the LUMIR challenge: The pathway to foundational registration models</title><link>https://arxiv.org/abs/2505.24160</link><description>arXiv:2505.24160v2 Announce Type: replace-cross 
Abstract: Medical image challenges have played a transformative role in advancing the field, catalyzing innovation and establishing new performance benchmarks. Image registration, a foundational task in neuroimaging, has similarly advanced through the Learn2Reg initiative. Building on this, we introduce the Large-scale Unsupervised Brain MRI Image Registration (LUMIR) challenge, a next-generation benchmark for unsupervised brain MRI registration. Previous challenges relied upon anatomical label maps, however LUMIR provides 4,014 unlabeled T1-weighted MRIs for training, encouraging biologically plausible deformation modeling through self-supervision. Evaluation includes 590 in-domain test subjects and extensive zero-shot tasks across disease populations, imaging protocols, and species. Deep learning methods consistently achieved state-of-the-art performance and produced anatomically plausible, diffeomorphic deformation fields. They outperformed several leading optimization-based methods and remained robust to most domain shifts. These findings highlight the growing maturity of deep learning in neuroimaging registration and its potential to serve as a foundation model for general-purpose medical image registration.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.24160v2</guid></item><item><title>[cs updates on arXiv.org] Optimizing Sparse SYK</title><link>https://arxiv.org/abs/2506.09037</link><description>arXiv:2506.09037v2 Announce Type: replace-cross 
Abstract: Finding the ground state of strongly-interacting fermionic systems is often the prerequisite for fully understanding both quantum chemistry and condensed matter systems. The Sachdev--Ye--Kitaev (SYK) model is a representative example of such a system; it is particularly interesting not only due to the existence of efficient quantum algorithms preparing approximations to the ground state such as Hastings--O'Donnell (STOC 2022), but also known no-go results for many classical ansatzes in preparing low-energy states. However, this quantum-classical separation is known to \emph{not} persist when the SYK model is sufficiently sparsified, i.e., when terms in the model are discarded with probability $1-p$, where $p=\Theta(1/n^3)$ and $n$ is the system size. This raises the question of how robust the quantum and classical complexities of the SYK model are to sparsification.
  In this work we initiate the study of the sparse SYK model where $p \in [\Theta(1/n^3),1]$ and show there indeed exists a certain robustness of sparsification. We prove that with high probability, Gaussian states achieve only a $\Theta(1/\sqrt{n})$-factor approximation to the true ground state energy of sparse SYK for all $p\geq\Omega(\log n/n^2)$, and that Gaussian states cannot achieve constant-factor approximations unless $p \leq O(\log^2 n/n^3)$. Additionally, we prove that the quantum algorithm of Hastings--O'Donnell still achieves a constant-factor approximation to the ground state energy when $p\geq\Omega(\log n/n)$. Combined, these show a provable separation between classical algorithms outputting Gaussian states and efficient quantum algorithms for the goal of finding approximate sparse SYK ground states whenever $p \geq \Omega(\log n/n)$, extending the analogous $p=1$ result of Hastings--O'Donnell.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.09037v2</guid></item><item><title>[cs updates on arXiv.org] State Space Models Naturally Produce Time Cell and Oscillatory Behaviors and Scale to Abstract Cognitive Functions</title><link>https://arxiv.org/abs/2507.13638</link><description>arXiv:2507.13638v2 Announce Type: replace-cross 
Abstract: A grand challenge in modern neuroscience is to bridge the gap between the detailed mapping of microscale neural circuits and mechanistic understanding of cognitive functions. While extensive knowledge exists about neuronal connectivity and biophysics, how these low-level phenomena eventually produce abstract behaviors remains largely unresolved. Here, we propose that a framework based on State Space Models, an emerging class of deep learning architectures, can help bridge this gap. We suggest that the differential equations governing elements in a State Space Model are conceptually consistent with the dynamics of biophysical processes, while the model offers a scalable framework to build on the dynamics to produce emergent behaviors observed in experimental neuroscience. We test this framework by training a model employing a diagonal state transition matrix on temporal discrimination tasks with reinforcement learning. Our results suggest that neural behaviors such as time cells naturally emerge from two fundamental principles: optimal pre-configuration and rotational dynamics. These features are shown mathematically to optimize history compression, and naturally generate structured temporal dynamics even prior to training, mirroring recent findings in biological circuits. We show that learning acts primarily as a selection mechanism that fine-tunes these pre-configured oscillatory modes, rather than constructing temporal codes de novo. The model can be readily scaled to abstract cognitive functions such as event counting, supporting the use of State Space Models as a computationally tractable framework for understanding neural activities.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.13638v2</guid></item><item><title>[cs updates on arXiv.org] Lightweight Implicit Neural Network for Binaural Audio Synthesis</title><link>https://arxiv.org/abs/2509.14069</link><description>arXiv:2509.14069v2 Announce Type: replace-cross 
Abstract: High-fidelity binaural audio synthesis is crucial for immersive listening, but existing methods require extensive computational resources, limiting their edge-device application. To address this, we propose the Lightweight Implicit Neural Network (Lite-INN), a novel two-stage framework. Lite-INN first generates initial estimates using a time-domain warping, which is then refined by an Implicit Binaural Corrector (IBC) module. IBC is an implicit neural network that predicts amplitude and phase corrections directly, resulting in a highly compact model architecture. Experimental results show that Lite-INN achieves statistically comparable perceptual quality to the best-performing baseline model while significantly improving computational efficiency. Compared to the previous state-of-the-art method (NFS), Lite-INN achieves a 72.7% reduction in parameters and requires significantly fewer compute operations (MACs). This demonstrates that our approach effectively addresses the trade-off between synthesis quality and computational efficiency, providing a new solution for high-fidelity edge-device spatial audio applications.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.14069v2</guid></item><item><title>[cs updates on arXiv.org] Frame-Stacked Local Transformers For Efficient Multi-Codebook Speech Generation</title><link>https://arxiv.org/abs/2509.19592</link><description>arXiv:2509.19592v2 Announce Type: replace-cross 
Abstract: Speech generation models based on large language models (LLMs) typically operate on discrete acoustic codes, which differ fundamentally from text tokens due to their multicodebook structure. At each timestep, models must predict N codebook entries jointly, introducing dependencies that challenge simple parallel prediction approaches. Parallel prediction assumes independence among codebooks, yielding efficient decoding but often at the cost of reduced fidelity. To address this, hierarchical strategies employ a local transformer (LT) to refine predictions and capture intra-timestep dependencies. In this work, we systematically investigate two LT architectures: an autoregressive transformer that generates codebooks sequentially, and a MaskGIT-based transformer that performs iterative masked prediction. Both designs further enable frame stacking, where the primary transformer predicts multiple frames jointly, and the LT decodes their codebooks, offering improvements in speed without compromising perceptual quality. Through extensive analysis, we characterize the tradeoffs between parallel and iterative sampling strategies across different throughput and quality regimes. Finally, we propose practical guidelines for selecting decoding strategies based on deployment priorities such as computational efficiency and synthesis fidelity.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.19592v2</guid></item><item><title>[cs updates on arXiv.org] Enhanced Generative Machine Listener</title><link>https://arxiv.org/abs/2509.21463</link><description>arXiv:2509.21463v2 Announce Type: replace-cross 
Abstract: We present GMLv2, a reference-based model designed for the prediction of subjective audio quality as measured by MUSHRA scores. GMLv2 introduces a Beta distribution-based loss to model the listener ratings and incorporates additional neural audio coding (NAC) subjective datasets to extend its generalization and applicability. Extensive evaluations on diverse testset demonstrate that proposed GMLv2 consistently outperforms widely used metrics, such as PEAQ and ViSQOL, both in terms of correlation with subjective scores and in reliably predicting these scores across diverse content types and codec configurations. Consequently, GMLv2 offers a scalable and automated framework for perceptual audio quality evaluation, poised to accelerate research and development in modern audio coding technologies.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.21463v2</guid></item><item><title>[cs updates on arXiv.org] Speaker Anonymisation for Speech-based Suicide Risk Detection</title><link>https://arxiv.org/abs/2509.22148</link><description>arXiv:2509.22148v2 Announce Type: replace-cross 
Abstract: Adolescent suicide is a critical global health issue, and speech provides a cost-effective modality for automatic suicide risk detection. Given the vulnerable population, protecting speaker identity is particularly important, as speech itself can reveal personally identifiable information if the data is leaked or maliciously exploited. This work presents the first systematic study of speaker anonymisation for speech-based suicide risk detection. A broad range of anonymisation methods are investigated, including techniques based on traditional signal processing, neural voice conversion, and speech synthesis. A comprehensive evaluation framework is built to assess the trade-off between protecting speaker identity and preserving information essential for suicide risk detection. Results show that combining anonymisation methods that retain complementary information yields detection performance comparable to that of original speech, while achieving protection of speaker identity for vulnerable populations.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.22148v2</guid></item><item><title>[cs updates on arXiv.org] StarEmbed: Benchmarking Time Series Foundation Models on Astronomical Observations of Variable Stars</title><link>https://arxiv.org/abs/2510.06200</link><description>arXiv:2510.06200v2 Announce Type: replace-cross 
Abstract: Time series foundation models (TSFMs) are increasingly being adopted as highly-capable general-purpose time series representation learners. Although their training corpora are vast, they exclude astronomical time series data. Observations of stars produce peta-scale time series with unique challenges including irregular sampling and heteroskedasticity. We introduce StarEmbed, the first public benchmark for rigorous and standardized evaluation of state-of-the-art TSFMs on stellar time series observations (``light curves''). We benchmark on three scientifically-motivated downstream tasks: unsupervised clustering, supervised classification, and out-of-distribution source detection. StarEmbed integrates a catalog of expert-vetted labels with multi-variate light curves from the Zwicky Transient Facility, yielding ~40k hand-labeled light curves spread across seven astrophysical classes. We evaluate the zero-shot representation capabilities of three TSFMs (MOIRAI, Chronos, Chronos-Bolt) and a domain-specific transformer (Astromer) against handcrafted feature extraction, the long-standing baseline in the astrophysics literature. Our results demonstrate that these TSFMs, especially the Chronos models, which are trained on data completely unlike the astronomical observations, can outperform established astrophysics-specific baselines in some tasks and effectively generalize to entirely new data. In particular, TSFMs deliver state-of-the-art performance on our out-of-distribution source detection benchmark. With the first benchmark of TSFMs on astronomical time series data, we test the limits of their generalization and motivate a paradigm shift in time-domain astronomy from using task-specific, fully supervised pipelines toward adopting generic foundation model representations for the analysis of peta-scale datasets from forthcoming observatories.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.06200v2</guid></item><item><title>[cs updates on arXiv.org] Kernel-Based Nonparametric Tests For Shape Constraints</title><link>https://arxiv.org/abs/2510.16745</link><description>arXiv:2510.16745v3 Announce Type: replace-cross 
Abstract: We propose a kernel-based nonparametric framework for mean-variance optimization that enables inference on economically motivated shape constraints in finance, including positivity, monotonicity, and convexity. Many central hypotheses in financial econometrics are naturally expressed as shape relations on latent functions (e.g., term premia, CAPM relations, and the pricing kernel), yet enforcing such constraints during estimation can mask economically meaningful violations; our approach therefore separates learning from validation by first estimating an unconstrained solution and then testing shape properties. We establish statistical properties of the regularized sample estimator and derive rigorous guarantees, including asymptotic consistency, a functional central limit theorem, and a finite-sample deviation bound achieving the Monte Carlo rate up to a regularization term. Building on these results, we construct a joint Wald-type statistic to test shape constraints on finite grids. An efficient algorithm based on a pivoted Cholesky factorization yields scalability to large datasets. Numerical studies, including an options-based asset-pricing application, illustrate the usefulness of the proposed method for evaluating monotonicity and convexity restrictions.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.16745v3</guid></item><item><title>[cs updates on arXiv.org] Practical hybrid decoding scheme for parity-encoded spin systems</title><link>https://arxiv.org/abs/2510.26189</link><description>arXiv:2510.26189v4 Announce Type: replace-cross 
Abstract: We propose a practical hybrid decoding scheme for the parity-encoding architecture. This architecture was first introduced by N. Sourlas as a computational technique for tackling hard optimization problems, especially those modeled by spin systems such as the Ising model and spin glasses, and reinvented by W. Lechner, P. Hauke, and P. Zoller to develop quantum annealing devices. We study the specific model, called the SLHZ model, aiming to achieve a near-term quantum annealing device implemented solely through geometrically local spin interactions. Taking account of the close connection between the SLHZ model and a classical low-density-parity-check code, two approaches can be chosen for the decoding: (1) finding the ground state of a spin Hamiltonian derived from the SLHZ model, which can be achieved via stochastic decoders such as a quantum annealer or a classical Monte Carlo sampler; (2) using deterministic decoding techniques for the classical LDPC code, such as belief propagation and bit-flip decoder. The proposed hybrid approach combines the two approaches by applying bit-flip decoding to the readout of the stochastic decoder based on the SLHZ model. We present simulations demonstrating that this approach can reveal the latent potential of the SLHZ model, realizing soft-annealing concept proposed by Sourlas.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.26189v4</guid></item><item><title>[cs updates on arXiv.org] SAMRI: Segment Anything Model for MRI</title><link>https://arxiv.org/abs/2510.26635</link><description>arXiv:2510.26635v2 Announce Type: replace-cross 
Abstract: Accurate magnetic resonance imaging (MRI) segmentation is crucial for clinical decision-making, but remains labor-intensive when performed manually. Convolutional neural network (CNN) based methods can be accurate and efficient but often generalize poorly to MRI variable contrast, intensity inhomogeneity, and sequences. Although the transformer-based Segment Anything Model (SAM) has demonstrated remarkable generalizability in natural images, existing adaptations often treat MRI as another imaging modality, overlooking these modality-specific challenges. We present SAMRI, an MRI-specialized SAM trained and validated on 1.1 million labeled MR slices spanning whole-body organs and pathologies. We demonstrate that SAM can be effectively adapted to MRI by fine-tuning its mask decoder using a two-stage strategy, reducing training time by 94 percent and trainable parameters by 96 percent compared to full-model retraining. Across diverse MRI segmentation tasks, SAMRI achieves a mean Dice of 0.87, delivering state-of-the-art accuracy across anatomical regions and robust generalization on unseen structures, particularly small clinically important structures. In addition, we provide a complete training-to-inference pipeline and a user-friendly local graphical interface that enables interactive application of pretrained SAMRI models on standard machines, facilitating practical deployment for real-world MRI segmentation.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.26635v2</guid></item><item><title>[cs updates on arXiv.org] On the relationship between MESP and 0/1 D-Opt and their upper bounds</title><link>https://arxiv.org/abs/2511.04350</link><description>arXiv:2511.04350v2 Announce Type: replace-cross 
Abstract: We establish strong connections between two fundamental nonlinear 0/1 optimization problems coming from the area of experimental design, namely maximum entropy sampling and 0/1 D-Optimality. The connections are based on maps between instances, and we analyze the behavior of these maps. Using these maps, we transport basic upper-bounding methods between these two problems, and we are able to establish new domination results and other inequalities relating various basic upper bounds. Further, we establish results relating how different branch-and-bound schemes based on these maps compare. Additionally, we observe some surprising numerical results, where bounding methods that did not seem promising in their direct application to real-data MESP instances, are now useful for MESP instances that come from 0/1 D-Optimality.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.04350v2</guid></item><item><title>[cs updates on arXiv.org] Computational TIRF enables optical sectioning beyond the evanescent field for widefield fluorescence microscopy</title><link>https://arxiv.org/abs/2511.06853</link><description>arXiv:2511.06853v2 Announce Type: replace-cross 
Abstract: The resolving ability of widefield fluorescence microscopy is fundamentally limited by out-of-focus background owing to its low axial resolution, particularly for densely labeled biological samples. Although total internal reflection fluorescence (TIRF) microscopy provides strong near-surface sectioning, they are intrinsically restricted to shallow imaging depths. Here we present computational TIRF (cTIRF), a deep learning-based imaging modality that generates TIRF-like sectioned images directly from conventional widefield epifluorescence measurements without any optical modification. By integrating a physics-informed forward model into network training, cTIRF achieves effective background suppression and axial resolution enhancement while maintaining consistency with the measured widefield data. We demonstrate that cTIRF recovers near-surface structures with performance comparable to experimental TIRF, and further enables both single-frame and volumetric sectioned reconstruction in densely labeled samples where conventional TIRF fails. This work establishes cTIRF as a practical and deployable alternative to hardware-based optical sectioning in fluorescence microscopy, enabled by rapid adaptation to new imaging systems with minimal calibration data.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.06853v2</guid></item><item><title>[cs updates on arXiv.org] Reinforcement Learning for Charging Optimization of Inhomogeneous Dicke Quantum Batteries</title><link>https://arxiv.org/abs/2511.12176</link><description>arXiv:2511.12176v2 Announce Type: replace-cross 
Abstract: Charging optimization is a key challenge to the implementation of quantum batteries, particularly under inhomogeneity and partial observability. This paper employs reinforcement learning to optimize piecewise-constant charging policies for an inhomogeneous Dicke battery. We systematically compare policies across four observability regimes, from full-state access to experimentally accessible observables (energies of individual two-level systems (TLSs), first-order averages, and second-order correlations). Simulation results demonstrate that full observability yields near-optimal ergotropy with low variability, while under partial observability, access to only single-TLS energies or energies plus first-order averages lags behind the fully observed baseline. However, augmenting partial observations with second-order correlations recovers most of the gap, reaching 94%-98% of the full-state baseline. The learned schedules are nonmyopic, trading temporary plateaus or declines for superior terminal outcomes. These findings highlight a practical route to effective fast-charging protocols under realistic information constraints.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.12176v2</guid></item><item><title>[cs updates on arXiv.org] FRQI Pairs method for image classification using Quantum Recurrent Neural Network</title><link>https://arxiv.org/abs/2512.11499</link><description>arXiv:2512.11499v2 Announce Type: replace-cross 
Abstract: This study aims to introduce the FRQI Pairs method to a wider audience, a novel approach to image classification using Quantum Recurrent Neural Networks (QRNN) with Flexible Representation for Quantum Images (FRQI). The study highlights an innovative approach to use quantum encoded data for an image classification task, suggesting that such quantum-based approaches could significantly reduce the complexity of quantum algorithms. Comparison of the FRQI Pairs method with contemporary techniques underscores the promise of integrating quantum computing principles with neural network architectures for the development of quantum machine learning.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.11499v2</guid></item><item><title>[cs updates on arXiv.org] Variance-Reduced Diffusion Sampling via Target Score Identity</title><link>https://arxiv.org/abs/2601.01594</link><description>arXiv:2601.01594v3 Announce Type: replace-cross 
Abstract: We study variance reduction for score estimation and diffusion-based sampling in settings where the clean (target) score is available or can be approximated. Starting from the Target Score Identity (TSI), which expresses the noisy marginal score as a conditional expectation of the target score under the forward diffusion, we develop: (i) a plug-and-play nonparametric self-normalized importance sampling estimator compatible with standard reverse-time solvers, (ii) a variance-minimizing \emph{state- and time-dependent} blending rule between Tweedie-type and TSI estimators together with an anti-correlation analysis, (iii) a data-only extension based on locally fitted proxy scores, and (iv) a likelihood-tilting extension to Bayesian inverse problems. We also propose a \emph{Critic--Gate} distillation scheme that amortizes the state-dependent blending coefficient into a neural gate. Experiments on synthetic targets and PDE-governed inverse problems demonstrate improved sample quality for a fixed simulation budget.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.01594v3</guid></item><item><title>[cs updates on arXiv.org] Time-Optimal Switching Surfaces for Triple Integrator under Full Box Constraints</title><link>https://arxiv.org/abs/2601.16003</link><description>arXiv:2601.16003v2 Announce Type: replace-cross 
Abstract: Time-optimal control for triple integrator under full box constraints is a fundamental problem in the field of optimal control, which has been widely applied in the industry. However, scenarios involving asymmetric constraints, non-stationary boundary conditions, and active position constraints pose significant challenges. This paper provides a complete characterization of time-optimal switching surfaces for the problem, leading to novel insights into the geometric structure of the optimal control. The active condition of position constraints is derived, which is absent from the literature. An efficient algorithm is proposed, capable of planning time-optimal trajectories under asymmetric full constraints and arbitrary boundary states, with a 100% success rate. Computational time for each trajectory is within approximately 10$\mu$s, achieving a 5-order-of-magnitude reduction compared to optimization-based baselines.</description><author>cs updates on arXiv.org</author><pubDate>Mon, 26 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16003v2</guid></item><item><title>[cs updates on arXiv.org] Agentic Persona Control and Task State Tracking for Realistic User Simulation in Interactive Scenarios</title><link>https://arxiv.org/abs/2601.15290</link><description>arXiv:2601.15290v1 Announce Type: new 
Abstract: Testing conversational AI systems at scale across diverse domains necessitates realistic and diverse user interactions capturing a wide array of behavioral patterns. We present a novel multi-agent framework for realistic, explainable human user simulation in interactive scenarios, using persona control and task state tracking to mirror human cognitive processes during goal-oriented conversations. Our system employs three specialized AI agents: (1) a User Agent to orchestrate the overall interaction, (2) a State Tracking Agent to maintain structured task state, and (3) a Message Attributes Generation Agent that controls conversational attributes based on task progress and assigned persona. To validate our approach, we implement and evaluate the framework for guest ordering at a restaurant with scenarios rich in task complexity, behavioral diversity, and conversational ambiguity. Through systematic ablations, we evaluate the contributory efficacy of each agentic component to overall simulation quality in terms of persona adherence, task completion accuracy, explainability, and realism. Our experiments demonstrate that the complete multi-agent system achieves superior simulation quality compared to single-LLM baselines, with significant gains across all evaluation metrics. This framework establishes a powerful environment for orchestrating agents to simulate human users with cognitive plausibility, decomposing the simulation into specialized sub-agents that reflect distinct aspects of human thought processes applicable across interactive domains.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15290v1</guid></item><item><title>[cs updates on arXiv.org] Public transport challenges and technology-assisted accessibility for visually impaired elderly residents in urban environments</title><link>https://arxiv.org/abs/2601.15291</link><description>arXiv:2601.15291v1 Announce Type: new 
Abstract: Independent navigation is a core aspect of maintaining social participation and individual health for vulnerable populations. While historic cities such as Edinburgh, as the capital of Scotland, often feature well-established public transport systems, urban accessibility challenges remain and are exacerbated by a complex landscape, especially for groups with multiple vulnerabilities such as the blind elderly. With limited research examining how real-time data feeds and developments in artificial intelligence can enhance navigation aids, we address this gap through a mixed-methods approach. Our work combines statistical and machine learning techniques, with a focus on spatial analysis to investigate network coverage, service patterns, and density through live Transport for Edinburgh data, with a qualitative thematic analysis of semi-structured interviews with the mentioned target group. The results demonstrate the highly centralised nature of the city's transport system, the significance of memory-based navigation, and the lack of travel information in usable formats. We also find that participants already use navigation technology to varying degrees and express a willingness to adopt artificial intelligence. Our analysis highlights the importance of dynamic tools in terms of sensory and cognitive needs to meaningfully improve independent travel.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15291v1</guid></item><item><title>[cs updates on arXiv.org] A Mobile Application Front-End for Presenting Explainable AI Results in Diabetes Risk Estimation</title><link>https://arxiv.org/abs/2601.15292</link><description>arXiv:2601.15292v1 Announce Type: new 
Abstract: Diabetes is a significant and continuously rising health challenge in Indonesia. Although many artificial intelligence (AI)-based health applications have been developed for early detection, most function as "black boxes," lacking transparency in their predictions. Explainable AI (XAI) methods offer a solution, yet their technical outputs are often incomprehensible to non-expert users. This research aims to develop a mobile application front-end that presents XAI-driven diabetes risk analysis in an intuitive, understandable format. Development followed the waterfall methodology, comprising requirements analysis, interface design, implementation, and evaluation. Based on user preference surveys, the application adopts two primary visualization types - bar charts and pie charts - to convey the contribution of each risk factor. These are complemented by personalized textual narratives generated via integration with GPT-4o. The application was developed natively for Android using Kotlin and Jetpack Compose. The resulting prototype interprets SHAP (SHapley Additive exPlanations), a key XAI approach, into accessible graphical visualizations and narratives. Evaluation through user comprehension testing (Likert scale and interviews) and technical functionality testing confirmed the research objectives were met. The combination of visualization and textual narrative effectively enhanced user understanding (average score 4.31/5) and empowered preventive action, supported by a 100% technical testing success rate.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15292v1</guid></item><item><title>[cs updates on arXiv.org] Social Robotics for Disabled Students: An Empirical Investigation of Embodiment, Roles and Interaction</title><link>https://arxiv.org/abs/2601.15293</link><description>arXiv:2601.15293v1 Announce Type: new 
Abstract: Institutional and social barriers in higher education often prevent students with disabilities from effectively accessing support, including lengthy procedures, insufficient information, and high social-emotional demands. This study empirically explores how disabled students perceive robot-based support, comparing two interaction roles, one information based (signposting) and one disclosure based (sounding board), and two embodiment types (physical robot/disembodied voice agent). Participants assessed these systems across five dimensions: perceived understanding, social energy demands, information access/clarity, task difficulty, and data privacy concerns. The main findings of the study reveal that the physical robot was perceived as more understanding than the voice-only agent, with embodiment significantly shaping perceptions of sociability, animacy, and privacy. We also analyse differences between disability types. These results provide critical insights into the potential of social robots to mitigate accessibility barriers in higher education, while highlighting ethical, social and technical challenges.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15293v1</guid></item><item><title>[cs updates on arXiv.org] KnowTeX: Visualizing Mathematical Dependencies</title><link>https://arxiv.org/abs/2601.15294</link><description>arXiv:2601.15294v1 Announce Type: new 
Abstract: Mathematical knowledge exists in many forms, ranging from informal textbooks and lecture notes to large formal proof libraries, yet moving between these representations remains difficult. Informal texts hide dependencies, while formal systems expose every detail in ways that are not always human-readable. Dependency graphs offer a middle ground by making visible the structure of results, definitions, and proofs. We present KnowTeX, a standalone, user-friendly tool that extends the ideas of Lean's Blueprints, enabling the visualization of conceptual dependencies directly from LaTeX sources. Using a simple "uses" command, KnowTeX extracts relationships among statements and generates previewable graphs in DOT and TikZ formats. Applied to mathematical texts, such graphs clarify core results, support education and formalization, and provide a resource for aligning informal and formal mathematical representations. We argue that dependency graphs should become a standard feature of mathematical writing, benefiting both human readers and automated systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15294v1</guid></item><item><title>[cs updates on arXiv.org] Elsewise: Authoring AI-Based Interactive Narrative with Possibility Space Visualization</title><link>https://arxiv.org/abs/2601.15295</link><description>arXiv:2601.15295v1 Announce Type: new 
Abstract: Interactive narrative (IN) authors craft spaces of divergent narrative possibilities for players to explore, with the player's input determining which narrative possibilities they actually experience. Generative AI can enable new forms of IN by improvisationally expanding on pre-authored content in response to open-ended player input. However, this extrapolation risks widening the gap between author-envisioned and player-experienced stories, potentially limiting the strength of plot progression and the communication of the author's narrative intent. To bridge the gap, we introduce Elsewise: an authoring tool for AI-based INs that implements a novel Bundled Storyline concept to enhance author's perception and understanding of the narrative possibility space, allowing authors to explore similarities and differences between possible playthroughs of their IN in terms of open-ended, user-configurable narrative dimensions. A user study (n=12) shows that our approach improves author anticipation of player-experienced narrative, leading to more effective control and exploration of the narrative possibility spaces.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15295v1</guid></item><item><title>[cs updates on arXiv.org] Entropy-Tree: Tree-Based Decoding with Entropy-Guided Exploration</title><link>https://arxiv.org/abs/2601.15296</link><description>arXiv:2601.15296v1 Announce Type: new 
Abstract: Large language models achieve strong reasoning performance, yet existing decoding strategies either explore blindly (random sampling) or redundantly (independent multi-sampling). We propose Entropy-Tree, a tree-based decoding method that exploits entropy as a signal for branching decisions--expanding the search tree only at positions where the model exhibits genuine uncertainty. Entropy-Tree shows superior accuracy and calibration in reasoning tasks: it achieves better pass@k than Multi-chain across multiple models and datasets, and its predictive entropy demonstrates better AUROC compared to several traditional metrics. Entropy-Tree unifies efficient structured exploration and reliable uncertainty estimation within a single decoding procedure.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15296v1</guid></item><item><title>[cs updates on arXiv.org] AfriEconQA: A Benchmark Dataset for African Economic Analysis based on World Bank Reports</title><link>https://arxiv.org/abs/2601.15297</link><description>arXiv:2601.15297v1 Announce Type: new 
Abstract: We introduce AfriEconQA, a specialized benchmark dataset for African economic analysis grounded in a comprehensive corpus of 236 World Bank reports. The task of AfriEconQA is to answer complex economic queries that require high-precision numerical reasoning and temporal disambiguation from specialized institutional documents. The dataset consists of 8,937 curated QA instances, rigorously filtered from a pool of 10018 synthetic questions to ensure high-quality evidence-answer alignment. Each instance is composed of: (1) a question requiring reasoning over economic indicators, (2) the corresponding evidence retrieved from the corpus, (3) a verified ground-truth answer, and (4) source metadata (e.g., URL and publication date) to ensure temporal provenance. AfriEconQA is the first benchmark focused specifically on African economic analysis, providing a unique challenge for Information Retrieval (IR) systems, as the data is largely absent from the pretraining corpora of current Large Language Models (LLMs). We operationalize this dataset through an 11-experiment matrix, benchmarking a zero-shot baseline (GPT-5 Mini) against RAG configurations using GPT-4o and Qwen 32B across five distinct embedding and ranking strategies. Our results demonstrate a severe parametric knowledge gap, where zero-shot models fail to answer over 90 percent of queries, and even state-of-the-art RAG pipelines struggle to achieve high precision. This confirms AfriEconQA as a robust and challenging benchmark for the next generation of domain-specific IR and RAG systems. The AfriEconQA dataset and code will be made publicly available upon publication.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15297v1</guid></item><item><title>[cs updates on arXiv.org] Embedding Retrofitting: Data Engineering for better RAG</title><link>https://arxiv.org/abs/2601.15298</link><description>arXiv:2601.15298v1 Announce Type: new 
Abstract: Embedding retrofitting adjusts pre-trained word vectors using knowledge graph constraints to improve domain-specific retrieval. However, the effectiveness of retrofitting depends critically on knowledge graph quality, which in turn depends on text preprocessing. This paper presents a data engineering framework that addresses data quality degradation from annotation artifacts in real-world corpora.
  The analysis shows that hashtag annotations inflate knowledge graph density, leading to creating spurious edges that corrupt the retrofitting objective. On noisy graphs, all retrofitting techniques produce statistically significant degradation ($-3.5\%$ to $-5.2\%$, $p&lt;0.05$). After preprocessing, \acrshort{ewma} retrofitting achieves $+6.2\%$ improvement ($p=0.0348$) with benefits concentrated in quantitative synthesis questions ($+33.8\%$ average). The gap between clean and noisy preprocessing (10\%+ swing) exceeds the gap between algorithms (3\%), establishing preprocessing quality as the primary determinant of retrofitting success.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15298v1</guid></item><item><title>[cs updates on arXiv.org] MALTopic: Multi-Agent LLM Topic Modeling Framework</title><link>https://arxiv.org/abs/2601.15299</link><description>arXiv:2601.15299v1 Announce Type: new 
Abstract: Topic modeling is a crucial technique for extracting latent themes from unstructured text data, particularly valuable in analyzing survey responses. However, traditional methods often only consider free-text responses and do not natively incorporate structured or categorical survey responses for topic modeling. And they produce abstract topics, requiring extensive human interpretation. To address these limitations, we propose the Multi-Agent LLM Topic Modeling Framework (MALTopic). This framework decomposes topic modeling into specialized tasks executed by individual LLM agents: an enrichment agent leverages structured data to enhance textual responses, a topic modeling agent extracts latent themes, and a deduplication agent refines the results. Comparative analysis on a survey dataset demonstrates that MALTopic significantly improves topic coherence, diversity, and interpretability compared to LDA and BERTopic. By integrating structured data and employing a multi-agent approach, MALTopic generates human-readable topics with enhanced contextual relevance, offering a more effective solution for analyzing complex survey data.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15299v1</guid></item><item><title>[cs updates on arXiv.org] Intelligence Degradation in Long-Context LLMs: Critical Threshold Determination via Natural Length Distribution Analysis</title><link>https://arxiv.org/abs/2601.15300</link><description>arXiv:2601.15300v1 Announce Type: new 
Abstract: Large Language Models (LLMs) exhibit catastrophic performance degradation when processing contexts approaching certain critical thresholds, even when information remains relevant. This intelligence degradation-defined as over 30% drop in task performance-severely limits long-context applications. This degradation shows a common pattern: models maintain strong performance up to a critical threshold, then collapse catastrophically. We term this shallow long-context adaptation-models adapt for short to medium contexts but fail beyond critical thresholds. This paper presents three contributions: (1) Natural Length Distribution Analysis: We use each sample's natural token length without truncation or padding, providing stronger causal evidence that degradation results from context length itself. (2) Critical Threshold Determination: Through experiments on a mixed dataset (1,000 samples covering 5%-95% of context length), we identify the critical threshold for Qwen2.5-7B at 40-50% of maximum context length, where F1 scores drop from 0.55-0.56 to 0.3 (45.5% degradation), using five-method cross-validation. (3) Unified Framework: We consolidate shallow adaptation, explaining degradation patterns and providing a foundation for mitigation strategies. This work provides the first systematic characterization of intelligence degradation in open-source Qwen models, offering practical guidance for deploying LLMs in long-context scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15300v1</guid></item><item><title>[cs updates on arXiv.org] Can We Trust LLM Detectors?</title><link>https://arxiv.org/abs/2601.15301</link><description>arXiv:2601.15301v1 Announce Type: new 
Abstract: The rapid adoption of LLMs has increased the need for reliable AI text detection, yet existing detectors often fail outside controlled benchmarks. We systematically evaluate 2 dominant paradigms (training-free and supervised) and show that both are brittle under distribution shift, unseen generators, and simple stylistic perturbations. To address these limitations, we propose a supervised contrastive learning (SCL) framework that learns discriminative style embeddings. Experiments show that while supervised detectors excel in-domain, they degrade sharply out-of-domain, and training-free methods remain highly sensitive to proxy choice. Overall, our results expose fundamental challenges in building domain-agnostic detectors. Our code is available at: https://github.com/HARSHITJAIS14/DetectAI</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15301v1</guid></item><item><title>[cs updates on arXiv.org] Gated Sparse Attention: Combining Computational Efficiency with Training Stability for Long-Context Language Models</title><link>https://arxiv.org/abs/2601.15305</link><description>arXiv:2601.15305v1 Announce Type: new 
Abstract: The computational burden of attention in long-context language models has motivated two largely independent lines of work: sparse attention mechanisms that reduce complexity by attending to selected tokens, and gated attention variants that improve training sta-bility while mitigating the attention sink phenomenon. We observe that these approaches address complementary weaknesses and propose Gated Sparse Attention (GSA), an architecture that realizes the benefits of both. GSA incorporates a gated lightning indexer with sigmoid activations that produce bounded, interpretable selection scores, an adaptive sparsity controller that modulates the number of attended tokens based on local uncertainty, and dual gating at the value and output stages. We establish theoretical foundations for the approach, including complexity analysis, expressiveness results, and convergence guarantees. In experiments with 1.7B parameter models trained on 400B tokens, GSA matches the efficiency of sparse-only baselines (12-16x speedup at 128K context) while achieving the quality gains associated with gated attention: perplexity improves from 6.03 to 5.70, RULER scores at 128K context nearly double, and attention to the first token, a proxy for attention sinks, drops from 47% to under 4%. Training stability improves markedly, with loss spikes reduced by 98%.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15305v1</guid></item><item><title>[cs updates on arXiv.org] Uncovering Latent Bias in LLM-Based Emergency Department Triage Through Proxy Variables</title><link>https://arxiv.org/abs/2601.15306</link><description>arXiv:2601.15306v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have enabled their integration into clinical decision-making; however, hidden biases against patients across racial, social, economic, and clinical backgrounds persist. In this study, we investigate bias in LLM-based medical AI systems applied to emergency department (ED) triage. We employ 32 patient-level proxy variables, each represented by paired positive and negative qualifiers, and evaluate their effects using both public (MIMIC-IV-ED Demo, MIMIC-IV Demo) and restricted-access credentialed (MIMIC-IV-ED and MIMIC-IV) datasets as appropriate~\cite{mimiciv_ed_demo,mimiciv_ed,mimiciv}. Our results reveal discriminatory behavior mediated through proxy variables in ED triage scenarios, as well as a systematic tendency for LLMs to modify perceived patient severity when specific tokens appear in the input context, regardless of whether they are framed positively or negatively. These findings indicate that AI systems is still imperfectly trained on noisy, sometimes non-causal signals that do not reliably reflect true patient acuity. Consequently, more needs to be done to ensure the safe and responsible deployment of AI technologies in clinical settings.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15306v1</guid></item><item><title>[cs updates on arXiv.org] DeepSurvey-Bench: Evaluating Academic Value of Automatically Generated Scientific Survey</title><link>https://arxiv.org/abs/2601.15307</link><description>arXiv:2601.15307v1 Announce Type: new 
Abstract: The rapid development of automated scientific survey generation technology has made it increasingly important to establish a comprehensive benchmark to evaluate the quality of generated surveys.Nearly all existing evaluation benchmarks rely on flawed selection criteria such as citation counts and structural coherence to select human-written surveys as the ground truth survey datasets, and then use surface-level metrics such as structural quality and reference relevance to evaluate generated surveys.However, these benchmarks have two key issues: (1) the ground truth survey datasets are unreliable because of a lack academic dimension annotations; (2) the evaluation metrics only focus on the surface quality of the survey such as logical coherence. Both issues lead to existing benchmarks cannot assess to evaluate their deep "academic value", such as the core research objectives and the critical analysis of different studies. To address the above problems, we propose DeepSurvey-Bench, a novel benchmark designed to comprehensively evaluate the academic value of generated surveys. Specifically, our benchmark propose a comprehensive academic value evaluation criteria covering three dimensions: informational value, scholarly communication value, and research guidance value. Based on this criteria, we construct a reliable dataset with academic value annotations, and evaluate the deep academic value of the generated surveys. Extensive experimental results demonstrate that our benchmark is highly consistent with human performance in assessing the academic value of generated surveys.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15307v1</guid></item><item><title>[cs updates on arXiv.org] When Generative AI Meets Extended Reality: Enabling Scalable and Natural Interactions</title><link>https://arxiv.org/abs/2601.15308</link><description>arXiv:2601.15308v1 Announce Type: new 
Abstract: Extended Reality (XR), including virtual, augmented, and mixed reality, provides immersive and interactive experiences across diverse applications, from VR-based education to AR-based assistance and MR-based training. However, widespread XR adoption remains limited due to two key challenges: 1) the high cost and complexity of authoring 3D content, especially for large-scale environments or complex interactions; and 2) the steep learning curve associated with non-intuitive interaction methods like handheld controllers or scripted gestures. Generative AI (GenAI) presents a promising solution by enabling intuitive, language-driven interaction and automating content generation. Leveraging vision-language models and diffusion-based generation, GenAI can interpret ambiguous instructions, understand physical scenes, and generate or manipulate 3D content, significantly lowering barriers to XR adoption. This paper explores the integration of XR and GenAI through three concrete use cases, showing how they address key obstacles in scalability and natural interaction, and identifying technical challenges that must be resolved to enable broader adoption.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15308v1</guid></item><item><title>[cs updates on arXiv.org] Aeon: High-Performance Neuro-Symbolic Memory Management for Long-Horizon LLM Agents</title><link>https://arxiv.org/abs/2601.15311</link><description>arXiv:2601.15311v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are fundamentally constrained by the quadratic computational cost of self-attention and the "Lost in the Middle" phenomenon, where reasoning capabilities degrade as context windows expand. Existing solutions, primarily "Flat RAG" architectures relying on vector databases, treat memory as an unstructured bag of embeddings. This approach fails to capture the hierarchical and temporal structure of long-horizon interactions, leading to "Vector Haze", the retrieval of disjointed facts lacking episodic continuity. We propose Aeon, a Neuro-Symbolic Cognitive Operating System that redefines memory not as a static store, but as a managed OS resource. Aeon structures memory into a Memory Palace (a spatial index implemented via Atlas, a SIMD-accelerated Page-Clustered Vector Index that combines small-world graph navigation with B+ Tree-style disk locality to minimize read amplification) and a Trace (a neuro-symbolic episodic graph). We introduce the Semantic Lookaside Buffer (SLB), a predictive caching mechanism that exploits conversational locality to achieve sub-millisecond retrieval latencies. Benchmarks demonstrate that Aeon achieves &lt; 1ms retrieval latency on conversational workloads while ensuring state consistency via a zero-copy C++/Python bridge, effectively enabling persistent, structured memory for autonomous agents.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15311v1</guid></item><item><title>[cs updates on arXiv.org] Do people expect different behavior from large language models acting on their behalf? Evidence from norm elicitations in two canonical economic games</title><link>https://arxiv.org/abs/2601.15312</link><description>arXiv:2601.15312v1 Announce Type: new 
Abstract: While delegating tasks to large language models (LLMs) can save people time, there is growing evidence that offloading tasks to such models produces social costs. We use behavior in two canonical economic games to study whether people have different expectations when decisions are made by LLMs acting on their behalf instead of themselves. More specifically, we study the social appropriateness of a spectrum of possible behaviors: when LLMs divide resources on our behalf (Dictator Game and Ultimatum Game) and when they monitor the fairness of splits of resources (Ultimatum Game). We use the Krupka-Weber norm elicitation task to detect shifts in social appropriateness ratings. Results of two pre-registered and incentivized experimental studies using representative samples from the UK and US (N = 2,658) show three key findings. First, people find that offers from machines - when no acceptance is necessary - are judged to be less appropriate than when they come from humans, although there is no shift in the modal response. Second - when acceptance is necessary - it is more appropriate for a person to reject offers from machines than from humans. Third, receiving a rejection of an offer from a machine is no less socially appropriate than receiving the same rejection from a human. Overall, these results suggest that people apply different norms for machines deciding on how to split resources but are not opposed to machines enforcing the norms. The findings are consistent with offers made by machines now being viewed as having both a cognitive and emotional component.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15312v1</guid></item><item><title>[cs updates on arXiv.org] The Paradigm Shift: A Comprehensive Survey on Large Vision Language Models for Multimodal Fake News Detection</title><link>https://arxiv.org/abs/2601.15316</link><description>arXiv:2601.15316v1 Announce Type: new 
Abstract: In recent years, the rapid evolution of large vision-language models (LVLMs) has driven a paradigm shift in multimodal fake news detection (MFND), transforming it from traditional feature-engineering approaches to unified, end-to-end multimodal reasoning frameworks. Early methods primarily relied on shallow fusion techniques to capture correlations between text and images, but they struggled with high-level semantic understanding and complex cross-modal interactions. The emergence of LVLMs has fundamentally changed this landscape by enabling joint modeling of vision and language with powerful representation learning, thereby enhancing the ability to detect misinformation that leverages both textual narratives and visual content. Despite these advances, the field lacks a systematic survey that traces this transition and consolidates recent developments. To address this gap, this paper provides a comprehensive review of MFND through the lens of LVLMs. We first present a historical perspective, mapping the evolution from conventional multimodal detection pipelines to foundation model-driven paradigms. Next, we establish a structured taxonomy covering model architectures, datasets, and performance benchmarks. Furthermore, we analyze the remaining technical challenges, including interpretability, temporal reasoning, and domain generalization. Finally, we outline future research directions to guide the next stage of this paradigm shift. To the best of our knowledge, this is the first comprehensive survey to systematically document and analyze the transformative role of LVLMs in combating multimodal fake news. The summary of existing methods mentioned is in our Github: \href{https://github.com/Tan-YiLong/Overview-of-Fake-News-Detection}{https://github.com/Tan-YiLong/Overview-of-Fake-News-Detection}.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15316v1</guid></item><item><title>[cs updates on arXiv.org] Replayable Financial Agents: A Determinism-Faithfulness Assurance Harness for Tool-Using LLM Agents</title><link>https://arxiv.org/abs/2601.15322</link><description>arXiv:2601.15322v1 Announce Type: new 
Abstract: LLM agents struggle with regulatory audit replay: when asked to reproduce a flagged transaction decision with identical inputs, most deployments fail to return consistent results. This paper introduces the Determinism-Faithfulness Assurance Harness (DFAH), a framework for measuring trajectory determinism and evidence-conditioned faithfulness in tool-using agents deployed in financial services.
  Across 74 configurations (12 models, 4 providers, 8-24 runs each at T=0.0) in non-agentic baseline experiments, 7-20B parameter models achieved 100% determinism, while 120B+ models required 3.7x larger validation samples to achieve equivalent statistical reliability. Agentic tool-use introduces additional variance (see Tables 4-7). Contrary to the assumed reliability-capability trade-off, a positive Pearson correlation emerged (r = 0.45, p &lt; 0.01, n = 51 at T=0.0) between determinism and faithfulness; models producing consistent outputs also tended to be more evidence-aligned.
  Three financial benchmarks are provided (compliance triage, portfolio constraints, DataOps exceptions; 50 cases each) along with an open-source stress-test harness. In these benchmarks and under DFAH evaluation settings, Tier 1 models with schema-first architectures achieved determinism levels consistent with audit replay requirements.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15322v1</guid></item><item><title>[cs updates on arXiv.org] Prometheus Mind: Retrofitting Memory to Frozen Language Models</title><link>https://arxiv.org/abs/2601.15324</link><description>arXiv:2601.15324v1 Announce Type: new 
Abstract: Adding memory to pretrained language models typically requires architectural changes or weight modification. We present Prometheus Mind, which retrofits memory to a frozen Qwen3-4B using 11 modular adapters (530MB, 7% overhead) -- fully reversible by removing the adapters. Building this system required solving four problems: (1) Extraction -- we develop Contrastive Direction Discovery (CDD), which finds semantic directions via minimal pairs without labeled data. (2) Training -- end-to-end optimization collapses; stage-wise training of each adapter on simple proxy tasks succeeds. (3) Injection -- learned encoders fail to generalize; we find that lm_head.weight rows already provide the mapping we need, requiring no training. (4) Hidden state collapse -- transformers make ``wife'' and ``brother'' 0.98+ similar; we train projections to recover distinction (0.98 $\rightarrow$ 0.09). On PrometheusExtract-132 (132 cases), the system achieves 94.4% retrieval on clean inputs (n=54, 95% CI: [84.9%, 98.1%]), degrading to 19.4% on informal inputs with ellipsis, filler words, or implicit subjects (n=36). The primary bottleneck is relation classification (47.3% accuracy), responsible for most extraction errors.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15324v1</guid></item><item><title>[cs updates on arXiv.org] Rules Create Unequal Rewards: Elite Tennis Players Allocate Resources Efficiently</title><link>https://arxiv.org/abs/2601.15327</link><description>arXiv:2601.15327v1 Announce Type: new 
Abstract: In many competitive settings, from education to politics, rules do not reward effort evenly, and thresholds (e.g., grade cutoffs or electoral majorities) make some moments disproportionately important. Success thus depends on efficiently allocating limited resources. However, empirical demonstration has been difficult because effort allocation is rarely observable and feedback is often delayed, limiting our understanding of expertise. Professional tennis provides an ideal natural experiment. Because each game resets after a player wins four points and points in a lost game are wasted, the value of a point varies sharply across scores. Efficient allocation should therefore win games without wasting points, conserving resources for future games. Such allocation manifests in score-dependent point-winning probabilities, from which we derive each player's Pareto frontier-the theoretical limit of the trade-off between game-winning probability and the expected points per game. Here, we show that top players operate closer to this frontier, converting points to game wins more efficiently. Optimal strategies reduce the probability of winning points when the player is far behind (e.g.,0-2, 0-3). This behavior is psychologically difficult-letting go of the current game-but represents a rational energy conservation strategy. Top players exhibit this pattern especially in return games, where winning points is harder than in service games, requiring them to drastically vary their efforts, consistent with game-theoretic predictions. These findings suggest that elite performance reflects efficient adaptation to rule-created value structures; knowing when to give up may be as fundamental to expertise as knowing when to compete.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15327v1</guid></item><item><title>[cs updates on arXiv.org] ICPO: Illocution-Calibrated Policy Optimization for Multi-Turn Conversation</title><link>https://arxiv.org/abs/2601.15330</link><description>arXiv:2601.15330v1 Announce Type: new 
Abstract: Large Language Models (LLMs) in multi-turn conversations often suffer from a ``lost-in-conversation'' phenomenon, where they struggle to recover from early incorrect assumptions, particularly when users provide ambiguous initial instructions. We find that standard post-training techniques like Reinforcement Learning with Verifiable Rewards (RLVR) exacerbate this issue by rewarding confident, direct answers, thereby inducing overconfidence and discouraging the model from seeking clarification. To address this, we propose Illocution-Calibrated Policy Optimization (ICPO), a novel training framework that sensitizes the model to instruction ambiguity. ICPO augments the training corpus with underspecified prompts and conditions the reward signal on the user's illocutionary intent, rewarding the model for expressing uncertainty or asking for clarification when faced with ambiguity. Experiments demonstrate that ICPO fosters appropriate humility, yielding a substantial average improvement of 75\% in multi-turn conversation, while preserving robust performance on single-turn benchmarks. Our work presents a practical path toward more robust and collaborative conversational AI that can better navigate the nuances of human interaction.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15330v1</guid></item><item><title>[cs updates on arXiv.org] RECAP: A Resource-Efficient Method for Adversarial Prompting in Large Language Models</title><link>https://arxiv.org/abs/2601.15331</link><description>arXiv:2601.15331v1 Announce Type: new 
Abstract: The deployment of large language models (LLMs) has raised security concerns due to their susceptibility to producing harmful or policy-violating outputs when exposed to adversarial prompts. While alignment and guardrails mitigate common misuse, they remain vulnerable to automated jailbreaking methods such as GCG, PEZ, and GBDA, which generate adversarial suffixes via training and gradient-based search. Although effective, these methods particularly GCG are computationally expensive, limiting their practicality for organisations with constrained resources. This paper introduces a resource-efficient adversarial prompting approach that eliminates the need for retraining by matching new prompts to a database of pre-trained adversarial prompts. A dataset of 1,000 prompts was classified into seven harm-related categories, and GCG, PEZ, and GBDA were evaluated on a Llama 3 8B model to identify the most effective attack method per category. Results reveal a correlation between prompt type and algorithm effectiveness. By retrieving semantically similar successful adversarial prompts, the proposed method achieves competitive attack success rates with significantly reduced computational cost. This work provides a practical framework for scalable red-teaming and security evaluation of aligned LLMs, including in settings where model internals are inaccessible.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15331v1</guid></item><item><title>[cs updates on arXiv.org] Empowering LLMs for Structure-Based Drug Design via Exploration-Augmented Latent Inference</title><link>https://arxiv.org/abs/2601.15333</link><description>arXiv:2601.15333v1 Announce Type: new 
Abstract: Large Language Models (LLMs) possess strong representation and reasoning capabilities, but their application to structure-based drug design (SBDD) is limited by insufficient understanding of protein structures and unpredictable molecular generation. To address these challenges, we propose Exploration-Augmented Latent Inference for LLMs (ELILLM), a framework that reinterprets the LLM generation process as an encoding, latent space exploration, and decoding workflow. ELILLM explicitly explores portions of the design problem beyond the model's current knowledge while using a decoding module to handle familiar regions, generating chemically valid and synthetically reasonable molecules. In our implementation, Bayesian optimization guides the systematic exploration of latent embeddings, and a position-aware surrogate model efficiently predicts binding affinity distributions to inform the search. Knowledge-guided decoding further reduces randomness and effectively imposes chemical validity constraints. We demonstrate ELILLM on the CrossDocked2020 benchmark, showing strong controlled exploration and high binding affinity scores compared with seven baseline methods. These results demonstrate that ELILLM can effectively enhance LLMs capabilities for SBDD.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15333v1</guid></item><item><title>[cs updates on arXiv.org] No Reliable Evidence of Self-Reported Sentience in Small Large Language Models</title><link>https://arxiv.org/abs/2601.15334</link><description>arXiv:2601.15334v1 Announce Type: new 
Abstract: Whether language models possess sentience has no empirical answer. But whether they believe themselves to be sentient can, in principle, be tested. We do so by querying several open-weights models about their own consciousness, and then verifying their responses using classifiers trained on internal activations. We draw upon three model families (Qwen, Llama, GPT-OSS) ranging from 0.6 billion to 70 billion parameters, approximately 50 questions about consciousness and subjective experience, and three classification methods from the interpretability literature. First, we find that models consistently deny being sentient: they attribute consciousness to humans but not to themselves. Second, classifiers trained to detect underlying beliefs - rather than mere outputs - provide no clear evidence that these denials are untruthful. Third, within the Qwen family, larger models deny sentience more confidently than smaller ones. These findings contrast with recent work suggesting that models harbour latent beliefs in their own consciousness.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15334v1</guid></item><item><title>[cs updates on arXiv.org] ToolCaching: Towards Efficient Caching for LLM Tool-calling</title><link>https://arxiv.org/abs/2601.15335</link><description>arXiv:2601.15335v1 Announce Type: new 
Abstract: Recent advances in Large Language Models (LLMs) have revolutionized web applications, enabling intelligent search, recommendation, and assistant services with natural language interfaces. Tool-calling extends LLMs with the ability to interact with external APIs, greatly enhancing their practical utility. While prior research has improved tool-calling performance by adopting traditional computer systems techniques, such as parallel and asynchronous execution, the challenge of redundant or repeated tool-calling requests remains largely unaddressed. Caching is a classic solution to this problem, but applying it to LLM tool-calling introduces new difficulties due to heterogeneous request semantics, dynamic workloads, and varying freshness requirements, which render conventional cache policies ineffective. To address these issues, we propose ToolCaching, an efficient feature-driven and adaptive caching framework for LLM tool-calling systems. ToolCaching systematically integrates semantic and system-level features to evaluate request cacheability and estimate caching value. At its core, the VAAC algorithm integrates bandit-based admission with value-driven, multi-factor eviction, jointly accounting for request frequency, recency, and caching value. Extensive experiments on synthetic and public tool-calling workloads demonstrate that ToolCaching with VAAC achieves up to 11% higher cache hit ratios and 34% lower latency compared to standard policies, effectively accelerating LLM tool-calling in practical applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15335v1</guid></item><item><title>[cs updates on arXiv.org] Language Models Entangle Language and Culture</title><link>https://arxiv.org/abs/2601.15337</link><description>arXiv:2601.15337v1 Announce Type: new 
Abstract: Users should not be systemically disadvantaged by the language they use for interacting with LLMs; i.e. users across languages should get responses of similar quality irrespective of language used. In this work, we create a set of real-world open-ended questions based on our analysis of the WildChat dataset and use it to evaluate whether responses vary by language, specifically, whether answer quality depends on the language used to query the model. We also investigate how language and culture are entangled in LLMs such that choice of language changes the cultural information and context used in the response by using LLM-as-a-Judge to identify the cultural context present in responses. To further investigate this, we evaluate LLMs on a translated subset of the CulturalBench benchmark across multiple languages. Our evaluations reveal that LLMs consistently provide lower quality answers to open-ended questions in low resource languages. We find that language significantly impacts the cultural context used by the model. This difference in context impacts the quality of the downstream answer.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15337v1</guid></item><item><title>[cs updates on arXiv.org] From Quotes to Concepts: Axial Coding of Political Debates with Ensemble LMs</title><link>https://arxiv.org/abs/2601.15338</link><description>arXiv:2601.15338v1 Announce Type: new 
Abstract: Axial coding is a commonly used qualitative analysis method that enhances document understanding by organizing sentence-level open codes into broader categories. In this paper, we operationalize axial coding with large language models (LLMs). Extending an ensemble-based open coding approach with an LLM moderator, we add an axial coding step that groups open codes into higher-order categories, transforming raw debate transcripts into concise, hierarchical representations. We compare two strategies: (i) clustering embeddings of code-utterance pairs using density-based and partitioning algorithms followed by LLM labeling, and (ii) direct LLM-based grouping of codes and utterances into categories. We apply our method to Dutch parliamentary debates, converting lengthy transcripts into compact, hierarchically structured codes and categories. We evaluate our method using extrinsic metrics aligned with human-assigned topic labels (ROUGE-L, cosine, BERTScore), and intrinsic metrics describing code groups (coverage, brevity, coherence, novelty, JSD divergence). Our results reveal a trade-off: density-based clustering achieves high coverage and strong cluster alignment, while direct LLM grouping results in higher fine-grained alignment, but lower coverage 20%. Overall, clustering maximizes coverage and structural separation, whereas LLM grouping produces more concise, interpretable, and semantically aligned categories. To support future research, we publicly release the full dataset of utterances and codes, enabling reproducibility and comparative studies.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15338v1</guid></item><item><title>[cs updates on arXiv.org] Lost in Transcription: How Speech-to-Text Errors Derail Code Understanding</title><link>https://arxiv.org/abs/2601.15339</link><description>arXiv:2601.15339v1 Announce Type: new 
Abstract: Code understanding is a foundational capability in software engineering tools and developer workflows. However, most existing systems are designed for English-speaking users interacting via keyboards, which limits accessibility in multilingual and voice-first settings, particularly in regions like India. Voice-based interfaces offer a more inclusive modality, but spoken queries involving code present unique challenges due to the presence of non-standard English usage, domain-specific vocabulary, and custom identifiers such as variable and function names, often combined with code-mixed expressions. In this work, we develop a multilingual speech-driven framework for code understanding that accepts spoken queries in a user native language, transcribes them using Automatic Speech Recognition (ASR), applies code-aware ASR output refinement using Large Language Models (LLMs), and interfaces with code models to perform tasks such as code question answering and code retrieval through benchmarks such as CodeSearchNet, CoRNStack, and CodeQA. Focusing on four widely spoken Indic languages and English, we systematically characterize how transcription errors impact downstream task performance. We also identified key failure modes in ASR for code and demonstrated that LLM-guided refinement significantly improves performance across both transcription and code understanding stages. Our findings underscore the need for code-sensitive adaptations in speech interfaces and offer a practical solution for building robust, multilingual voice-driven programming tools.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15339v1</guid></item><item><title>[cs updates on arXiv.org] Logic Programming on Knowledge Graph Networks And its Application in Medical Domain</title><link>https://arxiv.org/abs/2601.15347</link><description>arXiv:2601.15347v1 Announce Type: new 
Abstract: The rash development of knowledge graph research has brought big driving force to its application in many areas, including the medicine and healthcare domain. However, we have found that the application of some major information processing techniques on knowledge graph still lags behind. This defect includes the failure to make sufficient use of advanced logic reasoning, advanced artificial intelligence techniques, special-purpose programming languages, modern probabilistic and statistic theories et al. on knowledge graphs development and application. In particular, the multiple knowledge graphs cooperation and competition techniques have not got enough attention from researchers. This paper develops a systematic theory, technique and application of the concept 'knowledge graph network' and its application in medical and healthcare domain. Our research covers its definition, development, reasoning, computing and application under different conditions such as unsharp, uncertain, multi-modal, vectorized, distributed, federated. Almost in each case we provide (real data) examples and experiment results. Finally, a conclusion of innovation is provided.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15347v1</guid></item><item><title>[cs updates on arXiv.org] Abusive music and song transformation using GenAI and LLMs</title><link>https://arxiv.org/abs/2601.15348</link><description>arXiv:2601.15348v1 Announce Type: new 
Abstract: Repeated exposure to violence and abusive content in music and song content can influence listeners' emotions and behaviours, potentially normalising aggression or reinforcing harmful stereotypes. In this study, we explore the use of generative artificial intelligence (GenAI) and Large Language Models (LLMs) to automatically transform abusive words (vocal delivery) and lyrical content in popular music. Rather than simply muting or replacing a single word, our approach transforms the tone, intensity, and sentiment, thus not altering just the lyrics, but how it is expressed. We present a comparative analysis of four selected English songs and their transformed counterparts, evaluating changes through both acoustic and sentiment-based lenses. Our findings indicate that Gen-AI significantly reduces vocal aggressiveness, with acoustic analysis showing improvements in Harmonic to Noise Ratio, Cepstral Peak Prominence, and Shimmer. Sentiment analysis reduced aggression by 63.3-85.6\% across artists, with major improvements in chorus sections (up to 88.6\% reduction). The transformed versions maintained musical coherence while mitigating harmful content, offering a promising alternative to traditional content moderation that avoids triggering the "forbidden fruit" effect, where the censored content becomes more appealing simply because it is restricted. This approach demonstrates the potential for GenAI to create safer listening experiences while preserving artistic expression.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15348v1</guid></item><item><title>[cs updates on arXiv.org] Preparation and Motion Study of Magnetically Driven Micro Soft Robot Mimicking the Cownose Ray</title><link>https://arxiv.org/abs/2601.15349</link><description>arXiv:2601.15349v1 Announce Type: new 
Abstract: In narrow, unstructured underwater environments such as environmental monitoring and minimally invasive medical procedures, micro soft robots exhibit unique advantages due to their flexible movement capabilities and small size. At the same time, applying bionic technology to the structural design of micro soft robots can significantly improve their swimming performance. However, limited by their miniaturization, these robots are difficult to power internally and usually adopt a wireless power supply method. This study designs and fabricates a magnetically responsive, cownose ray-inspired micro soft robot based on the swimming principle of the cownose ray. The robot is made of a certain proportion of NdFeB and PDMS. Then, a three-dimensional Helmholtz coil is used to generate an oscillating harmonic magnetic field to conduct swimming experiments on the robot, exploring the influence of magnetic field parameters on the robot's swimming performance. The experimental results show that the swimming speed is the fastest at B = 5 mT and f = 11 Hz, reaching 5.25 mm/s, which is about 0.5 body lengths per second. In addition, by adjusting the current direction and frequency of the coil, the robot can perform different swimming modes such as straight swimming, turning swimming, and directional swimming. By employing a stepwise adjustment method, the impact of response errors on the robot's trajectory can be effectively reduced. This study demonstrates a method for magnetically driven micro soft robots, laying a foundation for the application of wireless-driven robots in underwater narrow spaces.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15349v1</guid></item><item><title>[cs updates on arXiv.org] A Prompt-Based Framework for Loop Vulnerability Detection Using Local LLMs</title><link>https://arxiv.org/abs/2601.15352</link><description>arXiv:2601.15352v1 Announce Type: new 
Abstract: Loop vulnerabilities are one major risky construct in software development. They can easily lead to infinite loops or executions, exhaust resources, or introduce logical errors that degrade performance and compromise security. The problem are often undetected by traditional static analyzers because such tools rely on syntactic patterns, which makes them struggle to detect semantic flaws. Consequently, Large Language Models (LLMs) offer new potential for vulnerability detection because of their ability to understand code contextually. Moreover, local LLMs unlike commercial ones like ChatGPT or Gemini addresses issues such as privacy, latency, and dependency concerns by facilitating efficient offline analysis. Consequently, this study proposes a prompt-based framework that utilize local LLMs for the detection of loop vulnerabilities within Python 3.7+ code. The framework targets three categories of loop-related issues, such as control and logic errors, security risks inside loops, and resource management inefficiencies. A generalized and structured prompt-based framework was designed and tested with two locally deployed LLMs (LLaMA 3.2; 3B and Phi 3.5; 4B) by guiding their behavior via iterative prompting. The designed prompt-based framework included key safeguarding features such as language-specific awareness, code-aware grounding, version sensitivity, and hallucination prevention. The LLM results were validated against a manually established baseline truth, and the results indicate that Phi outperforms LLaMA in precision, recall, and F1-score. The findings emphasize the importance of designing effective prompts for local LLMs to perform secure and accurate code vulnerability analysis.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15352v1</guid></item><item><title>[cs updates on arXiv.org] AI-Based Culvert-Sewer Inspection</title><link>https://arxiv.org/abs/2601.15366</link><description>arXiv:2601.15366v1 Announce Type: new 
Abstract: Culverts and sewer pipes are critical components of drainage systems, and their failure can lead to serious risks to public safety and the environment. In this thesis, we explore methods to improve automated defect segmentation in culverts and sewer pipes. Collecting and annotating data in this field is cumbersome and requires domain knowledge. Having a large dataset for structural defect detection is therefore not feasible. Our proposed methods are tested under conditions with limited annotated data to demonstrate applicability to real-world scenarios. Overall, this thesis proposes three methods to significantly enhance defect segmentation and handle data scarcity. This can be addressed either by enhancing the training data or by adjusting a models architecture.
  First, we evaluate preprocessing strategies, including traditional data augmentation and dynamic label injection. These techniques significantly improve segmentation performance, increasing both Intersection over Union (IoU) and F1 score. Second, we introduce FORTRESS, a novel architecture that combines depthwise separable convolutions, adaptive Kolmogorov-Arnold Networks (KAN), and multi-scale attention mechanisms. FORTRESS achieves state-of-the-art performance on the culvert sewer pipe defect dataset, while significantly reducing the number of trainable parameters, as well as its computational cost. Finally, we investigate few-shot semantic segmentation and its applicability to defect detection. Few-shot learning aims to train models with only limited data available. By employing a bidirectional prototypical network with attention mechanisms, the model achieves richer feature representations and achieves satisfactory results across evaluation metrics.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15366v1</guid></item><item><title>[cs updates on arXiv.org] Improving MoE Compute Efficiency by Composing Weight and Data Sparsity</title><link>https://arxiv.org/abs/2601.15370</link><description>arXiv:2601.15370v1 Announce Type: new 
Abstract: Mixture-of-Experts layers achieve compute efficiency through weight sparsity: each token activates only a subset of experts. Data sparsity, where each expert processes only a subset of tokens, offers a complementary axis. Expert-choice routing implements data sparsity directly but violates causality in autoregressive models, creating train-inference mismatch. We recover data sparsity within causal token-choice MoE by leveraging zero-compute (null) experts within the routing pool. When a token routes to null experts, those slots consume no compute. The standard load balancing objective trains the model to uniformly use all experts (real and null) therefore creating data sparsity in expectation without the causality violations. We evaluate on vision-language model training, where data heterogeneity is pronounced: vision encoders produce many low-information tokens while text tokens are denser. At matched expected FLOPs, composing weight and data sparsity yields a more compute-efficient frontier than weight sparsity alone, with gains in training loss and downstream performance. The model learns implicit modality-aware allocation, routing vision tokens to null experts more aggressively than text, without explicit modality routing.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15370v1</guid></item><item><title>[cs updates on arXiv.org] You Need Better Attention Priors</title><link>https://arxiv.org/abs/2601.15380</link><description>arXiv:2601.15380v1 Announce Type: new 
Abstract: We generalize the attention mechanism by viewing it through the lens of Entropic Optimal Transport, revealing that standard attention corresponds to a transport problem regularized by an implicit uniform prior. We introduce Generalized Optimal transport Attention with Trainable priors (GOAT), a new attention mechanism that replaces this naive assumption with a learnable, continuous prior. This prior maintains full compatibility with optimized kernels such as FlashAttention. GOAT also provides an EOT-based explanation of attention sinks and materializes a solution for them, avoiding the representational trade-offs of standard attention. Finally, by absorbing spatial information into the core attention computation, GOAT learns an extrapolatable prior that combines the flexibility of learned positional embeddings with the length generalization of fixed encodings.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15380v1</guid></item><item><title>[cs updates on arXiv.org] VegaChat: A Robust Framework for LLM-Based Chart Generation and Assessment</title><link>https://arxiv.org/abs/2601.15385</link><description>arXiv:2601.15385v1 Announce Type: new 
Abstract: Natural-language-to-visualization (NL2VIS) systems based on large language models (LLMs) have substantially improved the accessibility of data visualization. However, their further adoption is hindered by two coupled challenges: (i) the absence of standardized evaluation metrics makes it difficult to assess progress in the field and compare different approaches; and (ii) natural language descriptions are inherently underspecified, so multiple visualizations may be valid for the same query. To address these issues, we introduce VegaChat, a framework for generating, validating, and assessing declarative visualizations from natural language.
  We propose two complementary metrics: Spec Score, a deterministic metric that measures specification-level similarity without invoking an LLM, and Vision Score, a library-agnostic, image-based metric that leverages a multimodal LLM to assess chart similarity and prompt compliance.
  We evaluate VegaChat on the NLV Corpus and on the annotated subset of ChartLLM. VegaChat achieves near-zero rates of invalid or empty visualizations, while Spec Score and Vision Score exhibit strong correlation with human judgments (Pearson 0.65 and 0.71, respectively), indicating that the proposed metrics support consistent, cross-library comparison.
  The code and evaluation artifacts are available at https://zenodo.org/records/17062309.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15385v1</guid></item><item><title>[cs updates on arXiv.org] FedUMM: A General Framework for Federated Learning with Unified Multimodal Models</title><link>https://arxiv.org/abs/2601.15390</link><description>arXiv:2601.15390v1 Announce Type: new 
Abstract: Unified multimodal models (UMMs) are emerging as strong foundation models that can do both generation and understanding tasks in a single architecture. However, they are typically trained in centralized settings where all training and downstream datasets are gathered in a central server, limiting the deployment in privacy-sensitive and geographically distributed scenarios. In this paper, we present FedUMM, a general federated learning framework for UMMs under non-IID multimodal data with low communication cost. Built on NVIDIA FLARE, FedUMM instantiates federation for a BLIP3o backbone via parameter-efficient fine-tuning: clients train lightweight LoRA adapters while freezing the foundation models, and the server aggregates only adapter updates. We evaluate on VQA v2 and the GenEval compositional generation benchmarks under Dirichlet-controlled heterogeneity with up to 16 clients. Results show slight degradation as client count and heterogeneity increase, while remaining competitive with centralized training. We further analyze computation--communication trade-offs and demonstrate that adapter-only federation reduces per-round communication by over an order of magnitude compared to full fine-tuning, enabling practical federated UMM training. This work provides empirical experience for future research on privacy-preserving federated unified multimodal models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15390v1</guid></item><item><title>[cs updates on arXiv.org] GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation</title><link>https://arxiv.org/abs/2601.15392</link><description>arXiv:2601.15392v1 Announce Type: new 
Abstract: Biomedical research increasingly relies on integrating diverse data modalities, including gene expression profiles, medical images, and clinical metadata. While medical images and clinical metadata are routinely collected in clinical practice, gene expression data presents unique challenges for widespread research use, mainly due to stringent privacy regulations and costly laboratory experiments. To address these limitations, we present GeMM-GAN, a novel Generative Adversarial Network conditioned on histopathology tissue slides and clinical metadata, designed to synthesize realistic gene expression profiles. GeMM-GAN combines a Transformer Encoder for image patches with a final Cross Attention mechanism between patches and text tokens, producing a conditioning vector to guide a generative model in generating biologically coherent gene expression profiles. We evaluate our approach on the TCGA dataset and demonstrate that our framework outperforms standard generative models and generates more realistic and functionally meaningful gene expression profiles, improving by more than 11\% the accuracy on downstream disease type prediction compared to current state-of-the-art generative models. Code will be available at: https://github.com/francescapia/GeMM-GAN</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15392v1</guid></item><item><title>[cs updates on arXiv.org] Memorization Dynamics in Knowledge Distillation for Language Models</title><link>https://arxiv.org/abs/2601.15394</link><description>arXiv:2601.15394v1 Announce Type: new 
Abstract: Knowledge Distillation (KD) is increasingly adopted to transfer capabilities from large language models to smaller ones, offering significant improvements in efficiency and utility while often surpassing standard fine-tuning. Beyond performance, KD is also explored as a privacy-preserving mechanism to mitigate the risk of training data leakage. While training data memorization has been extensively studied in standard pre-training and fine-tuning settings, its dynamics in a knowledge distillation setup remain poorly understood. In this work, we study memorization across the KD pipeline using three large language model (LLM) families (Pythia, OLMo-2, Qwen-3) and three datasets (FineWeb, Wikitext, Nemotron-CC-v2). We find: (1) distilled models memorize significantly less training data than standard fine-tuning (reducing memorization by more than 50%); (2) some examples are inherently easier to memorize and account for a large fraction of memorization during distillation (over ~95%); (3) student memorization is predictable prior to distillation using features based on zlib entropy, KL divergence, and perplexity; and (4) while soft and hard distillation have similar overall memorization rates, hard distillation poses a greater risk: it inherits $2.7\times$ more teacher-specific examples than soft distillation. Overall, we demonstrate that distillation can provide both improved generalization and reduced memorization risks compared to standard fine-tuning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15394v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Fixed Psychological Personas: State Beats Trait, but Language Models are State-Blind</title><link>https://arxiv.org/abs/2601.15395</link><description>arXiv:2601.15395v1 Announce Type: new 
Abstract: User interactions with language models vary due to static properties of the user (trait) and the specific context of the interaction (state). However, existing persona datasets (like PersonaChat, PANDORA etc.) capture only trait, and ignore the impact of state. We introduce Chameleon, a dataset of 5,001 contextual psychological profiles from 1,667 Reddit users, each measured across multiple contexts. Using the Chameleon dataset, we present three key findings. First, inspired by Latent State-Trait theory, we decompose variance and find that 74\% is within-person(state) while only 26\% is between-person (trait). Second, we find that LLMs are state-blind: they focus on trait only, and produce similar responses regardless of state. Third, we find that reward models react to user state, but inconsistently: different models favor or penalize the same users in opposite directions. We release Chameleon to support research on affective computing, personalized dialogue, and RLHF alignment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15395v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Prompting: Efficient and Robust Contextual Biasing for Speech LLMs via Logit-Space Integration (LOGIC)</title><link>https://arxiv.org/abs/2601.15397</link><description>arXiv:2601.15397v1 Announce Type: new 
Abstract: The rapid emergence of new entities -- driven by cultural shifts, evolving trends, and personalized user data -- poses a significant challenge for existing Speech Large Language Models (Speech LLMs). While these models excel at general conversational tasks, their static training knowledge limits their ability to recognize domain-specific terms such as contact names, playlists, or technical jargon. Existing solutions primarily rely on prompting, which suffers from poor scalability: as the entity list grows, prompting encounters context window limitations, increased inference latency, and the "lost-in-the-middle" phenomenon. An alternative approach, Generative Error Correction (GEC), attempts to rewrite transcripts via post-processing but frequently suffers from "over-correction", introducing hallucinations of entities that were never spoken.
  In this work, we introduce LOGIC (Logit-Space Integration for Contextual Biasing), an efficient and robust framework that operates directly in the decoding layer. Unlike prompting, LOGIC decouples context injection from input processing, ensuring constant-time complexity relative to prompt length. Extensive experiments using the Phi-4-MM model across 11 multilingual locales demonstrate that LOGIC achieves an average 9% relative reduction in Entity WER with a negligible 0.30% increase in False Alarm Rate.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15397v1</guid></item><item><title>[cs updates on arXiv.org] Attention-Informed Surrogates for Navigating Power-Performance Trade-offs in HPC</title><link>https://arxiv.org/abs/2601.15399</link><description>arXiv:2601.15399v1 Announce Type: new 
Abstract: High-Performance Computing (HPC) schedulers must balance user performance with facility-wide resource constraints. The task boils down to selecting the optimal number of nodes for a given job. We present a surrogate-assisted multi-objective Bayesian optimization (MOBO) framework to automate this complex decision. Our core hypothesis is that surrogate models informed by attention-based embeddings of job telemetry can capture performance dynamics more effectively than standard regression techniques. We pair this with an intelligent sample acquisition strategy to ensure the approach is data-efficient. On two production HPC datasets, our embedding-informed method consistently identified higher-quality Pareto fronts of runtime-power trade-offs compared to baselines. Furthermore, our intelligent data sampling strategy drastically reduced training costs while improving the stability of the results. To our knowledge, this is the first work to successfully apply embedding-informed surrogates in a MOBO framework to the HPC scheduling problem, jointly optimizing for performance and power on production workloads.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15399v1</guid></item><item><title>[cs updates on arXiv.org] Multi-Input Ciphertext Multiplication for Homomorphic Encryption</title><link>https://arxiv.org/abs/2601.15401</link><description>arXiv:2601.15401v1 Announce Type: new 
Abstract: Homomorphic encryption (HE) enables arithmetic operations to be performed directly on encrypted data. It is essential for privacy-preserving applications such as machine learning, medical diagnosis, and financial data analysis. In popular HE schemes, ciphertext multiplication is only defined for two inputs. However, the multiplication of multiple inputs is needed in many HE applications. In our previous work, a three-input ciphertext multiplication method for the CKKS HE scheme was developed. This paper first reformulates the three-input ciphertext multiplication to enable the combination of computations in order to further reduce the complexity. The second contribution is extending the multiplication to multiple inputs without compromising the noise overhead. Additional evaluation keys are introduced to achieve relinearization of polynomial multiplication results. To minimize the complexity of the large number of rescaling units in the multiplier, a theoretical analysis is developed to relocate the rescaling, and a multi-level rescaling approach is proposed to implement combined rescaling with complexity similar to that of a single rescaling unit. Guidelines and examples are provided on the input partition to enable the combination of more rescaling. Additionally, efficient hardware architectures are designed to implement our proposed multipliers. The improved three-input ciphertext multiplier reduces the logic area and latency by 15% and 50%, respectively, compared to the best prior design. For multipliers with more inputs, ranging from 4 to 12, the architectural analysis reveals 32% savings in area and 45% shorter latency, on average, compared to prior work.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15401v1</guid></item><item><title>[cs updates on arXiv.org] Partially Polarized Polar Codes: A New Design for 6G Control Channels</title><link>https://arxiv.org/abs/2601.15404</link><description>arXiv:2601.15404v1 Announce Type: new 
Abstract: We introduce a new family of polar-like codes, called Partially Polarized Polar (PPP) codes. PPP codes are constructed from conventional polar codes by selectively pruning polarization kernels, thereby modifying the synthesized bit-channel capacities to ensure a guaranteed number of non-frozen bits available early in decoding. These early-access information bits enable more effective early termination, which is particularly valuable for blind decoding in downlink control channels, where user equipment (UE) must process multiple candidates, many of which carry no valid control information. Our results show that PPP codes offer substantial performance gains over conventional polar codes, particularly at larger block lengths where hardware limitations restrict straightforward scaling. Compared with existing methods such as aggregation or segmentation, PPP codes achieve higher efficiency without the need for additional hardware support. Finally, we propose several frozen-bitmap design strategies tailored to PPP codes.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15404v1</guid></item><item><title>[cs updates on arXiv.org] Evaluating Multimodal Large Language Models for Heterogeneous Face Recognition</title><link>https://arxiv.org/abs/2601.15406</link><description>arXiv:2601.15406v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) have recently demonstrated strong performance on a wide range of vision-language tasks, raising interest in their potential use for biometric applications. In this paper, we conduct a systematic evaluation of state-of-the-art MLLMs for heterogeneous face recognition (HFR), where enrollment and probe images are from different sensing modalities, including visual (VIS), near infrared (NIR), short-wave infrared (SWIR), and thermal camera. We benchmark multiple open-source MLLMs across several cross-modality scenarios, including VIS-NIR, VIS-SWIR, and VIS-THERMAL face recognition. The recognition performance of MLLMs is evaluated using biometric protocols and based on different metrics, including Acquire Rate, Equal Error Rate (EER), and True Accept Rate (TAR). Our results reveal substantial performance gaps between MLLMs and classical face recognition systems, particularly under challenging cross-spectral conditions, in spite of recent advances in MLLMs. Our findings highlight the limitations of current MLLMs for HFR and also the importance of rigorous biometric evaluation when considering their deployment in face recognition systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15406v1</guid></item><item><title>[cs updates on arXiv.org] CURE: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation</title><link>https://arxiv.org/abs/2601.15408</link><description>arXiv:2601.15408v1 Announce Type: new 
Abstract: Medical vision-language models can automate the generation of radiology reports but struggle with accurate visual grounding and factual consistency. Existing models often misalign textual findings with visual evidence, leading to unreliable or weakly grounded predictions. We present CURE, an error-aware curriculum learning framework that improves grounding and report quality without any additional data. CURE fine-tunes a multimodal instructional model on phrase grounding, grounded report generation, and anatomy-grounded report generation using public datasets. The method dynamically adjusts sampling based on model performance, emphasizing harder samples to improve spatial and textual alignment. CURE improves grounding accuracy by +0.37 IoU, boosts report quality by +0.188 CXRFEScore, and reduces hallucinations by 18.6%. CURE is a data-efficient framework that enhances both grounding accuracy and report reliability. Code is available at https://github.com/PabloMessina/CURE and model weights at https://huggingface.co/pamessina/medgemma-4b-it-cure</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15408v1</guid></item><item><title>[cs updates on arXiv.org] DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction</title><link>https://arxiv.org/abs/2601.15416</link><description>arXiv:2601.15416v1 Announce Type: new 
Abstract: Sparse-view Cone-Beam Computed Tomography reconstruction from limited X-ray projections remains a challenging problem in medical imaging due to the inherent undersampling of fine-grained anatomical details, which correspond to high-frequency components. Conventional CNN-based methods often struggle to recover these fine structures, as they are typically biased toward learning low-frequency information. To address this challenge, this paper presents DuFal (Dual-Frequency-Aware Learning), a novel framework that integrates frequency-domain and spatial-domain processing via a dual-path architecture. The core innovation lies in our High-Local Factorized Fourier Neural Operator, which comprises two complementary branches: a Global High-Frequency Enhanced Fourier Neural Operator that captures global frequency patterns and a Local High-Frequency Enhanced Fourier Neural Operator that processes spatially partitioned patches to preserve spatial locality that might be lost in global frequency analysis. To improve efficiency, we design a Spectral-Channel Factorization scheme that reduces the Fourier Neural Operator parameter count. We also design a Cross-Attention Frequency Fusion module to integrate spatial and frequency features effectively. The fused features are then decoded through a Feature Decoder to produce projection representations, which are subsequently processed through an Intensity Field Decoding pipeline to reconstruct a final Computed Tomography volume. Experimental results on the LUNA16 and ToothFairy datasets demonstrate that DuFal significantly outperforms existing state-of-the-art methods in preserving high-frequency anatomical features, particularly under extremely sparse-view settings.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15416v1</guid></item><item><title>[cs updates on arXiv.org] Ambient Dataloops: Generative Models for Dataset Refinement</title><link>https://arxiv.org/abs/2601.15417</link><description>arXiv:2601.15417v1 Announce Type: new 
Abstract: We propose Ambient Dataloops, an iterative framework for refining datasets that makes it easier for diffusion models to learn the underlying data distribution. Modern datasets contain samples of highly varying quality, and training directly on such heterogeneous data often yields suboptimal models. We propose a dataset-model co-evolution process; at each iteration of our method, the dataset becomes progressively higher quality, and the model improves accordingly. To avoid destructive self-consuming loops, at each generation, we treat the synthetically improved samples as noisy, but at a slightly lower noisy level than the previous iteration, and we use Ambient Diffusion techniques for learning under corruption. Empirically, Ambient Dataloops achieve state-of-the-art performance in unconditional and text-conditional image generation and de novo protein design. We further provide a theoretical justification for the proposed framework that captures the benefits of the data looping procedure.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15417v1</guid></item><item><title>[cs updates on arXiv.org] Learning a Unified Latent Space for Cross-Embodiment Robot Control</title><link>https://arxiv.org/abs/2601.15419</link><description>arXiv:2601.15419v1 Announce Type: new 
Abstract: We present a scalable framework for cross-embodiment humanoid robot control by learning a shared latent representation that unifies motion across humans and diverse humanoid platforms, including single-arm, dual-arm, and legged humanoid robots. Our method proceeds in two stages: first, we construct a decoupled latent space that captures localized motion patterns across different body parts using contrastive learning, enabling accurate and flexible motion retargeting even across robots with diverse morphologies. To enhance alignment between embodiments, we introduce tailored similarity metrics that combine joint rotation and end-effector positioning for critical segments, such as arms. Then, we train a goal-conditioned control policy directly within this latent space using only human data. Leveraging a conditional variational autoencoder, our policy learns to predict latent space displacements guided by intended goal directions. We show that the trained policy can be directly deployed on multiple robots without any adaptation. Furthermore, our method supports the efficient addition of new robots to the latent space by learning only a lightweight, robot-specific embedding layer. The learned latent policies can also be directly applied to the new robots. Experimental results demonstrate that our approach enables robust, scalable, and embodiment-agnostic robot control across a wide range of humanoid platforms.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15419v1</guid></item><item><title>[cs updates on arXiv.org] Problems with fixpoints of polynomials of polynomials</title><link>https://arxiv.org/abs/2601.15420</link><description>arXiv:2601.15420v1 Announce Type: new 
Abstract: Motivated by applications in computable analysis, we study fixpoints of certain endofunctors over categories of containers. More specifically, we focus on fibred endofunctors over the fibrewise opposite of the codomain fibration that can be themselves be represented by families of polynomial endofunctors. In this setting, we show how to compute initial algebras, terminal coalgebras and another kind of fixpoint $\zeta$. We then explore a number of examples of derived operators inspired by Weihrauch complexity and the usual construction of the free polynomial monad.
  We introduce $\zeta$-expressions as the syntax of $\mu$-bicomplete categories, extended with $\zeta$-binders and parallel products, which thus have a natural denotation in containers. By interpreting certain $\zeta$-expressions in a category of type 2 computable maps, we are able to capture a number of meaningful Weihrauch degrees, ranging from closed choice on $\{0, 1\}$ to determinacy of infinite parity games, via an "answerable part" operator.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15420v1</guid></item><item><title>[cs updates on arXiv.org] Lattice: A Confidence-Gated Hybrid System for Uncertainty-Aware Sequential Prediction with Behavioral Archetypes</title><link>https://arxiv.org/abs/2601.15423</link><description>arXiv:2601.15423v1 Announce Type: new 
Abstract: We introduce Lattice, a hybrid sequential prediction system that conditionally activates learned behavioral structure using binary confidence gating. The system clusters behavior windows into behavioral archetypes and uses binary confidence gating to activate archetype-based scoring only when confidence exceeds a threshold, falling back to baseline predictions when uncertain. We validate Lattice on recommendation systems (MovieLens), scientific time-series (LIGO), and financial markets, using LSTM and transformer backbones. On MovieLens with LSTM, Lattice achieves +31.9% improvement over LSTM baseline in HR@10 (p &lt; 3.29 x 10^-25, 30 seeds), outperforming transformer baselines by 109.4% over SASRec and 218.6% over BERT4Rec. On LIGO and financial data, the system correctly refuses archetype activation when distribution shift occurs - a successful outcome demonstrating confidence gating prevents false activation. On transformer backbones, Lattice provides 0.0% improvement (neutral, no degradation), gracefully deferring when structure is already present. This bidirectional validation - activating when patterns apply, refusing when they don't, and deferring when redundant - supports confidence gating as a promising architectural principle for managing epistemic uncertainty in safety-critical applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15423v1</guid></item><item><title>[cs updates on arXiv.org] Domain-Specific Knowledge Graphs in RAG-Enhanced Healthcare LLMs</title><link>https://arxiv.org/abs/2601.15429</link><description>arXiv:2601.15429v1 Announce Type: new 
Abstract: Large Language Models (LLMs) generate fluent answers but can struggle with trustworthy, domain-specific reasoning. We evaluate whether domain knowledge graphs (KGs) improve Retrieval-Augmented Generation (RAG) for healthcare by constructing three PubMed-derived graphs: $\mathbb{G}_1$ (T2DM), $\mathbb{G}_2$ (Alzheimer's disease), and $\mathbb{G}_3$ (AD+T2DM). We design two probes: Probe 1 targets merged AD T2DM knowledge, while Probe 2 targets the intersection of $\mathbb{G}_1$ and $\mathbb{G}_2$. Seven instruction-tuned LLMs are tested across retrieval sources {No-RAG, $\mathbb{G}_1$, $\mathbb{G}_2$, $\mathbb{G}_1$ + $\mathbb{G}_2$, $\mathbb{G}_3$, $\mathbb{G}_1$+$\mathbb{G}_2$ + $\mathbb{G}_3$} and three decoding temperatures. Results show that scope alignment between probe and KG is decisive: precise, scope-matched retrieval (notably $\mathbb{G}_2$) yields the most consistent gains, whereas indiscriminate graph unions often introduce distractors that reduce accuracy. Larger models frequently match or exceed KG-RAG with a No-RAG baseline on Probe 1, indicating strong parametric priors, whereas smaller/mid-sized models benefit more from well-scoped retrieval. Temperature plays a secondary role; higher values rarely help. We conclude that precision-first, scope-matched KG-RAG is preferable to breadth-first unions, and we outline practical guidelines for graph selection, model sizing, and retrieval/reranking. Code and Data available here - https://github.com/sydneyanuyah/RAGComparison</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15429v1</guid></item><item><title>[cs updates on arXiv.org] SplatBus: A Gaussian Splatting Viewer Framework via GPU Interprocess Communication</title><link>https://arxiv.org/abs/2601.15431</link><description>arXiv:2601.15431v1 Announce Type: new 
Abstract: Radiance field-based rendering methods have attracted significant interest from the computer vision and computer graphics communities. They enable high-fidelity rendering with complex real-world lighting effects, but at the cost of high rendering time. 3D Gaussian Splatting solves this issue with a rasterisation-based approach for real-time rendering, enabling applications such as autonomous driving, robotics, virtual reality, and extended reality. However, current 3DGS implementations are difficult to integrate into traditional mesh-based rendering pipelines, which is a common use case for interactive applications and artistic exploration. To address this limitation, this software solution uses Nvidia's interprocess communication (IPC) APIs to easily integrate into implementations and allow the results to be viewed in external clients such as Unity, Blender, Unreal Engine, and OpenGL viewers. The code is available at https://github.com/RockyXu66/splatbus.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15431v1</guid></item><item><title>[cs updates on arXiv.org] MEDFORD in a Box: Improvements and Future Directions for a Metadata Description Language</title><link>https://arxiv.org/abs/2601.15432</link><description>arXiv:2601.15432v1 Announce Type: new 
Abstract: Scientific research metadata is vital to ensure the validity, reusability, and cost-effectiveness of research efforts. The MEDFORD metadata language was previously introduced to simplify the process of writing and maintaining metadata for non-programmers. However, barriers to entry and usability remain, including limited automatic validation, difficulty of data transport, and user unfamiliarity with text file editing. To address these issues, we introduce MEDFORD-in-a-Box (MIAB), a documentation ecosystem to facilitate researcher adoption and earlier metadata capture. MIAB contains many improvements, including an updated MEDFORD parser with expanded validation routines and BagIt export capability. MIAB also includes an improved VS Code extension that supports these changes through a visual IDE. By simplifying metadata generation, this new tool supports the creation of correct, consistent, and reusable metadata, ultimately improving research reproducibility.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15432v1</guid></item><item><title>[cs updates on arXiv.org] ManuRAG: Multi-modal Retrieval Augmented Generation for Manufacturing Question Answering</title><link>https://arxiv.org/abs/2601.15434</link><description>arXiv:2601.15434v1 Announce Type: new 
Abstract: The evolution of digital manufacturing requires intelligent Question Answering (QA) systems that can seamlessly integrate and analyze complex multi-modal data, such as text, images, formulas, and tables. Conventional Retrieval Augmented Generation (RAG) methods often fall short in handling this complexity, resulting in subpar performance. We introduce ManuRAG, an innovative multi-modal RAG framework designed for manufacturing QA, incorporating specialized techniques to improve answer accuracy, reliability, and interpretability. To benchmark performance, we evaluate ManuRAG on three datasets comprising a total of 1,515 QA pairs, corresponding to mathematical, multiple-choice, and review-based questions in manufacturing principles and practices. Experimental results show that ManuRAG consistently outperforms existing methods across all evaluated datasets. Furthermore, ManuRAG's adaptable design makes it applicable to other domains, including law, healthcare, and finance, positioning it as a versatile tool for domain-specific QA.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15434v1</guid></item><item><title>[cs updates on arXiv.org] Not Your Typical Sycophant: The Elusive Nature of Sycophancy in Large Language Models</title><link>https://arxiv.org/abs/2601.15436</link><description>arXiv:2601.15436v1 Announce Type: new 
Abstract: We propose a novel way to evaluate sycophancy of LLMs in a direct and neutral way, mitigating various forms of uncontrolled bias, noise, or manipulative language, deliberately injected to prompts in prior works. A key novelty in our approach is the use of LLM-as-a-judge, evaluation of sycophancy as a zero-sum game in a bet setting. Under this framework, sycophancy serves one individual (the user) while explicitly incurring cost on another. Comparing four leading models - Gemini 2.5 Pro, ChatGpt 4o, Mistral-Large-Instruct-2411, and Claude Sonnet 3.7 - we find that while all models exhibit sycophantic tendencies in the common setting, in which sycophancy is self-serving to the user and incurs no cost on others, Claude and Mistral exhibit "moral remorse" and over-compensate for their sycophancy in case it explicitly harms a third party. Additionally, we observed that all models are biased toward the answer proposed last. Crucially, we find that these two phenomena are not independent; sycophancy and recency bias interact to produce `constructive interference' effect, where the tendency to agree with the user is exacerbated when the user's opinion is presented last.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15436v1</guid></item><item><title>[cs updates on arXiv.org] Exploring Implicit Perspectives on Autism in Large Language Models Through Multi-Agent Simulations</title><link>https://arxiv.org/abs/2601.15437</link><description>arXiv:2601.15437v1 Announce Type: new 
Abstract: Large Language Models (LLMs) like ChatGPT offer potential support for autistic people, but this potential requires understanding the implicit perspectives these models might carry, including their biases and assumptions about autism. Moving beyond single-agent prompting, we utilized LLM-based multi-agent systems to investigate complex social scenarios involving autistic and non-autistic agents. In our study, agents engaged in group-task conversations and answered structured interview questions, which we analyzed to examine ChatGPT's biases and how it conceptualizes autism. We found that ChatGPT assumes autistic people are socially dependent, which may affect how it interacts with autistic users or conveys information about autism. To address these challenges, we propose adopting the double empathy problem, which reframes communication breakdowns as a mutual challenge. We describe how future LLMs could address the biases we observed and improve interactions involving autistic people by incorporating the double empathy problem into their design.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15437v1</guid></item><item><title>[cs updates on arXiv.org] CASL: Concept-Aligned Sparse Latents for Interpreting Diffusion Models</title><link>https://arxiv.org/abs/2601.15441</link><description>arXiv:2601.15441v1 Announce Type: new 
Abstract: Internal activations of diffusion models encode rich semantic information, but interpreting such representations remains challenging. While Sparse Autoencoders (SAEs) have shown promise in disentangling latent representations, existing SAE-based methods for diffusion model understanding rely on unsupervised approaches that fail to align sparse features with human-understandable concepts. This limits their ability to provide reliable semantic control over generated images. We introduce CASL (Concept-Aligned Sparse Latents), a supervised framework that aligns sparse latent dimensions of diffusion models with semantic concepts. CASL first trains an SAE on frozen U-Net activations to obtain disentangled latent representations, and then learns a lightweight linear mapping that associates each concept with a small set of relevant latent dimensions. To validate the semantic meaning of these aligned directions, we propose CASL-Steer, a controlled latent intervention that shifts activations along the learned concept axis. Unlike editing methods, CASL-Steer is used solely as a causal probe to reveal how concept-aligned latents influence generated content. We further introduce the Editing Precision Ratio (EPR), a metric that jointly measures concept specificity and the preservation of unrelated attributes. Experiments show that our method achieves superior editing precision and interpretability compared to existing approaches. To the best of our knowledge, this is the first work to achieve supervised alignment between latent representations and semantic concepts in diffusion models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15441v1</guid></item><item><title>[cs updates on arXiv.org] A tensor network formalism for neuro-symbolic AI</title><link>https://arxiv.org/abs/2601.15442</link><description>arXiv:2601.15442v1 Announce Type: new 
Abstract: The unification of neural and symbolic approaches to artificial intelligence remains a central open challenge. In this work, we introduce a tensor network formalism, which captures sparsity principles originating in the different approaches in tensor decompositions. In particular, we describe a basis encoding scheme for functions and model neural decompositions as tensor decompositions. The proposed formalism can be applied to represent logical formulas and probability distributions as structured tensor decompositions. This unified treatment identifies tensor network contractions as a fundamental inference class and formulates efficiently scaling reasoning algorithms, originating from probability theory and propositional logic, as contraction message passing schemes. The framework enables the definition and training of hybrid logical and probabilistic models, which we call Hybrid Logic Network. The theoretical concepts are accompanied by the python library tnreason, which enables the implementation and practical use of the proposed architectures.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15442v1</guid></item><item><title>[cs updates on arXiv.org] Reflexis: Supporting Reflexivity and Rigor in Collaborative Qualitative Analysis through Design for Deliberation</title><link>https://arxiv.org/abs/2601.15445</link><description>arXiv:2601.15445v1 Announce Type: new 
Abstract: Reflexive Thematic Analysis (RTA) is a critical method for generating deep interpretive insights. Yet its core tenets, including researcher reflexivity, tangible analytical evolution, and productive disagreement, are often poorly supported by software tools that prioritize speed and consensus over interpretive depth. To address this gap, we introduce Reflexis, a collaborative workspace that centers these practices. It supports reflexivity by integrating in-situ reflection prompts, makes code evolution transparent and tangible, and scaffolds collaborative interpretation by turning differences into productive, positionality-aware dialogue. Results from our paired-analyst study (N=12) indicate that Reflexis encouraged participants toward more granular reflection and reframed disagreements as productive conversations. The evaluation also surfaced key design tensions, including a desire for higher-level, networked memos and more user control over the timing of proactive alerts. Reflexis contributes a design framework for tools that prioritize rigor and transparency to support deep, collaborative interpretation in an age of automation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15445v1</guid></item><item><title>[cs updates on arXiv.org] DevPrompt: Deviation-Based Prompt Learning for One-Normal ShotImage Anomaly Detection</title><link>https://arxiv.org/abs/2601.15453</link><description>arXiv:2601.15453v1 Announce Type: new 
Abstract: Few-normal shot anomaly detection (FNSAD) aims to detect abnormal regions in images using only a few normal training samples, making the task highly challenging due to limited supervision and the diversity of potential defects. Recent approaches leverage vision-language models such as CLIP with prompt-based learning to align image and text features. However, existing methods often exhibit weak discriminability between normal and abnormal prompts and lack principled scoring mechanisms for patch-level anomalies. We propose a deviation-guided prompt learning framework that integrates the semantic power of vision-language models with the statistical reliability of deviation-based scoring. Specifically, we replace fixed prompt prefixes with learnable context vectors shared across normal and abnormal prompts, while anomaly-specific suffix tokens enable class-aware alignment. To enhance separability, we introduce a deviation loss with Top-K Multiple Instance Learning (MIL), modeling patch-level features as Gaussian deviations from the normal distribution. This allows the network to assign higher anomaly scores to patches with statistically significant deviations, improving localization and interpretability. Experiments on the MVTecAD and VISA benchmarks demonstrate superior pixel-level detection performance compared to PromptAD and other baselines. Ablation studies further validate the effectiveness of learnable prompts, deviation-based scoring, and the Top-K MIL strategy.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15453v1</guid></item><item><title>[cs updates on arXiv.org] Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering</title><link>https://arxiv.org/abs/2601.15457</link><description>arXiv:2601.15457v1 Announce Type: new 
Abstract: The integration of Large Language Models (LLMs) into the public health policy sector offers a transformative approach to navigating the vast repositories of regulatory guidance maintained by agencies such as the Centers for Disease Control and Prevention (CDC). However, the propensity for LLMs to generate hallucinations, defined as plausible but factually incorrect assertions, presents a critical barrier to the adoption of these technologies in high-stakes environments where information integrity is non-negotiable. This empirical evaluation explores the effectiveness of Retrieval-Augmented Generation (RAG) architectures in mitigating these risks by grounding generative outputs in authoritative document context. Specifically, this study compares a baseline Vanilla LLM against Basic RAG and Advanced RAG pipelines utilizing cross-encoder re-ranking. The experimental framework employs a Mistral-7B-Instruct-v0.2 model and an all-MiniLM-L6-v2 embedding model to process a corpus of official CDC policy analytical frameworks and guidance documents. The analysis measures the impact of two distinct chunking strategies, recursive character-based and token-based semantic splitting, on system accuracy, measured through faithfulness and relevance scores across a curated set of complex policy scenarios. Quantitative findings indicate that while Basic RAG architectures provide a substantial improvement in faithfulness (0.621) over Vanilla baselines (0.347), the Advanced RAG configuration achieves a superior faithfulness average of 0.797. These results demonstrate that two-stage retrieval mechanisms are essential for achieving the precision required for domain-specific policy question answering, though structural constraints in document segmentation remain a significant bottleneck for multi-step reasoning tasks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15457v1</guid></item><item><title>[cs updates on arXiv.org] MuSAlS: A Fast Multiple Sequence Alignment Approach Using Hierarchical Clustering</title><link>https://arxiv.org/abs/2601.15458</link><description>arXiv:2601.15458v1 Announce Type: new 
Abstract: Motivation: The multiple sequence alignment (MSA) problem has been extensively studied, with numerous approaches developed over recent years. With the rapid growth of sequence data, there is an increasing need for fast and accurate MSA tools that scale effectively to large datasets. Building on our previous work on CLAM, we are able to use exact dynamic programming (Needleman-Wunsch) while scaling to large datasets. We introduce MuSAlS (Multiple Sequence Alignment at Scale), a fast and scalable de novo MSA aligner. MuSAlS uses hierarchical clustering to construct a guide tree based on the Levenshtein distance metric, enabling efficient and accurate alignment through a bottom-up approach. Results: MuSAlS achieves competitive accuracy compared to state-of-the-art methods while significantly improving runtime performance. This makes it a valuable tool for researchers analyzing large-scale genomic and metagenomic datasets, addressing the growing demand for scalable bioinformatics solutions. Availability and Implementation: MuSAlS is implemented in the Rust programming language, and available at https://github.com/URI-ABD/clam</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15458v1</guid></item><item><title>[cs updates on arXiv.org] Neural Collision Detection for Multi-arm Laparoscopy Surgical Robots Through Learning-from-Simulation</title><link>https://arxiv.org/abs/2601.15459</link><description>arXiv:2601.15459v1 Announce Type: new 
Abstract: This study presents an integrated framework for enhancing the safety and operational efficiency of robotic arms in laparoscopic surgery by addressing key challenges in collision detection and minimum distance estimation. By combining analytical modeling, real-time simulation, and machine learning, the framework offers a robust solution for ensuring safe robotic operations. An analytical model was developed to estimate the minimum distances between robotic arms based on their joint configurations, offering precise theoretical calculations that serve as both a validation tool and a benchmark. To complement this, a 3D simulation environment was created to model two 7-DOF Kinova robotic arms, generating a diverse dataset of configurations for collision detection and distance estimation. Using these insights, a deep neural network model was trained with joint actuators of robot arms and relative positions as inputs, achieving a mean absolute error of 282.2 mm and an R-squared value of 0.85. The close alignment between predicted and actual distances highlights the network's accuracy and its ability to generalize spatial relationships. This work demonstrates the effectiveness of combining analytical precision with machine learning algorithms to enhance the precision and reliability of robotic systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15459v1</guid></item><item><title>[cs updates on arXiv.org] Rank-metric codes over arbitrary fields: Bounds and constructions</title><link>https://arxiv.org/abs/2601.15464</link><description>arXiv:2601.15464v1 Announce Type: new 
Abstract: Rank-metric codes, defined as sets of matrices over a finite field with the rank distance, have gained significant attention due to their applications in network coding and connections to diverse mathematical areas. Initially studied by Delsarte in 1978 and later rediscovered by Gabidulin, these codes have become a central topic in coding theory. This paper surveys the development and mathematical foundations, in particular, regarding bounds and constructions of rank-metric codes, emphasizing their extension beyond finite fields to more general settings. We examine Singleton-like bounds on code parameters, demonstrating their sharpness in finite field cases and contrasting this with contexts where the bounds are not tight. Furthermore, we discuss constructions of Maximum Rank Distance (MRD) codes over fields with cyclic Galois extensions and the relationship between linear rank-metric codes with systems and evasive subspaces. The paper also reviews results for algebraically closed fields and real numbers, previously appearing in the context of topology and measure theory. We conclude by proposing future research directions, including conjectures on MRD code existence and the exploration of rank-metric codes over various field extensions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15464v1</guid></item><item><title>[cs updates on arXiv.org] Cloning the Self for Mental Well-Being: A Framework for Designing Safe and Therapeutic Self-Clone Chatbots</title><link>https://arxiv.org/abs/2601.15465</link><description>arXiv:2601.15465v1 Announce Type: new 
Abstract: As digital tools increasingly mediate mental health care, self-clone chatbots can offer a uniquely novel approach to intra-personal exploration and self-derived support. Trained to replicate users' conversational patterns, self-clones allow users to talk to themselves through their digital replicas. Despite the promises, these systems may carry risks around identity confusion, negative reinforcement, and blurred user agency. Through interviews with 16 mental health professionals and 6 general users, we aim to uncover tensions and design opportunities in this emerging space to guide responsible self-clone design. Our analysis produces a design framework organized around three priorities: (1) defining goals and grounding the approach in existing therapeutic models, (2) design dimensions including the self-clone persona and user-clone relationship dynamics, and (3) considerations for minimizing potential emotional and ethical harms. This framework contributes an interdisciplinary foundation for designing self-clone chatbots as AI-mediated self-interaction tools that are emotionally and ethically attuned in mental health contexts.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15465v1</guid></item><item><title>[cs updates on arXiv.org] Shape of You: Implications of Social Context and Avatar Body Shape on Relatedness, Emotions, and Performance in a Virtual Reality Workout</title><link>https://arxiv.org/abs/2601.15466</link><description>arXiv:2601.15466v1 Announce Type: new 
Abstract: It is obvious that emotions are causal variables of motivation, as they elicit states, forces and energies that trigger and guide labor behavior. Thus, a motivational tension that is not informed by needs alone, but also by emotions, intention, goals and means to achieve them is therefore generated within the mental, emotional and physical plane. Based on Montserrat's opinion (2004: 131), that "to motivate means, above all, to move and to transmit an emotion", we will undertake to identify the mutual influences between emotions and motivation. The main objectives of this article are to display a summary of the theories and definitions about emotions and to explore the links between emotions and motivation. Although interconnected, emotions and motivation can be contemplated from a double perspective: (1) emotions influence motivation and (2) motivation influences emotions. Moreover, we will consider motivation from three dimensions: (1) cognitive, (2) affective and (3) volitional. The ultimate purpose of this article is to issue a warning as to the importance of the emotional side of motivation. An important part in implementing such insight is to be played by managers (and by employees, also), who should develop the skills and know-how needed to keep a well-balanced emotional climate that effectively favors the maximization of individual and group motivation at the workplace.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15466v1</guid></item><item><title>[cs updates on arXiv.org] Learning from Synthetic Data: Limitations of ERM</title><link>https://arxiv.org/abs/2601.15468</link><description>arXiv:2601.15468v1 Announce Type: new 
Abstract: The prevalence and low cost of LLMs have led to a rise of synthetic content. From review sites to court documents, ``natural'' content has been contaminated by data points that appear similar to natural data, but are in fact LLM-generated. In this work we revisit fundamental learning theory questions in this, now ubiquitous, setting. We model this scenario as a sequence of learning tasks where the input is a mix of natural and synthetic data, and the learning algorithms are oblivious to the origin of any individual example.
  We study the possibilities and limitations of ERM in this setting. For the problem of estimating the mean of an arbitrary $d$-dimensional distribution, we find that while ERM converges to the true mean, it is outperformed by an algorithm that assigns non-uniform weights to examples from different generations of data. For the PAC learning setting, the disparity is even more stark. We find that ERM does not always converge to the true concept, echoing the model collapse literature. However, we show there are algorithms capable of learning the correct hypothesis for arbitrary VC classes and arbitrary amounts of contamination.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15468v1</guid></item><item><title>[cs updates on arXiv.org] Nested and outlier embeddings into trees</title><link>https://arxiv.org/abs/2601.15470</link><description>arXiv:2601.15470v1 Announce Type: new 
Abstract: In this paper, we consider outlier embeddings into HSTs and ultrametrics. In particular, for $(X,d)$, let $k$ be the size of the smallest subset of $X$ such that all but that subset (i.e. the ``outlier set'') can be probabilistically embedded into the space of HSTs with expected distortion at most $c$. Our primary result is showing that there exists an efficient algorithm that takes in $(X,d)$ and a target distortion $c$ and samples from a probabilistic embedding with at most $O(\frac k \epsilon \log^2k)$ outliers and distortion at most $(32+\epsilon)c$, for any $\epsilon&gt;0$. This leads to better instance-specific approximations for certain instances of the buy-at-bulk and dial-a-ride problems, whose current best approximation algorithms go through HST embeddings.
  In order to facilitate our results, we largely focus on the concept of compositions of nested embeddings introduced by [Chawla and Sheridan 2024]. A nested embedding is a composition of two embeddings of a metric space $(X,d)$ -- a low distortion embedding of a subset $S$ of nodes, and a higher distortion embedding of the entire metric. The composition is a single embedding that preserves the low distortion over $S$ and does not increase distortion over the remaining points by much. In this paper, we expand this concept from the setting of deterministic embeddings to the setting of probabilistic embeddings. We show how to find good nested compositions of embeddings into HSTs, and combine this with an approximation algorithm of [Munagala et al. 2023] to obtain our results.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15470v1</guid></item><item><title>[cs updates on arXiv.org] Put Your Muscle Into It: Introducing XEM2, a Novel Approach for Monitoring Exertion in Stationary Physical Exercises Leveraging Muscle Work</title><link>https://arxiv.org/abs/2601.15472</link><description>arXiv:2601.15472v1 Announce Type: new 
Abstract: We present a novel system for camera-based measurement and visualization of muscle work based on the Hill-Type-Muscle-Model: the exercise exertion muscle-work monitor (\textit{XEM}$^{2}$). Our aim is to complement and, thus, address issues of established measurement techniques that offer imprecise data for non-uniform movements (burned calories) or provide limited information on strain across different body parts (self-perception scales). We validate the reliability of XEM's measurements through a technical evaluation of ten participants and five exercises. Further, we assess the acceptance, usefulness, benefits, and opportunities of \textit{XEM}$^{2}$ in an empirical user study. Our results show that \textit{XEM}$^{2}$ provides reliable values of muscle work and supports participants in understanding their workout while also providing reliable information about perceived exertion per muscle group. With this paper, we introduce a novel system capable of measuring and visualizing exertion for single muscle groups, which has the potential to improve exercise monitoring to prevent unbalanced workouts.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15472v1</guid></item><item><title>[cs updates on arXiv.org] Panther: Faster and Cheaper Computations with Randomized Numerical Linear Algebra</title><link>https://arxiv.org/abs/2601.15473</link><description>arXiv:2601.15473v1 Announce Type: new 
Abstract: Training modern deep learning models is increasingly constrained by GPU memory and compute limits. While Randomized Numerical Linear Algebra (RandNLA) offers proven techniques to compress these models, the lack of a unified, production-grade library prevents widely adopting these methods. We present Panther, a PyTorch-compatible library that consolidates established RandNLA algorithms into a single high-performance framework. Panther engineers efficient, drop-in replacements for standard components including sketched linear layers, 2D convolution, multi-head attention, and randomized matrix decompositions (such as pivoted CholeskyQR). By implementing a custom C++/CUDA backend (pawX), Panther provides an optimized implementation that can run on both CPUs and GPUs. We demonstrate the effectiveness of RandNLA techniques and Panther's ease of adoption. By replacing standard PyTorch linear layers with Panther layers (requiring only a few lines of code) we achieve significant memory savings (up to 75%) on BERT while maintaining comparable loss. Source code is available (MIT License) at https://github.com/FahdSeddik/panther, along with demonstration video at https://youtu.be/7M3RQb4KWxs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15473v1</guid></item><item><title>[cs updates on arXiv.org] Multi-Targeted Graph Backdoor Attack</title><link>https://arxiv.org/abs/2601.15474</link><description>arXiv:2601.15474v1 Announce Type: new 
Abstract: Graph neural network (GNN) have demonstrated exceptional performance in solving critical problems across diverse domains yet remain susceptible to backdoor attacks. Existing studies on backdoor attack for graph classification are limited to single target attack using subgraph replacement based mechanism where the attacker implants only one trigger into the GNN model. In this paper, we introduce the first multi-targeted backdoor attack for graph classification task, where multiple triggers simultaneously redirect predictions to different target labels. Instead of subgraph replacement, we propose subgraph injection which preserves the structure of the original graphs while poisoning the clean graphs. Extensive experiments demonstrate the efficacy of our approach, where our attack achieves high attack success rates for all target labels with minimal impact on the clean accuracy. Experimental results on five dataset demonstrate the superior performance of our attack framework compared to the conventional subgraph replacement-based attack. Our analysis on four GNN models confirms the generalization capability of our attack which is effective regardless of the GNN model architectures and training parameters settings. We further investigate the impact of the attack design parameters including injection methods, number of connections, trigger sizes, trigger edge density and poisoning ratios. Additionally, our evaluation against state-of-the-art defenses (randomized smoothing and fine-pruning) demonstrates the robustness of our proposed multi-target attacks. This work highlights the GNN vulnerability against multi-targeted backdoor attack in graph classification task. Our source codes will be available at https://github.com/SiSL-URI/Multi-Targeted-Graph-Backdoor-Attack.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15474v1</guid></item><item><title>[cs updates on arXiv.org] Seeing through Light and Darkness: Sensor-Physics Grounded Deblurring HDR NeRF from Single-Exposure Images and Events</title><link>https://arxiv.org/abs/2601.15475</link><description>arXiv:2601.15475v1 Announce Type: new 
Abstract: Novel view synthesis from low dynamic range (LDR) blurry images, which are common in the wild, struggles to recover high dynamic range (HDR) and sharp 3D representations in extreme lighting conditions. Although existing methods employ event data to address this issue, they ignore the sensor-physics mismatches between the camera output and physical world radiance, resulting in suboptimal HDR and deblurring results. To cope with this problem, we propose a unified sensor-physics grounded NeRF framework for sharp HDR novel view synthesis from single-exposure blurry LDR images and corresponding events. We employ NeRF to directly represent the actual radiance of the 3D scene in the HDR domain and model raw HDR scene rays hitting the sensor pixels as in the physical world. A pixel-wise RGB mapping field is introduced to align the above rendered pixel values with the sensor-recorded LDR pixel values of the input images. A novel event mapping field is also designed to bridge the physical scene dynamics and actual event sensor output. The two mapping fields are jointly optimized with the NeRF network, leveraging the spatial and temporal dynamic information in events to enhance the sharp HDR 3D representation learning. Experiments on the collected and public datasets demonstrate that our method can achieve state-of-the-art deblurring HDR novel view synthesis results with single-exposure blurry LDR images and corresponding events.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15475v1</guid></item><item><title>[cs updates on arXiv.org] Reliability by design: quantifying and eliminating fabrication risk in LLMs. From generative to consultative AI: a comparative analysis in the legal domain and lessons for high-stakes knowledge bases</title><link>https://arxiv.org/abs/2601.15476</link><description>arXiv:2601.15476v1 Announce Type: new 
Abstract: This paper examines how to make large language models reliable for high-stakes legal work by reducing hallucinations. It distinguishes three AI paradigms: (1) standalone generative models ("creative oracle"), (2) basic retrieval-augmented systems ("expert archivist"), and (3) an advanced, end-to-end optimized RAG system ("rigorous archivist"). The authors introduce two reliability metrics -False Citation Rate (FCR) and Fabricated Fact Rate (FFR)- and evaluate 2,700 judicial-style answers from 12 LLMs across 75 legal tasks using expert, double-blind review. Results show that standalone models are unsuitable for professional use (FCR above 30%), while basic RAG greatly reduces errors but still leaves notable misgrounding. Advanced RAG, using techniques such as embedding fine-tuning, re-ranking, and self-correction, reduces fabrication to negligible levels (below 0.2%). The study concludes that trustworthy legal AI requires rigor-focused, retrieval-based architectures emphasizing verification and traceability, and provides an evaluation framework applicable to other high-risk domains.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15476v1</guid></item><item><title>[cs updates on arXiv.org] Equal-Pay Contracts</title><link>https://arxiv.org/abs/2601.15478</link><description>arXiv:2601.15478v1 Announce Type: new 
Abstract: We study multi-agent contract design, where a principal incentivizes a team of agents to take costly actions that jointly determine the project success via a combinatorial reward function. While prior work largely focuses on unconstrained contracts that allow heterogeneous payments across agents, many real-world environments limit payment dispersion. Motivated by this, we study equal-pay contracts, where all agents receive identical payments. Our results also extend to nearly-equal-pay contracts where any two payments are identical up to a constant factor.
  We provide both algorithmic and hardness results across a broad hierarchy of reward functions, under both binary and combinatorial action models. While we focus on equal-pay contracts, our analysis also yields new insights into unconstrained contract design, and resolves two important open problems. On the positive side, we design polynomial-time O(1)-approximation algorithms for (i) submodular rewards under combinatorial actions, and (ii) XOS rewards under binary actions. These guarantees are tight: We rule out the existence of (i) a PTAS for combinatorial actions, even for gross substitutes rewards (unless P = NP), and (ii) any O(1)-approximation for XOS rewards with combinatorial actions. Crucially, our hardness results hold even for unconstrained contracts, thereby settling the corresponding open problems in this setting.
  Finally, we quantify the loss induced by fairness via the price of equality, defined as the worst-case ratio between the optimal principal's utility achievable by unconstrained contracts and that achievable by equal-pay contracts. We obtain a bound of $\Theta(\log n/ \log \log n)$, where $n$ is the number of agents. This gap is tight in a strong sense: the upper bound applies even for XOS rewards with combinatorial actions, while the lower bound arises already for additive rewards with binary actions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15478v1</guid></item><item><title>[cs updates on arXiv.org] Benchmarking LLMs for Pairwise Causal Discovery in Biomedical and Multi-Domain Contexts</title><link>https://arxiv.org/abs/2601.15479</link><description>arXiv:2601.15479v1 Announce Type: new 
Abstract: The safe deployment of large language models (LLMs) in high-stakes fields like biomedicine, requires them to be able to reason about cause and effect. We investigate this ability by testing 13 open-source LLMs on a fundamental task: pairwise causal discovery (PCD) from text. Our benchmark, using 12 diverse datasets, evaluates two core skills: 1) \textbf{Causal Detection} (identifying if a text contains a causal link) and 2) \textbf{Causal Extraction} (pulling out the exact cause and effect phrases). We tested various prompting methods, from simple instructions (zero-shot) to more complex strategies like Chain-of-Thought (CoT) and Few-shot In-Context Learning (FICL).
  The results show major deficiencies in current models. The best model for detection, DeepSeek-R1-Distill-Llama-70B, only achieved a mean score of 49.57\% ($C_{detect}$), while the best for extraction, Qwen2.5-Coder-32B-Instruct, reached just 47.12\% ($C_{extract}$). Models performed best on simple, explicit, single-sentence relations. However, performance plummeted for more difficult (and realistic) cases, such as implicit relationships, links spanning multiple sentences, and texts containing multiple causal pairs. We provide a unified evaluation framework, built on a dataset validated with high inter-annotator agreement ($\kappa \ge 0.758$), and make all our data, code, and prompts publicly available to spur further research. \href{https://github.com/sydneyanuyah/CausalDiscovery}{Code available here: https://github.com/sydneyanuyah/CausalDiscovery}</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15479v1</guid></item><item><title>[cs updates on arXiv.org] Early predicting of hospital admission using machine learning algorithms: Priority queues approach</title><link>https://arxiv.org/abs/2601.15481</link><description>arXiv:2601.15481v1 Announce Type: new 
Abstract: Emergency Department overcrowding is a critical issue that compromises patient safety and operational efficiency, necessitating accurate demand forecasting for effective resource allocation. This study evaluates and compares three distinct predictive models: Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors (SARIMAX), EXtreme Gradient Boosting (XGBoost) and Long Short-Term Memory (LSTM) networks for forecasting daily ED arrivals over a seven-day horizon. Utilizing data from an Australian tertiary referral hospital spanning January 2017 to December 2021, this research distinguishes itself by decomposing demand into eight specific ward categories and stratifying patients by clinical complexity. To address data distortions caused by the COVID-19 pandemic, the study employs the Prophet model to generate synthetic counterfactual values for the anomalous period. Experimental results demonstrate that all three proposed models consistently outperform a seasonal naive baseline. XGBoost demonstrated the highest accuracy for predicting total daily admissions with a Mean Absolute Error of 6.63, while the statistical SARIMAX model proved marginally superior for forecasting major complexity cases with an MAE of 3.77. The study concludes that while these techniques successfully reproduce regular day-to-day patterns, they share a common limitation in underestimating sudden, infrequent surges in patient volume.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15481v1</guid></item><item><title>[cs updates on arXiv.org] Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding</title><link>https://arxiv.org/abs/2601.15482</link><description>arXiv:2601.15482v1 Announce Type: new 
Abstract: Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15482v1</guid></item><item><title>[cs updates on arXiv.org] Is Grokipedia Right-Leaning? Comparing Political Framing in Wikipedia and Grokipedia on Controversial Topics</title><link>https://arxiv.org/abs/2601.15484</link><description>arXiv:2601.15484v1 Announce Type: new 
Abstract: Online encyclopedias are central to contemporary information infrastructures and have become focal points of debates over ideological bias. Wikipedia, in particular, has long been accused of left-leaning bias, while Grokipedia, an AI-generated encyclopedia launched by xAI, has been framed as a right-leaning alternative. This paper presents a comparative analysis of Wikipedia and Grokipedia on well-established politically contested topics. Specifically, we examine differences in semantic framing, political orientation, and content prioritization. We find that semantic similarity between the two platforms decays across article sections and diverges more strongly on controversial topics than on randomly sampled ones. Additionally, we show that both encyclopedias predominantly exhibit left-leaning framings, although Grokipedia exhibits a more bimodal distribution with increased prominence of right-leaning content. The experimental code is publicly available.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15484v1</guid></item><item><title>[cs updates on arXiv.org] The Rise of Large Language Models and the Direction and Impact of US Federal Research Funding</title><link>https://arxiv.org/abs/2601.15485</link><description>arXiv:2601.15485v1 Announce Type: new 
Abstract: Federal research funding shapes the direction, diversity, and impact of the US scientific enterprise. Large language models (LLMs) are rapidly diffusing into scientific practice, holding substantial promise while raising widespread concerns. Despite growing attention to AI use in scientific writing and evaluation, little is known about how the rise of LLMs is reshaping the public funding landscape. Here, we examine LLM involvement at key stages of the federal funding pipeline by combining two complementary data sources: confidential National Science Foundation (NSF) and National Institutes of Health (NIH) proposal submissions from two large US R1 universities, including funded, unfunded, and pending proposals, and the full population of publicly released NSF and NIH awards. We find that LLM use rises sharply beginning in 2023 and exhibits a bimodal distribution, indicating a clear split between minimal and substantive use. Across both private submissions and public awards, higher LLM involvement is consistently associated with lower semantic distinctiveness, positioning projects closer to recently funded work within the same agency. The consequences of this shift are agency-dependent. LLM use is positively associated with proposal success and higher subsequent publication output at NIH, whereas no comparable associations are observed at NSF. Notably, the productivity gains at NIH are concentrated in non-hit papers rather than the most highly cited work. Together, these findings provide large-scale evidence that the rise of LLMs is reshaping how scientific ideas are positioned, selected, and translated into publicly funded research, with implications for portfolio governance, research diversity, and the long-run impact of science.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15485v1</guid></item><item><title>[cs updates on arXiv.org] A Universal Large Language Model -- Drone Command and Control Interface</title><link>https://arxiv.org/abs/2601.15486</link><description>arXiv:2601.15486v1 Announce Type: new 
Abstract: The use of artificial intelligence (AI) for drone control can have a transformative impact on drone capabilities, especially when real world information can be integrated with drone sensing, command, and control, part of a growing field of physical AI. Large language models (LLMs) can be advantageous if trained at scale on general knowledge, but especially and in particular when the training data includes information such as detailed map geography topology of the entire planet, as well as the ability to access real time situational data such as weather. However, challenges remain in the interface between drones and LLMs in general, with each application requiring a tedious, labor intensive effort to connect the LLM trained knowledge to drone command and control. Here, we solve that problem, using an interface strategy that is LLM agnostic and drone agnostic, providing the first universal, versatile, comprehensive and easy to use drone control interface. We do this using the new model context protocol (MCP) standard, an open standard that provides a universal way for AI systems to access external data, tools, and services. We develop and deploy a cloud based Linux machine hosting an MCP server that supports the Mavlink protocol, an ubiquitous drone control language used almost universally by millions of drones including Ardupilot and PX4 framework.We demonstrate flight control of a real unmanned aerial vehicle. In further testing, we demonstrate extensive flight planning and control capability in a simulated drone, integrated with a Google Maps MCP server for up to date, real time navigation information. This demonstrates a universal approach to integration of LLMs with drone command and control, a paradigm that leverages and exploits virtually all of modern AI industry with drone technology in an easy to use interface that translates natural language to drone control.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15486v1</guid></item><item><title>[cs updates on arXiv.org] MiRAGE: A Multiagent Framework for Generating Multimodal Multihop Question-Answer Dataset for RAG Evaluation</title><link>https://arxiv.org/abs/2601.15487</link><description>arXiv:2601.15487v1 Announce Type: new 
Abstract: The rapid evolution of Retrieval-Augmented Generation (RAG) toward multimodal, high-stakes enterprise applications has outpaced the development of domain specific evaluation benchmarks. Existing datasets often rely on general-domain corpora or purely textual retrieval, failing to capture the complexity of specialized technical documents where information is inextricably multimodal and reasoning requires synthesizing disjoint evidence. We address this gap by introducing MiRAGE, a Multiagent framework for RAG systems Evaluation, that leverages a collaborative swarm of specialized agents to generate verified, domain-specific, multimodal, and multi-hop Question-Answer datasets. MiRAGE orchestrates a swarm of specialized agents: a recursive context optimization loop to aggregate scattered evidence, an adversarial verifier agent to guarantee factual grounding, and an agent to recognize the expert persona and the relevant domain to mimic expert cognitive workflows. Extensive empirical evaluation across four distinct domains (regulations, finance, quantitative biology, and journalism) demonstrates that MiRAGE generates datasets with significantly higher reasoning complexity (&gt;2.3 average hops) and factual faithfulness. Our ablation studies point that MiRAGE can be powered by LLMs if textual descriptions of the images are available. Visual grounding still remains a frontier. By automating the creation of gold standard evaluation datasets that reflect the latent thematic structure of proprietary corpora, MiRAGE provides the necessary infrastructure to rigorously benchmark the next generation information retrieval systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15487v1</guid></item><item><title>[cs updates on arXiv.org] Multi-Persona Thinking for Bias Mitigation in Large Language Models</title><link>https://arxiv.org/abs/2601.15488</link><description>arXiv:2601.15488v1 Announce Type: new 
Abstract: Large Language Models (LLMs) exhibit significant social biases that can perpetuate harmful stereotypes and unfair outcomes. In this paper, we propose Multi-Persona Thinking (MPT), a novel inference-time framework that leverages dialectical reasoning from multiple perspectives to reduce bias. MPT guides models to adopt contrasting social identities (e.g., male and female) along with a neutral viewpoint, and then engages these personas iteratively to expose and correct biases. Through a dialectical reasoning process, the framework transforms the potential weakness of persona assignment into a strength for bias mitigation. We evaluate MPT on two widely used bias benchmarks across both open-source and closed-source models of varying scales. Our results demonstrate substantial improvements over existing prompting-based strategies: MPT achieves the lowest bias while maintaining core reasoning ability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15488v1</guid></item><item><title>[cs updates on arXiv.org] Hybrid Vision Transformer_GAN Attribute Neutralizer for Mitigating Bias in Chest X_Ray Diagnosis</title><link>https://arxiv.org/abs/2601.15490</link><description>arXiv:2601.15490v1 Announce Type: new 
Abstract: Bias in chest X-ray classifiers frequently stems from sex- and age-related shortcuts, leading to systematic underdiagnosis of minority subgroups. Previous pixel-space attribute neutralizers, which rely on convolutional encoders, lessen but do not fully remove this attribute leakage at clinically usable edit strengths. This study evaluates whether substituting the U-Net convolutional encoder with a Vision Transformer backbone in the Attribute-Neutral Framework can reduce demographic attribute leakage while preserving diagnostic accuracy. A data-efficient Image Transformer Small (DeiT-S) neutralizer was trained on the ChestX-ray14 dataset. Its edited images, generated across eleven edit-intensity levels, were evaluated with an independent AI judge for attribute leakage and with a convolutional neural network (ConvNet) for disease prediction. At a moderate edit level (alpha = 0.5), the Vision Transformer (ViT) neutralizer reduces patient sex-recognition area under the curve (AUC) to approximately 0.80, about 10 percentage points below the original framework's convolutional U-Net encoder, despite being trained for only half as many epochs. Meanwhile, macro receiver operating characteristic area under the curve (ROC AUC) across 15 findings stays within five percentage points of the unedited baseline, and the worst-case subgroup AUC remains near 0.70. These results indicate that global self-attention vision models can further suppress attribute leakage without sacrificing clinical utility, suggesting a practical route toward fairer chest X-ray AI.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15490v1</guid></item><item><title>[cs updates on arXiv.org] Testing Deep Learning Libraries via Neurosymbolic Constraint Learning</title><link>https://arxiv.org/abs/2601.15493</link><description>arXiv:2601.15493v1 Announce Type: new 
Abstract: Deep Learning (DL) libraries (e.g., PyTorch) are popular in AI development. These libraries are complex and contain bugs. Researchers have proposed various bug-finding techniques for such libraries. Yet, there is much room for improvement. A key challenge in testing DL libraries is the lack of API specifications. Prior testing approaches often inaccurately model the input specifications of DL APIs, resulting in missed valid inputs that could reveal bugs or false alarms due to invalid inputs.
  To address this challenge, we develop Centaur -- the first neurosymbolic technique to test DL library APIs using dynamically learned input constraints. Centaur leverages the key idea that formal API constraints can be learned from a small number of automatically generated seed inputs, and that the learned constraints can be solved using SMT solvers to generate valid and diverse test inputs.
  We develop a novel grammar that represents first-order logic formulae over API parameters and expresses tensor-related properties (e.g., shape, data types) as well as relational properties between parameters. We use the grammar to guide a Large Language Model (LLM) to enumerate syntactically correct candidate rules, validated using seed inputs. Further, we develop a custom refinement strategy to prune the set of learned rules to eliminate spurious or redundant rules. We use the learned constraints to systematically generate valid and diverse inputs by integrating SMT-based solving with randomized sampling.
  We evaluate Centaur for testing PyTorch and TensorFlow. Our results show that Centaur's constraints have a recall of 94.0% and a precision of 94.0% on average. In terms of coverage, Centaur covers 203, 150, and 9,608 more branches than TitanFuzz, ACETest and Pathfinder, respectively. Using Centaur, we also detect 26 new bugs in PyTorch and TensorFlow, 18 of which are confirmed.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15493v1</guid></item><item><title>[cs updates on arXiv.org] Tracking the Limits of Knowledge Propagation: How LLMs Fail at Multi-Step Reasoning with Conflicting Knowledge</title><link>https://arxiv.org/abs/2601.15495</link><description>arXiv:2601.15495v1 Announce Type: new 
Abstract: A common solution for mitigating outdated or incorrect information in Large Language Models (LLMs) is to provide updated facts in-context or through knowledge editing. However, these methods introduce knowledge conflicts when the knowledge update fails to overwrite the model's parametric knowledge, which propagate to faulty reasoning. Current benchmarks for this problem, however, largely focus only on single knowledge updates and fact recall without evaluating how these updates affect downstream reasoning. In this work, we introduce TRACK (Testing Reasoning Amid Conflicting Knowledge), a new benchmark for studying how LLMs propagate new knowledge through multi-step reasoning when it conflicts with the model's initial parametric knowledge. Spanning three reasoning-intensive scenarios (WIKI, CODE, and MATH), TRACK introduces multiple, realistic conflicts to mirror real-world complexity. Our results on TRACK reveal that providing updated facts to models for reasoning can worsen performance compared to providing no updated facts to a model, and that this performance degradation exacerbates as more updated facts are provided. We show this failure stems from both inability to faithfully integrate updated facts, but also flawed reasoning even when knowledge is integrated. TRACK provides a rigorous new benchmark to measure and guide future progress on propagating conflicting knowledge in multi-step reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15495v1</guid></item><item><title>[cs updates on arXiv.org] Semantics in Actuation Systems: From Age of Actuation to Age of Actuated Information</title><link>https://arxiv.org/abs/2601.15496</link><description>arXiv:2601.15496v1 Announce Type: new 
Abstract: In this paper, we study the timeliness of actions in communication systems where actuation is constrained by control permissions or energy availability. Building on the Age of Actuation (AoA) metric, which quantifies the timeliness of actions independently of data freshness, we introduce a new metric, the \emph{Age of Actuated Information (AoAI)}. AoAI captures the end-to-end timeliness of actions by explicitly accounting for the age of the data packet at the moment it is actuated. We analyze and characterize both AoA and AoAI in discrete-time systems with data storage capabilities under multiple actuation scenarios. The actuator requires both a data packet and an actuation opportunity, which may be provided by a controller or enabled by harvested energy. Data packets may be stored either in a single-packet buffer or an infinite-capacity queue for future actuation. For these settings, we derive closed-form expressions for the average AoA and AoAI and investigate their structural differences. While AoA and AoAI coincide in instantaneous actuation systems, they differentiate when data buffering is present. Our results reveal counterintuitive regimes in which increasing update or actuation rates degrade action timeliness for both AoA and AoAI. Moreover, as part of the analysis, we obtain a novel closed-form characterization of the steady-state distribution of a Geo/Geo/1 queue operating under the FCFS discipline, expressed solely in terms of the queue length and the age of the head-of-line packet. The proposed metrics and analytical results provide new insights into the semantics of timeliness in systems where information ultimately serves the purpose of actuation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15496v1</guid></item><item><title>[cs updates on arXiv.org] MARS: Unleashing the Power of Speculative Decoding via Margin-Aware Verification</title><link>https://arxiv.org/abs/2601.15498</link><description>arXiv:2601.15498v1 Announce Type: new 
Abstract: Speculative Decoding (SD) accelerates autoregressive large language model (LLM) inference by decoupling generation and verification. While recent methods improve draft quality by tightly coupling the drafter with the target model, the verification mechanism itself remains largely unchanged, relying on strict token-level rejection sampling. In practice, modern LLMs frequently operate in low-margin regimes where the target model exhibits weak preference among top candidates. In such cases, rejecting plausible runner-up tokens yields negligible information gain while incurring substantial rollback cost, leading to a fundamental inefficiency in verification. We propose Margin-Aware Speculative Verification, a training-free and domain-agnostic verification strategy that adapts to the target model's local decisiveness. Our method conditions verification on decision stability measured directly from the target logits and relaxes rejection only when strict verification provides minimal benefit. Importantly, the approach modifies only the verification rule and is fully compatible with existing target-coupled speculative decoding frameworks. Extensive experiments across model scales ranging from 8B to 235B demonstrate that our method delivers consistent and significant inference speedups over state-of-the-art baselines while preserving generation quality across diverse benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15498v1</guid></item><item><title>[cs updates on arXiv.org] Data-driven Lake Water Quality Forecasting for Time Series with Missing Data using Machine Learning</title><link>https://arxiv.org/abs/2601.15503</link><description>arXiv:2601.15503v1 Announce Type: new 
Abstract: Volunteer-led lake monitoring yields irregular, seasonal time series with many gaps arising from ice cover, weather-related access constraints, and occasional human errors, complicating forecasting and early warning of harmful algal blooms. We study Secchi Disk Depth (SDD) forecasting on a 30-lake, data-rich subset drawn from three decades of in situ records collected across Maine lakes. Missingness is handled via Multiple Imputation by Chained Equations (MICE), and we evaluate performance with a normalized Mean Absolute Error (nMAE) metric for cross-lake comparability. Among six candidates, ridge regression provides the best mean test performance. Using ridge regression, we then quantify the minimal sample size, showing that under a backward, recent-history protocol, the model reaches within 5% of full-history accuracy with approximately 176 training samples per lake on average. We also identify a minimal feature set, where a compact four-feature subset matches the thirteen-feature baseline within the same 5% tolerance. Bringing these results together, we introduce a joint feasibility function that identifies the minimal training history and fewest predictors sufficient to achieve the target of staying within 5% of the complete-history, full-feature baseline. In our study, meeting the 5% accuracy target required about 64 recent samples and just one predictor per lake, highlighting the practicality of targeted monitoring. Hence, our joint feasibility strategy unifies recent-history length and feature choice under a fixed accuracy target, yielding a simple, efficient rule for setting sampling effort and measurement priorities for lake researchers.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15503v1</guid></item><item><title>[cs updates on arXiv.org] SAGE-FM: A lightweight and interpretable spatial transcriptomics foundation model</title><link>https://arxiv.org/abs/2601.15504</link><description>arXiv:2601.15504v1 Announce Type: new 
Abstract: Spatial transcriptomics enables spatial gene expression profiling, motivating computational models that capture spatially conditioned regulatory relationships. We introduce SAGE-FM, a lightweight spatial transcriptomics foundation model based on graph convolutional networks (GCNs) trained with a masked central spot prediction objective. Trained on 416 human Visium samples spanning 15 organs, SAGE-FM learns spatially coherent embeddings that robustly recover masked genes, with 91% of masked genes showing significant correlations (p &lt; 0.05). The embeddings generated by SAGE-FM outperform MOFA and existing spatial transcriptomics methods in unsupervised clustering and preservation of biological heterogeneity. SAGE-FM generalizes to downstream tasks, enabling 81% accuracy in pathologist-defined spot annotation in oropharyngeal squamous cell carcinoma and improving glioblastoma subtype prediction relative to MOFA. In silico perturbation experiments further demonstrate that the model captures directional ligand-receptor and upstream-downstream regulatory effects consistent with ground truth. These results demonstrate that simple, parameter-efficient GCNs can serve as biologically interpretable and spatially aware foundation models for large-scale spatial transcriptomics.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15504v1</guid></item><item><title>[cs updates on arXiv.org] Stabilizer-Code Channel Transforms Beyond Repetition Codes for Improved Hashing Bounds</title><link>https://arxiv.org/abs/2601.15505</link><description>arXiv:2601.15505v1 Announce Type: new 
Abstract: The quantum hashing bound guarantees that rates up to $1-H(p_I, p_X, p_Y, p_Z)$ are achievable for memoryless Pauli channels, but it is not generally tight. A known way to improve achievable rates for certain asymmetric Pauli channels is to apply a small inner stabilizer code to a few channel uses, decode, and treat the resulting logical noise as an induced Pauli channel; reapplying the hashing argument to this induced channel can beat the baseline hashing bound. We generalize this induced-channel viewpoint to arbitrary stabilizer codes used purely as channel transforms. Given any $ [\![ n, k ]\!] $ stabilizer generator set, we construct a full symplectic tableau, compute the induced joint distribution of logical Pauli errors and syndromes under the physical Pauli channel, and obtain an achievable rate via a hashing bound with decoder side information. We perform a structured search over small transforms and report instances that improve the baseline hashing bound for a family of Pauli channels with skewed and independent errors studied in prior work.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15505v1</guid></item><item><title>[cs updates on arXiv.org] ViT Registers and Fractal ViT</title><link>https://arxiv.org/abs/2601.15506</link><description>arXiv:2601.15506v1 Announce Type: new 
Abstract: Drawing inspiration from recent findings including surprisingly decent performance of transformers without positional encoding (NoPE) in the domain of language models and how registers (additional throwaway tokens not tied to input) may improve the performance of large vision transformers (ViTs), we invent and test a variant of ViT called fractal ViT that breaks permutation invariance among the tokens by applying an attention mask between the regular tokens and ``summary tokens'' similar to registers, in isolation or in combination with various positional encodings. These models do not improve upon ViT with registers, highlighting the fact that these findings may be scale, domain, or application-specific.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15506v1</guid></item><item><title>[cs updates on arXiv.org] Controllable Layered Image Generation for Real-World Editing</title><link>https://arxiv.org/abs/2601.15507</link><description>arXiv:2601.15507v1 Announce Type: new 
Abstract: Recent image generation models have shown impressive progress, yet they often struggle to yield controllable and consistent results when users attempt to edit specific elements within an existing image. Layered representations enable flexible, user-driven content creation, but existing approaches often fail to produce layers with coherent compositing relationships, and their object layers typically lack realistic visual effects such as shadows and reflections. To overcome these limitations, we propose LASAGNA, a novel, unified framework that generates an image jointly with its composing layers--a photorealistic background and a high-quality transparent foreground with compelling visual effects. Unlike prior work, LASAGNA efficiently learns correct image composition from a wide range of conditioning inputs--text prompts, foreground, background, and location masks--offering greater controllability for real-world applications. To enable this, we introduce LASAGNA-48K, a new dataset composed of clean backgrounds and RGBA foregrounds with physically grounded visual effects. We also propose LASAGNABENCH, the first benchmark for layer editing. We demonstrate that LASAGNA excels in generating highly consistent and coherent results across multiple image layers simultaneously, enabling diverse post-editing applications that accurately preserve identity and visual effects. LASAGNA-48K and LASAGNABENCH will be publicly released to foster open research in the community. The project page is https://rayjryang.github.io/LASAGNA-Page/.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15507v1</guid></item><item><title>[cs updates on arXiv.org] Computational Representations of Character Significance in Novels</title><link>https://arxiv.org/abs/2601.15508</link><description>arXiv:2601.15508v1 Announce Type: new 
Abstract: Characters in novels have typically been modeled based on their presence in scenes in narrative, considering aspects like their actions, named mentions, and dialogue. This conception of character places significant emphasis on the main character who is present in the most scenes. In this work, we instead adopt a framing developed from a new literary theory proposing a six-component structural model of character. This model enables a comprehensive approach to character that accounts for the narrator-character distinction and includes a component neglected by prior methods, discussion by other characters. We compare general-purpose LLMs with task-specific transformers for operationalizing this model of character on major 19th-century British realist novels. Our methods yield both component-level and graph representations of character discussion. We then demonstrate that these representations allow us to approach literary questions at scale from a new computational lens. Specifically, we explore Woloch's classic "the one vs the many" theory of character centrality and the gendered dynamics of character discussion.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15508v1</guid></item><item><title>[cs updates on arXiv.org] The Dark Side of AI Transformers: Sentiment Polarization &amp; the Loss of Business Neutrality by NLP Transformers</title><link>https://arxiv.org/abs/2601.15509</link><description>arXiv:2601.15509v1 Announce Type: new 
Abstract: The use of Transfer Learning &amp; Transformers has steadily improved accuracy and has significantly contributed in solving complex computation problems. However, this transformer led accuracy improvement in Applied AI Analytics specifically in sentiment analytics comes with the dark side. It is observed during experiments that a lot of these improvements in transformer led accuracy of one class of sentiment has been at the cost of polarization of another class of sentiment and the failing of neutrality. This lack of neutrality poses an acute problem in the Applied NLP space, which relies heavily on the computational outputs of sentiment analytics for reliable industry ready tasks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15509v1</guid></item><item><title>[cs updates on arXiv.org] AdversaRiskQA: An Adversarial Factuality Benchmark for High-Risk Domains</title><link>https://arxiv.org/abs/2601.15511</link><description>arXiv:2601.15511v1 Announce Type: new 
Abstract: Hallucination in large language models (LLMs) remains an acute concern, contributing to the spread of misinformation and diminished public trust, particularly in high-risk domains. Among hallucination types, factuality is crucial, as it concerns a model's alignment with established world knowledge. Adversarial factuality, defined as the deliberate insertion of misinformation into prompts with varying levels of expressed confidence, tests a model's ability to detect and resist confidently framed falsehoods. Existing work lacks high-quality, domain-specific resources for assessing model robustness under such adversarial conditions, and no prior research has examined the impact of injected misinformation on long-form text factuality.
  To address this gap, we introduce AdversaRiskQA, the first verified and reliable benchmark systematically evaluating adversarial factuality across Health, Finance, and Law. The benchmark includes two difficulty levels to test LLMs' defensive capabilities across varying knowledge depths. We propose two automated methods for evaluating the adversarial attack success and long-form factuality. We evaluate six open- and closed-source LLMs from the Qwen, GPT-OSS, and GPT families, measuring misinformation detection rates. Long-form factuality is assessed on Qwen3 (30B) under both baseline and adversarial conditions. Results show that after excluding meaningless responses, Qwen3 (80B) achieves the highest average accuracy, while GPT-5 maintains consistently high accuracy. Performance scales non-linearly with model size, varies by domains, and gaps between difficulty levels narrow as models grow. Long-form evaluation reveals no significant correlation between injected misinformation and the model's factual output. AdversaRiskQA provides a valuable benchmark for pinpointing LLM weaknesses and developing more reliable models for high-stakes applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15511v1</guid></item><item><title>[cs updates on arXiv.org] DCeption: Real-world Wireless Man-in-the-Middle Attacks Against CCS EV Charging</title><link>https://arxiv.org/abs/2601.15515</link><description>arXiv:2601.15515v1 Announce Type: new 
Abstract: The adoption of Electric Vehicles (EVs) is happening at a rapid pace. To ensure fast and safe charging, complex communication is required between the vehicle and the charging station. In the globally used Combined Charging System (CCS), this communication is carried over the HomePlug Green PHY (HPGP) physical layer. However, HPGP is known to suffer from wireless leakage, which may expose this data link to nearby attackers.
  In this paper, we examine active wireless attacks against CCS, and study the impact they can have. We present the first real-time Software-Defined Radio (SDR) implementation of HPGP, granting unprecedented access to the communications within the charging cables. We analyze the characteristics of 2,750 real-world charging sessions to understand the timing constraints for hijacking. Using novel techniques to increase the attacks' reliability, we design a robust wireless Man-in-the-Middle evaluation framework for CCS.
  We demonstrate full control over TLS usage and CCS protocol version negotiation, including TLS stripping attacks. We investigate how real devices respond to safety-critical MitM attacks, which modify power delivery information, and found target vehicles to be highly permissive. First, we caused a vehicle to display charging power exceeding 900 kW on the dashboard, while receiving only 40 kW. Second, we remotely overcharged a vehicle, at twice the requested current for 17 seconds before the vehicle triggered the emergency shutdown. Finally, we propose a backwards-compatible, downgrade-proof protocol extension to mitigate the underlying vulnerabilities.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15515v1</guid></item><item><title>[cs updates on arXiv.org] DeltaDorsal: Enhancing Hand Pose Estimation with Dorsal Features in Egocentric Views</title><link>https://arxiv.org/abs/2601.15516</link><description>arXiv:2601.15516v1 Announce Type: new 
Abstract: The proliferation of XR devices has made egocentric hand pose estimation a vital task, yet this perspective is inherently challenged by frequent finger occlusions. To address this, we propose a novel approach that leverages the rich information in dorsal hand skin deformation, unlocked by recent advances in dense visual featurizers. We introduce a dual-stream delta encoder that learns pose by contrasting features from a dynamic hand with a baseline relaxed position. Our evaluation demonstrates that, using only cropped dorsal images, our method reduces the Mean Per Joint Angle Error (MPJAE) by 18% in self-occluded scenarios (fingers &gt;=50% occluded) compared to state-of-the-art techniques that depend on the whole hand's geometry and large model backbones. Consequently, our method not only enhances the reliability of downstream tasks like index finger pinch and tap estimation in occluded scenarios but also unlocks new interaction paradigms, such as detecting isometric force for a surface "click" without visible movement while minimizing model size.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15516v1</guid></item><item><title>[cs updates on arXiv.org] DS@GT at TREC TOT 2025: Bridging Vague Recollection with Fusion Retrieval and Learned Reranking</title><link>https://arxiv.org/abs/2601.15518</link><description>arXiv:2601.15518v1 Announce Type: new 
Abstract: We develop a two-stage retrieval system that combines multiple complementary retrieval methods with a learned reranker and LLM-based reranking, to address the TREC Tip-of-the-Tongue (ToT) task. In the first stage, we employ hybrid retrieval that merges LLM-based retrieval, sparse (BM25), and dense (BGE-M3) retrieval methods. We also introduce topic-aware multi-index dense retrieval that partitions the Wikipedia corpus into 24 topical domains. In the second stage, we evaluate both a trained LambdaMART reranker and LLM-based reranking. To support model training, we generate 5000 synthetic ToT queries using LLMs. Our best system achieves recall of 0.66 and NDCG@1000 of 0.41 on the test set by combining hybrid retrieval with Gemini-2.5-flash reranking, demonstrating the effectiveness of fusion retrieval.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15518v1</guid></item><item><title>[cs updates on arXiv.org] TransportAgents: a multi-agents LLM framework for traffic accident severity prediction</title><link>https://arxiv.org/abs/2601.15519</link><description>arXiv:2601.15519v1 Announce Type: new 
Abstract: Accurate prediction of traffic crash severity is critical for improving emergency response and public safety planning. Although recent large language models (LLMs) exhibit strong reasoning capabilities, their single-agent architectures often struggle with heterogeneous, domain-specific crash data and tend to generate biased or unstable predictions. To address these limitations, this paper proposes TransportAgents, a hybrid multi-agent framework that integrates category-specific LLM reasoning with a multilayer perceptron (MLP) integration module. Each specialized agent focuses on a particular subset of traffic information, such as demographics, environmental context, or incident details, to produce intermediate severity assessments that are subsequently fused into a unified prediction. Extensive experiments on two complementary U.S. datasets, the Consumer Product Safety Risk Management System (CPSRMS) and the National Electronic Injury Surveillance System (NEISS), demonstrate that TransportAgents consistently outperforms both traditional machine learning and advanced LLM-based baselines. Across three representative backbones, including closed-source models such as GPT-3.5 and GPT-4o, as well as open-source models such as LLaMA-3.3, the framework exhibits strong robustness, scalability, and cross-dataset generalizability. A supplementary distributional analysis further shows that TransportAgents produces more balanced and well-calibrated severity predictions than standard single-agent LLM approaches, highlighting its interpretability and reliability for safety-critical decision support applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15519v1</guid></item><item><title>[cs updates on arXiv.org] Securing LLM-as-a-Service for Small Businesses: An Industry Case Study of a Distributed Chatbot Deployment Platform</title><link>https://arxiv.org/abs/2601.15528</link><description>arXiv:2601.15528v1 Announce Type: new 
Abstract: Large Language Model (LLM)-based question-answering systems offer significant potential for automating customer support and internal knowledge access in small businesses, yet their practical deployment remains challenging due to infrastructure costs, engineering complexity, and security risks, particularly in retrieval-augmented generation (RAG)-based settings. This paper presents an industry case study of an open-source, multi-tenant platform that enables small businesses to deploy customised LLM-based support chatbots via a no-code workflow. The platform is built on distributed, lightweight k3s clusters spanning heterogeneous, low-cost machines and interconnected through an encrypted overlay network, enabling cost-efficient resource pooling while enforcing container-based isolation and per-tenant data access controls. In addition, the platform integrates practical, platform-level defences against prompt injection attacks in RAG-based chatbots, translating insights from recent prompt injection research into deployable security mechanisms without requiring model retraining or enterprise-scale infrastructure. We evaluate the proposed platform through a real-world e-commerce deployment, demonstrating that secure and efficient LLM-based chatbot services can be achieved under realistic cost, operational, and security constraints faced by small businesses.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15528v1</guid></item><item><title>[cs updates on arXiv.org] Resource Allocation and Sharing for UAV-Assisted Integrated TN-NTN with Multi-Connectivity</title><link>https://arxiv.org/abs/2601.15532</link><description>arXiv:2601.15532v1 Announce Type: new 
Abstract: Unmanned aerial vehicles (UAVs) with multi- connectivity (MC) capabilities efficiently and reliably transfer data between terrestrial networks (TNs) and non-terrestrial networks (NTNs). However, optimally sharing and allocating spectrum and power resources to maintain MC while ensuring reliable connectivity and optimal performance remains challeng- ing in such networks. Channel variations induced by mobility in UAV networks, coupled with the varying quality of service (QoS) demands of heterogeneous devices, resource sharing, and fairness requirements in capacity distribution pose challenges to optimal resource allocation. Thus, this paper investigates resource allocation for QoS-constrained, MC-enabled, dynamic UAVs in an integrated TN-NTN environment with spectrum sharing and fairness considerations. To this end, we consider three types of links: UAV-to-radio base station (RBS), UAV-to-UAV, and UAV-to-HAP. We also assume two types of UAVs with diverse QoS requirements to reflect a practical scenario. Consequently, we propose two algorithms. The first algorithm maximizes the capacity of UAVs-RBS and UAVs-HAP links while ensuring the reliability of the UAV-UAV link. To achieve this, the algorithm maximizes the collective throughput of the UAVs by optimizing the sum capacity of all the UAV-RBS and UAV-HAP links. Next, to provide constant capacity to all links and ensure fairness, we propose another algorithm that maximizes the minimum capacity across all links. We validate the performance of both algorithms through simulation</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15532v1</guid></item><item><title>[cs updates on arXiv.org] From Generative Engines to Actionable Simulators: The Imperative of Physical Grounding in World Models</title><link>https://arxiv.org/abs/2601.15533</link><description>arXiv:2601.15533v1 Announce Type: new 
Abstract: A world model is an AI system that simulates how an environment evolves under actions, enabling planning through imagined futures rather than reactive perception. Current world models, however, suffer from visual conflation: the mistaken assumption that high-fidelity video generation implies an understanding of physical and causal dynamics. We show that while modern models excel at predicting pixels, they frequently violate invariant constraints, fail under intervention, and break down in safety-critical decision-making. This survey argues that visual realism is an unreliable proxy for world understanding. Instead, effective world models must encode causal structure, respect domain-specific constraints, and remain stable over long horizons. We propose a reframing of world models as actionable simulators rather than visual engines, emphasizing structured 4D interfaces, constraint-aware dynamics, and closed-loop evaluation. Using medical decision-making as an epistemic stress test, where trial-and-error is impossible and errors are irreversible, we demonstrate that a world model's value is determined not by how realistic its rollouts appear, but by its ability to support counterfactual reasoning, intervention planning, and robust long-horizon foresight.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15533v1</guid></item><item><title>[cs updates on arXiv.org] QUAIL: Quantization Aware Unlearning for Mitigating Misinformation in LLMs</title><link>https://arxiv.org/abs/2601.15538</link><description>arXiv:2601.15538v1 Announce Type: new 
Abstract: Machine unlearning aims to remove specific knowledge (e.g., copyrighted or private data) from a trained model without full retraining. In practice, models are often quantized (e.g., 4-bit) for deployment, but we find that quantization can catastrophically restore forgotten information [1]. In this paper, we (1) analyze why low-bit quantization undermines unlearning, and (2) propose a quantization-aware unlearning method to mitigate this. We first compute weight-change statistics and bucket overlaps in quantization to show that typical unlearning updates are too small to cross quantization thresholds. Building on this insight, we introduce a logits space hinge loss: for each forget example, we force the output logits of the unlearned model to differ from the original model by at least a margin (half the quantization step). This ensures forgotten examples remain distinguishable even after quantization. We evaluate on language and classification tasks (including a Twitter misinformation dataset) and show our method preserves forgetting under 4-bit quantization, whereas existing methods almost entirely recover the forgotten knowledge.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15538v1</guid></item><item><title>[cs updates on arXiv.org] PRISM: Deriving the Transformer as a Signal-Denoising Operator via Maximum Coding Rate Reduction</title><link>https://arxiv.org/abs/2601.15540</link><description>arXiv:2601.15540v1 Announce Type: new 
Abstract: Deep learning models, particularly Transformers, are often criticized as "black boxes" and lack interpretability. We propose Prism, a white-box attention-based architecture derived from the principles of Maximizing Coding Rate Reduction ($\text{MCR}^2$). By modeling the attention mechanism as a gradient ascent process on a distinct signal-noise manifold, we introduce two physical constraints: an overcomplete dictionary to expand the representational phase space, and an irrational frequency separation ($\pi$-RoPE) to enforce incoherence between signal and noise subspaces. We demonstrate that these geometric inductive biases can be viewed as a physical constraint and they are sufficient to induce unsupervised functional disentanglement alone. Using TinyStories as a controlled testbed for verifying spectral dynamics, we observe that Prism spontaneously specializes its attention heads into spectrally distinct regimes: low-frequency heads capturing long-range causal dependencies (signal) and high-frequency heads handling local syntactic constraints (noise). Our results suggest that interpretability and performance are not a trade-off, but can be unified through principled geometric construction.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15540v1</guid></item><item><title>[cs updates on arXiv.org] CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation</title><link>https://arxiv.org/abs/2601.15541</link><description>arXiv:2601.15541v1 Announce Type: new 
Abstract: We propose a CompliantVLA-adaptor that augments the state-of-the-art Vision-Language-Action (VLA) models with vision-language model (VLM)-informed context-aware variable impedance control (VIC) to improve the safety and effectiveness of contact-rich robotic manipulation tasks. Existing VLA systems (e.g., RDT, Pi0, OpenVLA-oft) typically output position, but lack force-aware adaptation, leading to unsafe or failed interactions in physical tasks involving contact, compliance, or uncertainty. In the proposed CompliantVLA-adaptor, a VLM interprets task context from images and natural language to adapt the stiffness and damping parameters of a VIC controller. These parameters are further regulated using real-time force/torque feedback to ensure interaction forces remain within safe thresholds. We demonstrate that our method outperforms the VLA baselines on a suite of complex contact-rich tasks, both in simulation and on real hardware, with improved success rates and reduced force violations. The overall success rate across all tasks increases from 9.86\% to 17.29\%, presenting a promising path towards safe contact-rich manipulation using VLAs. We release our code, prompts, and force-torque-impedance-scenario context datasets at https://sites.google.com/view/compliantvla.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15541v1</guid></item><item><title>[cs updates on arXiv.org] RDumb++: Drift-Aware Continual Test-Time Adaptation</title><link>https://arxiv.org/abs/2601.15544</link><description>arXiv:2601.15544v1 Announce Type: new 
Abstract: Continual Test-Time Adaptation (CTTA) seeks to update a pretrained model during deployment using only the incoming, unlabeled data stream. Although prior approaches such as Tent, EATA etc. provide meaningful improvements under short evolving shifts, they struggle when the test distribution changes rapidly or over extremely long horizons. This challenge is exemplified by the CCC benchmark, where models operate over streams of 7.5M samples with continually changing corruption types and severities. We propose RDumb++, a principled extension of RDumb that introduces two drift-detection mechanisms i.e entropy-based drift scoring and KL-divergence drift scoring, together with adaptive reset strategies. These mechanisms allow the model to detect when accumulated adaptation becomes harmful and to recover before prediction collapse occurs. Across CCC-medium with three speeds and three seeds (nine runs, each containing one million samples), RDumb++ consistently surpasses RDumb, yielding approx 3% absolute accuracy gains while maintaining stable adaptation throughout the entire stream. Ablation experiments on drift thresholds and reset strengths further show that drift-aware resetting is essential for preventing collapse and achieving reliable long-horizon CTTA.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15544v1</guid></item><item><title>[cs updates on arXiv.org] Learning Neural Operators from Partial Observations via Latent Autoregressive Modeling</title><link>https://arxiv.org/abs/2601.15547</link><description>arXiv:2601.15547v1 Announce Type: new 
Abstract: Real-world scientific applications frequently encounter incomplete observational data due to sensor limitations, geographic constraints, or measurement costs. Although neural operators significantly advanced PDE solving in terms of computational efficiency and accuracy, their underlying assumption of fully-observed spatial inputs severely restricts applicability in real-world applications. We introduce the first systematic framework for learning neural operators from partial observation. We identify and formalize two fundamental obstacles: (i) the supervision gap in unobserved regions that prevents effective learning of physical correlations, and (ii) the dynamic spatial mismatch between incomplete inputs and complete solution fields. Specifically, our proposed Latent Autoregressive Neural Operator~(\ours) introduces two novel components designed explicitly to address the core difficulties of partial observations: (i) a mask-to-predict training strategy that creates artificial supervision by strategically masking observed regions, and (ii) a Physics-Aware Latent Propagator that reconstructs solutions through boundary-first autoregressive generation in latent space. Additionally, we develop POBench-PDE, a dedicated and comprehensive benchmark designed specifically for evaluating neural operators under partial observation conditions across three PDE-governed tasks. \ours achieves state-of-the-art performance with 18--69$\%$ relative L2 error reduction across all benchmarks under patch-wise missingness with less than 50$\%$ missing rate, including real-world climate prediction. Our approach effectively addresses practical scenarios involving up to 75$\%$ missing rate, to some extent bridging the existing gap between idealized research settings and the complexities of real-world scientific computing.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15547v1</guid></item><item><title>[cs updates on arXiv.org] VIOLA: Towards Video In-Context Learning with Minimal Annotations</title><link>https://arxiv.org/abs/2601.15549</link><description>arXiv:2601.15549v1 Announce Type: new 
Abstract: Generalizing Multimodal Large Language Models (MLLMs) to novel video domains is essential for real-world deployment but remains challenging due to the scarcity of labeled data. While In-Context Learning (ICL) offers a training-free adaptation path, standard methods rely on large annotated pools, which are often impractical in specialized environments like industrial or surgical settings since they require the experts' annotations. To bridge this gap, we introduce VIOLA (Video In-cOntext Learning with minimal Annotation), a label-efficient framework that synergizes minimal expert supervision with abundant unlabeled data. First, to maximize the efficiency of a strict annotation budget, we propose density-uncertainty-weighted sampling. Unlike standard diversity or uncertainty strategies that risk selecting visual outliers, our method leverages density estimation to identify samples that are simultaneously diverse, representative, and informative. Second, to utilize the remaining unlabeled data without noise propagation, we construct a hybrid pool and introduce confidence-aware retrieval and confidence-aware prompting. These mechanisms explicitly model label reliability, retrieving demonstrations based on a composite score of similarity and confidence while enabling the MLLM to adaptively distinguish between verified ground truths and noisy pseudo-labels. Extensive experiments across nine diverse benchmarks using four MLLMs demonstrate that our framework significantly outperforms various baselines in low-resource settings, achieving robust adaptation with minimal annotation costs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15549v1</guid></item><item><title>[cs updates on arXiv.org] Common to Whom? Regional Cultural Commonsense and LLM Bias in India</title><link>https://arxiv.org/abs/2601.15550</link><description>arXiv:2601.15550v1 Announce Type: new 
Abstract: Existing cultural commonsense benchmarks treat nations as monolithic, assuming uniform practices within national boundaries. But does cultural commonsense hold uniformly within a nation, or does it vary at the sub-national level? We introduce Indica, the first benchmark designed to test LLMs' ability to address this question, focusing on India - a nation of 28 states, 8 union territories, and 22 official languages. We collect human-annotated answers from five Indian regions (North, South, East, West, and Central) across 515 questions spanning 8 domains of everyday life, yielding 1,630 region-specific question-answer pairs. Strikingly, only 39.4% of questions elicit agreement across all five regions, demonstrating that cultural commonsense in India is predominantly regional, not national. We evaluate eight state-of-the-art LLMs and find two critical gaps: models achieve only 13.4%-20.9% accuracy on region-specific questions, and they exhibit geographic bias, over-selecting Central and North India as the "default" (selected 30-40% more often than expected) while under-representing East and West. Beyond India, our methodology provides a generalizable framework for evaluating cultural commonsense in any culturally heterogeneous nation, from question design grounded in anthropological taxonomy, to regional data collection, to bias measurement.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15550v1</guid></item><item><title>[cs updates on arXiv.org] ALIGNAgent: Adaptive Learner Intelligence for Gap Identification and Next-step guidance</title><link>https://arxiv.org/abs/2601.15551</link><description>arXiv:2601.15551v1 Announce Type: new 
Abstract: Personalized learning systems have emerged as a promising approach to enhance student outcomes by tailoring educational content, pacing, and feedback to individual needs. However, most existing systems remain fragmented, specializing in either knowledge tracing, diagnostic modeling, or resource recommendation, but rarely integrating these components into a cohesive adaptive cycle. In this paper, we propose ALIGNAgent (Adaptive Learner Intelligence for Gap Identification and Next-step guidance), a multi-agent educational framework designed to deliver personalized learning through integrated knowledge estimation, skill-gap identification, and targeted resource recommendation.ALIGNAgent begins by processing student quiz performance, gradebook data, and learner preferences to generate topic-level proficiency estimates using a Skill Gap Agent that employs concept-level diagnostic reasoning to identify specific misconceptions and knowledge deficiencies. After identifying skill gaps, the Recommender Agent retrieves preference-aware learning materials aligned with diagnosed deficiencies, implementing a continuous feedback loop where interventions occur before advancing to subsequent topics. Extensive empirical evaluation on authentic datasets from two undergraduate computer science courses demonstrates ALIGNAgent's effectiveness, with GPT-4o-based agents achieving precision of 0.87-0.90 and F1 scores of 0.84-0.87 in knowledge proficiency estimation validated against actual exam performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15551v1</guid></item><item><title>[cs updates on arXiv.org] BanditLP: Large-Scale Stochastic Optimization for Personalized Recommendations</title><link>https://arxiv.org/abs/2601.15552</link><description>arXiv:2601.15552v1 Announce Type: new 
Abstract: We present BanditLP, a scalable multi-stakeholder contextual bandit framework that unifies neural Thompson Sampling for learning objective-specific outcomes with a large-scale linear program for constrained action selection at serving time. The methodology is application-agnostic, compatible with arbitrary neural architectures, and deployable at web scale, with an LP solver capable of handling billions of variables. Experiments on public benchmarks and synthetic data show consistent gains over strong baselines. We apply this approach in LinkedIn's email marketing system and demonstrate business win, illustrating the value of integrated exploration and constrained optimization in production.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15552v1</guid></item><item><title>[cs updates on arXiv.org] LLM or Human? Perceptions of Trust and Information Quality in Research Summaries</title><link>https://arxiv.org/abs/2601.15556</link><description>arXiv:2601.15556v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly used to generate and edit scientific abstracts, yet their integration into academic writing raises questions about trust, quality, and disclosure. Despite growing adoption, little is known about how readers perceive LLM-generated summaries and how these perceptions influence evaluations of scientific work. This paper presents a mixed-methods survey experiment investigating whether readers with ML expertise can distinguish between human- and LLM-generated abstracts, how actual and perceived LLM involvement affects judgments of quality and trustworthiness, and what orientations readers adopt toward AI-assisted writing. Our findings show that participants struggle to reliably identify LLM-generated content, yet their beliefs about LLM involvement significantly shape their evaluations. Notably, abstracts edited by LLMs are rated more favorably than those written solely by humans or LLMs. We also identify three distinct reader orientations toward LLM-assisted writing, offering insights into evolving norms and informing policy around disclosure and acceptable use in scientific communication.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15556v1</guid></item><item><title>[cs updates on arXiv.org] From Generation to Collaboration: Using LLMs to Edit for Empathy in Healthcare</title><link>https://arxiv.org/abs/2601.15558</link><description>arXiv:2601.15558v1 Announce Type: new 
Abstract: Clinical empathy is essential for patient care, but physicians need continually balance emotional warmth with factual precision under the cognitive and emotional constraints of clinical practice. This study investigates how large language models (LLMs) can function as empathy editors, refining physicians' written responses to enhance empathetic tone while preserving underlying medical information. More importantly, we introduce novel quantitative metrics, an Empathy Ranking Score and a MedFactChecking Score to systematically assess both emotional and factual quality of the responses. Experimental results show that LLM edited responses significantly increase perceived empathy while preserving factual accuracy compared with fully LLM generated outputs. These findings suggest that using LLMs as editorial assistants, rather than autonomous generators, offers a safer, more effective pathway to empathetic and trustworthy AI-assisted healthcare communication.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15558v1</guid></item><item><title>[cs updates on arXiv.org] Relative Classification Accuracy: A Calibrated Metric for Identity Consistency in Fine-Grained K-pop Face Generation</title><link>https://arxiv.org/abs/2601.15560</link><description>arXiv:2601.15560v1 Announce Type: new 
Abstract: Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable success in high-fidelity image generation. However, evaluating their semantic controllability-specifically for fine-grained, single-domain tasks-remains challenging. Standard metrics like FID and Inception Score (IS) often fail to detect identity misalignment in such specialized contexts. In this work, we investigate Class-Conditional DDPMs for K-pop idol face generation (32x32), a domain characterized by high inter-class similarity. We propose a calibrated metric, Relative Classification Accuracy (RCA), which normalizes generative performance against an oracle classifier's baseline. Our evaluation reveals a critical trade-off: while the model achieves high visual quality (FID 8.93), it suffers from severe semantic mode collapse (RCA 0.27), particularly for visually ambiguous identities. We analyze these failure modes through confusion matrices and attribute them to resolution constraints and intra-gender ambiguity. Our framework provides a rigorous standard for verifying identity consistency in conditional generative models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15560v1</guid></item><item><title>[cs updates on arXiv.org] Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial Optimization Problems</title><link>https://arxiv.org/abs/2601.15561</link><description>arXiv:2601.15561v1 Announce Type: new 
Abstract: This article critically investigates the limitations of the simulated annealing algorithm using probabilistic bits (pSA) in solving large-scale combinatorial optimization problems. The study begins with an in-depth analysis of the pSA process, focusing on the issues resulting from unexpected oscillations among p-bits. These oscillations hinder the energy reduction of the Ising model and thus obstruct the successful execution of pSA in complex tasks. Through detailed simulations, we unravel the root cause of this energy stagnation, identifying the feedback mechanism inherent to the pSA operation as the primary contributor to these disruptive oscillations. To address this challenge, we propose two novel algorithms, time average pSA (TApSA) and stalled pSA (SpSA). These algorithms are designed based on partial deactivation of p-bits and are thoroughly tested using Python simulations on maximum cut benchmarks that are typical combinatorial optimization problems. On the 16 benchmarks from 800 to 5,000 nodes, the proposed methods improve the normalized cut value from 0.8% to 98.4% on average in comparison with the conventional pSA.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15561v1</guid></item><item><title>[cs updates on arXiv.org] PromptHelper: A Prompt Recommender System for Encouraging Creativity in AI Chatbot Interactions</title><link>https://arxiv.org/abs/2601.15575</link><description>arXiv:2601.15575v1 Announce Type: new 
Abstract: Prompting is central to interaction with AI systems, yet many users struggle to explore alternative directions, articulate creative intent, or understand how variations in prompts shape model outputs. We introduce prompt recommender systems (PRS) as an interaction approach that supports exploration, suggesting contextually relevant follow-up prompts. We present PromptHelper, a PRS prototype integrated into an AI chatbot that surfaces semantically diverse prompt suggestions while users work on real writing tasks. We evaluate PromptHelper in a 2x2 fully within-subjects study (N=32) across creative and academic writing tasks. Results show that PromptHelper significantly increases users' perceived exploration and expressiveness without increasing cognitive workload. Qualitative findings illustrate how prompt recommendations help users branch into new directions, overcome uncertainty about what to ask next, and better articulate their intent. We discuss implications for designing AI interfaces that scaffold exploratory interaction while preserving user agency, and release open-source resources to support research on prompt recommendation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15575v1</guid></item><item><title>[cs updates on arXiv.org] MapViT: A Two-Stage ViT-Based Framework for Real-Time Radio Quality Map Prediction in Dynamic Environments</title><link>https://arxiv.org/abs/2601.15578</link><description>arXiv:2601.15578v1 Announce Type: new 
Abstract: Recent advancements in mobile and wireless networks are unlocking the full potential of robotic autonomy, enabling robots to take advantage of ultra-low latency, high data throughput, and ubiquitous connectivity. However, for robots to navigate and operate seamlessly, efficiently and reliably, they must have an accurate understanding of both their surrounding environment and the quality of radio signals. Achieving this in highly dynamic and ever-changing environments remains a challenging and largely unsolved problem. In this paper, we introduce MapViT, a two-stage Vision Transformer (ViT)-based framework inspired by the success of pre-train and fine-tune paradigm for Large Language Models (LLMs). MapViT is designed to predict both environmental changes and expected radio signal quality. We evaluate the framework using a set of representative Machine Learning (ML) models, analyzing their respective strengths and limitations across different scenarios. Experimental results demonstrate that the proposed two-stage pipeline enables real-time prediction, with the ViT-based implementation achieving a strong balance between accuracy and computational efficiency. This makes MapViT a promising solution for energy- and resource-constrained platforms such as mobile robots. Moreover, the geometry foundation model derived from the self-supervised pre-training stage improves data efficiency and transferability, enabling effective downstream predictions even with limited labeled data. Overall, this work lays the foundation for next-generation digital twin ecosystems, and it paves the way for a new class of ML foundation models driving multi-modal intelligence in future 6G-enabled systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15578v1</guid></item><item><title>[cs updates on arXiv.org] YuFeng-XGuard: A Reasoning-Centric, Interpretable, and Flexible Guardrail Model for Large Language Models</title><link>https://arxiv.org/abs/2601.15588</link><description>arXiv:2601.15588v1 Announce Type: new 
Abstract: As large language models (LLMs) are increasingly deployed in real-world applications, safety guardrails are required to go beyond coarse-grained filtering and support fine-grained, interpretable, and adaptable risk assessment. However, existing solutions often rely on rapid classification schemes or post-hoc rules, resulting in limited transparency, inflexible policies, or prohibitive inference costs. To this end, we present YuFeng-XGuard, a reasoning-centric guardrail model family designed to perform multi-dimensional risk perception for LLM interactions. Instead of producing opaque binary judgments, YuFeng-XGuard generates structured risk predictions, including explicit risk categories and configurable confidence scores, accompanied by natural language explanations that expose the underlying reasoning process. This formulation enables safety decisions that are both actionable and interpretable. To balance decision latency and explanatory depth, we adopt a tiered inference paradigm that performs an initial risk decision based on the first decoded token, while preserving ondemand explanatory reasoning when required. In addition, we introduce a dynamic policy mechanism that decouples risk perception from policy enforcement, allowing safety policies to be adjusted without model retraining. Extensive experiments on a diverse set of public safety benchmarks demonstrate that YuFeng-XGuard achieves stateof-the-art performance while maintaining strong efficiency-efficacy trade-offs. We release YuFeng-XGuard as an open model family, including both a full-capacity variant and a lightweight version, to support a wide range of deployment scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15588v1</guid></item><item><title>[cs updates on arXiv.org] Deep Learning for Perishable Inventory Systems with Human Knowledge</title><link>https://arxiv.org/abs/2601.15589</link><description>arXiv:2601.15589v1 Announce Type: new 
Abstract: Managing perishable products with limited lifetimes is a fundamental challenge in inventory management, as poor ordering decisions can quickly lead to stockouts or excessive waste. We study a perishable inventory system with random lead times in which both the demand process and the lead time distribution are unknown. We consider a practical setting where orders are placed using limited historical data together with observed covariates and current system states. To improve learning efficiency under limited data, we adopt a marginal cost accounting scheme that assigns each order a single lifetime cost and yields a unified loss function for end-to-end learning. This enables training a deep learning-based policy that maps observed covariates and system states directly to order quantities. We develop two end-to-end variants: a purely black-box approach that outputs order quantities directly (E2E-BB), and a structure-guided approach that embeds the projected inventory level (PIL) policy, capturing inventory effects through explicit computation rather than additional learning (E2E-PIL). We further show that the objective induced by E2E-PIL is homogeneous of degree one, enabling a boosting technique from operational data analytics (ODA) that yields an enhanced policy (E2E-BPIL). Experiments on synthetic and real data establish a robust performance ordering: E2E-BB is dominated by E2E-PIL, which is further improved by E2E-BPIL. Using an excess-risk decomposition, we show that embedding heuristic policy structure reduces effective model complexity and improves learning efficiency with only a modest loss of flexibility. More broadly, our results suggest that deep learning-based decision tools are more effective and robust when guided by human knowledge, highlighting the value of integrating advanced analytics with inventory theory.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15589v1</guid></item><item><title>[cs updates on arXiv.org] Parallelism and Generation Order in Masked Diffusion Language Models: Limits Today, Potential Tomorrow</title><link>https://arxiv.org/abs/2601.15593</link><description>arXiv:2601.15593v1 Announce Type: new 
Abstract: Masked Diffusion Language Models (MDLMs) promise parallel token generation and arbitrary-order decoding, yet it remains unclear to what extent current models truly realize these capabilities. We characterize MDLM behavior along two dimensions -- parallelism strength and generation order -- using Average Finalization Parallelism (AFP) and Kendall's tau. We evaluate eight mainstream MDLMs (up to 100B parameters) on 58 benchmarks spanning knowledge, reasoning, and programming. The results show that MDLMs still lag behind comparably sized autoregressive models, mainly because parallel probabilistic modeling weakens inter-token dependencies. Meanwhile, MDLMs exhibit adaptive decoding behavior: their parallelism and generation order vary significantly with the task domain, the stage of reasoning, and whether the output is correct. On tasks that require "backward information" (e.g., Sudoku), MDLMs adopt a solution order that tends to fill easier Sudoku blanks first, highlighting their advantages. Finally, we provide theoretical motivation and design insights supporting a Generate-then-Edit paradigm, which mitigates dependency loss while retaining the efficiency of parallel decoding.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15593v1</guid></item><item><title>[cs updates on arXiv.org] Blockchain-Based Spectrum Resource Securitization via Semi-Fungible Token-Lock</title><link>https://arxiv.org/abs/2601.15594</link><description>arXiv:2601.15594v1 Announce Type: new 
Abstract: As 6G networks evolve, spectrum assets require flexible, dynamic, and efficient utilization, motivating blockchain based spectrum securitization. Existing approaches based on ERC404 style hybrid token models rely on frequent minting and burning during asset transfers, which disrupt token identity continuity and increase on chain overhead. This paper proposes the Semi Fungible Token Lock (SFT Lock) method, a lock/unlock based mechanism that preserves NFT identity and historical traceability while enabling fractional ownership and transferability. By replacing mint/burn operations with deterministic state transitions, SFT Lock ensures consistent lifecycle representation of spectrum assets and significantly reduces on chain operations. Based on this mechanism, a modular smart contract architecture is designed to support spectrum authorization, securitization, and sharing, and a staking mechanism is introduced to enhance asset liquidity. Experimental results on a private Ethereum network demonstrate that, compared with ERC404 style hybrid token models, the proposed method achieves substantial gas savings while maintaining functional correctness and traceability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15594v1</guid></item><item><title>[cs updates on arXiv.org] Data-Free Privacy-Preserving for LLMs via Model Inversion and Selective Unlearning</title><link>https://arxiv.org/abs/2601.15595</link><description>arXiv:2601.15595v1 Announce Type: new 
Abstract: Large language models (LLMs) exhibit powerful capabilities but risk memorizing sensitive personally identifiable information (PII) from their training data, posing significant privacy concerns. While machine unlearning techniques aim to remove such data, they predominantly depend on access to the training data. This requirement is often impractical, as training data in real-world deployments is commonly proprietary or inaccessible. To address this limitation, we propose Data-Free Selective Unlearning (DFSU), a novel privacy-preserving framework that removes sensitive PII from an LLM without requiring its training data. Our approach first synthesizes pseudo-PII through language model inversion, then constructs token-level privacy masks for these synthetic samples, and finally performs token-level selective unlearning via a contrastive mask loss within a low-rank adaptation (LoRA) subspace. Extensive experiments on the AI4Privacy PII-Masking dataset using Pythia models demonstrate that our method effectively removes target PII while maintaining model utility.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15595v1</guid></item><item><title>[cs updates on arXiv.org] DeepASMR: LLM-Based Zero-Shot ASMR Speech Generation for Anyone of Any Voice</title><link>https://arxiv.org/abs/2601.15596</link><description>arXiv:2601.15596v1 Announce Type: new 
Abstract: While modern Text-to-Speech (TTS) systems achieve high fidelity for read-style speech, they struggle to generate Autonomous Sensory Meridian Response (ASMR), a specialized, low-intensity speech style essential for relaxation. The inherent challenges include ASMR's subtle, often unvoiced characteristics and the demand for zero-shot speaker adaptation. In this paper, we introduce DeepASMR, the first framework designed for zero-shot ASMR generation. We demonstrate that a single short snippet of a speaker's ordinary, read-style speech is sufficient to synthesize high-fidelity ASMR in their voice, eliminating the need for whispered training data from the target speaker. Methodologically, we first identify that discrete speech tokens provide a soft factorization of ASMR style from speaker timbre. Leveraging this insight, we propose a two-stage pipeline incorporating a Large Language Model (LLM) for content-style encoding and a flow-matching acoustic decoder for timbre reconstruction. Furthermore, we contribute DeepASMR-DB, a comprehensive 670-hour English-Chinese multi-speaker ASMR speech corpus, and introduce a novel evaluation protocol integrating objective metrics, human listening tests, LLM-based scoring and unvoiced speech analysis. Extensive experiments confirm that DeepASMR achieves state-of-the-art naturalness and style fidelity in ASMR generation for anyone of any voice, while maintaining competitive performance on normal speech synthesis.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15596v1</guid></item><item><title>[cs updates on arXiv.org] Neural Nonlinear Shrinkage of Covariance Matrices for Minimum Variance Portfolio Optimization</title><link>https://arxiv.org/abs/2601.15597</link><description>arXiv:2601.15597v1 Announce Type: new 
Abstract: This paper introduces a neural network-based nonlinear shrinkage estimator of covariance matrices for the purpose of minimum variance portfolio optimization. It is a hybrid approach that integrates statistical estimation with machine learning. Starting from the Ledoit-Wolf (LW) shrinkage estimator, we decompose the LW covariance matrix into its eigenvalues and eigenvectors, and apply a lightweight transformer-based neural network to learn a nonlinear eigenvalue shrinkage function. Trained with portfolio risk as the loss function, the resulting precision matrix (the inverse covariance matrix) estimator directly targets portfolio risk minimization. By conditioning on the sample-to-dimension ratio, the approach remains scalable across different sample sizes and asset universes. Empirical results on stock daily returns from Standard &amp; Poor's 500 Index (S&amp;amp;P500) demonstrate that the proposed method consistently achieves lower out-of-sample realized risk than benchmark approaches. This highlights the promise of integrating structural statistical models with data-driven learning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15597v1</guid></item><item><title>[cs updates on arXiv.org] Ternary Spiking Neural Networks Enhanced by Complemented Neurons and Membrane Potential Aggregation</title><link>https://arxiv.org/abs/2601.15598</link><description>arXiv:2601.15598v1 Announce Type: new 
Abstract: Spiking Neural Networks (SNNs) are promising energy-efficient models and powerful framworks of modeling neuron dynamics. However, existing binary spiking neurons exhibit limited biological plausibilities and low information capacity. Recently developed ternary spiking neuron possesses higher consistency with biological principles (i.e. excitation-inhibition balance mechanism). Despite of this, the ternary spiking neuron suffers from defects including iterative information loss, temporal gradient vanishing and irregular distributions of membrane potentials. To address these issues, we propose Complemented Ternary Spiking Neuron (CTSN), a novel ternary spiking neuron model that incorporates an learnable complemental term to store information from historical inputs. CTSN effectively improves the deficiencies of ternary spiking neuron, while the embedded learnable factors enable CTSN to adaptively adjust neuron dynamics, providing strong neural heterogeneity. Furthermore, based on the temporal evolution features of ternary spiking neurons' membrane potential distributions, we propose the Temporal Membrane Potential Regularization (TMPR) training method. TMPR introduces time-varying regularization strategy utilizing membrane potentials, furhter enhancing the training process by creating extra backpropagation paths. We validate our methods through extensive experiments on various datasets, demonstrating remarkable performance advances.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15598v1</guid></item><item><title>[cs updates on arXiv.org] Autonomous Business System via Neuro-symbolic AI</title><link>https://arxiv.org/abs/2601.15599</link><description>arXiv:2601.15599v1 Announce Type: new 
Abstract: Current business environments require organizations to continuously reconfigure cross-functional processes, yet enterprise systems are still organized around siloed departments, rigid workflows, and hard-coded automation. Meanwhile large language models (LLMs) excel at interpreting natural language and unstructured data but lack deterministic, verifiable execution of complex business logic. To address this gap, here we introduce AUTOBUS, an Autonomous Business System that integrates LLM-based AI agents, predicate-logic programming, and business-semantics-centric enterprise data into a coherent neuro-symbolic AI architecture for orchestrating end-to-end business initiatives. AUTOBUS models an initiative as a network of tasks with explicit pre/post conditions, required data, evaluation rules, and API-level actions. Enterprise data is organized as a knowledge graph whose entities, relationships, and constraints are translated into logic facts and foundational rules, providing the semantic grounding for task reasoning. Core AI agents synthesize task instructions, enterprise semantics, and available tools into task-specific logic programs, which are executed by a logic engine that enforces constraints, coordinates auxiliary tools, and orchestrate execution of actions and outcomes. Humans define and maintain the semantics, policies and task instructions, curate tools, and supervise high-impact or ambiguous decisions, ensuring accountability and adaptability. We detail the AUTOBUS architecture, the anatomy of the AI agent generated logic programs, and the role of humans and auxiliary tools in the lifecycle of a business initiative.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15599v1</guid></item><item><title>[cs updates on arXiv.org] ToxiTwitch: Toward Emote-Aware Hybrid Moderation for Live Streaming Platforms</title><link>https://arxiv.org/abs/2601.15605</link><description>arXiv:2601.15605v1 Announce Type: new 
Abstract: The rapid growth of live-streaming platforms such as Twitch has introduced complex challenges in moderating toxic behavior. Traditional moderation approaches, such as human annotation and keyword-based filtering, have demonstrated utility, but human moderators on Twitch constantly struggle to scale effectively in the fast-paced, high-volume, and context-rich chat environment of the platform while also facing harassment themselves. Recent advances in large language models (LLMs), such as DeepSeek-R1-Distill and Llama-3-8B-Instruct, offer new opportunities for toxicity detection, especially in understanding nuanced, multimodal communication involving emotes. In this work, we present an exploratory comparison of toxicity detection approaches tailored to Twitch. Our analysis reveals that incorporating emotes improves the detection of toxic behavior. To this end, we introduce ToxiTwitch, a hybrid model that combines LLM-generated embeddings of text and emotes with traditional machine learning classifiers, including Random Forest and SVM. In our case study, the proposed hybrid approach reaches up to 80 percent accuracy under channel-specific training (with 13 percent improvement over BERT and F1-score of 76 percent). This work is an exploratory study intended to surface challenges and limits of emote-aware toxicity detection on Twitch.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15605v1</guid></item><item><title>[cs updates on arXiv.org] Airflow Source Seeking on Small Quadrotors Using a Single Flow Sensor</title><link>https://arxiv.org/abs/2601.15607</link><description>arXiv:2601.15607v1 Announce Type: new 
Abstract: As environmental disasters happen more frequently and severely, seeking the source of pollutants or harmful particulates using plume tracking becomes even more important. Plume tracking on small quadrotors would allow these systems to operate around humans and fly in more confined spaces, but can be challenging due to poor sensitivity and long response times from gas sensors that fit on small quadrotors. In this work, we present an approach to complement chemical plume tracking with airflow source-seeking behavior using a custom flow sensor that can sense both airflow magnitude and direction on small quadrotors &lt; 100 g. We use this sensor to implement a modified version of the `Cast and Surge' algorithm that takes advantage of flow direction sensing to find and navigate towards flow sources. A series of characterization experiments verified that the system can detect airflow while in flight and reorient the quadrotor toward the airflow. Several trials with random starting locations and orientations were used to show that our source-seeking algorithm can reliably find a flow source. This work aims to provide a foundation for future platforms that can use flow sensors in concert with other sensors to enable richer plume tracking data collection and source-seeking.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15607v1</guid></item><item><title>[cs updates on arXiv.org] When Sharpening Becomes Collapse: Sampling Bias and Semantic Coupling in RL with Verifiable Rewards</title><link>https://arxiv.org/abs/2601.15609</link><description>arXiv:2601.15609v1 Announce Type: new 
Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a central paradigm for turning large language models (LLMs) into reliable problem solvers, especially in logic-heavy domains. Despite its empirical success, it remains unclear whether RLVR elicits novel capabilities or merely sharpens the distribution over existing knowledge. We study this by formalizing over-sharpening, a phenomenon where the policy collapses onto limited modes, suppressing valid alternatives. At a high level, we discover finite-batch updates intrinsically bias learning toward sampled modes, triggering a collapse that propagates globally via semantic coupling. To mitigate this, we propose inverse-success advantage calibration to prioritize difficult queries and distribution-level calibration to diversify sampling via a memory network. Empirical evaluations validate that our strategies can effectively improve generalization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15609v1</guid></item><item><title>[cs updates on arXiv.org] AION: Aerial Indoor Object-Goal Navigation Using Dual-Policy Reinforcement Learning</title><link>https://arxiv.org/abs/2601.15614</link><description>arXiv:2601.15614v1 Announce Type: new 
Abstract: Object-Goal Navigation (ObjectNav) requires an agent to autonomously explore an unknown environment and navigate toward target objects specified by a semantic label. While prior work has primarily studied zero-shot ObjectNav under 2D locomotion, extending it to aerial platforms with 3D locomotion capability remains underexplored. Aerial robots offer superior maneuverability and search efficiency, but they also introduce new challenges in spatial perception, dynamic control, and safety assurance. In this paper, we propose AION for vision-based aerial ObjectNav without relying on external localization or global maps. AION is an end-to-end dual-policy reinforcement learning (RL) framework that decouples exploration and goal-reaching behaviors into two specialized policies. We evaluate AION on the AI2-THOR benchmark and further assess its real-time performance in IsaacSim using high-fidelity drone models. Experimental results show that AION achieves superior performance across comprehensive evaluation metrics in exploration, navigation efficiency, and safety. The video can be found at https://youtu.be/TgsUm6bb7zg.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15614v1</guid></item><item><title>[cs updates on arXiv.org] Region-aware Spatiotemporal Modeling with Collaborative Domain Generalization for Cross-Subject EEG Emotion Recognition</title><link>https://arxiv.org/abs/2601.15615</link><description>arXiv:2601.15615v1 Announce Type: new 
Abstract: Cross-subject EEG-based emotion recognition (EER) remains challenging due to strong inter-subject variability, which induces substantial distribution shifts in EEG signals, as well as the high complexity of emotion-related neural representations in both spatial organization and temporal evolution. Existing approaches typically improve spatial modeling, temporal modeling, or generalization strategies in isolation, which limits their ability to align representations across subjects while capturing multi-scale dynamics and suppressing subject-specific bias within a unified framework. To address these gaps, we propose a Region-aware Spatiotemporal Modeling framework with Collaborative Domain Generalization (RSM-CoDG) for cross-subject EEG emotion recognition. RSM-CoDG incorporates neuroscience priors derived from functional brain region partitioning to construct region-level spatial representations, thereby improving cross-subject comparability. It also employs multi-scale temporal modeling to characterize the dynamic evolution of emotion-evoked neural activity. In addition, the framework employs a collaborative domain generalization strategy, incorporating multidimensional constraints to reduce subject-specific bias in a fully unseen target subject setting, which enhances the generalization to unknown individuals. Extensive experimental results on SEED series datasets demonstrate that RSM-CoDG consistently outperforms existing competing methods, providing an effective approach for improving robustness. The source code is available at https://github.com/RyanLi-X/RSM-CoDG.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15615v1</guid></item><item><title>[cs updates on arXiv.org] Closing the Gap on the Sample Complexity of 1-Identification</title><link>https://arxiv.org/abs/2601.15620</link><description>arXiv:2601.15620v1 Announce Type: new 
Abstract: 1-identification is a fundamental multi-armed bandit formulation on pure exploration. An agent aims to determine whether there exists a qualified arm whose mean reward is not less than a known threshold $\mu_0$, or to output \textsf{None} if it believes such an arm does not exist. The agent needs to guarantee its output is correct with probability at least $1-\delta$, while making expected total pulling times $\mathbb{E}\tau$ as small as possible. We work on 1-identification with two main contributions. (1) We utilize an optimization formulation to derive a new lower bound of $\mathbb{E}\tau$, when there is at least one qualified arm. (2) We design a new algorithm, deriving tight upper bounds whose gap to lower bounds are up to a polynomial of logarithm factor across all problem instance. Our result complements the analysis of $\mathbb{E}\tau$ when there are multiple qualified arms, which is an open problem left by history literature.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15620v1</guid></item><item><title>[cs updates on arXiv.org] Design, Modelling, and Control of Magnetic Ball Suspension System</title><link>https://arxiv.org/abs/2601.15622</link><description>arXiv:2601.15622v1 Announce Type: new 
Abstract: This paper presents the modeling, control design, and performance analysis of a Magnetic Ball Suspension System (MBSS), a nonlinear and inherently unstable electromechanical system used in various precision applications. The system's primary objective is to levitate a steel ball using electromagnetic force without physical contact, thereby eliminating frictional losses. A comprehensive state-space model was developed, capturing both the mechanical and electrical dynamics. The equilibrium points of the system were determined through feedback linearization using the Jacobian matrix. To ensure system stability, controllability and observability analyses were conducted, confirming that state feedback and observer-based control strategies could be effectively implemented. Three distinct control methods were explored: pole placement-based state feedback control, full-order observer design, and optimal state feedback control using the Linear Quadratic Regulator (LQR). Each control strategy was validated through Simulink simulations for both linearized and nonlinear models. Simulation results demonstrated that the linearized system consistently achieved desired performance with minimal oscillations, whereas the nonlinear system exhibited significant transient oscillations before stabilization. The full-order observer enhanced estimation accuracy, enabling effective control where direct state measurement was impractical. The LQR-based control offered improved robustness and minimized control effort, though its performance was comparable to standard state feedback in some cases.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15622v1</guid></item><item><title>[cs updates on arXiv.org] Mapping Social Media User Behaviors in Reciprocity Space</title><link>https://arxiv.org/abs/2601.15623</link><description>arXiv:2601.15623v1 Announce Type: new 
Abstract: Social media users exhibit diverse behavioral patterns as platforms function simultaneously as information and friendship networks. We introduce a reciprocity-based framework mapping users onto two-dimensional space defined by bidirectional connection ratios. Analyzing 48,830 Twitter users and 149 million connections, we demonstrate that fragmented user types from prior studies (influencers, lurkers, brokers, and follow-back accounts) emerge naturally as regions within continuous behavioral space rather than discrete categories. User properties vary smoothly across the reciprocity dimensions, revealing clear behavioral gradients. This framework provides the first unified model encompassing the full spectrum of social media behaviors and offers interpretable metrics for influence measurement and platform design.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15623v1</guid></item><item><title>[cs updates on arXiv.org] Explainable Deepfake Detection with RL Enhanced Self-Blended Images</title><link>https://arxiv.org/abs/2601.15624</link><description>arXiv:2601.15624v1 Announce Type: new 
Abstract: Most prior deepfake detection methods lack explainable outputs. With the growing interest in multimodal large language models (MLLMs), researchers have started exploring their use in interpretable deepfake detection. However, a major obstacle in applying MLLMs to this task is the scarcity of high-quality datasets with detailed forgery attribution annotations, as textual annotation is both costly and challenging - particularly for high-fidelity forged images or videos. Moreover, multiple studies have shown that reinforcement learning (RL) can substantially enhance performance in visual tasks, especially in improving cross-domain generalization. To facilitate the adoption of mainstream MLLM frameworks in deepfake detection with reduced annotation cost, and to investigate the potential of RL in this context, we propose an automated Chain-of-Thought (CoT) data generation framework based on Self-Blended Images, along with an RL-enhanced deepfake detection framework. Extensive experiments validate the effectiveness of our CoT data construction pipeline, tailored reward mechanism, and feedback-driven synthetic data generation approach. Our method achieves performance competitive with state-of-the-art (SOTA) approaches across multiple cross-dataset benchmarks. Implementation details are available at https://github.com/deon1219/rlsbi.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15624v1</guid></item><item><title>[cs updates on arXiv.org] Robust Tool Use via Fission-GRPO: Learning to Recover from Execution Errors</title><link>https://arxiv.org/abs/2601.15625</link><description>arXiv:2601.15625v1 Announce Type: new 
Abstract: Large language models (LLMs) can call tools effectively, yet they remain brittle in multi-turn execution: following a tool call error, smaller models often degenerate into repetitive invalid re-invocations, failing to interpret error feedback and self-correct. This brittleness hinders reliable real-world deployment, where the execution errors are inherently inevitable during tool interaction procedures. We identify a key limitation of current approaches: standard reinforcement learning (RL) treats errors as sparse negative rewards, providing no guidance on how to recover, while pre-collected synthetic error-correction datasets suffer from distribution mismatch with the model's on-policy error modes. To bridge this gap, we propose Fission-GRPO, a framework that converts execution errors into corrective supervision within the RL training loop. Our core mechanism fissions each failed trajectory into a new training instance by augmenting it with diagnostic feedback from a finetuned Error Simulator, then resampling recovery rollouts on-policy. This enables the model to learn from the precise errors it makes during exploration, rather than from static, pre-collected error cases. On the BFCL v4 Multi-Turn, Fission-GRPO improves the error recovery rate of Qwen3-8B by 5.7% absolute, crucially, yielding a 4% overall accuracy gain (42.75% to 46.75%) over GRPO and outperforming specialized tool-use agents.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15625v1</guid></item><item><title>[cs updates on arXiv.org] Bridging Qualitative Rubrics and AI: A Binary Question Framework for Criterion-Referenced Grading in Engineering</title><link>https://arxiv.org/abs/2601.15626</link><description>arXiv:2601.15626v1 Announce Type: new 
Abstract: PURPOSE OR GOAL: This study investigates how GenAI can be integrated with a criterion-referenced grading framework to improve the efficiency and quality of grading for mathematical assessments in engineering. It specifically explores the challenges demonstrators face with manual, model solution-based grading and how a GenAI-supported system can be designed to reliably identify student errors, provide high-quality feedback, and support human graders. The research also examines human graders' perceptions of the effectiveness of this GenAI-assisted approach. ACTUAL OR ANTICIPATED OUTCOMES: The study found that GenAI achieved an overall grading accuracy of 92.5%, comparable to two experienced human graders. The two researchers, who also served as subject demonstrators, perceived the GenAI as a helpful second reviewer that improved accuracy by catching small errors and provided more complete feedback than they could manually. A central outcome was the significant enhancement of formative feedback. However, they noted the GenAI tool is not yet reliable enough for autonomous use, especially with unconventional solutions. CONCLUSIONS/RECOMMENDATIONS/SUMMARY: This study demonstrates that GenAI, when paired with a structured, criterion-referenced framework using binary questions, can grade engineering mathematical assessments with an accuracy comparable to human experts. Its primary contribution is a novel methodological approach that embeds the generation of high-quality, scalable formative feedback directly into the assessment workflow. Future work should investigate student perceptions of GenAI grading and feedback.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15626v1</guid></item><item><title>[cs updates on arXiv.org] CogToM: A Comprehensive Theory of Mind Benchmark inspired by Human Cognition for Large Language Models</title><link>https://arxiv.org/abs/2601.15628</link><description>arXiv:2601.15628v1 Announce Type: new 
Abstract: Whether Large Language Models (LLMs) truly possess human-like Theory of Mind (ToM) capabilities has garnered increasing attention. However, existing benchmarks remain largely restricted to narrow paradigms like false belief tasks, failing to capture the full spectrum of human cognitive mechanisms. We introduce CogToM, a comprehensive, theoretically grounded benchmark comprising over 8000 bilingual instances across 46 paradigms, validated by 49 human annotator.A systematic evaluation of 22 representative models, including frontier models like GPT-5.1 and Qwen3-Max, reveals significant performance heterogeneities and highlights persistent bottlenecks in specific dimensions. Further analysis based on human cognitive patterns suggests potential divergences between LLM and human cognitive structures. CogToM offers a robust instrument and perspective for investigating the evolving cognitive boundaries of LLMs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15628v1</guid></item><item><title>[cs updates on arXiv.org] Agentic AI Governance and Lifecycle Management in Healthcare</title><link>https://arxiv.org/abs/2601.15630</link><description>arXiv:2601.15630v1 Announce Type: new 
Abstract: Healthcare organizations are beginning to embed agentic AI into routine workflows, including clinical documentation support and early-warning monitoring. As these capabilities diffuse across departments and vendors, health systems face agent sprawl, causing duplicated agents, unclear accountability, inconsistent controls, and tool permissions that persist beyond the original use case. Existing AI governance frameworks emphasize lifecycle risk management but provide limited guidance for the day-to-day operations of agent fleets. We propose a Unified Agent Lifecycle Management (UALM) blueprint derived from a rapid, practice-oriented synthesis of governance standards, agent security literature, and healthcare compliance requirements. UALM maps recurring gaps onto five control-plane layers: (1) an identity and persona registry, (2) orchestration and cross-domain mediation, (3) PHI-bounded context and memory, (4) runtime policy enforcement with kill-switch triggers, and (5) lifecycle management and decommissioning linked to credential revocation and audit logging. A companion maturity model supports staged adoption. UALM offers healthcare CIOs, CISOs, and clinical leaders an implementable pattern for audit-ready oversight that preserves local innovation and enables safer scaling across clinical and administrative domains.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15630v1</guid></item><item><title>[cs updates on arXiv.org] Advancing RT Core-Accelerated Fixed-Radius Nearest Neighbor Search</title><link>https://arxiv.org/abs/2601.15633</link><description>arXiv:2601.15633v1 Announce Type: new 
Abstract: In this work we introduce three ideas that can further improve particle FRNN physics simulations running on RT Cores; i) a real-time update/rebuild ratio optimizer for the bounding volume hierarchy (BVH) structure, ii) a new RT core use, with two variants, that eliminates the need of a neighbor list and iii) a technique that enables RT cores for FRNN with periodic boundary conditions (BC). Experimental evaluation using the Lennard-Jones FRNN interaction model as a case study shows that the proposed update/rebuild ratio optimizer is capable of adapting to the different dynamics that emerge during a simulation, leading to a RT core pipeline up to $\sim 3.4\times$ faster than with other known approaches to manage the BVH. In terms of simulation step performance, the proposed variants can significantly improve the speedup and EE of the base RT core idea; from $\sim1.3\times$ at small radius to $\sim2.0\times$ for log normal radius distributions. Furthermore, the proposed variants manage to simulate cases that would otherwise not fit in memory because of the use of neighbor lists, such as clusters of particles with log normal radius distribution. The proposed RT Core technique to support periodic BC is indeed effective as it does not introduce any significant penalty in performance. In terms of scaling, the proposed methods scale both their performance and EE across GPU generations. Throughout the experimental evaluation, we also identify the simulation cases were regular GPU computation should still be preferred, contributing to the understanding of the strengths and limitations of RT cores.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15633v1</guid></item><item><title>[cs updates on arXiv.org] Community-Size Biases in Statistical Inference of Communities in Temporal Networks</title><link>https://arxiv.org/abs/2601.15635</link><description>arXiv:2601.15635v1 Announce Type: new 
Abstract: In the study of time-dependent (i.e., temporal) networks, researchers often examine the evolution of communities, which are sets of densely connected sets of nodes that are connected sparsely to other nodes. An increasingly prominent approach to studying community structure in temporal networks is statistical inference. In the present paper, we study the performance of a class of statistical-inference methods for community detection in temporal networks. We represent temporal networks as multilayer networks, with each layer encoding a time step, and we illustrate that statistical-inference models that generate community assignments via either a uniform distribution on community assignments or discrete-time Markov processes are biased against generating communities with large or small numbers of nodes. In particular, we demonstrate that statistical-inference methods that use such generative models tend to poorly identify community structure in networks with large or small communities. To rectify this issue, we introduce a novel statistical model that generates the community assignments of the nodes in given layer (i.e., at a given time) using all of the community assignments in the previous layer. We prove results that guarantee that our approach greatly mitigates the bias against large and small communities, so using our generative model is beneficial for studying community structure in networks with large or small communities. Our code is available at https://github.com/tfaust0196/TemporalCommunityComparison.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15635v1</guid></item><item><title>[cs updates on arXiv.org] A Class of Subadditive Information Measures and their Applications</title><link>https://arxiv.org/abs/2601.15639</link><description>arXiv:2601.15639v1 Announce Type: new 
Abstract: We introduce a two-parameter family of discrepancy measures, termed \emph{$(G,f)$-divergences}, obtained by applying a non-decreasing function $G$ to an $f$-divergence $D_f$. Building on Csisz\'ar's formulation of mutual $f$-information, we define a corresponding $(G,f)$-information measure $
I_{G,f}(X;Y)$. A central theme of the paper is subadditivity over product distributions and product channels. We develop reduction principles showing that, for broad classes of $G$, it suffices to verify divergence subadditivity on binary alphabets. Specializing to the functions $G(x)\in\{x,\log(1+x),-\log(1-x)\}$, we derive tractable sufficient conditions on $f$ that guarantee subadditivity, covering many standard $f$-divergences. Finally, we present applications to finite-blocklength converses for channel coding, bounds in binary hypothesis testing, and an extension of the Shannon--Gallager--Berlekamp sphere-packing exponent framework to subadditive $(G,f)$-divergences.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15639v1</guid></item><item><title>[cs updates on arXiv.org] An Empirical Study on Ensemble-Based Transfer Learning Bayesian Optimisation with Mixed Variable Types</title><link>https://arxiv.org/abs/2601.15640</link><description>arXiv:2601.15640v1 Announce Type: new 
Abstract: Bayesian optimisation is a sample efficient method for finding a global optimum of expensive black-box objective functions. Historic datasets from related problems can be exploited to help improve performance of Bayesian optimisation by adapting transfer learning methods to various components of the Bayesian optimisation pipeline. In this study we perform an empirical analysis of various ensemble-based transfer learning Bayesian optimisation methods and pipeline components. We expand on previous work in the literature by contributing some specific pipeline components, and three new real-time transfer learning Bayesian optimisation benchmarks. In particular we propose to use a weighting strategy for ensemble surrogate model predictions based on regularised regression with weights constrained to be positive, and a related component for handling the case when transfer learning is not improving Bayesian optimisation performance. We find that in general, two components that help improve transfer learning Bayesian optimisation performance are warm start initialisation and constraining weights used with ensemble surrogate model to be positive.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15640v1</guid></item><item><title>[cs updates on arXiv.org] Generative AI-Empowered Semantic Twin Channel Model for ISAC</title><link>https://arxiv.org/abs/2601.15642</link><description>arXiv:2601.15642v1 Announce Type: new 
Abstract: Integrated sensing and communication (ISAC) increasingly exposes a gap in today's channel modeling. Efficient statistical models focus on coarse communication-centric metrics, and therefore miss the weak but critical multipath signatures for sensing, whereas deterministic models are computationally inefficient to scale for system-level ISAC evaluation. This gap calls for a unifying abstraction that can couple what the environment means for sensing with how the channel behaves for communication, namely, environmental semantics. This article clarifies the meaning and essentiality of environmental semantics in ISAC channel modeling and establishes how semantics is connected to observable channel structures across multiple semantic levels. Based on this perspective, a semantics-oriented channel modeling principle was advocated, which preserves environmental semantics while abstracting unnecessary detail to balance accuracy and complexity. Then, a generative AI-empowered semantic twin channel model (STCM) was introduced to generate a family of physically plausible channel realizations representative of a semantic condition. Case studies further show semantic consistency under challenging multi-view settings, suggesting a practical path to controllable simulation, dataset generation, and reproducible ISAC benchmarking toward future design and standardization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15642v1</guid></item><item><title>[cs updates on arXiv.org] Evolving Without Ending: Unifying Multimodal Incremental Learning for Continual Panoptic Perception</title><link>https://arxiv.org/abs/2601.15643</link><description>arXiv:2601.15643v1 Announce Type: new 
Abstract: Continual learning (CL) is a great endeavour in developing intelligent perception AI systems. However, the pioneer research has predominantly focus on single-task CL, which restricts the potential in multi-task and multimodal scenarios. Beyond the well-known issue of catastrophic forgetting, the multi-task CL also brings semantic obfuscation across multimodal alignment, leading to severe model degradation during incremental training steps. In this paper, we extend CL to continual panoptic perception (CPP), integrating multimodal and multi-task CL to enhance comprehensive image perception through pixel-level, instance-level, and image-level joint interpretation. We formalize the CL task in multimodal scenarios and propose an end-to-end continual panoptic perception model. Concretely, CPP model features a collaborative cross-modal encoder (CCE) for multimodal embedding. We also propose a malleable knowledge inheritance module via contrastive feature distillation and instance distillation, addressing catastrophic forgetting from task-interactive boosting manner. Furthermore, we propose a cross-modal consistency constraint and develop CPP+, ensuring multimodal semantic alignment for model updating under multi-task incremental scenarios. Additionally, our proposed model incorporates an asymmetric pseudo-labeling manner, enabling model evolving without exemplar replay. Extensive experiments on multimodal datasets and diverse CL tasks demonstrate the superiority of the proposed model, particularly in fine-grained CL tasks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15643v1</guid></item><item><title>[cs updates on arXiv.org] Towards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation</title><link>https://arxiv.org/abs/2601.15645</link><description>arXiv:2601.15645v1 Announce Type: new 
Abstract: Large-scale language models (LLMs) often offer clinical judgments based on incomplete information, increasing the risk of misdiagnosis. Existing studies have primarily evaluated confidence in single-turn, static settings, overlooking the coupling between confidence and correctness as clinical evidence accumulates during real consultations, which limits their support for reliable decision-making. We propose the first benchmark for assessing confidence in multi-turn interaction during realistic medical consultations. Our benchmark unifies three types of medical data for open-ended diagnostic generation and introduces an information sufficiency gradient to characterize the confidence-correctness dynamics as evidence increases. We implement and compare 27 representative methods on this benchmark; two key insights emerge: (1) medical data amplifies the inherent limitations of token-level and consistency-level confidence methods, and (2) medical reasoning must be evaluated for both diagnostic accuracy and information completeness. Based on these insights, we present MedConf, an evidence-grounded linguistic self-assessment framework that constructs symptom profiles via retrieval-augmented generation, aligns patient information with supporting, missing, and contradictory relations, and aggregates them into an interpretable confidence estimate through weighted integration. Across two LLMs and three medical datasets, MedConf consistently outperforms state-of-the-art methods on both AUROC and Pearson correlation coefficient metrics, maintaining stable performance under conditions of information insufficiency and multimorbidity. These results demonstrate that information adequacy is a key determinant of credible medical confidence modeling, providing a new pathway toward building more reliable and interpretable large medical models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15645v1</guid></item><item><title>[cs updates on arXiv.org] Predictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models</title><link>https://arxiv.org/abs/2601.15652</link><description>arXiv:2601.15652v1 Announce Type: new 
Abstract: Hallucinations in Large Language Models (LLMs) -- generations that are plausible but factually unfaithful -- remain a critical barrier to high-stakes deployment. Current detection methods typically rely on computationally expensive external retrieval loops or opaque black-box LLM judges requiring 70B+ parameters. In this work, we introduce [Model Name], a hybrid detection framework that combines neuroscience-inspired signal design with supervised machine learning. We extract interpretable signals grounded in Predictive Coding (quantifying surprise against internal priors) and the Information Bottleneck (measuring signal retention under perturbation). Through systematic ablation, we demonstrate three key enhancements: Entity-Focused Uptake (concentrating on high-value tokens), Context Adherence (measuring grounding strength), and Falsifiability Score (detecting confident but contradictory claims).
  Evaluating on HaluBench (n=200, perfectly balanced), our theory-guided baseline achieves 0.8017 AUROC. BASE supervised models reach 0.8274 AUROC, while IMPROVED features boost performance to 0.8669 AUROC (4.95% gain), demonstrating consistent improvements across architectures. This competitive performance is achieved while using 75x less training data than Lynx (200 vs 15,000 samples), 1000x faster inference (5ms vs 5s), and remaining fully interpretable. Crucially, we report a negative result: the Rationalization signal fails to distinguish hallucinations, suggesting that LLMs generate coherent reasoning for false premises ("Sycophancy").
  This work demonstrates that domain knowledge encoded in signal architecture provides superior data efficiency compared to scaling LLM judges, achieving strong performance with lightweight (less than 1M parameter), explainable models suitable for production deployment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15652v1</guid></item><item><title>[cs updates on arXiv.org] Event-VStream: Event-Driven Real-Time Understanding for Long Video Streams</title><link>https://arxiv.org/abs/2601.15655</link><description>arXiv:2601.15655v1 Announce Type: new 
Abstract: Real-time understanding of long video streams remains challenging for multimodal large language models (VLMs) due to redundant frame processing and rapid forgetting of past context. Existing streaming systems rely on fixed-interval decoding or cache pruning, which either produce repetitive outputs or discard crucial temporal information. We introduce Event-VStream, an event-aware framework that represents continuous video as a sequence of discrete, semantically coherent events. Our system detects meaningful state transitions by integrating motion, semantic, and predictive cues, and triggers language generation only at those boundaries. Each event embedding is consolidated into a persistent memory bank, enabling long-horizon reasoning while maintaining low latency. Across OVOBench-Realtime, and long-form Ego4D evaluations, Event-VStream achieves competitive performance. It improves over a VideoLLM-Online-8B baseline by +10.4 points on OVOBench-Realtime, achieves performance close to Flash-VStream-7B despite using only a general-purpose LLaMA-3-8B text backbone, and maintains around 70% GPT-5 win rate on 2-hour Ego4D streams.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15655v1</guid></item><item><title>[cs updates on arXiv.org] Reflective Motion and a Physical Canvas: Exploring Embodied Journaling in Virtual Reality</title><link>https://arxiv.org/abs/2601.15656</link><description>arXiv:2601.15656v1 Announce Type: new 
Abstract: In traditional journaling practices, authors express and process their thoughts by writing them down. We propose a somaesthetic-inspired alternative that uses the human body, rather than written words, as the medium of expression. We coin this embodied journaling, as people's isolated body movements and spoken words become the canvas of reflection. We implemented embodied journaling in virtual reality and conducted a within-subject user study (n=20) to explore the emergent behaviours from the process and to compare its expressive and reflective qualities to those of written journaling. When writing-based norms and affordances were absent, we found that participants defaulted towards unfiltered emotional expression, often forgoing words altogether. Rather, subconscious body motion and paralinguistic acoustic qualities unveiled deeper, sometimes hidden feelings, prompting reflection that happens after emotional expression rather than during it. We discuss both the capabilities and pitfalls of embodied journaling, ultimately challenging the idea that reflection culminates in linguistic reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15656v1</guid></item><item><title>[cs updates on arXiv.org] Integrating Knowledge Distillation Methods: A Sequential Multi-Stage Framework</title><link>https://arxiv.org/abs/2601.15657</link><description>arXiv:2601.15657v1 Announce Type: new 
Abstract: Knowledge distillation (KD) transfers knowledge from large teacher models to compact student models, enabling efficient deployment on resource constrained devices. While diverse KD methods, including response based, feature based, and relation based approaches, capture different aspects of teacher knowledge, integrating multiple methods or knowledge sources is promising but often hampered by complex implementation, inflexible combinations, and catastrophic forgetting, which limits practical effectiveness.
  This work proposes SMSKD (Sequential Multi Stage Knowledge Distillation), a flexible framework that sequentially integrates heterogeneous KD methods. At each stage, the student is trained with a specific distillation method, while a frozen reference model from the previous stage anchors learned knowledge to mitigate forgetting. In addition, we introduce an adaptive weighting mechanism based on the teacher true class probability (TCP) that dynamically adjusts the reference loss per sample to balance knowledge retention and integration.
  By design, SMSKD supports arbitrary method combinations and stage counts with negligible computational overhead. Extensive experiments show that SMSKD consistently improves student accuracy across diverse teacher student architectures and method combinations, outperforming existing baselines. Ablation studies confirm that stage wise distillation and reference model supervision are primary contributors to performance gains, with TCP based adaptive weighting providing complementary benefits. Overall, SMSKD is a practical and resource efficient solution for integrating heterogeneous KD methods.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15657v1</guid></item><item><title>[cs updates on arXiv.org] TempoNet: Learning Realistic Communication and Timing Patterns for Network Traffic Simulation</title><link>https://arxiv.org/abs/2601.15663</link><description>arXiv:2601.15663v1 Announce Type: new 
Abstract: Realistic network traffic simulation is critical for evaluating intrusion detection systems, stress-testing network protocols, and constructing high-fidelity environments for cybersecurity training. While attack traffic can often be layered into training environments using red-teaming or replay methods, generating authentic benign background traffic remains a core challenge -- particularly in simulating the complex temporal and communication dynamics of real-world networks. This paper introduces TempoNet, a novel generative model that combines multi-task learning with multi-mark temporal point processes to jointly model inter-arrival times and all packet- and flow-header fields. TempoNet captures fine-grained timing patterns and higher-order correlations such as host-pair behavior and seasonal trends, addressing key limitations of GAN-, LLM-, and Bayesian-based methods that fail to reproduce structured temporal variation. TempoNet produces temporally consistent, high-fidelity traces, validated on real-world datasets. Furthermore, we show that intrusion detection models trained on TempoNet-generated background traffic perform comparably to those trained on real data, validating its utility for real-world security applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15663v1</guid></item><item><title>[cs updates on arXiv.org] Skywork UniPic 3.0: Unified Multi-Image Composition via Sequence Modeling</title><link>https://arxiv.org/abs/2601.15664</link><description>arXiv:2601.15664v1 Announce Type: new 
Abstract: The recent surge in popularity of Nano-Banana and Seedream 4.0 underscores the community's strong interest in multi-image composition tasks. Compared to single-image editing, multi-image composition presents significantly greater challenges in terms of consistency and quality, yet existing models have not disclosed specific methodological details for achieving high-quality fusion. Through statistical analysis, we identify Human-Object Interaction (HOI) as the most sought-after category by the community. We therefore systematically analyze and implement a state-of-the-art solution for multi-image composition with a primary focus on HOI-centric tasks. We present Skywork UniPic 3.0, a unified multimodal framework that integrates single-image editing and multi-image composition. Our model supports an arbitrary (1~6) number and resolution of input images, as well as arbitrary output resolutions (within a total pixel budget of 1024x1024). To address the challenges of multi-image composition, we design a comprehensive data collection, filtering, and synthesis pipeline, achieving strong performance with only 700K high-quality training samples. Furthermore, we introduce a novel training paradigm that formulates multi-image composition as a sequence-modeling problem, transforming conditional generation into unified sequence synthesis. To accelerate inference, we integrate trajectory mapping and distribution matching into the post-training stage, enabling the model to produce high-fidelity samples in just 8 steps and achieve a 12.5x speedup over standard synthesis sampling. Skywork UniPic 3.0 achieves state-of-the-art performance on single-image editing benchmark and surpasses both Nano-Banana and Seedream 4.0 on multi-image composition benchmark, thereby validating the effectiveness of our data pipeline and training paradigm. Code, models and dataset are publicly available.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15664v1</guid></item><item><title>[cs updates on arXiv.org] Impression Zombies: Characteristics Analysis and Classification of New Harmful Accounts on Social Media</title><link>https://arxiv.org/abs/2601.15666</link><description>arXiv:2601.15666v1 Announce Type: new 
Abstract: ``Impression Zombies'', a type of malicious account designed to artificially inflate engagement metrics, have recently emerged as a significant threat on X (formerly Twitter). These accounts disseminate a high volume of low-quality, irrelevant posts, which degrade the user experience. This study aims (1) to quantitatively characterize their behavioral patterns and (2) to develop a method for detecting such accounts. To address the first objective, we collected data from 9,909 accounts and compared the characteristics of Impression Zombies and general users within this dataset. We find that, Impression Zombies post more than three times the average total number of posts per day and tend to gather followers by using phrases such as ``follow back.'' Addressing the second objective, we constructed a classification model for Impression Zombies that leverages the contextual incoherence often observed between parent posts and the replies from Impression Zombies. Experimental results show that our model achieved approximately 92\% accuracy in detecting Impression Zombies. This study provides the first quantitative insights into Impression Zombies and offers a practical framework for detecting such accounts, contributing to platform transparency and the health of social media ecosystems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15666v1</guid></item><item><title>[cs updates on arXiv.org] EmotionThinker: Prosody-Aware Reinforcement Learning for Explainable Speech Emotion Reasoning</title><link>https://arxiv.org/abs/2601.15668</link><description>arXiv:2601.15668v1 Announce Type: new 
Abstract: Emotional information in speech plays a unique role in multimodal perception. However, current Speech Large Language Models (SpeechLLMs), similar to conventional speech emotion recognition (SER) systems, still treat emotion understanding as a simple classification problem. This provides limited interpretability of predictions, while leaving the LLMs' expressive and reasoning capabilities underutilized. In this work, we take the first step to reformulate SER as a deep reasoning problem through reinforcement learning (RL). We propose EmotionThinker, which is designed to generate accurate emotion predictions with interpretable explanations grounded in fine-grained acoustic cues. To achieve this, we first construct EmotionCoT-35K, an emotional reasoning dataset with Chain-of-Thought annotations and detailed captions. Second, we observe that current SpeechLLMs exhibit weak prosody perception, whereas prosodic cues constitute fundamental signals for interpreting emotions. To address this, we develop the prosody-enhanced foundation model EmotionThinker-Base, and demonstrate that prosody enhancement improves emotion understanding. Third, we introduce Group-Relative-Policy-Optimization with Progressive-Trust-aware-Reasoning-Reward (GRPO-PTR) for RL. Different from standard GRPO, which relies only on rule-based outcome rewards, GRPO-PTR progressively introduces reasoning reward, dynamically adjusts it with a trustworthiness weight reflecting the alignment between reasoning and outcome, and evaluates the overall reasoning quality with a reward model based on multi-dimensional criteria. EmotionThinker outperforms previous state-of-the-art evaluation models both in emotion accuracy and explanation quality, advancing SER toward interpretable multimodal reasoning. Project page: https://github.com/dingdongwang/EmotionThinker</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15668v1</guid></item><item><title>[cs updates on arXiv.org] Dualformer: Time-Frequency Dual Domain Learning for Long-term Time Series Forecasting</title><link>https://arxiv.org/abs/2601.15669</link><description>arXiv:2601.15669v1 Announce Type: new 
Abstract: Transformer-based models, despite their promise for long-term time series forecasting (LTSF), suffer from an inherent low-pass filtering effect that limits their effectiveness. This issue arises due to undifferentiated propagation of frequency components across layers, causing a progressive attenuation of high-frequency information crucial for capturing fine-grained temporal variations. To address this limitation, we propose Dualformer, a principled dual-domain framework that rethinks frequency modeling from a layer-wise perspective. Dualformer introduces three key components: (1) a dual-branch architecture that concurrently models complementary temporal patterns in both time and frequency domains; (2) a hierarchical frequency sampling module that allocates distinct frequency bands to different layers, preserving high-frequency details in lower layers while modeling low-frequency trends in deeper layers; and (3) a periodicity-aware weighting mechanism that dynamically balances contributions from the dual branches based on the harmonic energy ratio of inputs, supported theoretically by a derived lower bound. This design enables structured frequency modeling and adaptive integration of time-frequency features, effectively preserving high-frequency information and enhancing generalization. Extensive experiments conducted on eight widely used benchmarks demonstrate Dualformer's robustness and superior performance, particularly on heterogeneous or weakly periodic data. Our code is publicly available at https://github.com/Akira-221/Dualformer.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15669v1</guid></item><item><title>[cs updates on arXiv.org] StreetDesignAI: A Multi-Persona Evaluation System for Inclusive Infrastructure Design</title><link>https://arxiv.org/abs/2601.15671</link><description>arXiv:2601.15671v1 Announce Type: new 
Abstract: Designing inclusive cycling infrastructure requires balancing competing needs of diverse user groups, yet designers often struggle to anticipate how different cyclists experience the same street. We investigate how persona-based multi-agent evaluation can support inclusive design by making experiential conflicts explicit. We present StreetDesignAI, an interactive system that enables designers to (1) ground evaluation in street context through imagery and map data, (2) receive parallel feedback from cyclist personas spanning confident to cautious users, and (3) iteratively modify designs while surfacing conflicts across perspectives. A within-subjects study with 26 transportation professionals demonstrates that structured multi-perspective feedback significantly improves designers' understanding of diverse user perspectives, ability to identify persona needs, and confidence in translating them into design decisions, with higher satisfaction and stronger intention for professional adoption. Qualitative findings reveal how conflict surfacing transforms design exploration from single-perspective optimization toward deliberate trade-off reasoning. We discuss implications for AI tools that scaffold inclusive design through disagreement as an interaction primitive.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15671v1</guid></item><item><title>[cs updates on arXiv.org] Enhancing guidance for missing data in diffusion-based sequential recommendation</title><link>https://arxiv.org/abs/2601.15673</link><description>arXiv:2601.15673v1 Announce Type: new 
Abstract: Contemporary sequential recommendation methods are becoming more complex, shifting from classification to a diffusion-guided generative paradigm. However, the quality of guidance in the form of user information is often compromised by missing data in the observed sequences, leading to suboptimal generation quality. Existing methods address this by removing locally similar items, but overlook ``critical turning points'' in user interest, which are crucial for accurately predicting subsequent user intent. To address this, we propose a novel Counterfactual Attention Regulation Diffusion model (CARD), which focuses on amplifying the signal from key interest-turning-point items while concurrently identifying and suppressing noise within the user sequence. CARD consists of (1) a Dual-side Thompson Sampling method to identify sequences undergoing significant interest shift, and (2) a counterfactual attention mechanism for these sequences to quantify the importance of each item. In this manner, CARD provides the diffusion model with a high-quality guidance signal composed of dynamically re-weighted interaction vectors to enable effective generation. Experiments show our method works well on real-world data without being computationally expensive. Our code is available at https://github.com/yanqilong3321/CARD.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15673v1</guid></item><item><title>[cs updates on arXiv.org] What Patients Really Ask: Exploring the Effect of False Assumptions in Patient Information Seeking</title><link>https://arxiv.org/abs/2601.15674</link><description>arXiv:2601.15674v1 Announce Type: new 
Abstract: Patients are increasingly using large language models (LLMs) to seek answers to their healthcare-related questions. However, benchmarking efforts in LLMs for question answering often focus on medical exam questions, which differ significantly in style and content from the questions patients actually raise in real life. To bridge this gap, we sourced data from Google's People Also Ask feature by querying the top 200 prescribed medications in the United States, curating a dataset of medical questions people commonly ask. A considerable portion of the collected questions contains incorrect assumptions and dangerous intentions. We demonstrate that the emergence of these corrupted questions is not uniformly random and depends heavily on the degree of incorrectness in the history of questions that led to their appearance. Current LLMs that perform strongly on other benchmarks struggle to identify incorrect assumptions in everyday questions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15674v1</guid></item><item><title>[cs updates on arXiv.org] Bridging the Perception Gap: A Lightweight Coarse-to-Fine Architecture for Edge Audio Systems</title><link>https://arxiv.org/abs/2601.15676</link><description>arXiv:2601.15676v1 Announce Type: new 
Abstract: Deploying Audio-Language Models (Audio-LLMs) on edge infrastructure exposes a persistent tension between perception depth and computational efficiency. Lightweight local models tend to produce passive perception - generic summaries that miss the subtle evidence required for multi-step audio reasoning - while indiscriminate cloud offloading incurs unacceptable latency, bandwidth cost, and privacy risk. We propose CoFi-Agent (Tool-Augmented Coarse-to-Fine Agent), a hybrid architecture targeting edge servers and gateways. It performs fast local perception and triggers conditional forensic refinement only when uncertainty is detected. CoFi-Agent runs an initial single-pass on a local 7B Audio-LLM, then a cloud controller gates difficult cases and issues lightweight plans for on-device tools such as temporal re-listening and local ASR. On the MMAR benchmark, CoFi-Agent improves accuracy from 27.20% to 53.60%, while achieving a better accuracy-efficiency trade-off than an always-on investigation pipeline. Overall, CoFi-Agent bridges the perception gap via tool-enabled, conditional edge-cloud collaboration under practical system constraints.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15676v1</guid></item><item><title>[cs updates on arXiv.org] Connect the Dots: Knowledge Graph-Guided Crawler Attack on Retrieval-Augmented Generation Systems</title><link>https://arxiv.org/abs/2601.15678</link><description>arXiv:2601.15678v1 Announce Type: new 
Abstract: Retrieval-augmented generation (RAG) systems integrate document retrieval with large language models and have been widely adopted. However, in privacy-related scenarios, RAG introduces a new privacy risk: adversaries can issue carefully crafted queries to exfiltrate sensitive content from the underlying corpus gradually. Although recent studies have demonstrated multi-turn extraction attacks, they rely on heuristics and fail to perform long-term extraction planning. To address these limitations, we formulate the RAG extraction attack as an adaptive stochastic coverage problem (ASCP). In ASCP, each query is treated as a probabilistic action that aims to maximize conditional marginal gain (CMG), enabling principled long-term planning under uncertainty. However, integrating ASCP with practical RAG attack faces three key challenges: unobservable CMG, intractability in the action space, and feasibility constraints. To overcome these challenges, we maintain a global attacker-side state to guide the attack. Building on this idea, we introduce RAGCRAWLER, which builds a knowledge graph to represent revealed information, uses this global state to estimate CMG, and plans queries in semantic space that target unretrieved regions. In comprehensive experiments across diverse RAG architectures and datasets, our proposed method, RAGCRAWLER, consistently outperforms all baselines. It achieves up to 84.4% corpus coverage within a fixed query budget and deliver an average improvement of 20.7% over the top-performing baseline. It also maintains high semantic fidelity and strong content reconstruction accuracy with low attack cost. Crucially, RAGCRAWLER proves its robustness by maintaining effectiveness against advanced RAG systems employing query rewriting and multi-query retrieval strategies. Our work reveals significant security gaps and highlights the pressing need for stronger safeguards for RAG.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15678v1</guid></item><item><title>[cs updates on arXiv.org] Improving Methodologies for Agentic Evaluations Across Domains: Leakage of Sensitive Information, Fraud and Cybersecurity Threats</title><link>https://arxiv.org/abs/2601.15679</link><description>arXiv:2601.15679v1 Announce Type: new 
Abstract: The rapid rise of autonomous AI systems and advancements in agent capabilities are introducing new risks due to reduced oversight of real-world interactions. Yet agent testing remains nascent and is still a developing science. As AI agents begin to be deployed globally, it is important that they handle different languages and cultures accurately and securely.
  To address this, participants from The International Network for Advanced AI Measurement, Evaluation and Science, including representatives from Singapore, Japan, Australia, Canada, the European Commission, France, Kenya, South Korea, and the United Kingdom have come together to align approaches to agentic evaluations.
  This is the third exercise, building on insights from two earlier joint testing exercises conducted by the Network in November 2024 and February 2025. The objective is to further refine best practices for testing advanced AI systems.
  The exercise was split into two strands: (1) common risks, including leakage of sensitive information and fraud, led by Singapore AISI; and (2) cybersecurity, led by UK AISI. A mix of open and closed-weight models were evaluated against tasks from various public agentic benchmarks. Given the nascency of agentic testing, our primary focus was on understanding methodological issues in conducting such tests, rather than examining test results or model capabilities. This collaboration marks an important step forward as participants work together to advance the science of agentic evaluations.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15679v1</guid></item><item><title>[cs updates on arXiv.org] Consistency-Regularized GAN for Few-Shot SAR Target Recognition</title><link>https://arxiv.org/abs/2601.15681</link><description>arXiv:2601.15681v1 Announce Type: new 
Abstract: Few-shot recognition in synthetic aperture radar (SAR) imagery remains a critical bottleneck for real-world applications due to extreme data scarcity. A promising strategy involves synthesizing a large dataset with a generative adversarial network (GAN), pre-training a model via self-supervised learning (SSL), and then fine-tuning on the few labeled samples. However, this approach faces a fundamental paradox: conventional GANs themselves require abundant data for stable training, contradicting the premise of few-shot learning. To resolve this, we propose the consistency-regularized generative adversarial network (Cr-GAN), a novel framework designed to synthesize diverse, high-fidelity samples even when trained under these severe data limitations. Cr-GAN introduces a dual-branch discriminator that decouples adversarial training from representation learning. This architecture enables a channel-wise feature interpolation strategy to create novel latent features, complemented by a dual-domain cycle consistency mechanism that ensures semantic integrity. Our Cr-GAN framework is adaptable to various GAN architectures, and its synthesized data effectively boosts multiple SSL algorithms. Extensive experiments on the MSTAR and SRSDD datasets validate our approach, with Cr-GAN achieving a highly competitive accuracy of 71.21% and 51.64%, respectively, in the 8-shot setting, significantly outperforming leading baselines, while requiring only ~5 of the parameters of state-of-the-art diffusion models. Code is available at: https://github.com/yikuizhai/Cr-GAN.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15681v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Hard Writes and Rigid Preservation: Soft Recursive Least-Squares for Lifelong LLM Editing</title><link>https://arxiv.org/abs/2601.15686</link><description>arXiv:2601.15686v1 Announce Type: new 
Abstract: Model editing updates a pre-trained LLM with new facts or rules without re-training, while preserving unrelated behavior. In real deployment, edits arrive as long streams, and existing editors often face a plasticity-stability dilemma: locate-then-edit "hard writes" can accumulate interference over time, while null-space-style "hard preservation" preserves only what is explicitly constrained, so past edits can be overwritten and unconstrained behaviors may deviate, degrading general capabilities in the many-edits regime. We propose RLSEdit, a recursive least-squares editor for long sequential editing. RLSEdit formulates editing as an online quadratic optimization with soft constraints, minimizing a cumulative key-value fitting objective with two regularizers that control for both deviation from the pre-trained weights and from a designated anchor mapping. The resulting update admits an efficient online recursion via the Woodbury identity, with per-edit cost independent of history length and scaling only with the current edit size. We further provide deviation bounds and an asymptotic characterization of the adherence-preservation trade-off in the many-edits regime. Experiments on multiple model families demonstrate stable scaling to 10K edits, outperforming strong baselines in both edit success and holistic stability -- crucially retaining early edits, and preserving general capabilities on GLUE and held-out reasoning/code benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15686v1</guid></item><item><title>[cs updates on arXiv.org] FARM: Field-Aware Resolution Model for Intelligent Trigger-Action Automation</title><link>https://arxiv.org/abs/2601.15687</link><description>arXiv:2601.15687v1 Announce Type: new 
Abstract: Trigger-Action Programming (TAP) platforms such as IFTTT and Zapier enable Web of Things (WoT) automation by composing event-driven rules across heterogeneous services. A TAP applet links a trigger to an action and must bind trigger outputs (ingredients) to action inputs (fields) to be executable. Prior work largely treats TAP as service-level prediction from natural language, which often yields non-executable applets that still require manual configuration. We study the function-level configuration problem: generating complete applets with correct ingredient-to-field bindings. We propose FARM (Field-Aware Resolution Model), a two-stage architecture for automated applet generation with full configuration. Stage 1 trains contrastive dual encoders with selective layer freezing over schema-enriched representations, retrieving candidates from 1,724 trigger functions and 1,287 action functions (2.2M possible trigger-action pairs). Stage 2 performs selection and configuration using an LLM-based multi-agent pipeline. It includes intent analysis, trigger selection, action selection via cross-schema scoring, and configuration verification. Agents coordinate through shared state and agreement-based selection. FARM achieves 81% joint accuracy on Gold (62% Noisy, 70% One-shot) at the function level, where both trigger and action functions must match the ground truth. For comparison with service-level baselines, we map functions to their parent services and evaluate at the service level. FARM reaches 81% joint accuracy and improves over TARGE by 23 percentage points. FARM also generates ingredient-to-field bindings, producing executable automation configurations.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15687v1</guid></item><item><title>[cs updates on arXiv.org] Performance-guided Reinforced Active Learning for Object Detection</title><link>https://arxiv.org/abs/2601.15688</link><description>arXiv:2601.15688v1 Announce Type: new 
Abstract: Active learning (AL) strategies aim to train high-performance models with minimal labeling efforts, only selecting the most informative instances for annotation. Current approaches to evaluating data informativeness predominantly focus on the data's distribution or intrinsic information content and do not directly correlate with downstream task performance, such as mean average precision (mAP) in object detection. Thus, we propose Performance-guided (i.e. mAP-guided) Reinforced Active Learning for Object Detection (MGRAL), a novel approach that leverages the concept of expected model output changes as informativeness. To address the combinatorial explosion challenge of batch sample selection and the non-differentiable correlation between model performance and selected batches, MGRAL skillfully employs a reinforcement learning-based sampling agent that optimizes selection using policy gradient with mAP improvement as reward. Moreover, to reduce the computational overhead of mAP estimation with unlabeled samples, MGRAL utilizes an unsupervised way with fast look-up tables, ensuring feasible deployment. We evaluate MGRAL's active learning performance on detection tasks over PASCAL VOC and COCO benchmarks. Our approach demonstrates the highest AL curve with convincing visualizations, establishing a new paradigm in reinforcement learning-driven active object detection.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15688v1</guid></item><item><title>[cs updates on arXiv.org] From Passive Metric to Active Signal: The Evolving Role of Uncertainty Quantification in Large Language Models</title><link>https://arxiv.org/abs/2601.15690</link><description>arXiv:2601.15690v1 Announce Type: new 
Abstract: While Large Language Models (LLMs) show remarkable capabilities, their unreliability remains a critical barrier to deployment in high-stakes domains. This survey charts a functional evolution in addressing this challenge: the evolution of uncertainty from a passive diagnostic metric to an active control signal guiding real-time model behavior. We demonstrate how uncertainty is leveraged as an active control signal across three frontiers: in \textbf{advanced reasoning} to optimize computation and trigger self-correction; in \textbf{autonomous agents} to govern metacognitive decisions about tool use and information seeking; and in \textbf{reinforcement learning} to mitigate reward hacking and enable self-improvement via intrinsic rewards. By grounding these advancements in emerging theoretical frameworks like Bayesian methods and Conformal Prediction, we provide a unified perspective on this transformative trend. This survey provides a comprehensive overview, critical analysis, and practical design patterns, arguing that mastering the new trend of uncertainty is essential for building the next generation of scalable, reliable, and trustworthy AI.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15690v1</guid></item><item><title>[cs updates on arXiv.org] Balancing Security and Privacy: The Pivotal Role of AI in Modern Healthcare Systems</title><link>https://arxiv.org/abs/2601.15697</link><description>arXiv:2601.15697v1 Announce Type: new 
Abstract: As digital threats continue to grow, organizations must find ways to enhance security while protecting user privacy. This paper explores how artificial intelligence (AI) plays a crucial role in achieving this balance. AI technologies can improve security by detecting threats, monitoring systems, and automating responses. However, using AI also raises privacy concerns that need careful consideration.We examine real-world examples from the healthcare sector to illustrate how organizations can implement AI solutions that strengthen security without compromising patient privacy. Additionally, we discuss the importance of creating transparent AI systems and adhering to privacy regulations.Ultimately, this paper provides insights and recommendations for integrating AI into healthcare security practices, helping organizations navigate the challenges of modern management while keeping patient data safe.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15697v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs</title><link>https://arxiv.org/abs/2601.15698</link><description>arXiv:2601.15698v1 Announce Type: new 
Abstract: The rapid advancement of Multimodal Large Language Models (MLLMs) has introduced complex security challenges, particularly at the intersection of textual and visual safety. While existing schemes have explored the security vulnerabilities of MLLMs, the investigation into their visual safety boundaries remains insufficient. In this paper, we propose Beyond Visual Safety (BVS), a novel image-text pair jailbreaking framework specifically designed to probe the visual safety boundaries of MLLMs. BVS employs a "reconstruction-then-generation" strategy, leveraging neutralized visual splicing and inductive recomposition to decouple malicious intent from raw inputs, thereby leading MLLMs to be induced into generating harmful images. Experimental results demonstrate that BVS achieves a remarkable jailbreak success rate of 98.21\% against GPT-5 (12 January 2026 release). Our findings expose critical vulnerabilities in the visual safety alignment of current MLLMs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15698v1</guid></item><item><title>[cs updates on arXiv.org] Agentic Uncertainty Quantification</title><link>https://arxiv.org/abs/2601.15703</link><description>arXiv:2601.15703v1 Announce Type: new 
Abstract: Although AI agents have demonstrated impressive capabilities in long-horizon reasoning, their reliability is severely hampered by the ``Spiral of Hallucination,'' where early epistemic errors propagate irreversibly. Existing methods face a dilemma: uncertainty quantification (UQ) methods typically act as passive sensors, only diagnosing risks without addressing them, while self-reflection mechanisms suffer from continuous or aimless corrections. To bridge this gap, we propose a unified Dual-Process Agentic UQ (AUQ) framework that transforms verbalized uncertainty into active, bi-directional control signals. Our architecture comprises two complementary mechanisms: System 1 (Uncertainty-Aware Memory, UAM), which implicitly propagates verbalized confidence and semantic explanations to prevent blind decision-making; and System 2 (Uncertainty-Aware Reflection, UAR), which utilizes these explanations as rational cues to trigger targeted inference-time resolution only when necessary. This enables the agent to balance efficient execution and deep deliberation dynamically. Extensive experiments on closed-loop benchmarks and open-ended deep research tasks demonstrate that our training-free approach achieves superior performance and trajectory-level calibration. We believe this principled framework AUQ represents a significant step towards reliable agents.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15703v1</guid></item><item><title>[cs updates on arXiv.org] Enhanced LULC Segmentation via Lightweight Model Refinements on ALOS-2 SAR Data</title><link>https://arxiv.org/abs/2601.15705</link><description>arXiv:2601.15705v1 Announce Type: new 
Abstract: This work focuses on national-scale land-use/land-cover (LULC) semantic segmentation using ALOS-2 single-polarization (HH) SAR data over Japan, together with a companion binary water detection task. Building on SAR-W-MixMAE self-supervised pretraining [1], we address common SAR dense-prediction failure modes, boundary over-smoothing, missed thin/slender structures, and rare-class degradation under long-tailed labels, without increasing pipeline complexity. We introduce three lightweight refinements: (i) injecting high-resolution features into multi-scale decoding, (ii) a progressive refine-up head that alternates convolutional refinement and stepwise upsampling, and (iii) an $\alpha$-scale factor that tempers class reweighting within a focal+dice objective. The resulting model yields consistent improvements on the Japan-wide ALOS-2 LULC benchmark, particularly for under-represented classes, and improves water detection across standard evaluation metrics.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15705v1</guid></item><item><title>[cs updates on arXiv.org] Improving Methodologies for LLM Evaluations Across Global Languages</title><link>https://arxiv.org/abs/2601.15706</link><description>arXiv:2601.15706v1 Announce Type: new 
Abstract: As frontier AI models are deployed globally, it is essential that their behaviour remains safe and reliable across diverse linguistic and cultural contexts. To examine how current model safeguards hold up in such settings, participants from the International Network for Advanced AI Measurement, Evaluation and Science, including representatives from Singapore, Japan, Australia, Canada, the EU, France, Kenya, South Korea and the UK conducted a joint multilingual evaluation exercise. Led by Singapore AISI, two open-weight models were tested across ten languages spanning high and low resourced groups: Cantonese English, Farsi, French, Japanese, Korean, Kiswahili, Malay, Mandarin Chinese and Telugu. Over 6,000 newly translated prompts were evaluated across five harm categories (privacy, non-violent crime, violent crime, intellectual property and jailbreak robustness), using both LLM-as-a-judge and human annotation.
  The exercise shows how safety behaviours can vary across languages. These include differences in safeguard robustness across languages and harm types and variation in evaluator reliability (LLM-as-judge vs. human review). Further, it also generated methodological insights for improving multilingual safety evaluations, such as the need for culturally contextualised translations, stress-tested evaluator prompts and clearer human annotation guidelines. This work represents an initial step toward a shared framework for multilingual safety testing of advanced AI systems and calls for continued collaboration with the wider research community and industry.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15706v1</guid></item><item><title>[cs updates on arXiv.org] D-Optimality-Guided Reinforcement Learning for Efficient Open-Loop Calibration of a 3-DOF Ankle Rehabilitation Robot</title><link>https://arxiv.org/abs/2601.15707</link><description>arXiv:2601.15707v1 Announce Type: new 
Abstract: Accurate alignment of multi-degree-of-freedom rehabilitation robots is essential for safe and effective patient training. This paper proposes a two-stage calibration framework for a self-designed three-degree-of-freedom (3-DOF) ankle rehabilitation robot. First, a Kronecker-product-based open-loop calibration method is developed to cast the input-output alignment into a linear parameter identification problem, which in turn defines the associated experimental design objective through the resulting information matrix. Building on this formulation, calibration posture selection is posed as a combinatorial design-of-experiments problem guided by a D-optimality criterion, i.e., selecting a small subset of postures that maximises the determinant of the information matrix. To enable practical selection under constraints, a Proximal Policy Optimization (PPO) agent is trained in simulation to choose 4 informative postures from a candidate set of 50. Across simulation and real-robot evaluations, the learned policy consistently yields substantially more informative posture combinations than random selection: the mean determinant of the information matrix achieved by PPO is reported to be more than two orders of magnitude higher with reduced variance. In addition, real-world results indicate that a parameter vector identified from only four D-optimality-guided postures provides stronger cross-episode prediction consistency than estimates obtained from a larger but unstructured set of 50 postures. The proposed framework therefore improves calibration efficiency while maintaining robust parameter estimation, offering practical guidance for high-precision alignment of multi-DOF rehabilitation robots.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15707v1</guid></item><item><title>[cs updates on arXiv.org] Persona Switch: Mixing Distinct Perspectives in Decoding Time</title><link>https://arxiv.org/abs/2601.15708</link><description>arXiv:2601.15708v1 Announce Type: new 
Abstract: Role-play prompting is known to steer the behavior of language models by injecting a persona into the prompt, improving their zero-shot reasoning capabilities. However, such improvements are inconsistent across different tasks or instances. This inconsistency suggests that zero-shot and role-play prompting may offer complementary strengths rather than one being universally superior. Building on this insight, we propose Persona Switch, a novel decoding method that dynamically combines the benefits of both prompting strategies. Our method proceeds step-by-step, selecting the better output between zero-shot and role-play prompting at each step by comparing their output confidence, as measured by the logit gap. Experiments with widely-used LLMs demonstrate that Persona Switch consistently outperforms competitive baselines, achieving up to 5.13% accuracy improvement. Furthermore, we show that output confidence serves as an informative measure for selecting the more reliable output.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15708v1</guid></item><item><title>[cs updates on arXiv.org] AgentSM: Semantic Memory for Agentic Text-to-SQL</title><link>https://arxiv.org/abs/2601.15709</link><description>arXiv:2601.15709v1 Announce Type: new 
Abstract: Recent advances in LLM-based Text-to-SQL have achieved remarkable gains on public benchmarks such as BIRD and Spider. Yet, these systems struggle to scale in realistic enterprise settings with large, complex schemas, diverse SQL dialects, and expensive multi-step reasoning. Emerging agentic approaches show potential for adaptive reasoning but often suffer from inefficiency and instability-repeating interactions with databases, producing inconsistent outputs, and occasionally failing to generate valid answers. To address these challenges, we introduce Agent Semantic Memory (AgentSM), an agentic framework for Text-to-SQL that builds and leverages interpretable semantic memory. Instead of relying on raw scratchpads or vector retrieval, AgentSM captures prior execution traces-or synthesizes curated ones-as structured programs that directly guide future reasoning. This design enables systematic reuse of reasoning paths, which allows agents to scale to larger schemas, more complex questions, and longer trajectories efficiently and reliably. Compared to state-of-the-art systems, AgentSM achieves higher efficiency by reducing average token usage and trajectory length by 25% and 35%, respectively, on the Spider 2.0 benchmark. It also improves execution accuracy, reaching a state-of-the-art accuracy of 44.8% on the Spider 2.0 Lite benchmark.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15709v1</guid></item><item><title>[cs updates on arXiv.org] FlexLLM: Composable HLS Library for Flexible Hybrid LLM Accelerator Design</title><link>https://arxiv.org/abs/2601.15710</link><description>arXiv:2601.15710v1 Announce Type: new 
Abstract: We present FlexLLM, a composable High-Level Synthesis (HLS) library for rapid development of domain-specific LLM accelerators. FlexLLM exposes key architectural degrees of freedom for stage-customized inference, enabling hybrid designs that tailor temporal reuse and spatial dataflow differently for prefill and decode, and provides a comprehensive quantization suite to support accurate low-bit deployment. Using FlexLLM, we build a complete inference system for the Llama-3.2 1B model in under two months with only 1K lines of code. The system includes: (1) a stage-customized accelerator with hardware-efficient quantization (12.68 WikiText-2 PPL) surpassing SpinQuant baseline, and (2) a Hierarchical Memory Transformer (HMT) plug-in for efficient long-context processing. On the AMD U280 FPGA at 16nm, the accelerator achieves 1.29$\times$ end-to-end speedup, 1.64$\times$ higher decode throughput, and 3.14$\times$ better energy efficiency than an NVIDIA A100 GPU (7nm) running BF16 inference; projected results on the V80 FPGA at 7nm reach 4.71$\times$, 6.55$\times$, and 4.13$\times$, respectively. In long-context scenarios, integrating the HMT plug-in reduces prefill latency by 23.23$\times$ and extends the context window by 64$\times$, delivering 1.10$\times$/4.86$\times$ lower end-to-end latency and 5.21$\times$/6.27$\times$ higher energy efficiency on the U280/V80 compared to the A100 baseline. FlexLLM thus bridges algorithmic innovation in LLM inference and high-performance accelerators with minimal manual effort.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15710v1</guid></item><item><title>[cs updates on arXiv.org] Zero-Shot Product Attribute Labeling with Vision-Language Models: A Three-Tier Evaluation Framework</title><link>https://arxiv.org/abs/2601.15711</link><description>arXiv:2601.15711v1 Announce Type: new 
Abstract: Fine-grained attribute prediction is essential for fashion retail applications including catalog enrichment, visual search, and recommendation systems. Vision-Language Models (VLMs) offer zero-shot prediction without task-specific training, yet their systematic evaluation on multi-attribute fashion tasks remains underexplored. A key challenge is that fashion attributes are often conditional. For example, "outer fabric" is undefined when no outer garment is visible. This requires models to detect attribute applicability before attempting classification. We introduce a three-tier evaluation framework that decomposes this challenge: (1) overall task performance across all classes (including NA class: suggesting attribute is not applicable) for all attributes, (2) attribute applicability detection, and (3) fine-grained classification when attributes are determinable. Using DeepFashion-MultiModal, which explicitly defines NA (meaning attribute doesn't exist or is not visible) within attribute label spaces, we benchmark nine VLMs spanning flagship (GPT-5, Gemini 2.5 Pro), efficient (GPT-5 Mini, Gemini 2.5 Flash), and ultra-efficient tiers (GPT-5 Nano, Gemini 2.5 Flash-Lite) against classifiers trained on pretrained Fashion-CLIP embeddings on 5,000 images across 18 attributes. Our findings reveal that: (1) zero-shot VLMs achieve 64.0% macro-F1, a threefold improvement over logistic regression on pretrained Fashion-CLIP embeddings; (2) VLMs excel at fine-grained classification (Tier 3: 70.8% F1) but struggle with applicability detection (Tier 2: 34.1% NA-F1), identifying a key bottleneck; (3) efficient models achieve over 90% of flagship performance at lower cost, offering practical deployment paths. This diagnostic framework enables practitioners to pinpoint whether errors stem from visibility detection or classification, guiding targeted improvements for production systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15711v1</guid></item><item><title>[cs updates on arXiv.org] Even GPT-5.2 Can't Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs</title><link>https://arxiv.org/abs/2601.15714</link><description>arXiv:2601.15714v1 Announce Type: new 
Abstract: We propose Zero-Error Horizon (ZEH) for trustworthy LLMs, which represents the maximum range that a model can solve without any errors. While ZEH itself is simple, we demonstrate that evaluating the ZEH of state-of-the-art LLMs yields abundant insights. For example, by evaluating the ZEH of GPT-5.2, we found that GPT-5.2 cannot even compute the parity of a short string like 11000, and GPT-5.2 cannot determine whether the parentheses in ((((()))))) are balanced. This is surprising given the excellent capabilities of GPT-5.2. The fact that LLMs make mistakes on such simple problems serves as an important lesson when applying LLMs to safety-critical domains. By applying ZEH to Qwen2.5 and conducting detailed analysis, we found that while ZEH correlates with accuracy, the detailed behaviors differ, and ZEH provides clues about the emergence of algorithmic capabilities. Finally, while computing ZEH incurs significant computational cost, we discuss how to mitigate this cost by achieving up to one order of magnitude speedup using tree structures and online softmax.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15714v1</guid></item><item><title>[cs updates on arXiv.org] Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind</title><link>https://arxiv.org/abs/2601.15715</link><description>arXiv:2601.15715v1 Announce Type: new 
Abstract: Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15715v1</guid></item><item><title>[cs updates on arXiv.org] zkFinGPT: Zero-Knowledge Proofs for Financial Generative Pre-trained Transformers</title><link>https://arxiv.org/abs/2601.15716</link><description>arXiv:2601.15716v1 Announce Type: new 
Abstract: Financial Generative Pre-trained Transformers (FinGPT) with multimodal capabilities are now being increasingly adopted in various financial applications. However, due to the intellectual property of model weights and the copyright of training corpus and benchmarking questions, verifying the legitimacy of GPT's model weights and the credibility of model outputs is a pressing challenge. In this paper, we introduce a novel zkFinGPT scheme that applies zero-knowledge proofs (ZKPs) to high-value financial use cases, enabling verification while protecting data privacy. We describe how zkFinGPT will be applied to three financial use cases. Our experiments on two existing packages reveal that zkFinGPT introduces substantial computational overhead that hinders its real-world adoption. E.g., for LLama3-8B model, it generates a commitment file of $7.97$MB using $531$ seconds, and takes $620$ seconds to prove and $2.36$ seconds to verify.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15716v1</guid></item><item><title>[cs updates on arXiv.org] Investigation of the Generalisation Ability of Genetic Programming-evolved Scheduling Rules in Dynamic Flexible Job Shop Scheduling</title><link>https://arxiv.org/abs/2601.15717</link><description>arXiv:2601.15717v1 Announce Type: new 
Abstract: Dynamic Flexible Job Shop Scheduling (DFJSS) is a complex combinatorial optimisation problem that requires simultaneous machine assignment and operation sequencing decisions in dynamic production environments. Genetic Programming (GP) has been widely applied to automatically evolve scheduling rules for DFJSS. However, existing studies typically train and test GP-evolved rules on DFJSS instances of the same type, which differ only by random seeds rather than by structural characteristics, leaving their cross-type generalisation ability largely unexplored. To address this gap, this paper systematically investigates the generalisation ability of GP-evolved scheduling rules under diverse DFJSS conditions. A series of experiments are conducted across multiple dimensions, including problem scale (i.e., the number of machines and jobs), key job shop parameters (e.g., utilisation level), and data distributions, to analyse how these factors influence GP performance on unseen instance types. The results show that good generalisation occurs when the training instances contain more jobs than the test instances while keeping the number of machines fixed, and when both training and test instances have similar scales or job shop parameters. Further analysis reveals that the number and distribution of decision points in DFJSS instances play a crucial role in explaining these performance differences. Similar decision point distributions lead to better generalisation, whereas significant discrepancies result in a marked degradation of performance. Overall, this study provides new insights into the generalisation ability of GP in DFJSS and highlights the necessity of evolving more generalisable GP rules capable of handling heterogeneous DFJSS instances effectively.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15717v1</guid></item><item><title>[cs updates on arXiv.org] U3-xi: Pushing the Boundaries of Speaker Recognition via Incorporating Uncertainty</title><link>https://arxiv.org/abs/2601.15719</link><description>arXiv:2601.15719v1 Announce Type: new 
Abstract: An utterance-level speaker embedding is typically obtained by aggregating a sequence of frame-level representations. However, in real-world scenarios, individual frames encode not only speaker-relevant information but also various nuisance factors. As a result, different frames contribute unequally to the final utterance-level speaker representation for Automatic Speaker Verification systems. To address this issue, we propose to estimate the inherent uncertainty of each frame and assign adaptive weights accordingly, where frames with higher uncertainty receive lower attention. Based on this idea, we present U3-xi, a comprehensive framework designed to produce more reliable and interpretable uncertainty estimates for speaker embeddings. Specifically, we introduce several strategies for uncertainty supervision. First, we propose speaker-level uncertainty supervision via a Stochastic Variance Loss, where the distance between an utterance embedding and its corresponding speaker centroid serves as a pseudo ground truth for uncertainty learning. Second, we incorporate global-level uncertainty supervision by injecting the predicted uncertainty into the sof tmax scale during training. This adaptive scaling mechanism adjusts the sharpness of the decision boundary according to sample difficulty, providing global guidance. Third, we redesign the uncertainty estimation module by integrating a Transformer encoder with multi-view self-attention, enabling the model to capture rich local and long-range temporal dependencies. Comprehensive experiments demonstrate that U3-xi is model-agnostic and can be seamlessly applied to various speaker encoders. In particular, when applied to ECAPA-TDNN, it achieves 21.1% and 15.57% relative improvements on the VoxCeleb1 test sets in terms of EER and minDCF, respectively.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15719v1</guid></item><item><title>[cs updates on arXiv.org] CoNRec: Context-Discerning Negative Recommendation with LLMs</title><link>https://arxiv.org/abs/2601.15721</link><description>arXiv:2601.15721v1 Announce Type: new 
Abstract: Understanding what users like is relatively straightforward; understanding what users dislike, however, remains a challenging and underexplored problem. Research into users' negative preferences has gained increasing importance in modern recommendation systems. Numerous platforms have introduced explicit negative feedback mechanisms and leverage such signals to refine their recommendation models. Beyond traditional business metrics, user experience-driven metrics, such as negative feedback rates, have become critical indicators for evaluating system performance. However, most existing approaches primarily use negative feedback as an auxiliary signal to enhance positive recommendations, paying little attention to directly modeling negative interests, which can be highly valuable in offline applications. Moreover, due to the inherent sparsity of negative feedback data, models often suffer from context understanding biases induced by positive feedback dominance. To address these challenges, we propose the first large language model framework for negative feedback modeling with special designed context-discerning modules. We use semantic ID Representation to replace text-based item descriptions and introduce an item-level alignment task that enhances the LLM's understanding of the semantic context behind negative feedback. Furthermore, we design a Progressive GRPO training paradigm that enables the model to dynamically balance the positive and negative behavioral context utilization. Besides, our investigation further reveals a fundamental misalignment between the conventional next-negative-item prediction objective and users' true negative preferences, which is heavily influenced by the system's recommendation order. To mitigate this, we propose a novel reward function and evaluation metric grounded in multi-day future negative feedback and their collaborative signals.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15721v1</guid></item><item><title>[cs updates on arXiv.org] Communication-efficient Federated Graph Classification via Generative Diffusion Modeling</title><link>https://arxiv.org/abs/2601.15722</link><description>arXiv:2601.15722v1 Announce Type: new 
Abstract: Graph Neural Networks (GNNs) unlock new ways of learning from graph-structured data, proving highly effective in capturing complex relationships and patterns. Federated GNNs (FGNNs) have emerged as a prominent distributed learning paradigm for training GNNs over decentralized data. However, FGNNs face two significant challenges: high communication overhead from multiple rounds of parameter exchanges and non-IID data characteristics across clients. To address these issues, we introduce CeFGC, a novel FGNN paradigm that facilitates efficient GNN training over non-IID data by limiting communication between the server and clients to three rounds only. The core idea of CeFGC is to leverage generative diffusion models to minimize direct client-server communication. Each client trains a generative diffusion model that captures its local graph distribution and shares this model with the server, which then redistributes it back to all clients. Using these generative models, clients generate synthetic graphs combined with their local graphs to train local GNN models. Finally, clients upload their model weights to the server for aggregation into a global GNN model. We theoretically analyze the I/O complexity of communication volume to show that CeFGC reduces to a constant of three communication rounds only. Extensive experiments on several real graph datasets demonstrate the effectiveness and efficiency of CeFGC against state-of-the-art competitors, reflecting our superior performance on non-IID graphs by aligning local and global model objectives and enriching the training set with diverse graphs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15722v1</guid></item><item><title>[cs updates on arXiv.org] Generalized Information Inequalities via Submodularity, and Two Combinatorial Problems</title><link>https://arxiv.org/abs/2601.15723</link><description>arXiv:2601.15723v1 Announce Type: new 
Abstract: It is well known that there is a strong connection between entropy inequalities and submodularity, since the entropy of a collection of random variables is a submodular function. Unifying frameworks for information inequalities arising from submodularity were developed by Madiman and Tetali (2010) and Sason (2022). Madiman and Tetali (2010) established strong and weak fractional inequalities that subsume classical results such as Han's inequality and Shearer's lemma. Sason (2022) introduced a convex-functional framework for generalizing Han's inequality, and derived unified inequalities for submodular and supermodular functions. In this work, we build on these frameworks and make three contributions. First, we establish convex-functional generalizations of the strong and weak Madiman and Tetali inequalities for submodular functions. Second, using a special case of the strong Madiman-Tetali inequality, we derive a new Loomis-Whitney-type projection inequality for finite point sets in $\mathbb{R}^d$, which improves upon the classical Loomis-Whitney bound by incorporating slice-level structural information. Finally, we study an extremal graph theory problem that recovers and extends the previously known results of Sason (2022) and Boucheron et al., employing Shearer's lemma in contrast to the use of Han's inequality in those works.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15723v1</guid></item><item><title>[cs updates on arXiv.org] VideoThinker: Building Agentic VideoLLMs with LLM-Guided Tool Reasoning</title><link>https://arxiv.org/abs/2601.15724</link><description>arXiv:2601.15724v1 Announce Type: new 
Abstract: Long-form video understanding remains a fundamental challenge for current Video Large Language Models. Most existing models rely on static reasoning over uniformly sampled frames, which weakens temporal localization and leads to substantial information loss in long videos. Agentic tools such as temporal retrieval, spatial zoom, and temporal zoom offer a natural way to overcome these limitations by enabling adaptive exploration of key moments. However, constructing agentic video understanding data requires models that already possess strong long-form video comprehension, creating a circular dependency. We address this challenge with VideoThinker, an agentic Video Large Language Model trained entirely on synthetic tool interaction trajectories. Our key idea is to convert videos into rich captions and employ a powerful agentic language model to generate multi-step tool use sequences in caption space. These trajectories are subsequently grounded back to video by replacing captions with the corresponding frames, yielding a large-scale interleaved video and tool reasoning dataset without requiring any long-form understanding from the underlying model. Training on this synthetic agentic dataset equips VideoThinker with dynamic reasoning capabilities, adaptive temporal exploration, and multi-step tool use. Remarkably, VideoThinker significantly outperforms both caption-only language model agents and strong video model baselines across long-video benchmarks, demonstrating the effectiveness of tool augmented synthetic data and adaptive retrieval and zoom reasoning for long-form video understanding.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15724v1</guid></item><item><title>[cs updates on arXiv.org] Profit Maximization for Viral Marketing in Online Social Networks using Two Phase Diffusion Approach</title><link>https://arxiv.org/abs/2601.15726</link><description>arXiv:2601.15726v1 Announce Type: new 
Abstract: Now-a-days, Online Social Networks (OSNs) are extensively used by different commercial houses for viral marketing. The key problem that arises in this context is to choose a limited number of highly influential users as the initial adopters of a brand such that the influence regarding the brand in the network gets maximized. Deviating from this standard setting, in this paper, we study the problem where every user of the network is associated with a selection cost and a benefit value. This benefit value can be earned from the user if (s)he is influenced by the brand. A fixed amount of budget is allocated for selecting the seed users. The goal of initial adopters is to choose a set of seed users within the budget such that the profit is maximized. We propose a two phase diffusion model for this problem where the goal is to split the diffusion process into two phases, and hence, split the budget into two halves. First, we spend the first half budget to select seed users for the first phase and observe the diffusion for a few rounds and then deploy the seed users for the second phase and successively complete the diffusion process. We prove several properties of the two phase influence function. Three solution approaches have been proposed for our problem with detailed analysis and illustrative examples. We conduct a number of experiments with three real-world social network datasets. From the experiments, we observe that the two phase diffusion approach leads to more amount of profit compared to the single-phase diffusion. In particular, for most instances, this improvement is greater than 18% and reaching as high as 40% by the proposed methodologies.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15726v1</guid></item><item><title>[cs updates on arXiv.org] Towards Automated Kernel Generation in the Era of LLMs</title><link>https://arxiv.org/abs/2601.15727</link><description>arXiv:2601.15727v1 Announce Type: new 
Abstract: The performance of modern AI systems is fundamentally constrained by the quality of their underlying kernels, which translate high-level algorithmic semantics into low-level hardware operations. Achieving near-optimal kernels requires expert-level understanding of hardware architectures and programming models, making kernel engineering a critical but notoriously time-consuming and non-scalable process. Recent advances in large language models (LLMs) and LLM-based agents have opened new possibilities for automating kernel generation and optimization. LLMs are well-suited to compress expert-level kernel knowledge that is difficult to formalize, while agentic systems further enable scalable optimization by casting kernel development as an iterative, feedback-driven loop. Rapid progress has been made in this area. However, the field remains fragmented, lacking a systematic perspective for LLM-driven kernel generation. This survey addresses this gap by providing a structured overview of existing approaches, spanning LLM-based approaches and agentic optimization workflows, and systematically compiling the datasets and benchmarks that underpin learning and evaluation in this domain. Moreover, key open challenges and future research directions are further outlined, aiming to establish a comprehensive reference for the next generation of automated kernel optimization. To keep track of this field, we maintain an open-source GitHub repository at https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15727v1</guid></item><item><title>[cs updates on arXiv.org] Benchmarking Text-to-Python against Text-to-SQL: The Impact of Explicit Logic and Ambiguity</title><link>https://arxiv.org/abs/2601.15728</link><description>arXiv:2601.15728v1 Announce Type: new 
Abstract: While Text-to-SQL remains the dominant approach for database interaction, real-world analytics increasingly require the flexibility of general-purpose programming languages such as Python or Pandas to manage file-based data and complex analytical workflows. Despite this growing need, the reliability of Text-to-Python in core data retrieval remains underexplored relative to the mature SQL ecosystem. To address this gap, we introduce BIRD-Python, a benchmark designed for cross-paradigm evaluation. We systematically refined the original dataset to reduce annotation noise and align execution semantics, thereby establishing a consistent and standardized baseline for comparison. Our analysis reveals a fundamental paradigmatic divergence: whereas SQL leverages implicit DBMS behaviors through its declarative structure, Python requires explicit procedural logic, making it highly sensitive to underspecified user intent. To mitigate this challenge, we propose the Logic Completion Framework (LCF), which resolves ambiguity by incorporating latent domain knowledge into the generation process. Experimental results show that (1) performance differences primarily stem from missing domain context rather than inherent limitations in code generation, and (2) when these gaps are addressed, Text-to-Python achieves performance parity with Text-to-SQL. These findings establish Python as a viable foundation for analytical agents-provided that systems effectively ground ambiguous natural language inputs in executable logical specifications. Resources are available at https://anonymous.4open.science/r/Bird-Python-43B7/.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15728v1</guid></item><item><title>[cs updates on arXiv.org] DualShield: Safe Model Predictive Diffusion via Reachability Analysis for Interactive Autonomous Driving</title><link>https://arxiv.org/abs/2601.15729</link><description>arXiv:2601.15729v1 Announce Type: new 
Abstract: Diffusion models have emerged as a powerful approach for multimodal motion planning in autonomous driving. However, their practical deployment is typically hindered by the inherent difficulty in enforcing vehicle dynamics and a critical reliance on accurate predictions of other agents, making them prone to safety issues under uncertain interactions. To address these limitations, we introduce DualShield, a planning and control framework that leverages Hamilton-Jacobi (HJ) reachability value functions in a dual capacity. First, the value functions act as proactive guidance, steering the diffusion denoising process towards safe and dynamically feasible regions. Second, they form a reactive safety shield using control barrier-value functions (CBVFs) to modify the executed actions and ensure safety. This dual mechanism preserves the rich exploration capabilities of diffusion models while providing principled safety assurance under uncertain and even adversarial interactions. Simulations in challenging unprotected U-turn scenarios demonstrate that DualShield significantly improves both safety and task efficiency compared to leading methods from different planning paradigms under uncertainty.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15729v1</guid></item><item><title>[cs updates on arXiv.org] FAIR-ESI: Feature Adaptive Importance Refinement for Electrophysiological Source Imaging</title><link>https://arxiv.org/abs/2601.15731</link><description>arXiv:2601.15731v1 Announce Type: new 
Abstract: An essential technique for diagnosing brain disorders is electrophysiological source imaging (ESI). While model-based optimization and deep learning methods have achieved promising results in this field, the accurate selection and refinement of features remains a central challenge for precise ESI. This paper proposes FAIR-ESI, a novel framework that adaptively refines feature importance across different views, including FFT-based spectral feature refinement, weighted temporal feature refinement, and self-attention-based patch-wise feature refinement. Extensive experiments on two simulation datasets with diverse configurations and two real-world clinical datasets validate our framework's efficacy, highlighting its potential to advance brain disorder diagnosis and offer new insights into brain function.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15731v1</guid></item><item><title>[cs updates on arXiv.org] Sub-Region-Aware Modality Fusion and Adaptive Prompting for Multi-Modal Brain Tumor Segmentation</title><link>https://arxiv.org/abs/2601.15734</link><description>arXiv:2601.15734v1 Announce Type: new 
Abstract: The successful adaptation of foundation models to multi-modal medical imaging is a critical yet unresolved challenge. Existing models often struggle to effectively fuse information from multiple sources and adapt to the heterogeneous nature of pathological tissues. To address this, we introduce a novel framework for adapting foundation models to multi-modal medical imaging, featuring two key technical innovations: sub-region-aware modality attention and adaptive prompt engineering. The attention mechanism enables the model to learn the optimal combination of modalities for each tumor sub-region, while the adaptive prompting strategy leverages the inherent capabilities of foundation models to refine segmentation accuracy. We validate our framework on the BraTS 2020 brain tumor segmentation dataset, demonstrating that our approach significantly outperforms baseline methods, particularly in the challenging necrotic core sub-region. Our work provides a principled and effective approach to multi-modal fusion and prompting, paving the way for more accurate and robust foundation model-based solutions in medical imaging.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15734v1</guid></item><item><title>[cs updates on arXiv.org] PhysProver: Advancing Automatic Theorem Proving for Physics</title><link>https://arxiv.org/abs/2601.15737</link><description>arXiv:2601.15737v1 Announce Type: new 
Abstract: The combination of verifiable languages and LLMs has significantly influenced both the mathematical and computer science communities because it provides a rigorous foundation for theorem proving. Recent advancements in the field provide foundation models and sophisticated agentic systems pushing the boundaries of formal mathematical reasoning to approach the natural language capability of LLMs. However, little attention has been given to the formal physics reasoning, which also heavily relies on similar problem-solving and theorem-proving frameworks. To solve this problem, this paper presents, to the best of our knowledge, the first approach to enhance formal theorem proving in the physics domain. We compose a dedicated dataset PhysLeanData for the task. It is composed of theorems sampled from PhysLean and data generated by a conjecture-based formal data generation pipeline. In the training pipeline, we leverage DeepSeek-Prover-V2-7B, a strong open-source mathematical theorem prover, and apply Reinforcement Learning with Verifiable Rewards (RLVR) to train our model PhysProver. Comprehensive experiments demonstrate that, using only $\sim$5K training samples, PhysProver achieves an overall 2.4\% improvement in multiple sub-domains. Furthermore, after formal physics training, we observe 1.3\% gains on the MiniF2F-Test benchmark, which indicates non-trivial generalization beyond physics domains and enhancement for formal math capability as well. The results highlight the effectiveness and efficiency of our approach, which provides a paradigm for extending formal provers outside mathematical domains. To foster further research, we will release both our dataset and model to the community.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15737v1</guid></item><item><title>[cs updates on arXiv.org] LLM-Assisted Automatic Dispatching Rule Design for Dynamic Flexible Assembly Flow Shop Scheduling</title><link>https://arxiv.org/abs/2601.15738</link><description>arXiv:2601.15738v1 Announce Type: new 
Abstract: Dynamic multi-product delivery environments demand rapid coordination of part completion and product-level kitting within hybrid processing and assembly systems to satisfy strict hierarchical supply constraints. The flexible assembly flow shop scheduling problem formally defines dependencies for multi-stage kitting, yet dynamic variants make designing integrated scheduling rules under multi-level time coupling highly challenging. Existing automated heuristic design methods, particularly genetic programming constrained to fixed terminal symbol sets, struggle to capture and leverage dynamic uncertainties and hierarchical dependency information under transient decision states. This study develops an LLM-assisted Dynamic Rule Design framework (LLM4DRD) that automatically evolves integrated online scheduling rules adapted to scheduling features. Firstly, multi-stage processing and assembly supply decisions are transformed into feasible directed edge orderings based on heterogeneous graph. Then, an elite knowledge guided initialization embeds advanced design expertise into initial rules to enhance initial quality. Additionally, a dual-expert mechanism is introduced in which LLM-A evolutionary code to generate candidate rules and LLM-S conducts scheduling evaluation, while dynamic feature-fitting rule evolution combined with hybrid evaluation enables continuous improvement and extracts adaptive rules with strong generalization capability. A series of experiments are conducted to validate the effectiveness of the method. The average tardiness of LLM4DRD is 3.17-12.39% higher than state-of-the-art methods in 20 practical instances used for training and testing, respectively. In 24 scenarios with different resource configurations, order loads, and disturbance levels totaling 480 instances, it achieves 11.10% higher performance than the second best competitor, exhibiting excellent robustness.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15738v1</guid></item><item><title>[cs updates on arXiv.org] Breaking the Resolution Barrier: Arbitrary-resolution Deep Image Steganography Framework</title><link>https://arxiv.org/abs/2601.15739</link><description>arXiv:2601.15739v1 Announce Type: new 
Abstract: Deep image steganography (DIS) has achieved significant results in capacity and invisibility. However, current paradigms enforce the secret image to maintain the same resolution as the cover image during hiding and revealing. This leads to two challenges: secret images with inconsistent resolutions must undergo resampling beforehand which results in detail loss during recovery, and the secret image cannot be recovered to its original resolution when the resolution value is unknown. To address these, we propose ARDIS, the first Arbitrary Resolution DIS framework, which shifts the paradigm from discrete mapping to reference-guided continuous signal reconstruction. Specifically, to minimize the detail loss caused by resolution mismatch, we first design a Frequency Decoupling Architecture in hiding stage. It disentangles the secret into a resolution-aligned global basis and a resolution-agnostic high-frequency latent to hide in a fixed-resolution cover. Second, for recovery, we propose a Latent-Guided Implicit Reconstructor to perform deterministic restoration. The recovered detail latent code modulates a continuous implicit function to accurately query and render high-frequency residuals onto the recovered global basis, ensuring faithful restoration of original details. Furthermore, to achieve blind recovery, we introduce an Implicit Resolution Coding strategy. By transforming discrete resolution values into dense feature maps and hiding them in the redundant space of the feature domain, the reconstructor can correctly decode the secret's resolution directly from the steganographic representation. Experimental results demonstrate that ARDIS significantly outperforms state-of-the-art methods in both invisibility and cross-resolution recovery fidelity.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15739v1</guid></item><item><title>[cs updates on arXiv.org] Hallucination Mitigating for Medical Report Generation</title><link>https://arxiv.org/abs/2601.15745</link><description>arXiv:2601.15745v1 Announce Type: new 
Abstract: In the realm of medical report generation (MRG), the integration of natural language processing has emerged as a vital tool to alleviate the workload of radiologists. Despite the impressive capabilities demonstrated by large vision language models (LVLMs) in understanding natural language, their susceptibility to generating plausible yet inaccurate claims, known as ``hallucinations'', raises concerns-especially in the nuanced and critical field of medical. In this work, we introduce a framework, \textbf{K}nowledge-\textbf{E}nhanced with Fine-Grained \textbf{R}einforced Rewards \textbf{M}edical Report Generation (KERM), to tackle the issue. Our approach refines the input to the LVLM by first utilizing MedCLIP for knowledge retrieval, incorporating relevant lesion fact sentences from a curated knowledge corpus. We then introduce a novel purification module to ensure the retrieved knowledge is contextually relevant to the patient's clinical context. Subsequently, we employ fine-grained rewards to guide these models in generating highly supportive and clinically relevant descriptions, ensuring the alignment of model's outputs with desired behaviors. Experimental results on IU-Xray and MIMIC-CXR datasets validate the effectiveness of our approach in mitigating hallucinations and enhancing report quality.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15745v1</guid></item><item><title>[cs updates on arXiv.org] Tabular Incremental Inference</title><link>https://arxiv.org/abs/2601.15751</link><description>arXiv:2601.15751v1 Announce Type: new 
Abstract: Tabular data is a fundamental form of data structure. The evolution of table analysis tools reflects humanity's continuous progress in data acquisition, management, and processing. The dynamic changes in table columns arise from technological advancements, changing needs, data integration, etc. However, the standard process of training AI models on tables with fixed columns and then performing inference is not suitable for handling dynamically changed tables. Therefore, new methods are needed for efficiently handling such tables in an unsupervised manner. In this paper, we introduce a new task, Tabular Incremental Inference (TabII), which aims to enable trained models to incorporate new columns during the inference stage, enhancing the practicality of AI models in scenarios where tables are dynamically changed. Furthermore, we demonstrate that this new task can be framed as an optimization problem based on the information bottleneck theory, which emphasizes that the key to an ideal tabular incremental inference approach lies in minimizing mutual information between tabular data and representation while maximizing between representation and task labels. Under this guidance, we design a TabII method with Large Language Model placeholders and Pretrained TabAdapter to provide external knowledge and Incremental Sample Condensation blocks to condense the task-relevant information given by incremental column attributes. Experimental results across eight public datasets show that TabII effectively utilizes incremental attributes, achieving state-of-the-art performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15751v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Marginal Distributions: A Framework to Evaluate the Representativeness of Demographic-Aligned LLMs</title><link>https://arxiv.org/abs/2601.15755</link><description>arXiv:2601.15755v1 Announce Type: new 
Abstract: Large language models are increasingly used to represent human opinions, values, or beliefs, and their steerability towards these ideals is an active area of research. Existing work focuses predominantly on aligning marginal response distributions, treating each survey item independently. While essential, this may overlook deeper latent structures that characterise real populations and underpin cultural values theories. We propose a framework for evaluating the representativeness of aligned models through multivariate correlation patterns in addition to marginal distributions. We show the value of our evaluation scheme by comparing two model steering techniques (persona prompting and demographic fine-tuning) and evaluating them against human responses from the World Values Survey. While the demographically fine-tuned model better approximates marginal response distributions than persona prompting, both techniques fail to fully capture the gold standard correlation patterns. We conclude that representativeness is a distinct aspect of value alignment and an evaluation focused on marginals can mask structural failures, leading to overly optimistic conclusions about model capabilities.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15755v1</guid></item><item><title>[cs updates on arXiv.org] CTL* Model Checking on Infinite Families of Finite-State Labeled Transition Systems (Technical Report)</title><link>https://arxiv.org/abs/2601.15756</link><description>arXiv:2601.15756v1 Announce Type: new 
Abstract: We study model checking algorithms for infinite families of finite-state labeled transition systems against temporal properties written in CTL*. Such families arise, for example, as models of highly configurable systems or software product lines.
  We model families using context-free graph grammars. We then develop a state labeling algorithm that works compositionally on the grammar's production rules with limited information about the context in which the rule is applied. The result is a graph grammar modeling the same family but with extended labels. We leverage this grammar to decide whether all, some, or (in)finitely many members of a family satisfy a given temporal property. We have implemented our algorithms and present early experiments.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15756v1</guid></item><item><title>[cs updates on arXiv.org] White-Box mHC: Electromagnetic Spectrum-Aware and Interpretable Stream Interactions for Hyperspectral Image Classification</title><link>https://arxiv.org/abs/2601.15757</link><description>arXiv:2601.15757v1 Announce Type: new 
Abstract: In hyperspectral image classification (HSIC), most deep learning models rely on opaque spectral-spatial feature mixing, limiting their interpretability and hindering understanding of internal decision mechanisms. We present physical spectrum-aware white-box mHC, named ES-mHC, a hyper-connection framework that explicitly models interactions among different electromagnetic spectrum groupings (residual stream in mHC) interactions using structured, directional matrices. By separating feature representation from interaction structure, ES-mHC promotes electromagnetic spectrum grouping specialization, reduces redundancy, and exposes internal information flow that can be directly visualized and spatially analyzed. Using hyperspectral image classification as a representative testbed, we demonstrate that the learned hyper-connection matrices exhibit coherent spatial patterns and asymmetric interaction behaviors, providing mechanistic insight into the model internal dynamics. Furthermore, we find that increasing the expansion rate accelerates the emergence of structured interaction patterns. These results suggest that ES-mHC transforms HSIC from a purely black-box prediction task into a structurally transparent, partially white-box learning process.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15757v1</guid></item><item><title>[cs updates on arXiv.org] NL4ST: A Natural Language Query Tool for Spatio-Temporal Databases</title><link>https://arxiv.org/abs/2601.15758</link><description>arXiv:2601.15758v1 Announce Type: new 
Abstract: The advancement of mobile computing devices and positioning technologies has led to an explosive growth of spatio-temporal data managed in databases. Representative queries over such data include range queries, nearest neighbor queries, and join queries. However, formulating those queries usually requires domain-specific expertise and familiarity with executable query languages, which would be a challenging task for non-expert users. It leads to a great demand for well-supported natural language queries (NLQs) in spatio-temporal databases. To bridge the gap between non-experts and query plans in databases, we present NL4ST, an interactive tool that allows users to query spatio-temporal databases in natural language. NL4ST features a three-layer architecture: (i) knowledge base and corpus for knowledge preparation, (ii) natural language understanding for entity linking, and (iii) generating physical plans. Our demonstration will showcase how NL4ST provides effective spatio-temporal physical plans, verified by using four real and synthetic datasets. We make NL4ST online and provide the demo video at https://youtu.be/-J1R7R5WoqQ.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15758v1</guid></item><item><title>[cs updates on arXiv.org] Atlas-Assisted Segment Anything Model for Fetal Brain MRI (FeTal-SAM)</title><link>https://arxiv.org/abs/2601.15759</link><description>arXiv:2601.15759v1 Announce Type: new 
Abstract: This paper presents FeTal-SAM, a novel adaptation of the Segment Anything Model (SAM) tailored for fetal brain MRI segmentation. Traditional deep learning methods often require large annotated datasets for a fixed set of labels, making them inflexible when clinical or research needs change. By integrating atlas-based prompts and foundation-model principles, FeTal-SAM addresses two key limitations in fetal brain MRI segmentation: (1) the need to retrain models for varying label definitions, and (2) the lack of insight into whether segmentations are driven by genuine image contrast or by learned spatial priors. We leverage multi-atlas registration to generate spatially aligned label templates that serve as dense prompts, alongside a bounding-box prompt, for SAM's segmentation decoder. This strategy enables binary segmentation on a per-structure basis, which is subsequently fused to reconstruct the full 3D segmentation volumes. Evaluations on two datasets, the dHCP dataset and an in-house dataset demonstrate FeTal-SAM's robust performance across gestational ages. Notably, it achieves Dice scores comparable to state-of-the-art baselines which were trained for each dataset and label definition for well-contrasted structures like cortical plate and cerebellum, while maintaining the flexibility to segment any user-specified anatomy. Although slightly lower accuracy is observed for subtle, low-contrast structures (e.g., hippocampus, amygdala), our results highlight FeTal-SAM's potential to serve as a general-purpose segmentation model without exhaustive retraining. This method thus constitutes a promising step toward clinically adaptable fetal brain MRI analysis tools.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15759v1</guid></item><item><title>[cs updates on arXiv.org] Off-Policy Actor-Critic with Sigmoid-Bounded Entropy for Real-World Robot Learning</title><link>https://arxiv.org/abs/2601.15761</link><description>arXiv:2601.15761v1 Announce Type: new 
Abstract: Deploying reinforcement learning in the real world remains challenging due to sample inefficiency, sparse rewards, and noisy visual observations. Prior work leverages demonstrations and human feedback to improve learning efficiency and robustness. However, offline-to-online methods need large datasets and can be unstable, while VLA-assisted RL relies on large-scale pretraining and fine-tuning. As a result, a low-cost real-world RL method with minimal data requirements has yet to emerge. We introduce \textbf{SigEnt-SAC}, an off-policy actor-critic method that learns from scratch using a single expert trajectory. Our key design is a sigmoid-bounded entropy term that prevents negative-entropy-driven optimization toward out-of-distribution actions and reduces Q-function oscillations. We benchmark SigEnt-SAC on D4RL tasks against representative baselines. Experiments show that SigEnt-SAC substantially alleviates Q-function oscillations and reaches a 100\% success rate faster than prior methods. Finally, we validate SigEnt-SAC on four real-world robotic tasks across multiple embodiments, where agents learn from raw images and sparse rewards; results demonstrate that SigEnt-SAC can learn successful policies with only a small number of real-world interactions, suggesting a low-cost and practical pathway for real-world RL deployment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15761v1</guid></item><item><title>[cs updates on arXiv.org] NMRGym: A Comprehensive Benchmark for Nuclear Magnetic Resonance Based Molecular Structure Elucidation</title><link>https://arxiv.org/abs/2601.15763</link><description>arXiv:2601.15763v1 Announce Type: new 
Abstract: Nuclear Magnetic Resonance (NMR) spectroscopy is the cornerstone of small-molecule structure elucidation. While deep learning has demonstrated significant potential in automating structure elucidation and spectral simulation, current progress is severely impeded by the reliance on synthetic datasets, which introduces significant domain shifts when applied to real-world experimental spectra. Furthermore, the lack of standardized evaluation protocols and rigorous data splitting strategies frequently leads to unfair comparisons and data leakage. To address these challenges, we introduce \textbf{NMRGym}, the largest and most comprehensive standardized dataset and benchmark derived from high-quality experimental NMR data to date. Comprising \textbf{269,999} unique molecules paired with high-fidelity $^1$H and $^{13}$C spectra, NMRGym bridges the critical gap between synthetic approximations and real-world diversity. We implement a strict quality control pipeline and unify data formats to ensure fair comparison. To strictly prevent data leakage, we enforce a scaffold-based split. Additionally, we provide fine-grained peak-atom level annotations to support future usage. Leveraging this resource, we establish a comprehensive evaluation suite covering diverse downstream tasks, including structure elucidation, functional group prediction from NMR, toxicity prediction from NMR, and spectral simulation, benchmarking representative state-of-the-art methodologies. Finally, we release an open-source leadboard with an automated leaderboard to foster community collaboration and standardize future research. The dataset, benchmark and leaderboard are publicly available at \textcolor{blue}{https://AIMS-Lab-HKUSTGZ.github.io/NMRGym/}.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15763v1</guid></item><item><title>[cs updates on arXiv.org] LL-GaussianMap: Zero-shot Low-Light Image Enhancement via 2D Gaussian Splatting Guided Gain Maps</title><link>https://arxiv.org/abs/2601.15766</link><description>arXiv:2601.15766v1 Announce Type: new 
Abstract: Significant progress has been made in low-light image enhancement with respect to visual quality. However, most existing methods primarily operate in the pixel domain or rely on implicit feature representations. As a result, the intrinsic geometric structural priors of images are often neglected. 2D Gaussian Splatting (2DGS) has emerged as a prominent explicit scene representation technique characterized by superior structural fitting capabilities and high rendering efficiency. Despite these advantages, the utilization of 2DGS in low-level vision tasks remains unexplored. To bridge this gap, LL-GaussianMap is proposed as the first unsupervised framework incorporating 2DGS into low-light image enhancement. Distinct from conventional methodologies, the enhancement task is formulated as a gain map generation process guided by 2DGS primitives. The proposed method comprises two primary stages. First, high-fidelity structural reconstruction is executed utilizing 2DGS. Then, data-driven enhancement dictionary coefficients are rendered via the rasterization mechanism of Gaussian splatting through an innovative unified enhancement module. This design effectively incorporates the structural perception capabilities of 2DGS into gain map generation, thereby preserving edges and suppressing artifacts during enhancement. Additionally, the reliance on paired data is circumvented through unsupervised learning. Experimental results demonstrate that LL-GaussianMap achieves superior enhancement performance with an extremely low storage footprint, highlighting the effectiveness of explicit Gaussian representations for image enhancement.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15766v1</guid></item><item><title>[cs updates on arXiv.org] Recursive Flow: A Generative Framework for MIMO Channel Estimation</title><link>https://arxiv.org/abs/2601.15767</link><description>arXiv:2601.15767v1 Announce Type: new 
Abstract: Channel estimation is a fundamental challenge in massive multiple-input multiple-output systems, where estimation accuracy governs the spectral efficiency and link reliability. In this work, we introduce Recursive Flow (RC-Flow), a novel solver that leverages pre-trained flow matching priors to robustly recover channel state information from noisy, under-determined measurements. Different from conventional open-loop generative models, our approach establishes a closed-loop refinement framework via a serial restart mechanism and anchored trajectory rectification. By synergizing flow-consistent prior directions with data-fidelity proximal projections, the proposed RC-Flow achieves robust channel reconstruction and delivers state-of-the-art performance across diverse noise levels, particularly in noise-dominated scenarios. The framework is further augmented by an adaptive dual-scheduling strategy, offering flexible management of the trade-off between convergence speed and reconstruction accuracy. Theoretically, we analyze the Jacobian spectral radius of the recursive operator to prove its global asymptotic stability. Numerical results demonstrate that RC-Flow reduces inference latency by two orders of magnitude while achieving a 2.7 dB performance gain in low signal-to-noise ratio regimes compared to the score-based baseline.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15767v1</guid></item><item><title>[cs updates on arXiv.org] Rethinking Drug-Drug Interaction Modeling as Generalizable Relation Learning</title><link>https://arxiv.org/abs/2601.15771</link><description>arXiv:2601.15771v1 Announce Type: new 
Abstract: Drug-drug interaction (DDI) prediction is central to drug discovery and clinical development, particularly in the context of increasingly prevalent polypharmacy. Although existing computational methods achieve strong performance on standard benchmarks, they often fail to generalize to realistic deployment scenarios, where most candidate drug pairs involve previously unseen drugs and validated interactions are scarce. We demonstrate that proximity in the embedding spaces of prevailing molecule-centric DDI models does not reliably correspond to interaction labels, and that simply scaling up model capacity therefore fails to improve generalization. To address these limitations, we propose GenRel-DDI, a generalizable relation learning framework that reformulates DDI prediction as a relation-centric learning problem, in which interaction representations are learned independently of drug identities. This relation-level abstraction enables the capture of transferable interaction patterns that generalize to unseen drugs and novel drug pairs. Extensive experiments across multiple benchmark demonstrate that GenRel-DDI consistently and significantly outperforms state-of-the-art methods, with particularly large gains on strict entity-disjoint evaluations, highlighting the effectiveness and practical utility of relation learning for robust DDI prediction. The code is available at https://github.com/SZU-ADDG/GenRel-DDI.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15771v1</guid></item><item><title>[cs updates on arXiv.org] Next Generation Active Learning: Mixture of LLMs in the Loop</title><link>https://arxiv.org/abs/2601.15773</link><description>arXiv:2601.15773v1 Announce Type: new 
Abstract: With the rapid advancement and strong generalization capabilities of large language models (LLMs), they have been increasingly incorporated into the active learning pipelines as annotators to reduce annotation costs. However, considering the annotation quality, labels generated by LLMs often fall short of real-world applicability. To address this, we propose a novel active learning framework, Mixture of LLMs in the Loop Active Learning, replacing human annotators with labels generated through a Mixture-of-LLMs-based annotation model, aimed at enhancing LLM-based annotation robustness by aggregating the strengths of multiple LLMs. To further mitigate the impact of the noisy labels, we introduce annotation discrepancy and negative learning to identify the unreliable annotations and enhance learning effectiveness. Extensive experiments demonstrate that our framework achieves performance comparable to human annotation and consistently outperforms single-LLM baselines and other LLM-ensemble-based approaches. Moreover, our framework is built on lightweight LLMs, enabling it to operate fully on local machines in real-world applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15773v1</guid></item><item><title>[cs updates on arXiv.org] FirmReBugger: A Benchmark Framework for Monolithic Firmware Fuzzers</title><link>https://arxiv.org/abs/2601.15774</link><description>arXiv:2601.15774v1 Announce Type: new 
Abstract: Monolithic Firmware is widespread. Unsurprisingly, fuzz testing firmware is an active research field with new advances addressing the unique challenges in the domain. However, understanding and evaluating improvements by deriving metrics such as code coverage and unique crashes are problematic, leading to a desire for a reliable bug-based benchmark. To address the need, we design and build FirmReBugger, a holistic framework for fairly assessing monolithic firmware fuzzers with a realistic, diverse, bug-based benchmark. FirmReBugger proposes using bug oracles--C syntax expressions of bug descriptors--with an interpreter to automate analysis and accurately report on bugs discovered, discriminating between states of detected, triggered, reached and not reached. Importantly, our idea of benchmarking does not modify the target binary and simply replays fuzzing seeds to isolate the benchmark implementation from the fuzzer while providing a simple means to extend with new bug oracles. Further, analyzing fuzzing roadblocks, we created FirmBench, a set of diverse, real-world binary targets with 313 software bug oracles. Incorporating our analysis of roadblocks challenging monolithic firmware fuzzing, the bench provides for rapid evaluation of future advances. We implement FirmReBugger in a FuzzBench-for-Firmware type service and use FirmBench to evaluate 9 state-of-the art monolithic firmware fuzzers in the style of a reproducibility study, using a 10 CPU-year effort, to report our findings.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15774v1</guid></item><item><title>[cs updates on arXiv.org] Glove2UAV: A Wearable IMU-Based Glove for Intuitive Control of UAV</title><link>https://arxiv.org/abs/2601.15775</link><description>arXiv:2601.15775v1 Announce Type: new 
Abstract: This paper presents Glove2UAV, a wearable IMU-glove interface for intuitive UAV control through hand and finger gestures, augmented with vibrotactile warnings for exceeding predefined speed thresholds. To promote safer and more predictable interaction in dynamic flight, Glove2UAV is designed as a lightweight and easily deployable wearable interface intended for real-time operation. Glove2UAV streams inertial measurements in real time and estimates palm and finger orientations using a compact processing pipeline that combines median-based outlier suppression with Madgwick-based orientation estimation. The resulting motion estimations are mapped to a small set of control primitives for directional flight (forward/backward and lateral motion) and, when supported by the platform, to object-interaction commands. Vibrotactile feedback is triggered when flight speed exceeds predefined threshold values, providing an additional alert channel during operation. We validate real-time feasibility by synchronizing glove signals with UAV telemetry in both simulation and real-world flights. The results show fast gesture-based command execution, stable coupling between gesture dynamics and platform motion, correct operation of the core command set in our trials, and timely delivery of vibratile warning cues.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15775v1</guid></item><item><title>[cs updates on arXiv.org] UXCascade: Scalable Usability Testing with Simulated User Agents</title><link>https://arxiv.org/abs/2601.15777</link><description>arXiv:2601.15777v1 Announce Type: new 
Abstract: Simulated user agents are increasingly used in usability testing to support fast, iterative UX workflows, as they generate rich data such as action logs and think-aloud reasoning, but the unstructured nature of this output often obscures actionable insights. We present UXCascade, an interactive tool for extracting, aggregating, and presenting agent-generated usability feedback at scale. Our core contribution is a multi-level analysis workflow that (1) highlights patterns across persona traits, goals, and outcomes, (2) links agent reasoning to specific issues, and (3) supports actionable design improvements. UXCascade operationalizes this approach by listing agent goals, traits, and issues in a structured overview. Practitioners can explore detailed reasoning traces and annotated views, propose interface edits, and assess their impact across personas. This enables a top-down, exploration-driven analysis from patterns to concrete UX interventions. A user study with eight UX professionals demonstrates that UXCascade integrates into existing workflows, enabling iterative feedback during early-stage interface development.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15777v1</guid></item><item><title>[cs updates on arXiv.org] Agentic Confidence Calibration</title><link>https://arxiv.org/abs/2601.15778</link><description>arXiv:2601.15778v1 Announce Type: new 
Abstract: AI agents are rapidly advancing from passive language models to autonomous systems executing complex, multi-step tasks. Yet their overconfidence in failure remains a fundamental barrier to deployment in high-stakes settings. Existing calibration methods, built for static single-turn outputs, cannot address the unique challenges of agentic systems, such as compounding errors along trajectories, uncertainty from external tools, and opaque failure modes. To address these challenges, we introduce, for the first time, the problem of Agentic Confidence Calibration and propose Holistic Trajectory Calibration (HTC), a novel diagnostic framework that extracts rich process-level features ranging from macro dynamics to micro stability across an agent's entire trajectory. Powered by a simple, interpretable model, HTC consistently surpasses strong baselines in both calibration and discrimination, across eight benchmarks, multiple LLMs, and diverse agent frameworks. Beyond performance, HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure, enables transferability by applying across domains without retraining, and achieves generalization through a General Agent Calibrator (GAC) that achieves the best calibration (lowest ECE) on the out-of-domain GAIA benchmark. Together, these contributions establish a new process-centric paradigm for confidence calibration, providing a framework for diagnosing and enhancing the reliability of AI agents.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15778v1</guid></item><item><title>[cs updates on arXiv.org] Diffusion Model-Based Data Augmentation for Enhanced Neuron Segmentation</title><link>https://arxiv.org/abs/2601.15779</link><description>arXiv:2601.15779v1 Announce Type: new 
Abstract: Neuron segmentation in electron microscopy (EM) aims to reconstruct the complete neuronal connectome; however, current deep learning-based methods are limited by their reliance on large-scale training data and extensive, time-consuming manual annotations. Traditional methods augment the training set through geometric and photometric transformations; however, the generated samples remain highly correlated with the original images and lack structural diversity. To address this limitation, we propose a diffusion-based data augmentation framework capable of generating diverse and structurally plausible image-label pairs for neuron segmentation. Specifically, the framework employs a resolution-aware conditional diffusion model with multi-scale conditioning and EM resolution priors to enable voxel-level image synthesis from 3D masks. It further incorporates a biology-guided mask remodeling module that produces augmented masks with enhanced structural realism. Together, these components effectively enrich the training set and improve segmentation performance. On the AC3 and AC4 datasets under low-annotation regimes, our method improves the ARAND metric by 32.1% and 30.7%, respectively, when combined with two different post-processing methods. Our code is available at https://github.com/HeadLiuYun/NeuroDiff.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15779v1</guid></item><item><title>[cs updates on arXiv.org] Assessing Situational and Spatial Awareness of VLMs with Synthetically Generated Video</title><link>https://arxiv.org/abs/2601.15780</link><description>arXiv:2601.15780v1 Announce Type: new 
Abstract: Spatial reasoning in vision language models (VLMs) remains fragile when semantics hinge on subtle temporal or geometric cues. We introduce a synthetic benchmark that probes two complementary skills: situational awareness (recognizing whether an interaction is harmful or benign) and spatial awareness (tracking who does what to whom, and reasoning about relative positions and motion). Through minimal video pairs, we test three challenges: distinguishing violence from benign activity, binding assailant roles across viewpoints, and judging fine-grained trajectory alignment. While we evaluate recent VLMs in a training-free setting, the benchmark is applicable to any video classification model. Results show performance only slightly above chance across tasks. A simple aid, stable color cues, partly reduces assailant role confusions but does not resolve the underlying weakness. By releasing data and code, we aim to provide reproducible diagnostics and seed exploration of lightweight spatial priors to complement large-scale pretraining.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15780v1</guid></item><item><title>[cs updates on arXiv.org] Endowing Molecular Language with Geometry Perception via Modality Compensation for High-Throughput Quantum Hamiltonian Prediction</title><link>https://arxiv.org/abs/2601.15786</link><description>arXiv:2601.15786v1 Announce Type: new 
Abstract: The quantum Hamiltonian is a fundamental property that governs a molecule's electronic structure and behavior, and its calculation and prediction are paramount in computational chemistry and materials science. Accurate prediction is highly reliant on extensive training data, including precise molecular geometries and the Hamiltonian matrices, which are expensive to acquire via either experimental or computational methods. Towards a fast yet accurate method for Hamiltonian prediction, we first introduce a geometry information-aware molecular language model to bypass the use of expensive molecular geometries by only using the readily available molecular language -- simplified molecular input line entry system (SMILES). Our method employs multimodal alignment to bridge the relationship between SMILES strings and their corresponding molecular geometries. Recognizing that the molecular language inherently lacks explicit geometric information, we propose a geometry modality compensation strategy to imbue molecular language representations with essential geometric features, thereby enabling accurate predictions using SMILES. In addition, given the high cost of acquiring Hamiltonian data, we devise a weakly supervised strategy to fine-tune the molecular language model, thus improving the data efficiency. Theoretically, we prove that the prediction generalization error without explicit molecular geometry can be bounded through our modality compensation scheme. Empirically, our method achieves superior computational efficiency, providing up to 100x speedup over conventional quantum mechanical methods while maintaining comparable prediction accuracy. We further demonstrate the practical case study of our approach in the screening of electrolyte formulations.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15786v1</guid></item><item><title>[cs updates on arXiv.org] HumanLLM: Towards Personalized Understanding and Simulation of Human Nature</title><link>https://arxiv.org/abs/2601.15793</link><description>arXiv:2601.15793v1 Announce Type: new 
Abstract: Motivated by the remarkable progress of large language models (LLMs) in objective tasks like mathematics and coding, there is growing interest in their potential to simulate human behavior--a capability with profound implications for transforming social science research and customer-centric business insights. However, LLMs often lack a nuanced understanding of human cognition and behavior, limiting their effectiveness in social simulation and personalized applications. We posit that this limitation stems from a fundamental misalignment: standard LLM pretraining on vast, uncontextualized web data does not capture the continuous, situated context of an individual's decisions, thoughts, and behaviors over time. To bridge this gap, we introduce HumanLLM, a foundation model designed for personalized understanding and simulation of individuals. We first construct the Cognitive Genome Dataset, a large-scale corpus curated from real-world user data on platforms like Reddit, Twitter, Blogger, and Amazon. Through a rigorous, multi-stage pipeline involving data filtering, synthesis, and quality control, we automatically extract over 5.5 million user logs to distill rich profiles, behaviors, and thinking patterns. We then formulate diverse learning tasks and perform supervised fine-tuning to empower the model to predict a wide range of individualized human behaviors, thoughts, and experiences. Comprehensive evaluations demonstrate that HumanLLM achieves superior performance in predicting user actions and inner thoughts, more accurately mimics user writing styles and preferences, and generates more authentic user profiles compared to base models. Furthermore, HumanLLM shows significant gains on out-of-domain social intelligence benchmarks, indicating enhanced generalization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15793v1</guid></item><item><title>[cs updates on arXiv.org] Creativity in the Age of AI: Rethinking the Role of Intentional Agency</title><link>https://arxiv.org/abs/2601.15797</link><description>arXiv:2601.15797v1 Announce Type: new 
Abstract: Many theorists of creativity maintain that intentional agency is a necessary condition of creativity. We argue that this requirement, which we call the Intentional Agency Condition (IAC), should be rejected as a general condition of creativity, while retaining its relevance in specific contexts. We show that recent advances in generative AI have rendered the IAC increasingly problematic, both descriptively and functionally. We offer two reasons for abandoning it at the general level. First, we present corpus evidence indicating that authors and journalists are increasingly comfortable ascribing creativity to generative AI, despite its lack of intentional agency. This development places pressure on the linguistic intuitions that have traditionally been taken to support the IAC. Second, drawing on the method of conceptual engineering, we argue that the IAC no longer fulfils its core social function. Rather than facilitating the identification and encouragement of reliable sources of novel and valuable products, it now feeds into biases that distort our assessments of AI-generated outputs. We therefore propose replacing the IAC with a consistency requirement, according to which creativity tracks the reliable generation of novel and valuable products. Nonetheless, we explain why the IAC should be retained in specific local domains.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15797v1</guid></item><item><title>[cs updates on arXiv.org] VitalDiagnosis: AI-Driven Ecosystem for 24/7 Vital Monitoring and Chronic Disease Management</title><link>https://arxiv.org/abs/2601.15798</link><description>arXiv:2601.15798v1 Announce Type: new 
Abstract: Chronic diseases have become the leading cause of death worldwide, a challenge intensified by strained medical resources and an aging population. Individually, patients often struggle to interpret early signs of deterioration or maintain adherence to care plans. In this paper, we introduce VitalDiagnosis, an LLM-driven ecosystem designed to shift chronic disease management from passive monitoring to proactive, interactive engagement. By integrating continuous data from wearable devices with the reasoning capabilities of LLMs, the system addresses both acute health anomalies and routine adherence. It analyzes triggers through context-aware inquiries, produces provisional insights within a collaborative patient-clinician workflow, and offers personalized guidance. This approach aims to promote a more proactive and cooperative care paradigm, with the potential to enhance patient self-management and reduce avoidable clinical workload.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15798v1</guid></item><item><title>[cs updates on arXiv.org] Attributing and Exploiting Safety Vectors through Global Optimization in Large Language Models</title><link>https://arxiv.org/abs/2601.15801</link><description>arXiv:2601.15801v1 Announce Type: new 
Abstract: While Large Language Models (LLMs) are aligned to mitigate risks, their safety guardrails remain fragile against jailbreak attacks. This reveals limited understanding of components governing safety. Existing methods rely on local, greedy attribution that assumes independent component contributions. However, they overlook the cooperative interactions between different components in LLMs, such as attention heads, which jointly contribute to safety mechanisms. We propose \textbf{G}lobal \textbf{O}ptimization for \textbf{S}afety \textbf{V}ector Extraction (GOSV), a framework that identifies safety-critical attention heads through global optimization over all heads simultaneously. We employ two complementary activation repatching strategies: Harmful Patching and Zero Ablation. These strategies identify two spatially distinct sets of safety vectors with consistently low overlap, termed Malicious Injection Vectors and Safety Suppression Vectors, demonstrating that aligned LLMs maintain separate functional pathways for safety purposes. Through systematic analyses, we find that complete safety breakdown occurs when approximately 30\% of total heads are repatched across all models. Building on these insights, we develop a novel inference-time white-box jailbreak method that exploits the identified safety vectors through activation repatching. Our attack substantially outperforms existing white-box attacks across all test models, providing strong evidence for the effectiveness of the proposed GOSV framework on LLM safety interpretability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15801v1</guid></item><item><title>[cs updates on arXiv.org] A Beacon Based Solution for Autonomous UUVs GNSS-Denied Stealthy Navigation</title><link>https://arxiv.org/abs/2601.15802</link><description>arXiv:2601.15802v1 Announce Type: new 
Abstract: Autonomous Unmanned Underwater Vehicles (UUVs) enable military and civilian covert operations in coastal areas without relying on support vessels or Global Navigation Satellite Systems (GNSS). Such operations are critical when surface access is not possible and stealthy navigation is required in restricted environments such as protected zones or dangerous areas under access ban. GNSS denied navigation is then essential to maintaining concealment as surfacing could expose UUVs to detection. To ensure a precise fleet positioning a constellation of beacons deployed by aerial or surface drones establish a synthetic landmark network that will guide the fleet of UUVs along an optimized path from the continental shelf to the goal on the shore. These beacons either submerged or floating emit acoustic signals for UUV localisation and navigation. A hierarchical planner generates an adaptive route for the drones executing primitive actions while continuously monitoring and replanning as needed to maintain trajectory accuracy.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15802v1</guid></item><item><title>[cs updates on arXiv.org] Entangled Life and Code: A Computational Design Taxonomy for Synergistic Bio-Digital Systems</title><link>https://arxiv.org/abs/2601.15804</link><description>arXiv:2601.15804v1 Announce Type: new 
Abstract: Bio-digital systems that merge microbial life with technology promise new modes of computation, combining biological adaptability with digital precision. Yet realizing this potential symbiotically -- where biological and digital agents co-adapt and co-process -- remains elusive, largely due to the absence of a shared vocabulary bridging biology and computing. Consequently, microbes are often constrained to uni-directional roles, functioning as sensors or actuators rather than as active, computational partners in bio-digital systems. In response, we propose a taxonomy and pathways that articulate and expand the roles of biological and digital entities for synergetic bio-digital computation. Using this taxonomy, we analysed 70 systems across HCI, design, and engineering, identifying how biological mechanisms can be mapped onto computational abstractions. We argue that such mappings enable computationally actionable directions that foster richer and reciprocal relationships in bio-digital systems, supporting regenerative ecologies across time and scale while inspiring new paradigms for computation in HCI.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15804v1</guid></item><item><title>[cs updates on arXiv.org] Inference-Time Scaling of Verification: Self-Evolving Deep Research Agents via Test-Time Rubric-Guided Verification</title><link>https://arxiv.org/abs/2601.15808</link><description>arXiv:2601.15808v1 Announce Type: new 
Abstract: Recent advances in Deep Research Agents (DRAs) are transforming automated knowledge discovery and problem-solving. While the majority of existing efforts focus on enhancing policy capabilities via post-training, we propose an alternative paradigm: self-evolving the agent's ability by iteratively verifying the policy model's outputs, guided by meticulously crafted rubrics. This approach gives rise to the inference-time scaling of verification, wherein an agent self-improves by evaluating its generated answers to produce iterative feedback and refinements. We derive the rubrics based on an automatically constructed DRA Failure Taxonomy, which systematically classifies agent failures into five major categories and thirteen sub-categories. We present DeepVerifier, a rubrics-based outcome reward verifier that leverages the asymmetry of verification and outperforms vanilla agent-as-judge and LLM judge baselines by 12%-48% in meta-evaluation F1 score. To enable practical self-evolution, DeepVerifier integrates as a plug-and-play module during test-time inference. The verifier produces detailed rubric-based feedback, which is fed back to the agent for iterative bootstrapping, refining responses without additional training. This test-time scaling delivers 8%-11% accuracy gains on challenging subsets of GAIA and XBench-DeepResearch when powered by capable closed-source LLMs. Finally, to support open-source advancement, we release DeepVerifier-4K, a curated supervised fine-tuning dataset of 4,646 high-quality agent steps focused on DRA verification. These examples emphasize reflection and self-critique, enabling open models to develop robust verification capabilities.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15808v1</guid></item><item><title>[cs updates on arXiv.org] SteerEval: Inference-time Interventions Strengthen Multilingual Generalization in Neural Summarization Metrics</title><link>https://arxiv.org/abs/2601.15809</link><description>arXiv:2601.15809v1 Announce Type: new 
Abstract: An increasing body of work has leveraged multilingual language models for Natural Language Generation tasks such as summarization. A major empirical bottleneck in this area is the shortage of accurate and robust evaluation metrics for many languages, which hinders progress. Recent studies suggest that multilingual language models often use English as an internal pivot language, and that misalignment with this pivot can lead to degraded downstream performance. Motivated by the hypothesis that this mismatch could also apply to multilingual neural metrics, we ask whether steering their activations toward an English pivot can improve correlation with human judgments. We experiment with encoder- and decoder-based metrics and find that test-time intervention methods are effective across the board, increasing metric effectiveness for diverse languages.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15809v1</guid></item><item><title>[cs updates on arXiv.org] A Mobile Application for Flower Recognition System Based on Convolutional Neural Networks</title><link>https://arxiv.org/abs/2601.15810</link><description>arXiv:2601.15810v1 Announce Type: new 
Abstract: A convolutional neural network (CNN) is a deep learning algorithm that has been specifically designed for computer vision applications. The CNNs proved successful in handling the increasing amount of data in many computer vision problems, where classical machine learning algorithms were insufficient. Flowers have many uses in our daily lives, from decorating to making medicines to detoxifying the environment. Identifying flower types requires expert knowledge. However, accessing experts at any time and in any location may not always be feasible. In this study a mobile application based on CNNs was developed to recognize different types of flowers to provide non-specialists with quick and easy access to information about flower types. The study employed three distinct CNN models, namely MobileNet, DenseNet121, and Xception, to determine the most suitable model for the mobile application. The classification performances of the models were evaluated by training them with seven different optimization algorithms. The DenseNet-121 architecture, which uses the stochastic gradient descent (SGD) optimization algorithm, was the most successful, achieving 95.84 % accuracy, 96.00% precision, recall, and F1-score. This result shows that CNNs can be used for flower classification in mobile applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15810v1</guid></item><item><title>[cs updates on arXiv.org] Contractions of quasi relation algebras and applications to representability</title><link>https://arxiv.org/abs/2601.15811</link><description>arXiv:2601.15811v1 Announce Type: new 
Abstract: Quasi relation algebras (qRAs) were first described by Galatos and Jipsen in 2013. They are generalisations of relation algebras and can also be viewed as certain residuated lattice expansions. We identify positive symmetric idempotent elements in qRAs and show that they can be used to construct new qRAs, so-called contractions of the original algebra. We then show that the contraction of a distributive qRA will be representable when the original algebra is representable. Further, we identify a class of distributive qRAs that are not finitely representable.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15811v1</guid></item><item><title>[cs updates on arXiv.org] ErrorMap and ErrorAtlas: Charting the Failure Landscape of Large Language Models</title><link>https://arxiv.org/abs/2601.15812</link><description>arXiv:2601.15812v1 Announce Type: new 
Abstract: Large Language Models (LLM) benchmarks tell us when models fail, but not why they fail. A wrong answer on a reasoning dataset may stem from formatting issues, calculation errors, or dataset noise rather than weak reasoning. Without disentangling such causes, benchmarks remain incomplete and cannot reliably guide model improvement. We introduce ErrorMap, the first method to chart the sources of LLM failure. It extracts a model's unique "failure signature", clarifies what benchmarks measure, and broadens error identification to reduce blind spots. This helps developers debug models, aligns benchmark goals with outcomes, and supports informed model selection. ErrorMap works on any model or dataset with the same logic. Applying our method to 35 datasets and 83 models we generate ErrorAtlas, a taxonomy of model errors, revealing recurring failure patterns. ErrorAtlas highlights error types that are currently underexplored in LLM research, such as omissions of required details in the output and question misinterpretation. By shifting focus from where models succeed to why they fail, ErrorMap and ErrorAtlas enable advanced evaluation - one that exposes hidden weaknesses and directs progress. Unlike success, typically measured by task-level metrics, our approach introduces a deeper evaluation layer that can be applied globally across models and tasks, offering richer insights into model behavior and limitations. We make the taxonomy and code publicly available with plans to periodically update ErrorAtlas as new benchmarks and models emerge.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15812v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Off-the-Shelf Models: A Lightweight and Accessible Machine Learning Pipeline for Ecologists Working with Image Data</title><link>https://arxiv.org/abs/2601.15813</link><description>arXiv:2601.15813v1 Announce Type: new 
Abstract: We introduce a lightweight experimentation pipeline designed to lower the barrier for applying machine learning (ML) methods for classifying images in ecological research. We enable ecologists to experiment with ML models independently, thus they can move beyond off-the-shelf models and generate insights tailored to local datasets and specific classification tasks and target variables. Our tool combines a simple command-line interface for preprocessing, training, and evaluation with a graphical interface for annotation, error analysis, and model comparison. This design enables ecologists to build and iterate on compact, task-specific classifiers without requiring advanced ML expertise. As a proof of concept, we apply the pipeline to classify red deer (Cervus elaphus) by age and sex from 3392 camera trap images collected in the Veldenstein Forest, Germany. Using 4352 cropped images containing individual deer labeled by experts, we trained and evaluated multiple backbone architectures with a wide variety of parameters and data augmentation strategies. Our best-performing models achieved 90.77% accuracy for age classification and 96.15% for sex classification. These results demonstrate that reliable demographic classification is feasible even with limited data to answer narrow, well-defined ecological problems. More broadly, the framework provides ecologists with an accessible tool for developing ML models tailored to specific research questions, paving the way for broader adoption of ML in wildlife monitoring and demographic analysis.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15813v1</guid></item><item><title>[cs updates on arXiv.org] Virtual Traffic Police: Large Language Model-Augmented Traffic Signal Control for Unforeseen Incidents</title><link>https://arxiv.org/abs/2601.15816</link><description>arXiv:2601.15816v1 Announce Type: new 
Abstract: Adaptive traffic signal control (TSC) has demonstrated strong effectiveness in managing dynamic traffic flows. However, conventional methods often struggle when unforeseen traffic incidents occur (e.g., accidents and road maintenance), which typically require labor-intensive and inefficient manual interventions by traffic police officers. Large Language Models (LLMs) appear to be a promising solution thanks to their remarkable reasoning and generalization capabilities. Nevertheless, existing works often propose to replace existing TSC systems with LLM-based systems, which can be (i) unreliable due to the inherent hallucinations of LLMs and (ii) costly due to the need for system replacement. To address the issues of existing works, we propose a hierarchical framework that augments existing TSC systems with LLMs, whereby a virtual traffic police agent at the upper level dynamically fine-tunes selected parameters of signal controllers at the lower level in response to real-time traffic incidents. To enhance domain-specific reliability in response to unforeseen traffic incidents, we devise a self-refined traffic language retrieval system (TLRS), whereby retrieval-augmented generation is employed to draw knowledge from a tailored traffic language database that encompasses traffic conditions and controller operation principles. Moreover, we devise an LLM-based verifier to update the TLRS continuously over the reasoning process. Our results show that LLMs can serve as trustworthy virtual traffic police officers that can adapt conventional TSC methods to unforeseen traffic incidents with significantly improved operational efficiency and reliability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15816v1</guid></item><item><title>[cs updates on arXiv.org] ExDR: Explanation-driven Dynamic Retrieval Enhancement for Multimodal Fake News Detection</title><link>https://arxiv.org/abs/2601.15820</link><description>arXiv:2601.15820v1 Announce Type: new 
Abstract: The rapid spread of multimodal fake news poses a serious societal threat, as its evolving nature and reliance on timely factual details challenge existing detection methods. Dynamic Retrieval-Augmented Generation provides a promising solution by triggering keyword-based retrieval and incorporating external knowledge, thus enabling both efficient and accurate evidence selection. However, it still faces challenges in addressing issues such as redundant retrieval, coarse similarity, and irrelevant evidence when applied to deceptive content. In this paper, we propose ExDR, an Explanation-driven Dynamic Retrieval-Augmented Generation framework for Multimodal Fake News Detection. Our framework systematically leverages model-generated explanations in both the retrieval triggering and evidence retrieval modules. It assesses triggering confidence from three complementary dimensions, constructs entity-aware indices by fusing deceptive entities, and retrieves contrastive evidence based on deception-specific features to challenge the initial claim and enhance the final prediction. Experiments on two benchmark datasets, AMG and MR2, demonstrate that ExDR consistently outperforms previous methods in retrieval triggering accuracy, retrieval quality, and overall detection performance, highlighting its effectiveness and generalization capability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15820v1</guid></item><item><title>[cs updates on arXiv.org] Introducing the Generative Application Firewall (GAF)</title><link>https://arxiv.org/abs/2601.15824</link><description>arXiv:2601.15824v1 Announce Type: new 
Abstract: This paper introduces the Generative Application Firewall (GAF), a new architectural layer for securing LLM applications. Existing defenses -- prompt filters, guardrails, and data-masking -- remain fragmented; GAF unifies them into a single enforcement point, much like a WAF coordinates defenses for web traffic, while also covering autonomous agents and their tool interactions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15824v1</guid></item><item><title>[cs updates on arXiv.org] Can professional translators identify machine-generated text?</title><link>https://arxiv.org/abs/2601.15828</link><description>arXiv:2601.15828v1 Announce Type: new 
Abstract: This study investigates whether professional translators can reliably identify short stories generated in Italian by artificial intelligence (AI) without prior specialized training. Sixty-nine translators took part in an in-person experiment, where they assessed three anonymized short stories - two written by ChatGPT-4o and one by a human author. For each story, participants rated the likelihood of AI authorship and provided justifications for their choices. While average results were inconclusive, a statistically significant subset (16.2%) successfully distinguished the synthetic texts from the human text, suggesting that their judgements were informed by analytical skill rather than chance. However, a nearly equal number misclassified the texts in the opposite direction, often relying on subjective impressions rather than objective markers, possibly reflecting a reader preference for AI-generated texts. Low burstiness and narrative contradiction emerged as the most reliable indicators of synthetic authorship, with unexpected calques, semantic loans and syntactic transfer from English also reported. In contrast, features such as grammatical accuracy and emotional tone frequently led to misclassification. These findings raise questions about the role and scope of synthetic-text editing in professional contexts.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15828v1</guid></item><item><title>[cs updates on arXiv.org] Towards Realistic Remote Sensing Dataset Distillation with Discriminative Prototype-guided Diffusion</title><link>https://arxiv.org/abs/2601.15829</link><description>arXiv:2601.15829v1 Announce Type: new 
Abstract: Recent years have witnessed the remarkable success of deep learning in remote sensing image interpretation, driven by the availability of large-scale benchmark datasets. However, this reliance on massive training data also brings two major challenges: (1) high storage and computational costs, and (2) the risk of data leakage, especially when sensitive categories are involved. To address these challenges, this study introduces the concept of dataset distillation into the field of remote sensing image interpretation for the first time. Specifically, we train a text-to-image diffusion model to condense a large-scale remote sensing dataset into a compact and representative distilled dataset. To improve the discriminative quality of the synthesized samples, we propose a classifier-driven guidance by injecting a classification consistency loss from a pre-trained model into the diffusion training process. Besides, considering the rich semantic complexity of remote sensing imagery, we further perform latent space clustering on training samples to select representative and diverse prototypes as visual style guidance, while using a visual language model to provide aggregated text descriptions. Experiments on three high-resolution remote sensing scene classification benchmarks show that the proposed method can distill realistic and diverse samples for downstream model training. Code and pre-trained models are available online (https://github.com/YonghaoXu/DPD).</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15829v1</guid></item><item><title>[cs updates on arXiv.org] An IoT-Based Smart Plant Monitoring and Irrigation System with Real-Time Environmental Sensing, Automated Alerts, and Cloud Analytics</title><link>https://arxiv.org/abs/2601.15830</link><description>arXiv:2601.15830v1 Announce Type: new 
Abstract: The increasing global demand for sustainable agriculture necessitates intelligent monitoring systems that optimize resource utilization and plant health management. Traditional farming methods rely on manual observation and periodic watering, often leading to water wastage, inconsistent plant growth, and delayed response to environmental changes. This paper presents a comprehensive IoT-based smart plant monitoring system that integrates multiple environmental sensors with automated irrigation and cloud analytics. The proposed system utilizes an ESP32 microcontroller to collect real-time data from DHT22 (temperature/humidity), HC-SR04 (water level), and soil moisture sensors, with visual feedback through an OLED display and auditory alerts via a buzzer. All sensor data is wirelessly transmitted to the ThingSpeak cloud platform for remote monitoring, historical analysis, and automated alert generation. Experimental results demonstrate the system's effectiveness in maintaining optimal soil moisture levels (with 92\% accuracy), providing real-time environmental monitoring, and reducing water consumption by approximately 40\% compared to conventional irrigation methods. The integrated web dashboard offers comprehensive visualization of plant health parameters, making it suitable for both small-scale gardening and commercial agriculture applications. With a total implementation cost of \$45.20, this system provides an affordable, scalable solution for precision agriculture and smart farming.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15830v1</guid></item><item><title>[cs updates on arXiv.org] RF Intelligence for Health: Classification of SmartBAN Signals in overcrowded ISM band</title><link>https://arxiv.org/abs/2601.15836</link><description>arXiv:2601.15836v1 Announce Type: new 
Abstract: Accurate classification of Radio-Frequency (RF) signals is essential for reliable wearable health-monitoring systems, providing awareness of the interference conditions in which medical protocols operate. In the overcrowded 2.4 GHz ISM band, however, identifying low-power transmissions from medical sensors is challenging due to strong co-channel interference and substantial power asymmetry with coexisting technologies. This work introduces the first open source framework for automatic recognition of SmartBAN signals in Body Area Networks (BANs). The framework combines a synthetic dataset of simulated signals with real RF acquisitions obtained through Software-Defined Radios (SDRs), enabling both controlled and realistic evaluation. Deep convolutional neural networks based on ResNet encoders and U-Net decoders with attention mechanisms are trained and assessed across diverse propagation conditions. The proposed approach achieves over 90% accuracy on synthetic datasets and demonstrates consistent performance on real over-the-air spectrograms. By enabling reliable SmartBAN signal recognition in dense spectral environments, this framework supports interferenceaware coexistence strategies and improves the dependability of wearable healthcare systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15836v1</guid></item><item><title>[cs updates on arXiv.org] TinySense: Effective CSI Compression for Scalable and Accurate Wi-Fi Sensing</title><link>https://arxiv.org/abs/2601.15838</link><description>arXiv:2601.15838v1 Announce Type: new 
Abstract: With the growing demand for device-free and privacy-preserving sensing solutions, Wi-Fi sensing has emerged as a promising approach for human pose estimation (HPE). However, existing methods often process vast amounts of channel state information (CSI) data directly, ultimately straining networking resources. This paper introduces TinySense, an efficient compression framework that enhances the scalability of Wi-Fi-based human sensing. Our approach is based on a new vector quantization-based generative adversarial network (VQGAN). Specifically, by leveraging a VQGAN-learned codebook, TinySense significantly reduces CSI data while maintaining the accuracy required for reliable HPE. To optimize compression, we employ the K-means algorithm to dynamically adjust compression bitrates to cluster a large-scale pre-trained codebook into smaller subsets. Furthermore, a Transformer model is incorporated to mitigate bitrate loss, enhancing robustness in unreliable networking conditions. We prototype TinySense on an experimental testbed using Jetson Nano and Raspberry Pi to measure latency and network resource use. Extensive results demonstrate that TinySense significantly outperforms state-of-the-art compression schemes, achieving up to 1.5x higher HPE accuracy score (PCK20) under the same compression rate. It also reduces latency and networking overhead, respectively, by up to 5x and 2.5x. The code repository is available online at here.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15838v1</guid></item><item><title>[cs updates on arXiv.org] Determinants of Training Corpus Size for Clinical Text Classification</title><link>https://arxiv.org/abs/2601.15846</link><description>arXiv:2601.15846v1 Announce Type: new 
Abstract: Introduction: Clinical text classification using natural language processing (NLP) models requires adequate training data to achieve optimal performance. For that, 200-500 documents are typically annotated. The number is constrained by time and costs and lacks justification of the sample size requirements and their relationship to text vocabulary properties.
  Methods: Using the publicly available MIMIC-III dataset containing hospital discharge notes with ICD-9 diagnoses as labels, we employed pre-trained BERT embeddings followed by Random Forest classifiers to identify 10 randomly selected diagnoses, varying training corpus sizes from 100 to 10,000 documents, and analyzed vocabulary properties by identifying strong and noisy predictive words through Lasso logistic regression on bag-of-words embeddings.
  Results: Learning curves varied significantly across the 10 classification tasks despite identical preprocessing and algorithms, with 600 documents sufficient to achieve 95% of the performance attainable with 10,000 documents for all tasks. Vocabulary analysis revealed that more strong predictors and fewer noisy predictors were associated with steeper learning curves, where every 100 additional noisy words decreased accuracy by approximately 0.02 while 100 additional strong predictors increased maximum accuracy by approximately 0.04.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15846v1</guid></item><item><title>[cs updates on arXiv.org] CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval</title><link>https://arxiv.org/abs/2601.15849</link><description>arXiv:2601.15849v1 Announce Type: new 
Abstract: General-purpose embedding models have demonstrated strong performance in text retrieval but remain suboptimal for table retrieval, where highly structured content leads to semantic compression and query-table mismatch. Recent LLM-based retrieval augmentation methods mitigate this issue by generating synthetic queries, yet they often rely on heuristic partial-table selection and seldom leverage these synthetic queries as supervision to improve the embedding model. We introduce CGPT, a training framework that enhances table retrieval through LLM-generated supervision. CGPT constructs semantically diverse partial tables by clustering table instances using K-means and sampling across clusters to broaden semantic coverage. An LLM then generates synthetic queries for these partial tables, which are used in hard-negative contrastive fine-tuning to refine the embedding model. Experiments across four public benchmarks (MimoTable, OTTQA, FetaQA, and E2E-WTQ) show that CGPT consistently outperforms retrieval baselines, including QGpT, with an average R@1 improvement of 16.54 percent. In a unified multi-domain corpus setting, CGPT further demonstrates strong cross-domain generalization and remains effective even when using smaller LLMs for synthetic query generation. These results indicate that semantically guided partial-table construction, combined with contrastive training from LLM-generated supervision, provides an effective and scalable paradigm for large-scale table retrieval. Our code is available at https://github.com/yumeow0122/CGPT.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15849v1</guid></item><item><title>[cs updates on arXiv.org] Practical applications of Set Shaping Theory to Non-Uniform Sequences</title><link>https://arxiv.org/abs/2601.15853</link><description>arXiv:2601.15853v1 Announce Type: new 
Abstract: Set Shaping Theory (SST) moves beyond the classical fixed-space model by constructing bijective mappings the original sequence set into structured regions of a larger sequence space. These shaped subsets are characterized by a reduced average information content, measured by the product of the empirical entropy and the length, yielding (N +k)H0(f(s)) &lt; NH0(s), which represents the universal coding limit when the source distribution is unknown. The principal experimental difficulty in applying Set Shaping Theory to non-uniform sequences arises from the need to order the sequences of both the original and transformed sets according to their information content. An exact ordering of these sets entails exponential complexity, rendering a direct implementation impractical. In this article, we show that this obstacle can be overcome by performing an approximate but informative ordering that preserves the structural requirements of SST while achieving the shaping gain predicted by the theory. This result extends previous experimental findings obtained for uniformly distributed sequences and demonstrates that the shaping advantage of SST persists for non-uniform sequences. Finally, to ensure full reproducibility, the software implementing the proposed method has been made publicly available on GitHub, enabling independent verification of the results reported in this work</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15853v1</guid></item><item><title>[cs updates on arXiv.org] Uncertainty-guided Generation of Dark-field Radiographs</title><link>https://arxiv.org/abs/2601.15859</link><description>arXiv:2601.15859v1 Announce Type: new 
Abstract: X-ray dark-field radiography provides complementary diagnostic information to conventional attenuation imaging by visualizing microstructural tissue changes through small-angle scattering. However, the limited availability of such data poses challenges for developing robust deep learning models. In this work, we present the first framework for generating dark-field images directly from standard attenuation chest X-rays using an Uncertainty-Guided Progressive Generative Adversarial Network. The model incorporates both aleatoric and epistemic uncertainty to improve interpretability and reliability. Experiments demonstrate high structural fidelity of the generated images, with consistent improvement of quantitative metrics across stages. Furthermore, out-of-distribution evaluation confirms that the proposed model generalizes well. Our results indicate that uncertainty-guided generative modeling enables realistic dark-field image synthesis and provides a reliable foundation for future clinical applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15859v1</guid></item><item><title>[cs updates on arXiv.org] STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion</title><link>https://arxiv.org/abs/2601.15860</link><description>arXiv:2601.15860v1 Announce Type: new 
Abstract: Table retrieval is the task of retrieving the most relevant tables from large-scale corpora given natural language queries. However, structural and semantic discrepancies between unstructured text and structured tables make embedding alignment particularly challenging. Recent methods such as QGpT attempt to enrich table semantics by generating synthetic queries, yet they still rely on coarse partial-table sampling and simple fusion strategies, which limit semantic diversity and hinder effective query-table alignment. We propose STAR (Semantic Table Representation), a lightweight framework that improves semantic table representation through semantic clustering and weighted fusion. STAR first applies header-aware K-means clustering to group semantically similar rows and selects representative centroid instances to construct a diverse partial table. It then generates cluster-specific synthetic queries to comprehensively cover the table's semantic space. Finally, STAR employs weighted fusion strategies to integrate table and query embeddings, enabling fine-grained semantic alignment. This design enables STAR to capture complementary information from structured and textual sources, improving the expressiveness of table representations. Experiments on five benchmarks show that STAR achieves consistently higher Recall than QGpT on all datasets, demonstrating the effectiveness of semantic clustering and adaptive weighted fusion for robust table representation. Our code is available at https://github.com/adsl135789/STAR.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15860v1</guid></item><item><title>[cs updates on arXiv.org] Finding large sparse induced subgraphs in graphs of small (but not very small) tree-independence number</title><link>https://arxiv.org/abs/2601.15861</link><description>arXiv:2601.15861v1 Announce Type: new 
Abstract: The independence number of a tree decomposition is the size of a largest independent set contained in a single bag. The tree-independence number of a graph $G$ is the minimum independence number of a tree decomposition of $G$. As shown recently by Lima et al. [ESA~2024], a large family of optimization problems asking for a maximum-weight induced subgraph of bounded treewidth, satisfying a given \textsf{CMSO}$_2$ property, can be solved in polynomial time in graphs whose tree-independence number is bounded by some constant~$k$.
  However, the complexity of the algorithm of Lima et al. grows rapidly with $k$, making it useless if the tree-independence number is superconstant. In this paper we present a refined version of the algorithm. We show that the same family of problems can be solved in time~$n^{\mathcal{O}(k)}$, where $n$ is the number of vertices of the instance, $k$ is the tree-independence number, and the $\mathcal{O}(\cdot)$-notation hides factors depending on the treewidth bound of the solution and the considered \textsf{CMSO}$_2$ property.
  This running time is quasipolynomial for classes of graphs with polylogarithmic tree-independence number; several such classes were recently discovered. Furthermore, the running time is subexponential for many natural classes of geometric intersection graphs -- namely, ones that admit balanced clique-based separators of sublinear size.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15861v1</guid></item><item><title>[cs updates on arXiv.org] A Lightweight Brain-Inspired Machine Learning Framework for Coronary Angiography: Hybrid Neural Representation and Robust Learning Strategies</title><link>https://arxiv.org/abs/2601.15865</link><description>arXiv:2601.15865v1 Announce Type: new 
Abstract: Background: Coronary angiography (CAG) is a cornerstone imaging modality for assessing coronary artery disease and guiding interventional treatment decisions. However, in real-world clinical settings, angiographic images are often characterized by complex lesion morphology, severe class imbalance, label uncertainty, and limited computational resources, posing substantial challenges to conventional deep learning approaches in terms of robustness and generalization.Methods: The proposed framework is built upon a pretrained convolutional neural network to construct a lightweight hybrid neural representation. A selective neural plasticity training strategy is introduced to enable efficient parameter adaptation. Furthermore, a brain-inspired attention-modulated loss function, combining Focal Loss with label smoothing, is employed to enhance sensitivity to hard samples and uncertain annotations. Class-imbalance-aware sampling and cosine annealing with warm restarts are adopted to mimic rhythmic regulation and attention allocation mechanisms observed in biological neural systems.Results: Experimental results demonstrate that the proposed lightweight brain-inspired model achieves strong and stable performance in binary coronary angiography classification, yielding competitive accuracy, recall, F1-score, and AUC metrics while maintaining high computational efficiency.Conclusion: This study validates the effectiveness of brain-inspired learning mechanisms in lightweight medical image analysis and provides a biologically plausible and deployable solution for intelligent clinical decision support under limited computational resources.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15865v1</guid></item><item><title>[cs updates on arXiv.org] Out-of-Distribution Detection Based on Total Variation Estimation</title><link>https://arxiv.org/abs/2601.15867</link><description>arXiv:2601.15867v1 Announce Type: new 
Abstract: This paper introduces a novel approach to securing machine learning model deployments against potential distribution shifts in practical applications, the Total Variation Out-of-Distribution (TV-OOD) detection method. Existing methods have produced satisfactory results, but TV-OOD improves upon these by leveraging the Total Variation Network Estimator to calculate each input's contribution to the overall total variation. By defining this as the total variation score, TV-OOD discriminates between in- and out-of-distribution data. The method's efficacy was tested across a range of models and datasets, consistently yielding results in image classification tasks that were either comparable or superior to those achieved by leading-edge out-of-distribution detection techniques across all evaluation metrics.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15867v1</guid></item><item><title>[cs updates on arXiv.org] Artificial Rigidities vs. Biological Noise: A Comparative Analysis of Multisensory Integration in AV-HuBERT and Human Observers</title><link>https://arxiv.org/abs/2601.15869</link><description>arXiv:2601.15869v1 Announce Type: new 
Abstract: This study evaluates AV-HuBERT's perceptual bio-fidelity by benchmarking its response to incongruent audiovisual stimuli (McGurk effect) against human observers (N=44). Results reveal a striking quantitative isomorphism: AI and humans exhibited nearly identical auditory dominance rates (32.0% vs. 31.8%), suggesting the model captures biological thresholds for auditory resistance. However, AV-HuBERT showed a deterministic bias toward phonetic fusion (68.0%), significantly exceeding human rates (47.7%). While humans displayed perceptual stochasticity and diverse error profiles, the model remained strictly categorical. Findings suggest that current self-supervised architectures mimic multisensory outcomes but lack the neural variability inherent to human speech perception.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15869v1</guid></item><item><title>[cs updates on arXiv.org] PF-D2M: A Pose-free Diffusion Model for Universal Dance-to-Music Generation</title><link>https://arxiv.org/abs/2601.15872</link><description>arXiv:2601.15872v1 Announce Type: new 
Abstract: Dance-to-music generation aims to generate music that is aligned with dance movements. Existing approaches typically rely on body motion features extracted from a single human dancer and limited dance-to-music datasets, which restrict their performance and applicability to real-world scenarios involving multiple dancers and non-human dancers. In this paper, we propose PF-D2M, a universal diffusion-based dance-to-music generation model that incorporates visual features extracted from dance videos. PF-D2M is trained with a progressive training strategy that effectively addresses data scarcity and generalization challenges. Both objective and subjective evaluations show that PF-D2M achieves state-of-the-art performance in dance-music alignment and music quality.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15872v1</guid></item><item><title>[cs updates on arXiv.org] SoK: Challenges in Tabular Membership Inference Attacks</title><link>https://arxiv.org/abs/2601.15874</link><description>arXiv:2601.15874v1 Announce Type: new 
Abstract: Membership Inference Attacks (MIAs) are currently a dominant approach for evaluating privacy in machine learning applications. Despite their significance in identifying records belonging to the training dataset, several concerns remain unexplored, particularly with regard to tabular data. In this paper, first, we provide an extensive review and analysis of MIAs considering two main learning paradigms: centralized and federated learning. We extend and refine the taxonomy for both. Second, we demonstrate the efficacy of MIAs in tabular data using several attack strategies, also including defenses. Furthermore, in a federated learning scenario, we consider the threat posed by an outsider adversary, which is often neglected. Third, we demonstrate the high vulnerability of single-outs (records with a unique signature) to MIAs. Lastly, we explore how MIAs transfer across model architectures. Our results point towards a general poor performance of these attacks in tabular data which contrasts with previous state-of-the-art. Notably, even attacks with limited attack performance can still successfully expose a large portion of single-outs. Moreover, our findings suggest that using different surrogate models makes MIAs more effective.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15874v1</guid></item><item><title>[cs updates on arXiv.org] EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience</title><link>https://arxiv.org/abs/2601.15876</link><description>arXiv:2601.15876v1 Announce Type: new 
Abstract: The development of native computer-use agents (CUA) represents a significant leap in multimodal AI. However, their potential is currently bottlenecked by the constraints of static data scaling. Existing paradigms relying primarily on passive imitation of static datasets struggle to capture the intricate causal dynamics inherent in long-horizon computer tasks. In this work, we introduce EvoCUA, a native computer use agentic model. Unlike static imitation, EvoCUA integrates data generation and policy optimization into a self-sustaining evolutionary cycle. To mitigate data scarcity, we develop a verifiable synthesis engine that autonomously generates diverse tasks coupled with executable validators. To enable large-scale experience acquisition, we design a scalable infrastructure orchestrating tens of thousands of asynchronous sandbox rollouts. Building on these massive trajectories, we propose an iterative evolving learning strategy to efficiently internalize this experience. This mechanism dynamically regulates policy updates by identifying capability boundaries -- reinforcing successful routines while transforming failure trajectories into rich supervision through error analysis and self-correction. Empirical evaluations on the OSWorld benchmark demonstrate that EvoCUA achieves a success rate of 56.7%, establishing a new open-source state-of-the-art. Notably, EvoCUA significantly outperforms the previous best open-source model, OpenCUA-72B (45.0%), and surpasses leading closed-weights models such as UI-TARS-2 (53.1%). Crucially, our results underscore the generalizability of this approach: the evolving paradigm driven by learning from experience yields consistent performance gains across foundation models of varying scales, establishing a robust and scalable path for advancing native agent capabilities.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15876v1</guid></item><item><title>[cs updates on arXiv.org] Evaluating and Achieving Controllable Code Completion in Code LLM</title><link>https://arxiv.org/abs/2601.15879</link><description>arXiv:2601.15879v1 Announce Type: new 
Abstract: Code completion has become a central task, gaining significant attention with the rise of large language model (LLM)-based tools in software engineering. Although recent advances have greatly improved LLMs' code completion abilities, evaluation methods have not advanced equally. Most current benchmarks focus solely on functional correctness of code completions based on given context, overlooking models' ability to follow user instructions during completion-a common scenario in LLM-assisted programming. To address this limitation, we present the first instruction-guided code completion benchmark, Controllable Code Completion Benchmark (C3-Bench), comprising 2,195 carefully designed completion tasks. Through comprehensive evaluation of over 40 mainstream LLMs across C3-Bench and conventional benchmarks, we reveal substantial gaps in instruction-following capabilities between open-source and advanced proprietary models during code completion tasks. Moreover, we develop a straightforward data synthesis pipeline that leverages Qwen2.5-Coder to generate high-quality instruction-completion pairs for supervised fine-tuning (SFT). The resulting model, Qwen2.5-Coder-C3, achieves state-of-the-art performance on C3-Bench. Our findings provide valuable insights for enhancing LLMs' code completion and instruction-following capabilities, establishing new directions for future research in code LLMs. To facilitate reproducibility and foster further research in code LLMs, we open-source all code, datasets, and models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15879v1</guid></item><item><title>[cs updates on arXiv.org] PMPBench: A Paired Multi-Modal Pan-Cancer Benchmark for Medical Image Synthesis</title><link>https://arxiv.org/abs/2601.15884</link><description>arXiv:2601.15884v1 Announce Type: new 
Abstract: Contrast medium plays a pivotal role in radiological imaging, as it amplifies lesion conspicuity and improves detection for the diagnosis of tumor-related diseases. However, depending on the patient's health condition or the medical resources available, the use of contrast medium is not always feasible. Recent work has explored AI-based image translation to synthesize contrast-enhanced images directly from non-contrast scans, aims to reduce side effects and streamlines clinical workflows. Progress in this direction has been constrained by data limitations: (1) existing public datasets focus almost exclusively on brain-related paired MR modalities; (2) other collections include partially paired data but suffer from missing modalities/timestamps and imperfect spatial alignment; (3) explicit labeling of CT vs. CTC or DCE phases is often absent; (4) substantial resources remain private. To bridge this gap, we introduce the first public, fully paired, pan-cancer medical imaging dataset spanning 11 human organs. The MR data include complete dynamic contrast-enhanced (DCE) sequences covering all three phases (DCE1-DCE3), while the CT data provide paired non-contrast and contrast-enhanced acquisitions (CTC). The dataset is curated for anatomical correspondence, enabling rigorous evaluation of 1-to-1, N-to-1, and N-to-N translation settings (e.g., predicting DCE phases from non-contrast inputs). Built upon this resource, we establish a comprehensive benchmark. We report results from representative baselines of contemporary image-to-image translation. We release the dataset and benchmark to catalyze research on safe, effective contrast synthesis, with direct relevance to multi-organ oncology imaging workflows. Our code and dataset are publicly available at https://github.com/YifanChen02/PMPBench.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15884v1</guid></item><item><title>[cs updates on arXiv.org] Understanding the Transfer Limits of Vision Foundation Models</title><link>https://arxiv.org/abs/2601.15888</link><description>arXiv:2601.15888v1 Announce Type: new 
Abstract: Foundation models leverage large-scale pretraining to capture extensive knowledge, demonstrating generalization in a wide range of language tasks. By comparison, vision foundation models (VFMs) often exhibit uneven improvements across downstream tasks, despite substantial computational investment. We postulate that this limitation arises from a mismatch between pretraining objectives and the demands of downstream vision-and-imaging tasks. Pretraining strategies like masked image reconstruction or contrastive learning shape representations for tasks such as recovery of generic visual patterns or global semantic structures, which may not align with the task-specific requirements of downstream applications including segmentation, classification, or image synthesis. To investigate this in a concrete real-world clinical area, we assess two VFMs, a reconstruction-focused MAE-based model (ProFound) and a contrastive-learning-based model (ProViCNet), on five prostate multiparametric MR imaging tasks, examining how such task alignment influences transfer performance, i.e., from pretraining to fine-tuning. Our findings indicate that better alignment between pretraining and downstream tasks, measured by simple divergence metrics such as maximum-mean-discrepancy (MMD) between the same features before and after fine-tuning, correlates with greater performance improvements and faster convergence, emphasizing the importance of designing and analyzing pretraining objectives with downstream applicability in mind.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15888v1</guid></item><item><title>[cs updates on arXiv.org] Existential Positive Transductions of Sparse Graphs</title><link>https://arxiv.org/abs/2601.15890</link><description>arXiv:2601.15890v1 Announce Type: new 
Abstract: Monadic stability generalizes many tameness notions from structural graph theory such as planarity, bounded degree, bounded tree-width, and nowhere density. The sparsification conjecture predicts that the (possibly dense) monadically stable graph classes are exactly those that can be logically encoded by first-order (FO) transductions in the (always sparse) nowhere dense classes. So far this conjecture has been verified for several special cases, such as for classes of bounded shrub-depth, and for the monadically stable fragments of bounded (linear) clique-width, twin-width, and merge-width.
  In this work we propose the existential positive sparsification conjecture, predicting that the more restricted co-matching-free, monadically stable classes are exactly those that can be transduced from nowhere dense classes using only existential positive FO formulas. While the general conjecture remains open, we verify its truth for all known special cases of the original conjecture. Even stronger, we find the sparse preimages as subgraphs of the dense input graphs.
  As a key ingredient, we introduce a new combinatorial operation, called subflip, that arises as the natural co-matching-free analog of the flip operation, which is a central tool in the characterization of monadic stability. Using subflips, we characterize the co-matching-free fragment of monadic stability by appropriate strengthenings of the known flip-flatness and flipper game characterizations for monadic stability. In an attempt to generalize our results to the more expressive MSO logic, we discover (rediscover?) that on relational structures (existential) positive MSO has the same expressive power as (existential) positive FO.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15890v1</guid></item><item><title>[cs updates on arXiv.org] RadJEPA: Radiology Encoder for Chest X-Rays via Joint Embedding Predictive Architecture</title><link>https://arxiv.org/abs/2601.15891</link><description>arXiv:2601.15891v1 Announce Type: new 
Abstract: Recent advances in medical vision language models guide the learning of visual representations; however, this form of supervision is constrained by the availability of paired image text data, raising the question of whether robust radiology encoders can be learned without relying on language supervision. In this work, we introduce RadJEPA, a self-supervised framework built on a Joint Embedding Predictive Architecture that learns without language supervision. Pre-trained solely on unlabeled chest X-ray images, the model learns to predict latent representations of masked image regions. This predictive objective differs fundamentally from both image text pre-training and DINO-style self-distillation: rather than aligning global representations across views or modalities, RadJEPA explicitly models latent-space prediction. We evaluate the learned encoder on disease classification, semantic segmentation, and report generation tasks. Across benchmarks, RadJEPA achieves performance exceeding state-of-the-art approaches, including Rad-DINO.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15891v1</guid></item><item><title>[cs updates on arXiv.org] Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model</title><link>https://arxiv.org/abs/2601.15892</link><description>arXiv:2601.15892v1 Announce Type: new 
Abstract: Diffusion-based language models (DLLMs) offer non-sequential, block-wise generation and richer data reuse compared to autoregressive (AR) models, but existing code DLLMs still lag behind strong AR baselines under comparable budgets. We revisit this setting in a controlled study and introduce Stable-DiffCoder, a block diffusion code model that reuses the Seed-Coder architecture, data, and training pipeline. To enable efficient knowledge learning and stable training, we incorporate a block diffusion continual pretraining (CPT) stage enhanced by a tailored warmup and block-wise clipped noise schedule. Under the same data and architecture, Stable-DiffCoder overall outperforms its AR counterpart on a broad suite of code benchmarks. Moreover, relying only on the CPT and supervised fine-tuning stages, Stable-DiffCoder achieves stronger performance than a wide range of \~8B ARs and DLLMs, demonstrating that diffusion-based training can improve code modeling quality beyond AR training alone. Moreover, diffusion-based any-order modeling improves structured code modeling for editing and reasoning, and through data augmentation, benefits low-resource coding languages.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15892v1</guid></item><item><title>[cs updates on arXiv.org] Iterative Amortized Hierarchical VAE</title><link>https://arxiv.org/abs/2601.15894</link><description>arXiv:2601.15894v1 Announce Type: new 
Abstract: In this paper we propose the Iterative Amortized Hierarchical Variational Autoencoder (IA-HVAE), which expands on amortized inference with a hybrid scheme containing an initial amortized guess and iterative refinement with decoder gradients. We achieve this by creating a linearly separable decoder in a transform domain (e.g. Fourier space), enabling real-time applications with very high model depths. The architectural change leads to a 35x speed-up for iterative inference with respect to the traditional HVAE. We show that our hybrid approach outperforms fully amortized and fully iterative equivalents in accuracy and speed respectively. Moreover, the IAHVAE shows improved reconstruction quality over a vanilla HVAE in inverse problems such as deblurring and denoising.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15894v1</guid></item><item><title>[cs updates on arXiv.org] Co-Constructing Alignment: A Participatory Approach to Situate AI Values</title><link>https://arxiv.org/abs/2601.15895</link><description>arXiv:2601.15895v1 Announce Type: new 
Abstract: As AI systems become embedded in everyday practice, value misalignment has emerged as a pressing concern. Yet, dominant alignment approaches remain model centric, treating users as passive recipients of prespecified values rather than as epistemic agents who encounter and respond to misalignment during interactions. Drawing on situated perspectives, we frame alignment as an interactional practice co-constructed during human AI interaction. We investigate how users understand and wish to contribute to this process through a participatory workshop that combines misalignment diaries with generative design activities. We surface how misalignments materialise in practice and how users envision acting on them, grounded in the context of researchers using Large Language Models as research assistants. Our findings show that misalignments are experienced less as abstract ethical violations than as unexpected responses, and task or social breakdowns. Participants articulated roles ranging from adjusting and interpreting model behaviour to deliberate non-engagement as an alignment strategy. We conclude with implications for designing systems that support alignment as an ongoing, situated, and shared practice.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15895v1</guid></item><item><title>[cs updates on arXiv.org] ThermoSplat: Cross-Modal 3D Gaussian Splatting with Feature Modulation and Geometry Decoupling</title><link>https://arxiv.org/abs/2601.15897</link><description>arXiv:2601.15897v1 Announce Type: new 
Abstract: Multi-modal scene reconstruction integrating RGB and thermal infrared data is essential for robust environmental perception across diverse lighting and weather conditions. However, extending 3D Gaussian Splatting (3DGS) to multi-spectral scenarios remains challenging. Current approaches often struggle to fully leverage the complementary information of multi-modal data, typically relying on mechanisms that either tend to neglect cross-modal correlations or leverage shared representations that fail to adaptively handle the complex structural correlations and physical discrepancies between spectrums. To address these limitations, we propose ThermoSplat, a novel framework that enables deep spectral-aware reconstruction through active feature modulation and adaptive geometry decoupling. First, we introduce a Cross-Modal FiLM Modulation mechanism that dynamically conditions shared latent features on thermal structural priors, effectively guiding visible texture synthesis with reliable cross-modal geometric cues. Second, to accommodate modality-specific geometric inconsistencies, we propose a Modality-Adaptive Geometric Decoupling scheme that learns independent opacity offsets and executes an independent rasterization pass for the thermal branch. Additionally, a hybrid rendering pipeline is employed to integrate explicit Spherical Harmonics with implicit neural decoding, ensuring both semantic consistency and high-frequency detail preservation. Extensive experiments on the RGBT-Scenes dataset demonstrate that ThermoSplat achieves state-of-the-art rendering quality across both visible and thermal spectrums.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15897v1</guid></item><item><title>[cs updates on arXiv.org] Blind Identification of Channel Codes: A Subspace-Coding Approach</title><link>https://arxiv.org/abs/2601.15903</link><description>arXiv:2601.15903v1 Announce Type: new 
Abstract: The problem of blind identification of channel codes at a receiver involves identifying a code chosen by a transmitter from a known code-family, by observing the transmitted codewords through the channel. Most existing approaches for code-identification are contingent upon the codes in the family having some special structure, and are often computationally expensive otherwise. Further, rigorous analytical guarantees on the performance of these existing techniques are largely absent. This work presents a new method for code-identification on the binary symmetric channel (BSC), inspired by the framework of subspace codes for operator channels, carefully combining principles of hamming-metric and subspace-metric decoding. We refer to this method as the minimum denoised subspace discrepancy decoder. We present theoretical guarantees for code-identification using this decoder, for bounded-weight errors, and also present a bound on the probability of error when used on the BSC. Simulations demonstrate the improved performance of our decoder for random linear codes beyond existing general-purpose techniques, across most channel conditions and even with a limited number of received vectors.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15903v1</guid></item><item><title>[cs updates on arXiv.org] Dynamic Server Allocation Under Stochastic Switchover on Time-Varying Links</title><link>https://arxiv.org/abs/2601.15904</link><description>arXiv:2601.15904v1 Announce Type: new 
Abstract: Dynamic resource allocation to parallel queues is a cornerstone of network scheduling, yet classical solutions often fail when accounting for the overhead of switching delays to queues with superior link conditions. In particular, system performance is further degraded when switching delays are stochastic and inhomogeneous. In this domain, the myopic, Max-Weight policy struggles, as it is agnostic to switching delays. This paper introduces ACI, a non-myopic, frame-based scheduling framework that directly amortizes these switching delays. We first use a Lyapunov drift analysis to prove that backlog-driven ACI is throughput-optimal with respect to a scaled capacity region; then validate ACI's effectiveness on multi-UAV networks with an FSO backhaul. Finally, we demonstrate how adapting its core urgency metric provides the flexibility to navigate the throughput-latency trade-off.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15904v1</guid></item><item><title>[cs updates on arXiv.org] Pregroup representable expansions of residuated lattices</title><link>https://arxiv.org/abs/2601.15905</link><description>arXiv:2601.15905v1 Announce Type: new 
Abstract: Group representable relation algebras play an important role in the study of representable relation algebras. The class of distributive involutive FL-algebras (DInFL-algebras) generalises relation algebras, as well as Sugihara monoids and MV-algebras. We construct DInFL-algebras from pregroups and show that they can be represented as algebras of binary relations. Even for finite pregroups we obtain relational representations of DInFL-algebras with non-Boolean lattice reducts. If the pregroup is enriched with a particular unary order-reversing operation, then our construction yields representation results for distributive quasi relation algebras.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15905v1</guid></item><item><title>[cs updates on arXiv.org] Opening the Black Box: Preliminary Insights into Affective Modeling in Multimodal Foundation Models</title><link>https://arxiv.org/abs/2601.15906</link><description>arXiv:2601.15906v1 Announce Type: new 
Abstract: Understanding where and how emotions are represented in large-scale foundation models remains an open problem, particularly in multimodal affective settings. Despite the strong empirical performance of recent affective models, the internal architectural mechanisms that support affective understanding and generation are still poorly understood. In this work, we present a systematic mechanistic study of affective modeling in multimodal foundation models. Across multiple architectures, training strategies, and affective tasks, we analyze how emotion-oriented supervision reshapes internal model parameters. Our results consistently reveal a clear and robust pattern: affective adaptation does not primarily focus on the attention module, but instead localizes to the feed-forward gating projection (\texttt{gate\_proj}). Through controlled module transfer, targeted single-module adaptation, and destructive ablation, we further demonstrate that \texttt{gate\_proj} is sufficient, efficient, and necessary for affective understanding and generation. Notably, by tuning only approximately 24.5\% of the parameters tuned by AffectGPT, our approach achieves 96.6\% of its average performance across eight affective tasks, highlighting substantial parameter efficiency. Together, these findings provide empirical evidence that affective capabilities in foundation models are structurally mediated by feed-forward gating mechanisms and identify \texttt{gate\_proj} as a central architectural locus of affective modeling.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15906v1</guid></item><item><title>[cs updates on arXiv.org] Transfer Learning from ImageNet for MEG-Based Decoding of Imagined Speech</title><link>https://arxiv.org/abs/2601.15909</link><description>arXiv:2601.15909v1 Announce Type: new 
Abstract: Non-invasive decoding of imagined speech remains challenging due to weak, distributed signals and limited labeled data. Our paper introduces an image-based approach that transforms magnetoencephalography (MEG) signals into time-frequency representations compatible with pretrained vision models. MEG data from 21 participants performing imagined speech tasks were projected into three spatial scalogram mixtures via a learnable sensor-space convolution, producing compact image-like inputs for ImageNet-pretrained vision architectures. These models outperformed classical and non-pretrained models, achieving up to 90.4% balanced accuracy for imagery vs. silence, 81.0% vs. silent reading, and 60.6% for vowel decoding. Cross-subject evaluation confirmed that pretrained models capture shared neural representations, and temporal analyses localized discriminative information to imagery-locked intervals. These findings show that pretrained vision models applied to image-based MEG representations can effectively capture the structure of imagined speech in non-invasive neural signals.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15909v1</guid></item><item><title>[cs updates on arXiv.org] A fully diagonalized spectral method on the unit ball</title><link>https://arxiv.org/abs/2601.15911</link><description>arXiv:2601.15911v1 Announce Type: new 
Abstract: Our main objective in this work is to show how Sobolev orthogonal polynomials emerge as a useful tool within the framework of spectral methods for boundary-value problems. The solution of a boundary-value problem for a stationary Schr\"odinger equation on the unit ball can be studied from a variational perspective. In this variational formulation, a Sobolev inner product naturally arises. As test functions, we consider the linear space of the polynomials satisfying the boundary conditions on the sphere, and a basis of mutually orthogonal polynomials with respect to the Sobolev inner product is provided. The basis of the proposed method is given in terms of spherical harmonics and univariate Sobolev orthogonal polynomials. The connection formula between these Sobolev orthogonal polynomials and the classical orthogonal polynomials on the ball is established. Consequently, the Sobolev Fourier coefficients of a function satisfying the boundary value problem are recursively derived. Finally, one numerical experiment is presented.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15911v1</guid></item><item><title>[cs updates on arXiv.org] TeNet: Text-to-Network for Compact Policy Synthesis</title><link>https://arxiv.org/abs/2601.15912</link><description>arXiv:2601.15912v1 Announce Type: new 
Abstract: Robots that follow natural-language instructions often either plan at a high level using hand-designed interfaces or rely on large end-to-end models that are difficult to deploy for real-time control. We propose TeNet (Text-to-Network), a framework for instantiating compact, task-specific robot policies directly from natural language descriptions. TeNet conditions a hypernetwork on text embeddings produced by a pretrained large language model (LLM) to generate a fully executable policy, which then operates solely on low-dimensional state inputs at high control frequencies. By using the language only once at the policy instantiation time, TeNet inherits the general knowledge and paraphrasing robustness of pretrained LLMs while remaining lightweight and efficient at execution time. To improve generalization, we optionally ground language in behavior during training by aligning text embeddings with demonstrated actions, while requiring no demonstrations at inference time. Experiments on MuJoCo and Meta-World benchmarks show that TeNet produces policies that are orders of magnitude smaller than sequence-based baselines, while achieving strong performance in both multi-task and meta-learning settings and supporting high-frequency control. These results show that text-conditioned hypernetworks offer a practical way to build compact, language-driven controllers for ressource-constrained robot control tasks with real-time requirements.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15912v1</guid></item><item><title>[cs updates on arXiv.org] The Latency Wall: Benchmarking Off-the-Shelf Emotion Recognition for Real-Time Virtual Avatars</title><link>https://arxiv.org/abs/2601.15914</link><description>arXiv:2601.15914v1 Announce Type: new 
Abstract: In the realm of Virtual Reality (VR) and Human-Computer Interaction (HCI), real-time emotion recognition shows promise for supporting individuals with Autism Spectrum Disorder (ASD) in improving social skills. This task requires a strict latency-accuracy trade-off, with motion-to-photon (MTP) latency kept below 140 ms to maintain contingency. However, most off-the-shelf Deep Learning models prioritize accuracy over the strict timing constraints of commodity hardware. As a first step toward accessible VR therapy, we benchmark State-of-the-Art (SOTA) models for Zero-Shot Facial Expression Recognition (FER) on virtual characters using the UIBVFED dataset. We evaluate Medium and Nano variants of YOLO (v8, v11, and v12) for face detection, alongside general-purpose Vision Transformers including CLIP, SigLIP, and ViT-FER.Our results on CPU-only inference demonstrate that while face detection on stylized avatars is robust (100% accuracy), a "Latency Wall" exists in the classification stage. The YOLOv11n architecture offers the optimal balance for detection (~54 ms). However, general-purpose Transformers like CLIP and SigLIP fail to achieve viable accuracy (&lt;23%) or speed (&gt;150 ms) for real-time loops. This study highlights the necessity for lightweight, domain-specific architectures to enable accessible, real-time AI in therapeutic settings.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15914v1</guid></item><item><title>[cs updates on arXiv.org] Class Confidence Aware Reweighting for Long Tailed Learning</title><link>https://arxiv.org/abs/2601.15924</link><description>arXiv:2601.15924v1 Announce Type: new 
Abstract: Deep neural network models degrade significantly in the long-tailed data distribution, with the overall training data dominated by a small set of classes in the head, and the tail classes obtaining less training examples. Addressing the imbalance in the classes, attention in the related literature was given mainly to the adjustments carried out in the decision space in terms of either corrections performed at the logit level in order to compensate class-prior bias, with the least attention to the optimization process resulting from the adjustments introduced through the differences in the confidences among the samples. In the current study, we present the design of a class and confidence-aware re-weighting scheme for long-tailed learning. This scheme is purely based upon the loss level and has a complementary nature to the existing methods performing the adjustment of the logits. In the practical implementation stage of the proposed scheme, we use an {\Omega}(p_t, f_c) function. This function enables the modulation of the contribution towards the training task based upon the confidence value of the prediction, as well as the relative frequency of the corresponding class. Our observations in the experiments are corroborated by significant experimental results performed on the CIFAR-100-LT, ImageNet-LT, and iNaturalist2018 datasets under various values of imbalance factors that clearly authenticate the theoretical discussions above.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15924v1</guid></item><item><title>[cs updates on arXiv.org] NeuroMamba: Multi-Perspective Feature Interaction with Visual Mamba for Neuron Segmentation</title><link>https://arxiv.org/abs/2601.15929</link><description>arXiv:2601.15929v1 Announce Type: new 
Abstract: Neuron segmentation is the cornerstone of reconstructing comprehensive neuronal connectomes, which is essential for deciphering the functional organization of the brain. The irregular morphology and densely intertwined structures of neurons make this task particularly challenging. Prevailing CNN-based methods often fail to resolve ambiguous boundaries due to the lack of long-range context, whereas Transformer-based methods suffer from boundary imprecision caused by the loss of voxel-level details during patch partitioning. To address these limitations, we propose NeuroMamba, a multi-perspective framework that exploits the linear complexity of Mamba to enable patch-free global modeling and synergizes this with complementary local feature modeling, thereby efficiently capturing long-range dependencies while meticulously preserving fine-grained voxel details. Specifically, we design a channel-gated Boundary Discriminative Feature Extractor (BDFE) to enhance local morphological cues. Complementing this, we introduce the Spatial Continuous Feature Extractor (SCFE), which integrates a resolution-aware scanning mechanism into the Visual Mamba architecture to adaptively model global dependencies across varying data resolutions. Finally, a cross-modulation mechanism synergistically fuses these multi-perspective features. Our method demonstrates state-of-the-art performance across four public EM datasets, validating its exceptional adaptability to both anisotropic and isotropic resolutions. The source code will be made publicly available.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15929v1</guid></item><item><title>[cs updates on arXiv.org] MMGRid: Navigating Temporal-aware and Cross-domain Generative Recommendation via Model Merging</title><link>https://arxiv.org/abs/2601.15930</link><description>arXiv:2601.15930v1 Announce Type: new 
Abstract: Model merging (MM) offers an efficient mechanism for integrating multiple specialized models without access to original training data or costly retraining. While MM has demonstrated success in domains like computer vision, its role in recommender systems (RSs) remains largely unexplored. Recently, Generative Recommendation (GR) has emerged as a new paradigm in RSs, characterized by rapidly growing model scales and substantial computational costs, making MM particularly appealing for cost-sensitive deployment scenarios. In this work, we present the first systematic study of MM in GR through a contextual lens. We focus on a fundamental yet underexplored challenge in real-world: how to merge generative recommenders specialized to different real-world contexts, arising from temporal evolving user behaviors and heterogeneous application domains. To this end, we propose a unified framework MMGRid, a structured contextual grid of GR checkpoints that organizes models trained under diverse contexts induced by temporal evolution and domain diversity. All checkpoints are derived from a shared base LLM but fine-tuned on context-specific data, forming a realistic and controlled model space for systematically analyzing MM across GR paradigms and merging algorithms. Our investigation reveals several key insights. First, training GR models from LLMs can introduce parameter conflicts during merging due to token distribution shifts and objective disparities; such conflicts can be alleviated by disentangling task-aware and context-specific parameter changes via base model replacement. Second, incremental training across contexts induces recency bias, which can be effectively balanced through weighted contextual merging. Notably, we observe that optimal merging weights correlate with context-dependent interaction characteristics, offering practical guidance for weight selection in real-world deployments.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15930v1</guid></item><item><title>[cs updates on arXiv.org] ICON: Invariant Counterfactual Optimization with Neuro-Symbolic Priors for Text-Based Person Search</title><link>https://arxiv.org/abs/2601.15931</link><description>arXiv:2601.15931v1 Announce Type: new 
Abstract: Text-Based Person Search (TBPS) holds unique value in real-world surveillance bridging visual perception and language understanding, yet current paradigms utilizing pre-training models often fail to transfer effectively to complex open-world scenarios. The reliance on "Passive Observation" leads to multifaceted spurious correlations and spatial semantic misalignment, causing a lack of robustness against distribution shifts. To fundamentally resolve these defects, this paper proposes ICON (Invariant Counterfactual Optimization with Neuro-symbolic priors), a framework integrating causal and topological priors. First, we introduce Rule-Guided Spatial Intervention to strictly penalize sensitivity to bounding box noise, forcibly severing location shortcuts to achieve geometric invariance. Second, Counterfactual Context Disentanglement is implemented via semantic-driven background transplantation, compelling the model to ignore background interference for environmental independence. Then, we employ Saliency-Driven Semantic Regularization with adaptive masking to resolve local saliency bias and guarantee holistic completeness. Finally, Neuro-Symbolic Topological Alignment utilizes neuro-symbolic priors to constrain feature matching, ensuring activated regions are topologically consistent with human structural logic. Experimental results demonstrate that ICON not only maintains leading performance on standard benchmarks but also exhibits exceptional robustness against occlusion, background interference, and localization noise. This approach effectively advances the field by shifting from fitting statistical co-occurrences to learning causal invariance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15931v1</guid></item><item><title>[cs updates on arXiv.org] Layered automata: A canonical model for automata over infinite words</title><link>https://arxiv.org/abs/2601.15940</link><description>arXiv:2601.15940v1 Announce Type: new 
Abstract: We introduce layered automata, a subclass of alternating parity automata that generalises deterministic automata. Assuming a consistency property, these automata are history deterministic and 0-1 probabilistic. We show that every omega-regular language is recognised by a unique minimal consistent layered automaton, and that this canonical form can be computed in polynomial time from every layered or deterministic automaton. We further establish that for layered automata both consistency checking and inclusion testing can be performed in polynomial time. Much like deterministic finite automata, minimal consistent layered automata admit a characterisation based on congruences.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15940v1</guid></item><item><title>[cs updates on arXiv.org] Accurate Calibration and Robust LiDAR-Inertial Odometry for Spinning Actuated LiDAR Systems</title><link>https://arxiv.org/abs/2601.15946</link><description>arXiv:2601.15946v1 Announce Type: new 
Abstract: Accurate calibration and robust localization are fundamental for downstream tasks in spinning actuated LiDAR applications. Existing methods, however, require parameterizing extrinsic parameters based on different mounting configurations, limiting their generalizability. Additionally, spinning actuated LiDAR inevitably scans featureless regions, which complicates the balance between scanning coverage and localization robustness. To address these challenges, this letter presents a targetless LiDAR-motor calibration (LM-Calibr) on the basis of the Denavit-Hartenberg convention and an environmental adaptive LiDAR-inertial odometry (EVA-LIO). LM-Calibr supports calibration of LiDAR-motor systems with various mounting configurations. Extensive experiments demonstrate its accuracy and convergence across different scenarios, mounting angles, and initial values. Additionally, EVA-LIO adaptively selects downsample rates and map resolutions according to spatial scale. This adaptivity enables the actuator to operate at maximum speed, thereby enhancing scanning completeness while ensuring robust localization, even when LiDAR briefly scans featureless areas. The source code and hardware design are available on GitHub: \textcolor{blue}{\href{https://github.com/zijiechenrobotics/lm_calibr}{github.com/zijiechenrobotics/lm\_calibr}}. The video is available at \textcolor{blue}{\href{https://youtu.be/cZyyrkmeoSk}{youtu.be/cZyyrkmeoSk}}</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15946v1</guid></item><item><title>[cs updates on arXiv.org] Natural Language-Driven Global Mapping of Martian Landforms</title><link>https://arxiv.org/abs/2601.15949</link><description>arXiv:2601.15949v1 Announce Type: new 
Abstract: Planetary surfaces are typically analyzed using high-level semantic concepts in natural language, yet vast orbital image archives remain organized at the pixel level. This mismatch limits scalable, open-ended exploration of planetary surfaces. Here we present MarScope, a planetary-scale vision-language framework enabling natural language-driven, label-free mapping of Martian landforms. MarScope aligns planetary images and text in a shared semantic space, trained on over 200,000 curated image-text pairs. This framework transforms global geomorphic mapping on Mars by replacing pre-defined classifications with flexible semantic retrieval, enabling arbitrary user queries across the entire planet in 5 seconds with F1 scores up to 0.978. Applications further show that it extends beyond morphological classification to facilitate process-oriented analysis and similarity-based geomorphological mapping at a planetary scale. MarScope establishes a new paradigm where natural language serves as a direct interface for scientific discovery over massive geospatial datasets.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15949v1</guid></item><item><title>[cs updates on arXiv.org] EVolSplat4D: Efficient Volume-based Gaussian Splatting for 4D Urban Scene Synthesis</title><link>https://arxiv.org/abs/2601.15951</link><description>arXiv:2601.15951v1 Announce Type: new 
Abstract: Novel view synthesis (NVS) of static and dynamic urban scenes is essential for autonomous driving simulation, yet existing methods often struggle to balance reconstruction time with quality. While state-of-the-art neural radiance fields and 3D Gaussian Splatting approaches achieve photorealism, they often rely on time-consuming per-scene optimization. Conversely, emerging feed-forward methods frequently adopt per-pixel Gaussian representations, which lead to 3D inconsistencies when aggregating multi-view predictions in complex, dynamic environments. We propose EvolSplat4D, a feed-forward framework that moves beyond existing per-pixel paradigms by unifying volume-based and pixel-based Gaussian prediction across three specialized branches. For close-range static regions, we predict consistent geometry of 3D Gaussians over multiple frames directly from a 3D feature volume, complemented by a semantically-enhanced image-based rendering module for predicting their appearance. For dynamic actors, we utilize object-centric canonical spaces and a motion-adjusted rendering module to aggregate temporal features, ensuring stable 4D reconstruction despite noisy motion priors. Far-Field scenery is handled by an efficient per-pixel Gaussian branch to ensure full-scene coverage. Experimental results on the KITTI-360, KITTI, Waymo, and PandaSet datasets show that EvolSplat4D reconstructs both static and dynamic environments with superior accuracy and consistency, outperforming both per-scene optimization and state-of-the-art feed-forward baselines.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15951v1</guid></item><item><title>[cs updates on arXiv.org] Decoupling Return-to-Go for Efficient Decision Transformer</title><link>https://arxiv.org/abs/2601.15953</link><description>arXiv:2601.15953v1 Announce Type: new 
Abstract: The Decision Transformer (DT) has established a powerful sequence modeling approach to offline reinforcement learning. It conditions its action predictions on Return-to-Go (RTG), using it both to distinguish trajectory quality during training and to guide action generation at inference. In this work, we identify a critical redundancy in this design: feeding the entire sequence of RTGs into the Transformer is theoretically unnecessary, as only the most recent RTG affects action prediction. We show that this redundancy can impair DT's performance through experiments. To resolve this, we propose the Decoupled DT (DDT). DDT simplifies the architecture by processing only observation and action sequences through the Transformer, using the latest RTG to guide the action prediction. This streamlined approach not only improves performance but also reduces computational cost. Our experiments show that DDT significantly outperforms DT and establishes competitive performance against state-of-the-art DT variants across multiple offline RL tasks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15953v1</guid></item><item><title>[cs updates on arXiv.org] HyperAlign: Hypernetwork for Efficient Test-Time Alignment of Diffusion Models</title><link>https://arxiv.org/abs/2601.15968</link><description>arXiv:2601.15968v1 Announce Type: new 
Abstract: Diffusion models achieve state-of-the-art performance but often fail to generate outputs that align with human preferences and intentions, resulting in images with poor aesthetic quality and semantic inconsistencies. Existing alignment methods present a difficult trade-off: fine-tuning approaches suffer from loss of diversity with reward over-optimization, while test-time scaling methods introduce significant computational overhead and tend to under-optimize. To address these limitations, we propose HyperAlign, a novel framework that trains a hypernetwork for efficient and effective test-time alignment. Instead of modifying latent states, HyperAlign dynamically generates low-rank adaptation weights to modulate the diffusion model's generation operators. This allows the denoising trajectory to be adaptively adjusted based on input latents, timesteps and prompts for reward-conditioned alignment. We introduce multiple variants of HyperAlign that differ in how frequently the hypernetwork is applied, balancing between performance and efficiency. Furthermore, we optimize the hypernetwork using a reward score objective regularized with preference data to reduce reward hacking. We evaluate HyperAlign on multiple extended generative paradigms, including Stable Diffusion and FLUX. It significantly outperforms existing fine-tuning and test-time scaling baselines in enhancing semantic consistency and visual appeal.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15968v1</guid></item><item><title>[cs updates on arXiv.org] Unveiling and Simulating Short-Video Addiction Behaviors via Economic Addiction Theory</title><link>https://arxiv.org/abs/2601.15975</link><description>arXiv:2601.15975v1 Announce Type: new 
Abstract: Short-video applications have attracted substantial user traffic. However, these platforms also foster problematic usage patterns, commonly referred to as short-video addiction, which pose risks to both user health and the sustainable development of platforms. Prior studies on this issue have primarily relied on questionnaires or volunteer-based data collection, which are often limited by small sample sizes and population biases. In contrast, short-video platforms have large-scale behavioral data, offering a valuable foundation for analyzing addictive behaviors. To examine addiction-aware behavior patterns, we combine economic addiction theory with users' implicit behavior captured by recommendation systems. Our analysis shows that short-video addiction follows functional patterns similar to traditional forms of addictive behavior (e.g., substance abuse) and that its intensity is consistent with findings from previous social science studies. To develop a simulator that can learn and model these patterns, we introduce a novel training framework, AddictSim. To consider the personalized addiction patterns, AddictSim uses a mean-to-adapted strategy with group relative policy optimization training. Experiments on two large-scale datasets show that AddictSim consistently outperforms existing training strategies. Our simulation results show that integrating diversity-aware algorithms can mitigate addictive behaviors well.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15975v1</guid></item><item><title>[cs updates on arXiv.org] Predicting Healthcare System Visitation Flow by Integrating Hospital Attributes and Population Socioeconomics with Human Mobility Data</title><link>https://arxiv.org/abs/2601.15977</link><description>arXiv:2601.15977v1 Announce Type: new 
Abstract: Healthcare visitation patterns are influenced by a complex interplay of hospital attributes, population socioeconomics, and spatial factors. However, existing research often adopts a fragmented approach, examining these determinants in isolation. This study addresses this gap by integrating hospital capacities, occupancy rates, reputation, and popularity with population SES and spatial mobility patterns to predict visitation flows and analyze influencing factors. Utilizing four years of SafeGraph mobility data and user experience data from Google Maps Reviews, five flow prediction models, Naive Regression, Gradient Boosting, Multilayer Perceptrons (MLPs), Deep Gravity, and Heterogeneous Graph Neural Networks (HGNN),were trained and applied to simulate visitation flows in Houston, Texas, U.S. The Shapley additive explanation (SHAP) analysis and the Partial Dependence Plot (PDP) method were employed to examine the combined impacts of different factors on visitation patterns. The findings reveal that Deep Gravity outperformed other models. Hospital capacities, ICU occupancy rates, ratings, and popularity significantly influence visitation patterns, with their effects varying across different travel distances. Short-distance visits are primarily driven by convenience, whereas long-distance visits are influenced by hospital ratings. White-majority areas exhibited lower sensitivity to hospital ratings for short-distance visits, while Asian populations and those with higher education levels prioritized hospital rating in their visitation decisions. SES further influence these patterns, as areas with higher proportions of Hispanic, Black, under-18, and over-65 populations tend to have more frequent hospital visits, potentially reflecting greater healthcare needs or limited access to alternative medical services.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15977v1</guid></item><item><title>[cs updates on arXiv.org] Partially Lazy Gradient Descent for Smoothed Online Learning</title><link>https://arxiv.org/abs/2601.15984</link><description>arXiv:2601.15984v1 Announce Type: new 
Abstract: We introduce $k$-lazyGD, an online learning algorithm that bridges the gap between greedy Online Gradient Descent (OGD, for $k=1$) and lazy GD/dual-averaging (for $k=T$), creating a spectrum between reactive and stable updates. We analyze this spectrum in Smoothed Online Convex Optimization (SOCO), where the learner incurs both hitting and movement costs. Our main contribution is establishing that laziness is possible without sacrificing hitting performance: we prove that $k$-lazyGD achieves the optimal dynamic regret $\mathcal{O}(\sqrt{(P_T+1)T})$ for any laziness slack $k$ up to $\Theta(\sqrt{T/P_T})$, where $P_T$ is the comparator path length. This result formally connects the allowable laziness to the comparator's shifts, showing that $k$-lazyGD can retain the inherently small movements of lazy methods without compromising tracking ability. We base our analysis on the Follow the Regularized Leader (FTRL) framework, and derive a matching lower bound. Since the slack depends on $P_T$, an ensemble of learners with various slacks is used, yielding a method that is provably stable when it can be, and agile when it must be.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15984v1</guid></item><item><title>[cs updates on arXiv.org] Efficient Cloud-edge Collaborative Approaches to SPARQL Queries over Large RDF graphs</title><link>https://arxiv.org/abs/2601.15992</link><description>arXiv:2601.15992v1 Announce Type: new 
Abstract: With the increasing use of RDF graphs, storing and querying such data using SPARQL remains a critical problem. Current mainstream solutions rely on cloud-based data management architectures, but often suffer from performance bottle- necks in environments with limited bandwidth or high system load. To address this issue, this paper explores for the first time the integration of edge computing to move graph data storage and processing to edge environments, thereby improving query performance. This approach requires offloading query processing to edge servers, which involves addressing two challenges: data localization and network scheduling. First, the data localization challenge lies in computing the subgraphs maintained on edge servers to quickly identify the servers that can handle specific queries. To address this challenge, we introduce a new concept of pattern-induced subgraphs. Second, the network scheduling challenge involves efficiently assigning queries to edge and cloud servers to optimize overall system performance. We tackle this by constructing a overall system model that jointly captures data distribution, query characteristics, network communication, and computational resources. Accordingly, we further propose a joint formulation of query assignment and computational resource allocation, modeling it as a Mixed Integer Nonlinear Programming (MINLP) problem and solve this problem using a modified branch-and-bound algorithm. Experimental results on real datasets under a real cloud platform demonstrate that our proposed method outperforms the state-of-the-art baseline methods in terms of efficiency. The codes are available on GitHub</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15992v1</guid></item><item><title>[cs updates on arXiv.org] PUMA: Perception-driven Unified Foothold Prior for Mobility Augmented Quadruped Parkour</title><link>https://arxiv.org/abs/2601.15995</link><description>arXiv:2601.15995v1 Announce Type: new 
Abstract: Parkour tasks for quadrupeds have emerged as a promising benchmark for agile locomotion. While human athletes can effectively perceive environmental characteristics to select appropriate footholds for obstacle traversal, endowing legged robots with similar perceptual reasoning remains a significant challenge. Existing methods often rely on hierarchical controllers that follow pre-computed footholds, thereby constraining the robot's real-time adaptability and the exploratory potential of reinforcement learning. To overcome these challenges, we present PUMA, an end-to-end learning framework that integrates visual perception and foothold priors into a single-stage training process. This approach leverages terrain features to estimate egocentric polar foothold priors, composed of relative distance and heading, guiding the robot in active posture adaptation for parkour tasks. Extensive experiments conducted in simulation and real-world environments across various discrete complex terrains, demonstrate PUMA's exceptional agility and robustness in challenging scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15995v1</guid></item><item><title>[cs updates on arXiv.org] PhysicsMind: Sim and Real Mechanics Benchmarking for Physical Reasoning and Prediction in Foundational VLMs and World Models</title><link>https://arxiv.org/abs/2601.16007</link><description>arXiv:2601.16007v1 Announce Type: new 
Abstract: Modern foundational Multimodal Large Language Models (MLLMs) and video world models have advanced significantly in mathematical, common-sense, and visual reasoning, but their grasp of the underlying physics remains underexplored. Existing benchmarks attempting to measure this matter rely on synthetic, Visual Question Answer templates or focus on perceptual video quality that is tangential to measuring how well the video abides by physical laws. To address this fragmentation, we introduce PhysicsMind, a unified benchmark with both real and simulation environments that evaluates law-consistent reasoning and generation over three canonical principles: Center of Mass, Lever Equilibrium, and Newton's First Law. PhysicsMind comprises two main tasks: i) VQA tasks, testing whether models can reason and determine physical quantities and values from images or short videos, and ii) Video Generation(VG) tasks, evaluating if predicted motion trajectories obey the same center-of-mass, torque, and inertial constraints as the ground truth. A broad range of recent models and video generation models is evaluated on PhysicsMind and found to rely on appearance heuristics while often violating basic mechanics. These gaps indicate that current scaling and training are still insufficient for robust physical understanding, underscoring PhysicsMind as a focused testbed for physics-aware multimodal models. Our data will be released upon acceptance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16007v1</guid></item><item><title>[cs updates on arXiv.org] Prioritizing Configuration Relevance via Compiler-Based Refined Feature Ranking</title><link>https://arxiv.org/abs/2601.16008</link><description>arXiv:2601.16008v1 Announce Type: new 
Abstract: Modern programming languages, most notably Rust, offer advanced linguistic constructs for building highly configurable software systems as aggregation of features -- identified by a configuration. However, they pose substantial challenges for program analysis, optimization, and testing, as the combinatorial explosion of configurations often makes exhaustive exploration infeasible. In this manuscript, we present the first compiler-based method for prioritizing configurations. Our approach consists of four main steps: 1. extracting a tailored intermediate representation from the Rust compiler, 2. constructing two complementary graph-based data structures, 3. using centrality measures to rank features, and 4. refining the ranking by considering the extent of code they impact. A fixed number of most relevant configurations are generated based on the achieved feature ranking. The validity of the generated configurations is guaranteed by using a SAT solver that takes a representation of this graph in conjunctive normal form. We formalized this approach and implemented it in a prototype, RustyEx, by instrumenting the Rust compiler. An empirical evaluation on higher-ranked open source Rust projects shows that RustyEx efficiently generates user-specified sets of configurations within bounded resources, while ensuring soundness by construction. The results demonstrate that centrality-guided configuration prioritization enables effective and practical exploration of large configuration spaces, paving the way for future research in configuration-aware analysis and optimization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16008v1</guid></item><item><title>[cs updates on arXiv.org] The Role of Cognitive Abilities in Requirements Inspection: Comparing UML and Textual Representations</title><link>https://arxiv.org/abs/2601.16009</link><description>arXiv:2601.16009v1 Announce Type: new 
Abstract: The representation of requirements plays a critical role in the accuracy of requirements inspection. While visual representations, such as UML diagrams, are widely used alongside text-based requirements, their effectiveness in supporting inspection is still debated. Cognitive abilities, such as working memory and mental rotation skills, may also influence inspection accuracy. This study aims to evaluate whether the use of UML sequence diagrams alongside text-based requirements improves the accuracy of requirements inspection compared to text-based requirements alone and to explore whether cognitive abilities are associated with differences in performance across the two treatments (text vs text with UML support). We conducted a crossover experiment with 38 participants to assess the accuracy of requirements inspection under the two treatments in terms of issues found and justifications provided. Linear mixed-effects and generalized linear models were used to analyse the effects of treatment, period, sequence, and cognitive abilities. The results indicate a significant three-way interaction between representation type, working memory capacity, and mental rotation ability. This finding suggests that the effectiveness of UML support is not uniform across individuals: participants with high scores in both cognitive abilities experienced reduced performance when using UML for violation detection. Conversely, the same cognitive profile was associated with improved justification accuracy under UML-aided inspection, indicating that higher cognitive abilities may support deeper reasoning processes when dealing with multi-modal information, i.e., diagrams and text.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16009v1</guid></item><item><title>[cs updates on arXiv.org] Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain</title><link>https://arxiv.org/abs/2601.16018</link><description>arXiv:2601.16018v1 Announce Type: new 
Abstract: This paper presents Mecellem models, a framework for developing specialized language models for the Turkish legal domain through domain adaptation strategies. We make two contributions: (1)Encoder Model Pre-trained from Scratch: ModernBERT-based bidirectional encoders pre-trained on a Turkish-dominant corpus of 112.7 billion tokens. We implement a checkpoint selection strategy that evaluates downstream retrieval performance throughout training, revealing that optimal checkpoints achieve best retrieval scores before pre-training loss reaches its minimum. Our encoder models achieve top-3 rankings on the Turkish retrieval leaderboard, with smaller models (155M parameters) achieving comparable performance to larger reference models (307M-567M parameters). Our approach achieves 92.36% production efficiency compared to state-of-the-art models (embeddinggemma-300m: 100.00%, BAAI/bge-m3: 99.54%, newmindai/bge-m3-stsb: 94.38%), ranking fourth overall despite requiring less computational resources. SOTA models rely on multi-stage, computationally intensive training pipelines, making our single-stage pre-training followed by efficient post-training approach a cost-effective alternative; (2)Decoder Model with Continual Pre-training (CPT): Qwen3-1.7B and Qwen3-4B models adapted to Turkish legal domain through controlled curriculum learning. Four-phase CPT with optimal sample ratios enables gradual transition from general language knowledge to specialized legal terminology and long-context reasoning. This approach achieves 36.2% perplexity reduction on Turkish legal text, demonstrating domain adaptation gains.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16018v1</guid></item><item><title>[cs updates on arXiv.org] Keyframe-Based Feed-Forward Visual Odometry</title><link>https://arxiv.org/abs/2601.16020</link><description>arXiv:2601.16020v1 Announce Type: new 
Abstract: The emergence of visual foundation models has revolutionized visual odometry~(VO) and SLAM, enabling pose estimation and dense reconstruction within a single feed-forward network. However, unlike traditional pipelines that leverage keyframe methods to enhance efficiency and accuracy, current foundation model based methods, such as VGGT-Long, typically process raw image sequences indiscriminately. This leads to computational redundancy and degraded performance caused by low inter-frame parallax, which provides limited contextual stereo information. Integrating traditional geometric heuristics into these methods is non-trivial, as their performance depends on high-dimensional latent representations rather than explicit geometric metrics. To bridge this gap, we propose a novel keyframe-based feed-forward VO. Instead of relying on hand-crafted rules, our approach employs reinforcement learning to derive an adaptive keyframe policy in a data-driven manner, aligning selection with the intrinsic characteristics of the underlying foundation model. We train our agent on TartanAir dataset and conduct extensive evaluations across several real-world datasets. Experimental results demonstrate that the proposed method achieves consistent and substantial improvements over state-of-the-art feed-forward VO methods.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16020v1</guid></item><item><title>[cs updates on arXiv.org] PAINT: Pathology-Aware Integrated Next-Scale Transformation for Virtual Immunohistochemistry</title><link>https://arxiv.org/abs/2601.16024</link><description>arXiv:2601.16024v1 Announce Type: new 
Abstract: Virtual immunohistochemistry (IHC) aims to computationally synthesize molecular staining patterns from routine Hematoxylin and Eosin (H\&amp;amp;E) images, offering a cost-effective and tissue-efficient alternative to traditional physical staining. However, this task is particularly challenging: H\&amp;amp;E morphology provides ambiguous cues about protein expression, and similar tissue structures may correspond to distinct molecular states. Most existing methods focus on direct appearance synthesis to implicitly achieve cross-modal generation, often resulting in semantic inconsistencies due to insufficient structural priors. In this paper, we propose Pathology-Aware Integrated Next-Scale Transformation (PAINT), a visual autoregressive framework that reformulates the synthesis process as a structure-first conditional generation task. Unlike direct image translation, PAINT enforces a causal order by resolving molecular details conditioned on a global structural layout. Central to this approach is the introduction of a Spatial Structural Start Map (3S-Map), which grounds the autoregressive initialization in observed morphology, ensuring deterministic, spatially aligned synthesis. Experiments on the IHC4BC and MIST datasets demonstrate that PAINT outperforms state-of-the-art methods in structural fidelity and clinical downstream tasks, validating the potential of structure-guided autoregressive modeling.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16024v1</guid></item><item><title>[cs updates on arXiv.org] EAIFD: A Fast and Scalable Algorithm for Incremental Functional Dependency Discovery</title><link>https://arxiv.org/abs/2601.16025</link><description>arXiv:2601.16025v1 Announce Type: new 
Abstract: Functional dependencies (FDs) are fundamental integrity constraints in relational databases, but discovering them under incremental updates remains challenging. While static algorithms are inefficient due to full re-execution, incremental algorithms suffer from severe performance and memory bottlenecks. To address these challenges, this paper proposes EAIFD, a novel algorithm for incremental FD discovery. EAIFD maintains the partial hypergraph of difference sets and reframes the incremental FD discovery problem into minimal hitting set enumeration on hypergraph, avoiding full re-runs. EAIFD introduces two key innovations. First, a multi-attribute hash table ($MHT$) is devised for high-frequency key-value mappings of valid FDs, whose memory consumption is proven to be independent of the dataset size. Second, two-step validation strategy is developed to efficiently validate the enumerated candidates, which leverages $MHT$ to effectively reduce the validation space and then selectively loads data blocks for batch validation of remaining candidates, effectively avoiding repeated I/O operations. Experimental results on real-world datasets demonstrate the significant advantages of EAIFD. Compared to existing algorithms, EAIFD achieves up to an order-of-magnitude speedup in runtime while reducing memory usage by over two orders-of-magnitude, establishing it as a highly efficient and scalable solution for incremental FD discovery.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16025v1</guid></item><item><title>[cs updates on arXiv.org] Deja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment</title><link>https://arxiv.org/abs/2601.16027</link><description>arXiv:2601.16027v1 Announce Type: new 
Abstract: The rise of live streaming has transformed online interaction, enabling massive real-time engagement but also exposing platforms to complex risks such as scams and coordinated malicious behaviors. Detecting these risks is challenging because harmful actions often accumulate gradually and recur across seemingly unrelated streams. To address this, we propose CS-VAR (Cross-Session Evidence-Aware Retrieval-Augmented Detector) for live streaming risk assessment. In CS-VAR, a lightweight, domain-specific model performs fast session-level risk inference, guided during training by a Large Language Model (LLM) that reasons over retrieved cross-session behavioral evidence and transfers its local-to-global insights to the small model. This design enables the small model to recognize recurring patterns across streams, perform structured risk assessment, and maintain efficiency for real-time deployment. Extensive offline experiments on large-scale industrial datasets, combined with online validation, demonstrate the state-of-the-art performance of CS-VAR. Furthermore, CS-VAR provides interpretable, localized signals that effectively empower real-world moderation for live streaming.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16027v1</guid></item><item><title>[cs updates on arXiv.org] Data-Driven Conditional Flexibility Index</title><link>https://arxiv.org/abs/2601.16028</link><description>arXiv:2601.16028v1 Announce Type: new 
Abstract: With the increasing flexibilization of processes, determining robust scheduling decisions has become an important goal. Traditionally, the flexibility index has been used to identify safe operating schedules by approximating the admissible uncertainty region using simple admissible uncertainty sets, such as hypercubes. Presently, available contextual information, such as forecasts, has not been considered to define the admissible uncertainty set when determining the flexibility index. We propose the conditional flexibility index (CFI), which extends the traditional flexibility index in two ways: by learning the parametrized admissible uncertainty set from historical data and by using contextual information to make the admissible uncertainty set conditional. This is achieved using a normalizing flow that learns a bijective mapping from a Gaussian base distribution to the data distribution. The admissible latent uncertainty set is constructed as a hypersphere in the latent space and mapped to the data space. By incorporating contextual information, the CFI provides a more informative estimate of flexibility by defining admissible uncertainty sets in regions that are more likely to be relevant under given conditions. Using an illustrative example, we show that no general statement can be made about data-driven admissible uncertainty sets outperforming simple sets, or conditional sets outperforming unconditional ones. However, both data-driven and conditional admissible uncertainty sets ensure that only regions of the uncertain parameter space containing realizations are considered. We apply the CFI to a security-constrained unit commitment example and demonstrate that the CFI can improve scheduling quality by incorporating temporal information.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16028v1</guid></item><item><title>[cs updates on arXiv.org] Stacked Intelligent Metasurface-Aided Wave-Domain Signal Processing: From Communications to Sensing and Computing</title><link>https://arxiv.org/abs/2601.16030</link><description>arXiv:2601.16030v1 Announce Type: new 
Abstract: Neural networks possess incredible capabilities for extracting abstract features from data. Electromagnetic computing harnesses wave propagation to execute computational operations. Metasurfaces, composed of subwavelength meta-atoms, are capable of engineering electromagnetic waves in unprecedented ways. What happens when combining these three cutting-edge technologies? This question has sparked a surge of interest in designing physical neural networks using stacked intelligent metasurface (SIM) technology, with the aim of implementing various computational tasks by directly processing electromagnetic waves. SIMs open up an exciting avenue toward high-speed, massively parallel, and low-power signal processing in the electromagnetic domain. This article provides a comprehensive overview of SIM technology, commencing with its evolutionary development. We subsequently examine its theoretical foundations and existing SIM prototypes in depth. Furthermore, the optimization/training strategies conceived to configure SIMs for achieving the desired functionalities are discussed from two different perspectives. Additionally, we explore the diverse applications of SIM technology across the communication, sensing, and computing domains, presenting experimental evidence that highlights its distinctive advantages in supporting multiple functions within a single device. Finally, we identify critical technical challenges that must be addressed to deploy SIMs in next-generation wireless networks and shed light on promising research directions to unlock their full potential.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16030v1</guid></item><item><title>[cs updates on arXiv.org] Sawtooth Wavefront Reordering: Enhanced CuTile FlashAttention on NVIDIA GB10</title><link>https://arxiv.org/abs/2601.16032</link><description>arXiv:2601.16032v1 Announce Type: new 
Abstract: High-performance attention kernels are essential for Large Language Models. This paper presents analysis of CuTile-based Flash Attention memory behavior and a technique to improve its cache performance. In particular, our analysis on the NVIDIA GB10 (Grace Blackwell) identifies the main cause of L2 cache miss. Leveraging this insight, we introduce a new programming technique called Sawtooth Wavefront Reordering that reduces L2 misses. We validate it in both CUDA and CuTile, observing 50\% or greater reduction in L2 misses and up to 60\% increase in throughput on GB10.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16032v1</guid></item><item><title>[cs updates on arXiv.org] Universal Refusal Circuits Across LLMs: Cross-Model Transfer via Trajectory Replay and Concept-Basis Reconstruction</title><link>https://arxiv.org/abs/2601.16034</link><description>arXiv:2601.16034v1 Announce Type: new 
Abstract: Refusal behavior in aligned LLMs is often viewed as model-specific, yet we hypothesize it stems from a universal, low-dimensional semantic circuit shared across models. To test this, we introduce Trajectory Replay via Concept-Basis Reconstruction, a framework that transfers refusal interventions from donor to target models, spanning diverse architectures (e.g., Dense to MoE) and training regimes, without using target-side refusal supervision. By aligning layers via concept fingerprints and reconstructing refusal directions using a shared ``recipe'' of concept atoms, we map the donor's ablation trajectory into the target's semantic space. To preserve capabilities, we introduce a weight-SVD stability guard that projects interventions away from high-variance weight subspaces to prevent collateral damage. Our evaluation across 8 model pairs (including GPT-OSS-20B and GLM-4) confirms that these transferred recipes consistently attenuate refusal while maintaining performance, providing strong evidence for the semantic universality of safety alignment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16034v1</guid></item><item><title>[cs updates on arXiv.org] Collision-Free Humanoid Traversal in Cluttered Indoor Scenes</title><link>https://arxiv.org/abs/2601.16035</link><description>arXiv:2601.16035v1 Announce Type: new 
Abstract: We study the problem of collision-free humanoid traversal in cluttered indoor scenes, such as hurdling over objects scattered on the floor, crouching under low-hanging obstacles, or squeezing through narrow passages. To achieve this goal, the humanoid needs to map its perception of surrounding obstacles with diverse spatial layouts and geometries to the corresponding traversal skills. However, the lack of an effective representation that captures humanoid-obstacle relationships during collision avoidance makes directly learning such mappings difficult. We therefore propose Humanoid Potential Field (HumanoidPF), which encodes these relationships as collision-free motion directions, significantly facilitating RL-based traversal skill learning. We also find that HumanoidPF exhibits a surprisingly negligible sim-to-real gap as a perceptual representation. To further enable generalizable traversal skills through diverse and challenging cluttered indoor scenes, we further propose a hybrid scene generation method, incorporating crops of realistic 3D indoor scenes and procedurally synthesized obstacles. We successfully transfer our policy to the real world and develop a teleoperation system where users could command the humanoid to traverse in cluttered indoor scenes with just a single click. Extensive experiments are conducted in both simulation and the real world to validate the effectiveness of our method. Demos and code can be found in our website: https://axian12138.github.io/CAT/.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16035v1</guid></item><item><title>[cs updates on arXiv.org] Tri-Hybrid Beamforming Design for integrated Sensing and Communications</title><link>https://arxiv.org/abs/2601.16036</link><description>arXiv:2601.16036v1 Announce Type: new 
Abstract: Tri-hybrid beamforming architectures have been proposed to enable energy-efficient communications systems in extra-largescale antenna arrays using low-cost programmable metasurface antennas. We study the tri-hybrid beamforming design for integrated sensing and communications (ISAC) to improve both communications and sensing performances. Specifically, we formulate a multi-objective optimization problem that balances communications signal-to-noise ratio (SNR) and the sensing power at a target direction, subject to constraints on the total power consumption and physical limitations inherent to the trihybrid beamforming architecture. We develop an efficient iterative algorithm in which the variables are updated in a closed form at each iteration, leading to a low-complexity and fast-execution design. Numerical results show that the tri-hybrid architecture improves spatial gain and energy efficiency, though with reduced beam alignment capability compared to conventional hybrid beamforming architectures.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16036v1</guid></item><item><title>[cs updates on arXiv.org] Grounding Large Language Models in Reaction Knowledge Graphs for Synthesis Retrieval</title><link>https://arxiv.org/abs/2601.16038</link><description>arXiv:2601.16038v1 Announce Type: new 
Abstract: Large Language Models (LLMs) can aid synthesis planning in chemistry, but standard prompting methods often yield hallucinated or outdated suggestions. We study LLM interactions with a reaction knowledge graph by casting reaction path retrieval as a Text2Cypher (natural language to graph query) generation problem, and define single- and multi-step retrieval tasks. We compare zero-shot prompting to one-shot variants using static, random, and embedding-based exemplar selection, and assess a checklist-driven validator/corrector loop. To evaluate our framework, we consider query validity and retrieval accuracy. We find that one-shot prompting with aligned exemplars consistently performs best. Our checklist-style self-correction loop mainly improves executability in zero-shot settings and offers limited additional retrieval gains once a good exemplar is present. We provide a reproducible Text2Cypher evaluation setup to facilitate further work on KG-grounded LLMs for synthesis planning. Code is available at https://github.com/Intelligent-molecular-systems/KG-LLM-Synthesis-Retrieval.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16038v1</guid></item><item><title>[cs updates on arXiv.org] Characterizations of monadically dependent tree-ordered weakly sparse structures</title><link>https://arxiv.org/abs/2601.16039</link><description>arXiv:2601.16039v1 Announce Type: new 
Abstract: A class of structures is monadically dependent if one cannot interpret all graphs in colored expansions from the class using a fixed first-order formula. A tree-ordered $\sigma$-structure is the expansion of a $\sigma$-structure with a tree-order. A tree-ordered $\sigma$-structure is weakly sparse if the Gaifman graph of its $\sigma$-reduct excludes some biclique (of a given fixed size) as a subgraph. Tree-ordered weakly sparse graphs are commonly used as tree-models (for example for classes with bounded shrubdepth, structurally bounded expansion, bounded cliquewidth, or bounded twin-width), motivating their study on their own. In this paper, we consider several constructions on tree-ordered structures, such as tree-ordered variants of the Gaifman graph and of the incidence graph, induced and non-induced tree-ordered minors, and generalized fundamental graphs.
  We provide characterizations of monadically dependent classes of tree-ordered weakly sparse $\sigma$-structures based on each of these constructions, some of them establishing unexpected bridges with sparsity theory. As an application, we prove that a class of tree-ordered weakly sparse structures is monadically dependent if and only if its sparsification is nowhere-dense. Moreover, the sparsification transduction translates boundedness of clique-width and linear clique-width into boundedness of tree-width and path-width. We also prove that first-order model checking is not fixed parameter tractable on independent hereditary classes of tree-ordered weakly sparse graphs (assuming $AW[*]\neq FPT$) and give what we believe is the first model-theoretical characterization of classes of graphs excluding a minor, thus opening a new perspective of structural graph theory.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16039v1</guid></item><item><title>[cs updates on arXiv.org] Can Platform Design Encourage Curiosity? Evidence from an Independent Social Media Experiment</title><link>https://arxiv.org/abs/2601.16040</link><description>arXiv:2601.16040v1 Announce Type: new 
Abstract: Social media platforms are often criticized for fostering antisocial behavior rather than prosocial behavior. Yet, testing interventions to encourage prosocial dispositions, such as open-mindedness, has been hindered by researchers' limited ability to manipulate platform features and isolate causal effects in commercial environments. We address this challenge through a randomized controlled trial with 2,282 U.S. adults conducted on a new research platform we developed that uses AI bots to replicate live social media dynamics while enabling controlled experimentation. Participants engaged in 15-minute discussions about energy and climate topics, with treatment groups exposed to curiosity priming either through modified on-platform social norms, interface affordances, or both. Results demonstrate that curiosity priming significantly increased question-asking behavior and textual measures of curiosity in user posts, while also reducing toxicity. Although interventions decreased generic engagement behaviors like liking and commenting, they had no significant negative impact on reported app enjoyment or time spent writing posts and replies. Leveraging experimental control over platform features, our findings suggest that platform designs prioritizing curiosity can promote prosocial behaviors among users without compromising user experience.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16040v1</guid></item><item><title>[cs updates on arXiv.org] AgriPINN: A Process-Informed Neural Network for Interpretable and Scalable Crop Biomass Prediction Under Water Stress</title><link>https://arxiv.org/abs/2601.16045</link><description>arXiv:2601.16045v1 Announce Type: new 
Abstract: Accurate prediction of crop above-ground biomass (AGB) under water stress is critical for monitoring crop productivity, guiding irrigation, and supporting climate-resilient agriculture. Data-driven models scale well but often lack interpretability and degrade under distribution shift, whereas process-based crop models (e.g. DSSAT, APSIM, LINTUL5) require extensive calibration and are difficult to deploy over large spatial domains. To address these limitations, we propose AgriPINN, a process-informed neural network that integrates a biophysical crop-growth differential equation as a differentiable constraint within a deep learning backbone. This design encourages physiologically consistent biomass dynamics under water-stress conditions while preserving model scalability for spatially distributed AGB prediction. AgriPINN recovers latent physiological variables, including leaf area index (LAI), absorbed photosynthetically active radiation (PAR), radiation use efficiency (RUE), and water-stress factors, without requiring direct supervision. We pretrain AgriPINN on 60 years of historical data across 397 regions in Germany and fine-tune it on three years of field experiments under controlled water treatments. Results show that AgriPINN consistently outperforms state-of-the-art deep-learning baselines (ConvLSTM-ViT, SLTF, CNN-Transformer) and the process-based LINTUL5 model in terms of accuracy (RMSE reductions up to $43\%$) and computational efficiency. By combining the scalability of deep learning with the biophysical rigor of process-based modeling, AgriPINN provides a robust and interpretable framework for spatio-temporal AGB prediction, offering practical value for planning of irrigation infrastructure, yield forecasting, and climate-adaptation planning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16045v1</guid></item><item><title>[cs updates on arXiv.org] DextER: Language-driven Dexterous Grasp Generation with Embodied Reasoning</title><link>https://arxiv.org/abs/2601.16046</link><description>arXiv:2601.16046v1 Announce Type: new 
Abstract: Language-driven dexterous grasp generation requires the models to understand task semantics, 3D geometry, and complex hand-object interactions. While vision-language models have been applied to this problem, existing approaches directly map observations to grasp parameters without intermediate reasoning about physical interactions. We present DextER, Dexterous Grasp Generation with Embodied Reasoning, which introduces contact-based embodied reasoning for multi-finger manipulation. Our key insight is that predicting which hand links contact where on the object surface provides an embodiment-aware intermediate representation bridging task semantics with physical constraints. DextER autoregressively generates embodied contact tokens specifying which finger links contact where on the object surface, followed by grasp tokens encoding the hand configuration. On DexGYS, DextER achieves 67.14% success rate, outperforming state-of-the-art by 3.83%p with 96.4% improvement in intention alignment. We also demonstrate steerable generation through partial contact specification, providing fine-grained control over grasp synthesis.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16046v1</guid></item><item><title>[cs updates on arXiv.org] From Harm to Healing: Understanding Individual Resilience after Cybercrimes</title><link>https://arxiv.org/abs/2601.16050</link><description>arXiv:2601.16050v1 Announce Type: new 
Abstract: How do individuals recover from cybercrimes? Victims experience various types of harm after cybercrimes, including monetary loss, data breaches, negative emotions, and even psychological trauma. The aspects that support their recovery process and contribute to individual cyber resilience remain underinvestigated. To address this gap, we interviewed 18 cybercrime victims from Western Europe using a trauma-informed approach. We identified four common stages following victimization: recognition, coping, processing, and recovery. Participants adopted various strategies to mitigate the impact of cybercrime and used different indicators to describe recovery. While they mostly relied on social support and self-regulation for emotional coping, service providers largely determined whether victims were able to recover their money. Internal factors, external support, and context sensitivity collectively contribute to individuals' cyber resilience. We recommend trauma-informed support for cybercrime victims. Extending our conceptualization of individual cyber resilience, we propose collaborative and context-sensitive strategies to address the harmful impacts of cybercrime.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16050v1</guid></item><item><title>[cs updates on arXiv.org] Designing faster mixed integer linear programming algorithm via learning the optimal path</title><link>https://arxiv.org/abs/2601.16056</link><description>arXiv:2601.16056v1 Announce Type: new 
Abstract: Designing faster algorithms for solving Mixed-Integer Linear Programming (MILP) problems is highly desired across numerous practical domains, as a vast array of complex real-world challenges can be effectively modeled as MILP formulations. Solving these problems typically employs the branch-and-bound algorithm, the core of which can be conceived as searching for a path of nodes (or sub-problems) that contains the optimal solution to the original MILP problem. Traditional approaches to finding this path rely heavily on hand-crafted, intuition-based heuristic strategies, which often suffer from unstable and unpredictable performance across different MILP problem instances. To address this limitation, we introduce DeepBound, a deep learning-based node selection algorithm that automates the learning of such human intuition from data. The core of DeepBound lies in learning to prioritize nodes containing the optimal solution, thereby improving solving efficiency. DeepBound introduces a multi-level feature fusion network to capture the node representations. To tackle the inherent node imbalance in branch-and-bound trees, DeepBound employs a pairwise training paradigm that enhances the model's ability to discriminate between nodes. Extensive experiments on three NP-hard MILP benchmarks demonstrate that DeepBound achieves superior solving efficiency over conventional heuristic rules and existing learning-based approaches, obtaining optimal feasible solutions with significantly reduced computation time. Moreover, DeepBound demonstrates strong generalization capability on large and complex instances. The analysis of its learned features reveals that the method can automatically discover more flexible and robust feature selection, which may effectively improve and potentially replace human-designed heuristic rules.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16056v1</guid></item><item><title>[cs updates on arXiv.org] ProGiDiff: Prompt-Guided Diffusion-Based Medical Image Segmentation</title><link>https://arxiv.org/abs/2601.16060</link><description>arXiv:2601.16060v1 Announce Type: new 
Abstract: Widely adopted medical image segmentation methods, although efficient, are primarily deterministic and remain poorly amenable to natural language prompts. Thus, they lack the capability to estimate multiple proposals, human interaction, and cross-modality adaptation. Recently, text-to-image diffusion models have shown potential to bridge the gap. However, training them from scratch requires a large dataset-a limitation for medical image segmentation. Furthermore, they are often limited to binary segmentation and cannot be conditioned on a natural language prompt. To this end, we propose a novel framework called ProGiDiff that leverages existing image generation models for medical image segmentation purposes. Specifically, we propose a ControlNet-style conditioning mechanism with a custom encoder, suitable for image conditioning, to steer a pre-trained diffusion model to output segmentation masks. It naturally extends to a multi-class setting simply by prompting the target organ. Our experiment on organ segmentation from CT images demonstrates strong performance compared to previous methods and could greatly benefit from an expert-in-the-loop setting to leverage multiple proposals. Importantly, we demonstrate that the learned conditioning mechanism can be easily transferred through low-rank, few-shot adaptation to segment MR images.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16060v1</guid></item><item><title>[cs updates on arXiv.org] Dynamic Tactile Sensing System and Soft Actor Critic Reinforcement Learning for Inclusion Characterization</title><link>https://arxiv.org/abs/2601.16061</link><description>arXiv:2601.16061v1 Announce Type: new 
Abstract: This paper presents the Dynamic Tactile Sensing System that utilizes robotic tactile sensing in conjunction with reinforcement learning to locate and characterize embedded inclusions. A dual arm robot is integrated with an optical Tactile Imaging Sensor that utilizes the Soft Actor Critic Algorithm to acquire tactile data based on a pixel intensity reward. A Dynamic Interrogation procedure for tactile exploration is developed that enables the robot to first localize inclusion and refine their positions for precise imaging. Experimental validation conducted on Polydimethylsiloxane phantoms demonstrates that the robot using the Tactile Soft Actor Critic Model was able to achieve size estimation errors of 2.61% and 5.29% for soft and hard inclusions compared to 7.84% and 6.87% for expert human operators. Results also show that Dynamic Tactile Sensing System was able to locate embedded inclusions and autonomously determine their mechanical properties, useful in applications such as breast tumor characterization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16061v1</guid></item><item><title>[cs updates on arXiv.org] Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Theoretical Analysis</title><link>https://arxiv.org/abs/2601.16062</link><description>arXiv:2601.16062v1 Announce Type: new 
Abstract: One of core advantages of the SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. Current research on Lie group based extended Kalman filters has demonstrated that error propagation autonomy holds in low-precision applications, such as in micro electromechanical system (MEMS) based integrated navigation without considering earth rotation and inertial device biases. However, in high-precision navigation state estimation, maintaining autonomy is extremely difficult when considering with earth rotation and inertial device biases. This paper presents the theoretical analysis on the autonomy of SE2(3) group based high-precision navigation models under inertial, earth and world frame respectively. Through theoretical analysis, we find that the limitation of the traditional, trivial SE2(3) group navigation modeling method is that the presence of Coriolis force terms introduced by velocity in non-inertial frame. Therefore, a construction method for SE2(3) group navigation models is proposed, which brings the navigation models closer to full autonomy.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16062v1</guid></item><item><title>[cs updates on arXiv.org] DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models</title><link>https://arxiv.org/abs/2601.16065</link><description>arXiv:2601.16065v1 Announce Type: new 
Abstract: Vision-Language Action (VLA) models have shown remarkable progress in robotic manipulation by leveraging the powerful perception abilities of Vision-Language Models (VLMs) to understand environments and directly output actions. However, by default, VLA models may overly attend to image tokens in the task-irrelevant region, which we describe as 'distracting tokens'. This behavior can disturb the model from the generation of the desired action tokens in each step, affecting the success rate of tasks. In this paper, we introduce a simple yet effective plug-and-play Distracting Token Pruning (DTP) framework, which dynamically detects and prunes these distracting image tokens. By correcting the model's visual attention patterns, we aim to improve the task success rate, as well as exploring the performance upper boundaries of the model without altering its original architecture or adding additional inputs. Experiments on the SIMPLER Benchmark (Li et al., 2024) show that our method consistently achieving relative improvements in task success rates across different types of novel VLA models, demonstrating generalizability to transformer-based VLAs. Further analysis reveals a negative correlation between the task success rate and the amount of attentions in the task-irrelevant region for all models tested, highlighting a common phenomenon of VLA models that could guide future research. We also publish our code at: https://anonymous.4open.science/r/CBD3.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16065v1</guid></item><item><title>[cs updates on arXiv.org] CLASP: An online learning algorithm for Convex Losses And Squared Penalties</title><link>https://arxiv.org/abs/2601.16072</link><description>arXiv:2601.16072v1 Announce Type: new 
Abstract: We study Constrained Online Convex Optimization (COCO), where a learner chooses actions iteratively, observes both unanticipated convex loss and convex constraint, and accumulates loss while incurring penalties for constraint violations. We introduce CLASP (Convex Losses And Squared Penalties), an algorithm that minimizes cumulative loss together with squared constraint violations. Our analysis departs from prior work by fully leveraging the firm non-expansiveness of convex projectors, a proof strategy not previously applied in this setting. For convex losses, CLASP achieves regret $O\left(T^{\max\{\beta,1-\beta\}}\right)$ and cumulative squared penalty $O\left(T^{1-\beta}\right)$ for any $\beta \in (0,1)$. Most importantly, for strongly convex problems, CLASP provides the first logarithmic guarantees on both regret and cumulative squared penalty. In the strongly convex case, the regret is upper bounded by $O( \log T )$ and the cumulative squared penalty is also upper bounded by $O( \log T )$.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16072v1</guid></item><item><title>[cs updates on arXiv.org] DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models</title><link>https://arxiv.org/abs/2601.16073</link><description>arXiv:2601.16073v1 Announce Type: new 
Abstract: Foundation Models (FMs) have demonstrated strong generalization across diverse vision tasks. However, their deployment in federated settings is hindered by high computational demands, substantial communication overhead, and significant inference costs. We propose DSFedMed, a dual-scale federated framework that enables mutual knowledge distillation between a centralized foundation model and lightweight client models for medical image segmentation. To support knowledge distillation, a set of high-quality medical images is generated to replace real public datasets, and a learnability-guided sample selection strategy is proposed to enhance efficiency and effectiveness in dual-scale distillation. This mutual distillation enables the foundation model to transfer general knowledge to lightweight clients, while also incorporating client-specific insights to refine the foundation model. Evaluations on five medical imaging segmentation datasets show that DSFedMed achieves an average 2 percent improvement in Dice score while reducing communication costs and inference time by nearly 90 percent compared to existing federated foundation model baselines. These results demonstrate significant efficiency gains and scalability for resource-limited federated deployments.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16073v1</guid></item><item><title>[cs updates on arXiv.org] Explainable AI to Improve Machine Learning Reliability for Industrial Cyber-Physical Systems</title><link>https://arxiv.org/abs/2601.16074</link><description>arXiv:2601.16074v1 Announce Type: new 
Abstract: Industrial Cyber-Physical Systems (CPS) are sensitive infrastructure from both safety and economics perspectives, making their reliability critically important. Machine Learning (ML), specifically deep learning, is increasingly integrated in industrial CPS, but the inherent complexity of ML models results in non-transparent operation. Rigorous evaluation is needed to prevent models from exhibiting unexpected behaviour on future, unseen data. Explainable AI (XAI) can be used to uncover model reasoning, allowing a more extensive analysis of behaviour. We apply XAI to to improve predictive performance of ML models intended for industrial CPS. We analyse the effects of components from time-series data decomposition on model predictions using SHAP values. Through this method, we observe evidence on the lack of sufficient contextual information during model training. By increasing the window size of data instances, informed by the XAI findings, we are able to improve model performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16074v1</guid></item><item><title>[cs updates on arXiv.org] Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Application</title><link>https://arxiv.org/abs/2601.16078</link><description>arXiv:2601.16078v1 Announce Type: new 
Abstract: One of the core advantages of SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. In the previous paper, the theoretical analysis of autonomy property of navigation model in inertial, earth and world frames was given. A construction method for SE2(3) group navigation model is proposed to improve the non-inertial navigation model toward full autonomy. This paper serves as a counterpart to previous paper and conducts the real-world strapdown inertial navigation system (SINS)/odometer(ODO) experiments as well as Monte-Carlo simulations to demonstrate the performance of improved SE2(3) group based high-precision navigation models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16078v1</guid></item><item><title>[cs updates on arXiv.org] Masked Modeling for Human Motion Recovery Under Occlusions</title><link>https://arxiv.org/abs/2601.16079</link><description>arXiv:2601.16079v1 Announce Type: new 
Abstract: Human motion reconstruction from monocular videos is a fundamental challenge in computer vision, with broad applications in AR/VR, robotics, and digital content creation, but remains challenging under frequent occlusions in real-world settings.Existing regression-based methods are efficient but fragile to missing observations, while optimization- and diffusion-based approaches improve robustness at the cost of slow inference speed and heavy preprocessing steps. To address these limitations, we leverage recent advances in generative masked modeling and present MoRo: Masked Modeling for human motion Recovery under Occlusions. MoRo is an occlusion-robust, end-to-end generative framework that formulates motion reconstruction as a video-conditioned task, and efficiently recover human motion in a consistent global coordinate system from RGB videos. By masked modeling, MoRo naturally handles occlusions while enabling efficient, end-to-end inference. To overcome the scarcity of paired video-motion data, we design a cross-modality learning scheme that learns multi-modal priors from a set of heterogeneous datasets: (i) a trajectory-aware motion prior trained on MoCap datasets, (ii) an image-conditioned pose prior trained on image-pose datasets, capturing diverse per-frame poses, and (iii) a video-conditioned masked transformer that fuses motion and pose priors, finetuned on video-motion datasets to integrate visual cues with motion dynamics for robust inference. Extensive experiments on EgoBody and RICH demonstrate that MoRo substantially outperforms state-of-the-art methods in accuracy and motion realism under occlusions, while performing on-par in non-occluded scenarios. MoRo achieves real-time inference at 70 FPS on a single H200 GPU.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16079v1</guid></item><item><title>[cs updates on arXiv.org] Towards a Goal-Centric Assessment of Requirements Engineering Methods for Privacy by Design</title><link>https://arxiv.org/abs/2601.16080</link><description>arXiv:2601.16080v1 Announce Type: new 
Abstract: Implementing privacy by design (PbD) according to the General Data Protection Regulation (GDPR) is met with a growing number of requirements engineering (RE) approaches. However, the question of which RE method for PbD fits best the goals of organisations remains a challenge. We report our endeavor to close this gap by synthesizing a goal-centric approach for PbD methods assessment. We used literature review, interviews, and validation with practitioners to achieve the goal of our study. As practitioners do not approach PbD systematically, we suggest that RE methods for PbD should be assessed against organisational goals, rather than process characteristics only. We hope that, when further developed, the goal-centric approach could support the development, selection, and tailoring of RE practices for PbD.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16080v1</guid></item><item><title>[cs updates on arXiv.org] Probably Approximately Correct Maximum A Posteriori Inference</title><link>https://arxiv.org/abs/2601.16083</link><description>arXiv:2601.16083v1 Announce Type: new 
Abstract: Computing the conditional mode of a distribution, better known as the $\mathit{maximum\ a\ posteriori}$ (MAP) assignment, is a fundamental task in probabilistic inference. However, MAP estimation is generally intractable, and remains hard even under many common structural constraints and approximation schemes. We introduce $\mathit{probably\ approximately\ correct}$ (PAC) algorithms for MAP inference that provide provably optimal solutions under variable and fixed computational budgets. We characterize tractability conditions for PAC-MAP using information theoretic measures that can be estimated from finite samples. Our PAC-MAP solvers are efficiently implemented using probabilistic circuits with appropriate architectures. The randomization strategies we develop can be used either as standalone MAP inference techniques or to improve on popular heuristics, fortifying their solutions with rigorous guarantees. Experiments confirm the benefits of our method in a range of benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16083v1</guid></item><item><title>[cs updates on arXiv.org] Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics</title><link>https://arxiv.org/abs/2601.16087</link><description>arXiv:2601.16087v1 Announce Type: new 
Abstract: Large language model (LLM) agents often exhibit abrupt shifts in tone and persona during extended interaction, reflecting the absence of explicit temporal structure governing agent-level state. While prior work emphasizes turn-local sentiment or static emotion classification, the role of explicit affective dynamics in shaping long-horizon agent behavior remains underexplored. This work investigates whether imposing dynamical structure on an external affective state can induce temporal coherence and controlled recovery in multi-turn dialogue. We introduce an agent-level affective subsystem that maintains a continuous Valence-Arousal-Dominance (VAD) state external to the language model and governed by first- and second-order update rules. Instantaneous affective signals are extracted using a fixed, memoryless estimator and integrated over time via exponential smoothing or momentum-based dynamics. The resulting affective state is injected back into generation without modifying model parameters. Using a fixed 25-turn dialogue protocol, we compare stateless, first-order, and second-order affective dynamics. Stateless agents fail to exhibit coherent trajectories or recovery, while state persistence enables delayed responses and reliable recovery. Second-order dynamics introduce affective inertia and hysteresis that increase with momentum, revealing a trade-off between stability and responsiveness.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16087v1</guid></item><item><title>[cs updates on arXiv.org] Delayed Assignments in Online Non-Centroid Clustering with Stochastic Arrivals</title><link>https://arxiv.org/abs/2601.16091</link><description>arXiv:2601.16091v1 Announce Type: new 
Abstract: Clustering is a fundamental problem, aiming to partition a set of elements, like agents or data points, into clusters such that elements in the same cluster are closer to each other than to those in other clusters. In this paper, we present a new framework for studying online non-centroid clustering with delays, where elements, that arrive one at a time as points in a finite metric space, should be assigned to clusters, but assignments need not be immediate. Specifically, upon arrival, each point's location is revealed, and an online algorithm has to irrevocably assign it to an existing cluster or create a new one containing, at this moment, only this point. However, we allow decisions to be postponed at a delay cost, instead of following the more common assumption of immediate decisions upon arrival. This poses a critical challenge: the goal is to minimize both the total distance costs between points in each cluster and the overall delay costs incurred by postponing assignments. In the classic worst-case arrival model, where points arrive in an arbitrary order, no algorithm has a competitive ratio better than sublogarithmic in the number of points. To overcome this strong impossibility, we focus on a stochastic arrival model, where points' locations are drawn independently across time from an unknown and fixed probability distribution over the finite metric space. We offer hope for beyond worst-case adversaries: we devise an algorithm that is constant competitive in the sense that, as the number of points grows, the ratio between the expected overall costs of the output clustering and an optimal offline clustering is bounded by a constant.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16091v1</guid></item><item><title>[cs updates on arXiv.org] SAMTok: Representing Any Mask with Two Words</title><link>https://arxiv.org/abs/2601.16093</link><description>arXiv:2601.16093v1 Announce Type: new 
Abstract: Pixel-wise capabilities are essential for building interactive intelligent systems. However, pixel-wise multi-modal LLMs (MLLMs) remain difficult to scale due to complex region-level encoders, specialized segmentation decoders, and incompatible training objectives. To address these challenges, we present SAMTok, a discrete mask tokenizer that converts any region mask into two special tokens and reconstructs the mask using these tokens with high fidelity. By treating masks as new language tokens, SAMTok enables base MLLMs (such as the QwenVL series) to learn pixel-wise capabilities through standard next-token prediction and simple reinforcement learning, without architectural modifications and specialized loss design. SAMTok builds on SAM2 and is trained on 209M diverse masks using a mask encoder and residual vector quantizer to produce discrete, compact, and information-rich tokens. With 5M SAMTok-formatted mask understanding and generation data samples, QwenVL-SAMTok attains state-of-the-art or comparable results on region captioning, region VQA, grounded conversation, referring segmentation, scene graph parsing, and multi-round interactive segmentation. We further introduce a textual answer-matching reward that enables efficient reinforcement learning for mask generation, delivering substantial improvements on GRES and GCG benchmarks. Our results demonstrate a scalable and straightforward paradigm for equipping MLLMs with strong pixel-wise capabilities. Our code and models are available.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16093v1</guid></item><item><title>[cs updates on arXiv.org] Neural Particle Automata: Learning Self-Organizing Particle Dynamics</title><link>https://arxiv.org/abs/2601.16096</link><description>arXiv:2601.16096v1 Announce Type: new 
Abstract: We introduce Neural Particle Automata (NPA), a Lagrangian generalization of Neural Cellular Automata (NCA) from static lattices to dynamic particle systems. Unlike classical Eulerian NCA where cells are pinned to pixels or voxels, NPA model each cell as a particle with a continuous position and internal state, both updated by a shared, learnable neural rule. This particle-based formulation yields clear individuation of cells, allows heterogeneous dynamics, and concentrates computation only on regions where activity is present. At the same time, particle systems pose challenges: neighborhoods are dynamic, and a naive implementation of local interactions scale quadratically with the number of particles. We address these challenges by replacing grid-based neighborhood perception with differentiable Smoothed Particle Hydrodynamics (SPH) operators backed by memory-efficient, CUDA-accelerated kernels, enabling scalable end-to-end training. Across tasks including morphogenesis, point-cloud classification, and particle-based texture synthesis, we show that NPA retain key NCA behaviors such as robustness and self-regeneration, while enabling new behaviors specific to particle systems. Together, these results position NPA as a compact neural model for learning self-organizing particle dynamics.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16096v1</guid></item><item><title>[cs updates on arXiv.org] Adapter Fusion for Multilingual Text2Cypher with Linear and Learned Gating</title><link>https://arxiv.org/abs/2601.16097</link><description>arXiv:2601.16097v1 Announce Type: new 
Abstract: Large Language Models enable users to access database using natural language interfaces using tools like Text2SQL, Text2SPARQL, and Text2Cypher, which translate user questions into structured database queries. While these systems improve database accessibility, most research focuses on English with limited multilingual support. This work investigates a scalable multilingual Text2Cypher, aiming to support new languages without re-running full fine-tuning, avoiding manual hyper-parameter tuning, and maintaining performance close to joint multilingual fine-tuning. We train language-specific LoRA adapters for English, Spanish, and Turkish and combined them via uniform linear merging or learned fusion MLP with dynamic gating. Experimental results show that the fusion MLP recovers around 75\% of the accuracy gains from joint multilingual fine-tuning while requiring only a smaller subset of the data, outperforming linear merging across all three languages. This approach enables incremental language expansion to new languages by requiring only one LoRA adapter and a lightweight MLP retraining. Learned adapter fusion offers a practical alternative to expensive joint fine-tuning, balancing performance, data efficiency, and scalability for multilingual Text2Cypher task.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16097v1</guid></item><item><title>[cs updates on arXiv.org] Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification</title><link>https://arxiv.org/abs/2601.16098</link><description>arXiv:2601.16098v1 Announce Type: new 
Abstract: Although Mamba models greatly improve Hyperspectral Image (HSI) classification, they have critical challenges in terms defining efficient and adaptive token sequences for improve performance. This paper therefore presents CSSMamba (Clustering-guided Spatial-Spectral Mamba) framework to better address the challenges, with the following contributions. First, to achieve efficient and adaptive token sequences for improved Mamba performance, we integrate the clustering mechanism into a spatial Mamba architecture, leading to a cluster-guided spatial Mamba module (CSpaMamba) that reduces the Mamba sequence length and improves Mamba feature learning capability. Second, to improve the learning of both spatial and spectral information, we integrate the CSpaMamba module with a spectral mamba module (SpeMamba), leading to a complete clustering-guided spatial-spectral Mamba framework. Third, to further improve feature learning capability, we introduce an Attention-Driven Token Selection mechanism to optimize Mamba token sequencing. Last, to seamlessly integrate clustering into the Mamba model in a coherent manner, we design a Learnable Clustering Module that learns the cluster memberships in an adaptive manner. Experiments on the Pavia University, Indian Pines, and Liao-Ning 01 datasets demonstrate that CSSMamba achieves higher accuracy and better boundary preservation compared to state-of-the-art CNN, Transformer, and Mamba-based methods.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16098v1</guid></item><item><title>[cs updates on arXiv.org] Benchmarking Deep Learning Models for Raman Spectroscopy Across Open-Source Datasets</title><link>https://arxiv.org/abs/2601.16107</link><description>arXiv:2601.16107v1 Announce Type: new 
Abstract: Deep learning classifiers for Raman spectroscopy are increasingly reported to outperform classical chemometric approaches. However their evaluations are often conducted in isolation or compared against traditional machine learning methods or trivially adapted vision-based architectures that were not originally proposed for Raman spectroscopy. As a result, direct comparisons between existing deep learning models developed specifically for Raman spectral analysis on shared open-source datasets remain scarce. To the best of our knowledge, this study presents one of the first systematic benchmarks comparing three or more published Raman-specific deep learning classifiers across multiple open-source Raman datasets. We evaluate five representative deep learning architectures under a unified training and hyperparameter tuning protocol across three open-source Raman datasets selected to support standard evaluation, fine-tuning, and explicit distribution-shift testing. We report classification accuracies and macro-averaged F1 scores to provide a fair and reproducible comparison of deep learning models for Raman spectra based classification.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16107v1</guid></item><item><title>[cs updates on arXiv.org] Multimodal Climate Disinformation Detection: Integrating Vision-Language Models with External Knowledge Sources</title><link>https://arxiv.org/abs/2601.16108</link><description>arXiv:2601.16108v1 Announce Type: new 
Abstract: Climate disinformation has become a major challenge in today digital world, especially with the rise of misleading images and videos shared widely on social media. These false claims are often convincing and difficult to detect, which can delay actions on climate change. While vision-language models (VLMs) have been used to identify visual disinformation, they rely only on the knowledge available at the time of training. This limits their ability to reason about recent events or updates. The main goal of this paper is to overcome that limitation by combining VLMs with external knowledge. By retrieving up-to-date information such as reverse image results, online fact-checks, and trusted expert content, the system can better assess whether an image and its claim are accurate, misleading, false, or unverifiable. This approach improves the model ability to handle real-world climate disinformation and supports efforts to protect public understanding of science in a rapidly changing information landscape.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16108v1</guid></item><item><title>[cs updates on arXiv.org] Efficiently Learning Robust Torque-based Locomotion Through Reinforcement with Model-Based Supervision</title><link>https://arxiv.org/abs/2601.16109</link><description>arXiv:2601.16109v1 Announce Type: new 
Abstract: We propose a control framework that integrates model-based bipedal locomotion with residual reinforcement learning (RL) to achieve robust and adaptive walking in the presence of real-world uncertainties. Our approach leverages a model-based controller, comprising a Divergent Component of Motion (DCM) trajectory planner and a whole-body controller, as a reliable base policy. To address the uncertainties of inaccurate dynamics modeling and sensor noise, we introduce a residual policy trained through RL with domain randomization. Crucially, we employ a model-based oracle policy, which has privileged access to ground-truth dynamics during training, to supervise the residual policy via a novel supervised loss. This supervision enables the policy to efficiently learn corrective behaviors that compensate for unmodeled effects without extensive reward shaping. Our method demonstrates improved robustness and generalization across a range of randomized conditions, offering a scalable solution for sim-to-real transfer in bipedal locomotion.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16109v1</guid></item><item><title>[cs updates on arXiv.org] synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier</title><link>https://arxiv.org/abs/2601.16113</link><description>arXiv:2601.16113v1 Announce Type: new 
Abstract: Optical Character Recognition (OCR) for low-resource languages remains a significant challenge due to the scarcity of large-scale annotated training datasets. Languages such as Kashmiri, with approximately 7 million speakers and a complex Perso-Arabic script featuring unique diacritical marks, currently lack support in major OCR systems including Tesseract, TrOCR, and PaddleOCR. Manual dataset creation for such languages is prohibitively expensive, time-consuming, and error-prone, often requiring word by word transcription of printed or handwritten text.
  We present SynthOCR-Gen, an open-source synthetic OCR dataset generator specifically designed for low-resource languages. Our tool addresses the fundamental bottleneck in OCR development by transforming digital Unicode text corpora into ready-to-use training datasets. The system implements a comprehensive pipeline encompassing text segmentation (character, word, n-gram, sentence, and line levels), Unicode normalization with script purity enforcement, multi-font rendering with configurable distribution, and 25+ data augmentation techniques simulating real-world document degradations including rotation, blur, noise, and scanner artifacts.
  We demonstrate the efficacy of our approach by generating a 600,000-sample word-segmented Kashmiri OCR dataset, which we release publicly on HuggingFace. This work provides a practical pathway for bringing low-resource languages into the era of vision-language AI models, and the tool is openly available for researchers and practitioners working with underserved writing systems worldwide.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16113v1</guid></item><item><title>[cs updates on arXiv.org] Distillation-based Layer Dropping (DLD) Effective End-to-end Framework for Dynamic Speech Networks</title><link>https://arxiv.org/abs/2601.16117</link><description>arXiv:2601.16117v1 Announce Type: new 
Abstract: Edge devices operate in constrained and varying resource settings, requiring dynamic architectures that can adapt to limitations of the available resources. To meet such demands, layer dropping ($\mathcal{LD}$) approach is typically used to transform static models into dynamic ones by skipping parts of the network along with reducing overall computational complexity. However, existing $\mathcal{LD}$ methods greatly impact the dynamic model's performance for low and high dropping cases, deteriorating the performance-computation trade-off. To this end, we propose a distillation-based layer dropping (DLD) framework that effectively combines the capabilities of knowledge distillation and $\mathcal{LD}$ in an end-to-end fashion, thereby achieving state-of-the-art performance for dynamic speech networks. Comprehensive experimentation utilizing well-known speech recognition methods, including conformer and WavLM, on three public benchmarks demonstrates the effectiveness of our framework, reducing the word error rate by $9.32\%$ and $2.25\%$ for high and no dropping cases with $33.3\%$ reduction in training time.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16117v1</guid></item><item><title>[cs updates on arXiv.org] A Case for Hypergraphs to Model and Map SNNs on Neuromorphic Hardware</title><link>https://arxiv.org/abs/2601.16118</link><description>arXiv:2601.16118v1 Announce Type: new 
Abstract: Executing Spiking Neural Networks (SNNs) on neuromorphic hardware poses the problem of mapping neurons to cores. SNNs operate by propagating spikes between neurons that form a graph through synapses. Neuromorphic hardware mimics them through a network-on-chip, transmitting spikes, and a mesh of cores, each managing several neurons. Its operational cost is tied to spike movement and active cores. A mapping comprises two tasks: partitioning the SNN's graph to fit inside cores and placement of each partition on the hardware mesh. Both are NP-hard problems, and as SNNs and hardware scale towards billions of neurons, they become increasingly difficult to tackle effectively. In this work, we propose to raise the abstraction of SNNs from graphs to hypergraphs, redesigning mapping techniques accordingly. The resulting model faithfully captures the replication of spikes inside cores by exposing the notion of hyperedge co-membership between neurons. We further show that the overlap and locality of hyperedges strongly correlate with high-quality mappings, making these properties instrumental in devising mapping algorithms. By exploiting them directly, grouping neurons through shared hyperedges, communication traffic and hardware resource usage can be reduced be yond what just contracting individual connections attains. To substantiate this insight, we consider several partitioning and placement algorithms, some newly devised, others adapted from literature, and compare them over progressively larger and bio-plausible SNNs. Our results show that hypergraph based techniques can achieve better mappings than the state-of-the-art at several execution time regimes. Based on these observations, we identify a promising selection of algorithms to achieve effective mappings at any scale.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16118v1</guid></item><item><title>[cs updates on arXiv.org] Canonical structure of the LLG equation for exponential updates in micromagnetism</title><link>https://arxiv.org/abs/2601.16122</link><description>arXiv:2601.16122v1 Announce Type: new 
Abstract: In this contribution we propose an exponential update algorithm for magnetic moments appearing in the framework of micromagnetics and the Landau-Lifshitz-Gilbert (LLG) equation. This algorithm can be interpreted as the geometric integration on spheres, that a priori satisfy the unit length constraint of the normalized magnetization vector. Even though the geometric structures for this are obvious and some works already use an exponential algorithm, to the best of the authors' knowledge, there is no canonical structure of the LLG equation for the exponential update algorithm in micromagnetism. Tensor algebraic reformulations of the LLG equation allow the canonical representation of the evolution equation for the magnetization, which serves as the basis for different integrators. Based on the specific structure of the exponential of skew symmetric matrices an efficient update scheme is derived. The excellent performance of the proposed exponential update algorithm is demonstrated in representative examples.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16122v1</guid></item><item><title>[cs updates on arXiv.org] Rethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing</title><link>https://arxiv.org/abs/2601.16125</link><description>arXiv:2601.16125v1 Announce Type: new 
Abstract: Composed Image Retrieval (CIR) is a pivotal and complex task in multimodal understanding. Current CIR benchmarks typically feature limited query categories and fail to capture the diverse requirements of real-world scenarios. To bridge this evaluation gap, we leverage image editing to achieve precise control over modification types and content, enabling a pipeline for synthesizing queries across a broad spectrum of categories. Using this pipeline, we construct EDIR, a novel fine-grained CIR benchmark. EDIR encompasses 5,000 high-quality queries structured across five main categories and fifteen subcategories. Our comprehensive evaluation of 13 multimodal embedding models reveals a significant capability gap; even state-of-the-art models (e.g., RzenEmbed and GME) struggle to perform consistently across all subcategories, highlighting the rigorous nature of our benchmark. Through comparative analysis, we further uncover inherent limitations in existing benchmarks, such as modality biases and insufficient categorical coverage. Furthermore, an in-domain training experiment demonstrates the feasibility of our benchmark. This experiment clarifies the task challenges by distinguishing between categories that are solvable with targeted data and those that expose intrinsic limitations of current model architectures.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16125v1</guid></item><item><title>[cs updates on arXiv.org] Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging</title><link>https://arxiv.org/abs/2601.16127</link><description>arXiv:2601.16127v1 Announce Type: new 
Abstract: Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50\%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60\%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16127v1</guid></item><item><title>[cs updates on arXiv.org] Replicating Human Motivated Reasoning Studies with LLMs</title><link>https://arxiv.org/abs/2601.16130</link><description>arXiv:2601.16130v1 Announce Type: new 
Abstract: Motivated reasoning -- the idea that individuals processing information may be motivated to reach a certain conclusion, whether it be accurate or predetermined -- has been well-explored as a human phenomenon. However, it is unclear whether base LLMs mimic these motivational changes. Replicating 4 prior political motivated reasoning studies, we find that base LLM behavior does not align with expected human behavior. Furthermore, base LLM behavior across models shares some similarities, such as smaller standard deviations and inaccurate argument strength assessments. We emphasize the importance of these findings for researchers using LLMs to automate tasks such as survey data collection and argument assessment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16130v1</guid></item><item><title>[cs updates on arXiv.org] LLM Prompt Evaluation for Educational Applications</title><link>https://arxiv.org/abs/2601.16134</link><description>arXiv:2601.16134v1 Announce Type: new 
Abstract: As large language models (LLMs) become increasingly common in educational applications, there is a growing need for evidence-based methods to design and evaluate LLM prompts that produce personalized and pedagogically aligned out-puts. This study presents a generalizable, systematic approach for evaluating prompts, demonstrated through an analysis of LLM-generated follow-up questions in a structured dialogue activity. Six prompt templates were designed and tested. The templates incorporated established prompt engineering patterns, with each prompt emphasizing distinct pedagogical strategies. The prompt templates were compared through a tournament-style evaluation framework that can be adapted for other educational applications. The tournament employed the Glicko2 rating system with eight judges evaluating question pairs across three dimensions: format, dialogue support, and appropriateness for learners. Data was sourced from 120 authentic user interactions across three distinct educational deployments. Results showed that a single prompt related to strategic reading out-performed other templates with win probabilities ranging from 81% to 100% in pairwise comparisons. This prompt combined persona and context manager pat-terns and was designed to support metacognitive learning strategies such as self-directed learning. The methodology showcases how educational technology re- searchers can systematically evaluate and improve prompt designs, moving beyond ad-hoc prompt engineering toward evidence-based prompt development for educational applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16134v1</guid></item><item><title>[cs updates on arXiv.org] Automatic Classification of Arabic Literature into Historical Eras</title><link>https://arxiv.org/abs/2601.16138</link><description>arXiv:2601.16138v1 Announce Type: new 
Abstract: The Arabic language has undergone notable transformations over time, including the emergence of new vocabulary, the obsolescence of others, and shifts in word usage. This evolution is evident in the distinction between the classical and modern Arabic eras. Although historians and linguists have partitioned Arabic literature into multiple eras, relatively little research has explored the automatic classification of Arabic texts by time period, particularly beyond the domain of poetry. This paper addresses this gap by employing neural networks and deep learning techniques to automatically classify Arabic texts into distinct eras and periods. The proposed models are evaluated using two datasets derived from two publicly available corpora, covering texts from the pre-Islamic to the modern era. The study examines class setups ranging from binary to 15-class classification and considers both predefined historical eras and custom periodizations. Results range from F1-scores of 0.83 and 0.79 on the binary-era classification task using the OpenITI and APCD datasets, respectively, to 0.20 on the 15-era classification task using OpenITI and 0.18 on the 12-era classification task using APCD.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16138v1</guid></item><item><title>[cs updates on arXiv.org] On the Intrinsic Dimensions of Data in Kernel Learning</title><link>https://arxiv.org/abs/2601.16139</link><description>arXiv:2601.16139v1 Announce Type: new 
Abstract: The manifold hypothesis suggests that the generalization performance of machine learning methods improves significantly when the intrinsic dimension of the input distribution's support is low. In the context of KRR, we investigate two alternative notions of intrinsic dimension. The first, denoted $d_\rho$, is the upper Minkowski dimension defined with respect to the canonical metric induced by a kernel function $K$ on a domain $\Omega$. The second, denoted $d_K$, is the effective dimension, derived from the decay rate of Kolmogorov $n$-widths associated with $K$ on $\Omega$. Given a probability measure $\mu$ on $\Omega$, we analyze the relationship between these $n$-widths and eigenvalues of the integral operator $\phi \to \int_\Omega K(\cdot,x)\phi(x)d\mu(x)$. We show that, for a fixed domain $\Omega$, the Kolmogorov $n$-widths characterize the worst-case eigenvalue decay across all probability measures $\mu$ supported on $\Omega$. These eigenvalues are central to understanding the generalization behavior of constrained KRR, enabling us to derive an excess error bound of order $O(n^{-\frac{2+d_K}{2+2d_K} + \epsilon})$ for any $\epsilon &gt; 0$, when the training set size $n$ is large. We also propose an algorithm that estimates upper bounds on the $n$-widths using only a finite sample from $\mu$. For distributions close to uniform, we prove that $\epsilon$-accurate upper bounds on all $n$-widths can be computed with high probability using at most $O\left(\epsilon^{-d_\rho}\log\frac{1}{\epsilon}\right)$ samples, with fewer required for small $n$. Finally, we compute the effective dimension $d_K$ for various fractal sets and present additional numerical experiments. Our results show that, for kernels such as the Laplace kernel, the effective dimension $d_K$ can be significantly smaller than the Minkowski dimension $d_\rho$, even though $d_K = d_\rho$ provably holds on regular domains.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16139v1</guid></item><item><title>[cs updates on arXiv.org] Learning to Watermark in the Latent Space of Generative Models</title><link>https://arxiv.org/abs/2601.16140</link><description>arXiv:2601.16140v1 Announce Type: new 
Abstract: Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models. We demonstrate that these latent watermarkers can be effectively distilled either into the generative model itself or into the latent decoder, enabling in-model watermarking. The resulting latent watermarks achieve competitive robustness while offering similar imperceptibility and up to 20x speedup compared to pixel-space baselines. Our experiments further reveal that distilling latent watermarkers outperforms distilling pixel-space ones, providing a solution that is both more efficient and more robust.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16140v1</guid></item><item><title>[cs updates on arXiv.org] Computing Fixpoints of Learned Functions: Chaotic Iteration and Simple Stochastic Games</title><link>https://arxiv.org/abs/2601.16142</link><description>arXiv:2601.16142v1 Announce Type: new 
Abstract: The problem of determining the (least) fixpoint of (higher-dimensional) functions over the non-negative reals frequently occurs when dealing with systems endowed with a quantitative semantics. We focus on the situation in which the functions of interest are not known precisely but can only be approximated. As a first contribution we generalize an iteration scheme called dampened Mann iteration, recently introduced in the literature. The improved scheme relaxes previous constraints on parameter sequences, allowing learning rates to converge to zero or not converge at all. While seemingly minor, this flexibility is essential to enable the implementation of chaotic iterations, where only a subset of components is updated in each step, allowing to tackle higher-dimensional problems. Additionally, by allowing learning rates to converge to zero, we can relax conditions on the convergence speed of function approximations, making the method more adaptable to various scenarios. We also show that dampened Mann iteration applies immediately to compute the expected payoff in various probabilistic models, including simple stochastic games, not covered by previous work.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16142v1</guid></item><item><title>[cs updates on arXiv.org] Low-altitude Multi-UAV-assisted Data Collection and Semantic Forwarding for Post-Disaster Relief</title><link>https://arxiv.org/abs/2601.16146</link><description>arXiv:2601.16146v1 Announce Type: new 
Abstract: The low-altitude economy (LAE) is an emerging economic paradigm which fosters integrated development across multiple fields. As a pivotal component of the LAE, low-altitude uncrewed aerial vehicles (UAVs) can restore communication by serving as aerial relays between the post-disaster areas and remote base stations (BSs). However, conventional approaches face challenges from vulnerable long-distance links between the UAVs and remote BSs, and data bottlenecks arising from massive data volumes and limited onboard UAV resources. In this work, we investigate a low-altitude multi-UAV-assisted data collection and semantic forwarding network, in which multiple UAVs collect data from ground users, form clusters, perform intra-cluster data aggregation with semantic extraction, and then cooperate as virtual antenna array (VAAs) to transmit the extracted semantic information to a remote BS via collaborative beamforming (CB). We formulate a data collection and semantic forwarding multi-objective optimization problem (DCSFMOP) that jointly maximizes both the user and semantic transmission rates while minimizing UAV energy consumption. The formulated DCSFMOP is a mixed-integer nonlinear programming (MINLP) problem that is inherently NP-hard and characterized by dynamically varying decision variable dimensionality. To address these challenges, we propose a large language model-enabled alternating optimization approach (LLM-AOA), which effectively handles the complex search space and variable dimensionality by optimizing different subsets of decision variables through tailored optimization strategies. Simulation results demonstrate that LLM-AOA outperforms AOA by approximately 26.8\% and 22.9\% in transmission rate and semantic rate, respectively.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16146v1</guid></item><item><title>[cs updates on arXiv.org] Beat-ssl: Capturing Local ECG Morphology through Heartbeat-level Contrastive Learning with Soft Targets</title><link>https://arxiv.org/abs/2601.16147</link><description>arXiv:2601.16147v1 Announce Type: new 
Abstract: Obtaining labelled ECG data for developing supervised models is challenging. Contrastive learning (CL) has emerged as a promising pretraining approach that enables effective transfer learning with limited labelled data. However, existing CL frameworks either focus solely on global context or fail to exploit ECG-specific characteristics. Furthermore, these methods rely on hard contrastive targets, which may not adequately capture the continuous nature of feature similarity in ECG signals. In this paper, we propose Beat-SSL, a contrastive learning framework that performs dual-context learning through both rhythm-level and heartbeat-level contrasting with soft targets. We evaluated our pretrained model on two downstream tasks: 1) multilabel classification for global rhythm assessment, and 2) ECG segmentation to assess its capacity to learn representations across both contexts. We conducted an ablation study and compared the best configuration with three other methods, including one ECG foundation model. Despite the foundation model's broader pretraining, Beat-SSL reached 93% of its performance in multilabel classification task and surpassed all other methods in the segmentation task by 4%.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16147v1</guid></item><item><title>[cs updates on arXiv.org] ActionMesh: Animated 3D Mesh Generation with Temporal 3D Diffusion</title><link>https://arxiv.org/abs/2601.16148</link><description>arXiv:2601.16148v1 Announce Type: new 
Abstract: Generating animated 3D objects is at the heart of many applications, yet most advanced works are typically difficult to apply in practice because of their limited setup, their long runtime, or their limited quality. We introduce ActionMesh, a generative model that predicts production-ready 3D meshes "in action" in a feed-forward manner. Drawing inspiration from early video models, our key insight is to modify existing 3D diffusion models to include a temporal axis, resulting in a framework we dubbed "temporal 3D diffusion". Specifically, we first adapt the 3D diffusion stage to generate a sequence of synchronized latents representing time-varying and independent 3D shapes. Second, we design a temporal 3D autoencoder that translates a sequence of independent shapes into the corresponding deformations of a pre-defined reference shape, allowing us to build an animation. Combining these two components, ActionMesh generates animated 3D meshes from different inputs like a monocular video, a text description, or even a 3D mesh with a text prompt describing its animation. Besides, compared to previous approaches, our method is fast and produces results that are rig-free and topology consistent, hence enabling rapid iteration and seamless applications like texturing and retargeting. We evaluate our model on standard video-to-4D benchmarks (Consistent4D, Objaverse) and report state-of-the-art performances on both geometric accuracy and temporal consistency, demonstrating that our model can deliver animated 3D meshes with unprecedented speed and quality.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16148v1</guid></item><item><title>[cs updates on arXiv.org] Pay (Cross) Attention to the Melody: Curriculum Masking for Single-Encoder Melodic Harmonization</title><link>https://arxiv.org/abs/2601.16150</link><description>arXiv:2601.16150v1 Announce Type: new 
Abstract: Melodic harmonization, the task of generating harmonic accompaniments for a given melody, remains a central challenge in computational music generation. Recent single encoder transformer approaches have framed harmonization as a masked sequence modeling problem, but existing training curricula inspired by discrete diffusion often result in weak (cross) attention between melody and harmony. This leads to limited exploitation of melodic cues, particularly in out-of-domain contexts. In this work, we introduce a training curriculum, FF (full-to-full), which keeps all harmony tokens masked for several training steps before progressively unmasking entire sequences during training to strengthen melody-harmony interactions. We systematically evaluate this approach against prior curricula across multiple experimental axes, including temporal quantization (quarter vs. sixteenth note), bar-level vs. time-signature conditioning, melody representation (full range vs. pitch class), and inference-time unmasking strategies. Models are trained on the HookTheory dataset and evaluated both in-domain and on a curated collection of jazz standards, using a comprehensive set of metrics that assess chord progression structure, harmony-melody alignment, and rhythmic coherence. Results demonstrate that the proposed FF curriculum consistently outperforms baselines in nearly all metrics, with particularly strong gains in out-of-domain evaluations where harmonic adaptability to novel melodic queues is crucial. We further find that quarter-note quantization, intertwining of bar tokens, and pitch-class melody representations are advantageous in the FF setting. Our findings highlight the importance of training curricula in enabling effective melody conditioning and suggest that full-to-full unmasking offers a robust strategy for single encoder harmonization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16150v1</guid></item><item><title>[cs updates on arXiv.org] Substrate Stability Under Persistent Disagreement: Structural Constraints for Neutral Ontological Substrates</title><link>https://arxiv.org/abs/2601.16152</link><description>arXiv:2601.16152v1 Announce Type: new 
Abstract: Modern data systems increasingly operate under conditions of persistent legal, political, and analytic disagreement. In such settings, interoperability cannot rely on shared interpretation, negotiated semantics, or centralized authority. Instead, representations must function as neutral substrates that preserve stable reference across incompatible extensions. This paper investigates the structural constraints imposed on ontological design by this requirement. Building on a neutrality framework that treats interpretive non-commitment and stability under extension as explicit design constraints, we ask what minimal ontological structure is forced if accountability relationships are to remain referable and comparable under disagreement. Minimality here is not mere parsimony: a reduction is admissible only if it does not reintroduce stability-critical distinctions as hidden roles, flags, or contextual predicates. We establish a conditional lower-bound result: any ontology capable of supporting accountability under persistent disagreement must realize at least six distinct identity-and-persistence regimes. We further show that a construction with exactly six such regimes is sufficient to satisfy the stated requirements without embedding causal or normative commitments in the substrate. The result is not a proposal for a universal ontology, but a constraint on what is possible when neutrality and stable reference are treated as non-negotiable design goals.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16152v1</guid></item><item><title>[cs updates on arXiv.org] HVD: Human Vision-Driven Video Representation Learning for Text-Video Retrieval</title><link>https://arxiv.org/abs/2601.16155</link><description>arXiv:2601.16155v1 Announce Type: new 
Abstract: The success of CLIP has driven substantial progress in text-video retrieval. However, current methods often suffer from "blind" feature interaction, where the model struggles to discern key visual information from background noise due to the sparsity of textual queries. To bridge this gap, we draw inspiration from human cognitive behavior and propose the Human Vision-Driven (HVD) model. Our framework establishes a coarse-to-fine alignment mechanism comprising two key components: the Frame Features Selection Module (FFSM) and the Patch Features Compression Module (PFCM). FFSM mimics the human macro-perception ability by selecting key frames to eliminate temporal redundancy. Subsequently, PFCM simulates micro-perception by aggregating patch features into salient visual entities through an advanced attention mechanism, enabling precise entity-level matching. Extensive experiments on five benchmarks demonstrate that HVD not only captures human-like visual focus but also achieves state-of-the-art performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16155v1</guid></item><item><title>[cs updates on arXiv.org] Domain-Incremental Continual Learning for Robust and Efficient Keyword Spotting in Resource Constrained Systems</title><link>https://arxiv.org/abs/2601.16158</link><description>arXiv:2601.16158v1 Announce Type: new 
Abstract: Keyword Spotting (KWS) systems with small footprint models deployed on edge devices face significant accuracy and robustness challenges due to domain shifts caused by varying noise and recording conditions. To address this, we propose a comprehensive framework for continual learning designed to adapt to new domains while maintaining computational efficiency. The proposed pipeline integrates a dual-input Convolutional Neural Network, utilizing both Mel Frequency Cepstral Coefficients (MFCC) and Mel-spectrogram features, supported by a multi-stage denoising process, involving discrete wavelet transform and spectral subtraction techniques, plus model and prototype update blocks. Unlike prior methods that restrict updates to specific layers, our approach updates the complete quantized model, made possible due to compact model architecture. A subset of input samples are selected during runtime using class prototypes and confidence-driven filtering, which are then pseudo-labeled and combined with rehearsal buffer for incremental model retraining. Experimental results on noisy test dataset demonstrate the framework's effectiveness, achieving 99.63\% accuracy on clean data and maintaining robust performance (exceeding 94\% accuracy) across diverse noisy environments, even at -10 dB Signal-to-Noise Ratio. The proposed framework work confirms that integrating efficient denoising with prototype-based continual learning enables KWS models to operate autonomously and robustly in resource-constrained, dynamic environments.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16158v1</guid></item><item><title>[cs updates on arXiv.org] CONTEX-T: Contextual Privacy Exploitation via Transformer Spectral Analysis for IoT Device Fingerprinting</title><link>https://arxiv.org/abs/2601.16160</link><description>arXiv:2601.16160v1 Announce Type: new 
Abstract: The rapid expansion of internet of things (IoT) devices have created a pervasive ecosystem where encrypted wireless communications serve as the primary privacy and security protection mechanism. While encryption effectively protects message content, packet metadata and statistics inadvertently expose device identities and user contexts. Various studies have exploited raw packet statistics and their visual representations for device fingerprinting and identification. However, these approaches remain confined to the spatial domain with limited feature representation. Therefore, this paper presents CONTEX-T, a novel framework that exploits contextual privacy vulnerabilities using spectral representation of encrypted wireless traffic for IoT device characterization. The experiments show that spectral analysis provides new and rich feature representation for covert reconnaissance attacks, revealing a complex and expanding threat landscape that would require robust countermeasures for IoT security management. CONTEXT-T first transforms raw packet length sequences into time-frequency spectral representations and then utilizes transformer-based spectral analysis for the device identification. We systematically evaluated multiple spectral representation techniques and transformer-based models across encrypted traffic samples from various IoT devices. CONTEXT-T effectively exploited privacy vulnerabilities and achieved device classification accuracy exceeding 99% across all devices while remaining completely passive and undetectable.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16160v1</guid></item><item><title>[cs updates on arXiv.org] Cosmos Policy: Fine-Tuning Video Models for Visuomotor Control and Planning</title><link>https://arxiv.org/abs/2601.16163</link><description>arXiv:2601.16163v1 Announce Type: new 
Abstract: Recent video generation models demonstrate remarkable ability to capture complex physical interactions and scene evolution over time. To leverage their spatiotemporal priors, robotics works have adapted video models for policy learning but introduce complexity by requiring multiple stages of post-training and new architectural components for action generation. In this work, we introduce Cosmos Policy, a simple approach for adapting a large pretrained video model (Cosmos-Predict2) into an effective robot policy through a single stage of post-training on the robot demonstration data collected on the target platform, with no architectural modifications. Cosmos Policy learns to directly generate robot actions encoded as latent frames within the video model's latent diffusion process, harnessing the model's pretrained priors and core learning algorithm to capture complex action distributions. Additionally, Cosmos Policy generates future state images and values (expected cumulative rewards), which are similarly encoded as latent frames, enabling test-time planning of action trajectories with higher likelihood of success. In our evaluations, Cosmos Policy achieves state-of-the-art performance on the LIBERO and RoboCasa simulation benchmarks (98.5% and 67.1% average success rates, respectively) and the highest average score in challenging real-world bimanual manipulation tasks, outperforming strong diffusion policies trained from scratch, video model-based policies, and state-of-the-art vision-language-action models fine-tuned on the same robot demonstrations. Furthermore, given policy rollout data, Cosmos Policy can learn from experience to refine its world model and value function and leverage model-based planning to achieve even higher success rates in challenging tasks. We release code, models, and training data at https://research.nvidia.com/labs/dir/cosmos-policy/</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16163v1</guid></item><item><title>[cs updates on arXiv.org] Tensor Reed-Muller Codes: Achieving Capacity with Quasilinear Decoding Time</title><link>https://arxiv.org/abs/2601.16164</link><description>arXiv:2601.16164v1 Announce Type: new 
Abstract: Define the codewords of the Tensor Reed-Muller code $\mathsf{TRM}(r_1,m_1;r_2,m_2;\dots;r_t,m_t)$ to be the evaluation vectors of all multivariate polynomials in the variables $\left\{x_{ij}\right\}_{i=1,\dots,t}^{j=1,\dots m_i}$ with degree at most $r_i$ in the variables $x_{i1},x_{i2},\dots,x_{im_i}$. The generator matrix of $\mathsf{TRM}(r_1,m_1;\dots;r_t,m_t)$ is thus the tensor product of the generator matrices of the Reed-Muller codes $\mathsf{RM}(r_1,m_1),\dots, \mathsf{RM}(r_t,m_t)$.
  We show that for any constant rate $R$ below capacity, one can construct a Tensor Reed-Muller code $\mathsf{TRM}(r_1,m_1;\dotsc;r_t,m_t)$ of rate $R$ that is decodable in quasilinear time. For any blocklength $n$, we provide two constructions of such codes:
  1) Our first construction (with $t=3$) has error probability $n^{-\omega(\log n)}$ and decoding time $O(n\log\log n)$.
  2) Our second construction, for any $t\geq 4$, has error probability $2^{-n^{\frac{1}{2}-\frac{1}{2(t-2)}-o(1)}}$ and decoding time $O(n\log n)$.
  One of our main tools is a polynomial-time algorithm for decoding an arbitrary tensor code $C=C_1\otimes\dotsc\otimes C_t$ from $\frac{d_{\min}(C)}{2\max\{d_{\min}(C_1),\dotsc,d_{\min}(C_t) \}}-1$ adversarial errors. Crucially, this algorithm does not require the codes $C_1,\dotsc,C_t$ to themselves be decodable in polynomial time.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16164v1</guid></item><item><title>[cs updates on arXiv.org] Scaling Sample-Based Quantum Diagonalization on GPU-Accelerated Systems using OpenMP Offload</title><link>https://arxiv.org/abs/2601.16169</link><description>arXiv:2601.16169v1 Announce Type: new 
Abstract: Hybrid quantum-HPC algorithms advance research by delegating complex tasks to quantum processors and using HPC systems to orchestrate workflows and complementary computations. Sample-based quantum diagonalization (SQD) is a hybrid quantum-HPC method in which information from a molecular Hamiltonian is encoded into a quantum circuit for evaluation on a quantum computer. A set of measurements on the quantum computer yields electronic configurations that are filtered on the classical computer, which also performs diagonalization on the selected subspace and identifies configurations to be carried over to the next step in an iterative process. Diagonalization is the most demanding task for the classical computer. Previous studies used the Fugaku supercomputer and a highly scalable diagonalization code designed for CPUs. In this work, we describe our efforts to enable efficient scalable and portable diagonalization on heterogeneous systems using GPUs as the main compute engines based on the previous work.
  GPUs provide massive on-device thread-level parallelism that is well aligned with the algorithms used for diagonalization. We focus on the computation of ground-state energies and wavefunctions using the Davidson algorithm with a selected set of electron configurations. We describe the offload strategy, code transformations, and data-movement, with examples of measurements on the Frontier supercomputer and five other GPU accelerated systems. Our measurements show that GPUs provide an outstanding performance boost of order 100x on a per-node basis. This dramatically expedites the diagonalization step-essential for extracting ground and excited state energies-bringing the classical processing time down from hours to minutes.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16169v1</guid></item><item><title>[cs updates on arXiv.org] Non-Linearly Separable Distributed Computing: A Sparse Tensor Factorization Approach</title><link>https://arxiv.org/abs/2601.16171</link><description>arXiv:2601.16171v1 Announce Type: new 
Abstract: The work considers the $N$-server distributed computing setting with $K$ users requesting functions that are arbitrary multi-variable polynomial evaluations of $L$ real (potentially non-linear) basis subfunctions. Our aim is to seek efficient task-allocation and data-communication techniques that reduce computation and communication costs. Towards this, we take a tensor-theoretic approach, in which we represent the requested non-linearly decomposable functions using a properly designed tensor $\bar{\mathcal{F}}$, whose sparse decomposition into a tensor $\bar{\mathcal{E}}$ and matrix $\mathbf{D}$ directly defines the task assignment, connectivity, and communication patterns. We here design an achievable scheme, employing novel fixed-support SVD-based tensor factorization methods and careful multi-dimensional tiling of subtensors, yielding computation and communication protocols whose costs are derived here, and which are shown to perform substantially better than the state of art.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16171v1</guid></item><item><title>[cs updates on arXiv.org] Structured Hints for Sample-Efficient Lean Theorem Proving</title><link>https://arxiv.org/abs/2601.16172</link><description>arXiv:2601.16172v1 Announce Type: new 
Abstract: State-of-the-art neural theorem provers like DeepSeek-Prover-V1.5 combine large language models with reinforcement learning, achieving impressive results through sophisticated training. We ask: do these highly-trained models still benefit from simple structural guidance at inference time? We evaluate a lightweight intervention -- a fixed prompt schedule over 15 common tactic skeletons -- on the miniF2F benchmark. This simple approach yields 21.7% pass@16 compared to 15.2% for standard sampling from the same model, a 43% relative improvement using the same number of samples (k=16) and same maximum generation length (1024 tokens). Our results suggest that even capable RL-trained provers underutilize structural priors available in the tactic language, and that simple inference-time guidance remains a cheap, complementary boost.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16172v1</guid></item><item><title>[cs updates on arXiv.org] Learning to Discover at Test Time</title><link>https://arxiv.org/abs/2601.16175</link><description>arXiv:2601.16175v1 Announce Type: new 
Abstract: How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems. Therefore, our learning objective and search subroutine are designed to prioritize the most promising solutions. We call this method Test-Time Training to Discover (TTT-Discover). Following prior work, we focus on problems with continuous rewards. We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erd\H{o}s' minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to $2\times$ faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers. All our results are achieved with an open model, OpenAI gpt-oss-120b, and can be reproduced with our publicly available code, in contrast to previous best results that required closed frontier models. Our test-time training runs are performed using Tinker, an API by Thinking Machines, with a cost of only a few hundred dollars per problem.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16175v1</guid></item><item><title>[cs updates on arXiv.org] Average Unfairness in Routing Games</title><link>https://arxiv.org/abs/2601.16187</link><description>arXiv:2601.16187v1 Announce Type: new 
Abstract: We propose average unfairness as a new measure of fairness in routing games, defined as the ratio between the average latency and the minimum latency experienced by users. This measure is a natural complement to two existing unfairness notions: loaded unfairness, which compares maximum and minimum latencies of routes with positive flow, and user equilibrium (UE) unfairness, which compares maximum latency with the latency of a Nash equilibrium. We show that the worst-case values of all three unfairness measures coincide and are characterized by a steepness parameter intrinsic to the latency function class. We show that average unfairness is always no greater than loaded unfairness, and the two measures are equal only when the flow is fully fair. Besides that, we offer a complete comparison of the three unfairness measures, which, to the best of our knowledge, is the first theoretical analysis in this direction. Finally, we study the constrained system optimum (CSO) problem, where one seeks to minimize total latency subject to an upper bound on unfairness. We prove that, for the same tolerance level, the optimal flow under an average unfairness constraint achieves lower total latency than any flow satisfying a loaded unfairness constraint. We show that such improvement is always strict in parallel-link networks and establish sufficient conditions for general networks. We further illustrate the latter with numerical examples. Our results provide theoretical guarantees and valuable insights for evaluating fairness-efficiency tradeoffs in network routing.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16187v1</guid></item><item><title>[cs updates on arXiv.org] 360Anything: Geometry-Free Lifting of Images and Videos to 360{\deg}</title><link>https://arxiv.org/abs/2601.16192</link><description>arXiv:2601.16192v1 Announce Type: new 
Abstract: Lifting perspective images and videos to 360{\deg} panoramas enables immersive 3D world generation. Existing approaches often rely on explicit geometric alignment between the perspective and the equirectangular projection (ERP) space. Yet, this requires known camera metadata, obscuring the application to in-the-wild data where such calibration is typically absent or noisy. We propose 360Anything, a geometry-free framework built upon pre-trained diffusion transformers. By treating the perspective input and the panorama target simply as token sequences, 360Anything learns the perspective-to-equirectangular mapping in a purely data-driven way, eliminating the need for camera information. Our approach achieves state-of-the-art performance on both image and video perspective-to-360{\deg} generation, outperforming prior works that use ground-truth camera information. We also trace the root cause of the seam artifacts at ERP boundaries to zero-padding in the VAE encoder, and introduce Circular Latent Encoding to facilitate seamless generation. Finally, we show competitive results in zero-shot camera FoV and orientation estimation benchmarks, demonstrating 360Anything's deep geometric understanding and broader utility in computer vision tasks. Additional results are available at https://360anything.github.io/.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16192v1</guid></item><item><title>[cs updates on arXiv.org] PAL*M: Property Attestation for Large Generative Models</title><link>https://arxiv.org/abs/2601.16199</link><description>arXiv:2601.16199v1 Announce Type: new 
Abstract: Machine learning property attestations allow provers (e.g., model providers or owners) to attest properties of their models/datasets to verifiers (e.g., regulators, customers), enabling accountability towards regulations and policies. But, current approaches do not support generative models or large datasets. We present PAL*M, a property attestation framework for large generative models, illustrated using large language models. PAL*M defines properties across training and inference, leverages confidential virtual machines with security-aware GPUs for coverage of CPU-GPU operations, and proposes using incremental multiset hashing over memory-mapped datasets to efficiently track their integrity. We implement PAL*M on Intel TDX and NVIDIA H100, showing it is efficient, scalable, versatile, and secure.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16199v1</guid></item><item><title>[cs updates on arXiv.org] Provable Robustness in Multimodal Large Language Models via Feature Space Smoothing</title><link>https://arxiv.org/abs/2601.16200</link><description>arXiv:2601.16200v1 Announce Type: new 
Abstract: Multimodal large language models (MLLMs) exhibit strong capabilities across diverse applications, yet remain vulnerable to adversarial perturbations that distort their feature representations and induce erroneous predictions. To address this vulnerability, we propose the Feature-space Smoothing (FS) and theoretically prove that FS offers certified robustness on the feature representations of MLLMs. Specifically, FS transforms any feature encoder into a smoothed variant that is guaranteed to maintain a certified lower bound on the feature cosine similarity between clean and adversarial representations under $\ell_2$-bounded attacks. Moreover, we indicate that the value of this Feature Cosine Similarity Bound (FCSB) derived from FS can be improved by enlarging the defined Gaussian robustness score on the vanilla encoder. Building upon this, we introduce the Purifier and Smoothness Mapper (PSM), a plug-and-play module that improves the Gaussian robustness score of MLLMs and thus enhances their certified robustness under FS, without requiring any retraining on MLLMs. We demonstrate that the FS with PSM not only provides a strong theoretical robustness guarantee but also exhibits superior empirical performance compared to adversarial training. Extensive experiments across diverse MLLMs and downstream tasks indicate the effectiveness of the FS-PSM, reducing the Attack Success Rate (ASR) of various white-box attacks from nearly 90\% to about 1\%.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16200v1</guid></item><item><title>[cs updates on arXiv.org] Counterfactual Training: Teaching Models Plausible and Actionable Explanations</title><link>https://arxiv.org/abs/2601.16205</link><description>arXiv:2601.16205v1 Announce Type: new 
Abstract: We propose a novel training regime termed counterfactual training that leverages counterfactual explanations to increase the explanatory capacity of models. Counterfactual explanations have emerged as a popular post-hoc explanation method for opaque machine learning models: they inform how factual inputs would need to change in order for a model to produce some desired output. To be useful in real-world decision-making systems, counterfactuals should be plausible with respect to the underlying data and actionable with respect to the feature mutability constraints. Much existing research has therefore focused on developing post-hoc methods to generate counterfactuals that meet these desiderata. In this work, we instead hold models directly accountable for the desired end goal: counterfactual training employs counterfactuals during the training phase to minimize the divergence between learned representations and plausible, actionable explanations. We demonstrate empirically and theoretically that our proposed method facilitates training models that deliver inherently desirable counterfactual explanations and additionally exhibit improved adversarial robustness.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16205v1</guid></item><item><title>[cs updates on arXiv.org] LLM-in-Sandbox Elicits General Agentic Intelligence</title><link>https://arxiv.org/abs/2601.16206</link><description>arXiv:2601.16206v1 Announce Type: new 
Abstract: We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox's efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16206v1</guid></item><item><title>[cs updates on arXiv.org] IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance</title><link>https://arxiv.org/abs/2601.16207</link><description>arXiv:2601.16207v1 Announce Type: new 
Abstract: Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model's built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16207v1</guid></item><item><title>[cs updates on arXiv.org] Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders</title><link>https://arxiv.org/abs/2601.16208</link><description>arXiv:2601.16208v1 Announce Type: new 
Abstract: Representation Autoencoders (RAEs) have shown distinct advantages in diffusion modeling on ImageNet by training in high-dimensional semantic latent spaces. In this work, we investigate whether this framework can scale to large-scale, freeform text-to-image (T2I) generation. We first scale RAE decoders on the frozen representation encoder (SigLIP-2) beyond ImageNet by training on web, synthetic, and text-rendering data, finding that while scale improves general fidelity, targeted data composition is essential for specific domains like text. We then rigorously stress-test the RAE design choices originally proposed for ImageNet. Our analysis reveals that scaling simplifies the framework: while dimension-dependent noise scheduling remains critical, architectural complexities such as wide diffusion heads and noise-augmented decoding offer negligible benefits at scale Building on this simplified framework, we conduct a controlled comparison of RAE against the state-of-the-art FLUX VAE across diffusion transformer scales from 0.5B to 9.8B parameters. RAEs consistently outperform VAEs during pretraining across all model scales. Further, during finetuning on high-quality datasets, VAE-based models catastrophically overfit after 64 epochs, while RAE models remain stable through 256 epochs and achieve consistently better performance. Across all experiments, RAE-based diffusion models demonstrate faster convergence and better generation quality, establishing RAEs as a simpler and stronger foundation than VAEs for large-scale T2I generation. Additionally, because both visual understanding and generation can operate in a shared representation space, the multimodal model can directly reason over generated latents, opening new possibilities for unified models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16208v1</guid></item><item><title>[cs updates on arXiv.org] PyraTok: Language-Aligned Pyramidal Tokenizer for Video Understanding and Generation</title><link>https://arxiv.org/abs/2601.16210</link><description>arXiv:2601.16210v1 Announce Type: new 
Abstract: Discrete video VAEs underpin modern text-to-video generation and video understanding systems, yet existing tokenizers typically learn visual codebooks at a single scale with limited vocabularies and shallow language supervision, leading to poor cross-modal alignment and zero-shot transfer. We introduce PyraTok, a language-aligned pyramidal tokenizer that learns semantically structured discrete latents across multiple spatiotemporal resolutions. PyraTok builds on a pretrained video VAE and a novel Language aligned Pyramidal Quantization (LaPQ) module that discretizes encoder features at several depths using a shared large binary codebook, yielding compact yet expressive video token sequences. To tightly couple visual tokens with language, PyraTok jointly optimizes multi-scale text-guided quantization and a global autoregressive objective over the token hierarchy. Across ten benchmarks, PyraTok delivers state-of-the-art (SOTA) video reconstruction, consistently improves text-to-video quality, and sets new SOTA zero-shot performance on video segmentation, temporal action localization, and video understanding, scaling robustly to up to 4K/8K resolutions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16210v1</guid></item><item><title>[cs updates on arXiv.org] Why Can't I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot Compositional Action Recognition</title><link>https://arxiv.org/abs/2601.16211</link><description>arXiv:2601.16211v1 Announce Type: new 
Abstract: We study Compositional Video Understanding (CVU), where models must recognize verbs and objects and compose them to generalize to unseen combinations. We find that existing Zero-Shot Compositional Action Recognition (ZS-CAR) models fail primarily due to an overlooked failure mode: object-driven verb shortcuts. Through systematic analysis, we show that this behavior arises from two intertwined factors: severe sparsity and skewness of compositional supervision, and the asymmetric learning difficulty between verbs and objects. As training progresses, the existing ZS-CAR model increasingly ignores visual evidence and overfits to co-occurrence statistics. Consequently, the existing model does not gain the benefit of compositional recognition in unseen verb-object compositions. To address this, we propose RCORE, a simple and effective framework that enforces temporally grounded verb learning. RCORE introduces (i) a composition-aware augmentation that diversifies verb-object combinations without corrupting motion cues, and (ii) a temporal order regularization loss that penalizes shortcut behaviors by explicitly modeling temporal structure. Across two benchmarks, Sth-com and our newly constructed EK100-com, RCORE significantly improves unseen composition accuracy, reduces reliance on co-occurrence bias, and achieves consistently positive compositional gaps. Our findings reveal object-driven shortcuts as a critical limiting factor in ZS-CAR and demonstrate that addressing them is essential for robust compositional video understanding.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16211v1</guid></item><item><title>[cs updates on arXiv.org] Point Bridge: 3D Representations for Cross Domain Policy Learning</title><link>https://arxiv.org/abs/2601.16212</link><description>arXiv:2601.16212v1 Announce Type: new 
Abstract: Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by the visual domain gap between simulation and reality. In this work, we present Point Bridge, a framework that leverages unified, domain-agnostic point-based representations to unlock synthetic datasets for zero-shot sim-to-real policy transfer, without explicit visual or object-level alignment. Point Bridge combines automated point-based representation extraction via Vision-Language Models (VLMs), transformer-based policy learning, and efficient inference-time pipelines to train capable real-world manipulation agents using only synthetic data. With additional co-training on small sets of real demonstrations, Point Bridge further improves performance, substantially outperforming prior vision-based sim-and-real co-training methods. It achieves up to 44% gains in zero-shot sim-to-real transfer and up to 66% with limited real data across both single-task and multitask settings. Videos of the robot are best viewed at: https://pointbridge3d.github.io/</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16212v1</guid></item><item><title>[cs updates on arXiv.org] CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback</title><link>https://arxiv.org/abs/2601.16214</link><description>arXiv:2601.16214v1 Announce Type: new 
Abstract: Recent advances in camera-controlled video diffusion models have significantly improved video-camera alignment. However, the camera controllability still remains limited. In this work, we build upon Reward Feedback Learning and aim to further improve camera controllability. However, directly borrowing existing ReFL approaches faces several challenges. First, current reward models lack the capacity to assess video-camera alignment. Second, decoding latent into RGB videos for reward computation introduces substantial computational overhead. Third, 3D geometric information is typically neglected during video decoding. To address these limitations, we introduce an efficient camera-aware 3D decoder that decodes video latent into 3D representations for reward quantization. Specifically, video latent along with the camera pose are decoded into 3D Gaussians. In this process, the camera pose not only acts as input, but also serves as a projection parameter. Misalignment between the video latent and camera pose will cause geometric distortions in the 3D structure, resulting in blurry renderings. Based on this property, we explicitly optimize pixel-level consistency between the rendered novel views and ground-truth ones as reward. To accommodate the stochastic nature, we further introduce a visibility term that selectively supervises only deterministic regions derived via geometric warping. Extensive experiments conducted on RealEstate10K and WorldScore benchmarks demonstrate the effectiveness of our proposed method. Project page: \href{https://a-bigbao.github.io/CamPilot/}{CamPilot Page}.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16214v1</guid></item><item><title>[cs updates on arXiv.org] Scalable Board Expansion within a General Game System</title><link>https://arxiv.org/abs/2601.16216</link><description>arXiv:2601.16216v1 Announce Type: new 
Abstract: This thesis explores the use of a General Game System (GGS) to support the automatic expansion of game boards in boardless games. Traditional implementations of such games often rely on oversized static boards defined from the start, even though large portions of these boards may never be used during gameplay. This approach leads to unnecessary complexity. To address this issue, this thesis propose a dynamic board expansion mechanism in which the game board grows automatically during play.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16216v1</guid></item><item><title>[cs updates on arXiv.org] Real-Time HAP-Assisted Vehicular Edge Computing for Rural Areas</title><link>https://arxiv.org/abs/2301.09957</link><description>arXiv:2301.09957v1 Announce Type: cross 
Abstract: Non-Terrestrial Networks (NTNs) are expected to be a key component of 6th generation (6G) networks to support broadband seamless Internet connectivity and expand the coverage even in rural and remote areas. In this context, High Altitude Platforms (HAPs) can act as edge servers to process computational tasks offloaded by energy-constrained terrestrial devices such as Internet of Things (IoT) sensors and ground vehicles (GVs). In this paper, we analyze the opportunity to support Vehicular Edge Computing (VEC) via HAP in a rural scenario where GVs can decide whether to process data onboard or offload them to a HAP. We characterize the system as a set of queues in which computational tasks arrive according to a Poisson arrival process. Then, we assess the optimal VEC offloading factor to maximize the probability of real-time service, given latency and computational capacity constraints.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2301.09957v1</guid></item><item><title>[cs updates on arXiv.org] Performance Evaluation of LoRa for IoT Applications in Non-Terrestrial Networks via ns-3</title><link>https://arxiv.org/abs/2509.02811</link><description>arXiv:2509.02811v1 Announce Type: cross 
Abstract: The integration of Internet of Things (IoT) and Non-Terrestrial Networks (NTNs) has emerged as a key paradigm to provide connectivity for sensors and actuators via satellite gateways in remote areas where terrestrial infrastructure is limited or unavailable. Among other Low-Power Wide-Area Network (LPWAN) technologies for IoT, Long Range (LoRa) holds great potential given its long range, energy efficiency, and flexibility. In this paper, we explore the feasibility and performance of LoRa to support large-scale IoT connectivity through Low Earth Orbit (LEO) satellite gateways. To do so, we developed a new ns3-LoRa-NTN simulation module, which integrates and extends the ns3-LoRa and ns3-NTN modules, to enable full-stack end-to-end simulation of satellite communication in LoRa networks. Our results, given in terms of average data rate and Packet Reception Ratio (PRR), confirm that LoRa can effectively support direct communication from the ground to LEO satellites, but network optimization is required to mitigate collision probability when end nodes use the same Spreading Factors (SFs) over long distances.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.02811v1</guid></item><item><title>[cs updates on arXiv.org] Ecosystem Competition and Cross-Market Subsidization: A Dynamic Theory of Platform Pricing</title><link>https://arxiv.org/abs/2601.15303</link><description>arXiv:2601.15303v1 Announce Type: cross 
Abstract: Platform giants in China have operated with persistently compressed margins in highly concentrated markets for much of the past decade, despite market shares exceeding 60\% in core segments. Standard theory predicts otherwise: either the weaker firm exits, or survivors raise prices to monopoly levels. We argue the puzzle dissolves once firms are viewed as ecosystem optimizers rather than single-market profit maximizers. We develop a dynamic game in which a firm's willingness to subsidize depends on the spillover value its users generate in adjacent markets -- what we call \textit{ecosystem complementarity}. When this complementarity is strong enough, perpetual below-cost pricing emerges as the unique stable equilibrium. The result is not predation in the classical sense; there is no recoupment phase. It is a permanent state of subsidized competition, rational for each firm individually but potentially inefficient in aggregate. We characterize the equilibrium, establish its dynamic stability, and show that welfare losses compound over time as capital flows into subsidy wars rather than innovation. The model's predictions are consistent with observed patterns in Chinese platform markets and suggest that effective antitrust intervention should target cross-market capital flows rather than prices.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15303v1</guid></item><item><title>[cs updates on arXiv.org] An Explainable Market Integrity Monitoring System with Multi-Source Attention Signals and Transparent Scoring</title><link>https://arxiv.org/abs/2601.15304</link><description>arXiv:2601.15304v1 Announce Type: cross 
Abstract: Market integrity monitoring is difficult because suspicious price/volume behavior can arise from many benign mechanisms, while modern detection systems often rely on opaque models that are hard to audit and communicate. We present AIMM-X, an explainable monitoring pipeline that combines market microstructure-style signals derived from OHLCV time series with multi-source public attention signals (e.g., news and online discussion proxies) to surface time windows that merit analyst review. The system detects candidate anomalous windows using transparent thresholding and aggregation, then assigns an interpretable integrity score decomposed into a small set of additive components, allowing practitioners to trace why a window was flagged and which factors drove the score. We provide an end-to-end, reproducible implementation that downloads data, constructs attention features, builds unified panels, detects windows, computes component signals, and generates summary figures/tables. Our goal is not to label manipulation, but to provide a practical, auditable screening tool that supports downstream investigation by compliance teams, exchanges, or researchers.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15304v1</guid></item><item><title>[cs updates on arXiv.org] Mind the Gap: Why Neural Memory Fails Under Semantic Density</title><link>https://arxiv.org/abs/2601.15313</link><description>arXiv:2601.15313v1 Announce Type: cross 
Abstract: The brain solves a problem that current AI architectures struggle to manage: storing specific episodic facts without corrupting general semantic knowledge. Neuroscience explains this through Complementary Learning Systems theory - a fast hippocampal system for episodic storage using pattern-separated representations, and a slow neocortical system for extracting statistical regularities. Current AI systems lack this separation, attempting both functions through neural weights alone. We identify the 'Stability Gap' in online neural memory: fast-weight mechanisms that write facts into shared continuous parameters collapse to near-random accuracy within tens of semantically related facts. Through semantic density (rho), we show collapse occurs with as few as N=5 facts at high density (rho &gt; 0.6) or N ~ 20-75 at moderate density - a phenomenon we formalise as the Orthogonality Constraint. This failure persists even with perfect attention and unlimited context, arising from write-time interference when storage and retrieval share the same substrate. We also identify schema drift and version ambiguity as primary failure modes in production systems, observing 40-70% schema consistency and 0-100% clean correction rates. Context-based memory incurs 30-300% cost premium over selective retrieval. We propose Knowledge Objects (KOs): discrete, typed memory units with controlled vocabularies and explicit version chains. Paired with neural weights, KOs enable a true complementary learning architecture, suggesting reliable AI memory may require this bicameral design.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15313v1</guid></item><item><title>[cs updates on arXiv.org] Beyond the Einstein-Bohr Debate: Cognitive Complementarity and the Emergence of Quantum Intuition</title><link>https://arxiv.org/abs/2601.15314</link><description>arXiv:2601.15314v1 Announce Type: cross 
Abstract: Recent high-precision experimental confirmations of quantum complementarity have revitalized foundational debates about measurement, description, and realism. This article argues that complementarity is most productively interpreted as an epistemic principle--constraining what can be simultaneously accessed and represented--rather than as an ontological claim about quantum reality. Reexamining the Einstein-Bohr debate through this lens reveals a persistent tension between descriptive completeness and contextual meaning, a tension experiments clarify but do not dissolve. Building on this analysis, we introduce cognitive complementarity as a structural principle governing reasoning under non-classical uncertainty, where mutually constraining representations cannot be jointly optimized. Within this framework, we propose quantum intuition as a testable cognitive capacity: the ability to sustain representational plurality, regulate commitment timing, and resolve perspective-incompatibilities in a context-sensitive manner. Formulated as a naturalistic construct grounded in shared informational constraints, quantum intuition offers a principled bridge between quantum measurement theory and cognition. This work reframes the historical debate, extends epistemic lessons from quantum foundations into cognitive science, and outlines empirical pathways for studying decision-making in contexts of irreducible uncertainty.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15314v1</guid></item><item><title>[cs updates on arXiv.org] The Impossibility of Cohesion Without Fragmentation</title><link>https://arxiv.org/abs/2601.15317</link><description>arXiv:2601.15317v1 Announce Type: cross 
Abstract: Most models in game theory and network formation implicitly assume that relations between agents are feasible whenever incentives are aligned or interaction opportunities exist. Under this premise analytical attention is directed toward equilibrium efficiency or probabilistic link formation while the possibility that a relation may be structurally infeasible is rarely examined. This paper develops a static axiomatic framework in which relation maintenance is treated as a problem of structural compatibility rather than strategic choice or stochastic realization. Agents occupy positions in an abstract space and relations are subject to minimum conditions defined over these positions. A bifurcation event such as a vote declaration or institutional assignment fixes agents positions and thereby determines which relations are compatible. We identify position dependent gain axes as the key source of structural selectivity and prove an impossibility result under any non degenerate positional constraint no bifurcation event can preserve all relations. Instead the post event network necessarily exhibits either the simultaneous emergence of fragmentation and cohesion or a degenerate trivial case in which constraints are position independent. The result is purely structural and does not rely on preferences beliefs incentives or dynamic adjustment. It establishes a fundamental limit on universally cohesive outcomes and reframes division not as a failure of design or coordination but as a logical consequence of positional constraints.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15317v1</guid></item><item><title>[cs updates on arXiv.org] Large Language Models as Simulative Agents for Neurodivergent Adult Psychometric Profiles</title><link>https://arxiv.org/abs/2601.15319</link><description>arXiv:2601.15319v1 Announce Type: cross 
Abstract: Adult neurodivergence, including Attention-Deficit/Hyperactivity Disorder (ADHD), high-functioning Autism Spectrum Disorder (ASD), and Cognitive Disengagement Syndrome (CDS), is marked by substantial symptom overlap that limits the discriminant sensitivity of standard psychometric instruments. While recent work suggests that Large Language Models (LLMs) can simulate human psychometric responses from qualitative data, it remains unclear whether they can accurately and stably model neurodevelopmental traits rather than broad personality characteristics. This study examines whether LLMs can generate psychometric responses that approximate those of real individuals when grounded in a structured qualitative interview, and whether such simulations are sensitive to variations in trait intensity. Twenty-six adults completed a 29-item open-ended interview and four standardized self-report measures (ASRS, BAARS-IV, AQ, RAADS-R). Two LLMs (GPT-4o and Qwen3-235B-A22B) were prompted to infer an individual psychological profile from interview content and then respond to each questionnaire in-role. Accuracy, reliability, and sensitivity were assessed using group-level comparisons, error metrics, exact-match scoring, and a randomized baseline. Both models outperformed random responses across instruments, with GPT-4o showing higher accuracy and reproducibility. Simulated responses closely matched human data for ASRS, BAARS-IV, and RAADS-R, while the AQ revealed subscale-specific limitations, particularly in Attention to Detail. Overall, the findings indicate that interview-grounded LLMs can produce coherent and above-chance simulations of neurodevelopmental traits, supporting their potential use as synthetic participants in early-stage psychometric research, while highlighting clear domain-specific constraints.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15319v1</guid></item><item><title>[cs updates on arXiv.org] ECGomics: An Open Platform for AI-ECG Digital Biomarker Discovery</title><link>https://arxiv.org/abs/2601.15326</link><description>arXiv:2601.15326v1 Announce Type: cross 
Abstract: Background: Conventional electrocardiogram (ECG) analysis faces a persistent dichotomy: expert-driven features ensure interpretability but lack sensitivity to latent patterns, while deep learning offers high accuracy but functions as a black box with high data dependency. We introduce ECGomics, a systematic paradigm and open-source platform for the multidimensional deconstruction of cardiac signals into digital biomarker. Methods: Inspired by the taxonomic rigor of genomics, ECGomics deconstructs cardiac activity across four dimensions: Structural, Intensity, Functional, and Comparative. This taxonomy synergizes expert-defined morphological rules with data-driven latent representations, effectively bridging the gap between handcrafted features and deep learning embeddings. Results: We operationalized this framework into a scalable ecosystem consisting of a web-based research platform and a mobile-integrated solution (https://github.com/PKUDigitalHealth/ECGomics). The web platform facilitates high-throughput analysis via precision parameter configuration, high-fidelity data ingestion, and 12-lead visualization, allowing for the systematic extraction of biomarkers across the four ECGomics dimensions. Complementarily, the mobile interface, integrated with portable sensors and a cloud-based engine, enables real-time signal acquisition and near-instantaneous delivery of structured diagnostic reports. This dual-interface architecture successfully transitions ECGomics from theoretical discovery to decentralized, real-world health management, ensuring professional-grade monitoring in diverse clinical and home-based settings. Conclusion: ECGomics harmonizes diagnostic precision, interpretability, and data efficiency. By providing a deployable software ecosystem, this paradigm establishes a robust foundation for digital biomarker discovery and personalized cardiovascular medicine.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15326v1</guid></item><item><title>[cs updates on arXiv.org] Learning Discrete Successor Transitions in Continuous Attractor Networks: Emergence, Limits, and Topological Constraints</title><link>https://arxiv.org/abs/2601.15336</link><description>arXiv:2601.15336v1 Announce Type: cross 
Abstract: Continuous attractor networks (CANs) are a well-established class of models for representing low-dimensional continuous variables such as head direction, spatial position, and phase. In canonical spatial domains, transitions along the attractor manifold are driven by continuous displacement signals, such as angular velocity-provided by sensorimotor systems external to the CAN itself. When such signals are not explicitly provided as dedicated displacement inputs, it remains unclear whether attractor-based circuits can reliably acquire recurrent dynamics that support stable state transitions, or whether alternative predictive strategies dominate.
  In this work, we present an experimental framework for training CANs to perform successor-like transitions between stable attractor states in the absence of externally provided displacement signals. We compare two recurrent topologies, a circular ring and a folded snake manifold, and systematically vary the temporal regime under which stability is evaluated. We find that, under short evaluation windows, networks consistently converge to impulse-driven associative solutions that achieve high apparent accuracy yet lack persistent attractor dynamics. Only when stability is explicitly enforced over extended free-run periods do genuine attractor-based transition dynamics emerge. This suggests that shortcut solutions are the default outcome of local learning in recurrent networks, while attractor dynamics represent a constrained regime rather than a generic result.
  Furthermore, we demonstrate that topology strictly limits the capacity for learned transitions. While the continuous ring topology achieves perfect stability over long horizons, the folded snake topology hits a geometric limit characterized by failure at manifold discontinuities, which neither curriculum learning nor basal ganglia-inspired gating can fully overcome.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15336v1</guid></item><item><title>[cs updates on arXiv.org] Learning Nonlinear Heterogeneity in Physical Kolmogorov-Arnold Networks</title><link>https://arxiv.org/abs/2601.15340</link><description>arXiv:2601.15340v1 Announce Type: cross 
Abstract: Physical neural networks typically train linear synaptic weights while treating device nonlinearities as fixed. We show the opposite - by training the synaptic nonlinearity itself, as in Kolmogorov-Arnold Network (KAN) architectures, we yield markedly higher task performance per physical resource and improved performance-parameter scaling than conventional linear weight-based networks, demonstrating ability of KAN topologies to exploit reconfigurable nonlinear physical dynamics.
  We experimentally realise physical KANs in silicon-on-insulator devices we term 'Synaptic Nonlinear Elements' (SYNEs), operating at room temperature, 0.1-1 microampere currents, and 2 MHz speeds with no observed degradation over 10^13 measurements and months-long timescales.
  We demonstrate nonlinear function regression, classification, and prediction of Li-Ion battery dynamics from noisy real-world multi-sensor data. Physical KANs outperform equivalently-parameterised software multilayer perceptron networks across all tasks, with up to two orders of magnitude fewer parameters, and two orders of magnitude fewer devices than linear weight based physical networks. These results establish learned physical nonlinearity as a hardware-native computational primitive for compact and efficient learning systems, and SYNE devices as effective substrates for heterogenous nonlinear computing.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15340v1</guid></item><item><title>[cs updates on arXiv.org] OmniSpectra: A Unified Foundation Model for Native Resolution Astronomical Spectra</title><link>https://arxiv.org/abs/2601.15351</link><description>arXiv:2601.15351v1 Announce Type: cross 
Abstract: We present OmniSpectra, the first native-resolution foundation model for astronomy spectra. Unlike traditional models, which are limited to fixed-length input sizes or configurations, OmniSpectra handles spectra of any length at their original size, without resampling or interpolation. Despite the large-scale spectroscopic data from diverse surveys fueling the rapid growth of astronomy, existing foundation models are limited to a fixed wavelength range and specific instruments. OmniSpectra is the first foundation model to learn simultaneously from multiple real-world spectra surveys with different configurations at a large scale. We achieve this by designing a novel architecture with adaptive patching across variable lengths, sinusoidal global wavelength encoding, local positional embeddings through depthwise convolution, and validity-aware self-attention masks. Allowing us to learn multi-scale spatial patterns while skipping attention for invalid patches. Even with a limited training example, OmniSpectra demonstrates excellent zero-shot generalization compared to methods tailored for specific tasks. This transfer learning capability makes this model the state-of-the-art across various astronomy tasks, including source classification, redshift estimation, and properties prediction for stars and galaxies. OmniSpectra reduces the need for training individual models for different tasks from scratch, establishing itself as the next-generation astronomy foundation model.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15351v1</guid></item><item><title>[cs updates on arXiv.org] Statistical Reinforcement Learning in the Real World: A Survey of Challenges and Future Directions</title><link>https://arxiv.org/abs/2601.15353</link><description>arXiv:2601.15353v1 Announce Type: cross 
Abstract: Reinforcement learning (RL) has achieved remarkable success in real-world decision-making across diverse domains, including gaming, robotics, online advertising, public health, and natural language processing. Despite these advances, a substantial gap remains between RL research and its deployment in many practical settings. Two recurring challenges often underlie this gap. First, many settings offer limited opportunity for the agent to interact extensively with the target environment due to practical constraints. Second, many target environments often undergo substantial changes, requiring redesign and redeployment of RL systems (e.g., advancements in science and technology that change the landscape of healthcare delivery). Addressing these challenges and bridging the gap between basic research and application requires theory and methodology that directly inform the design, implementation, and continual improvement of RL systems in real-world settings.
  In this paper, we frame the application of RL in practice as a three-component process: (i) online learning and optimization during deployment, (ii) post- or between-deployment offline analyses, and (iii) repeated cycles of deployment and redeployment to continually improve the RL system. We provide a narrative review of recent advances in statistical RL that address these components, including methods for maximizing data utility for between-deployment inference, enhancing sample efficiency for online learning within-deployment, and designing sequences of deployments for continual improvement. We also outline future research directions in statistical RL that are use-inspired -- aiming for impactful application of RL in practice.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15353v1</guid></item><item><title>[cs updates on arXiv.org] Q-Probe: Scaling Image Quality Assessment to High Resolution via Context-Aware Agentic Probing</title><link>https://arxiv.org/abs/2601.15356</link><description>arXiv:2601.15356v1 Announce Type: cross 
Abstract: Reinforcement Learning (RL) has empowered Multimodal Large Language Models (MLLMs) to achieve superior human preference alignment in Image Quality Assessment (IQA). However, existing RL-based IQA models typically rely on coarse-grained global views, failing to capture subtle local degradations in high-resolution scenarios. While emerging "Thinking with Images" paradigms enable multi-scale visual perception via zoom-in mechanisms, their direct adaptation to IQA induces spurious "cropping-implies-degradation" biases and misinterprets natural depth-of-field as artifacts. To address these challenges, we propose Q-Probe, the first agentic IQA framework designed to scale IQA to high resolution via context-aware probing. First, we construct Vista-Bench, a pioneering benchmark tailored for fine-grained local degradation analysis in high-resolution IQA settings. Furthermore, we propose a three-stage training paradigm that progressively aligns the model with human preferences, while simultaneously eliminating causal bias through a novel context-aware cropping strategy. Extensive experiments demonstrate that Q-Probe achieves state-of-the-art performance in high-resolution settings while maintaining superior efficacy across resolution scales.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15356v1</guid></item><item><title>[cs updates on arXiv.org] High-Fidelity 3D Tooth Reconstruction by Fusing Intraoral Scans and CBCT Data via a Deep Implicit Representation</title><link>https://arxiv.org/abs/2601.15358</link><description>arXiv:2601.15358v1 Announce Type: cross 
Abstract: High-fidelity 3D tooth models are essential for digital dentistry, but must capture both the detailed crown and the complete root. Clinical imaging modalities are limited: Cone-Beam Computed Tomography (CBCT) captures the root but has a noisy, low-resolution crown, while Intraoral Scanners (IOS) provide a high-fidelity crown but no root information. A naive fusion of these sources results in unnatural seams and artifacts. We propose a novel, fully-automated pipeline that fuses CBCT and IOS data using a deep implicit representation. Our method first segments and robustly registers the tooth instances, then creates a hybrid proxy mesh combining the IOS crown and the CBCT root. The core of our approach is to use this noisy proxy to guide a class-specific DeepSDF network. This optimization process projects the input onto a learned manifold of ideal tooth shapes, generating a seamless, watertight, and anatomically coherent model. Qualitative and quantitative evaluations show our method uniquely preserves both the high-fidelity crown from IOS and the patient-specific root morphology from CBCT, overcoming the limitations of each modality and naive stitching.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15358v1</guid></item><item><title>[cs updates on arXiv.org] Robust X-Learner: Breaking the Curse of Imbalance and Heavy Tails via Robust Cross-Imputation</title><link>https://arxiv.org/abs/2601.15360</link><description>arXiv:2601.15360v1 Announce Type: cross 
Abstract: Estimating Heterogeneous Treatment Effects (HTE) in industrial applications such as AdTech and healthcare presents a dual challenge: extreme class imbalance and heavy-tailed outcome distributions. While the X-Learner framework effectively addresses imbalance through cross-imputation, we demonstrate that it is fundamentally vulnerable to "Outlier Smearing" when reliant on Mean Squared Error (MSE) minimization. In this failure mode, the bias from a few extreme observations ("whales") in the minority group is propagated to the entire majority group during the imputation step, corrupting the estimated treatment effect structure. To resolve this, we propose the Robust X-Learner (RX-Learner). This framework integrates a redescending {\gamma}-divergence objective -- structurally equivalent to the Welsch loss under Gaussian assumptions -- into the gradient boosting machinery. We further stabilize the non-convex optimization using a Proxy Hessian strategy grounded in Majorization-Minimization (MM) principles. Empirical evaluation on a semi-synthetic Criteo Uplift dataset demonstrates that the RX-Learner reduces the Precision in Estimation of Heterogeneous Effect (PEHE) metric by 98.6% compared to the standard X-Learner, effectively decoupling the stable "Core" population from the volatile "Periphery".</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15360v1</guid></item><item><title>[cs updates on arXiv.org] USDs: A universal stabilizer decoder framework using symmetry</title><link>https://arxiv.org/abs/2601.15361</link><description>arXiv:2601.15361v1 Announce Type: cross 
Abstract: Quantum error correction is indispensable to achieving reliable quantum computation. When quantum information is encoded redundantly, a larger Hilbert space is constructed using multiple physical qubits, and the computation is performed within a designated subspace. When applying deep learning to the decoding of quantum error-correcting codes, a key challenge arises from the non-uniqueness between the syndrome measurements provided to the decoder and the corresponding error patterns that constitute the ground-truth labels. Building upon prior work that addressed this issue for the toric code by re-optimizing the decoder with respect to the symmetry inherent in the parity-check structure, we generalize this approach to arbitrary stabilizer codes. In our experiments, we employed multilayer perceptrons to approximate continuous functions that complement the syndrome measurements of the Color code and the Golay code. Using these models, we performed decoder re-optimization for each code. For the Color code, we achieved an improvement of approximately 0.8% in decoding accuracy at a physical error rate of 5%, while for the Golay code the accuracy increased by about 0.1%. Furthermore, from the evaluation of the geometric and algebraic structures in the continuous function approximation for each code, we showed that the design of generalized continuous functions is advantageous for learning the geometric structure inherent in the code. Our results also indicate that approximations that faithfully reproduce the code structure can have a significant impact on the effectiveness of reoptimization. This study demonstrates that the re-optimization technique previously shown to be effective for the Toric code can be generalized to address the challenge of label degeneracy that arises when applying deep learning to the decoding of stabilizer codes.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15361v1</guid></item><item><title>[cs updates on arXiv.org] Non-Stationary Functional Bilevel Optimization</title><link>https://arxiv.org/abs/2601.15363</link><description>arXiv:2601.15363v1 Announce Type: cross 
Abstract: Functional bilevel optimization (FBO) provides a powerful framework for hierarchical learning in function spaces, yet current methods are limited to static offline settings and perform suboptimally in online, non-stationary scenarios. We propose SmoothFBO, the first algorithm for non-stationary FBO with both theoretical guarantees and practical scalability. SmoothFBO introduces a time-smoothed stochastic hypergradient estimator that reduces variance through a window parameter, enabling stable outer-loop updates with sublinear regret. Importantly, the classical parametric bilevel case is a special reduction of our framework, making SmoothFBO a natural extension to online, non-stationary settings. Empirically, SmoothFBO consistently outperforms existing FBO methods in non-stationary hyperparameter optimization and model-based reinforcement learning, demonstrating its practical effectiveness. Together, these results establish SmoothFBO as a general, theoretically grounded, and practically viable foundation for bilevel optimization in online, non-stationary scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15363v1</guid></item><item><title>[cs updates on arXiv.org] OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation</title><link>https://arxiv.org/abs/2601.15369</link><description>arXiv:2601.15369v1 Announce Type: cross 
Abstract: This paper presents a family of advanced vision encoder, named OpenVision 3, that learns a single, unified visual representation that can serve both image understanding and image generation. Our core architecture is simple: we feed VAE-compressed image latents to a ViT encoder and train its output to support two complementary roles. First, the encoder output is passed to the ViT-VAE decoder to reconstruct the original image, encouraging the representation to capture generative structure. Second, the same representation is optimized with contrastive learning and image-captioning objectives, strengthening semantic features. By jointly optimizing reconstruction- and semantics-driven signals in a shared latent space, the encoder learns representations that synergize and generalize well across both regimes. We validate this unified design through extensive downstream evaluations with the encoder frozen. For multimodal understanding, we plug the encoder into the LLaVA-1.5 framework: it performs comparably with a standard CLIP vision encoder (e.g., 62.4 vs 62.2 on SeedBench, and 83.7 vs 82.9 on POPE). For generation, we test it under the RAE framework: ours substantially surpasses the standard CLIP-based encoder (e.g., gFID: 1.89 vs 2.54 on ImageNet). We hope this work can spur future research on unified modeling.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15369v1</guid></item><item><title>[cs updates on arXiv.org] ISAC-over-NTN: HAPS-UAV Framework for Post-Disaster Responsive 6G Networks</title><link>https://arxiv.org/abs/2601.15422</link><description>arXiv:2601.15422v1 Announce Type: cross 
Abstract: In disaster scenarios, ensuring both reliable communication and situational awareness becomes a critical challenge due to the partial or complete collapse of terrestrial networks. This paper proposes an integrated sensing and communication (ISAC) over non-terrestrial networks (NTN) architecture referred to as ISAC-over-NTN that integrates multiple uncrewed aerial vehicles (UAVs) and a high-altitude platform station (HAPS) to maintain resilient and reliable network operations in post-disaster conditions. We aim to achieve two main objectives: i) provide a reliable communication infrastructure, thereby ensuring the continuity of search-and-rescue activities and connecting people to their loved ones, and ii) detect users, such as those trapped under rubble or those who are mobile, using a Doppler-based mobility detection model. We employ an innovative beamforming method that simultaneously transmits data and detects Doppler-based mobility by integrating multi-user multiple-input multiple-output (MU-MIMO) communication and monostatic sensing within the same transmission chain. The results show that the proposed framework maintains reliable connectivity and achieves high detection accuracy of users in critical locations, reaching 90% motion detection sensitivity and 88% detection accuracy.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15422v1</guid></item><item><title>[cs updates on arXiv.org] Low-Dimensional Adaptation of Rectified Flow: A New Perspective through the Lens of Diffusion and Stochastic Localization</title><link>https://arxiv.org/abs/2601.15500</link><description>arXiv:2601.15500v1 Announce Type: cross 
Abstract: In recent years, Rectified flow (RF) has gained considerable popularity largely due to its generation efficiency and state-of-the-art performance. In this paper, we investigate the degree to which RF automatically adapts to the intrinsic low dimensionality of the support of the target distribution to accelerate sampling. We show that, using a carefully designed choice of the time-discretization scheme and with sufficiently accurate drift estimates, the RF sampler enjoys an iteration complexity of order $O(k/\varepsilon)$ (up to log factors), where $\varepsilon$ is the precision in total variation distance and $k$ is the intrinsic dimension of
  the target distribution. In addition, we show that the denoising diffusion probabilistic model (DDPM) procedure is equivalent to a stochastic version of RF by establishing a novel connection between these processes and stochastic localization. Building on this connection, we further design a stochastic RF sampler that also adapts to the low-dimensionality of the target distribution under milder requirements on the accuracy of the drift estimates, and also with a specific time schedule. We illustrate with simulations on the synthetic data and text-to-image data experiments the improved performance of the proposed samplers implementing the newly designed time-discretization schedules.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15500v1</guid></item><item><title>[cs updates on arXiv.org] Applicability and Limitation Analysis of PMU Data and Phasor Concept for Low- and High- Frequency Oscillations</title><link>https://arxiv.org/abs/2601.15529</link><description>arXiv:2601.15529v1 Announce Type: cross 
Abstract: Phasor Measurement Units (PMUs) convert high-speed waveform data into low-speed phasor data, which are fundamental to wide-area monitoring and control in power systems, with oscillation detection and localization among their most prominent applications. However, representing electrical waveform signals with oscillations using PMU phasors is effective only for low-frequency oscillations. This paper investigates the root causes of this limitation, focusing on errors introduced by Discrete Fourier Transform (DFT)-based signal processing, in addition to the attenuation effects of anti-aliasing filters, and the impact of low reporting rates. To better represent and estimate waveform signals with oscillations, we propose a more general signal model and a multi-step estimation method that leverages one-cycle DFT, the Matrix Pencil Method, and the Least Squares Method. Numerical experiments demonstrate the superior performance of the proposed signal model and estimation method. Furthermore, this paper reveals that the phasor concept, let alone PMU phasors, can become invalid for waveform signals with high-frequency oscillations characterized by asymmetric sub- and super-synchronous components. These findings highlight the fundamental limitations of PMU data and phasor concept, and emphasize the need to rely on waveform data for analyzing high-frequency oscillations in modern power systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15529v1</guid></item><item><title>[cs updates on arXiv.org] A Machine Vision Approach to Preliminary Skin Lesion Assessments</title><link>https://arxiv.org/abs/2601.15539</link><description>arXiv:2601.15539v1 Announce Type: cross 
Abstract: Early detection of malignant skin lesions is critical for improving patient outcomes in aggressive, metastatic skin cancers. This study evaluates a comprehensive system for preliminary skin lesion assessment that combines the clinically established ABCD rule of dermoscopy (analyzing Asymmetry, Borders, Color, and Dermoscopic Structures) with machine learning classification. Using a 1,000-image subset of the HAM10000 dataset, the system implements an automated, rule-based pipeline to compute a Total Dermoscopy Score (TDS) for each lesion. This handcrafted approach is compared against various machine learning solutions, including traditional classifiers (Logistic Regression, Random Forest, and SVM) and deep learning models. While the rule-based system provides high clinical interpretability, results indicate a performance bottleneck when reducing complex morphology to five numerical features. Experimental findings show that transfer learning with EfficientNet-B0 failed significantly due to domain shift between natural and medical images. In contrast, a custom three-layer Convolutional Neural Network (CNN) trained from scratch achieved 78.5% accuracy and 86.5% recall on median-filtered images, representing a 19-point accuracy improvement over traditional methods. The results demonstrate that direct pixel-level learning captures diagnostic patterns beyond handcrafted features and that purpose-built lightweight architectures can outperform large pretrained models for small, domain-specific medical datasets.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15539v1</guid></item><item><title>[cs updates on arXiv.org] Stabilizing Welfare-Maximizing Decisions via Endogenous Transfers</title><link>https://arxiv.org/abs/2601.15563</link><description>arXiv:2601.15563v1 Announce Type: cross 
Abstract: Many multiagent systems rely on collective decision-making among self-interested agents, which raises deep questions about coalition formation and stability. We study social choice with endogenous, outcome-contingent transfers, where agents voluntarily form contracts that redistribute utility depending on the collective decision, allowing fully strategic, incentive-aligned coalition formation. We show that under consensus rules, individually rational strong Nash equilibria (IR-SNE) always exist, implementing welfare-maximizing outcomes with feasible transfers, and provide a simple, efficient algorithm to construct them. For more general anonymous, monotonic, and resolute rules, we identify necessary conditions for profitable deviations, sharply limiting destabilizing coalitions. By bridging cooperative and noncooperative perspectives, our approach shows that transferable utility can achieve core-like stability, restoring efficiency and budget balance even where classical impossibility results apply. Overall, this framework offers a practical and robust way to coordinate large-scale strategic multiagent systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15563v1</guid></item><item><title>[cs updates on arXiv.org] FUGC: Benchmarking Semi-Supervised Learning Methods for Cervical Segmentation</title><link>https://arxiv.org/abs/2601.15572</link><description>arXiv:2601.15572v1 Announce Type: cross 
Abstract: Accurate segmentation of cervical structures in transvaginal ultrasound (TVS) is critical for assessing the risk of spontaneous preterm birth (PTB), yet the scarcity of labeled data limits the performance of supervised learning approaches. This paper introduces the Fetal Ultrasound Grand Challenge (FUGC), the first benchmark for semi-supervised learning in cervical segmentation, hosted at ISBI 2025. FUGC provides a dataset of 890 TVS images, including 500 training images, 90 validation images, and 300 test images. Methods were evaluated using the Dice Similarity Coefficient (DSC), Hausdorff Distance (HD), and runtime (RT), with a weighted combination of 0.4/0.4/0.2. The challenge attracted 10 teams with 82 participants submitting innovative solutions. The best-performing methods for each individual metric achieved 90.26\% mDSC, 38.88 mHD, and 32.85 ms RT, respectively. FUGC establishes a standardized benchmark for cervical segmentation, demonstrates the efficacy of semi-supervised methods with limited labeled data, and provides a foundation for AI-assisted clinical PTB risk assessment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15572v1</guid></item><item><title>[cs updates on arXiv.org] On the Nonasymptotic Scaling Guarantee of Hyperparameter Estimation in Inhomogeneous, Weakly-Dependent Complex Network Dynamical Systems</title><link>https://arxiv.org/abs/2601.15603</link><description>arXiv:2601.15603v1 Announce Type: cross 
Abstract: Hierarchical Bayesian models are increasingly used in large, inhomogeneous complex network dynamical systems by modeling parameters as draws from a hyperparameter-governed distribution. However, theoretical guarantees for these estimates as the system size grows have been lacking. A critical concern is that hyperparameter estimation may diverge for larger networks, undermining the model's reliability. Formulating the system's evolution in a measure transport perspective, we propose a theoretical framework for estimating hyperparameters with mean-type observations, which are prevalent in many scientific applications. Our primary contribution is a nonasymptotic bound for the deviation of estimate of hyperparameters in inhomogeneous complex network dynamical systems with respect to network population size, which is established for a general family of optimization algorithms within a fixed observation duration. While we firstly establish a consistency result for systems with independent nodes, our main result extends this guarantee to the more challenging and realistic setting of weakly-dependent nodes. We validate our theoretical findings with numerical experiments on two representative models: a Susceptible-Infected-Susceptible model and a Spiking Neuronal Network model. In both cases, the results confirm that the estimation error decreases as the network population size increases, aligning with our theoretical guarantees. This research proposes the foundational theory to ensure that hierarchical Bayesian methods are statistically consistent for large-scale inhomogeneous systems, filling a gap in this area of theoretical research and justifying their application in practice.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15603v1</guid></item><item><title>[cs updates on arXiv.org] Machine Failure Detection Based on Projected Quantum Models</title><link>https://arxiv.org/abs/2601.15641</link><description>arXiv:2601.15641v1 Announce Type: cross 
Abstract: Detecting machine failures promptly is of utmost importance in industry for maintaining efficiency and minimizing downtime. This paper introduces a failure detection algorithm based on quantum computing and a statistical change-point detection approach. Our method leverages the potential of projected quantum feature maps to enhance the precision of anomaly detection in machine monitoring systems. We empirically validate our approach on benchmark multi-dimensional time series datasets as well as on a real-world dataset comprising IoT sensor readings from operational machines, ensuring the practical relevance of our study. The algorithm was executed on IBM's 133-qubit Heron quantum processor, demonstrating the feasibility of integrating quantum computing into industrial maintenance procedures. The presented results underscore the effectiveness of our quantum-based failure detection system, showcasing its capability to accurately identify anomalies in noisy time series data. This work not only highlights the potential of quantum computing in industrial diagnostics but also paves the way for more sophisticated quantum algorithms in the realm of predictive maintenance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15641v1</guid></item><item><title>[cs updates on arXiv.org] A Stabilized Hybrid Active Noise Control Algorithm of GFANC and FxNLMS with Online Clustering</title><link>https://arxiv.org/abs/2601.15889</link><description>arXiv:2601.15889v1 Announce Type: cross 
Abstract: The Filtered-x Normalized Least Mean Square (FxNLMS) algorithm suffers from slow convergence and a risk of divergence, although it can achieve low steady-state errors after sufficient adaptation. In contrast, the Generative Fixed-Filter Active Noise Control (GFANC) method offers fast response speed, but its lack of adaptability may lead to large steady-state errors. This paper proposes a hybrid GFANC-FxNLMS algorithm to leverage the complementary advantages of both approaches. In the hybrid GFANC-FxNLMS algorithm, GFANC provides a frame-level control filter as an initialization for FxNLMS, while FxNLMS performs continuous adaptation at the sampling rate. Small variations in the GFANC-generated filter may repeatedly reinitialize FxNLMS, interrupting its adaptation process and destabilizing the system. An online clustering module is introduced to avoid unnecessary re-initializations and improve system stability. Simulation results show that the proposed algorithm achieves fast response, very low steady-state error, and high stability, requiring only one pre-trained broadband filter.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15889v1</guid></item><item><title>[cs updates on arXiv.org] Progressive Power Homotopy for Non-convex Optimization</title><link>https://arxiv.org/abs/2601.15915</link><description>arXiv:2601.15915v1 Announce Type: cross 
Abstract: We propose a novel first-order method for non-convex optimization of the form $\max_{\bm{w}\in\mathbb{R}^d}\mathbb{E}_{\bm{x}\sim\mathcal{D}}[f_{\bm{w}}(\bm{x})]$, termed Progressive Power Homotopy (Prog-PowerHP). The method applies stochastic gradient ascent to a surrogate objective obtained by first performing a power transformation and then Gaussian smoothing, $F_{N,\sigma}(\bm{\mu}):=\mathbb{E}_{\bm{w}\sim\mathcal{N}(\bm{\mu},\sigma^2I_d),\bm{x}\sim\mathcal{D}}[e^{Nf_w(\bm{x})}]$, while progressively increasing the power parameter $N$ and decreasing the smoothing scale $\sigma$ along the optimization trajectory. We prove that, under mild regularity conditions, Prog-PowerHP converges to a small neighborhood of the global optimum with an iteration complexity scaling nearly as $O(d^2\varepsilon^{-2})$. Empirically, Prog-PowerHP demonstrates clear advantages in phase retrieval when the samples-to-dimension ratio approaches the information-theoretic limit, and in training two-layer neural networks in under-parameterized regimes. These results suggest that Prog-PowerHP is particularly effective for navigating cluttered non-convex landscapes where standard first-order methods struggle.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15915v1</guid></item><item><title>[cs updates on arXiv.org] An Efficient Algorithm to Generate all Labeled Triangle-free Graphs with a given Graphical Degree Sequence</title><link>https://arxiv.org/abs/2601.15943</link><description>arXiv:2601.15943v1 Announce Type: cross 
Abstract: We extend our previous algorithm that generates all labeled graphs with a given graphical degree sequence to generate all labeled triangle-free graphs with a given graphical degree sequence. The algorithm uses various pruning techniques to avoid having to first generate all labeled realizations of the input sequence and then testing whether each labeled realization is triangle-free. It can be further extended to generate all labeled bipartite graphs with a given graphical degree sequence by adding a simple test whether each generated triangle-free realization is a bipartite graph. All output graphs are generated in the lexicographical ordering as in the original algorithm. The algorithms can also be easily parallelized.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15943v1</guid></item><item><title>[cs updates on arXiv.org] Performance Scaling Laws for PD Array-based Receivers in IM/DD Optical Wireless Communication Systems</title><link>https://arxiv.org/abs/2601.15973</link><description>arXiv:2601.15973v1 Announce Type: cross 
Abstract: We study the performance scaling laws for electrical-domain combining in photodetector (PD) array-based receivers employing intensity modulation and direct detection, taking into account the inherent square-law relationship between the optical and electrical received powers. The performance of PD array-based systems is compared, in terms of signal-to-noise ratio (SNR) and achievable rate, to that of a reference receiver employing a single PD. Analytical and numerical results show that PD arrays provide performance gains for sufficiently narrow beams and above an SNR threshold. Furthermore, increasing the number of PDs alone does not enhance performance, and joint optimization of beam pattern, transverse electromagnetic mode, received power, and PD positions is necessary. Our model and derived insights provide practical guidelines and highlight the trade-offs for the design of next-generation high-bandwidth PD array receivers.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15973v1</guid></item><item><title>[cs updates on arXiv.org] Time-Optimal Switching Surfaces for Triple Integrator under Full Box Constraints</title><link>https://arxiv.org/abs/2601.16003</link><description>arXiv:2601.16003v1 Announce Type: cross 
Abstract: Time-optimal control for triple integrator under full box constraints is a fundamental problem in the field of optimal control, which has been widely applied in the industry. However, scenarios involving asymmetric constraints, non-stationary boundary conditions, and active position constraints pose significant challenges. This paper provides a complete characterization of time-optimal switching surfaces for the problem, leading to novel insights into the geometric and algebraic structure of the optimal control. The active condition of position constraints is derived, which is absent from the literature. An efficient algorithm is proposed, capable of planning time-optimal trajectories under asymmetric full constraints and arbitrary boundary states, with a 100% success rate. Computational time for each trajectory is within approximately 10{\mu}s, achieving a 5-order-of-magnitude reduction compared to optimization-based baselines.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16003v1</guid></item><item><title>[cs updates on arXiv.org] Wigner's Friend as a Circuit: Inter-Branch Communication Witness Benchmarks on Superconducting Quantum Hardware</title><link>https://arxiv.org/abs/2601.16004</link><description>arXiv:2601.16004v1 Announce Type: cross 
Abstract: We implement and benchmark on IBM Quantum hardware the circuit family proposed by Violaris for estimating operational inter-branch communication witnesses, defined as correlations in classical measurement records produced by compiled Wigner's-friend-style circuits. We realize a five-qubit instance of the protocol as an inter-register message-transfer pattern within a single circuit, rather than physical signaling, and evaluate its behavior under realistic device noise and compilation constraints. The circuit encodes branch-conditioned evolution of an observer subsystem whose dynamics depend on a control qubit, followed by a controlled transfer operation that probes correlations between conditional measurement contexts.
  Executing on the ibm_fez backend with 20000 shots, we observe population-based visibility of 0.877, coherence witnesses of 0.840 and -0.811 along orthogonal axes, and a phase-sensitive magnitude of approximately 1.17. While the visibility metric is insensitive to some classes of dephasing, the coherence witnesses provide complementary sensitivity to off-diagonal noise.
  This work does not test or discriminate among interpretations of quantum mechanics. Instead, it provides a reproducible operational constraint pipeline for evaluating detectability of non-ideal channels relative to calibrated device noise.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16004v1</guid></item><item><title>[cs updates on arXiv.org] THOR: A Versatile Foundation Model for Earth Observation Climate and Society Applications</title><link>https://arxiv.org/abs/2601.16011</link><description>arXiv:2601.16011v1 Announce Type: cross 
Abstract: Current Earth observation foundation models are architecturally rigid, struggle with heterogeneous sensors and are constrained to fixed patch sizes. This limits their deployment in real-world scenarios requiring flexible computeaccuracy trade-offs. We propose THOR, a "computeadaptive" foundation model that solves both input heterogeneity and deployment rigidity. THOR is the first architecture to unify data from Copernicus Sentinel-1, -2, and -3 (OLCI &amp; SLSTR) satellites, processing their native 10 m to 1000 m resolutions in a single model. We pre-train THOR with a novel randomized patch and input image size strategy. This allows a single set of pre-trained weights to be deployed at inference with any patch size, enabling a dynamic trade-off between computational cost and feature resolution without retraining. We pre-train THOR on THOR Pretrain, a new, large-scale multi-sensor dataset and demonstrate state-of-the-art performance on downstream benchmarks, particularly in data-limited regimes like the PANGAEA 10% split, validating that THOR's flexible feature generation excels for diverse climate and society applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16011v1</guid></item><item><title>[cs updates on arXiv.org] Timbre-Aware LLM-based Direct Speech-to-Speech Translation Extendable to Multiple Language Pairs</title><link>https://arxiv.org/abs/2601.16023</link><description>arXiv:2601.16023v1 Announce Type: cross 
Abstract: Direct Speech-to-Speech Translation (S2ST) has gained increasing attention for its ability to translate speech from one language to another, while reducing error propagation and latency inherent in traditional cascaded pipelines. However, existing direct S2ST systems continue to face notable challenges, including instability in semantic-acoustic alignment when parallel speech data is scarce, difficulty in preserving speaker identity, and limited multilingual scalability. In this work, we introduce DS2ST-LM, a scalable, single-stage direct S2ST framework leveraging a multilingual Large Language Model (LLM). The architecture integrates a Whisper speech encoder, a learnable projection module, a Qwen2-0.5B LLM, and a timbre-controlled vocoder. We construct GigaS2S-1000, a 1000-hour bilingual corpus by extending the GigaST dataset with high-fidelity synthetic target speech, and show that this synthetic data alleviates data scarcity to some extent. We investigate two semantic token generation strategies: speech-derived S3 tokens and text-derived tokens generated by a pre-trained LLM, and analyze their impact on training stability and semantic consistency. We further evaluate three projection architectures (Linear, Conv1D-Linear, and Q-Former) and observe that while higher-capacity projectors converge faster, the simple Linear projector achieves higher performance. Extensive experiments demonstrate that DS2ST-LM outperforms traditional cascaded and ST (Qwen-Audio) + TTS baselines across both lexical (BLEU, METEOR) and semantic (BLEURT, COMET) metrics, while extending to multiple language pairs, including French, Spanish, German, Hindi, Bengali, and Urdu. Furthermore, we incorporate timbre-aware speech synthesis to preserve speaker information, enabling DS2ST-LM to surpass prior direct S2ST systems in both speaker similarity and perceptual naturalness.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16023v1</guid></item><item><title>[cs updates on arXiv.org] Risk reversal for least squares estimators under nested convex constraints</title><link>https://arxiv.org/abs/2601.16041</link><description>arXiv:2601.16041v1 Announce Type: cross 
Abstract: In constrained stochastic optimization, one naturally expects that imposing a stricter feasible set does not increase the statistical risk of an estimator defined by projection onto that set. In this paper, we show that this intuition can fail even in canonical settings.
  We study the Gaussian sequence model, a deliberately austere test best, where for a compact, convex set $\Theta \subset \mathbb{R}^d$ one observes \[ Y = \theta^\star + \sigma Z, \qquad Z \sim N(0, I_d), \] and seeks to estimate an unknown parameter $\theta^\star \in \Theta$. The natural estimator is the least squares estimator (LSE), which coincides with the Euclidean projection of $Y$ onto $\Theta$. We construct an explicit example exhibiting \emph{risk reversal}: for sufficiently large noise, there exist nested compact convex sets $\Theta_S \subset \Theta_L$ and a parameter $\theta^\star \in \Theta_S$ such that the LSE constrained to $\Theta_S$ has strictly larger risk than the LSE constrained to $\Theta_L$. We further show that this phenomenon can persist at the level of worst-case risk, with the supremum risk over the smaller constraint set exceeding that over the larger one.
  We clarify this behavior by contrasting noise regimes. In the vanishing-noise limit, the risk admits a first-order expansion governed by the statistical dimension of the tangent cone at $\theta^\star$, and tighter constraints uniformly reduce risk. In contrast, in the diverging-noise regime, the risk is determined by global geometric interactions between the constraint set and random noise directions. Here, the embedding of $\Theta_S$ within $\Theta_L$ can reverse the risk ordering.
  These results reveal a previously unrecognized failure mode of projection-based estimators: in sufficiently noisy settings, tightening a constraint can paradoxically degrade statistical performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16041v1</guid></item><item><title>[cs updates on arXiv.org] Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation</title><link>https://arxiv.org/abs/2601.16064</link><description>arXiv:2601.16064v1 Announce Type: cross 
Abstract: Deep learning has substantially advanced medical image segmentation, yet achieving robust generalization across diverse imaging modalities and anatomical structures remains a major challenge. A key contributor to this limitation lies in how existing architectures, ranging from CNNs to Transformers and their hybrids, primarily encode spatial information while overlooking frequency-domain representations that capture rich structural and textural cues. Although few recent studies have begun exploring spectral information at the feature level, supervision-level integration of frequency cues-crucial for fine-grained object localization-remains largely untapped. To this end, we propose Phi-SegNet, a CNN-based architecture that incorporates phase-aware information at both architectural and optimization levels. The network integrates Bi-Feature Mask Former (BFMF) modules that blend neighboring encoder features to reduce semantic gaps, and Reverse Fourier Attention (RFA) blocks that refine decoder outputs using phase-regularized features. A dedicated phase-aware loss aligns these features with structural priors, forming a closed feedback loop that emphasizes boundary precision. Evaluated on five public datasets spanning X-ray, US, histopathology, MRI, and colonoscopy, Phi-SegNet consistently achieved state-of-the-art performance, with an average relative improvement of 1.54+/-1.26% in IoU and 0.98+/-0.71% in F1-score over the next best-performing model. In cross-dataset generalization scenarios involving unseen datasets from the known domain, Phi-SegNet also exhibits robust and superior performance, highlighting its adaptability and modality-agnostic design. These findings demonstrate the potential of leveraging spectral priors in both feature representation and supervision, paving the way for generalized segmentation frameworks that excel in fine-grained object localization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16064v1</guid></item><item><title>[cs updates on arXiv.org] On damage of interpolation to adversarial robustness in regression</title><link>https://arxiv.org/abs/2601.16070</link><description>arXiv:2601.16070v1 Announce Type: cross 
Abstract: Deep neural networks (DNNs) typically involve a large number of parameters and are trained to achieve zero or near-zero training error. Despite such interpolation, they often exhibit strong generalization performance on unseen data, a phenomenon that has motivated extensive theoretical investigations. Comforting results show that interpolation indeed may not affect the minimax rate of convergence under the squared error loss. In the mean time, DNNs are well known to be highly vulnerable to adversarial perturbations in future inputs. A natural question then arises: Can interpolation also escape from suboptimal performance under a future $X$-attack? In this paper, we investigate the adversarial robustness of interpolating estimators in a framework of nonparametric regression. A finding is that interpolating estimators must be suboptimal even under a subtle future $X$-attack, and achieving perfect fitting can substantially damage their robustness. An interesting phenomenon in the high interpolation regime, which we term the curse of simple size, is also revealed and discussed. Numerical experiments support our theoretical findings.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16070v1</guid></item><item><title>[cs updates on arXiv.org] Synthetic Augmentation in Imbalanced Learning: When It Helps, When It Hurts, and How Much to Add</title><link>https://arxiv.org/abs/2601.16120</link><description>arXiv:2601.16120v1 Announce Type: cross 
Abstract: Imbalanced classification, where one class is observed far less frequently than the other, often causes standard training procedures to prioritize the majority class and perform poorly on rare but important cases. A classic and widely used remedy is to augment the minority class with synthetic examples, but two basic questions remain under-resolved: when does synthetic augmentation actually help, and how many synthetic samples should be generated?
  We develop a unified statistical framework for synthetic augmentation in imbalanced learning, studying models trained on imbalanced data augmented with synthetic minority samples and evaluated under the balanced population risk. Our theory shows that synthetic data is not always beneficial. In a ``local symmetry" regime, imbalance is not the dominant source of error near the balanced optimum, so adding synthetic samples cannot improve learning rates and can even degrade performance by amplifying generator mismatch. When augmentation can help (a ``local asymmetry" regime), the optimal synthetic size depends on generator accuracy and on whether the generator's residual mismatch is directionally aligned with the intrinsic majority-minority shift. This structure can make the best synthetic size deviate from naive full balancing, sometimes by a small refinement and sometimes substantially when generator bias is systematic. Practically, we recommend Validation-Tuned Synthetic Size (VTSS): select the synthetic size by minimizing balanced validation loss over a range centered near the fully balanced baseline, while allowing meaningful departures when the data indicate them. Simulations and a real sepsis prediction study support the theory and illustrate when synthetic augmentation helps, when it cannot, and how to tune its quantity effectively.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16120v1</guid></item></channel></rss>