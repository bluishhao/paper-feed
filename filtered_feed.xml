<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>My Customized Papers</title><link>https://github.com/your_username/your_repo</link><description>Aggregated research papers</description><language>en-US</language><lastBuildDate>Sun, 25 Jan 2026 18:23:57 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>[cs updates on arXiv.org] Agentic Persona Control and Task State Tracking for Realistic User Simulation in Interactive Scenarios</title><link>https://arxiv.org/abs/2601.15290</link><description>arXiv:2601.15290v1 Announce Type: new 
Abstract: Testing conversational AI systems at scale across diverse domains necessitates realistic and diverse user interactions capturing a wide array of behavioral patterns. We present a novel multi-agent framework for realistic, explainable human user simulation in interactive scenarios, using persona control and task state tracking to mirror human cognitive processes during goal-oriented conversations. Our system employs three specialized AI agents: (1) a User Agent to orchestrate the overall interaction, (2) a State Tracking Agent to maintain structured task state, and (3) a Message Attributes Generation Agent that controls conversational attributes based on task progress and assigned persona. To validate our approach, we implement and evaluate the framework for guest ordering at a restaurant with scenarios rich in task complexity, behavioral diversity, and conversational ambiguity. Through systematic ablations, we evaluate the contributory efficacy of each agentic component to overall simulation quality in terms of persona adherence, task completion accuracy, explainability, and realism. Our experiments demonstrate that the complete multi-agent system achieves superior simulation quality compared to single-LLM baselines, with significant gains across all evaluation metrics. This framework establishes a powerful environment for orchestrating agents to simulate human users with cognitive plausibility, decomposing the simulation into specialized sub-agents that reflect distinct aspects of human thought processes applicable across interactive domains.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15290v1</guid></item><item><title>[cs updates on arXiv.org] Public transport challenges and technology-assisted accessibility for visually impaired elderly residents in urban environments</title><link>https://arxiv.org/abs/2601.15291</link><description>arXiv:2601.15291v1 Announce Type: new 
Abstract: Independent navigation is a core aspect of maintaining social participation and individual health for vulnerable populations. While historic cities such as Edinburgh, as the capital of Scotland, often feature well-established public transport systems, urban accessibility challenges remain and are exacerbated by a complex landscape, especially for groups with multiple vulnerabilities such as the blind elderly. With limited research examining how real-time data feeds and developments in artificial intelligence can enhance navigation aids, we address this gap through a mixed-methods approach. Our work combines statistical and machine learning techniques, with a focus on spatial analysis to investigate network coverage, service patterns, and density through live Transport for Edinburgh data, with a qualitative thematic analysis of semi-structured interviews with the mentioned target group. The results demonstrate the highly centralised nature of the city's transport system, the significance of memory-based navigation, and the lack of travel information in usable formats. We also find that participants already use navigation technology to varying degrees and express a willingness to adopt artificial intelligence. Our analysis highlights the importance of dynamic tools in terms of sensory and cognitive needs to meaningfully improve independent travel.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15291v1</guid></item><item><title>[cs updates on arXiv.org] A Mobile Application Front-End for Presenting Explainable AI Results in Diabetes Risk Estimation</title><link>https://arxiv.org/abs/2601.15292</link><description>arXiv:2601.15292v1 Announce Type: new 
Abstract: Diabetes is a significant and continuously rising health challenge in Indonesia. Although many artificial intelligence (AI)-based health applications have been developed for early detection, most function as "black boxes," lacking transparency in their predictions. Explainable AI (XAI) methods offer a solution, yet their technical outputs are often incomprehensible to non-expert users. This research aims to develop a mobile application front-end that presents XAI-driven diabetes risk analysis in an intuitive, understandable format. Development followed the waterfall methodology, comprising requirements analysis, interface design, implementation, and evaluation. Based on user preference surveys, the application adopts two primary visualization types - bar charts and pie charts - to convey the contribution of each risk factor. These are complemented by personalized textual narratives generated via integration with GPT-4o. The application was developed natively for Android using Kotlin and Jetpack Compose. The resulting prototype interprets SHAP (SHapley Additive exPlanations), a key XAI approach, into accessible graphical visualizations and narratives. Evaluation through user comprehension testing (Likert scale and interviews) and technical functionality testing confirmed the research objectives were met. The combination of visualization and textual narrative effectively enhanced user understanding (average score 4.31/5) and empowered preventive action, supported by a 100% technical testing success rate.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15292v1</guid></item><item><title>[cs updates on arXiv.org] Social Robotics for Disabled Students: An Empirical Investigation of Embodiment, Roles and Interaction</title><link>https://arxiv.org/abs/2601.15293</link><description>arXiv:2601.15293v1 Announce Type: new 
Abstract: Institutional and social barriers in higher education often prevent students with disabilities from effectively accessing support, including lengthy procedures, insufficient information, and high social-emotional demands. This study empirically explores how disabled students perceive robot-based support, comparing two interaction roles, one information based (signposting) and one disclosure based (sounding board), and two embodiment types (physical robot/disembodied voice agent). Participants assessed these systems across five dimensions: perceived understanding, social energy demands, information access/clarity, task difficulty, and data privacy concerns. The main findings of the study reveal that the physical robot was perceived as more understanding than the voice-only agent, with embodiment significantly shaping perceptions of sociability, animacy, and privacy. We also analyse differences between disability types. These results provide critical insights into the potential of social robots to mitigate accessibility barriers in higher education, while highlighting ethical, social and technical challenges.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15293v1</guid></item><item><title>[cs updates on arXiv.org] KnowTeX: Visualizing Mathematical Dependencies</title><link>https://arxiv.org/abs/2601.15294</link><description>arXiv:2601.15294v1 Announce Type: new 
Abstract: Mathematical knowledge exists in many forms, ranging from informal textbooks and lecture notes to large formal proof libraries, yet moving between these representations remains difficult. Informal texts hide dependencies, while formal systems expose every detail in ways that are not always human-readable. Dependency graphs offer a middle ground by making visible the structure of results, definitions, and proofs. We present KnowTeX, a standalone, user-friendly tool that extends the ideas of Lean's Blueprints, enabling the visualization of conceptual dependencies directly from LaTeX sources. Using a simple "uses" command, KnowTeX extracts relationships among statements and generates previewable graphs in DOT and TikZ formats. Applied to mathematical texts, such graphs clarify core results, support education and formalization, and provide a resource for aligning informal and formal mathematical representations. We argue that dependency graphs should become a standard feature of mathematical writing, benefiting both human readers and automated systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15294v1</guid></item><item><title>[cs updates on arXiv.org] Elsewise: Authoring AI-Based Interactive Narrative with Possibility Space Visualization</title><link>https://arxiv.org/abs/2601.15295</link><description>arXiv:2601.15295v1 Announce Type: new 
Abstract: Interactive narrative (IN) authors craft spaces of divergent narrative possibilities for players to explore, with the player's input determining which narrative possibilities they actually experience. Generative AI can enable new forms of IN by improvisationally expanding on pre-authored content in response to open-ended player input. However, this extrapolation risks widening the gap between author-envisioned and player-experienced stories, potentially limiting the strength of plot progression and the communication of the author's narrative intent. To bridge the gap, we introduce Elsewise: an authoring tool for AI-based INs that implements a novel Bundled Storyline concept to enhance author's perception and understanding of the narrative possibility space, allowing authors to explore similarities and differences between possible playthroughs of their IN in terms of open-ended, user-configurable narrative dimensions. A user study (n=12) shows that our approach improves author anticipation of player-experienced narrative, leading to more effective control and exploration of the narrative possibility spaces.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15295v1</guid></item><item><title>[cs updates on arXiv.org] Entropy-Tree: Tree-Based Decoding with Entropy-Guided Exploration</title><link>https://arxiv.org/abs/2601.15296</link><description>arXiv:2601.15296v1 Announce Type: new 
Abstract: Large language models achieve strong reasoning performance, yet existing decoding strategies either explore blindly (random sampling) or redundantly (independent multi-sampling). We propose Entropy-Tree, a tree-based decoding method that exploits entropy as a signal for branching decisions--expanding the search tree only at positions where the model exhibits genuine uncertainty. Entropy-Tree shows superior accuracy and calibration in reasoning tasks: it achieves better pass@k than Multi-chain across multiple models and datasets, and its predictive entropy demonstrates better AUROC compared to several traditional metrics. Entropy-Tree unifies efficient structured exploration and reliable uncertainty estimation within a single decoding procedure.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15296v1</guid></item><item><title>[cs updates on arXiv.org] AfriEconQA: A Benchmark Dataset for African Economic Analysis based on World Bank Reports</title><link>https://arxiv.org/abs/2601.15297</link><description>arXiv:2601.15297v1 Announce Type: new 
Abstract: We introduce AfriEconQA, a specialized benchmark dataset for African economic analysis grounded in a comprehensive corpus of 236 World Bank reports. The task of AfriEconQA is to answer complex economic queries that require high-precision numerical reasoning and temporal disambiguation from specialized institutional documents. The dataset consists of 8,937 curated QA instances, rigorously filtered from a pool of 10018 synthetic questions to ensure high-quality evidence-answer alignment. Each instance is composed of: (1) a question requiring reasoning over economic indicators, (2) the corresponding evidence retrieved from the corpus, (3) a verified ground-truth answer, and (4) source metadata (e.g., URL and publication date) to ensure temporal provenance. AfriEconQA is the first benchmark focused specifically on African economic analysis, providing a unique challenge for Information Retrieval (IR) systems, as the data is largely absent from the pretraining corpora of current Large Language Models (LLMs). We operationalize this dataset through an 11-experiment matrix, benchmarking a zero-shot baseline (GPT-5 Mini) against RAG configurations using GPT-4o and Qwen 32B across five distinct embedding and ranking strategies. Our results demonstrate a severe parametric knowledge gap, where zero-shot models fail to answer over 90 percent of queries, and even state-of-the-art RAG pipelines struggle to achieve high precision. This confirms AfriEconQA as a robust and challenging benchmark for the next generation of domain-specific IR and RAG systems. The AfriEconQA dataset and code will be made publicly available upon publication.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15297v1</guid></item><item><title>[cs updates on arXiv.org] Embedding Retrofitting: Data Engineering for better RAG</title><link>https://arxiv.org/abs/2601.15298</link><description>arXiv:2601.15298v1 Announce Type: new 
Abstract: Embedding retrofitting adjusts pre-trained word vectors using knowledge graph constraints to improve domain-specific retrieval. However, the effectiveness of retrofitting depends critically on knowledge graph quality, which in turn depends on text preprocessing. This paper presents a data engineering framework that addresses data quality degradation from annotation artifacts in real-world corpora.
  The analysis shows that hashtag annotations inflate knowledge graph density, leading to creating spurious edges that corrupt the retrofitting objective. On noisy graphs, all retrofitting techniques produce statistically significant degradation ($-3.5\%$ to $-5.2\%$, $p&lt;0.05$). After preprocessing, \acrshort{ewma} retrofitting achieves $+6.2\%$ improvement ($p=0.0348$) with benefits concentrated in quantitative synthesis questions ($+33.8\%$ average). The gap between clean and noisy preprocessing (10\%+ swing) exceeds the gap between algorithms (3\%), establishing preprocessing quality as the primary determinant of retrofitting success.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15298v1</guid></item><item><title>[cs updates on arXiv.org] MALTopic: Multi-Agent LLM Topic Modeling Framework</title><link>https://arxiv.org/abs/2601.15299</link><description>arXiv:2601.15299v1 Announce Type: new 
Abstract: Topic modeling is a crucial technique for extracting latent themes from unstructured text data, particularly valuable in analyzing survey responses. However, traditional methods often only consider free-text responses and do not natively incorporate structured or categorical survey responses for topic modeling. And they produce abstract topics, requiring extensive human interpretation. To address these limitations, we propose the Multi-Agent LLM Topic Modeling Framework (MALTopic). This framework decomposes topic modeling into specialized tasks executed by individual LLM agents: an enrichment agent leverages structured data to enhance textual responses, a topic modeling agent extracts latent themes, and a deduplication agent refines the results. Comparative analysis on a survey dataset demonstrates that MALTopic significantly improves topic coherence, diversity, and interpretability compared to LDA and BERTopic. By integrating structured data and employing a multi-agent approach, MALTopic generates human-readable topics with enhanced contextual relevance, offering a more effective solution for analyzing complex survey data.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15299v1</guid></item><item><title>[cs updates on arXiv.org] Intelligence Degradation in Long-Context LLMs: Critical Threshold Determination via Natural Length Distribution Analysis</title><link>https://arxiv.org/abs/2601.15300</link><description>arXiv:2601.15300v1 Announce Type: new 
Abstract: Large Language Models (LLMs) exhibit catastrophic performance degradation when processing contexts approaching certain critical thresholds, even when information remains relevant. This intelligence degradation-defined as over 30% drop in task performance-severely limits long-context applications. This degradation shows a common pattern: models maintain strong performance up to a critical threshold, then collapse catastrophically. We term this shallow long-context adaptation-models adapt for short to medium contexts but fail beyond critical thresholds. This paper presents three contributions: (1) Natural Length Distribution Analysis: We use each sample's natural token length without truncation or padding, providing stronger causal evidence that degradation results from context length itself. (2) Critical Threshold Determination: Through experiments on a mixed dataset (1,000 samples covering 5%-95% of context length), we identify the critical threshold for Qwen2.5-7B at 40-50% of maximum context length, where F1 scores drop from 0.55-0.56 to 0.3 (45.5% degradation), using five-method cross-validation. (3) Unified Framework: We consolidate shallow adaptation, explaining degradation patterns and providing a foundation for mitigation strategies. This work provides the first systematic characterization of intelligence degradation in open-source Qwen models, offering practical guidance for deploying LLMs in long-context scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15300v1</guid></item><item><title>[cs updates on arXiv.org] Can We Trust LLM Detectors?</title><link>https://arxiv.org/abs/2601.15301</link><description>arXiv:2601.15301v1 Announce Type: new 
Abstract: The rapid adoption of LLMs has increased the need for reliable AI text detection, yet existing detectors often fail outside controlled benchmarks. We systematically evaluate 2 dominant paradigms (training-free and supervised) and show that both are brittle under distribution shift, unseen generators, and simple stylistic perturbations. To address these limitations, we propose a supervised contrastive learning (SCL) framework that learns discriminative style embeddings. Experiments show that while supervised detectors excel in-domain, they degrade sharply out-of-domain, and training-free methods remain highly sensitive to proxy choice. Overall, our results expose fundamental challenges in building domain-agnostic detectors. Our code is available at: https://github.com/HARSHITJAIS14/DetectAI</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15301v1</guid></item><item><title>[cs updates on arXiv.org] Gated Sparse Attention: Combining Computational Efficiency with Training Stability for Long-Context Language Models</title><link>https://arxiv.org/abs/2601.15305</link><description>arXiv:2601.15305v1 Announce Type: new 
Abstract: The computational burden of attention in long-context language models has motivated two largely independent lines of work: sparse attention mechanisms that reduce complexity by attending to selected tokens, and gated attention variants that improve training sta-bility while mitigating the attention sink phenomenon. We observe that these approaches address complementary weaknesses and propose Gated Sparse Attention (GSA), an architecture that realizes the benefits of both. GSA incorporates a gated lightning indexer with sigmoid activations that produce bounded, interpretable selection scores, an adaptive sparsity controller that modulates the number of attended tokens based on local uncertainty, and dual gating at the value and output stages. We establish theoretical foundations for the approach, including complexity analysis, expressiveness results, and convergence guarantees. In experiments with 1.7B parameter models trained on 400B tokens, GSA matches the efficiency of sparse-only baselines (12-16x speedup at 128K context) while achieving the quality gains associated with gated attention: perplexity improves from 6.03 to 5.70, RULER scores at 128K context nearly double, and attention to the first token, a proxy for attention sinks, drops from 47% to under 4%. Training stability improves markedly, with loss spikes reduced by 98%.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15305v1</guid></item><item><title>[cs updates on arXiv.org] Uncovering Latent Bias in LLM-Based Emergency Department Triage Through Proxy Variables</title><link>https://arxiv.org/abs/2601.15306</link><description>arXiv:2601.15306v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have enabled their integration into clinical decision-making; however, hidden biases against patients across racial, social, economic, and clinical backgrounds persist. In this study, we investigate bias in LLM-based medical AI systems applied to emergency department (ED) triage. We employ 32 patient-level proxy variables, each represented by paired positive and negative qualifiers, and evaluate their effects using both public (MIMIC-IV-ED Demo, MIMIC-IV Demo) and restricted-access credentialed (MIMIC-IV-ED and MIMIC-IV) datasets as appropriate~\cite{mimiciv_ed_demo,mimiciv_ed,mimiciv}. Our results reveal discriminatory behavior mediated through proxy variables in ED triage scenarios, as well as a systematic tendency for LLMs to modify perceived patient severity when specific tokens appear in the input context, regardless of whether they are framed positively or negatively. These findings indicate that AI systems is still imperfectly trained on noisy, sometimes non-causal signals that do not reliably reflect true patient acuity. Consequently, more needs to be done to ensure the safe and responsible deployment of AI technologies in clinical settings.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15306v1</guid></item><item><title>[cs updates on arXiv.org] DeepSurvey-Bench: Evaluating Academic Value of Automatically Generated Scientific Survey</title><link>https://arxiv.org/abs/2601.15307</link><description>arXiv:2601.15307v1 Announce Type: new 
Abstract: The rapid development of automated scientific survey generation technology has made it increasingly important to establish a comprehensive benchmark to evaluate the quality of generated surveys.Nearly all existing evaluation benchmarks rely on flawed selection criteria such as citation counts and structural coherence to select human-written surveys as the ground truth survey datasets, and then use surface-level metrics such as structural quality and reference relevance to evaluate generated surveys.However, these benchmarks have two key issues: (1) the ground truth survey datasets are unreliable because of a lack academic dimension annotations; (2) the evaluation metrics only focus on the surface quality of the survey such as logical coherence. Both issues lead to existing benchmarks cannot assess to evaluate their deep "academic value", such as the core research objectives and the critical analysis of different studies. To address the above problems, we propose DeepSurvey-Bench, a novel benchmark designed to comprehensively evaluate the academic value of generated surveys. Specifically, our benchmark propose a comprehensive academic value evaluation criteria covering three dimensions: informational value, scholarly communication value, and research guidance value. Based on this criteria, we construct a reliable dataset with academic value annotations, and evaluate the deep academic value of the generated surveys. Extensive experimental results demonstrate that our benchmark is highly consistent with human performance in assessing the academic value of generated surveys.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15307v1</guid></item><item><title>[cs updates on arXiv.org] When Generative AI Meets Extended Reality: Enabling Scalable and Natural Interactions</title><link>https://arxiv.org/abs/2601.15308</link><description>arXiv:2601.15308v1 Announce Type: new 
Abstract: Extended Reality (XR), including virtual, augmented, and mixed reality, provides immersive and interactive experiences across diverse applications, from VR-based education to AR-based assistance and MR-based training. However, widespread XR adoption remains limited due to two key challenges: 1) the high cost and complexity of authoring 3D content, especially for large-scale environments or complex interactions; and 2) the steep learning curve associated with non-intuitive interaction methods like handheld controllers or scripted gestures. Generative AI (GenAI) presents a promising solution by enabling intuitive, language-driven interaction and automating content generation. Leveraging vision-language models and diffusion-based generation, GenAI can interpret ambiguous instructions, understand physical scenes, and generate or manipulate 3D content, significantly lowering barriers to XR adoption. This paper explores the integration of XR and GenAI through three concrete use cases, showing how they address key obstacles in scalability and natural interaction, and identifying technical challenges that must be resolved to enable broader adoption.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15308v1</guid></item><item><title>[cs updates on arXiv.org] Aeon: High-Performance Neuro-Symbolic Memory Management for Long-Horizon LLM Agents</title><link>https://arxiv.org/abs/2601.15311</link><description>arXiv:2601.15311v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are fundamentally constrained by the quadratic computational cost of self-attention and the "Lost in the Middle" phenomenon, where reasoning capabilities degrade as context windows expand. Existing solutions, primarily "Flat RAG" architectures relying on vector databases, treat memory as an unstructured bag of embeddings. This approach fails to capture the hierarchical and temporal structure of long-horizon interactions, leading to "Vector Haze", the retrieval of disjointed facts lacking episodic continuity. We propose Aeon, a Neuro-Symbolic Cognitive Operating System that redefines memory not as a static store, but as a managed OS resource. Aeon structures memory into a Memory Palace (a spatial index implemented via Atlas, a SIMD-accelerated Page-Clustered Vector Index that combines small-world graph navigation with B+ Tree-style disk locality to minimize read amplification) and a Trace (a neuro-symbolic episodic graph). We introduce the Semantic Lookaside Buffer (SLB), a predictive caching mechanism that exploits conversational locality to achieve sub-millisecond retrieval latencies. Benchmarks demonstrate that Aeon achieves &lt; 1ms retrieval latency on conversational workloads while ensuring state consistency via a zero-copy C++/Python bridge, effectively enabling persistent, structured memory for autonomous agents.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15311v1</guid></item><item><title>[cs updates on arXiv.org] Do people expect different behavior from large language models acting on their behalf? Evidence from norm elicitations in two canonical economic games</title><link>https://arxiv.org/abs/2601.15312</link><description>arXiv:2601.15312v1 Announce Type: new 
Abstract: While delegating tasks to large language models (LLMs) can save people time, there is growing evidence that offloading tasks to such models produces social costs. We use behavior in two canonical economic games to study whether people have different expectations when decisions are made by LLMs acting on their behalf instead of themselves. More specifically, we study the social appropriateness of a spectrum of possible behaviors: when LLMs divide resources on our behalf (Dictator Game and Ultimatum Game) and when they monitor the fairness of splits of resources (Ultimatum Game). We use the Krupka-Weber norm elicitation task to detect shifts in social appropriateness ratings. Results of two pre-registered and incentivized experimental studies using representative samples from the UK and US (N = 2,658) show three key findings. First, people find that offers from machines - when no acceptance is necessary - are judged to be less appropriate than when they come from humans, although there is no shift in the modal response. Second - when acceptance is necessary - it is more appropriate for a person to reject offers from machines than from humans. Third, receiving a rejection of an offer from a machine is no less socially appropriate than receiving the same rejection from a human. Overall, these results suggest that people apply different norms for machines deciding on how to split resources but are not opposed to machines enforcing the norms. The findings are consistent with offers made by machines now being viewed as having both a cognitive and emotional component.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15312v1</guid></item><item><title>[cs updates on arXiv.org] The Paradigm Shift: A Comprehensive Survey on Large Vision Language Models for Multimodal Fake News Detection</title><link>https://arxiv.org/abs/2601.15316</link><description>arXiv:2601.15316v1 Announce Type: new 
Abstract: In recent years, the rapid evolution of large vision-language models (LVLMs) has driven a paradigm shift in multimodal fake news detection (MFND), transforming it from traditional feature-engineering approaches to unified, end-to-end multimodal reasoning frameworks. Early methods primarily relied on shallow fusion techniques to capture correlations between text and images, but they struggled with high-level semantic understanding and complex cross-modal interactions. The emergence of LVLMs has fundamentally changed this landscape by enabling joint modeling of vision and language with powerful representation learning, thereby enhancing the ability to detect misinformation that leverages both textual narratives and visual content. Despite these advances, the field lacks a systematic survey that traces this transition and consolidates recent developments. To address this gap, this paper provides a comprehensive review of MFND through the lens of LVLMs. We first present a historical perspective, mapping the evolution from conventional multimodal detection pipelines to foundation model-driven paradigms. Next, we establish a structured taxonomy covering model architectures, datasets, and performance benchmarks. Furthermore, we analyze the remaining technical challenges, including interpretability, temporal reasoning, and domain generalization. Finally, we outline future research directions to guide the next stage of this paradigm shift. To the best of our knowledge, this is the first comprehensive survey to systematically document and analyze the transformative role of LVLMs in combating multimodal fake news. The summary of existing methods mentioned is in our Github: \href{https://github.com/Tan-YiLong/Overview-of-Fake-News-Detection}{https://github.com/Tan-YiLong/Overview-of-Fake-News-Detection}.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15316v1</guid></item><item><title>[cs updates on arXiv.org] Replayable Financial Agents: A Determinism-Faithfulness Assurance Harness for Tool-Using LLM Agents</title><link>https://arxiv.org/abs/2601.15322</link><description>arXiv:2601.15322v1 Announce Type: new 
Abstract: LLM agents struggle with regulatory audit replay: when asked to reproduce a flagged transaction decision with identical inputs, most deployments fail to return consistent results. This paper introduces the Determinism-Faithfulness Assurance Harness (DFAH), a framework for measuring trajectory determinism and evidence-conditioned faithfulness in tool-using agents deployed in financial services.
  Across 74 configurations (12 models, 4 providers, 8-24 runs each at T=0.0) in non-agentic baseline experiments, 7-20B parameter models achieved 100% determinism, while 120B+ models required 3.7x larger validation samples to achieve equivalent statistical reliability. Agentic tool-use introduces additional variance (see Tables 4-7). Contrary to the assumed reliability-capability trade-off, a positive Pearson correlation emerged (r = 0.45, p &lt; 0.01, n = 51 at T=0.0) between determinism and faithfulness; models producing consistent outputs also tended to be more evidence-aligned.
  Three financial benchmarks are provided (compliance triage, portfolio constraints, DataOps exceptions; 50 cases each) along with an open-source stress-test harness. In these benchmarks and under DFAH evaluation settings, Tier 1 models with schema-first architectures achieved determinism levels consistent with audit replay requirements.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15322v1</guid></item><item><title>[cs updates on arXiv.org] Prometheus Mind: Retrofitting Memory to Frozen Language Models</title><link>https://arxiv.org/abs/2601.15324</link><description>arXiv:2601.15324v1 Announce Type: new 
Abstract: Adding memory to pretrained language models typically requires architectural changes or weight modification. We present Prometheus Mind, which retrofits memory to a frozen Qwen3-4B using 11 modular adapters (530MB, 7% overhead) -- fully reversible by removing the adapters. Building this system required solving four problems: (1) Extraction -- we develop Contrastive Direction Discovery (CDD), which finds semantic directions via minimal pairs without labeled data. (2) Training -- end-to-end optimization collapses; stage-wise training of each adapter on simple proxy tasks succeeds. (3) Injection -- learned encoders fail to generalize; we find that lm_head.weight rows already provide the mapping we need, requiring no training. (4) Hidden state collapse -- transformers make ``wife'' and ``brother'' 0.98+ similar; we train projections to recover distinction (0.98 $\rightarrow$ 0.09). On PrometheusExtract-132 (132 cases), the system achieves 94.4% retrieval on clean inputs (n=54, 95% CI: [84.9%, 98.1%]), degrading to 19.4% on informal inputs with ellipsis, filler words, or implicit subjects (n=36). The primary bottleneck is relation classification (47.3% accuracy), responsible for most extraction errors.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15324v1</guid></item><item><title>[cs updates on arXiv.org] Rules Create Unequal Rewards: Elite Tennis Players Allocate Resources Efficiently</title><link>https://arxiv.org/abs/2601.15327</link><description>arXiv:2601.15327v1 Announce Type: new 
Abstract: In many competitive settings, from education to politics, rules do not reward effort evenly, and thresholds (e.g., grade cutoffs or electoral majorities) make some moments disproportionately important. Success thus depends on efficiently allocating limited resources. However, empirical demonstration has been difficult because effort allocation is rarely observable and feedback is often delayed, limiting our understanding of expertise. Professional tennis provides an ideal natural experiment. Because each game resets after a player wins four points and points in a lost game are wasted, the value of a point varies sharply across scores. Efficient allocation should therefore win games without wasting points, conserving resources for future games. Such allocation manifests in score-dependent point-winning probabilities, from which we derive each player's Pareto frontier-the theoretical limit of the trade-off between game-winning probability and the expected points per game. Here, we show that top players operate closer to this frontier, converting points to game wins more efficiently. Optimal strategies reduce the probability of winning points when the player is far behind (e.g.,0-2, 0-3). This behavior is psychologically difficult-letting go of the current game-but represents a rational energy conservation strategy. Top players exhibit this pattern especially in return games, where winning points is harder than in service games, requiring them to drastically vary their efforts, consistent with game-theoretic predictions. These findings suggest that elite performance reflects efficient adaptation to rule-created value structures; knowing when to give up may be as fundamental to expertise as knowing when to compete.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15327v1</guid></item><item><title>[cs updates on arXiv.org] ICPO: Illocution-Calibrated Policy Optimization for Multi-Turn Conversation</title><link>https://arxiv.org/abs/2601.15330</link><description>arXiv:2601.15330v1 Announce Type: new 
Abstract: Large Language Models (LLMs) in multi-turn conversations often suffer from a ``lost-in-conversation'' phenomenon, where they struggle to recover from early incorrect assumptions, particularly when users provide ambiguous initial instructions. We find that standard post-training techniques like Reinforcement Learning with Verifiable Rewards (RLVR) exacerbate this issue by rewarding confident, direct answers, thereby inducing overconfidence and discouraging the model from seeking clarification. To address this, we propose Illocution-Calibrated Policy Optimization (ICPO), a novel training framework that sensitizes the model to instruction ambiguity. ICPO augments the training corpus with underspecified prompts and conditions the reward signal on the user's illocutionary intent, rewarding the model for expressing uncertainty or asking for clarification when faced with ambiguity. Experiments demonstrate that ICPO fosters appropriate humility, yielding a substantial average improvement of 75\% in multi-turn conversation, while preserving robust performance on single-turn benchmarks. Our work presents a practical path toward more robust and collaborative conversational AI that can better navigate the nuances of human interaction.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15330v1</guid></item><item><title>[cs updates on arXiv.org] RECAP: A Resource-Efficient Method for Adversarial Prompting in Large Language Models</title><link>https://arxiv.org/abs/2601.15331</link><description>arXiv:2601.15331v1 Announce Type: new 
Abstract: The deployment of large language models (LLMs) has raised security concerns due to their susceptibility to producing harmful or policy-violating outputs when exposed to adversarial prompts. While alignment and guardrails mitigate common misuse, they remain vulnerable to automated jailbreaking methods such as GCG, PEZ, and GBDA, which generate adversarial suffixes via training and gradient-based search. Although effective, these methods particularly GCG are computationally expensive, limiting their practicality for organisations with constrained resources. This paper introduces a resource-efficient adversarial prompting approach that eliminates the need for retraining by matching new prompts to a database of pre-trained adversarial prompts. A dataset of 1,000 prompts was classified into seven harm-related categories, and GCG, PEZ, and GBDA were evaluated on a Llama 3 8B model to identify the most effective attack method per category. Results reveal a correlation between prompt type and algorithm effectiveness. By retrieving semantically similar successful adversarial prompts, the proposed method achieves competitive attack success rates with significantly reduced computational cost. This work provides a practical framework for scalable red-teaming and security evaluation of aligned LLMs, including in settings where model internals are inaccessible.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15331v1</guid></item><item><title>[cs updates on arXiv.org] Empowering LLMs for Structure-Based Drug Design via Exploration-Augmented Latent Inference</title><link>https://arxiv.org/abs/2601.15333</link><description>arXiv:2601.15333v1 Announce Type: new 
Abstract: Large Language Models (LLMs) possess strong representation and reasoning capabilities, but their application to structure-based drug design (SBDD) is limited by insufficient understanding of protein structures and unpredictable molecular generation. To address these challenges, we propose Exploration-Augmented Latent Inference for LLMs (ELILLM), a framework that reinterprets the LLM generation process as an encoding, latent space exploration, and decoding workflow. ELILLM explicitly explores portions of the design problem beyond the model's current knowledge while using a decoding module to handle familiar regions, generating chemically valid and synthetically reasonable molecules. In our implementation, Bayesian optimization guides the systematic exploration of latent embeddings, and a position-aware surrogate model efficiently predicts binding affinity distributions to inform the search. Knowledge-guided decoding further reduces randomness and effectively imposes chemical validity constraints. We demonstrate ELILLM on the CrossDocked2020 benchmark, showing strong controlled exploration and high binding affinity scores compared with seven baseline methods. These results demonstrate that ELILLM can effectively enhance LLMs capabilities for SBDD.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15333v1</guid></item><item><title>[cs updates on arXiv.org] No Reliable Evidence of Self-Reported Sentience in Small Large Language Models</title><link>https://arxiv.org/abs/2601.15334</link><description>arXiv:2601.15334v1 Announce Type: new 
Abstract: Whether language models possess sentience has no empirical answer. But whether they believe themselves to be sentient can, in principle, be tested. We do so by querying several open-weights models about their own consciousness, and then verifying their responses using classifiers trained on internal activations. We draw upon three model families (Qwen, Llama, GPT-OSS) ranging from 0.6 billion to 70 billion parameters, approximately 50 questions about consciousness and subjective experience, and three classification methods from the interpretability literature. First, we find that models consistently deny being sentient: they attribute consciousness to humans but not to themselves. Second, classifiers trained to detect underlying beliefs - rather than mere outputs - provide no clear evidence that these denials are untruthful. Third, within the Qwen family, larger models deny sentience more confidently than smaller ones. These findings contrast with recent work suggesting that models harbour latent beliefs in their own consciousness.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15334v1</guid></item><item><title>[cs updates on arXiv.org] ToolCaching: Towards Efficient Caching for LLM Tool-calling</title><link>https://arxiv.org/abs/2601.15335</link><description>arXiv:2601.15335v1 Announce Type: new 
Abstract: Recent advances in Large Language Models (LLMs) have revolutionized web applications, enabling intelligent search, recommendation, and assistant services with natural language interfaces. Tool-calling extends LLMs with the ability to interact with external APIs, greatly enhancing their practical utility. While prior research has improved tool-calling performance by adopting traditional computer systems techniques, such as parallel and asynchronous execution, the challenge of redundant or repeated tool-calling requests remains largely unaddressed. Caching is a classic solution to this problem, but applying it to LLM tool-calling introduces new difficulties due to heterogeneous request semantics, dynamic workloads, and varying freshness requirements, which render conventional cache policies ineffective. To address these issues, we propose ToolCaching, an efficient feature-driven and adaptive caching framework for LLM tool-calling systems. ToolCaching systematically integrates semantic and system-level features to evaluate request cacheability and estimate caching value. At its core, the VAAC algorithm integrates bandit-based admission with value-driven, multi-factor eviction, jointly accounting for request frequency, recency, and caching value. Extensive experiments on synthetic and public tool-calling workloads demonstrate that ToolCaching with VAAC achieves up to 11% higher cache hit ratios and 34% lower latency compared to standard policies, effectively accelerating LLM tool-calling in practical applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15335v1</guid></item><item><title>[cs updates on arXiv.org] Language Models Entangle Language and Culture</title><link>https://arxiv.org/abs/2601.15337</link><description>arXiv:2601.15337v1 Announce Type: new 
Abstract: Users should not be systemically disadvantaged by the language they use for interacting with LLMs; i.e. users across languages should get responses of similar quality irrespective of language used. In this work, we create a set of real-world open-ended questions based on our analysis of the WildChat dataset and use it to evaluate whether responses vary by language, specifically, whether answer quality depends on the language used to query the model. We also investigate how language and culture are entangled in LLMs such that choice of language changes the cultural information and context used in the response by using LLM-as-a-Judge to identify the cultural context present in responses. To further investigate this, we evaluate LLMs on a translated subset of the CulturalBench benchmark across multiple languages. Our evaluations reveal that LLMs consistently provide lower quality answers to open-ended questions in low resource languages. We find that language significantly impacts the cultural context used by the model. This difference in context impacts the quality of the downstream answer.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15337v1</guid></item><item><title>[cs updates on arXiv.org] From Quotes to Concepts: Axial Coding of Political Debates with Ensemble LMs</title><link>https://arxiv.org/abs/2601.15338</link><description>arXiv:2601.15338v1 Announce Type: new 
Abstract: Axial coding is a commonly used qualitative analysis method that enhances document understanding by organizing sentence-level open codes into broader categories. In this paper, we operationalize axial coding with large language models (LLMs). Extending an ensemble-based open coding approach with an LLM moderator, we add an axial coding step that groups open codes into higher-order categories, transforming raw debate transcripts into concise, hierarchical representations. We compare two strategies: (i) clustering embeddings of code-utterance pairs using density-based and partitioning algorithms followed by LLM labeling, and (ii) direct LLM-based grouping of codes and utterances into categories. We apply our method to Dutch parliamentary debates, converting lengthy transcripts into compact, hierarchically structured codes and categories. We evaluate our method using extrinsic metrics aligned with human-assigned topic labels (ROUGE-L, cosine, BERTScore), and intrinsic metrics describing code groups (coverage, brevity, coherence, novelty, JSD divergence). Our results reveal a trade-off: density-based clustering achieves high coverage and strong cluster alignment, while direct LLM grouping results in higher fine-grained alignment, but lower coverage 20%. Overall, clustering maximizes coverage and structural separation, whereas LLM grouping produces more concise, interpretable, and semantically aligned categories. To support future research, we publicly release the full dataset of utterances and codes, enabling reproducibility and comparative studies.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15338v1</guid></item><item><title>[cs updates on arXiv.org] Lost in Transcription: How Speech-to-Text Errors Derail Code Understanding</title><link>https://arxiv.org/abs/2601.15339</link><description>arXiv:2601.15339v1 Announce Type: new 
Abstract: Code understanding is a foundational capability in software engineering tools and developer workflows. However, most existing systems are designed for English-speaking users interacting via keyboards, which limits accessibility in multilingual and voice-first settings, particularly in regions like India. Voice-based interfaces offer a more inclusive modality, but spoken queries involving code present unique challenges due to the presence of non-standard English usage, domain-specific vocabulary, and custom identifiers such as variable and function names, often combined with code-mixed expressions. In this work, we develop a multilingual speech-driven framework for code understanding that accepts spoken queries in a user native language, transcribes them using Automatic Speech Recognition (ASR), applies code-aware ASR output refinement using Large Language Models (LLMs), and interfaces with code models to perform tasks such as code question answering and code retrieval through benchmarks such as CodeSearchNet, CoRNStack, and CodeQA. Focusing on four widely spoken Indic languages and English, we systematically characterize how transcription errors impact downstream task performance. We also identified key failure modes in ASR for code and demonstrated that LLM-guided refinement significantly improves performance across both transcription and code understanding stages. Our findings underscore the need for code-sensitive adaptations in speech interfaces and offer a practical solution for building robust, multilingual voice-driven programming tools.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15339v1</guid></item><item><title>[cs updates on arXiv.org] Logic Programming on Knowledge Graph Networks And its Application in Medical Domain</title><link>https://arxiv.org/abs/2601.15347</link><description>arXiv:2601.15347v1 Announce Type: new 
Abstract: The rash development of knowledge graph research has brought big driving force to its application in many areas, including the medicine and healthcare domain. However, we have found that the application of some major information processing techniques on knowledge graph still lags behind. This defect includes the failure to make sufficient use of advanced logic reasoning, advanced artificial intelligence techniques, special-purpose programming languages, modern probabilistic and statistic theories et al. on knowledge graphs development and application. In particular, the multiple knowledge graphs cooperation and competition techniques have not got enough attention from researchers. This paper develops a systematic theory, technique and application of the concept 'knowledge graph network' and its application in medical and healthcare domain. Our research covers its definition, development, reasoning, computing and application under different conditions such as unsharp, uncertain, multi-modal, vectorized, distributed, federated. Almost in each case we provide (real data) examples and experiment results. Finally, a conclusion of innovation is provided.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15347v1</guid></item><item><title>[cs updates on arXiv.org] Abusive music and song transformation using GenAI and LLMs</title><link>https://arxiv.org/abs/2601.15348</link><description>arXiv:2601.15348v1 Announce Type: new 
Abstract: Repeated exposure to violence and abusive content in music and song content can influence listeners' emotions and behaviours, potentially normalising aggression or reinforcing harmful stereotypes. In this study, we explore the use of generative artificial intelligence (GenAI) and Large Language Models (LLMs) to automatically transform abusive words (vocal delivery) and lyrical content in popular music. Rather than simply muting or replacing a single word, our approach transforms the tone, intensity, and sentiment, thus not altering just the lyrics, but how it is expressed. We present a comparative analysis of four selected English songs and their transformed counterparts, evaluating changes through both acoustic and sentiment-based lenses. Our findings indicate that Gen-AI significantly reduces vocal aggressiveness, with acoustic analysis showing improvements in Harmonic to Noise Ratio, Cepstral Peak Prominence, and Shimmer. Sentiment analysis reduced aggression by 63.3-85.6\% across artists, with major improvements in chorus sections (up to 88.6\% reduction). The transformed versions maintained musical coherence while mitigating harmful content, offering a promising alternative to traditional content moderation that avoids triggering the "forbidden fruit" effect, where the censored content becomes more appealing simply because it is restricted. This approach demonstrates the potential for GenAI to create safer listening experiences while preserving artistic expression.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15348v1</guid></item><item><title>[cs updates on arXiv.org] Preparation and Motion Study of Magnetically Driven Micro Soft Robot Mimicking the Cownose Ray</title><link>https://arxiv.org/abs/2601.15349</link><description>arXiv:2601.15349v1 Announce Type: new 
Abstract: In narrow, unstructured underwater environments such as environmental monitoring and minimally invasive medical procedures, micro soft robots exhibit unique advantages due to their flexible movement capabilities and small size. At the same time, applying bionic technology to the structural design of micro soft robots can significantly improve their swimming performance. However, limited by their miniaturization, these robots are difficult to power internally and usually adopt a wireless power supply method. This study designs and fabricates a magnetically responsive, cownose ray-inspired micro soft robot based on the swimming principle of the cownose ray. The robot is made of a certain proportion of NdFeB and PDMS. Then, a three-dimensional Helmholtz coil is used to generate an oscillating harmonic magnetic field to conduct swimming experiments on the robot, exploring the influence of magnetic field parameters on the robot's swimming performance. The experimental results show that the swimming speed is the fastest at B = 5 mT and f = 11 Hz, reaching 5.25 mm/s, which is about 0.5 body lengths per second. In addition, by adjusting the current direction and frequency of the coil, the robot can perform different swimming modes such as straight swimming, turning swimming, and directional swimming. By employing a stepwise adjustment method, the impact of response errors on the robot's trajectory can be effectively reduced. This study demonstrates a method for magnetically driven micro soft robots, laying a foundation for the application of wireless-driven robots in underwater narrow spaces.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15349v1</guid></item><item><title>[cs updates on arXiv.org] A Prompt-Based Framework for Loop Vulnerability Detection Using Local LLMs</title><link>https://arxiv.org/abs/2601.15352</link><description>arXiv:2601.15352v1 Announce Type: new 
Abstract: Loop vulnerabilities are one major risky construct in software development. They can easily lead to infinite loops or executions, exhaust resources, or introduce logical errors that degrade performance and compromise security. The problem are often undetected by traditional static analyzers because such tools rely on syntactic patterns, which makes them struggle to detect semantic flaws. Consequently, Large Language Models (LLMs) offer new potential for vulnerability detection because of their ability to understand code contextually. Moreover, local LLMs unlike commercial ones like ChatGPT or Gemini addresses issues such as privacy, latency, and dependency concerns by facilitating efficient offline analysis. Consequently, this study proposes a prompt-based framework that utilize local LLMs for the detection of loop vulnerabilities within Python 3.7+ code. The framework targets three categories of loop-related issues, such as control and logic errors, security risks inside loops, and resource management inefficiencies. A generalized and structured prompt-based framework was designed and tested with two locally deployed LLMs (LLaMA 3.2; 3B and Phi 3.5; 4B) by guiding their behavior via iterative prompting. The designed prompt-based framework included key safeguarding features such as language-specific awareness, code-aware grounding, version sensitivity, and hallucination prevention. The LLM results were validated against a manually established baseline truth, and the results indicate that Phi outperforms LLaMA in precision, recall, and F1-score. The findings emphasize the importance of designing effective prompts for local LLMs to perform secure and accurate code vulnerability analysis.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15352v1</guid></item><item><title>[cs updates on arXiv.org] AI-Based Culvert-Sewer Inspection</title><link>https://arxiv.org/abs/2601.15366</link><description>arXiv:2601.15366v1 Announce Type: new 
Abstract: Culverts and sewer pipes are critical components of drainage systems, and their failure can lead to serious risks to public safety and the environment. In this thesis, we explore methods to improve automated defect segmentation in culverts and sewer pipes. Collecting and annotating data in this field is cumbersome and requires domain knowledge. Having a large dataset for structural defect detection is therefore not feasible. Our proposed methods are tested under conditions with limited annotated data to demonstrate applicability to real-world scenarios. Overall, this thesis proposes three methods to significantly enhance defect segmentation and handle data scarcity. This can be addressed either by enhancing the training data or by adjusting a models architecture.
  First, we evaluate preprocessing strategies, including traditional data augmentation and dynamic label injection. These techniques significantly improve segmentation performance, increasing both Intersection over Union (IoU) and F1 score. Second, we introduce FORTRESS, a novel architecture that combines depthwise separable convolutions, adaptive Kolmogorov-Arnold Networks (KAN), and multi-scale attention mechanisms. FORTRESS achieves state-of-the-art performance on the culvert sewer pipe defect dataset, while significantly reducing the number of trainable parameters, as well as its computational cost. Finally, we investigate few-shot semantic segmentation and its applicability to defect detection. Few-shot learning aims to train models with only limited data available. By employing a bidirectional prototypical network with attention mechanisms, the model achieves richer feature representations and achieves satisfactory results across evaluation metrics.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15366v1</guid></item><item><title>[cs updates on arXiv.org] Improving MoE Compute Efficiency by Composing Weight and Data Sparsity</title><link>https://arxiv.org/abs/2601.15370</link><description>arXiv:2601.15370v1 Announce Type: new 
Abstract: Mixture-of-Experts layers achieve compute efficiency through weight sparsity: each token activates only a subset of experts. Data sparsity, where each expert processes only a subset of tokens, offers a complementary axis. Expert-choice routing implements data sparsity directly but violates causality in autoregressive models, creating train-inference mismatch. We recover data sparsity within causal token-choice MoE by leveraging zero-compute (null) experts within the routing pool. When a token routes to null experts, those slots consume no compute. The standard load balancing objective trains the model to uniformly use all experts (real and null) therefore creating data sparsity in expectation without the causality violations. We evaluate on vision-language model training, where data heterogeneity is pronounced: vision encoders produce many low-information tokens while text tokens are denser. At matched expected FLOPs, composing weight and data sparsity yields a more compute-efficient frontier than weight sparsity alone, with gains in training loss and downstream performance. The model learns implicit modality-aware allocation, routing vision tokens to null experts more aggressively than text, without explicit modality routing.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15370v1</guid></item><item><title>[cs updates on arXiv.org] You Need Better Attention Priors</title><link>https://arxiv.org/abs/2601.15380</link><description>arXiv:2601.15380v1 Announce Type: new 
Abstract: We generalize the attention mechanism by viewing it through the lens of Entropic Optimal Transport, revealing that standard attention corresponds to a transport problem regularized by an implicit uniform prior. We introduce Generalized Optimal transport Attention with Trainable priors (GOAT), a new attention mechanism that replaces this naive assumption with a learnable, continuous prior. This prior maintains full compatibility with optimized kernels such as FlashAttention. GOAT also provides an EOT-based explanation of attention sinks and materializes a solution for them, avoiding the representational trade-offs of standard attention. Finally, by absorbing spatial information into the core attention computation, GOAT learns an extrapolatable prior that combines the flexibility of learned positional embeddings with the length generalization of fixed encodings.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15380v1</guid></item><item><title>[cs updates on arXiv.org] VegaChat: A Robust Framework for LLM-Based Chart Generation and Assessment</title><link>https://arxiv.org/abs/2601.15385</link><description>arXiv:2601.15385v1 Announce Type: new 
Abstract: Natural-language-to-visualization (NL2VIS) systems based on large language models (LLMs) have substantially improved the accessibility of data visualization. However, their further adoption is hindered by two coupled challenges: (i) the absence of standardized evaluation metrics makes it difficult to assess progress in the field and compare different approaches; and (ii) natural language descriptions are inherently underspecified, so multiple visualizations may be valid for the same query. To address these issues, we introduce VegaChat, a framework for generating, validating, and assessing declarative visualizations from natural language.
  We propose two complementary metrics: Spec Score, a deterministic metric that measures specification-level similarity without invoking an LLM, and Vision Score, a library-agnostic, image-based metric that leverages a multimodal LLM to assess chart similarity and prompt compliance.
  We evaluate VegaChat on the NLV Corpus and on the annotated subset of ChartLLM. VegaChat achieves near-zero rates of invalid or empty visualizations, while Spec Score and Vision Score exhibit strong correlation with human judgments (Pearson 0.65 and 0.71, respectively), indicating that the proposed metrics support consistent, cross-library comparison.
  The code and evaluation artifacts are available at https://zenodo.org/records/17062309.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15385v1</guid></item><item><title>[cs updates on arXiv.org] FedUMM: A General Framework for Federated Learning with Unified Multimodal Models</title><link>https://arxiv.org/abs/2601.15390</link><description>arXiv:2601.15390v1 Announce Type: new 
Abstract: Unified multimodal models (UMMs) are emerging as strong foundation models that can do both generation and understanding tasks in a single architecture. However, they are typically trained in centralized settings where all training and downstream datasets are gathered in a central server, limiting the deployment in privacy-sensitive and geographically distributed scenarios. In this paper, we present FedUMM, a general federated learning framework for UMMs under non-IID multimodal data with low communication cost. Built on NVIDIA FLARE, FedUMM instantiates federation for a BLIP3o backbone via parameter-efficient fine-tuning: clients train lightweight LoRA adapters while freezing the foundation models, and the server aggregates only adapter updates. We evaluate on VQA v2 and the GenEval compositional generation benchmarks under Dirichlet-controlled heterogeneity with up to 16 clients. Results show slight degradation as client count and heterogeneity increase, while remaining competitive with centralized training. We further analyze computation--communication trade-offs and demonstrate that adapter-only federation reduces per-round communication by over an order of magnitude compared to full fine-tuning, enabling practical federated UMM training. This work provides empirical experience for future research on privacy-preserving federated unified multimodal models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15390v1</guid></item><item><title>[cs updates on arXiv.org] GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation</title><link>https://arxiv.org/abs/2601.15392</link><description>arXiv:2601.15392v1 Announce Type: new 
Abstract: Biomedical research increasingly relies on integrating diverse data modalities, including gene expression profiles, medical images, and clinical metadata. While medical images and clinical metadata are routinely collected in clinical practice, gene expression data presents unique challenges for widespread research use, mainly due to stringent privacy regulations and costly laboratory experiments. To address these limitations, we present GeMM-GAN, a novel Generative Adversarial Network conditioned on histopathology tissue slides and clinical metadata, designed to synthesize realistic gene expression profiles. GeMM-GAN combines a Transformer Encoder for image patches with a final Cross Attention mechanism between patches and text tokens, producing a conditioning vector to guide a generative model in generating biologically coherent gene expression profiles. We evaluate our approach on the TCGA dataset and demonstrate that our framework outperforms standard generative models and generates more realistic and functionally meaningful gene expression profiles, improving by more than 11\% the accuracy on downstream disease type prediction compared to current state-of-the-art generative models. Code will be available at: https://github.com/francescapia/GeMM-GAN</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15392v1</guid></item><item><title>[cs updates on arXiv.org] Memorization Dynamics in Knowledge Distillation for Language Models</title><link>https://arxiv.org/abs/2601.15394</link><description>arXiv:2601.15394v1 Announce Type: new 
Abstract: Knowledge Distillation (KD) is increasingly adopted to transfer capabilities from large language models to smaller ones, offering significant improvements in efficiency and utility while often surpassing standard fine-tuning. Beyond performance, KD is also explored as a privacy-preserving mechanism to mitigate the risk of training data leakage. While training data memorization has been extensively studied in standard pre-training and fine-tuning settings, its dynamics in a knowledge distillation setup remain poorly understood. In this work, we study memorization across the KD pipeline using three large language model (LLM) families (Pythia, OLMo-2, Qwen-3) and three datasets (FineWeb, Wikitext, Nemotron-CC-v2). We find: (1) distilled models memorize significantly less training data than standard fine-tuning (reducing memorization by more than 50%); (2) some examples are inherently easier to memorize and account for a large fraction of memorization during distillation (over ~95%); (3) student memorization is predictable prior to distillation using features based on zlib entropy, KL divergence, and perplexity; and (4) while soft and hard distillation have similar overall memorization rates, hard distillation poses a greater risk: it inherits $2.7\times$ more teacher-specific examples than soft distillation. Overall, we demonstrate that distillation can provide both improved generalization and reduced memorization risks compared to standard fine-tuning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15394v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Fixed Psychological Personas: State Beats Trait, but Language Models are State-Blind</title><link>https://arxiv.org/abs/2601.15395</link><description>arXiv:2601.15395v1 Announce Type: new 
Abstract: User interactions with language models vary due to static properties of the user (trait) and the specific context of the interaction (state). However, existing persona datasets (like PersonaChat, PANDORA etc.) capture only trait, and ignore the impact of state. We introduce Chameleon, a dataset of 5,001 contextual psychological profiles from 1,667 Reddit users, each measured across multiple contexts. Using the Chameleon dataset, we present three key findings. First, inspired by Latent State-Trait theory, we decompose variance and find that 74\% is within-person(state) while only 26\% is between-person (trait). Second, we find that LLMs are state-blind: they focus on trait only, and produce similar responses regardless of state. Third, we find that reward models react to user state, but inconsistently: different models favor or penalize the same users in opposite directions. We release Chameleon to support research on affective computing, personalized dialogue, and RLHF alignment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15395v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Prompting: Efficient and Robust Contextual Biasing for Speech LLMs via Logit-Space Integration (LOGIC)</title><link>https://arxiv.org/abs/2601.15397</link><description>arXiv:2601.15397v1 Announce Type: new 
Abstract: The rapid emergence of new entities -- driven by cultural shifts, evolving trends, and personalized user data -- poses a significant challenge for existing Speech Large Language Models (Speech LLMs). While these models excel at general conversational tasks, their static training knowledge limits their ability to recognize domain-specific terms such as contact names, playlists, or technical jargon. Existing solutions primarily rely on prompting, which suffers from poor scalability: as the entity list grows, prompting encounters context window limitations, increased inference latency, and the "lost-in-the-middle" phenomenon. An alternative approach, Generative Error Correction (GEC), attempts to rewrite transcripts via post-processing but frequently suffers from "over-correction", introducing hallucinations of entities that were never spoken.
  In this work, we introduce LOGIC (Logit-Space Integration for Contextual Biasing), an efficient and robust framework that operates directly in the decoding layer. Unlike prompting, LOGIC decouples context injection from input processing, ensuring constant-time complexity relative to prompt length. Extensive experiments using the Phi-4-MM model across 11 multilingual locales demonstrate that LOGIC achieves an average 9% relative reduction in Entity WER with a negligible 0.30% increase in False Alarm Rate.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15397v1</guid></item><item><title>[cs updates on arXiv.org] Attention-Informed Surrogates for Navigating Power-Performance Trade-offs in HPC</title><link>https://arxiv.org/abs/2601.15399</link><description>arXiv:2601.15399v1 Announce Type: new 
Abstract: High-Performance Computing (HPC) schedulers must balance user performance with facility-wide resource constraints. The task boils down to selecting the optimal number of nodes for a given job. We present a surrogate-assisted multi-objective Bayesian optimization (MOBO) framework to automate this complex decision. Our core hypothesis is that surrogate models informed by attention-based embeddings of job telemetry can capture performance dynamics more effectively than standard regression techniques. We pair this with an intelligent sample acquisition strategy to ensure the approach is data-efficient. On two production HPC datasets, our embedding-informed method consistently identified higher-quality Pareto fronts of runtime-power trade-offs compared to baselines. Furthermore, our intelligent data sampling strategy drastically reduced training costs while improving the stability of the results. To our knowledge, this is the first work to successfully apply embedding-informed surrogates in a MOBO framework to the HPC scheduling problem, jointly optimizing for performance and power on production workloads.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15399v1</guid></item><item><title>[cs updates on arXiv.org] Multi-Input Ciphertext Multiplication for Homomorphic Encryption</title><link>https://arxiv.org/abs/2601.15401</link><description>arXiv:2601.15401v1 Announce Type: new 
Abstract: Homomorphic encryption (HE) enables arithmetic operations to be performed directly on encrypted data. It is essential for privacy-preserving applications such as machine learning, medical diagnosis, and financial data analysis. In popular HE schemes, ciphertext multiplication is only defined for two inputs. However, the multiplication of multiple inputs is needed in many HE applications. In our previous work, a three-input ciphertext multiplication method for the CKKS HE scheme was developed. This paper first reformulates the three-input ciphertext multiplication to enable the combination of computations in order to further reduce the complexity. The second contribution is extending the multiplication to multiple inputs without compromising the noise overhead. Additional evaluation keys are introduced to achieve relinearization of polynomial multiplication results. To minimize the complexity of the large number of rescaling units in the multiplier, a theoretical analysis is developed to relocate the rescaling, and a multi-level rescaling approach is proposed to implement combined rescaling with complexity similar to that of a single rescaling unit. Guidelines and examples are provided on the input partition to enable the combination of more rescaling. Additionally, efficient hardware architectures are designed to implement our proposed multipliers. The improved three-input ciphertext multiplier reduces the logic area and latency by 15% and 50%, respectively, compared to the best prior design. For multipliers with more inputs, ranging from 4 to 12, the architectural analysis reveals 32% savings in area and 45% shorter latency, on average, compared to prior work.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15401v1</guid></item><item><title>[cs updates on arXiv.org] Partially Polarized Polar Codes: A New Design for 6G Control Channels</title><link>https://arxiv.org/abs/2601.15404</link><description>arXiv:2601.15404v1 Announce Type: new 
Abstract: We introduce a new family of polar-like codes, called Partially Polarized Polar (PPP) codes. PPP codes are constructed from conventional polar codes by selectively pruning polarization kernels, thereby modifying the synthesized bit-channel capacities to ensure a guaranteed number of non-frozen bits available early in decoding. These early-access information bits enable more effective early termination, which is particularly valuable for blind decoding in downlink control channels, where user equipment (UE) must process multiple candidates, many of which carry no valid control information. Our results show that PPP codes offer substantial performance gains over conventional polar codes, particularly at larger block lengths where hardware limitations restrict straightforward scaling. Compared with existing methods such as aggregation or segmentation, PPP codes achieve higher efficiency without the need for additional hardware support. Finally, we propose several frozen-bitmap design strategies tailored to PPP codes.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15404v1</guid></item><item><title>[cs updates on arXiv.org] Evaluating Multimodal Large Language Models for Heterogeneous Face Recognition</title><link>https://arxiv.org/abs/2601.15406</link><description>arXiv:2601.15406v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) have recently demonstrated strong performance on a wide range of vision-language tasks, raising interest in their potential use for biometric applications. In this paper, we conduct a systematic evaluation of state-of-the-art MLLMs for heterogeneous face recognition (HFR), where enrollment and probe images are from different sensing modalities, including visual (VIS), near infrared (NIR), short-wave infrared (SWIR), and thermal camera. We benchmark multiple open-source MLLMs across several cross-modality scenarios, including VIS-NIR, VIS-SWIR, and VIS-THERMAL face recognition. The recognition performance of MLLMs is evaluated using biometric protocols and based on different metrics, including Acquire Rate, Equal Error Rate (EER), and True Accept Rate (TAR). Our results reveal substantial performance gaps between MLLMs and classical face recognition systems, particularly under challenging cross-spectral conditions, in spite of recent advances in MLLMs. Our findings highlight the limitations of current MLLMs for HFR and also the importance of rigorous biometric evaluation when considering their deployment in face recognition systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15406v1</guid></item><item><title>[cs updates on arXiv.org] CURE: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation</title><link>https://arxiv.org/abs/2601.15408</link><description>arXiv:2601.15408v1 Announce Type: new 
Abstract: Medical vision-language models can automate the generation of radiology reports but struggle with accurate visual grounding and factual consistency. Existing models often misalign textual findings with visual evidence, leading to unreliable or weakly grounded predictions. We present CURE, an error-aware curriculum learning framework that improves grounding and report quality without any additional data. CURE fine-tunes a multimodal instructional model on phrase grounding, grounded report generation, and anatomy-grounded report generation using public datasets. The method dynamically adjusts sampling based on model performance, emphasizing harder samples to improve spatial and textual alignment. CURE improves grounding accuracy by +0.37 IoU, boosts report quality by +0.188 CXRFEScore, and reduces hallucinations by 18.6%. CURE is a data-efficient framework that enhances both grounding accuracy and report reliability. Code is available at https://github.com/PabloMessina/CURE and model weights at https://huggingface.co/pamessina/medgemma-4b-it-cure</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15408v1</guid></item><item><title>[cs updates on arXiv.org] DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction</title><link>https://arxiv.org/abs/2601.15416</link><description>arXiv:2601.15416v1 Announce Type: new 
Abstract: Sparse-view Cone-Beam Computed Tomography reconstruction from limited X-ray projections remains a challenging problem in medical imaging due to the inherent undersampling of fine-grained anatomical details, which correspond to high-frequency components. Conventional CNN-based methods often struggle to recover these fine structures, as they are typically biased toward learning low-frequency information. To address this challenge, this paper presents DuFal (Dual-Frequency-Aware Learning), a novel framework that integrates frequency-domain and spatial-domain processing via a dual-path architecture. The core innovation lies in our High-Local Factorized Fourier Neural Operator, which comprises two complementary branches: a Global High-Frequency Enhanced Fourier Neural Operator that captures global frequency patterns and a Local High-Frequency Enhanced Fourier Neural Operator that processes spatially partitioned patches to preserve spatial locality that might be lost in global frequency analysis. To improve efficiency, we design a Spectral-Channel Factorization scheme that reduces the Fourier Neural Operator parameter count. We also design a Cross-Attention Frequency Fusion module to integrate spatial and frequency features effectively. The fused features are then decoded through a Feature Decoder to produce projection representations, which are subsequently processed through an Intensity Field Decoding pipeline to reconstruct a final Computed Tomography volume. Experimental results on the LUNA16 and ToothFairy datasets demonstrate that DuFal significantly outperforms existing state-of-the-art methods in preserving high-frequency anatomical features, particularly under extremely sparse-view settings.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15416v1</guid></item><item><title>[cs updates on arXiv.org] Ambient Dataloops: Generative Models for Dataset Refinement</title><link>https://arxiv.org/abs/2601.15417</link><description>arXiv:2601.15417v1 Announce Type: new 
Abstract: We propose Ambient Dataloops, an iterative framework for refining datasets that makes it easier for diffusion models to learn the underlying data distribution. Modern datasets contain samples of highly varying quality, and training directly on such heterogeneous data often yields suboptimal models. We propose a dataset-model co-evolution process; at each iteration of our method, the dataset becomes progressively higher quality, and the model improves accordingly. To avoid destructive self-consuming loops, at each generation, we treat the synthetically improved samples as noisy, but at a slightly lower noisy level than the previous iteration, and we use Ambient Diffusion techniques for learning under corruption. Empirically, Ambient Dataloops achieve state-of-the-art performance in unconditional and text-conditional image generation and de novo protein design. We further provide a theoretical justification for the proposed framework that captures the benefits of the data looping procedure.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15417v1</guid></item><item><title>[cs updates on arXiv.org] Learning a Unified Latent Space for Cross-Embodiment Robot Control</title><link>https://arxiv.org/abs/2601.15419</link><description>arXiv:2601.15419v1 Announce Type: new 
Abstract: We present a scalable framework for cross-embodiment humanoid robot control by learning a shared latent representation that unifies motion across humans and diverse humanoid platforms, including single-arm, dual-arm, and legged humanoid robots. Our method proceeds in two stages: first, we construct a decoupled latent space that captures localized motion patterns across different body parts using contrastive learning, enabling accurate and flexible motion retargeting even across robots with diverse morphologies. To enhance alignment between embodiments, we introduce tailored similarity metrics that combine joint rotation and end-effector positioning for critical segments, such as arms. Then, we train a goal-conditioned control policy directly within this latent space using only human data. Leveraging a conditional variational autoencoder, our policy learns to predict latent space displacements guided by intended goal directions. We show that the trained policy can be directly deployed on multiple robots without any adaptation. Furthermore, our method supports the efficient addition of new robots to the latent space by learning only a lightweight, robot-specific embedding layer. The learned latent policies can also be directly applied to the new robots. Experimental results demonstrate that our approach enables robust, scalable, and embodiment-agnostic robot control across a wide range of humanoid platforms.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15419v1</guid></item><item><title>[cs updates on arXiv.org] Problems with fixpoints of polynomials of polynomials</title><link>https://arxiv.org/abs/2601.15420</link><description>arXiv:2601.15420v1 Announce Type: new 
Abstract: Motivated by applications in computable analysis, we study fixpoints of certain endofunctors over categories of containers. More specifically, we focus on fibred endofunctors over the fibrewise opposite of the codomain fibration that can be themselves be represented by families of polynomial endofunctors. In this setting, we show how to compute initial algebras, terminal coalgebras and another kind of fixpoint $\zeta$. We then explore a number of examples of derived operators inspired by Weihrauch complexity and the usual construction of the free polynomial monad.
  We introduce $\zeta$-expressions as the syntax of $\mu$-bicomplete categories, extended with $\zeta$-binders and parallel products, which thus have a natural denotation in containers. By interpreting certain $\zeta$-expressions in a category of type 2 computable maps, we are able to capture a number of meaningful Weihrauch degrees, ranging from closed choice on $\{0, 1\}$ to determinacy of infinite parity games, via an "answerable part" operator.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15420v1</guid></item><item><title>[cs updates on arXiv.org] Lattice: A Confidence-Gated Hybrid System for Uncertainty-Aware Sequential Prediction with Behavioral Archetypes</title><link>https://arxiv.org/abs/2601.15423</link><description>arXiv:2601.15423v1 Announce Type: new 
Abstract: We introduce Lattice, a hybrid sequential prediction system that conditionally activates learned behavioral structure using binary confidence gating. The system clusters behavior windows into behavioral archetypes and uses binary confidence gating to activate archetype-based scoring only when confidence exceeds a threshold, falling back to baseline predictions when uncertain. We validate Lattice on recommendation systems (MovieLens), scientific time-series (LIGO), and financial markets, using LSTM and transformer backbones. On MovieLens with LSTM, Lattice achieves +31.9% improvement over LSTM baseline in HR@10 (p &lt; 3.29 x 10^-25, 30 seeds), outperforming transformer baselines by 109.4% over SASRec and 218.6% over BERT4Rec. On LIGO and financial data, the system correctly refuses archetype activation when distribution shift occurs - a successful outcome demonstrating confidence gating prevents false activation. On transformer backbones, Lattice provides 0.0% improvement (neutral, no degradation), gracefully deferring when structure is already present. This bidirectional validation - activating when patterns apply, refusing when they don't, and deferring when redundant - supports confidence gating as a promising architectural principle for managing epistemic uncertainty in safety-critical applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15423v1</guid></item><item><title>[cs updates on arXiv.org] Domain-Specific Knowledge Graphs in RAG-Enhanced Healthcare LLMs</title><link>https://arxiv.org/abs/2601.15429</link><description>arXiv:2601.15429v1 Announce Type: new 
Abstract: Large Language Models (LLMs) generate fluent answers but can struggle with trustworthy, domain-specific reasoning. We evaluate whether domain knowledge graphs (KGs) improve Retrieval-Augmented Generation (RAG) for healthcare by constructing three PubMed-derived graphs: $\mathbb{G}_1$ (T2DM), $\mathbb{G}_2$ (Alzheimer's disease), and $\mathbb{G}_3$ (AD+T2DM). We design two probes: Probe 1 targets merged AD T2DM knowledge, while Probe 2 targets the intersection of $\mathbb{G}_1$ and $\mathbb{G}_2$. Seven instruction-tuned LLMs are tested across retrieval sources {No-RAG, $\mathbb{G}_1$, $\mathbb{G}_2$, $\mathbb{G}_1$ + $\mathbb{G}_2$, $\mathbb{G}_3$, $\mathbb{G}_1$+$\mathbb{G}_2$ + $\mathbb{G}_3$} and three decoding temperatures. Results show that scope alignment between probe and KG is decisive: precise, scope-matched retrieval (notably $\mathbb{G}_2$) yields the most consistent gains, whereas indiscriminate graph unions often introduce distractors that reduce accuracy. Larger models frequently match or exceed KG-RAG with a No-RAG baseline on Probe 1, indicating strong parametric priors, whereas smaller/mid-sized models benefit more from well-scoped retrieval. Temperature plays a secondary role; higher values rarely help. We conclude that precision-first, scope-matched KG-RAG is preferable to breadth-first unions, and we outline practical guidelines for graph selection, model sizing, and retrieval/reranking. Code and Data available here - https://github.com/sydneyanuyah/RAGComparison</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15429v1</guid></item><item><title>[cs updates on arXiv.org] SplatBus: A Gaussian Splatting Viewer Framework via GPU Interprocess Communication</title><link>https://arxiv.org/abs/2601.15431</link><description>arXiv:2601.15431v1 Announce Type: new 
Abstract: Radiance field-based rendering methods have attracted significant interest from the computer vision and computer graphics communities. They enable high-fidelity rendering with complex real-world lighting effects, but at the cost of high rendering time. 3D Gaussian Splatting solves this issue with a rasterisation-based approach for real-time rendering, enabling applications such as autonomous driving, robotics, virtual reality, and extended reality. However, current 3DGS implementations are difficult to integrate into traditional mesh-based rendering pipelines, which is a common use case for interactive applications and artistic exploration. To address this limitation, this software solution uses Nvidia's interprocess communication (IPC) APIs to easily integrate into implementations and allow the results to be viewed in external clients such as Unity, Blender, Unreal Engine, and OpenGL viewers. The code is available at https://github.com/RockyXu66/splatbus.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15431v1</guid></item><item><title>[cs updates on arXiv.org] MEDFORD in a Box: Improvements and Future Directions for a Metadata Description Language</title><link>https://arxiv.org/abs/2601.15432</link><description>arXiv:2601.15432v1 Announce Type: new 
Abstract: Scientific research metadata is vital to ensure the validity, reusability, and cost-effectiveness of research efforts. The MEDFORD metadata language was previously introduced to simplify the process of writing and maintaining metadata for non-programmers. However, barriers to entry and usability remain, including limited automatic validation, difficulty of data transport, and user unfamiliarity with text file editing. To address these issues, we introduce MEDFORD-in-a-Box (MIAB), a documentation ecosystem to facilitate researcher adoption and earlier metadata capture. MIAB contains many improvements, including an updated MEDFORD parser with expanded validation routines and BagIt export capability. MIAB also includes an improved VS Code extension that supports these changes through a visual IDE. By simplifying metadata generation, this new tool supports the creation of correct, consistent, and reusable metadata, ultimately improving research reproducibility.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15432v1</guid></item><item><title>[cs updates on arXiv.org] ManuRAG: Multi-modal Retrieval Augmented Generation for Manufacturing Question Answering</title><link>https://arxiv.org/abs/2601.15434</link><description>arXiv:2601.15434v1 Announce Type: new 
Abstract: The evolution of digital manufacturing requires intelligent Question Answering (QA) systems that can seamlessly integrate and analyze complex multi-modal data, such as text, images, formulas, and tables. Conventional Retrieval Augmented Generation (RAG) methods often fall short in handling this complexity, resulting in subpar performance. We introduce ManuRAG, an innovative multi-modal RAG framework designed for manufacturing QA, incorporating specialized techniques to improve answer accuracy, reliability, and interpretability. To benchmark performance, we evaluate ManuRAG on three datasets comprising a total of 1,515 QA pairs, corresponding to mathematical, multiple-choice, and review-based questions in manufacturing principles and practices. Experimental results show that ManuRAG consistently outperforms existing methods across all evaluated datasets. Furthermore, ManuRAG's adaptable design makes it applicable to other domains, including law, healthcare, and finance, positioning it as a versatile tool for domain-specific QA.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15434v1</guid></item><item><title>[cs updates on arXiv.org] Not Your Typical Sycophant: The Elusive Nature of Sycophancy in Large Language Models</title><link>https://arxiv.org/abs/2601.15436</link><description>arXiv:2601.15436v1 Announce Type: new 
Abstract: We propose a novel way to evaluate sycophancy of LLMs in a direct and neutral way, mitigating various forms of uncontrolled bias, noise, or manipulative language, deliberately injected to prompts in prior works. A key novelty in our approach is the use of LLM-as-a-judge, evaluation of sycophancy as a zero-sum game in a bet setting. Under this framework, sycophancy serves one individual (the user) while explicitly incurring cost on another. Comparing four leading models - Gemini 2.5 Pro, ChatGpt 4o, Mistral-Large-Instruct-2411, and Claude Sonnet 3.7 - we find that while all models exhibit sycophantic tendencies in the common setting, in which sycophancy is self-serving to the user and incurs no cost on others, Claude and Mistral exhibit "moral remorse" and over-compensate for their sycophancy in case it explicitly harms a third party. Additionally, we observed that all models are biased toward the answer proposed last. Crucially, we find that these two phenomena are not independent; sycophancy and recency bias interact to produce `constructive interference' effect, where the tendency to agree with the user is exacerbated when the user's opinion is presented last.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15436v1</guid></item><item><title>[cs updates on arXiv.org] Exploring Implicit Perspectives on Autism in Large Language Models Through Multi-Agent Simulations</title><link>https://arxiv.org/abs/2601.15437</link><description>arXiv:2601.15437v1 Announce Type: new 
Abstract: Large Language Models (LLMs) like ChatGPT offer potential support for autistic people, but this potential requires understanding the implicit perspectives these models might carry, including their biases and assumptions about autism. Moving beyond single-agent prompting, we utilized LLM-based multi-agent systems to investigate complex social scenarios involving autistic and non-autistic agents. In our study, agents engaged in group-task conversations and answered structured interview questions, which we analyzed to examine ChatGPT's biases and how it conceptualizes autism. We found that ChatGPT assumes autistic people are socially dependent, which may affect how it interacts with autistic users or conveys information about autism. To address these challenges, we propose adopting the double empathy problem, which reframes communication breakdowns as a mutual challenge. We describe how future LLMs could address the biases we observed and improve interactions involving autistic people by incorporating the double empathy problem into their design.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15437v1</guid></item><item><title>[cs updates on arXiv.org] CASL: Concept-Aligned Sparse Latents for Interpreting Diffusion Models</title><link>https://arxiv.org/abs/2601.15441</link><description>arXiv:2601.15441v1 Announce Type: new 
Abstract: Internal activations of diffusion models encode rich semantic information, but interpreting such representations remains challenging. While Sparse Autoencoders (SAEs) have shown promise in disentangling latent representations, existing SAE-based methods for diffusion model understanding rely on unsupervised approaches that fail to align sparse features with human-understandable concepts. This limits their ability to provide reliable semantic control over generated images. We introduce CASL (Concept-Aligned Sparse Latents), a supervised framework that aligns sparse latent dimensions of diffusion models with semantic concepts. CASL first trains an SAE on frozen U-Net activations to obtain disentangled latent representations, and then learns a lightweight linear mapping that associates each concept with a small set of relevant latent dimensions. To validate the semantic meaning of these aligned directions, we propose CASL-Steer, a controlled latent intervention that shifts activations along the learned concept axis. Unlike editing methods, CASL-Steer is used solely as a causal probe to reveal how concept-aligned latents influence generated content. We further introduce the Editing Precision Ratio (EPR), a metric that jointly measures concept specificity and the preservation of unrelated attributes. Experiments show that our method achieves superior editing precision and interpretability compared to existing approaches. To the best of our knowledge, this is the first work to achieve supervised alignment between latent representations and semantic concepts in diffusion models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15441v1</guid></item><item><title>[cs updates on arXiv.org] A tensor network formalism for neuro-symbolic AI</title><link>https://arxiv.org/abs/2601.15442</link><description>arXiv:2601.15442v1 Announce Type: new 
Abstract: The unification of neural and symbolic approaches to artificial intelligence remains a central open challenge. In this work, we introduce a tensor network formalism, which captures sparsity principles originating in the different approaches in tensor decompositions. In particular, we describe a basis encoding scheme for functions and model neural decompositions as tensor decompositions. The proposed formalism can be applied to represent logical formulas and probability distributions as structured tensor decompositions. This unified treatment identifies tensor network contractions as a fundamental inference class and formulates efficiently scaling reasoning algorithms, originating from probability theory and propositional logic, as contraction message passing schemes. The framework enables the definition and training of hybrid logical and probabilistic models, which we call Hybrid Logic Network. The theoretical concepts are accompanied by the python library tnreason, which enables the implementation and practical use of the proposed architectures.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15442v1</guid></item><item><title>[cs updates on arXiv.org] Reflexis: Supporting Reflexivity and Rigor in Collaborative Qualitative Analysis through Design for Deliberation</title><link>https://arxiv.org/abs/2601.15445</link><description>arXiv:2601.15445v1 Announce Type: new 
Abstract: Reflexive Thematic Analysis (RTA) is a critical method for generating deep interpretive insights. Yet its core tenets, including researcher reflexivity, tangible analytical evolution, and productive disagreement, are often poorly supported by software tools that prioritize speed and consensus over interpretive depth. To address this gap, we introduce Reflexis, a collaborative workspace that centers these practices. It supports reflexivity by integrating in-situ reflection prompts, makes code evolution transparent and tangible, and scaffolds collaborative interpretation by turning differences into productive, positionality-aware dialogue. Results from our paired-analyst study (N=12) indicate that Reflexis encouraged participants toward more granular reflection and reframed disagreements as productive conversations. The evaluation also surfaced key design tensions, including a desire for higher-level, networked memos and more user control over the timing of proactive alerts. Reflexis contributes a design framework for tools that prioritize rigor and transparency to support deep, collaborative interpretation in an age of automation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15445v1</guid></item><item><title>[cs updates on arXiv.org] DevPrompt: Deviation-Based Prompt Learning for One-Normal ShotImage Anomaly Detection</title><link>https://arxiv.org/abs/2601.15453</link><description>arXiv:2601.15453v1 Announce Type: new 
Abstract: Few-normal shot anomaly detection (FNSAD) aims to detect abnormal regions in images using only a few normal training samples, making the task highly challenging due to limited supervision and the diversity of potential defects. Recent approaches leverage vision-language models such as CLIP with prompt-based learning to align image and text features. However, existing methods often exhibit weak discriminability between normal and abnormal prompts and lack principled scoring mechanisms for patch-level anomalies. We propose a deviation-guided prompt learning framework that integrates the semantic power of vision-language models with the statistical reliability of deviation-based scoring. Specifically, we replace fixed prompt prefixes with learnable context vectors shared across normal and abnormal prompts, while anomaly-specific suffix tokens enable class-aware alignment. To enhance separability, we introduce a deviation loss with Top-K Multiple Instance Learning (MIL), modeling patch-level features as Gaussian deviations from the normal distribution. This allows the network to assign higher anomaly scores to patches with statistically significant deviations, improving localization and interpretability. Experiments on the MVTecAD and VISA benchmarks demonstrate superior pixel-level detection performance compared to PromptAD and other baselines. Ablation studies further validate the effectiveness of learnable prompts, deviation-based scoring, and the Top-K MIL strategy.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15453v1</guid></item><item><title>[cs updates on arXiv.org] Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering</title><link>https://arxiv.org/abs/2601.15457</link><description>arXiv:2601.15457v1 Announce Type: new 
Abstract: The integration of Large Language Models (LLMs) into the public health policy sector offers a transformative approach to navigating the vast repositories of regulatory guidance maintained by agencies such as the Centers for Disease Control and Prevention (CDC). However, the propensity for LLMs to generate hallucinations, defined as plausible but factually incorrect assertions, presents a critical barrier to the adoption of these technologies in high-stakes environments where information integrity is non-negotiable. This empirical evaluation explores the effectiveness of Retrieval-Augmented Generation (RAG) architectures in mitigating these risks by grounding generative outputs in authoritative document context. Specifically, this study compares a baseline Vanilla LLM against Basic RAG and Advanced RAG pipelines utilizing cross-encoder re-ranking. The experimental framework employs a Mistral-7B-Instruct-v0.2 model and an all-MiniLM-L6-v2 embedding model to process a corpus of official CDC policy analytical frameworks and guidance documents. The analysis measures the impact of two distinct chunking strategies, recursive character-based and token-based semantic splitting, on system accuracy, measured through faithfulness and relevance scores across a curated set of complex policy scenarios. Quantitative findings indicate that while Basic RAG architectures provide a substantial improvement in faithfulness (0.621) over Vanilla baselines (0.347), the Advanced RAG configuration achieves a superior faithfulness average of 0.797. These results demonstrate that two-stage retrieval mechanisms are essential for achieving the precision required for domain-specific policy question answering, though structural constraints in document segmentation remain a significant bottleneck for multi-step reasoning tasks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15457v1</guid></item><item><title>[cs updates on arXiv.org] MuSAlS: A Fast Multiple Sequence Alignment Approach Using Hierarchical Clustering</title><link>https://arxiv.org/abs/2601.15458</link><description>arXiv:2601.15458v1 Announce Type: new 
Abstract: Motivation: The multiple sequence alignment (MSA) problem has been extensively studied, with numerous approaches developed over recent years. With the rapid growth of sequence data, there is an increasing need for fast and accurate MSA tools that scale effectively to large datasets. Building on our previous work on CLAM, we are able to use exact dynamic programming (Needleman-Wunsch) while scaling to large datasets. We introduce MuSAlS (Multiple Sequence Alignment at Scale), a fast and scalable de novo MSA aligner. MuSAlS uses hierarchical clustering to construct a guide tree based on the Levenshtein distance metric, enabling efficient and accurate alignment through a bottom-up approach. Results: MuSAlS achieves competitive accuracy compared to state-of-the-art methods while significantly improving runtime performance. This makes it a valuable tool for researchers analyzing large-scale genomic and metagenomic datasets, addressing the growing demand for scalable bioinformatics solutions. Availability and Implementation: MuSAlS is implemented in the Rust programming language, and available at https://github.com/URI-ABD/clam</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15458v1</guid></item><item><title>[cs updates on arXiv.org] Neural Collision Detection for Multi-arm Laparoscopy Surgical Robots Through Learning-from-Simulation</title><link>https://arxiv.org/abs/2601.15459</link><description>arXiv:2601.15459v1 Announce Type: new 
Abstract: This study presents an integrated framework for enhancing the safety and operational efficiency of robotic arms in laparoscopic surgery by addressing key challenges in collision detection and minimum distance estimation. By combining analytical modeling, real-time simulation, and machine learning, the framework offers a robust solution for ensuring safe robotic operations. An analytical model was developed to estimate the minimum distances between robotic arms based on their joint configurations, offering precise theoretical calculations that serve as both a validation tool and a benchmark. To complement this, a 3D simulation environment was created to model two 7-DOF Kinova robotic arms, generating a diverse dataset of configurations for collision detection and distance estimation. Using these insights, a deep neural network model was trained with joint actuators of robot arms and relative positions as inputs, achieving a mean absolute error of 282.2 mm and an R-squared value of 0.85. The close alignment between predicted and actual distances highlights the network's accuracy and its ability to generalize spatial relationships. This work demonstrates the effectiveness of combining analytical precision with machine learning algorithms to enhance the precision and reliability of robotic systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15459v1</guid></item><item><title>[cs updates on arXiv.org] Rank-metric codes over arbitrary fields: Bounds and constructions</title><link>https://arxiv.org/abs/2601.15464</link><description>arXiv:2601.15464v1 Announce Type: new 
Abstract: Rank-metric codes, defined as sets of matrices over a finite field with the rank distance, have gained significant attention due to their applications in network coding and connections to diverse mathematical areas. Initially studied by Delsarte in 1978 and later rediscovered by Gabidulin, these codes have become a central topic in coding theory. This paper surveys the development and mathematical foundations, in particular, regarding bounds and constructions of rank-metric codes, emphasizing their extension beyond finite fields to more general settings. We examine Singleton-like bounds on code parameters, demonstrating their sharpness in finite field cases and contrasting this with contexts where the bounds are not tight. Furthermore, we discuss constructions of Maximum Rank Distance (MRD) codes over fields with cyclic Galois extensions and the relationship between linear rank-metric codes with systems and evasive subspaces. The paper also reviews results for algebraically closed fields and real numbers, previously appearing in the context of topology and measure theory. We conclude by proposing future research directions, including conjectures on MRD code existence and the exploration of rank-metric codes over various field extensions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15464v1</guid></item><item><title>[cs updates on arXiv.org] Cloning the Self for Mental Well-Being: A Framework for Designing Safe and Therapeutic Self-Clone Chatbots</title><link>https://arxiv.org/abs/2601.15465</link><description>arXiv:2601.15465v1 Announce Type: new 
Abstract: As digital tools increasingly mediate mental health care, self-clone chatbots can offer a uniquely novel approach to intra-personal exploration and self-derived support. Trained to replicate users' conversational patterns, self-clones allow users to talk to themselves through their digital replicas. Despite the promises, these systems may carry risks around identity confusion, negative reinforcement, and blurred user agency. Through interviews with 16 mental health professionals and 6 general users, we aim to uncover tensions and design opportunities in this emerging space to guide responsible self-clone design. Our analysis produces a design framework organized around three priorities: (1) defining goals and grounding the approach in existing therapeutic models, (2) design dimensions including the self-clone persona and user-clone relationship dynamics, and (3) considerations for minimizing potential emotional and ethical harms. This framework contributes an interdisciplinary foundation for designing self-clone chatbots as AI-mediated self-interaction tools that are emotionally and ethically attuned in mental health contexts.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15465v1</guid></item><item><title>[cs updates on arXiv.org] Shape of You: Implications of Social Context and Avatar Body Shape on Relatedness, Emotions, and Performance in a Virtual Reality Workout</title><link>https://arxiv.org/abs/2601.15466</link><description>arXiv:2601.15466v1 Announce Type: new 
Abstract: It is obvious that emotions are causal variables of motivation, as they elicit states, forces and energies that trigger and guide labor behavior. Thus, a motivational tension that is not informed by needs alone, but also by emotions, intention, goals and means to achieve them is therefore generated within the mental, emotional and physical plane. Based on Montserrat's opinion (2004: 131), that "to motivate means, above all, to move and to transmit an emotion", we will undertake to identify the mutual influences between emotions and motivation. The main objectives of this article are to display a summary of the theories and definitions about emotions and to explore the links between emotions and motivation. Although interconnected, emotions and motivation can be contemplated from a double perspective: (1) emotions influence motivation and (2) motivation influences emotions. Moreover, we will consider motivation from three dimensions: (1) cognitive, (2) affective and (3) volitional. The ultimate purpose of this article is to issue a warning as to the importance of the emotional side of motivation. An important part in implementing such insight is to be played by managers (and by employees, also), who should develop the skills and know-how needed to keep a well-balanced emotional climate that effectively favors the maximization of individual and group motivation at the workplace.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15466v1</guid></item><item><title>[cs updates on arXiv.org] Learning from Synthetic Data: Limitations of ERM</title><link>https://arxiv.org/abs/2601.15468</link><description>arXiv:2601.15468v1 Announce Type: new 
Abstract: The prevalence and low cost of LLMs have led to a rise of synthetic content. From review sites to court documents, ``natural'' content has been contaminated by data points that appear similar to natural data, but are in fact LLM-generated. In this work we revisit fundamental learning theory questions in this, now ubiquitous, setting. We model this scenario as a sequence of learning tasks where the input is a mix of natural and synthetic data, and the learning algorithms are oblivious to the origin of any individual example.
  We study the possibilities and limitations of ERM in this setting. For the problem of estimating the mean of an arbitrary $d$-dimensional distribution, we find that while ERM converges to the true mean, it is outperformed by an algorithm that assigns non-uniform weights to examples from different generations of data. For the PAC learning setting, the disparity is even more stark. We find that ERM does not always converge to the true concept, echoing the model collapse literature. However, we show there are algorithms capable of learning the correct hypothesis for arbitrary VC classes and arbitrary amounts of contamination.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15468v1</guid></item><item><title>[cs updates on arXiv.org] Nested and outlier embeddings into trees</title><link>https://arxiv.org/abs/2601.15470</link><description>arXiv:2601.15470v1 Announce Type: new 
Abstract: In this paper, we consider outlier embeddings into HSTs and ultrametrics. In particular, for $(X,d)$, let $k$ be the size of the smallest subset of $X$ such that all but that subset (i.e. the ``outlier set'') can be probabilistically embedded into the space of HSTs with expected distortion at most $c$. Our primary result is showing that there exists an efficient algorithm that takes in $(X,d)$ and a target distortion $c$ and samples from a probabilistic embedding with at most $O(\frac k \epsilon \log^2k)$ outliers and distortion at most $(32+\epsilon)c$, for any $\epsilon&gt;0$. This leads to better instance-specific approximations for certain instances of the buy-at-bulk and dial-a-ride problems, whose current best approximation algorithms go through HST embeddings.
  In order to facilitate our results, we largely focus on the concept of compositions of nested embeddings introduced by [Chawla and Sheridan 2024]. A nested embedding is a composition of two embeddings of a metric space $(X,d)$ -- a low distortion embedding of a subset $S$ of nodes, and a higher distortion embedding of the entire metric. The composition is a single embedding that preserves the low distortion over $S$ and does not increase distortion over the remaining points by much. In this paper, we expand this concept from the setting of deterministic embeddings to the setting of probabilistic embeddings. We show how to find good nested compositions of embeddings into HSTs, and combine this with an approximation algorithm of [Munagala et al. 2023] to obtain our results.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15470v1</guid></item><item><title>[cs updates on arXiv.org] Put Your Muscle Into It: Introducing XEM2, a Novel Approach for Monitoring Exertion in Stationary Physical Exercises Leveraging Muscle Work</title><link>https://arxiv.org/abs/2601.15472</link><description>arXiv:2601.15472v1 Announce Type: new 
Abstract: We present a novel system for camera-based measurement and visualization of muscle work based on the Hill-Type-Muscle-Model: the exercise exertion muscle-work monitor (\textit{XEM}$^{2}$). Our aim is to complement and, thus, address issues of established measurement techniques that offer imprecise data for non-uniform movements (burned calories) or provide limited information on strain across different body parts (self-perception scales). We validate the reliability of XEM's measurements through a technical evaluation of ten participants and five exercises. Further, we assess the acceptance, usefulness, benefits, and opportunities of \textit{XEM}$^{2}$ in an empirical user study. Our results show that \textit{XEM}$^{2}$ provides reliable values of muscle work and supports participants in understanding their workout while also providing reliable information about perceived exertion per muscle group. With this paper, we introduce a novel system capable of measuring and visualizing exertion for single muscle groups, which has the potential to improve exercise monitoring to prevent unbalanced workouts.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15472v1</guid></item><item><title>[cs updates on arXiv.org] Panther: Faster and Cheaper Computations with Randomized Numerical Linear Algebra</title><link>https://arxiv.org/abs/2601.15473</link><description>arXiv:2601.15473v1 Announce Type: new 
Abstract: Training modern deep learning models is increasingly constrained by GPU memory and compute limits. While Randomized Numerical Linear Algebra (RandNLA) offers proven techniques to compress these models, the lack of a unified, production-grade library prevents widely adopting these methods. We present Panther, a PyTorch-compatible library that consolidates established RandNLA algorithms into a single high-performance framework. Panther engineers efficient, drop-in replacements for standard components including sketched linear layers, 2D convolution, multi-head attention, and randomized matrix decompositions (such as pivoted CholeskyQR). By implementing a custom C++/CUDA backend (pawX), Panther provides an optimized implementation that can run on both CPUs and GPUs. We demonstrate the effectiveness of RandNLA techniques and Panther's ease of adoption. By replacing standard PyTorch linear layers with Panther layers (requiring only a few lines of code) we achieve significant memory savings (up to 75%) on BERT while maintaining comparable loss. Source code is available (MIT License) at https://github.com/FahdSeddik/panther, along with demonstration video at https://youtu.be/7M3RQb4KWxs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15473v1</guid></item><item><title>[cs updates on arXiv.org] Multi-Targeted Graph Backdoor Attack</title><link>https://arxiv.org/abs/2601.15474</link><description>arXiv:2601.15474v1 Announce Type: new 
Abstract: Graph neural network (GNN) have demonstrated exceptional performance in solving critical problems across diverse domains yet remain susceptible to backdoor attacks. Existing studies on backdoor attack for graph classification are limited to single target attack using subgraph replacement based mechanism where the attacker implants only one trigger into the GNN model. In this paper, we introduce the first multi-targeted backdoor attack for graph classification task, where multiple triggers simultaneously redirect predictions to different target labels. Instead of subgraph replacement, we propose subgraph injection which preserves the structure of the original graphs while poisoning the clean graphs. Extensive experiments demonstrate the efficacy of our approach, where our attack achieves high attack success rates for all target labels with minimal impact on the clean accuracy. Experimental results on five dataset demonstrate the superior performance of our attack framework compared to the conventional subgraph replacement-based attack. Our analysis on four GNN models confirms the generalization capability of our attack which is effective regardless of the GNN model architectures and training parameters settings. We further investigate the impact of the attack design parameters including injection methods, number of connections, trigger sizes, trigger edge density and poisoning ratios. Additionally, our evaluation against state-of-the-art defenses (randomized smoothing and fine-pruning) demonstrates the robustness of our proposed multi-target attacks. This work highlights the GNN vulnerability against multi-targeted backdoor attack in graph classification task. Our source codes will be available at https://github.com/SiSL-URI/Multi-Targeted-Graph-Backdoor-Attack.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15474v1</guid></item><item><title>[cs updates on arXiv.org] Seeing through Light and Darkness: Sensor-Physics Grounded Deblurring HDR NeRF from Single-Exposure Images and Events</title><link>https://arxiv.org/abs/2601.15475</link><description>arXiv:2601.15475v1 Announce Type: new 
Abstract: Novel view synthesis from low dynamic range (LDR) blurry images, which are common in the wild, struggles to recover high dynamic range (HDR) and sharp 3D representations in extreme lighting conditions. Although existing methods employ event data to address this issue, they ignore the sensor-physics mismatches between the camera output and physical world radiance, resulting in suboptimal HDR and deblurring results. To cope with this problem, we propose a unified sensor-physics grounded NeRF framework for sharp HDR novel view synthesis from single-exposure blurry LDR images and corresponding events. We employ NeRF to directly represent the actual radiance of the 3D scene in the HDR domain and model raw HDR scene rays hitting the sensor pixels as in the physical world. A pixel-wise RGB mapping field is introduced to align the above rendered pixel values with the sensor-recorded LDR pixel values of the input images. A novel event mapping field is also designed to bridge the physical scene dynamics and actual event sensor output. The two mapping fields are jointly optimized with the NeRF network, leveraging the spatial and temporal dynamic information in events to enhance the sharp HDR 3D representation learning. Experiments on the collected and public datasets demonstrate that our method can achieve state-of-the-art deblurring HDR novel view synthesis results with single-exposure blurry LDR images and corresponding events.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15475v1</guid></item><item><title>[cs updates on arXiv.org] Reliability by design: quantifying and eliminating fabrication risk in LLMs. From generative to consultative AI: a comparative analysis in the legal domain and lessons for high-stakes knowledge bases</title><link>https://arxiv.org/abs/2601.15476</link><description>arXiv:2601.15476v1 Announce Type: new 
Abstract: This paper examines how to make large language models reliable for high-stakes legal work by reducing hallucinations. It distinguishes three AI paradigms: (1) standalone generative models ("creative oracle"), (2) basic retrieval-augmented systems ("expert archivist"), and (3) an advanced, end-to-end optimized RAG system ("rigorous archivist"). The authors introduce two reliability metrics -False Citation Rate (FCR) and Fabricated Fact Rate (FFR)- and evaluate 2,700 judicial-style answers from 12 LLMs across 75 legal tasks using expert, double-blind review. Results show that standalone models are unsuitable for professional use (FCR above 30%), while basic RAG greatly reduces errors but still leaves notable misgrounding. Advanced RAG, using techniques such as embedding fine-tuning, re-ranking, and self-correction, reduces fabrication to negligible levels (below 0.2%). The study concludes that trustworthy legal AI requires rigor-focused, retrieval-based architectures emphasizing verification and traceability, and provides an evaluation framework applicable to other high-risk domains.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15476v1</guid></item><item><title>[cs updates on arXiv.org] Equal-Pay Contracts</title><link>https://arxiv.org/abs/2601.15478</link><description>arXiv:2601.15478v1 Announce Type: new 
Abstract: We study multi-agent contract design, where a principal incentivizes a team of agents to take costly actions that jointly determine the project success via a combinatorial reward function. While prior work largely focuses on unconstrained contracts that allow heterogeneous payments across agents, many real-world environments limit payment dispersion. Motivated by this, we study equal-pay contracts, where all agents receive identical payments. Our results also extend to nearly-equal-pay contracts where any two payments are identical up to a constant factor.
  We provide both algorithmic and hardness results across a broad hierarchy of reward functions, under both binary and combinatorial action models. While we focus on equal-pay contracts, our analysis also yields new insights into unconstrained contract design, and resolves two important open problems. On the positive side, we design polynomial-time O(1)-approximation algorithms for (i) submodular rewards under combinatorial actions, and (ii) XOS rewards under binary actions. These guarantees are tight: We rule out the existence of (i) a PTAS for combinatorial actions, even for gross substitutes rewards (unless P = NP), and (ii) any O(1)-approximation for XOS rewards with combinatorial actions. Crucially, our hardness results hold even for unconstrained contracts, thereby settling the corresponding open problems in this setting.
  Finally, we quantify the loss induced by fairness via the price of equality, defined as the worst-case ratio between the optimal principal's utility achievable by unconstrained contracts and that achievable by equal-pay contracts. We obtain a bound of $\Theta(\log n/ \log \log n)$, where $n$ is the number of agents. This gap is tight in a strong sense: the upper bound applies even for XOS rewards with combinatorial actions, while the lower bound arises already for additive rewards with binary actions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15478v1</guid></item><item><title>[cs updates on arXiv.org] Benchmarking LLMs for Pairwise Causal Discovery in Biomedical and Multi-Domain Contexts</title><link>https://arxiv.org/abs/2601.15479</link><description>arXiv:2601.15479v1 Announce Type: new 
Abstract: The safe deployment of large language models (LLMs) in high-stakes fields like biomedicine, requires them to be able to reason about cause and effect. We investigate this ability by testing 13 open-source LLMs on a fundamental task: pairwise causal discovery (PCD) from text. Our benchmark, using 12 diverse datasets, evaluates two core skills: 1) \textbf{Causal Detection} (identifying if a text contains a causal link) and 2) \textbf{Causal Extraction} (pulling out the exact cause and effect phrases). We tested various prompting methods, from simple instructions (zero-shot) to more complex strategies like Chain-of-Thought (CoT) and Few-shot In-Context Learning (FICL).
  The results show major deficiencies in current models. The best model for detection, DeepSeek-R1-Distill-Llama-70B, only achieved a mean score of 49.57\% ($C_{detect}$), while the best for extraction, Qwen2.5-Coder-32B-Instruct, reached just 47.12\% ($C_{extract}$). Models performed best on simple, explicit, single-sentence relations. However, performance plummeted for more difficult (and realistic) cases, such as implicit relationships, links spanning multiple sentences, and texts containing multiple causal pairs. We provide a unified evaluation framework, built on a dataset validated with high inter-annotator agreement ($\kappa \ge 0.758$), and make all our data, code, and prompts publicly available to spur further research. \href{https://github.com/sydneyanuyah/CausalDiscovery}{Code available here: https://github.com/sydneyanuyah/CausalDiscovery}</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15479v1</guid></item><item><title>[cs updates on arXiv.org] Early predicting of hospital admission using machine learning algorithms: Priority queues approach</title><link>https://arxiv.org/abs/2601.15481</link><description>arXiv:2601.15481v1 Announce Type: new 
Abstract: Emergency Department overcrowding is a critical issue that compromises patient safety and operational efficiency, necessitating accurate demand forecasting for effective resource allocation. This study evaluates and compares three distinct predictive models: Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors (SARIMAX), EXtreme Gradient Boosting (XGBoost) and Long Short-Term Memory (LSTM) networks for forecasting daily ED arrivals over a seven-day horizon. Utilizing data from an Australian tertiary referral hospital spanning January 2017 to December 2021, this research distinguishes itself by decomposing demand into eight specific ward categories and stratifying patients by clinical complexity. To address data distortions caused by the COVID-19 pandemic, the study employs the Prophet model to generate synthetic counterfactual values for the anomalous period. Experimental results demonstrate that all three proposed models consistently outperform a seasonal naive baseline. XGBoost demonstrated the highest accuracy for predicting total daily admissions with a Mean Absolute Error of 6.63, while the statistical SARIMAX model proved marginally superior for forecasting major complexity cases with an MAE of 3.77. The study concludes that while these techniques successfully reproduce regular day-to-day patterns, they share a common limitation in underestimating sudden, infrequent surges in patient volume.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15481v1</guid></item><item><title>[cs updates on arXiv.org] Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding</title><link>https://arxiv.org/abs/2601.15482</link><description>arXiv:2601.15482v1 Announce Type: new 
Abstract: Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15482v1</guid></item><item><title>[cs updates on arXiv.org] Is Grokipedia Right-Leaning? Comparing Political Framing in Wikipedia and Grokipedia on Controversial Topics</title><link>https://arxiv.org/abs/2601.15484</link><description>arXiv:2601.15484v1 Announce Type: new 
Abstract: Online encyclopedias are central to contemporary information infrastructures and have become focal points of debates over ideological bias. Wikipedia, in particular, has long been accused of left-leaning bias, while Grokipedia, an AI-generated encyclopedia launched by xAI, has been framed as a right-leaning alternative. This paper presents a comparative analysis of Wikipedia and Grokipedia on well-established politically contested topics. Specifically, we examine differences in semantic framing, political orientation, and content prioritization. We find that semantic similarity between the two platforms decays across article sections and diverges more strongly on controversial topics than on randomly sampled ones. Additionally, we show that both encyclopedias predominantly exhibit left-leaning framings, although Grokipedia exhibits a more bimodal distribution with increased prominence of right-leaning content. The experimental code is publicly available.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15484v1</guid></item><item><title>[cs updates on arXiv.org] The Rise of Large Language Models and the Direction and Impact of US Federal Research Funding</title><link>https://arxiv.org/abs/2601.15485</link><description>arXiv:2601.15485v1 Announce Type: new 
Abstract: Federal research funding shapes the direction, diversity, and impact of the US scientific enterprise. Large language models (LLMs) are rapidly diffusing into scientific practice, holding substantial promise while raising widespread concerns. Despite growing attention to AI use in scientific writing and evaluation, little is known about how the rise of LLMs is reshaping the public funding landscape. Here, we examine LLM involvement at key stages of the federal funding pipeline by combining two complementary data sources: confidential National Science Foundation (NSF) and National Institutes of Health (NIH) proposal submissions from two large US R1 universities, including funded, unfunded, and pending proposals, and the full population of publicly released NSF and NIH awards. We find that LLM use rises sharply beginning in 2023 and exhibits a bimodal distribution, indicating a clear split between minimal and substantive use. Across both private submissions and public awards, higher LLM involvement is consistently associated with lower semantic distinctiveness, positioning projects closer to recently funded work within the same agency. The consequences of this shift are agency-dependent. LLM use is positively associated with proposal success and higher subsequent publication output at NIH, whereas no comparable associations are observed at NSF. Notably, the productivity gains at NIH are concentrated in non-hit papers rather than the most highly cited work. Together, these findings provide large-scale evidence that the rise of LLMs is reshaping how scientific ideas are positioned, selected, and translated into publicly funded research, with implications for portfolio governance, research diversity, and the long-run impact of science.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15485v1</guid></item><item><title>[cs updates on arXiv.org] A Universal Large Language Model -- Drone Command and Control Interface</title><link>https://arxiv.org/abs/2601.15486</link><description>arXiv:2601.15486v1 Announce Type: new 
Abstract: The use of artificial intelligence (AI) for drone control can have a transformative impact on drone capabilities, especially when real world information can be integrated with drone sensing, command, and control, part of a growing field of physical AI. Large language models (LLMs) can be advantageous if trained at scale on general knowledge, but especially and in particular when the training data includes information such as detailed map geography topology of the entire planet, as well as the ability to access real time situational data such as weather. However, challenges remain in the interface between drones and LLMs in general, with each application requiring a tedious, labor intensive effort to connect the LLM trained knowledge to drone command and control. Here, we solve that problem, using an interface strategy that is LLM agnostic and drone agnostic, providing the first universal, versatile, comprehensive and easy to use drone control interface. We do this using the new model context protocol (MCP) standard, an open standard that provides a universal way for AI systems to access external data, tools, and services. We develop and deploy a cloud based Linux machine hosting an MCP server that supports the Mavlink protocol, an ubiquitous drone control language used almost universally by millions of drones including Ardupilot and PX4 framework.We demonstrate flight control of a real unmanned aerial vehicle. In further testing, we demonstrate extensive flight planning and control capability in a simulated drone, integrated with a Google Maps MCP server for up to date, real time navigation information. This demonstrates a universal approach to integration of LLMs with drone command and control, a paradigm that leverages and exploits virtually all of modern AI industry with drone technology in an easy to use interface that translates natural language to drone control.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15486v1</guid></item><item><title>[cs updates on arXiv.org] MiRAGE: A Multiagent Framework for Generating Multimodal Multihop Question-Answer Dataset for RAG Evaluation</title><link>https://arxiv.org/abs/2601.15487</link><description>arXiv:2601.15487v1 Announce Type: new 
Abstract: The rapid evolution of Retrieval-Augmented Generation (RAG) toward multimodal, high-stakes enterprise applications has outpaced the development of domain specific evaluation benchmarks. Existing datasets often rely on general-domain corpora or purely textual retrieval, failing to capture the complexity of specialized technical documents where information is inextricably multimodal and reasoning requires synthesizing disjoint evidence. We address this gap by introducing MiRAGE, a Multiagent framework for RAG systems Evaluation, that leverages a collaborative swarm of specialized agents to generate verified, domain-specific, multimodal, and multi-hop Question-Answer datasets. MiRAGE orchestrates a swarm of specialized agents: a recursive context optimization loop to aggregate scattered evidence, an adversarial verifier agent to guarantee factual grounding, and an agent to recognize the expert persona and the relevant domain to mimic expert cognitive workflows. Extensive empirical evaluation across four distinct domains (regulations, finance, quantitative biology, and journalism) demonstrates that MiRAGE generates datasets with significantly higher reasoning complexity (&gt;2.3 average hops) and factual faithfulness. Our ablation studies point that MiRAGE can be powered by LLMs if textual descriptions of the images are available. Visual grounding still remains a frontier. By automating the creation of gold standard evaluation datasets that reflect the latent thematic structure of proprietary corpora, MiRAGE provides the necessary infrastructure to rigorously benchmark the next generation information retrieval systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15487v1</guid></item><item><title>[cs updates on arXiv.org] Multi-Persona Thinking for Bias Mitigation in Large Language Models</title><link>https://arxiv.org/abs/2601.15488</link><description>arXiv:2601.15488v1 Announce Type: new 
Abstract: Large Language Models (LLMs) exhibit significant social biases that can perpetuate harmful stereotypes and unfair outcomes. In this paper, we propose Multi-Persona Thinking (MPT), a novel inference-time framework that leverages dialectical reasoning from multiple perspectives to reduce bias. MPT guides models to adopt contrasting social identities (e.g., male and female) along with a neutral viewpoint, and then engages these personas iteratively to expose and correct biases. Through a dialectical reasoning process, the framework transforms the potential weakness of persona assignment into a strength for bias mitigation. We evaluate MPT on two widely used bias benchmarks across both open-source and closed-source models of varying scales. Our results demonstrate substantial improvements over existing prompting-based strategies: MPT achieves the lowest bias while maintaining core reasoning ability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15488v1</guid></item><item><title>[cs updates on arXiv.org] Hybrid Vision Transformer_GAN Attribute Neutralizer for Mitigating Bias in Chest X_Ray Diagnosis</title><link>https://arxiv.org/abs/2601.15490</link><description>arXiv:2601.15490v1 Announce Type: new 
Abstract: Bias in chest X-ray classifiers frequently stems from sex- and age-related shortcuts, leading to systematic underdiagnosis of minority subgroups. Previous pixel-space attribute neutralizers, which rely on convolutional encoders, lessen but do not fully remove this attribute leakage at clinically usable edit strengths. This study evaluates whether substituting the U-Net convolutional encoder with a Vision Transformer backbone in the Attribute-Neutral Framework can reduce demographic attribute leakage while preserving diagnostic accuracy. A data-efficient Image Transformer Small (DeiT-S) neutralizer was trained on the ChestX-ray14 dataset. Its edited images, generated across eleven edit-intensity levels, were evaluated with an independent AI judge for attribute leakage and with a convolutional neural network (ConvNet) for disease prediction. At a moderate edit level (alpha = 0.5), the Vision Transformer (ViT) neutralizer reduces patient sex-recognition area under the curve (AUC) to approximately 0.80, about 10 percentage points below the original framework's convolutional U-Net encoder, despite being trained for only half as many epochs. Meanwhile, macro receiver operating characteristic area under the curve (ROC AUC) across 15 findings stays within five percentage points of the unedited baseline, and the worst-case subgroup AUC remains near 0.70. These results indicate that global self-attention vision models can further suppress attribute leakage without sacrificing clinical utility, suggesting a practical route toward fairer chest X-ray AI.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15490v1</guid></item><item><title>[cs updates on arXiv.org] Testing Deep Learning Libraries via Neurosymbolic Constraint Learning</title><link>https://arxiv.org/abs/2601.15493</link><description>arXiv:2601.15493v1 Announce Type: new 
Abstract: Deep Learning (DL) libraries (e.g., PyTorch) are popular in AI development. These libraries are complex and contain bugs. Researchers have proposed various bug-finding techniques for such libraries. Yet, there is much room for improvement. A key challenge in testing DL libraries is the lack of API specifications. Prior testing approaches often inaccurately model the input specifications of DL APIs, resulting in missed valid inputs that could reveal bugs or false alarms due to invalid inputs.
  To address this challenge, we develop Centaur -- the first neurosymbolic technique to test DL library APIs using dynamically learned input constraints. Centaur leverages the key idea that formal API constraints can be learned from a small number of automatically generated seed inputs, and that the learned constraints can be solved using SMT solvers to generate valid and diverse test inputs.
  We develop a novel grammar that represents first-order logic formulae over API parameters and expresses tensor-related properties (e.g., shape, data types) as well as relational properties between parameters. We use the grammar to guide a Large Language Model (LLM) to enumerate syntactically correct candidate rules, validated using seed inputs. Further, we develop a custom refinement strategy to prune the set of learned rules to eliminate spurious or redundant rules. We use the learned constraints to systematically generate valid and diverse inputs by integrating SMT-based solving with randomized sampling.
  We evaluate Centaur for testing PyTorch and TensorFlow. Our results show that Centaur's constraints have a recall of 94.0% and a precision of 94.0% on average. In terms of coverage, Centaur covers 203, 150, and 9,608 more branches than TitanFuzz, ACETest and Pathfinder, respectively. Using Centaur, we also detect 26 new bugs in PyTorch and TensorFlow, 18 of which are confirmed.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15493v1</guid></item><item><title>[cs updates on arXiv.org] Tracking the Limits of Knowledge Propagation: How LLMs Fail at Multi-Step Reasoning with Conflicting Knowledge</title><link>https://arxiv.org/abs/2601.15495</link><description>arXiv:2601.15495v1 Announce Type: new 
Abstract: A common solution for mitigating outdated or incorrect information in Large Language Models (LLMs) is to provide updated facts in-context or through knowledge editing. However, these methods introduce knowledge conflicts when the knowledge update fails to overwrite the model's parametric knowledge, which propagate to faulty reasoning. Current benchmarks for this problem, however, largely focus only on single knowledge updates and fact recall without evaluating how these updates affect downstream reasoning. In this work, we introduce TRACK (Testing Reasoning Amid Conflicting Knowledge), a new benchmark for studying how LLMs propagate new knowledge through multi-step reasoning when it conflicts with the model's initial parametric knowledge. Spanning three reasoning-intensive scenarios (WIKI, CODE, and MATH), TRACK introduces multiple, realistic conflicts to mirror real-world complexity. Our results on TRACK reveal that providing updated facts to models for reasoning can worsen performance compared to providing no updated facts to a model, and that this performance degradation exacerbates as more updated facts are provided. We show this failure stems from both inability to faithfully integrate updated facts, but also flawed reasoning even when knowledge is integrated. TRACK provides a rigorous new benchmark to measure and guide future progress on propagating conflicting knowledge in multi-step reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15495v1</guid></item><item><title>[cs updates on arXiv.org] Semantics in Actuation Systems: From Age of Actuation to Age of Actuated Information</title><link>https://arxiv.org/abs/2601.15496</link><description>arXiv:2601.15496v1 Announce Type: new 
Abstract: In this paper, we study the timeliness of actions in communication systems where actuation is constrained by control permissions or energy availability. Building on the Age of Actuation (AoA) metric, which quantifies the timeliness of actions independently of data freshness, we introduce a new metric, the \emph{Age of Actuated Information (AoAI)}. AoAI captures the end-to-end timeliness of actions by explicitly accounting for the age of the data packet at the moment it is actuated. We analyze and characterize both AoA and AoAI in discrete-time systems with data storage capabilities under multiple actuation scenarios. The actuator requires both a data packet and an actuation opportunity, which may be provided by a controller or enabled by harvested energy. Data packets may be stored either in a single-packet buffer or an infinite-capacity queue for future actuation. For these settings, we derive closed-form expressions for the average AoA and AoAI and investigate their structural differences. While AoA and AoAI coincide in instantaneous actuation systems, they differentiate when data buffering is present. Our results reveal counterintuitive regimes in which increasing update or actuation rates degrade action timeliness for both AoA and AoAI. Moreover, as part of the analysis, we obtain a novel closed-form characterization of the steady-state distribution of a Geo/Geo/1 queue operating under the FCFS discipline, expressed solely in terms of the queue length and the age of the head-of-line packet. The proposed metrics and analytical results provide new insights into the semantics of timeliness in systems where information ultimately serves the purpose of actuation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15496v1</guid></item><item><title>[cs updates on arXiv.org] MARS: Unleashing the Power of Speculative Decoding via Margin-Aware Verification</title><link>https://arxiv.org/abs/2601.15498</link><description>arXiv:2601.15498v1 Announce Type: new 
Abstract: Speculative Decoding (SD) accelerates autoregressive large language model (LLM) inference by decoupling generation and verification. While recent methods improve draft quality by tightly coupling the drafter with the target model, the verification mechanism itself remains largely unchanged, relying on strict token-level rejection sampling. In practice, modern LLMs frequently operate in low-margin regimes where the target model exhibits weak preference among top candidates. In such cases, rejecting plausible runner-up tokens yields negligible information gain while incurring substantial rollback cost, leading to a fundamental inefficiency in verification. We propose Margin-Aware Speculative Verification, a training-free and domain-agnostic verification strategy that adapts to the target model's local decisiveness. Our method conditions verification on decision stability measured directly from the target logits and relaxes rejection only when strict verification provides minimal benefit. Importantly, the approach modifies only the verification rule and is fully compatible with existing target-coupled speculative decoding frameworks. Extensive experiments across model scales ranging from 8B to 235B demonstrate that our method delivers consistent and significant inference speedups over state-of-the-art baselines while preserving generation quality across diverse benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15498v1</guid></item><item><title>[cs updates on arXiv.org] Data-driven Lake Water Quality Forecasting for Time Series with Missing Data using Machine Learning</title><link>https://arxiv.org/abs/2601.15503</link><description>arXiv:2601.15503v1 Announce Type: new 
Abstract: Volunteer-led lake monitoring yields irregular, seasonal time series with many gaps arising from ice cover, weather-related access constraints, and occasional human errors, complicating forecasting and early warning of harmful algal blooms. We study Secchi Disk Depth (SDD) forecasting on a 30-lake, data-rich subset drawn from three decades of in situ records collected across Maine lakes. Missingness is handled via Multiple Imputation by Chained Equations (MICE), and we evaluate performance with a normalized Mean Absolute Error (nMAE) metric for cross-lake comparability. Among six candidates, ridge regression provides the best mean test performance. Using ridge regression, we then quantify the minimal sample size, showing that under a backward, recent-history protocol, the model reaches within 5% of full-history accuracy with approximately 176 training samples per lake on average. We also identify a minimal feature set, where a compact four-feature subset matches the thirteen-feature baseline within the same 5% tolerance. Bringing these results together, we introduce a joint feasibility function that identifies the minimal training history and fewest predictors sufficient to achieve the target of staying within 5% of the complete-history, full-feature baseline. In our study, meeting the 5% accuracy target required about 64 recent samples and just one predictor per lake, highlighting the practicality of targeted monitoring. Hence, our joint feasibility strategy unifies recent-history length and feature choice under a fixed accuracy target, yielding a simple, efficient rule for setting sampling effort and measurement priorities for lake researchers.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15503v1</guid></item><item><title>[cs updates on arXiv.org] SAGE-FM: A lightweight and interpretable spatial transcriptomics foundation model</title><link>https://arxiv.org/abs/2601.15504</link><description>arXiv:2601.15504v1 Announce Type: new 
Abstract: Spatial transcriptomics enables spatial gene expression profiling, motivating computational models that capture spatially conditioned regulatory relationships. We introduce SAGE-FM, a lightweight spatial transcriptomics foundation model based on graph convolutional networks (GCNs) trained with a masked central spot prediction objective. Trained on 416 human Visium samples spanning 15 organs, SAGE-FM learns spatially coherent embeddings that robustly recover masked genes, with 91% of masked genes showing significant correlations (p &lt; 0.05). The embeddings generated by SAGE-FM outperform MOFA and existing spatial transcriptomics methods in unsupervised clustering and preservation of biological heterogeneity. SAGE-FM generalizes to downstream tasks, enabling 81% accuracy in pathologist-defined spot annotation in oropharyngeal squamous cell carcinoma and improving glioblastoma subtype prediction relative to MOFA. In silico perturbation experiments further demonstrate that the model captures directional ligand-receptor and upstream-downstream regulatory effects consistent with ground truth. These results demonstrate that simple, parameter-efficient GCNs can serve as biologically interpretable and spatially aware foundation models for large-scale spatial transcriptomics.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15504v1</guid></item><item><title>[cs updates on arXiv.org] Stabilizer-Code Channel Transforms Beyond Repetition Codes for Improved Hashing Bounds</title><link>https://arxiv.org/abs/2601.15505</link><description>arXiv:2601.15505v1 Announce Type: new 
Abstract: The quantum hashing bound guarantees that rates up to $1-H(p_I, p_X, p_Y, p_Z)$ are achievable for memoryless Pauli channels, but it is not generally tight. A known way to improve achievable rates for certain asymmetric Pauli channels is to apply a small inner stabilizer code to a few channel uses, decode, and treat the resulting logical noise as an induced Pauli channel; reapplying the hashing argument to this induced channel can beat the baseline hashing bound. We generalize this induced-channel viewpoint to arbitrary stabilizer codes used purely as channel transforms. Given any $ [\![ n, k ]\!] $ stabilizer generator set, we construct a full symplectic tableau, compute the induced joint distribution of logical Pauli errors and syndromes under the physical Pauli channel, and obtain an achievable rate via a hashing bound with decoder side information. We perform a structured search over small transforms and report instances that improve the baseline hashing bound for a family of Pauli channels with skewed and independent errors studied in prior work.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15505v1</guid></item><item><title>[cs updates on arXiv.org] ViT Registers and Fractal ViT</title><link>https://arxiv.org/abs/2601.15506</link><description>arXiv:2601.15506v1 Announce Type: new 
Abstract: Drawing inspiration from recent findings including surprisingly decent performance of transformers without positional encoding (NoPE) in the domain of language models and how registers (additional throwaway tokens not tied to input) may improve the performance of large vision transformers (ViTs), we invent and test a variant of ViT called fractal ViT that breaks permutation invariance among the tokens by applying an attention mask between the regular tokens and ``summary tokens'' similar to registers, in isolation or in combination with various positional encodings. These models do not improve upon ViT with registers, highlighting the fact that these findings may be scale, domain, or application-specific.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15506v1</guid></item><item><title>[cs updates on arXiv.org] Controllable Layered Image Generation for Real-World Editing</title><link>https://arxiv.org/abs/2601.15507</link><description>arXiv:2601.15507v1 Announce Type: new 
Abstract: Recent image generation models have shown impressive progress, yet they often struggle to yield controllable and consistent results when users attempt to edit specific elements within an existing image. Layered representations enable flexible, user-driven content creation, but existing approaches often fail to produce layers with coherent compositing relationships, and their object layers typically lack realistic visual effects such as shadows and reflections. To overcome these limitations, we propose LASAGNA, a novel, unified framework that generates an image jointly with its composing layers--a photorealistic background and a high-quality transparent foreground with compelling visual effects. Unlike prior work, LASAGNA efficiently learns correct image composition from a wide range of conditioning inputs--text prompts, foreground, background, and location masks--offering greater controllability for real-world applications. To enable this, we introduce LASAGNA-48K, a new dataset composed of clean backgrounds and RGBA foregrounds with physically grounded visual effects. We also propose LASAGNABENCH, the first benchmark for layer editing. We demonstrate that LASAGNA excels in generating highly consistent and coherent results across multiple image layers simultaneously, enabling diverse post-editing applications that accurately preserve identity and visual effects. LASAGNA-48K and LASAGNABENCH will be publicly released to foster open research in the community. The project page is https://rayjryang.github.io/LASAGNA-Page/.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15507v1</guid></item><item><title>[cs updates on arXiv.org] Computational Representations of Character Significance in Novels</title><link>https://arxiv.org/abs/2601.15508</link><description>arXiv:2601.15508v1 Announce Type: new 
Abstract: Characters in novels have typically been modeled based on their presence in scenes in narrative, considering aspects like their actions, named mentions, and dialogue. This conception of character places significant emphasis on the main character who is present in the most scenes. In this work, we instead adopt a framing developed from a new literary theory proposing a six-component structural model of character. This model enables a comprehensive approach to character that accounts for the narrator-character distinction and includes a component neglected by prior methods, discussion by other characters. We compare general-purpose LLMs with task-specific transformers for operationalizing this model of character on major 19th-century British realist novels. Our methods yield both component-level and graph representations of character discussion. We then demonstrate that these representations allow us to approach literary questions at scale from a new computational lens. Specifically, we explore Woloch's classic "the one vs the many" theory of character centrality and the gendered dynamics of character discussion.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15508v1</guid></item><item><title>[cs updates on arXiv.org] The Dark Side of AI Transformers: Sentiment Polarization &amp; the Loss of Business Neutrality by NLP Transformers</title><link>https://arxiv.org/abs/2601.15509</link><description>arXiv:2601.15509v1 Announce Type: new 
Abstract: The use of Transfer Learning &amp; Transformers has steadily improved accuracy and has significantly contributed in solving complex computation problems. However, this transformer led accuracy improvement in Applied AI Analytics specifically in sentiment analytics comes with the dark side. It is observed during experiments that a lot of these improvements in transformer led accuracy of one class of sentiment has been at the cost of polarization of another class of sentiment and the failing of neutrality. This lack of neutrality poses an acute problem in the Applied NLP space, which relies heavily on the computational outputs of sentiment analytics for reliable industry ready tasks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15509v1</guid></item><item><title>[cs updates on arXiv.org] AdversaRiskQA: An Adversarial Factuality Benchmark for High-Risk Domains</title><link>https://arxiv.org/abs/2601.15511</link><description>arXiv:2601.15511v1 Announce Type: new 
Abstract: Hallucination in large language models (LLMs) remains an acute concern, contributing to the spread of misinformation and diminished public trust, particularly in high-risk domains. Among hallucination types, factuality is crucial, as it concerns a model's alignment with established world knowledge. Adversarial factuality, defined as the deliberate insertion of misinformation into prompts with varying levels of expressed confidence, tests a model's ability to detect and resist confidently framed falsehoods. Existing work lacks high-quality, domain-specific resources for assessing model robustness under such adversarial conditions, and no prior research has examined the impact of injected misinformation on long-form text factuality.
  To address this gap, we introduce AdversaRiskQA, the first verified and reliable benchmark systematically evaluating adversarial factuality across Health, Finance, and Law. The benchmark includes two difficulty levels to test LLMs' defensive capabilities across varying knowledge depths. We propose two automated methods for evaluating the adversarial attack success and long-form factuality. We evaluate six open- and closed-source LLMs from the Qwen, GPT-OSS, and GPT families, measuring misinformation detection rates. Long-form factuality is assessed on Qwen3 (30B) under both baseline and adversarial conditions. Results show that after excluding meaningless responses, Qwen3 (80B) achieves the highest average accuracy, while GPT-5 maintains consistently high accuracy. Performance scales non-linearly with model size, varies by domains, and gaps between difficulty levels narrow as models grow. Long-form evaluation reveals no significant correlation between injected misinformation and the model's factual output. AdversaRiskQA provides a valuable benchmark for pinpointing LLM weaknesses and developing more reliable models for high-stakes applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15511v1</guid></item><item><title>[cs updates on arXiv.org] DCeption: Real-world Wireless Man-in-the-Middle Attacks Against CCS EV Charging</title><link>https://arxiv.org/abs/2601.15515</link><description>arXiv:2601.15515v1 Announce Type: new 
Abstract: The adoption of Electric Vehicles (EVs) is happening at a rapid pace. To ensure fast and safe charging, complex communication is required between the vehicle and the charging station. In the globally used Combined Charging System (CCS), this communication is carried over the HomePlug Green PHY (HPGP) physical layer. However, HPGP is known to suffer from wireless leakage, which may expose this data link to nearby attackers.
  In this paper, we examine active wireless attacks against CCS, and study the impact they can have. We present the first real-time Software-Defined Radio (SDR) implementation of HPGP, granting unprecedented access to the communications within the charging cables. We analyze the characteristics of 2,750 real-world charging sessions to understand the timing constraints for hijacking. Using novel techniques to increase the attacks' reliability, we design a robust wireless Man-in-the-Middle evaluation framework for CCS.
  We demonstrate full control over TLS usage and CCS protocol version negotiation, including TLS stripping attacks. We investigate how real devices respond to safety-critical MitM attacks, which modify power delivery information, and found target vehicles to be highly permissive. First, we caused a vehicle to display charging power exceeding 900 kW on the dashboard, while receiving only 40 kW. Second, we remotely overcharged a vehicle, at twice the requested current for 17 seconds before the vehicle triggered the emergency shutdown. Finally, we propose a backwards-compatible, downgrade-proof protocol extension to mitigate the underlying vulnerabilities.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15515v1</guid></item><item><title>[cs updates on arXiv.org] DeltaDorsal: Enhancing Hand Pose Estimation with Dorsal Features in Egocentric Views</title><link>https://arxiv.org/abs/2601.15516</link><description>arXiv:2601.15516v1 Announce Type: new 
Abstract: The proliferation of XR devices has made egocentric hand pose estimation a vital task, yet this perspective is inherently challenged by frequent finger occlusions. To address this, we propose a novel approach that leverages the rich information in dorsal hand skin deformation, unlocked by recent advances in dense visual featurizers. We introduce a dual-stream delta encoder that learns pose by contrasting features from a dynamic hand with a baseline relaxed position. Our evaluation demonstrates that, using only cropped dorsal images, our method reduces the Mean Per Joint Angle Error (MPJAE) by 18% in self-occluded scenarios (fingers &gt;=50% occluded) compared to state-of-the-art techniques that depend on the whole hand's geometry and large model backbones. Consequently, our method not only enhances the reliability of downstream tasks like index finger pinch and tap estimation in occluded scenarios but also unlocks new interaction paradigms, such as detecting isometric force for a surface "click" without visible movement while minimizing model size.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15516v1</guid></item><item><title>[cs updates on arXiv.org] DS@GT at TREC TOT 2025: Bridging Vague Recollection with Fusion Retrieval and Learned Reranking</title><link>https://arxiv.org/abs/2601.15518</link><description>arXiv:2601.15518v1 Announce Type: new 
Abstract: We develop a two-stage retrieval system that combines multiple complementary retrieval methods with a learned reranker and LLM-based reranking, to address the TREC Tip-of-the-Tongue (ToT) task. In the first stage, we employ hybrid retrieval that merges LLM-based retrieval, sparse (BM25), and dense (BGE-M3) retrieval methods. We also introduce topic-aware multi-index dense retrieval that partitions the Wikipedia corpus into 24 topical domains. In the second stage, we evaluate both a trained LambdaMART reranker and LLM-based reranking. To support model training, we generate 5000 synthetic ToT queries using LLMs. Our best system achieves recall of 0.66 and NDCG@1000 of 0.41 on the test set by combining hybrid retrieval with Gemini-2.5-flash reranking, demonstrating the effectiveness of fusion retrieval.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15518v1</guid></item><item><title>[cs updates on arXiv.org] TransportAgents: a multi-agents LLM framework for traffic accident severity prediction</title><link>https://arxiv.org/abs/2601.15519</link><description>arXiv:2601.15519v1 Announce Type: new 
Abstract: Accurate prediction of traffic crash severity is critical for improving emergency response and public safety planning. Although recent large language models (LLMs) exhibit strong reasoning capabilities, their single-agent architectures often struggle with heterogeneous, domain-specific crash data and tend to generate biased or unstable predictions. To address these limitations, this paper proposes TransportAgents, a hybrid multi-agent framework that integrates category-specific LLM reasoning with a multilayer perceptron (MLP) integration module. Each specialized agent focuses on a particular subset of traffic information, such as demographics, environmental context, or incident details, to produce intermediate severity assessments that are subsequently fused into a unified prediction. Extensive experiments on two complementary U.S. datasets, the Consumer Product Safety Risk Management System (CPSRMS) and the National Electronic Injury Surveillance System (NEISS), demonstrate that TransportAgents consistently outperforms both traditional machine learning and advanced LLM-based baselines. Across three representative backbones, including closed-source models such as GPT-3.5 and GPT-4o, as well as open-source models such as LLaMA-3.3, the framework exhibits strong robustness, scalability, and cross-dataset generalizability. A supplementary distributional analysis further shows that TransportAgents produces more balanced and well-calibrated severity predictions than standard single-agent LLM approaches, highlighting its interpretability and reliability for safety-critical decision support applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15519v1</guid></item><item><title>[cs updates on arXiv.org] Securing LLM-as-a-Service for Small Businesses: An Industry Case Study of a Distributed Chatbot Deployment Platform</title><link>https://arxiv.org/abs/2601.15528</link><description>arXiv:2601.15528v1 Announce Type: new 
Abstract: Large Language Model (LLM)-based question-answering systems offer significant potential for automating customer support and internal knowledge access in small businesses, yet their practical deployment remains challenging due to infrastructure costs, engineering complexity, and security risks, particularly in retrieval-augmented generation (RAG)-based settings. This paper presents an industry case study of an open-source, multi-tenant platform that enables small businesses to deploy customised LLM-based support chatbots via a no-code workflow. The platform is built on distributed, lightweight k3s clusters spanning heterogeneous, low-cost machines and interconnected through an encrypted overlay network, enabling cost-efficient resource pooling while enforcing container-based isolation and per-tenant data access controls. In addition, the platform integrates practical, platform-level defences against prompt injection attacks in RAG-based chatbots, translating insights from recent prompt injection research into deployable security mechanisms without requiring model retraining or enterprise-scale infrastructure. We evaluate the proposed platform through a real-world e-commerce deployment, demonstrating that secure and efficient LLM-based chatbot services can be achieved under realistic cost, operational, and security constraints faced by small businesses.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15528v1</guid></item><item><title>[cs updates on arXiv.org] Resource Allocation and Sharing for UAV-Assisted Integrated TN-NTN with Multi-Connectivity</title><link>https://arxiv.org/abs/2601.15532</link><description>arXiv:2601.15532v1 Announce Type: new 
Abstract: Unmanned aerial vehicles (UAVs) with multi- connectivity (MC) capabilities efficiently and reliably transfer data between terrestrial networks (TNs) and non-terrestrial networks (NTNs). However, optimally sharing and allocating spectrum and power resources to maintain MC while ensuring reliable connectivity and optimal performance remains challeng- ing in such networks. Channel variations induced by mobility in UAV networks, coupled with the varying quality of service (QoS) demands of heterogeneous devices, resource sharing, and fairness requirements in capacity distribution pose challenges to optimal resource allocation. Thus, this paper investigates resource allocation for QoS-constrained, MC-enabled, dynamic UAVs in an integrated TN-NTN environment with spectrum sharing and fairness considerations. To this end, we consider three types of links: UAV-to-radio base station (RBS), UAV-to-UAV, and UAV-to-HAP. We also assume two types of UAVs with diverse QoS requirements to reflect a practical scenario. Consequently, we propose two algorithms. The first algorithm maximizes the capacity of UAVs-RBS and UAVs-HAP links while ensuring the reliability of the UAV-UAV link. To achieve this, the algorithm maximizes the collective throughput of the UAVs by optimizing the sum capacity of all the UAV-RBS and UAV-HAP links. Next, to provide constant capacity to all links and ensure fairness, we propose another algorithm that maximizes the minimum capacity across all links. We validate the performance of both algorithms through simulation</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15532v1</guid></item><item><title>[cs updates on arXiv.org] From Generative Engines to Actionable Simulators: The Imperative of Physical Grounding in World Models</title><link>https://arxiv.org/abs/2601.15533</link><description>arXiv:2601.15533v1 Announce Type: new 
Abstract: A world model is an AI system that simulates how an environment evolves under actions, enabling planning through imagined futures rather than reactive perception. Current world models, however, suffer from visual conflation: the mistaken assumption that high-fidelity video generation implies an understanding of physical and causal dynamics. We show that while modern models excel at predicting pixels, they frequently violate invariant constraints, fail under intervention, and break down in safety-critical decision-making. This survey argues that visual realism is an unreliable proxy for world understanding. Instead, effective world models must encode causal structure, respect domain-specific constraints, and remain stable over long horizons. We propose a reframing of world models as actionable simulators rather than visual engines, emphasizing structured 4D interfaces, constraint-aware dynamics, and closed-loop evaluation. Using medical decision-making as an epistemic stress test, where trial-and-error is impossible and errors are irreversible, we demonstrate that a world model's value is determined not by how realistic its rollouts appear, but by its ability to support counterfactual reasoning, intervention planning, and robust long-horizon foresight.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15533v1</guid></item><item><title>[cs updates on arXiv.org] QUAIL: Quantization Aware Unlearning for Mitigating Misinformation in LLMs</title><link>https://arxiv.org/abs/2601.15538</link><description>arXiv:2601.15538v1 Announce Type: new 
Abstract: Machine unlearning aims to remove specific knowledge (e.g., copyrighted or private data) from a trained model without full retraining. In practice, models are often quantized (e.g., 4-bit) for deployment, but we find that quantization can catastrophically restore forgotten information [1]. In this paper, we (1) analyze why low-bit quantization undermines unlearning, and (2) propose a quantization-aware unlearning method to mitigate this. We first compute weight-change statistics and bucket overlaps in quantization to show that typical unlearning updates are too small to cross quantization thresholds. Building on this insight, we introduce a logits space hinge loss: for each forget example, we force the output logits of the unlearned model to differ from the original model by at least a margin (half the quantization step). This ensures forgotten examples remain distinguishable even after quantization. We evaluate on language and classification tasks (including a Twitter misinformation dataset) and show our method preserves forgetting under 4-bit quantization, whereas existing methods almost entirely recover the forgotten knowledge.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15538v1</guid></item><item><title>[cs updates on arXiv.org] PRISM: Deriving the Transformer as a Signal-Denoising Operator via Maximum Coding Rate Reduction</title><link>https://arxiv.org/abs/2601.15540</link><description>arXiv:2601.15540v1 Announce Type: new 
Abstract: Deep learning models, particularly Transformers, are often criticized as "black boxes" and lack interpretability. We propose Prism, a white-box attention-based architecture derived from the principles of Maximizing Coding Rate Reduction ($\text{MCR}^2$). By modeling the attention mechanism as a gradient ascent process on a distinct signal-noise manifold, we introduce two physical constraints: an overcomplete dictionary to expand the representational phase space, and an irrational frequency separation ($\pi$-RoPE) to enforce incoherence between signal and noise subspaces. We demonstrate that these geometric inductive biases can be viewed as a physical constraint and they are sufficient to induce unsupervised functional disentanglement alone. Using TinyStories as a controlled testbed for verifying spectral dynamics, we observe that Prism spontaneously specializes its attention heads into spectrally distinct regimes: low-frequency heads capturing long-range causal dependencies (signal) and high-frequency heads handling local syntactic constraints (noise). Our results suggest that interpretability and performance are not a trade-off, but can be unified through principled geometric construction.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15540v1</guid></item><item><title>[cs updates on arXiv.org] CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation</title><link>https://arxiv.org/abs/2601.15541</link><description>arXiv:2601.15541v1 Announce Type: new 
Abstract: We propose a CompliantVLA-adaptor that augments the state-of-the-art Vision-Language-Action (VLA) models with vision-language model (VLM)-informed context-aware variable impedance control (VIC) to improve the safety and effectiveness of contact-rich robotic manipulation tasks. Existing VLA systems (e.g., RDT, Pi0, OpenVLA-oft) typically output position, but lack force-aware adaptation, leading to unsafe or failed interactions in physical tasks involving contact, compliance, or uncertainty. In the proposed CompliantVLA-adaptor, a VLM interprets task context from images and natural language to adapt the stiffness and damping parameters of a VIC controller. These parameters are further regulated using real-time force/torque feedback to ensure interaction forces remain within safe thresholds. We demonstrate that our method outperforms the VLA baselines on a suite of complex contact-rich tasks, both in simulation and on real hardware, with improved success rates and reduced force violations. The overall success rate across all tasks increases from 9.86\% to 17.29\%, presenting a promising path towards safe contact-rich manipulation using VLAs. We release our code, prompts, and force-torque-impedance-scenario context datasets at https://sites.google.com/view/compliantvla.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15541v1</guid></item><item><title>[cs updates on arXiv.org] RDumb++: Drift-Aware Continual Test-Time Adaptation</title><link>https://arxiv.org/abs/2601.15544</link><description>arXiv:2601.15544v1 Announce Type: new 
Abstract: Continual Test-Time Adaptation (CTTA) seeks to update a pretrained model during deployment using only the incoming, unlabeled data stream. Although prior approaches such as Tent, EATA etc. provide meaningful improvements under short evolving shifts, they struggle when the test distribution changes rapidly or over extremely long horizons. This challenge is exemplified by the CCC benchmark, where models operate over streams of 7.5M samples with continually changing corruption types and severities. We propose RDumb++, a principled extension of RDumb that introduces two drift-detection mechanisms i.e entropy-based drift scoring and KL-divergence drift scoring, together with adaptive reset strategies. These mechanisms allow the model to detect when accumulated adaptation becomes harmful and to recover before prediction collapse occurs. Across CCC-medium with three speeds and three seeds (nine runs, each containing one million samples), RDumb++ consistently surpasses RDumb, yielding approx 3% absolute accuracy gains while maintaining stable adaptation throughout the entire stream. Ablation experiments on drift thresholds and reset strengths further show that drift-aware resetting is essential for preventing collapse and achieving reliable long-horizon CTTA.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15544v1</guid></item><item><title>[cs updates on arXiv.org] Learning Neural Operators from Partial Observations via Latent Autoregressive Modeling</title><link>https://arxiv.org/abs/2601.15547</link><description>arXiv:2601.15547v1 Announce Type: new 
Abstract: Real-world scientific applications frequently encounter incomplete observational data due to sensor limitations, geographic constraints, or measurement costs. Although neural operators significantly advanced PDE solving in terms of computational efficiency and accuracy, their underlying assumption of fully-observed spatial inputs severely restricts applicability in real-world applications. We introduce the first systematic framework for learning neural operators from partial observation. We identify and formalize two fundamental obstacles: (i) the supervision gap in unobserved regions that prevents effective learning of physical correlations, and (ii) the dynamic spatial mismatch between incomplete inputs and complete solution fields. Specifically, our proposed Latent Autoregressive Neural Operator~(\ours) introduces two novel components designed explicitly to address the core difficulties of partial observations: (i) a mask-to-predict training strategy that creates artificial supervision by strategically masking observed regions, and (ii) a Physics-Aware Latent Propagator that reconstructs solutions through boundary-first autoregressive generation in latent space. Additionally, we develop POBench-PDE, a dedicated and comprehensive benchmark designed specifically for evaluating neural operators under partial observation conditions across three PDE-governed tasks. \ours achieves state-of-the-art performance with 18--69$\%$ relative L2 error reduction across all benchmarks under patch-wise missingness with less than 50$\%$ missing rate, including real-world climate prediction. Our approach effectively addresses practical scenarios involving up to 75$\%$ missing rate, to some extent bridging the existing gap between idealized research settings and the complexities of real-world scientific computing.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15547v1</guid></item><item><title>[cs updates on arXiv.org] VIOLA: Towards Video In-Context Learning with Minimal Annotations</title><link>https://arxiv.org/abs/2601.15549</link><description>arXiv:2601.15549v1 Announce Type: new 
Abstract: Generalizing Multimodal Large Language Models (MLLMs) to novel video domains is essential for real-world deployment but remains challenging due to the scarcity of labeled data. While In-Context Learning (ICL) offers a training-free adaptation path, standard methods rely on large annotated pools, which are often impractical in specialized environments like industrial or surgical settings since they require the experts' annotations. To bridge this gap, we introduce VIOLA (Video In-cOntext Learning with minimal Annotation), a label-efficient framework that synergizes minimal expert supervision with abundant unlabeled data. First, to maximize the efficiency of a strict annotation budget, we propose density-uncertainty-weighted sampling. Unlike standard diversity or uncertainty strategies that risk selecting visual outliers, our method leverages density estimation to identify samples that are simultaneously diverse, representative, and informative. Second, to utilize the remaining unlabeled data without noise propagation, we construct a hybrid pool and introduce confidence-aware retrieval and confidence-aware prompting. These mechanisms explicitly model label reliability, retrieving demonstrations based on a composite score of similarity and confidence while enabling the MLLM to adaptively distinguish between verified ground truths and noisy pseudo-labels. Extensive experiments across nine diverse benchmarks using four MLLMs demonstrate that our framework significantly outperforms various baselines in low-resource settings, achieving robust adaptation with minimal annotation costs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15549v1</guid></item><item><title>[cs updates on arXiv.org] Common to Whom? Regional Cultural Commonsense and LLM Bias in India</title><link>https://arxiv.org/abs/2601.15550</link><description>arXiv:2601.15550v1 Announce Type: new 
Abstract: Existing cultural commonsense benchmarks treat nations as monolithic, assuming uniform practices within national boundaries. But does cultural commonsense hold uniformly within a nation, or does it vary at the sub-national level? We introduce Indica, the first benchmark designed to test LLMs' ability to address this question, focusing on India - a nation of 28 states, 8 union territories, and 22 official languages. We collect human-annotated answers from five Indian regions (North, South, East, West, and Central) across 515 questions spanning 8 domains of everyday life, yielding 1,630 region-specific question-answer pairs. Strikingly, only 39.4% of questions elicit agreement across all five regions, demonstrating that cultural commonsense in India is predominantly regional, not national. We evaluate eight state-of-the-art LLMs and find two critical gaps: models achieve only 13.4%-20.9% accuracy on region-specific questions, and they exhibit geographic bias, over-selecting Central and North India as the "default" (selected 30-40% more often than expected) while under-representing East and West. Beyond India, our methodology provides a generalizable framework for evaluating cultural commonsense in any culturally heterogeneous nation, from question design grounded in anthropological taxonomy, to regional data collection, to bias measurement.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15550v1</guid></item><item><title>[cs updates on arXiv.org] ALIGNAgent: Adaptive Learner Intelligence for Gap Identification and Next-step guidance</title><link>https://arxiv.org/abs/2601.15551</link><description>arXiv:2601.15551v1 Announce Type: new 
Abstract: Personalized learning systems have emerged as a promising approach to enhance student outcomes by tailoring educational content, pacing, and feedback to individual needs. However, most existing systems remain fragmented, specializing in either knowledge tracing, diagnostic modeling, or resource recommendation, but rarely integrating these components into a cohesive adaptive cycle. In this paper, we propose ALIGNAgent (Adaptive Learner Intelligence for Gap Identification and Next-step guidance), a multi-agent educational framework designed to deliver personalized learning through integrated knowledge estimation, skill-gap identification, and targeted resource recommendation.ALIGNAgent begins by processing student quiz performance, gradebook data, and learner preferences to generate topic-level proficiency estimates using a Skill Gap Agent that employs concept-level diagnostic reasoning to identify specific misconceptions and knowledge deficiencies. After identifying skill gaps, the Recommender Agent retrieves preference-aware learning materials aligned with diagnosed deficiencies, implementing a continuous feedback loop where interventions occur before advancing to subsequent topics. Extensive empirical evaluation on authentic datasets from two undergraduate computer science courses demonstrates ALIGNAgent's effectiveness, with GPT-4o-based agents achieving precision of 0.87-0.90 and F1 scores of 0.84-0.87 in knowledge proficiency estimation validated against actual exam performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15551v1</guid></item><item><title>[cs updates on arXiv.org] BanditLP: Large-Scale Stochastic Optimization for Personalized Recommendations</title><link>https://arxiv.org/abs/2601.15552</link><description>arXiv:2601.15552v1 Announce Type: new 
Abstract: We present BanditLP, a scalable multi-stakeholder contextual bandit framework that unifies neural Thompson Sampling for learning objective-specific outcomes with a large-scale linear program for constrained action selection at serving time. The methodology is application-agnostic, compatible with arbitrary neural architectures, and deployable at web scale, with an LP solver capable of handling billions of variables. Experiments on public benchmarks and synthetic data show consistent gains over strong baselines. We apply this approach in LinkedIn's email marketing system and demonstrate business win, illustrating the value of integrated exploration and constrained optimization in production.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15552v1</guid></item><item><title>[cs updates on arXiv.org] LLM or Human? Perceptions of Trust and Information Quality in Research Summaries</title><link>https://arxiv.org/abs/2601.15556</link><description>arXiv:2601.15556v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly used to generate and edit scientific abstracts, yet their integration into academic writing raises questions about trust, quality, and disclosure. Despite growing adoption, little is known about how readers perceive LLM-generated summaries and how these perceptions influence evaluations of scientific work. This paper presents a mixed-methods survey experiment investigating whether readers with ML expertise can distinguish between human- and LLM-generated abstracts, how actual and perceived LLM involvement affects judgments of quality and trustworthiness, and what orientations readers adopt toward AI-assisted writing. Our findings show that participants struggle to reliably identify LLM-generated content, yet their beliefs about LLM involvement significantly shape their evaluations. Notably, abstracts edited by LLMs are rated more favorably than those written solely by humans or LLMs. We also identify three distinct reader orientations toward LLM-assisted writing, offering insights into evolving norms and informing policy around disclosure and acceptable use in scientific communication.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15556v1</guid></item><item><title>[cs updates on arXiv.org] From Generation to Collaboration: Using LLMs to Edit for Empathy in Healthcare</title><link>https://arxiv.org/abs/2601.15558</link><description>arXiv:2601.15558v1 Announce Type: new 
Abstract: Clinical empathy is essential for patient care, but physicians need continually balance emotional warmth with factual precision under the cognitive and emotional constraints of clinical practice. This study investigates how large language models (LLMs) can function as empathy editors, refining physicians' written responses to enhance empathetic tone while preserving underlying medical information. More importantly, we introduce novel quantitative metrics, an Empathy Ranking Score and a MedFactChecking Score to systematically assess both emotional and factual quality of the responses. Experimental results show that LLM edited responses significantly increase perceived empathy while preserving factual accuracy compared with fully LLM generated outputs. These findings suggest that using LLMs as editorial assistants, rather than autonomous generators, offers a safer, more effective pathway to empathetic and trustworthy AI-assisted healthcare communication.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15558v1</guid></item><item><title>[cs updates on arXiv.org] Relative Classification Accuracy: A Calibrated Metric for Identity Consistency in Fine-Grained K-pop Face Generation</title><link>https://arxiv.org/abs/2601.15560</link><description>arXiv:2601.15560v1 Announce Type: new 
Abstract: Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable success in high-fidelity image generation. However, evaluating their semantic controllability-specifically for fine-grained, single-domain tasks-remains challenging. Standard metrics like FID and Inception Score (IS) often fail to detect identity misalignment in such specialized contexts. In this work, we investigate Class-Conditional DDPMs for K-pop idol face generation (32x32), a domain characterized by high inter-class similarity. We propose a calibrated metric, Relative Classification Accuracy (RCA), which normalizes generative performance against an oracle classifier's baseline. Our evaluation reveals a critical trade-off: while the model achieves high visual quality (FID 8.93), it suffers from severe semantic mode collapse (RCA 0.27), particularly for visually ambiguous identities. We analyze these failure modes through confusion matrices and attribute them to resolution constraints and intra-gender ambiguity. Our framework provides a rigorous standard for verifying identity consistency in conditional generative models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15560v1</guid></item><item><title>[cs updates on arXiv.org] Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial Optimization Problems</title><link>https://arxiv.org/abs/2601.15561</link><description>arXiv:2601.15561v1 Announce Type: new 
Abstract: This article critically investigates the limitations of the simulated annealing algorithm using probabilistic bits (pSA) in solving large-scale combinatorial optimization problems. The study begins with an in-depth analysis of the pSA process, focusing on the issues resulting from unexpected oscillations among p-bits. These oscillations hinder the energy reduction of the Ising model and thus obstruct the successful execution of pSA in complex tasks. Through detailed simulations, we unravel the root cause of this energy stagnation, identifying the feedback mechanism inherent to the pSA operation as the primary contributor to these disruptive oscillations. To address this challenge, we propose two novel algorithms, time average pSA (TApSA) and stalled pSA (SpSA). These algorithms are designed based on partial deactivation of p-bits and are thoroughly tested using Python simulations on maximum cut benchmarks that are typical combinatorial optimization problems. On the 16 benchmarks from 800 to 5,000 nodes, the proposed methods improve the normalized cut value from 0.8% to 98.4% on average in comparison with the conventional pSA.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15561v1</guid></item><item><title>[cs updates on arXiv.org] PromptHelper: A Prompt Recommender System for Encouraging Creativity in AI Chatbot Interactions</title><link>https://arxiv.org/abs/2601.15575</link><description>arXiv:2601.15575v1 Announce Type: new 
Abstract: Prompting is central to interaction with AI systems, yet many users struggle to explore alternative directions, articulate creative intent, or understand how variations in prompts shape model outputs. We introduce prompt recommender systems (PRS) as an interaction approach that supports exploration, suggesting contextually relevant follow-up prompts. We present PromptHelper, a PRS prototype integrated into an AI chatbot that surfaces semantically diverse prompt suggestions while users work on real writing tasks. We evaluate PromptHelper in a 2x2 fully within-subjects study (N=32) across creative and academic writing tasks. Results show that PromptHelper significantly increases users' perceived exploration and expressiveness without increasing cognitive workload. Qualitative findings illustrate how prompt recommendations help users branch into new directions, overcome uncertainty about what to ask next, and better articulate their intent. We discuss implications for designing AI interfaces that scaffold exploratory interaction while preserving user agency, and release open-source resources to support research on prompt recommendation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15575v1</guid></item><item><title>[cs updates on arXiv.org] MapViT: A Two-Stage ViT-Based Framework for Real-Time Radio Quality Map Prediction in Dynamic Environments</title><link>https://arxiv.org/abs/2601.15578</link><description>arXiv:2601.15578v1 Announce Type: new 
Abstract: Recent advancements in mobile and wireless networks are unlocking the full potential of robotic autonomy, enabling robots to take advantage of ultra-low latency, high data throughput, and ubiquitous connectivity. However, for robots to navigate and operate seamlessly, efficiently and reliably, they must have an accurate understanding of both their surrounding environment and the quality of radio signals. Achieving this in highly dynamic and ever-changing environments remains a challenging and largely unsolved problem. In this paper, we introduce MapViT, a two-stage Vision Transformer (ViT)-based framework inspired by the success of pre-train and fine-tune paradigm for Large Language Models (LLMs). MapViT is designed to predict both environmental changes and expected radio signal quality. We evaluate the framework using a set of representative Machine Learning (ML) models, analyzing their respective strengths and limitations across different scenarios. Experimental results demonstrate that the proposed two-stage pipeline enables real-time prediction, with the ViT-based implementation achieving a strong balance between accuracy and computational efficiency. This makes MapViT a promising solution for energy- and resource-constrained platforms such as mobile robots. Moreover, the geometry foundation model derived from the self-supervised pre-training stage improves data efficiency and transferability, enabling effective downstream predictions even with limited labeled data. Overall, this work lays the foundation for next-generation digital twin ecosystems, and it paves the way for a new class of ML foundation models driving multi-modal intelligence in future 6G-enabled systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15578v1</guid></item><item><title>[cs updates on arXiv.org] YuFeng-XGuard: A Reasoning-Centric, Interpretable, and Flexible Guardrail Model for Large Language Models</title><link>https://arxiv.org/abs/2601.15588</link><description>arXiv:2601.15588v1 Announce Type: new 
Abstract: As large language models (LLMs) are increasingly deployed in real-world applications, safety guardrails are required to go beyond coarse-grained filtering and support fine-grained, interpretable, and adaptable risk assessment. However, existing solutions often rely on rapid classification schemes or post-hoc rules, resulting in limited transparency, inflexible policies, or prohibitive inference costs. To this end, we present YuFeng-XGuard, a reasoning-centric guardrail model family designed to perform multi-dimensional risk perception for LLM interactions. Instead of producing opaque binary judgments, YuFeng-XGuard generates structured risk predictions, including explicit risk categories and configurable confidence scores, accompanied by natural language explanations that expose the underlying reasoning process. This formulation enables safety decisions that are both actionable and interpretable. To balance decision latency and explanatory depth, we adopt a tiered inference paradigm that performs an initial risk decision based on the first decoded token, while preserving ondemand explanatory reasoning when required. In addition, we introduce a dynamic policy mechanism that decouples risk perception from policy enforcement, allowing safety policies to be adjusted without model retraining. Extensive experiments on a diverse set of public safety benchmarks demonstrate that YuFeng-XGuard achieves stateof-the-art performance while maintaining strong efficiency-efficacy trade-offs. We release YuFeng-XGuard as an open model family, including both a full-capacity variant and a lightweight version, to support a wide range of deployment scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15588v1</guid></item><item><title>[cs updates on arXiv.org] Deep Learning for Perishable Inventory Systems with Human Knowledge</title><link>https://arxiv.org/abs/2601.15589</link><description>arXiv:2601.15589v1 Announce Type: new 
Abstract: Managing perishable products with limited lifetimes is a fundamental challenge in inventory management, as poor ordering decisions can quickly lead to stockouts or excessive waste. We study a perishable inventory system with random lead times in which both the demand process and the lead time distribution are unknown. We consider a practical setting where orders are placed using limited historical data together with observed covariates and current system states. To improve learning efficiency under limited data, we adopt a marginal cost accounting scheme that assigns each order a single lifetime cost and yields a unified loss function for end-to-end learning. This enables training a deep learning-based policy that maps observed covariates and system states directly to order quantities. We develop two end-to-end variants: a purely black-box approach that outputs order quantities directly (E2E-BB), and a structure-guided approach that embeds the projected inventory level (PIL) policy, capturing inventory effects through explicit computation rather than additional learning (E2E-PIL). We further show that the objective induced by E2E-PIL is homogeneous of degree one, enabling a boosting technique from operational data analytics (ODA) that yields an enhanced policy (E2E-BPIL). Experiments on synthetic and real data establish a robust performance ordering: E2E-BB is dominated by E2E-PIL, which is further improved by E2E-BPIL. Using an excess-risk decomposition, we show that embedding heuristic policy structure reduces effective model complexity and improves learning efficiency with only a modest loss of flexibility. More broadly, our results suggest that deep learning-based decision tools are more effective and robust when guided by human knowledge, highlighting the value of integrating advanced analytics with inventory theory.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15589v1</guid></item><item><title>[cs updates on arXiv.org] Parallelism and Generation Order in Masked Diffusion Language Models: Limits Today, Potential Tomorrow</title><link>https://arxiv.org/abs/2601.15593</link><description>arXiv:2601.15593v1 Announce Type: new 
Abstract: Masked Diffusion Language Models (MDLMs) promise parallel token generation and arbitrary-order decoding, yet it remains unclear to what extent current models truly realize these capabilities. We characterize MDLM behavior along two dimensions -- parallelism strength and generation order -- using Average Finalization Parallelism (AFP) and Kendall's tau. We evaluate eight mainstream MDLMs (up to 100B parameters) on 58 benchmarks spanning knowledge, reasoning, and programming. The results show that MDLMs still lag behind comparably sized autoregressive models, mainly because parallel probabilistic modeling weakens inter-token dependencies. Meanwhile, MDLMs exhibit adaptive decoding behavior: their parallelism and generation order vary significantly with the task domain, the stage of reasoning, and whether the output is correct. On tasks that require "backward information" (e.g., Sudoku), MDLMs adopt a solution order that tends to fill easier Sudoku blanks first, highlighting their advantages. Finally, we provide theoretical motivation and design insights supporting a Generate-then-Edit paradigm, which mitigates dependency loss while retaining the efficiency of parallel decoding.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15593v1</guid></item><item><title>[cs updates on arXiv.org] Blockchain-Based Spectrum Resource Securitization via Semi-Fungible Token-Lock</title><link>https://arxiv.org/abs/2601.15594</link><description>arXiv:2601.15594v1 Announce Type: new 
Abstract: As 6G networks evolve, spectrum assets require flexible, dynamic, and efficient utilization, motivating blockchain based spectrum securitization. Existing approaches based on ERC404 style hybrid token models rely on frequent minting and burning during asset transfers, which disrupt token identity continuity and increase on chain overhead. This paper proposes the Semi Fungible Token Lock (SFT Lock) method, a lock/unlock based mechanism that preserves NFT identity and historical traceability while enabling fractional ownership and transferability. By replacing mint/burn operations with deterministic state transitions, SFT Lock ensures consistent lifecycle representation of spectrum assets and significantly reduces on chain operations. Based on this mechanism, a modular smart contract architecture is designed to support spectrum authorization, securitization, and sharing, and a staking mechanism is introduced to enhance asset liquidity. Experimental results on a private Ethereum network demonstrate that, compared with ERC404 style hybrid token models, the proposed method achieves substantial gas savings while maintaining functional correctness and traceability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15594v1</guid></item><item><title>[cs updates on arXiv.org] Data-Free Privacy-Preserving for LLMs via Model Inversion and Selective Unlearning</title><link>https://arxiv.org/abs/2601.15595</link><description>arXiv:2601.15595v1 Announce Type: new 
Abstract: Large language models (LLMs) exhibit powerful capabilities but risk memorizing sensitive personally identifiable information (PII) from their training data, posing significant privacy concerns. While machine unlearning techniques aim to remove such data, they predominantly depend on access to the training data. This requirement is often impractical, as training data in real-world deployments is commonly proprietary or inaccessible. To address this limitation, we propose Data-Free Selective Unlearning (DFSU), a novel privacy-preserving framework that removes sensitive PII from an LLM without requiring its training data. Our approach first synthesizes pseudo-PII through language model inversion, then constructs token-level privacy masks for these synthetic samples, and finally performs token-level selective unlearning via a contrastive mask loss within a low-rank adaptation (LoRA) subspace. Extensive experiments on the AI4Privacy PII-Masking dataset using Pythia models demonstrate that our method effectively removes target PII while maintaining model utility.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15595v1</guid></item><item><title>[cs updates on arXiv.org] DeepASMR: LLM-Based Zero-Shot ASMR Speech Generation for Anyone of Any Voice</title><link>https://arxiv.org/abs/2601.15596</link><description>arXiv:2601.15596v1 Announce Type: new 
Abstract: While modern Text-to-Speech (TTS) systems achieve high fidelity for read-style speech, they struggle to generate Autonomous Sensory Meridian Response (ASMR), a specialized, low-intensity speech style essential for relaxation. The inherent challenges include ASMR's subtle, often unvoiced characteristics and the demand for zero-shot speaker adaptation. In this paper, we introduce DeepASMR, the first framework designed for zero-shot ASMR generation. We demonstrate that a single short snippet of a speaker's ordinary, read-style speech is sufficient to synthesize high-fidelity ASMR in their voice, eliminating the need for whispered training data from the target speaker. Methodologically, we first identify that discrete speech tokens provide a soft factorization of ASMR style from speaker timbre. Leveraging this insight, we propose a two-stage pipeline incorporating a Large Language Model (LLM) for content-style encoding and a flow-matching acoustic decoder for timbre reconstruction. Furthermore, we contribute DeepASMR-DB, a comprehensive 670-hour English-Chinese multi-speaker ASMR speech corpus, and introduce a novel evaluation protocol integrating objective metrics, human listening tests, LLM-based scoring and unvoiced speech analysis. Extensive experiments confirm that DeepASMR achieves state-of-the-art naturalness and style fidelity in ASMR generation for anyone of any voice, while maintaining competitive performance on normal speech synthesis.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15596v1</guid></item><item><title>[cs updates on arXiv.org] Neural Nonlinear Shrinkage of Covariance Matrices for Minimum Variance Portfolio Optimization</title><link>https://arxiv.org/abs/2601.15597</link><description>arXiv:2601.15597v1 Announce Type: new 
Abstract: This paper introduces a neural network-based nonlinear shrinkage estimator of covariance matrices for the purpose of minimum variance portfolio optimization. It is a hybrid approach that integrates statistical estimation with machine learning. Starting from the Ledoit-Wolf (LW) shrinkage estimator, we decompose the LW covariance matrix into its eigenvalues and eigenvectors, and apply a lightweight transformer-based neural network to learn a nonlinear eigenvalue shrinkage function. Trained with portfolio risk as the loss function, the resulting precision matrix (the inverse covariance matrix) estimator directly targets portfolio risk minimization. By conditioning on the sample-to-dimension ratio, the approach remains scalable across different sample sizes and asset universes. Empirical results on stock daily returns from Standard &amp; Poor's 500 Index (S&amp;amp;P500) demonstrate that the proposed method consistently achieves lower out-of-sample realized risk than benchmark approaches. This highlights the promise of integrating structural statistical models with data-driven learning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15597v1</guid></item><item><title>[cs updates on arXiv.org] Ternary Spiking Neural Networks Enhanced by Complemented Neurons and Membrane Potential Aggregation</title><link>https://arxiv.org/abs/2601.15598</link><description>arXiv:2601.15598v1 Announce Type: new 
Abstract: Spiking Neural Networks (SNNs) are promising energy-efficient models and powerful framworks of modeling neuron dynamics. However, existing binary spiking neurons exhibit limited biological plausibilities and low information capacity. Recently developed ternary spiking neuron possesses higher consistency with biological principles (i.e. excitation-inhibition balance mechanism). Despite of this, the ternary spiking neuron suffers from defects including iterative information loss, temporal gradient vanishing and irregular distributions of membrane potentials. To address these issues, we propose Complemented Ternary Spiking Neuron (CTSN), a novel ternary spiking neuron model that incorporates an learnable complemental term to store information from historical inputs. CTSN effectively improves the deficiencies of ternary spiking neuron, while the embedded learnable factors enable CTSN to adaptively adjust neuron dynamics, providing strong neural heterogeneity. Furthermore, based on the temporal evolution features of ternary spiking neurons' membrane potential distributions, we propose the Temporal Membrane Potential Regularization (TMPR) training method. TMPR introduces time-varying regularization strategy utilizing membrane potentials, furhter enhancing the training process by creating extra backpropagation paths. We validate our methods through extensive experiments on various datasets, demonstrating remarkable performance advances.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15598v1</guid></item><item><title>[cs updates on arXiv.org] Autonomous Business System via Neuro-symbolic AI</title><link>https://arxiv.org/abs/2601.15599</link><description>arXiv:2601.15599v1 Announce Type: new 
Abstract: Current business environments require organizations to continuously reconfigure cross-functional processes, yet enterprise systems are still organized around siloed departments, rigid workflows, and hard-coded automation. Meanwhile large language models (LLMs) excel at interpreting natural language and unstructured data but lack deterministic, verifiable execution of complex business logic. To address this gap, here we introduce AUTOBUS, an Autonomous Business System that integrates LLM-based AI agents, predicate-logic programming, and business-semantics-centric enterprise data into a coherent neuro-symbolic AI architecture for orchestrating end-to-end business initiatives. AUTOBUS models an initiative as a network of tasks with explicit pre/post conditions, required data, evaluation rules, and API-level actions. Enterprise data is organized as a knowledge graph whose entities, relationships, and constraints are translated into logic facts and foundational rules, providing the semantic grounding for task reasoning. Core AI agents synthesize task instructions, enterprise semantics, and available tools into task-specific logic programs, which are executed by a logic engine that enforces constraints, coordinates auxiliary tools, and orchestrate execution of actions and outcomes. Humans define and maintain the semantics, policies and task instructions, curate tools, and supervise high-impact or ambiguous decisions, ensuring accountability and adaptability. We detail the AUTOBUS architecture, the anatomy of the AI agent generated logic programs, and the role of humans and auxiliary tools in the lifecycle of a business initiative.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15599v1</guid></item><item><title>[cs updates on arXiv.org] ToxiTwitch: Toward Emote-Aware Hybrid Moderation for Live Streaming Platforms</title><link>https://arxiv.org/abs/2601.15605</link><description>arXiv:2601.15605v1 Announce Type: new 
Abstract: The rapid growth of live-streaming platforms such as Twitch has introduced complex challenges in moderating toxic behavior. Traditional moderation approaches, such as human annotation and keyword-based filtering, have demonstrated utility, but human moderators on Twitch constantly struggle to scale effectively in the fast-paced, high-volume, and context-rich chat environment of the platform while also facing harassment themselves. Recent advances in large language models (LLMs), such as DeepSeek-R1-Distill and Llama-3-8B-Instruct, offer new opportunities for toxicity detection, especially in understanding nuanced, multimodal communication involving emotes. In this work, we present an exploratory comparison of toxicity detection approaches tailored to Twitch. Our analysis reveals that incorporating emotes improves the detection of toxic behavior. To this end, we introduce ToxiTwitch, a hybrid model that combines LLM-generated embeddings of text and emotes with traditional machine learning classifiers, including Random Forest and SVM. In our case study, the proposed hybrid approach reaches up to 80 percent accuracy under channel-specific training (with 13 percent improvement over BERT and F1-score of 76 percent). This work is an exploratory study intended to surface challenges and limits of emote-aware toxicity detection on Twitch.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15605v1</guid></item><item><title>[cs updates on arXiv.org] Airflow Source Seeking on Small Quadrotors Using a Single Flow Sensor</title><link>https://arxiv.org/abs/2601.15607</link><description>arXiv:2601.15607v1 Announce Type: new 
Abstract: As environmental disasters happen more frequently and severely, seeking the source of pollutants or harmful particulates using plume tracking becomes even more important. Plume tracking on small quadrotors would allow these systems to operate around humans and fly in more confined spaces, but can be challenging due to poor sensitivity and long response times from gas sensors that fit on small quadrotors. In this work, we present an approach to complement chemical plume tracking with airflow source-seeking behavior using a custom flow sensor that can sense both airflow magnitude and direction on small quadrotors &lt; 100 g. We use this sensor to implement a modified version of the `Cast and Surge' algorithm that takes advantage of flow direction sensing to find and navigate towards flow sources. A series of characterization experiments verified that the system can detect airflow while in flight and reorient the quadrotor toward the airflow. Several trials with random starting locations and orientations were used to show that our source-seeking algorithm can reliably find a flow source. This work aims to provide a foundation for future platforms that can use flow sensors in concert with other sensors to enable richer plume tracking data collection and source-seeking.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15607v1</guid></item><item><title>[cs updates on arXiv.org] When Sharpening Becomes Collapse: Sampling Bias and Semantic Coupling in RL with Verifiable Rewards</title><link>https://arxiv.org/abs/2601.15609</link><description>arXiv:2601.15609v1 Announce Type: new 
Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a central paradigm for turning large language models (LLMs) into reliable problem solvers, especially in logic-heavy domains. Despite its empirical success, it remains unclear whether RLVR elicits novel capabilities or merely sharpens the distribution over existing knowledge. We study this by formalizing over-sharpening, a phenomenon where the policy collapses onto limited modes, suppressing valid alternatives. At a high level, we discover finite-batch updates intrinsically bias learning toward sampled modes, triggering a collapse that propagates globally via semantic coupling. To mitigate this, we propose inverse-success advantage calibration to prioritize difficult queries and distribution-level calibration to diversify sampling via a memory network. Empirical evaluations validate that our strategies can effectively improve generalization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15609v1</guid></item><item><title>[cs updates on arXiv.org] AION: Aerial Indoor Object-Goal Navigation Using Dual-Policy Reinforcement Learning</title><link>https://arxiv.org/abs/2601.15614</link><description>arXiv:2601.15614v1 Announce Type: new 
Abstract: Object-Goal Navigation (ObjectNav) requires an agent to autonomously explore an unknown environment and navigate toward target objects specified by a semantic label. While prior work has primarily studied zero-shot ObjectNav under 2D locomotion, extending it to aerial platforms with 3D locomotion capability remains underexplored. Aerial robots offer superior maneuverability and search efficiency, but they also introduce new challenges in spatial perception, dynamic control, and safety assurance. In this paper, we propose AION for vision-based aerial ObjectNav without relying on external localization or global maps. AION is an end-to-end dual-policy reinforcement learning (RL) framework that decouples exploration and goal-reaching behaviors into two specialized policies. We evaluate AION on the AI2-THOR benchmark and further assess its real-time performance in IsaacSim using high-fidelity drone models. Experimental results show that AION achieves superior performance across comprehensive evaluation metrics in exploration, navigation efficiency, and safety. The video can be found at https://youtu.be/TgsUm6bb7zg.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15614v1</guid></item><item><title>[cs updates on arXiv.org] Region-aware Spatiotemporal Modeling with Collaborative Domain Generalization for Cross-Subject EEG Emotion Recognition</title><link>https://arxiv.org/abs/2601.15615</link><description>arXiv:2601.15615v1 Announce Type: new 
Abstract: Cross-subject EEG-based emotion recognition (EER) remains challenging due to strong inter-subject variability, which induces substantial distribution shifts in EEG signals, as well as the high complexity of emotion-related neural representations in both spatial organization and temporal evolution. Existing approaches typically improve spatial modeling, temporal modeling, or generalization strategies in isolation, which limits their ability to align representations across subjects while capturing multi-scale dynamics and suppressing subject-specific bias within a unified framework. To address these gaps, we propose a Region-aware Spatiotemporal Modeling framework with Collaborative Domain Generalization (RSM-CoDG) for cross-subject EEG emotion recognition. RSM-CoDG incorporates neuroscience priors derived from functional brain region partitioning to construct region-level spatial representations, thereby improving cross-subject comparability. It also employs multi-scale temporal modeling to characterize the dynamic evolution of emotion-evoked neural activity. In addition, the framework employs a collaborative domain generalization strategy, incorporating multidimensional constraints to reduce subject-specific bias in a fully unseen target subject setting, which enhances the generalization to unknown individuals. Extensive experimental results on SEED series datasets demonstrate that RSM-CoDG consistently outperforms existing competing methods, providing an effective approach for improving robustness. The source code is available at https://github.com/RyanLi-X/RSM-CoDG.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15615v1</guid></item><item><title>[cs updates on arXiv.org] Closing the Gap on the Sample Complexity of 1-Identification</title><link>https://arxiv.org/abs/2601.15620</link><description>arXiv:2601.15620v1 Announce Type: new 
Abstract: 1-identification is a fundamental multi-armed bandit formulation on pure exploration. An agent aims to determine whether there exists a qualified arm whose mean reward is not less than a known threshold $\mu_0$, or to output \textsf{None} if it believes such an arm does not exist. The agent needs to guarantee its output is correct with probability at least $1-\delta$, while making expected total pulling times $\mathbb{E}\tau$ as small as possible. We work on 1-identification with two main contributions. (1) We utilize an optimization formulation to derive a new lower bound of $\mathbb{E}\tau$, when there is at least one qualified arm. (2) We design a new algorithm, deriving tight upper bounds whose gap to lower bounds are up to a polynomial of logarithm factor across all problem instance. Our result complements the analysis of $\mathbb{E}\tau$ when there are multiple qualified arms, which is an open problem left by history literature.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15620v1</guid></item><item><title>[cs updates on arXiv.org] Design, Modelling, and Control of Magnetic Ball Suspension System</title><link>https://arxiv.org/abs/2601.15622</link><description>arXiv:2601.15622v1 Announce Type: new 
Abstract: This paper presents the modeling, control design, and performance analysis of a Magnetic Ball Suspension System (MBSS), a nonlinear and inherently unstable electromechanical system used in various precision applications. The system's primary objective is to levitate a steel ball using electromagnetic force without physical contact, thereby eliminating frictional losses. A comprehensive state-space model was developed, capturing both the mechanical and electrical dynamics. The equilibrium points of the system were determined through feedback linearization using the Jacobian matrix. To ensure system stability, controllability and observability analyses were conducted, confirming that state feedback and observer-based control strategies could be effectively implemented. Three distinct control methods were explored: pole placement-based state feedback control, full-order observer design, and optimal state feedback control using the Linear Quadratic Regulator (LQR). Each control strategy was validated through Simulink simulations for both linearized and nonlinear models. Simulation results demonstrated that the linearized system consistently achieved desired performance with minimal oscillations, whereas the nonlinear system exhibited significant transient oscillations before stabilization. The full-order observer enhanced estimation accuracy, enabling effective control where direct state measurement was impractical. The LQR-based control offered improved robustness and minimized control effort, though its performance was comparable to standard state feedback in some cases.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15622v1</guid></item><item><title>[cs updates on arXiv.org] Mapping Social Media User Behaviors in Reciprocity Space</title><link>https://arxiv.org/abs/2601.15623</link><description>arXiv:2601.15623v1 Announce Type: new 
Abstract: Social media users exhibit diverse behavioral patterns as platforms function simultaneously as information and friendship networks. We introduce a reciprocity-based framework mapping users onto two-dimensional space defined by bidirectional connection ratios. Analyzing 48,830 Twitter users and 149 million connections, we demonstrate that fragmented user types from prior studies (influencers, lurkers, brokers, and follow-back accounts) emerge naturally as regions within continuous behavioral space rather than discrete categories. User properties vary smoothly across the reciprocity dimensions, revealing clear behavioral gradients. This framework provides the first unified model encompassing the full spectrum of social media behaviors and offers interpretable metrics for influence measurement and platform design.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15623v1</guid></item><item><title>[cs updates on arXiv.org] Explainable Deepfake Detection with RL Enhanced Self-Blended Images</title><link>https://arxiv.org/abs/2601.15624</link><description>arXiv:2601.15624v1 Announce Type: new 
Abstract: Most prior deepfake detection methods lack explainable outputs. With the growing interest in multimodal large language models (MLLMs), researchers have started exploring their use in interpretable deepfake detection. However, a major obstacle in applying MLLMs to this task is the scarcity of high-quality datasets with detailed forgery attribution annotations, as textual annotation is both costly and challenging - particularly for high-fidelity forged images or videos. Moreover, multiple studies have shown that reinforcement learning (RL) can substantially enhance performance in visual tasks, especially in improving cross-domain generalization. To facilitate the adoption of mainstream MLLM frameworks in deepfake detection with reduced annotation cost, and to investigate the potential of RL in this context, we propose an automated Chain-of-Thought (CoT) data generation framework based on Self-Blended Images, along with an RL-enhanced deepfake detection framework. Extensive experiments validate the effectiveness of our CoT data construction pipeline, tailored reward mechanism, and feedback-driven synthetic data generation approach. Our method achieves performance competitive with state-of-the-art (SOTA) approaches across multiple cross-dataset benchmarks. Implementation details are available at https://github.com/deon1219/rlsbi.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15624v1</guid></item><item><title>[cs updates on arXiv.org] Robust Tool Use via Fission-GRPO: Learning to Recover from Execution Errors</title><link>https://arxiv.org/abs/2601.15625</link><description>arXiv:2601.15625v1 Announce Type: new 
Abstract: Large language models (LLMs) can call tools effectively, yet they remain brittle in multi-turn execution: following a tool call error, smaller models often degenerate into repetitive invalid re-invocations, failing to interpret error feedback and self-correct. This brittleness hinders reliable real-world deployment, where the execution errors are inherently inevitable during tool interaction procedures. We identify a key limitation of current approaches: standard reinforcement learning (RL) treats errors as sparse negative rewards, providing no guidance on how to recover, while pre-collected synthetic error-correction datasets suffer from distribution mismatch with the model's on-policy error modes. To bridge this gap, we propose Fission-GRPO, a framework that converts execution errors into corrective supervision within the RL training loop. Our core mechanism fissions each failed trajectory into a new training instance by augmenting it with diagnostic feedback from a finetuned Error Simulator, then resampling recovery rollouts on-policy. This enables the model to learn from the precise errors it makes during exploration, rather than from static, pre-collected error cases. On the BFCL v4 Multi-Turn, Fission-GRPO improves the error recovery rate of Qwen3-8B by 5.7% absolute, crucially, yielding a 4% overall accuracy gain (42.75% to 46.75%) over GRPO and outperforming specialized tool-use agents.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15625v1</guid></item><item><title>[cs updates on arXiv.org] Bridging Qualitative Rubrics and AI: A Binary Question Framework for Criterion-Referenced Grading in Engineering</title><link>https://arxiv.org/abs/2601.15626</link><description>arXiv:2601.15626v1 Announce Type: new 
Abstract: PURPOSE OR GOAL: This study investigates how GenAI can be integrated with a criterion-referenced grading framework to improve the efficiency and quality of grading for mathematical assessments in engineering. It specifically explores the challenges demonstrators face with manual, model solution-based grading and how a GenAI-supported system can be designed to reliably identify student errors, provide high-quality feedback, and support human graders. The research also examines human graders' perceptions of the effectiveness of this GenAI-assisted approach. ACTUAL OR ANTICIPATED OUTCOMES: The study found that GenAI achieved an overall grading accuracy of 92.5%, comparable to two experienced human graders. The two researchers, who also served as subject demonstrators, perceived the GenAI as a helpful second reviewer that improved accuracy by catching small errors and provided more complete feedback than they could manually. A central outcome was the significant enhancement of formative feedback. However, they noted the GenAI tool is not yet reliable enough for autonomous use, especially with unconventional solutions. CONCLUSIONS/RECOMMENDATIONS/SUMMARY: This study demonstrates that GenAI, when paired with a structured, criterion-referenced framework using binary questions, can grade engineering mathematical assessments with an accuracy comparable to human experts. Its primary contribution is a novel methodological approach that embeds the generation of high-quality, scalable formative feedback directly into the assessment workflow. Future work should investigate student perceptions of GenAI grading and feedback.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15626v1</guid></item><item><title>[cs updates on arXiv.org] CogToM: A Comprehensive Theory of Mind Benchmark inspired by Human Cognition for Large Language Models</title><link>https://arxiv.org/abs/2601.15628</link><description>arXiv:2601.15628v1 Announce Type: new 
Abstract: Whether Large Language Models (LLMs) truly possess human-like Theory of Mind (ToM) capabilities has garnered increasing attention. However, existing benchmarks remain largely restricted to narrow paradigms like false belief tasks, failing to capture the full spectrum of human cognitive mechanisms. We introduce CogToM, a comprehensive, theoretically grounded benchmark comprising over 8000 bilingual instances across 46 paradigms, validated by 49 human annotator.A systematic evaluation of 22 representative models, including frontier models like GPT-5.1 and Qwen3-Max, reveals significant performance heterogeneities and highlights persistent bottlenecks in specific dimensions. Further analysis based on human cognitive patterns suggests potential divergences between LLM and human cognitive structures. CogToM offers a robust instrument and perspective for investigating the evolving cognitive boundaries of LLMs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15628v1</guid></item><item><title>[cs updates on arXiv.org] Agentic AI Governance and Lifecycle Management in Healthcare</title><link>https://arxiv.org/abs/2601.15630</link><description>arXiv:2601.15630v1 Announce Type: new 
Abstract: Healthcare organizations are beginning to embed agentic AI into routine workflows, including clinical documentation support and early-warning monitoring. As these capabilities diffuse across departments and vendors, health systems face agent sprawl, causing duplicated agents, unclear accountability, inconsistent controls, and tool permissions that persist beyond the original use case. Existing AI governance frameworks emphasize lifecycle risk management but provide limited guidance for the day-to-day operations of agent fleets. We propose a Unified Agent Lifecycle Management (UALM) blueprint derived from a rapid, practice-oriented synthesis of governance standards, agent security literature, and healthcare compliance requirements. UALM maps recurring gaps onto five control-plane layers: (1) an identity and persona registry, (2) orchestration and cross-domain mediation, (3) PHI-bounded context and memory, (4) runtime policy enforcement with kill-switch triggers, and (5) lifecycle management and decommissioning linked to credential revocation and audit logging. A companion maturity model supports staged adoption. UALM offers healthcare CIOs, CISOs, and clinical leaders an implementable pattern for audit-ready oversight that preserves local innovation and enables safer scaling across clinical and administrative domains.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15630v1</guid></item><item><title>[cs updates on arXiv.org] Advancing RT Core-Accelerated Fixed-Radius Nearest Neighbor Search</title><link>https://arxiv.org/abs/2601.15633</link><description>arXiv:2601.15633v1 Announce Type: new 
Abstract: In this work we introduce three ideas that can further improve particle FRNN physics simulations running on RT Cores; i) a real-time update/rebuild ratio optimizer for the bounding volume hierarchy (BVH) structure, ii) a new RT core use, with two variants, that eliminates the need of a neighbor list and iii) a technique that enables RT cores for FRNN with periodic boundary conditions (BC). Experimental evaluation using the Lennard-Jones FRNN interaction model as a case study shows that the proposed update/rebuild ratio optimizer is capable of adapting to the different dynamics that emerge during a simulation, leading to a RT core pipeline up to $\sim 3.4\times$ faster than with other known approaches to manage the BVH. In terms of simulation step performance, the proposed variants can significantly improve the speedup and EE of the base RT core idea; from $\sim1.3\times$ at small radius to $\sim2.0\times$ for log normal radius distributions. Furthermore, the proposed variants manage to simulate cases that would otherwise not fit in memory because of the use of neighbor lists, such as clusters of particles with log normal radius distribution. The proposed RT Core technique to support periodic BC is indeed effective as it does not introduce any significant penalty in performance. In terms of scaling, the proposed methods scale both their performance and EE across GPU generations. Throughout the experimental evaluation, we also identify the simulation cases were regular GPU computation should still be preferred, contributing to the understanding of the strengths and limitations of RT cores.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15633v1</guid></item><item><title>[cs updates on arXiv.org] Community-Size Biases in Statistical Inference of Communities in Temporal Networks</title><link>https://arxiv.org/abs/2601.15635</link><description>arXiv:2601.15635v1 Announce Type: new 
Abstract: In the study of time-dependent (i.e., temporal) networks, researchers often examine the evolution of communities, which are sets of densely connected sets of nodes that are connected sparsely to other nodes. An increasingly prominent approach to studying community structure in temporal networks is statistical inference. In the present paper, we study the performance of a class of statistical-inference methods for community detection in temporal networks. We represent temporal networks as multilayer networks, with each layer encoding a time step, and we illustrate that statistical-inference models that generate community assignments via either a uniform distribution on community assignments or discrete-time Markov processes are biased against generating communities with large or small numbers of nodes. In particular, we demonstrate that statistical-inference methods that use such generative models tend to poorly identify community structure in networks with large or small communities. To rectify this issue, we introduce a novel statistical model that generates the community assignments of the nodes in given layer (i.e., at a given time) using all of the community assignments in the previous layer. We prove results that guarantee that our approach greatly mitigates the bias against large and small communities, so using our generative model is beneficial for studying community structure in networks with large or small communities. Our code is available at https://github.com/tfaust0196/TemporalCommunityComparison.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15635v1</guid></item><item><title>[cs updates on arXiv.org] A Class of Subadditive Information Measures and their Applications</title><link>https://arxiv.org/abs/2601.15639</link><description>arXiv:2601.15639v1 Announce Type: new 
Abstract: We introduce a two-parameter family of discrepancy measures, termed \emph{$(G,f)$-divergences}, obtained by applying a non-decreasing function $G$ to an $f$-divergence $D_f$. Building on Csisz\'ar's formulation of mutual $f$-information, we define a corresponding $(G,f)$-information measure $
I_{G,f}(X;Y)$. A central theme of the paper is subadditivity over product distributions and product channels. We develop reduction principles showing that, for broad classes of $G$, it suffices to verify divergence subadditivity on binary alphabets. Specializing to the functions $G(x)\in\{x,\log(1+x),-\log(1-x)\}$, we derive tractable sufficient conditions on $f$ that guarantee subadditivity, covering many standard $f$-divergences. Finally, we present applications to finite-blocklength converses for channel coding, bounds in binary hypothesis testing, and an extension of the Shannon--Gallager--Berlekamp sphere-packing exponent framework to subadditive $(G,f)$-divergences.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15639v1</guid></item><item><title>[cs updates on arXiv.org] An Empirical Study on Ensemble-Based Transfer Learning Bayesian Optimisation with Mixed Variable Types</title><link>https://arxiv.org/abs/2601.15640</link><description>arXiv:2601.15640v1 Announce Type: new 
Abstract: Bayesian optimisation is a sample efficient method for finding a global optimum of expensive black-box objective functions. Historic datasets from related problems can be exploited to help improve performance of Bayesian optimisation by adapting transfer learning methods to various components of the Bayesian optimisation pipeline. In this study we perform an empirical analysis of various ensemble-based transfer learning Bayesian optimisation methods and pipeline components. We expand on previous work in the literature by contributing some specific pipeline components, and three new real-time transfer learning Bayesian optimisation benchmarks. In particular we propose to use a weighting strategy for ensemble surrogate model predictions based on regularised regression with weights constrained to be positive, and a related component for handling the case when transfer learning is not improving Bayesian optimisation performance. We find that in general, two components that help improve transfer learning Bayesian optimisation performance are warm start initialisation and constraining weights used with ensemble surrogate model to be positive.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15640v1</guid></item><item><title>[cs updates on arXiv.org] Generative AI-Empowered Semantic Twin Channel Model for ISAC</title><link>https://arxiv.org/abs/2601.15642</link><description>arXiv:2601.15642v1 Announce Type: new 
Abstract: Integrated sensing and communication (ISAC) increasingly exposes a gap in today's channel modeling. Efficient statistical models focus on coarse communication-centric metrics, and therefore miss the weak but critical multipath signatures for sensing, whereas deterministic models are computationally inefficient to scale for system-level ISAC evaluation. This gap calls for a unifying abstraction that can couple what the environment means for sensing with how the channel behaves for communication, namely, environmental semantics. This article clarifies the meaning and essentiality of environmental semantics in ISAC channel modeling and establishes how semantics is connected to observable channel structures across multiple semantic levels. Based on this perspective, a semantics-oriented channel modeling principle was advocated, which preserves environmental semantics while abstracting unnecessary detail to balance accuracy and complexity. Then, a generative AI-empowered semantic twin channel model (STCM) was introduced to generate a family of physically plausible channel realizations representative of a semantic condition. Case studies further show semantic consistency under challenging multi-view settings, suggesting a practical path to controllable simulation, dataset generation, and reproducible ISAC benchmarking toward future design and standardization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15642v1</guid></item><item><title>[cs updates on arXiv.org] Evolving Without Ending: Unifying Multimodal Incremental Learning for Continual Panoptic Perception</title><link>https://arxiv.org/abs/2601.15643</link><description>arXiv:2601.15643v1 Announce Type: new 
Abstract: Continual learning (CL) is a great endeavour in developing intelligent perception AI systems. However, the pioneer research has predominantly focus on single-task CL, which restricts the potential in multi-task and multimodal scenarios. Beyond the well-known issue of catastrophic forgetting, the multi-task CL also brings semantic obfuscation across multimodal alignment, leading to severe model degradation during incremental training steps. In this paper, we extend CL to continual panoptic perception (CPP), integrating multimodal and multi-task CL to enhance comprehensive image perception through pixel-level, instance-level, and image-level joint interpretation. We formalize the CL task in multimodal scenarios and propose an end-to-end continual panoptic perception model. Concretely, CPP model features a collaborative cross-modal encoder (CCE) for multimodal embedding. We also propose a malleable knowledge inheritance module via contrastive feature distillation and instance distillation, addressing catastrophic forgetting from task-interactive boosting manner. Furthermore, we propose a cross-modal consistency constraint and develop CPP+, ensuring multimodal semantic alignment for model updating under multi-task incremental scenarios. Additionally, our proposed model incorporates an asymmetric pseudo-labeling manner, enabling model evolving without exemplar replay. Extensive experiments on multimodal datasets and diverse CL tasks demonstrate the superiority of the proposed model, particularly in fine-grained CL tasks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15643v1</guid></item><item><title>[cs updates on arXiv.org] Towards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation</title><link>https://arxiv.org/abs/2601.15645</link><description>arXiv:2601.15645v1 Announce Type: new 
Abstract: Large-scale language models (LLMs) often offer clinical judgments based on incomplete information, increasing the risk of misdiagnosis. Existing studies have primarily evaluated confidence in single-turn, static settings, overlooking the coupling between confidence and correctness as clinical evidence accumulates during real consultations, which limits their support for reliable decision-making. We propose the first benchmark for assessing confidence in multi-turn interaction during realistic medical consultations. Our benchmark unifies three types of medical data for open-ended diagnostic generation and introduces an information sufficiency gradient to characterize the confidence-correctness dynamics as evidence increases. We implement and compare 27 representative methods on this benchmark; two key insights emerge: (1) medical data amplifies the inherent limitations of token-level and consistency-level confidence methods, and (2) medical reasoning must be evaluated for both diagnostic accuracy and information completeness. Based on these insights, we present MedConf, an evidence-grounded linguistic self-assessment framework that constructs symptom profiles via retrieval-augmented generation, aligns patient information with supporting, missing, and contradictory relations, and aggregates them into an interpretable confidence estimate through weighted integration. Across two LLMs and three medical datasets, MedConf consistently outperforms state-of-the-art methods on both AUROC and Pearson correlation coefficient metrics, maintaining stable performance under conditions of information insufficiency and multimorbidity. These results demonstrate that information adequacy is a key determinant of credible medical confidence modeling, providing a new pathway toward building more reliable and interpretable large medical models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15645v1</guid></item><item><title>[cs updates on arXiv.org] Predictive Coding and Information Bottleneck for Hallucination Detection in Large Language Models</title><link>https://arxiv.org/abs/2601.15652</link><description>arXiv:2601.15652v1 Announce Type: new 
Abstract: Hallucinations in Large Language Models (LLMs) -- generations that are plausible but factually unfaithful -- remain a critical barrier to high-stakes deployment. Current detection methods typically rely on computationally expensive external retrieval loops or opaque black-box LLM judges requiring 70B+ parameters. In this work, we introduce [Model Name], a hybrid detection framework that combines neuroscience-inspired signal design with supervised machine learning. We extract interpretable signals grounded in Predictive Coding (quantifying surprise against internal priors) and the Information Bottleneck (measuring signal retention under perturbation). Through systematic ablation, we demonstrate three key enhancements: Entity-Focused Uptake (concentrating on high-value tokens), Context Adherence (measuring grounding strength), and Falsifiability Score (detecting confident but contradictory claims).
  Evaluating on HaluBench (n=200, perfectly balanced), our theory-guided baseline achieves 0.8017 AUROC. BASE supervised models reach 0.8274 AUROC, while IMPROVED features boost performance to 0.8669 AUROC (4.95% gain), demonstrating consistent improvements across architectures. This competitive performance is achieved while using 75x less training data than Lynx (200 vs 15,000 samples), 1000x faster inference (5ms vs 5s), and remaining fully interpretable. Crucially, we report a negative result: the Rationalization signal fails to distinguish hallucinations, suggesting that LLMs generate coherent reasoning for false premises ("Sycophancy").
  This work demonstrates that domain knowledge encoded in signal architecture provides superior data efficiency compared to scaling LLM judges, achieving strong performance with lightweight (less than 1M parameter), explainable models suitable for production deployment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15652v1</guid></item><item><title>[cs updates on arXiv.org] Event-VStream: Event-Driven Real-Time Understanding for Long Video Streams</title><link>https://arxiv.org/abs/2601.15655</link><description>arXiv:2601.15655v1 Announce Type: new 
Abstract: Real-time understanding of long video streams remains challenging for multimodal large language models (VLMs) due to redundant frame processing and rapid forgetting of past context. Existing streaming systems rely on fixed-interval decoding or cache pruning, which either produce repetitive outputs or discard crucial temporal information. We introduce Event-VStream, an event-aware framework that represents continuous video as a sequence of discrete, semantically coherent events. Our system detects meaningful state transitions by integrating motion, semantic, and predictive cues, and triggers language generation only at those boundaries. Each event embedding is consolidated into a persistent memory bank, enabling long-horizon reasoning while maintaining low latency. Across OVOBench-Realtime, and long-form Ego4D evaluations, Event-VStream achieves competitive performance. It improves over a VideoLLM-Online-8B baseline by +10.4 points on OVOBench-Realtime, achieves performance close to Flash-VStream-7B despite using only a general-purpose LLaMA-3-8B text backbone, and maintains around 70% GPT-5 win rate on 2-hour Ego4D streams.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15655v1</guid></item><item><title>[cs updates on arXiv.org] Reflective Motion and a Physical Canvas: Exploring Embodied Journaling in Virtual Reality</title><link>https://arxiv.org/abs/2601.15656</link><description>arXiv:2601.15656v1 Announce Type: new 
Abstract: In traditional journaling practices, authors express and process their thoughts by writing them down. We propose a somaesthetic-inspired alternative that uses the human body, rather than written words, as the medium of expression. We coin this embodied journaling, as people's isolated body movements and spoken words become the canvas of reflection. We implemented embodied journaling in virtual reality and conducted a within-subject user study (n=20) to explore the emergent behaviours from the process and to compare its expressive and reflective qualities to those of written journaling. When writing-based norms and affordances were absent, we found that participants defaulted towards unfiltered emotional expression, often forgoing words altogether. Rather, subconscious body motion and paralinguistic acoustic qualities unveiled deeper, sometimes hidden feelings, prompting reflection that happens after emotional expression rather than during it. We discuss both the capabilities and pitfalls of embodied journaling, ultimately challenging the idea that reflection culminates in linguistic reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15656v1</guid></item><item><title>[cs updates on arXiv.org] Integrating Knowledge Distillation Methods: A Sequential Multi-Stage Framework</title><link>https://arxiv.org/abs/2601.15657</link><description>arXiv:2601.15657v1 Announce Type: new 
Abstract: Knowledge distillation (KD) transfers knowledge from large teacher models to compact student models, enabling efficient deployment on resource constrained devices. While diverse KD methods, including response based, feature based, and relation based approaches, capture different aspects of teacher knowledge, integrating multiple methods or knowledge sources is promising but often hampered by complex implementation, inflexible combinations, and catastrophic forgetting, which limits practical effectiveness.
  This work proposes SMSKD (Sequential Multi Stage Knowledge Distillation), a flexible framework that sequentially integrates heterogeneous KD methods. At each stage, the student is trained with a specific distillation method, while a frozen reference model from the previous stage anchors learned knowledge to mitigate forgetting. In addition, we introduce an adaptive weighting mechanism based on the teacher true class probability (TCP) that dynamically adjusts the reference loss per sample to balance knowledge retention and integration.
  By design, SMSKD supports arbitrary method combinations and stage counts with negligible computational overhead. Extensive experiments show that SMSKD consistently improves student accuracy across diverse teacher student architectures and method combinations, outperforming existing baselines. Ablation studies confirm that stage wise distillation and reference model supervision are primary contributors to performance gains, with TCP based adaptive weighting providing complementary benefits. Overall, SMSKD is a practical and resource efficient solution for integrating heterogeneous KD methods.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15657v1</guid></item><item><title>[cs updates on arXiv.org] TempoNet: Learning Realistic Communication and Timing Patterns for Network Traffic Simulation</title><link>https://arxiv.org/abs/2601.15663</link><description>arXiv:2601.15663v1 Announce Type: new 
Abstract: Realistic network traffic simulation is critical for evaluating intrusion detection systems, stress-testing network protocols, and constructing high-fidelity environments for cybersecurity training. While attack traffic can often be layered into training environments using red-teaming or replay methods, generating authentic benign background traffic remains a core challenge -- particularly in simulating the complex temporal and communication dynamics of real-world networks. This paper introduces TempoNet, a novel generative model that combines multi-task learning with multi-mark temporal point processes to jointly model inter-arrival times and all packet- and flow-header fields. TempoNet captures fine-grained timing patterns and higher-order correlations such as host-pair behavior and seasonal trends, addressing key limitations of GAN-, LLM-, and Bayesian-based methods that fail to reproduce structured temporal variation. TempoNet produces temporally consistent, high-fidelity traces, validated on real-world datasets. Furthermore, we show that intrusion detection models trained on TempoNet-generated background traffic perform comparably to those trained on real data, validating its utility for real-world security applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15663v1</guid></item><item><title>[cs updates on arXiv.org] Skywork UniPic 3.0: Unified Multi-Image Composition via Sequence Modeling</title><link>https://arxiv.org/abs/2601.15664</link><description>arXiv:2601.15664v1 Announce Type: new 
Abstract: The recent surge in popularity of Nano-Banana and Seedream 4.0 underscores the community's strong interest in multi-image composition tasks. Compared to single-image editing, multi-image composition presents significantly greater challenges in terms of consistency and quality, yet existing models have not disclosed specific methodological details for achieving high-quality fusion. Through statistical analysis, we identify Human-Object Interaction (HOI) as the most sought-after category by the community. We therefore systematically analyze and implement a state-of-the-art solution for multi-image composition with a primary focus on HOI-centric tasks. We present Skywork UniPic 3.0, a unified multimodal framework that integrates single-image editing and multi-image composition. Our model supports an arbitrary (1~6) number and resolution of input images, as well as arbitrary output resolutions (within a total pixel budget of 1024x1024). To address the challenges of multi-image composition, we design a comprehensive data collection, filtering, and synthesis pipeline, achieving strong performance with only 700K high-quality training samples. Furthermore, we introduce a novel training paradigm that formulates multi-image composition as a sequence-modeling problem, transforming conditional generation into unified sequence synthesis. To accelerate inference, we integrate trajectory mapping and distribution matching into the post-training stage, enabling the model to produce high-fidelity samples in just 8 steps and achieve a 12.5x speedup over standard synthesis sampling. Skywork UniPic 3.0 achieves state-of-the-art performance on single-image editing benchmark and surpasses both Nano-Banana and Seedream 4.0 on multi-image composition benchmark, thereby validating the effectiveness of our data pipeline and training paradigm. Code, models and dataset are publicly available.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15664v1</guid></item><item><title>[cs updates on arXiv.org] Impression Zombies: Characteristics Analysis and Classification of New Harmful Accounts on Social Media</title><link>https://arxiv.org/abs/2601.15666</link><description>arXiv:2601.15666v1 Announce Type: new 
Abstract: ``Impression Zombies'', a type of malicious account designed to artificially inflate engagement metrics, have recently emerged as a significant threat on X (formerly Twitter). These accounts disseminate a high volume of low-quality, irrelevant posts, which degrade the user experience. This study aims (1) to quantitatively characterize their behavioral patterns and (2) to develop a method for detecting such accounts. To address the first objective, we collected data from 9,909 accounts and compared the characteristics of Impression Zombies and general users within this dataset. We find that, Impression Zombies post more than three times the average total number of posts per day and tend to gather followers by using phrases such as ``follow back.'' Addressing the second objective, we constructed a classification model for Impression Zombies that leverages the contextual incoherence often observed between parent posts and the replies from Impression Zombies. Experimental results show that our model achieved approximately 92\% accuracy in detecting Impression Zombies. This study provides the first quantitative insights into Impression Zombies and offers a practical framework for detecting such accounts, contributing to platform transparency and the health of social media ecosystems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15666v1</guid></item><item><title>[cs updates on arXiv.org] EmotionThinker: Prosody-Aware Reinforcement Learning for Explainable Speech Emotion Reasoning</title><link>https://arxiv.org/abs/2601.15668</link><description>arXiv:2601.15668v1 Announce Type: new 
Abstract: Emotional information in speech plays a unique role in multimodal perception. However, current Speech Large Language Models (SpeechLLMs), similar to conventional speech emotion recognition (SER) systems, still treat emotion understanding as a simple classification problem. This provides limited interpretability of predictions, while leaving the LLMs' expressive and reasoning capabilities underutilized. In this work, we take the first step to reformulate SER as a deep reasoning problem through reinforcement learning (RL). We propose EmotionThinker, which is designed to generate accurate emotion predictions with interpretable explanations grounded in fine-grained acoustic cues. To achieve this, we first construct EmotionCoT-35K, an emotional reasoning dataset with Chain-of-Thought annotations and detailed captions. Second, we observe that current SpeechLLMs exhibit weak prosody perception, whereas prosodic cues constitute fundamental signals for interpreting emotions. To address this, we develop the prosody-enhanced foundation model EmotionThinker-Base, and demonstrate that prosody enhancement improves emotion understanding. Third, we introduce Group-Relative-Policy-Optimization with Progressive-Trust-aware-Reasoning-Reward (GRPO-PTR) for RL. Different from standard GRPO, which relies only on rule-based outcome rewards, GRPO-PTR progressively introduces reasoning reward, dynamically adjusts it with a trustworthiness weight reflecting the alignment between reasoning and outcome, and evaluates the overall reasoning quality with a reward model based on multi-dimensional criteria. EmotionThinker outperforms previous state-of-the-art evaluation models both in emotion accuracy and explanation quality, advancing SER toward interpretable multimodal reasoning. Project page: https://github.com/dingdongwang/EmotionThinker</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15668v1</guid></item><item><title>[cs updates on arXiv.org] Dualformer: Time-Frequency Dual Domain Learning for Long-term Time Series Forecasting</title><link>https://arxiv.org/abs/2601.15669</link><description>arXiv:2601.15669v1 Announce Type: new 
Abstract: Transformer-based models, despite their promise for long-term time series forecasting (LTSF), suffer from an inherent low-pass filtering effect that limits their effectiveness. This issue arises due to undifferentiated propagation of frequency components across layers, causing a progressive attenuation of high-frequency information crucial for capturing fine-grained temporal variations. To address this limitation, we propose Dualformer, a principled dual-domain framework that rethinks frequency modeling from a layer-wise perspective. Dualformer introduces three key components: (1) a dual-branch architecture that concurrently models complementary temporal patterns in both time and frequency domains; (2) a hierarchical frequency sampling module that allocates distinct frequency bands to different layers, preserving high-frequency details in lower layers while modeling low-frequency trends in deeper layers; and (3) a periodicity-aware weighting mechanism that dynamically balances contributions from the dual branches based on the harmonic energy ratio of inputs, supported theoretically by a derived lower bound. This design enables structured frequency modeling and adaptive integration of time-frequency features, effectively preserving high-frequency information and enhancing generalization. Extensive experiments conducted on eight widely used benchmarks demonstrate Dualformer's robustness and superior performance, particularly on heterogeneous or weakly periodic data. Our code is publicly available at https://github.com/Akira-221/Dualformer.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15669v1</guid></item><item><title>[cs updates on arXiv.org] StreetDesignAI: A Multi-Persona Evaluation System for Inclusive Infrastructure Design</title><link>https://arxiv.org/abs/2601.15671</link><description>arXiv:2601.15671v1 Announce Type: new 
Abstract: Designing inclusive cycling infrastructure requires balancing competing needs of diverse user groups, yet designers often struggle to anticipate how different cyclists experience the same street. We investigate how persona-based multi-agent evaluation can support inclusive design by making experiential conflicts explicit. We present StreetDesignAI, an interactive system that enables designers to (1) ground evaluation in street context through imagery and map data, (2) receive parallel feedback from cyclist personas spanning confident to cautious users, and (3) iteratively modify designs while surfacing conflicts across perspectives. A within-subjects study with 26 transportation professionals demonstrates that structured multi-perspective feedback significantly improves designers' understanding of diverse user perspectives, ability to identify persona needs, and confidence in translating them into design decisions, with higher satisfaction and stronger intention for professional adoption. Qualitative findings reveal how conflict surfacing transforms design exploration from single-perspective optimization toward deliberate trade-off reasoning. We discuss implications for AI tools that scaffold inclusive design through disagreement as an interaction primitive.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15671v1</guid></item><item><title>[cs updates on arXiv.org] Enhancing guidance for missing data in diffusion-based sequential recommendation</title><link>https://arxiv.org/abs/2601.15673</link><description>arXiv:2601.15673v1 Announce Type: new 
Abstract: Contemporary sequential recommendation methods are becoming more complex, shifting from classification to a diffusion-guided generative paradigm. However, the quality of guidance in the form of user information is often compromised by missing data in the observed sequences, leading to suboptimal generation quality. Existing methods address this by removing locally similar items, but overlook ``critical turning points'' in user interest, which are crucial for accurately predicting subsequent user intent. To address this, we propose a novel Counterfactual Attention Regulation Diffusion model (CARD), which focuses on amplifying the signal from key interest-turning-point items while concurrently identifying and suppressing noise within the user sequence. CARD consists of (1) a Dual-side Thompson Sampling method to identify sequences undergoing significant interest shift, and (2) a counterfactual attention mechanism for these sequences to quantify the importance of each item. In this manner, CARD provides the diffusion model with a high-quality guidance signal composed of dynamically re-weighted interaction vectors to enable effective generation. Experiments show our method works well on real-world data without being computationally expensive. Our code is available at https://github.com/yanqilong3321/CARD.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15673v1</guid></item><item><title>[cs updates on arXiv.org] What Patients Really Ask: Exploring the Effect of False Assumptions in Patient Information Seeking</title><link>https://arxiv.org/abs/2601.15674</link><description>arXiv:2601.15674v1 Announce Type: new 
Abstract: Patients are increasingly using large language models (LLMs) to seek answers to their healthcare-related questions. However, benchmarking efforts in LLMs for question answering often focus on medical exam questions, which differ significantly in style and content from the questions patients actually raise in real life. To bridge this gap, we sourced data from Google's People Also Ask feature by querying the top 200 prescribed medications in the United States, curating a dataset of medical questions people commonly ask. A considerable portion of the collected questions contains incorrect assumptions and dangerous intentions. We demonstrate that the emergence of these corrupted questions is not uniformly random and depends heavily on the degree of incorrectness in the history of questions that led to their appearance. Current LLMs that perform strongly on other benchmarks struggle to identify incorrect assumptions in everyday questions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15674v1</guid></item><item><title>[cs updates on arXiv.org] Bridging the Perception Gap: A Lightweight Coarse-to-Fine Architecture for Edge Audio Systems</title><link>https://arxiv.org/abs/2601.15676</link><description>arXiv:2601.15676v1 Announce Type: new 
Abstract: Deploying Audio-Language Models (Audio-LLMs) on edge infrastructure exposes a persistent tension between perception depth and computational efficiency. Lightweight local models tend to produce passive perception - generic summaries that miss the subtle evidence required for multi-step audio reasoning - while indiscriminate cloud offloading incurs unacceptable latency, bandwidth cost, and privacy risk. We propose CoFi-Agent (Tool-Augmented Coarse-to-Fine Agent), a hybrid architecture targeting edge servers and gateways. It performs fast local perception and triggers conditional forensic refinement only when uncertainty is detected. CoFi-Agent runs an initial single-pass on a local 7B Audio-LLM, then a cloud controller gates difficult cases and issues lightweight plans for on-device tools such as temporal re-listening and local ASR. On the MMAR benchmark, CoFi-Agent improves accuracy from 27.20% to 53.60%, while achieving a better accuracy-efficiency trade-off than an always-on investigation pipeline. Overall, CoFi-Agent bridges the perception gap via tool-enabled, conditional edge-cloud collaboration under practical system constraints.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15676v1</guid></item><item><title>[cs updates on arXiv.org] Connect the Dots: Knowledge Graph-Guided Crawler Attack on Retrieval-Augmented Generation Systems</title><link>https://arxiv.org/abs/2601.15678</link><description>arXiv:2601.15678v1 Announce Type: new 
Abstract: Retrieval-augmented generation (RAG) systems integrate document retrieval with large language models and have been widely adopted. However, in privacy-related scenarios, RAG introduces a new privacy risk: adversaries can issue carefully crafted queries to exfiltrate sensitive content from the underlying corpus gradually. Although recent studies have demonstrated multi-turn extraction attacks, they rely on heuristics and fail to perform long-term extraction planning. To address these limitations, we formulate the RAG extraction attack as an adaptive stochastic coverage problem (ASCP). In ASCP, each query is treated as a probabilistic action that aims to maximize conditional marginal gain (CMG), enabling principled long-term planning under uncertainty. However, integrating ASCP with practical RAG attack faces three key challenges: unobservable CMG, intractability in the action space, and feasibility constraints. To overcome these challenges, we maintain a global attacker-side state to guide the attack. Building on this idea, we introduce RAGCRAWLER, which builds a knowledge graph to represent revealed information, uses this global state to estimate CMG, and plans queries in semantic space that target unretrieved regions. In comprehensive experiments across diverse RAG architectures and datasets, our proposed method, RAGCRAWLER, consistently outperforms all baselines. It achieves up to 84.4% corpus coverage within a fixed query budget and deliver an average improvement of 20.7% over the top-performing baseline. It also maintains high semantic fidelity and strong content reconstruction accuracy with low attack cost. Crucially, RAGCRAWLER proves its robustness by maintaining effectiveness against advanced RAG systems employing query rewriting and multi-query retrieval strategies. Our work reveals significant security gaps and highlights the pressing need for stronger safeguards for RAG.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15678v1</guid></item><item><title>[cs updates on arXiv.org] Improving Methodologies for Agentic Evaluations Across Domains: Leakage of Sensitive Information, Fraud and Cybersecurity Threats</title><link>https://arxiv.org/abs/2601.15679</link><description>arXiv:2601.15679v1 Announce Type: new 
Abstract: The rapid rise of autonomous AI systems and advancements in agent capabilities are introducing new risks due to reduced oversight of real-world interactions. Yet agent testing remains nascent and is still a developing science. As AI agents begin to be deployed globally, it is important that they handle different languages and cultures accurately and securely.
  To address this, participants from The International Network for Advanced AI Measurement, Evaluation and Science, including representatives from Singapore, Japan, Australia, Canada, the European Commission, France, Kenya, South Korea, and the United Kingdom have come together to align approaches to agentic evaluations.
  This is the third exercise, building on insights from two earlier joint testing exercises conducted by the Network in November 2024 and February 2025. The objective is to further refine best practices for testing advanced AI systems.
  The exercise was split into two strands: (1) common risks, including leakage of sensitive information and fraud, led by Singapore AISI; and (2) cybersecurity, led by UK AISI. A mix of open and closed-weight models were evaluated against tasks from various public agentic benchmarks. Given the nascency of agentic testing, our primary focus was on understanding methodological issues in conducting such tests, rather than examining test results or model capabilities. This collaboration marks an important step forward as participants work together to advance the science of agentic evaluations.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15679v1</guid></item><item><title>[cs updates on arXiv.org] Consistency-Regularized GAN for Few-Shot SAR Target Recognition</title><link>https://arxiv.org/abs/2601.15681</link><description>arXiv:2601.15681v1 Announce Type: new 
Abstract: Few-shot recognition in synthetic aperture radar (SAR) imagery remains a critical bottleneck for real-world applications due to extreme data scarcity. A promising strategy involves synthesizing a large dataset with a generative adversarial network (GAN), pre-training a model via self-supervised learning (SSL), and then fine-tuning on the few labeled samples. However, this approach faces a fundamental paradox: conventional GANs themselves require abundant data for stable training, contradicting the premise of few-shot learning. To resolve this, we propose the consistency-regularized generative adversarial network (Cr-GAN), a novel framework designed to synthesize diverse, high-fidelity samples even when trained under these severe data limitations. Cr-GAN introduces a dual-branch discriminator that decouples adversarial training from representation learning. This architecture enables a channel-wise feature interpolation strategy to create novel latent features, complemented by a dual-domain cycle consistency mechanism that ensures semantic integrity. Our Cr-GAN framework is adaptable to various GAN architectures, and its synthesized data effectively boosts multiple SSL algorithms. Extensive experiments on the MSTAR and SRSDD datasets validate our approach, with Cr-GAN achieving a highly competitive accuracy of 71.21% and 51.64%, respectively, in the 8-shot setting, significantly outperforming leading baselines, while requiring only ~5 of the parameters of state-of-the-art diffusion models. Code is available at: https://github.com/yikuizhai/Cr-GAN.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15681v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Hard Writes and Rigid Preservation: Soft Recursive Least-Squares for Lifelong LLM Editing</title><link>https://arxiv.org/abs/2601.15686</link><description>arXiv:2601.15686v1 Announce Type: new 
Abstract: Model editing updates a pre-trained LLM with new facts or rules without re-training, while preserving unrelated behavior. In real deployment, edits arrive as long streams, and existing editors often face a plasticity-stability dilemma: locate-then-edit "hard writes" can accumulate interference over time, while null-space-style "hard preservation" preserves only what is explicitly constrained, so past edits can be overwritten and unconstrained behaviors may deviate, degrading general capabilities in the many-edits regime. We propose RLSEdit, a recursive least-squares editor for long sequential editing. RLSEdit formulates editing as an online quadratic optimization with soft constraints, minimizing a cumulative key-value fitting objective with two regularizers that control for both deviation from the pre-trained weights and from a designated anchor mapping. The resulting update admits an efficient online recursion via the Woodbury identity, with per-edit cost independent of history length and scaling only with the current edit size. We further provide deviation bounds and an asymptotic characterization of the adherence-preservation trade-off in the many-edits regime. Experiments on multiple model families demonstrate stable scaling to 10K edits, outperforming strong baselines in both edit success and holistic stability -- crucially retaining early edits, and preserving general capabilities on GLUE and held-out reasoning/code benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15686v1</guid></item><item><title>[cs updates on arXiv.org] FARM: Field-Aware Resolution Model for Intelligent Trigger-Action Automation</title><link>https://arxiv.org/abs/2601.15687</link><description>arXiv:2601.15687v1 Announce Type: new 
Abstract: Trigger-Action Programming (TAP) platforms such as IFTTT and Zapier enable Web of Things (WoT) automation by composing event-driven rules across heterogeneous services. A TAP applet links a trigger to an action and must bind trigger outputs (ingredients) to action inputs (fields) to be executable. Prior work largely treats TAP as service-level prediction from natural language, which often yields non-executable applets that still require manual configuration. We study the function-level configuration problem: generating complete applets with correct ingredient-to-field bindings. We propose FARM (Field-Aware Resolution Model), a two-stage architecture for automated applet generation with full configuration. Stage 1 trains contrastive dual encoders with selective layer freezing over schema-enriched representations, retrieving candidates from 1,724 trigger functions and 1,287 action functions (2.2M possible trigger-action pairs). Stage 2 performs selection and configuration using an LLM-based multi-agent pipeline. It includes intent analysis, trigger selection, action selection via cross-schema scoring, and configuration verification. Agents coordinate through shared state and agreement-based selection. FARM achieves 81% joint accuracy on Gold (62% Noisy, 70% One-shot) at the function level, where both trigger and action functions must match the ground truth. For comparison with service-level baselines, we map functions to their parent services and evaluate at the service level. FARM reaches 81% joint accuracy and improves over TARGE by 23 percentage points. FARM also generates ingredient-to-field bindings, producing executable automation configurations.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15687v1</guid></item><item><title>[cs updates on arXiv.org] Performance-guided Reinforced Active Learning for Object Detection</title><link>https://arxiv.org/abs/2601.15688</link><description>arXiv:2601.15688v1 Announce Type: new 
Abstract: Active learning (AL) strategies aim to train high-performance models with minimal labeling efforts, only selecting the most informative instances for annotation. Current approaches to evaluating data informativeness predominantly focus on the data's distribution or intrinsic information content and do not directly correlate with downstream task performance, such as mean average precision (mAP) in object detection. Thus, we propose Performance-guided (i.e. mAP-guided) Reinforced Active Learning for Object Detection (MGRAL), a novel approach that leverages the concept of expected model output changes as informativeness. To address the combinatorial explosion challenge of batch sample selection and the non-differentiable correlation between model performance and selected batches, MGRAL skillfully employs a reinforcement learning-based sampling agent that optimizes selection using policy gradient with mAP improvement as reward. Moreover, to reduce the computational overhead of mAP estimation with unlabeled samples, MGRAL utilizes an unsupervised way with fast look-up tables, ensuring feasible deployment. We evaluate MGRAL's active learning performance on detection tasks over PASCAL VOC and COCO benchmarks. Our approach demonstrates the highest AL curve with convincing visualizations, establishing a new paradigm in reinforcement learning-driven active object detection.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15688v1</guid></item><item><title>[cs updates on arXiv.org] From Passive Metric to Active Signal: The Evolving Role of Uncertainty Quantification in Large Language Models</title><link>https://arxiv.org/abs/2601.15690</link><description>arXiv:2601.15690v1 Announce Type: new 
Abstract: While Large Language Models (LLMs) show remarkable capabilities, their unreliability remains a critical barrier to deployment in high-stakes domains. This survey charts a functional evolution in addressing this challenge: the evolution of uncertainty from a passive diagnostic metric to an active control signal guiding real-time model behavior. We demonstrate how uncertainty is leveraged as an active control signal across three frontiers: in \textbf{advanced reasoning} to optimize computation and trigger self-correction; in \textbf{autonomous agents} to govern metacognitive decisions about tool use and information seeking; and in \textbf{reinforcement learning} to mitigate reward hacking and enable self-improvement via intrinsic rewards. By grounding these advancements in emerging theoretical frameworks like Bayesian methods and Conformal Prediction, we provide a unified perspective on this transformative trend. This survey provides a comprehensive overview, critical analysis, and practical design patterns, arguing that mastering the new trend of uncertainty is essential for building the next generation of scalable, reliable, and trustworthy AI.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15690v1</guid></item><item><title>[cs updates on arXiv.org] Balancing Security and Privacy: The Pivotal Role of AI in Modern Healthcare Systems</title><link>https://arxiv.org/abs/2601.15697</link><description>arXiv:2601.15697v1 Announce Type: new 
Abstract: As digital threats continue to grow, organizations must find ways to enhance security while protecting user privacy. This paper explores how artificial intelligence (AI) plays a crucial role in achieving this balance. AI technologies can improve security by detecting threats, monitoring systems, and automating responses. However, using AI also raises privacy concerns that need careful consideration.We examine real-world examples from the healthcare sector to illustrate how organizations can implement AI solutions that strengthen security without compromising patient privacy. Additionally, we discuss the importance of creating transparent AI systems and adhering to privacy regulations.Ultimately, this paper provides insights and recommendations for integrating AI into healthcare security practices, helping organizations navigate the challenges of modern management while keeping patient data safe.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15697v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs</title><link>https://arxiv.org/abs/2601.15698</link><description>arXiv:2601.15698v1 Announce Type: new 
Abstract: The rapid advancement of Multimodal Large Language Models (MLLMs) has introduced complex security challenges, particularly at the intersection of textual and visual safety. While existing schemes have explored the security vulnerabilities of MLLMs, the investigation into their visual safety boundaries remains insufficient. In this paper, we propose Beyond Visual Safety (BVS), a novel image-text pair jailbreaking framework specifically designed to probe the visual safety boundaries of MLLMs. BVS employs a "reconstruction-then-generation" strategy, leveraging neutralized visual splicing and inductive recomposition to decouple malicious intent from raw inputs, thereby leading MLLMs to be induced into generating harmful images. Experimental results demonstrate that BVS achieves a remarkable jailbreak success rate of 98.21\% against GPT-5 (12 January 2026 release). Our findings expose critical vulnerabilities in the visual safety alignment of current MLLMs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15698v1</guid></item><item><title>[cs updates on arXiv.org] Agentic Uncertainty Quantification</title><link>https://arxiv.org/abs/2601.15703</link><description>arXiv:2601.15703v1 Announce Type: new 
Abstract: Although AI agents have demonstrated impressive capabilities in long-horizon reasoning, their reliability is severely hampered by the ``Spiral of Hallucination,'' where early epistemic errors propagate irreversibly. Existing methods face a dilemma: uncertainty quantification (UQ) methods typically act as passive sensors, only diagnosing risks without addressing them, while self-reflection mechanisms suffer from continuous or aimless corrections. To bridge this gap, we propose a unified Dual-Process Agentic UQ (AUQ) framework that transforms verbalized uncertainty into active, bi-directional control signals. Our architecture comprises two complementary mechanisms: System 1 (Uncertainty-Aware Memory, UAM), which implicitly propagates verbalized confidence and semantic explanations to prevent blind decision-making; and System 2 (Uncertainty-Aware Reflection, UAR), which utilizes these explanations as rational cues to trigger targeted inference-time resolution only when necessary. This enables the agent to balance efficient execution and deep deliberation dynamically. Extensive experiments on closed-loop benchmarks and open-ended deep research tasks demonstrate that our training-free approach achieves superior performance and trajectory-level calibration. We believe this principled framework AUQ represents a significant step towards reliable agents.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15703v1</guid></item><item><title>[cs updates on arXiv.org] Enhanced LULC Segmentation via Lightweight Model Refinements on ALOS-2 SAR Data</title><link>https://arxiv.org/abs/2601.15705</link><description>arXiv:2601.15705v1 Announce Type: new 
Abstract: This work focuses on national-scale land-use/land-cover (LULC) semantic segmentation using ALOS-2 single-polarization (HH) SAR data over Japan, together with a companion binary water detection task. Building on SAR-W-MixMAE self-supervised pretraining [1], we address common SAR dense-prediction failure modes, boundary over-smoothing, missed thin/slender structures, and rare-class degradation under long-tailed labels, without increasing pipeline complexity. We introduce three lightweight refinements: (i) injecting high-resolution features into multi-scale decoding, (ii) a progressive refine-up head that alternates convolutional refinement and stepwise upsampling, and (iii) an $\alpha$-scale factor that tempers class reweighting within a focal+dice objective. The resulting model yields consistent improvements on the Japan-wide ALOS-2 LULC benchmark, particularly for under-represented classes, and improves water detection across standard evaluation metrics.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15705v1</guid></item><item><title>[cs updates on arXiv.org] Improving Methodologies for LLM Evaluations Across Global Languages</title><link>https://arxiv.org/abs/2601.15706</link><description>arXiv:2601.15706v1 Announce Type: new 
Abstract: As frontier AI models are deployed globally, it is essential that their behaviour remains safe and reliable across diverse linguistic and cultural contexts. To examine how current model safeguards hold up in such settings, participants from the International Network for Advanced AI Measurement, Evaluation and Science, including representatives from Singapore, Japan, Australia, Canada, the EU, France, Kenya, South Korea and the UK conducted a joint multilingual evaluation exercise. Led by Singapore AISI, two open-weight models were tested across ten languages spanning high and low resourced groups: Cantonese English, Farsi, French, Japanese, Korean, Kiswahili, Malay, Mandarin Chinese and Telugu. Over 6,000 newly translated prompts were evaluated across five harm categories (privacy, non-violent crime, violent crime, intellectual property and jailbreak robustness), using both LLM-as-a-judge and human annotation.
  The exercise shows how safety behaviours can vary across languages. These include differences in safeguard robustness across languages and harm types and variation in evaluator reliability (LLM-as-judge vs. human review). Further, it also generated methodological insights for improving multilingual safety evaluations, such as the need for culturally contextualised translations, stress-tested evaluator prompts and clearer human annotation guidelines. This work represents an initial step toward a shared framework for multilingual safety testing of advanced AI systems and calls for continued collaboration with the wider research community and industry.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15706v1</guid></item><item><title>[cs updates on arXiv.org] D-Optimality-Guided Reinforcement Learning for Efficient Open-Loop Calibration of a 3-DOF Ankle Rehabilitation Robot</title><link>https://arxiv.org/abs/2601.15707</link><description>arXiv:2601.15707v1 Announce Type: new 
Abstract: Accurate alignment of multi-degree-of-freedom rehabilitation robots is essential for safe and effective patient training. This paper proposes a two-stage calibration framework for a self-designed three-degree-of-freedom (3-DOF) ankle rehabilitation robot. First, a Kronecker-product-based open-loop calibration method is developed to cast the input-output alignment into a linear parameter identification problem, which in turn defines the associated experimental design objective through the resulting information matrix. Building on this formulation, calibration posture selection is posed as a combinatorial design-of-experiments problem guided by a D-optimality criterion, i.e., selecting a small subset of postures that maximises the determinant of the information matrix. To enable practical selection under constraints, a Proximal Policy Optimization (PPO) agent is trained in simulation to choose 4 informative postures from a candidate set of 50. Across simulation and real-robot evaluations, the learned policy consistently yields substantially more informative posture combinations than random selection: the mean determinant of the information matrix achieved by PPO is reported to be more than two orders of magnitude higher with reduced variance. In addition, real-world results indicate that a parameter vector identified from only four D-optimality-guided postures provides stronger cross-episode prediction consistency than estimates obtained from a larger but unstructured set of 50 postures. The proposed framework therefore improves calibration efficiency while maintaining robust parameter estimation, offering practical guidance for high-precision alignment of multi-DOF rehabilitation robots.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15707v1</guid></item><item><title>[cs updates on arXiv.org] Persona Switch: Mixing Distinct Perspectives in Decoding Time</title><link>https://arxiv.org/abs/2601.15708</link><description>arXiv:2601.15708v1 Announce Type: new 
Abstract: Role-play prompting is known to steer the behavior of language models by injecting a persona into the prompt, improving their zero-shot reasoning capabilities. However, such improvements are inconsistent across different tasks or instances. This inconsistency suggests that zero-shot and role-play prompting may offer complementary strengths rather than one being universally superior. Building on this insight, we propose Persona Switch, a novel decoding method that dynamically combines the benefits of both prompting strategies. Our method proceeds step-by-step, selecting the better output between zero-shot and role-play prompting at each step by comparing their output confidence, as measured by the logit gap. Experiments with widely-used LLMs demonstrate that Persona Switch consistently outperforms competitive baselines, achieving up to 5.13% accuracy improvement. Furthermore, we show that output confidence serves as an informative measure for selecting the more reliable output.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15708v1</guid></item><item><title>[cs updates on arXiv.org] AgentSM: Semantic Memory for Agentic Text-to-SQL</title><link>https://arxiv.org/abs/2601.15709</link><description>arXiv:2601.15709v1 Announce Type: new 
Abstract: Recent advances in LLM-based Text-to-SQL have achieved remarkable gains on public benchmarks such as BIRD and Spider. Yet, these systems struggle to scale in realistic enterprise settings with large, complex schemas, diverse SQL dialects, and expensive multi-step reasoning. Emerging agentic approaches show potential for adaptive reasoning but often suffer from inefficiency and instability-repeating interactions with databases, producing inconsistent outputs, and occasionally failing to generate valid answers. To address these challenges, we introduce Agent Semantic Memory (AgentSM), an agentic framework for Text-to-SQL that builds and leverages interpretable semantic memory. Instead of relying on raw scratchpads or vector retrieval, AgentSM captures prior execution traces-or synthesizes curated ones-as structured programs that directly guide future reasoning. This design enables systematic reuse of reasoning paths, which allows agents to scale to larger schemas, more complex questions, and longer trajectories efficiently and reliably. Compared to state-of-the-art systems, AgentSM achieves higher efficiency by reducing average token usage and trajectory length by 25% and 35%, respectively, on the Spider 2.0 benchmark. It also improves execution accuracy, reaching a state-of-the-art accuracy of 44.8% on the Spider 2.0 Lite benchmark.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15709v1</guid></item><item><title>[cs updates on arXiv.org] FlexLLM: Composable HLS Library for Flexible Hybrid LLM Accelerator Design</title><link>https://arxiv.org/abs/2601.15710</link><description>arXiv:2601.15710v1 Announce Type: new 
Abstract: We present FlexLLM, a composable High-Level Synthesis (HLS) library for rapid development of domain-specific LLM accelerators. FlexLLM exposes key architectural degrees of freedom for stage-customized inference, enabling hybrid designs that tailor temporal reuse and spatial dataflow differently for prefill and decode, and provides a comprehensive quantization suite to support accurate low-bit deployment. Using FlexLLM, we build a complete inference system for the Llama-3.2 1B model in under two months with only 1K lines of code. The system includes: (1) a stage-customized accelerator with hardware-efficient quantization (12.68 WikiText-2 PPL) surpassing SpinQuant baseline, and (2) a Hierarchical Memory Transformer (HMT) plug-in for efficient long-context processing. On the AMD U280 FPGA at 16nm, the accelerator achieves 1.29$\times$ end-to-end speedup, 1.64$\times$ higher decode throughput, and 3.14$\times$ better energy efficiency than an NVIDIA A100 GPU (7nm) running BF16 inference; projected results on the V80 FPGA at 7nm reach 4.71$\times$, 6.55$\times$, and 4.13$\times$, respectively. In long-context scenarios, integrating the HMT plug-in reduces prefill latency by 23.23$\times$ and extends the context window by 64$\times$, delivering 1.10$\times$/4.86$\times$ lower end-to-end latency and 5.21$\times$/6.27$\times$ higher energy efficiency on the U280/V80 compared to the A100 baseline. FlexLLM thus bridges algorithmic innovation in LLM inference and high-performance accelerators with minimal manual effort.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15710v1</guid></item><item><title>[cs updates on arXiv.org] Zero-Shot Product Attribute Labeling with Vision-Language Models: A Three-Tier Evaluation Framework</title><link>https://arxiv.org/abs/2601.15711</link><description>arXiv:2601.15711v1 Announce Type: new 
Abstract: Fine-grained attribute prediction is essential for fashion retail applications including catalog enrichment, visual search, and recommendation systems. Vision-Language Models (VLMs) offer zero-shot prediction without task-specific training, yet their systematic evaluation on multi-attribute fashion tasks remains underexplored. A key challenge is that fashion attributes are often conditional. For example, "outer fabric" is undefined when no outer garment is visible. This requires models to detect attribute applicability before attempting classification. We introduce a three-tier evaluation framework that decomposes this challenge: (1) overall task performance across all classes (including NA class: suggesting attribute is not applicable) for all attributes, (2) attribute applicability detection, and (3) fine-grained classification when attributes are determinable. Using DeepFashion-MultiModal, which explicitly defines NA (meaning attribute doesn't exist or is not visible) within attribute label spaces, we benchmark nine VLMs spanning flagship (GPT-5, Gemini 2.5 Pro), efficient (GPT-5 Mini, Gemini 2.5 Flash), and ultra-efficient tiers (GPT-5 Nano, Gemini 2.5 Flash-Lite) against classifiers trained on pretrained Fashion-CLIP embeddings on 5,000 images across 18 attributes. Our findings reveal that: (1) zero-shot VLMs achieve 64.0% macro-F1, a threefold improvement over logistic regression on pretrained Fashion-CLIP embeddings; (2) VLMs excel at fine-grained classification (Tier 3: 70.8% F1) but struggle with applicability detection (Tier 2: 34.1% NA-F1), identifying a key bottleneck; (3) efficient models achieve over 90% of flagship performance at lower cost, offering practical deployment paths. This diagnostic framework enables practitioners to pinpoint whether errors stem from visibility detection or classification, guiding targeted improvements for production systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15711v1</guid></item><item><title>[cs updates on arXiv.org] Even GPT-5.2 Can't Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs</title><link>https://arxiv.org/abs/2601.15714</link><description>arXiv:2601.15714v1 Announce Type: new 
Abstract: We propose Zero-Error Horizon (ZEH) for trustworthy LLMs, which represents the maximum range that a model can solve without any errors. While ZEH itself is simple, we demonstrate that evaluating the ZEH of state-of-the-art LLMs yields abundant insights. For example, by evaluating the ZEH of GPT-5.2, we found that GPT-5.2 cannot even compute the parity of a short string like 11000, and GPT-5.2 cannot determine whether the parentheses in ((((()))))) are balanced. This is surprising given the excellent capabilities of GPT-5.2. The fact that LLMs make mistakes on such simple problems serves as an important lesson when applying LLMs to safety-critical domains. By applying ZEH to Qwen2.5 and conducting detailed analysis, we found that while ZEH correlates with accuracy, the detailed behaviors differ, and ZEH provides clues about the emergence of algorithmic capabilities. Finally, while computing ZEH incurs significant computational cost, we discuss how to mitigate this cost by achieving up to one order of magnitude speedup using tree structures and online softmax.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15714v1</guid></item><item><title>[cs updates on arXiv.org] Dancing in Chains: Strategic Persuasion in Academic Rebuttal via Theory of Mind</title><link>https://arxiv.org/abs/2601.15715</link><description>arXiv:2601.15715v1 Announce Type: new 
Abstract: Although artificial intelligence (AI) has become deeply integrated into various stages of the research workflow and achieved remarkable advancements, academic rebuttal remains a significant and underexplored challenge. This is because rebuttal is a complex process of strategic communication under severe information asymmetry rather than a simple technical debate. Consequently, current approaches struggle as they largely imitate surface-level linguistics, missing the essential element of perspective-taking required for effective persuasion. In this paper, we introduce RebuttalAgent, the first framework to ground academic rebuttal in Theory of Mind (ToM), operationalized through a ToM-Strategy-Response (TSR) pipeline that models reviewer mental state, formulates persuasion strategy, and generates strategy-grounded response. To train our agent, we construct RebuttalBench, a large-scale dataset synthesized via a novel critique-and-refine approach. Our training process consists of two stages, beginning with a supervised fine-tuning phase to equip the agent with ToM-based analysis and strategic planning capabilities, followed by a reinforcement learning phase leveraging the self-reward mechanism for scalable self-improvement. For reliable and efficient automated evaluation, we further develop Rebuttal-RM, a specialized evaluator trained on over 100K samples of multi-source rebuttal data, which achieves scoring consistency with human preferences surpassing powerful judge GPT-4.1. Extensive experiments show RebuttalAgent significantly outperforms the base model by an average of 18.3% on automated metrics, while also outperforming advanced proprietary models across both automated and human evaluations. Disclaimer: the generated rebuttal content is for reference only to inspire authors and assist in drafting. It is not intended to replace the author's own critical analysis and response.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15715v1</guid></item><item><title>[cs updates on arXiv.org] zkFinGPT: Zero-Knowledge Proofs for Financial Generative Pre-trained Transformers</title><link>https://arxiv.org/abs/2601.15716</link><description>arXiv:2601.15716v1 Announce Type: new 
Abstract: Financial Generative Pre-trained Transformers (FinGPT) with multimodal capabilities are now being increasingly adopted in various financial applications. However, due to the intellectual property of model weights and the copyright of training corpus and benchmarking questions, verifying the legitimacy of GPT's model weights and the credibility of model outputs is a pressing challenge. In this paper, we introduce a novel zkFinGPT scheme that applies zero-knowledge proofs (ZKPs) to high-value financial use cases, enabling verification while protecting data privacy. We describe how zkFinGPT will be applied to three financial use cases. Our experiments on two existing packages reveal that zkFinGPT introduces substantial computational overhead that hinders its real-world adoption. E.g., for LLama3-8B model, it generates a commitment file of $7.97$MB using $531$ seconds, and takes $620$ seconds to prove and $2.36$ seconds to verify.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15716v1</guid></item><item><title>[cs updates on arXiv.org] Investigation of the Generalisation Ability of Genetic Programming-evolved Scheduling Rules in Dynamic Flexible Job Shop Scheduling</title><link>https://arxiv.org/abs/2601.15717</link><description>arXiv:2601.15717v1 Announce Type: new 
Abstract: Dynamic Flexible Job Shop Scheduling (DFJSS) is a complex combinatorial optimisation problem that requires simultaneous machine assignment and operation sequencing decisions in dynamic production environments. Genetic Programming (GP) has been widely applied to automatically evolve scheduling rules for DFJSS. However, existing studies typically train and test GP-evolved rules on DFJSS instances of the same type, which differ only by random seeds rather than by structural characteristics, leaving their cross-type generalisation ability largely unexplored. To address this gap, this paper systematically investigates the generalisation ability of GP-evolved scheduling rules under diverse DFJSS conditions. A series of experiments are conducted across multiple dimensions, including problem scale (i.e., the number of machines and jobs), key job shop parameters (e.g., utilisation level), and data distributions, to analyse how these factors influence GP performance on unseen instance types. The results show that good generalisation occurs when the training instances contain more jobs than the test instances while keeping the number of machines fixed, and when both training and test instances have similar scales or job shop parameters. Further analysis reveals that the number and distribution of decision points in DFJSS instances play a crucial role in explaining these performance differences. Similar decision point distributions lead to better generalisation, whereas significant discrepancies result in a marked degradation of performance. Overall, this study provides new insights into the generalisation ability of GP in DFJSS and highlights the necessity of evolving more generalisable GP rules capable of handling heterogeneous DFJSS instances effectively.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15717v1</guid></item><item><title>[cs updates on arXiv.org] U3-xi: Pushing the Boundaries of Speaker Recognition via Incorporating Uncertainty</title><link>https://arxiv.org/abs/2601.15719</link><description>arXiv:2601.15719v1 Announce Type: new 
Abstract: An utterance-level speaker embedding is typically obtained by aggregating a sequence of frame-level representations. However, in real-world scenarios, individual frames encode not only speaker-relevant information but also various nuisance factors. As a result, different frames contribute unequally to the final utterance-level speaker representation for Automatic Speaker Verification systems. To address this issue, we propose to estimate the inherent uncertainty of each frame and assign adaptive weights accordingly, where frames with higher uncertainty receive lower attention. Based on this idea, we present U3-xi, a comprehensive framework designed to produce more reliable and interpretable uncertainty estimates for speaker embeddings. Specifically, we introduce several strategies for uncertainty supervision. First, we propose speaker-level uncertainty supervision via a Stochastic Variance Loss, where the distance between an utterance embedding and its corresponding speaker centroid serves as a pseudo ground truth for uncertainty learning. Second, we incorporate global-level uncertainty supervision by injecting the predicted uncertainty into the sof tmax scale during training. This adaptive scaling mechanism adjusts the sharpness of the decision boundary according to sample difficulty, providing global guidance. Third, we redesign the uncertainty estimation module by integrating a Transformer encoder with multi-view self-attention, enabling the model to capture rich local and long-range temporal dependencies. Comprehensive experiments demonstrate that U3-xi is model-agnostic and can be seamlessly applied to various speaker encoders. In particular, when applied to ECAPA-TDNN, it achieves 21.1% and 15.57% relative improvements on the VoxCeleb1 test sets in terms of EER and minDCF, respectively.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15719v1</guid></item><item><title>[cs updates on arXiv.org] CoNRec: Context-Discerning Negative Recommendation with LLMs</title><link>https://arxiv.org/abs/2601.15721</link><description>arXiv:2601.15721v1 Announce Type: new 
Abstract: Understanding what users like is relatively straightforward; understanding what users dislike, however, remains a challenging and underexplored problem. Research into users' negative preferences has gained increasing importance in modern recommendation systems. Numerous platforms have introduced explicit negative feedback mechanisms and leverage such signals to refine their recommendation models. Beyond traditional business metrics, user experience-driven metrics, such as negative feedback rates, have become critical indicators for evaluating system performance. However, most existing approaches primarily use negative feedback as an auxiliary signal to enhance positive recommendations, paying little attention to directly modeling negative interests, which can be highly valuable in offline applications. Moreover, due to the inherent sparsity of negative feedback data, models often suffer from context understanding biases induced by positive feedback dominance. To address these challenges, we propose the first large language model framework for negative feedback modeling with special designed context-discerning modules. We use semantic ID Representation to replace text-based item descriptions and introduce an item-level alignment task that enhances the LLM's understanding of the semantic context behind negative feedback. Furthermore, we design a Progressive GRPO training paradigm that enables the model to dynamically balance the positive and negative behavioral context utilization. Besides, our investigation further reveals a fundamental misalignment between the conventional next-negative-item prediction objective and users' true negative preferences, which is heavily influenced by the system's recommendation order. To mitigate this, we propose a novel reward function and evaluation metric grounded in multi-day future negative feedback and their collaborative signals.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15721v1</guid></item><item><title>[cs updates on arXiv.org] Communication-efficient Federated Graph Classification via Generative Diffusion Modeling</title><link>https://arxiv.org/abs/2601.15722</link><description>arXiv:2601.15722v1 Announce Type: new 
Abstract: Graph Neural Networks (GNNs) unlock new ways of learning from graph-structured data, proving highly effective in capturing complex relationships and patterns. Federated GNNs (FGNNs) have emerged as a prominent distributed learning paradigm for training GNNs over decentralized data. However, FGNNs face two significant challenges: high communication overhead from multiple rounds of parameter exchanges and non-IID data characteristics across clients. To address these issues, we introduce CeFGC, a novel FGNN paradigm that facilitates efficient GNN training over non-IID data by limiting communication between the server and clients to three rounds only. The core idea of CeFGC is to leverage generative diffusion models to minimize direct client-server communication. Each client trains a generative diffusion model that captures its local graph distribution and shares this model with the server, which then redistributes it back to all clients. Using these generative models, clients generate synthetic graphs combined with their local graphs to train local GNN models. Finally, clients upload their model weights to the server for aggregation into a global GNN model. We theoretically analyze the I/O complexity of communication volume to show that CeFGC reduces to a constant of three communication rounds only. Extensive experiments on several real graph datasets demonstrate the effectiveness and efficiency of CeFGC against state-of-the-art competitors, reflecting our superior performance on non-IID graphs by aligning local and global model objectives and enriching the training set with diverse graphs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15722v1</guid></item><item><title>[cs updates on arXiv.org] Generalized Information Inequalities via Submodularity, and Two Combinatorial Problems</title><link>https://arxiv.org/abs/2601.15723</link><description>arXiv:2601.15723v1 Announce Type: new 
Abstract: It is well known that there is a strong connection between entropy inequalities and submodularity, since the entropy of a collection of random variables is a submodular function. Unifying frameworks for information inequalities arising from submodularity were developed by Madiman and Tetali (2010) and Sason (2022). Madiman and Tetali (2010) established strong and weak fractional inequalities that subsume classical results such as Han's inequality and Shearer's lemma. Sason (2022) introduced a convex-functional framework for generalizing Han's inequality, and derived unified inequalities for submodular and supermodular functions. In this work, we build on these frameworks and make three contributions. First, we establish convex-functional generalizations of the strong and weak Madiman and Tetali inequalities for submodular functions. Second, using a special case of the strong Madiman-Tetali inequality, we derive a new Loomis-Whitney-type projection inequality for finite point sets in $\mathbb{R}^d$, which improves upon the classical Loomis-Whitney bound by incorporating slice-level structural information. Finally, we study an extremal graph theory problem that recovers and extends the previously known results of Sason (2022) and Boucheron et al., employing Shearer's lemma in contrast to the use of Han's inequality in those works.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15723v1</guid></item><item><title>[cs updates on arXiv.org] VideoThinker: Building Agentic VideoLLMs with LLM-Guided Tool Reasoning</title><link>https://arxiv.org/abs/2601.15724</link><description>arXiv:2601.15724v1 Announce Type: new 
Abstract: Long-form video understanding remains a fundamental challenge for current Video Large Language Models. Most existing models rely on static reasoning over uniformly sampled frames, which weakens temporal localization and leads to substantial information loss in long videos. Agentic tools such as temporal retrieval, spatial zoom, and temporal zoom offer a natural way to overcome these limitations by enabling adaptive exploration of key moments. However, constructing agentic video understanding data requires models that already possess strong long-form video comprehension, creating a circular dependency. We address this challenge with VideoThinker, an agentic Video Large Language Model trained entirely on synthetic tool interaction trajectories. Our key idea is to convert videos into rich captions and employ a powerful agentic language model to generate multi-step tool use sequences in caption space. These trajectories are subsequently grounded back to video by replacing captions with the corresponding frames, yielding a large-scale interleaved video and tool reasoning dataset without requiring any long-form understanding from the underlying model. Training on this synthetic agentic dataset equips VideoThinker with dynamic reasoning capabilities, adaptive temporal exploration, and multi-step tool use. Remarkably, VideoThinker significantly outperforms both caption-only language model agents and strong video model baselines across long-video benchmarks, demonstrating the effectiveness of tool augmented synthetic data and adaptive retrieval and zoom reasoning for long-form video understanding.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15724v1</guid></item><item><title>[cs updates on arXiv.org] Profit Maximization for Viral Marketing in Online Social Networks using Two Phase Diffusion Approach</title><link>https://arxiv.org/abs/2601.15726</link><description>arXiv:2601.15726v1 Announce Type: new 
Abstract: Now-a-days, Online Social Networks (OSNs) are extensively used by different commercial houses for viral marketing. The key problem that arises in this context is to choose a limited number of highly influential users as the initial adopters of a brand such that the influence regarding the brand in the network gets maximized. Deviating from this standard setting, in this paper, we study the problem where every user of the network is associated with a selection cost and a benefit value. This benefit value can be earned from the user if (s)he is influenced by the brand. A fixed amount of budget is allocated for selecting the seed users. The goal of initial adopters is to choose a set of seed users within the budget such that the profit is maximized. We propose a two phase diffusion model for this problem where the goal is to split the diffusion process into two phases, and hence, split the budget into two halves. First, we spend the first half budget to select seed users for the first phase and observe the diffusion for a few rounds and then deploy the seed users for the second phase and successively complete the diffusion process. We prove several properties of the two phase influence function. Three solution approaches have been proposed for our problem with detailed analysis and illustrative examples. We conduct a number of experiments with three real-world social network datasets. From the experiments, we observe that the two phase diffusion approach leads to more amount of profit compared to the single-phase diffusion. In particular, for most instances, this improvement is greater than 18% and reaching as high as 40% by the proposed methodologies.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15726v1</guid></item><item><title>[cs updates on arXiv.org] Towards Automated Kernel Generation in the Era of LLMs</title><link>https://arxiv.org/abs/2601.15727</link><description>arXiv:2601.15727v1 Announce Type: new 
Abstract: The performance of modern AI systems is fundamentally constrained by the quality of their underlying kernels, which translate high-level algorithmic semantics into low-level hardware operations. Achieving near-optimal kernels requires expert-level understanding of hardware architectures and programming models, making kernel engineering a critical but notoriously time-consuming and non-scalable process. Recent advances in large language models (LLMs) and LLM-based agents have opened new possibilities for automating kernel generation and optimization. LLMs are well-suited to compress expert-level kernel knowledge that is difficult to formalize, while agentic systems further enable scalable optimization by casting kernel development as an iterative, feedback-driven loop. Rapid progress has been made in this area. However, the field remains fragmented, lacking a systematic perspective for LLM-driven kernel generation. This survey addresses this gap by providing a structured overview of existing approaches, spanning LLM-based approaches and agentic optimization workflows, and systematically compiling the datasets and benchmarks that underpin learning and evaluation in this domain. Moreover, key open challenges and future research directions are further outlined, aiming to establish a comprehensive reference for the next generation of automated kernel optimization. To keep track of this field, we maintain an open-source GitHub repository at https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15727v1</guid></item><item><title>[cs updates on arXiv.org] Benchmarking Text-to-Python against Text-to-SQL: The Impact of Explicit Logic and Ambiguity</title><link>https://arxiv.org/abs/2601.15728</link><description>arXiv:2601.15728v1 Announce Type: new 
Abstract: While Text-to-SQL remains the dominant approach for database interaction, real-world analytics increasingly require the flexibility of general-purpose programming languages such as Python or Pandas to manage file-based data and complex analytical workflows. Despite this growing need, the reliability of Text-to-Python in core data retrieval remains underexplored relative to the mature SQL ecosystem. To address this gap, we introduce BIRD-Python, a benchmark designed for cross-paradigm evaluation. We systematically refined the original dataset to reduce annotation noise and align execution semantics, thereby establishing a consistent and standardized baseline for comparison. Our analysis reveals a fundamental paradigmatic divergence: whereas SQL leverages implicit DBMS behaviors through its declarative structure, Python requires explicit procedural logic, making it highly sensitive to underspecified user intent. To mitigate this challenge, we propose the Logic Completion Framework (LCF), which resolves ambiguity by incorporating latent domain knowledge into the generation process. Experimental results show that (1) performance differences primarily stem from missing domain context rather than inherent limitations in code generation, and (2) when these gaps are addressed, Text-to-Python achieves performance parity with Text-to-SQL. These findings establish Python as a viable foundation for analytical agents-provided that systems effectively ground ambiguous natural language inputs in executable logical specifications. Resources are available at https://anonymous.4open.science/r/Bird-Python-43B7/.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15728v1</guid></item><item><title>[cs updates on arXiv.org] DualShield: Safe Model Predictive Diffusion via Reachability Analysis for Interactive Autonomous Driving</title><link>https://arxiv.org/abs/2601.15729</link><description>arXiv:2601.15729v1 Announce Type: new 
Abstract: Diffusion models have emerged as a powerful approach for multimodal motion planning in autonomous driving. However, their practical deployment is typically hindered by the inherent difficulty in enforcing vehicle dynamics and a critical reliance on accurate predictions of other agents, making them prone to safety issues under uncertain interactions. To address these limitations, we introduce DualShield, a planning and control framework that leverages Hamilton-Jacobi (HJ) reachability value functions in a dual capacity. First, the value functions act as proactive guidance, steering the diffusion denoising process towards safe and dynamically feasible regions. Second, they form a reactive safety shield using control barrier-value functions (CBVFs) to modify the executed actions and ensure safety. This dual mechanism preserves the rich exploration capabilities of diffusion models while providing principled safety assurance under uncertain and even adversarial interactions. Simulations in challenging unprotected U-turn scenarios demonstrate that DualShield significantly improves both safety and task efficiency compared to leading methods from different planning paradigms under uncertainty.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15729v1</guid></item><item><title>[cs updates on arXiv.org] FAIR-ESI: Feature Adaptive Importance Refinement for Electrophysiological Source Imaging</title><link>https://arxiv.org/abs/2601.15731</link><description>arXiv:2601.15731v1 Announce Type: new 
Abstract: An essential technique for diagnosing brain disorders is electrophysiological source imaging (ESI). While model-based optimization and deep learning methods have achieved promising results in this field, the accurate selection and refinement of features remains a central challenge for precise ESI. This paper proposes FAIR-ESI, a novel framework that adaptively refines feature importance across different views, including FFT-based spectral feature refinement, weighted temporal feature refinement, and self-attention-based patch-wise feature refinement. Extensive experiments on two simulation datasets with diverse configurations and two real-world clinical datasets validate our framework's efficacy, highlighting its potential to advance brain disorder diagnosis and offer new insights into brain function.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15731v1</guid></item><item><title>[cs updates on arXiv.org] Sub-Region-Aware Modality Fusion and Adaptive Prompting for Multi-Modal Brain Tumor Segmentation</title><link>https://arxiv.org/abs/2601.15734</link><description>arXiv:2601.15734v1 Announce Type: new 
Abstract: The successful adaptation of foundation models to multi-modal medical imaging is a critical yet unresolved challenge. Existing models often struggle to effectively fuse information from multiple sources and adapt to the heterogeneous nature of pathological tissues. To address this, we introduce a novel framework for adapting foundation models to multi-modal medical imaging, featuring two key technical innovations: sub-region-aware modality attention and adaptive prompt engineering. The attention mechanism enables the model to learn the optimal combination of modalities for each tumor sub-region, while the adaptive prompting strategy leverages the inherent capabilities of foundation models to refine segmentation accuracy. We validate our framework on the BraTS 2020 brain tumor segmentation dataset, demonstrating that our approach significantly outperforms baseline methods, particularly in the challenging necrotic core sub-region. Our work provides a principled and effective approach to multi-modal fusion and prompting, paving the way for more accurate and robust foundation model-based solutions in medical imaging.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15734v1</guid></item><item><title>[cs updates on arXiv.org] PhysProver: Advancing Automatic Theorem Proving for Physics</title><link>https://arxiv.org/abs/2601.15737</link><description>arXiv:2601.15737v1 Announce Type: new 
Abstract: The combination of verifiable languages and LLMs has significantly influenced both the mathematical and computer science communities because it provides a rigorous foundation for theorem proving. Recent advancements in the field provide foundation models and sophisticated agentic systems pushing the boundaries of formal mathematical reasoning to approach the natural language capability of LLMs. However, little attention has been given to the formal physics reasoning, which also heavily relies on similar problem-solving and theorem-proving frameworks. To solve this problem, this paper presents, to the best of our knowledge, the first approach to enhance formal theorem proving in the physics domain. We compose a dedicated dataset PhysLeanData for the task. It is composed of theorems sampled from PhysLean and data generated by a conjecture-based formal data generation pipeline. In the training pipeline, we leverage DeepSeek-Prover-V2-7B, a strong open-source mathematical theorem prover, and apply Reinforcement Learning with Verifiable Rewards (RLVR) to train our model PhysProver. Comprehensive experiments demonstrate that, using only $\sim$5K training samples, PhysProver achieves an overall 2.4\% improvement in multiple sub-domains. Furthermore, after formal physics training, we observe 1.3\% gains on the MiniF2F-Test benchmark, which indicates non-trivial generalization beyond physics domains and enhancement for formal math capability as well. The results highlight the effectiveness and efficiency of our approach, which provides a paradigm for extending formal provers outside mathematical domains. To foster further research, we will release both our dataset and model to the community.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15737v1</guid></item><item><title>[cs updates on arXiv.org] LLM-Assisted Automatic Dispatching Rule Design for Dynamic Flexible Assembly Flow Shop Scheduling</title><link>https://arxiv.org/abs/2601.15738</link><description>arXiv:2601.15738v1 Announce Type: new 
Abstract: Dynamic multi-product delivery environments demand rapid coordination of part completion and product-level kitting within hybrid processing and assembly systems to satisfy strict hierarchical supply constraints. The flexible assembly flow shop scheduling problem formally defines dependencies for multi-stage kitting, yet dynamic variants make designing integrated scheduling rules under multi-level time coupling highly challenging. Existing automated heuristic design methods, particularly genetic programming constrained to fixed terminal symbol sets, struggle to capture and leverage dynamic uncertainties and hierarchical dependency information under transient decision states. This study develops an LLM-assisted Dynamic Rule Design framework (LLM4DRD) that automatically evolves integrated online scheduling rules adapted to scheduling features. Firstly, multi-stage processing and assembly supply decisions are transformed into feasible directed edge orderings based on heterogeneous graph. Then, an elite knowledge guided initialization embeds advanced design expertise into initial rules to enhance initial quality. Additionally, a dual-expert mechanism is introduced in which LLM-A evolutionary code to generate candidate rules and LLM-S conducts scheduling evaluation, while dynamic feature-fitting rule evolution combined with hybrid evaluation enables continuous improvement and extracts adaptive rules with strong generalization capability. A series of experiments are conducted to validate the effectiveness of the method. The average tardiness of LLM4DRD is 3.17-12.39% higher than state-of-the-art methods in 20 practical instances used for training and testing, respectively. In 24 scenarios with different resource configurations, order loads, and disturbance levels totaling 480 instances, it achieves 11.10% higher performance than the second best competitor, exhibiting excellent robustness.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15738v1</guid></item><item><title>[cs updates on arXiv.org] Breaking the Resolution Barrier: Arbitrary-resolution Deep Image Steganography Framework</title><link>https://arxiv.org/abs/2601.15739</link><description>arXiv:2601.15739v1 Announce Type: new 
Abstract: Deep image steganography (DIS) has achieved significant results in capacity and invisibility. However, current paradigms enforce the secret image to maintain the same resolution as the cover image during hiding and revealing. This leads to two challenges: secret images with inconsistent resolutions must undergo resampling beforehand which results in detail loss during recovery, and the secret image cannot be recovered to its original resolution when the resolution value is unknown. To address these, we propose ARDIS, the first Arbitrary Resolution DIS framework, which shifts the paradigm from discrete mapping to reference-guided continuous signal reconstruction. Specifically, to minimize the detail loss caused by resolution mismatch, we first design a Frequency Decoupling Architecture in hiding stage. It disentangles the secret into a resolution-aligned global basis and a resolution-agnostic high-frequency latent to hide in a fixed-resolution cover. Second, for recovery, we propose a Latent-Guided Implicit Reconstructor to perform deterministic restoration. The recovered detail latent code modulates a continuous implicit function to accurately query and render high-frequency residuals onto the recovered global basis, ensuring faithful restoration of original details. Furthermore, to achieve blind recovery, we introduce an Implicit Resolution Coding strategy. By transforming discrete resolution values into dense feature maps and hiding them in the redundant space of the feature domain, the reconstructor can correctly decode the secret's resolution directly from the steganographic representation. Experimental results demonstrate that ARDIS significantly outperforms state-of-the-art methods in both invisibility and cross-resolution recovery fidelity.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15739v1</guid></item><item><title>[cs updates on arXiv.org] Hallucination Mitigating for Medical Report Generation</title><link>https://arxiv.org/abs/2601.15745</link><description>arXiv:2601.15745v1 Announce Type: new 
Abstract: In the realm of medical report generation (MRG), the integration of natural language processing has emerged as a vital tool to alleviate the workload of radiologists. Despite the impressive capabilities demonstrated by large vision language models (LVLMs) in understanding natural language, their susceptibility to generating plausible yet inaccurate claims, known as ``hallucinations'', raises concerns-especially in the nuanced and critical field of medical. In this work, we introduce a framework, \textbf{K}nowledge-\textbf{E}nhanced with Fine-Grained \textbf{R}einforced Rewards \textbf{M}edical Report Generation (KERM), to tackle the issue. Our approach refines the input to the LVLM by first utilizing MedCLIP for knowledge retrieval, incorporating relevant lesion fact sentences from a curated knowledge corpus. We then introduce a novel purification module to ensure the retrieved knowledge is contextually relevant to the patient's clinical context. Subsequently, we employ fine-grained rewards to guide these models in generating highly supportive and clinically relevant descriptions, ensuring the alignment of model's outputs with desired behaviors. Experimental results on IU-Xray and MIMIC-CXR datasets validate the effectiveness of our approach in mitigating hallucinations and enhancing report quality.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15745v1</guid></item><item><title>[cs updates on arXiv.org] Tabular Incremental Inference</title><link>https://arxiv.org/abs/2601.15751</link><description>arXiv:2601.15751v1 Announce Type: new 
Abstract: Tabular data is a fundamental form of data structure. The evolution of table analysis tools reflects humanity's continuous progress in data acquisition, management, and processing. The dynamic changes in table columns arise from technological advancements, changing needs, data integration, etc. However, the standard process of training AI models on tables with fixed columns and then performing inference is not suitable for handling dynamically changed tables. Therefore, new methods are needed for efficiently handling such tables in an unsupervised manner. In this paper, we introduce a new task, Tabular Incremental Inference (TabII), which aims to enable trained models to incorporate new columns during the inference stage, enhancing the practicality of AI models in scenarios where tables are dynamically changed. Furthermore, we demonstrate that this new task can be framed as an optimization problem based on the information bottleneck theory, which emphasizes that the key to an ideal tabular incremental inference approach lies in minimizing mutual information between tabular data and representation while maximizing between representation and task labels. Under this guidance, we design a TabII method with Large Language Model placeholders and Pretrained TabAdapter to provide external knowledge and Incremental Sample Condensation blocks to condense the task-relevant information given by incremental column attributes. Experimental results across eight public datasets show that TabII effectively utilizes incremental attributes, achieving state-of-the-art performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15751v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Marginal Distributions: A Framework to Evaluate the Representativeness of Demographic-Aligned LLMs</title><link>https://arxiv.org/abs/2601.15755</link><description>arXiv:2601.15755v1 Announce Type: new 
Abstract: Large language models are increasingly used to represent human opinions, values, or beliefs, and their steerability towards these ideals is an active area of research. Existing work focuses predominantly on aligning marginal response distributions, treating each survey item independently. While essential, this may overlook deeper latent structures that characterise real populations and underpin cultural values theories. We propose a framework for evaluating the representativeness of aligned models through multivariate correlation patterns in addition to marginal distributions. We show the value of our evaluation scheme by comparing two model steering techniques (persona prompting and demographic fine-tuning) and evaluating them against human responses from the World Values Survey. While the demographically fine-tuned model better approximates marginal response distributions than persona prompting, both techniques fail to fully capture the gold standard correlation patterns. We conclude that representativeness is a distinct aspect of value alignment and an evaluation focused on marginals can mask structural failures, leading to overly optimistic conclusions about model capabilities.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15755v1</guid></item><item><title>[cs updates on arXiv.org] CTL* Model Checking on Infinite Families of Finite-State Labeled Transition Systems (Technical Report)</title><link>https://arxiv.org/abs/2601.15756</link><description>arXiv:2601.15756v1 Announce Type: new 
Abstract: We study model checking algorithms for infinite families of finite-state labeled transition systems against temporal properties written in CTL*. Such families arise, for example, as models of highly configurable systems or software product lines.
  We model families using context-free graph grammars. We then develop a state labeling algorithm that works compositionally on the grammar's production rules with limited information about the context in which the rule is applied. The result is a graph grammar modeling the same family but with extended labels. We leverage this grammar to decide whether all, some, or (in)finitely many members of a family satisfy a given temporal property. We have implemented our algorithms and present early experiments.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15756v1</guid></item><item><title>[cs updates on arXiv.org] White-Box mHC: Electromagnetic Spectrum-Aware and Interpretable Stream Interactions for Hyperspectral Image Classification</title><link>https://arxiv.org/abs/2601.15757</link><description>arXiv:2601.15757v1 Announce Type: new 
Abstract: In hyperspectral image classification (HSIC), most deep learning models rely on opaque spectral-spatial feature mixing, limiting their interpretability and hindering understanding of internal decision mechanisms. We present physical spectrum-aware white-box mHC, named ES-mHC, a hyper-connection framework that explicitly models interactions among different electromagnetic spectrum groupings (residual stream in mHC) interactions using structured, directional matrices. By separating feature representation from interaction structure, ES-mHC promotes electromagnetic spectrum grouping specialization, reduces redundancy, and exposes internal information flow that can be directly visualized and spatially analyzed. Using hyperspectral image classification as a representative testbed, we demonstrate that the learned hyper-connection matrices exhibit coherent spatial patterns and asymmetric interaction behaviors, providing mechanistic insight into the model internal dynamics. Furthermore, we find that increasing the expansion rate accelerates the emergence of structured interaction patterns. These results suggest that ES-mHC transforms HSIC from a purely black-box prediction task into a structurally transparent, partially white-box learning process.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15757v1</guid></item><item><title>[cs updates on arXiv.org] NL4ST: A Natural Language Query Tool for Spatio-Temporal Databases</title><link>https://arxiv.org/abs/2601.15758</link><description>arXiv:2601.15758v1 Announce Type: new 
Abstract: The advancement of mobile computing devices and positioning technologies has led to an explosive growth of spatio-temporal data managed in databases. Representative queries over such data include range queries, nearest neighbor queries, and join queries. However, formulating those queries usually requires domain-specific expertise and familiarity with executable query languages, which would be a challenging task for non-expert users. It leads to a great demand for well-supported natural language queries (NLQs) in spatio-temporal databases. To bridge the gap between non-experts and query plans in databases, we present NL4ST, an interactive tool that allows users to query spatio-temporal databases in natural language. NL4ST features a three-layer architecture: (i) knowledge base and corpus for knowledge preparation, (ii) natural language understanding for entity linking, and (iii) generating physical plans. Our demonstration will showcase how NL4ST provides effective spatio-temporal physical plans, verified by using four real and synthetic datasets. We make NL4ST online and provide the demo video at https://youtu.be/-J1R7R5WoqQ.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15758v1</guid></item><item><title>[cs updates on arXiv.org] Atlas-Assisted Segment Anything Model for Fetal Brain MRI (FeTal-SAM)</title><link>https://arxiv.org/abs/2601.15759</link><description>arXiv:2601.15759v1 Announce Type: new 
Abstract: This paper presents FeTal-SAM, a novel adaptation of the Segment Anything Model (SAM) tailored for fetal brain MRI segmentation. Traditional deep learning methods often require large annotated datasets for a fixed set of labels, making them inflexible when clinical or research needs change. By integrating atlas-based prompts and foundation-model principles, FeTal-SAM addresses two key limitations in fetal brain MRI segmentation: (1) the need to retrain models for varying label definitions, and (2) the lack of insight into whether segmentations are driven by genuine image contrast or by learned spatial priors. We leverage multi-atlas registration to generate spatially aligned label templates that serve as dense prompts, alongside a bounding-box prompt, for SAM's segmentation decoder. This strategy enables binary segmentation on a per-structure basis, which is subsequently fused to reconstruct the full 3D segmentation volumes. Evaluations on two datasets, the dHCP dataset and an in-house dataset demonstrate FeTal-SAM's robust performance across gestational ages. Notably, it achieves Dice scores comparable to state-of-the-art baselines which were trained for each dataset and label definition for well-contrasted structures like cortical plate and cerebellum, while maintaining the flexibility to segment any user-specified anatomy. Although slightly lower accuracy is observed for subtle, low-contrast structures (e.g., hippocampus, amygdala), our results highlight FeTal-SAM's potential to serve as a general-purpose segmentation model without exhaustive retraining. This method thus constitutes a promising step toward clinically adaptable fetal brain MRI analysis tools.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15759v1</guid></item><item><title>[cs updates on arXiv.org] Off-Policy Actor-Critic with Sigmoid-Bounded Entropy for Real-World Robot Learning</title><link>https://arxiv.org/abs/2601.15761</link><description>arXiv:2601.15761v1 Announce Type: new 
Abstract: Deploying reinforcement learning in the real world remains challenging due to sample inefficiency, sparse rewards, and noisy visual observations. Prior work leverages demonstrations and human feedback to improve learning efficiency and robustness. However, offline-to-online methods need large datasets and can be unstable, while VLA-assisted RL relies on large-scale pretraining and fine-tuning. As a result, a low-cost real-world RL method with minimal data requirements has yet to emerge. We introduce \textbf{SigEnt-SAC}, an off-policy actor-critic method that learns from scratch using a single expert trajectory. Our key design is a sigmoid-bounded entropy term that prevents negative-entropy-driven optimization toward out-of-distribution actions and reduces Q-function oscillations. We benchmark SigEnt-SAC on D4RL tasks against representative baselines. Experiments show that SigEnt-SAC substantially alleviates Q-function oscillations and reaches a 100\% success rate faster than prior methods. Finally, we validate SigEnt-SAC on four real-world robotic tasks across multiple embodiments, where agents learn from raw images and sparse rewards; results demonstrate that SigEnt-SAC can learn successful policies with only a small number of real-world interactions, suggesting a low-cost and practical pathway for real-world RL deployment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15761v1</guid></item><item><title>[cs updates on arXiv.org] NMRGym: A Comprehensive Benchmark for Nuclear Magnetic Resonance Based Molecular Structure Elucidation</title><link>https://arxiv.org/abs/2601.15763</link><description>arXiv:2601.15763v1 Announce Type: new 
Abstract: Nuclear Magnetic Resonance (NMR) spectroscopy is the cornerstone of small-molecule structure elucidation. While deep learning has demonstrated significant potential in automating structure elucidation and spectral simulation, current progress is severely impeded by the reliance on synthetic datasets, which introduces significant domain shifts when applied to real-world experimental spectra. Furthermore, the lack of standardized evaluation protocols and rigorous data splitting strategies frequently leads to unfair comparisons and data leakage. To address these challenges, we introduce \textbf{NMRGym}, the largest and most comprehensive standardized dataset and benchmark derived from high-quality experimental NMR data to date. Comprising \textbf{269,999} unique molecules paired with high-fidelity $^1$H and $^{13}$C spectra, NMRGym bridges the critical gap between synthetic approximations and real-world diversity. We implement a strict quality control pipeline and unify data formats to ensure fair comparison. To strictly prevent data leakage, we enforce a scaffold-based split. Additionally, we provide fine-grained peak-atom level annotations to support future usage. Leveraging this resource, we establish a comprehensive evaluation suite covering diverse downstream tasks, including structure elucidation, functional group prediction from NMR, toxicity prediction from NMR, and spectral simulation, benchmarking representative state-of-the-art methodologies. Finally, we release an open-source leadboard with an automated leaderboard to foster community collaboration and standardize future research. The dataset, benchmark and leaderboard are publicly available at \textcolor{blue}{https://AIMS-Lab-HKUSTGZ.github.io/NMRGym/}.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15763v1</guid></item><item><title>[cs updates on arXiv.org] LL-GaussianMap: Zero-shot Low-Light Image Enhancement via 2D Gaussian Splatting Guided Gain Maps</title><link>https://arxiv.org/abs/2601.15766</link><description>arXiv:2601.15766v1 Announce Type: new 
Abstract: Significant progress has been made in low-light image enhancement with respect to visual quality. However, most existing methods primarily operate in the pixel domain or rely on implicit feature representations. As a result, the intrinsic geometric structural priors of images are often neglected. 2D Gaussian Splatting (2DGS) has emerged as a prominent explicit scene representation technique characterized by superior structural fitting capabilities and high rendering efficiency. Despite these advantages, the utilization of 2DGS in low-level vision tasks remains unexplored. To bridge this gap, LL-GaussianMap is proposed as the first unsupervised framework incorporating 2DGS into low-light image enhancement. Distinct from conventional methodologies, the enhancement task is formulated as a gain map generation process guided by 2DGS primitives. The proposed method comprises two primary stages. First, high-fidelity structural reconstruction is executed utilizing 2DGS. Then, data-driven enhancement dictionary coefficients are rendered via the rasterization mechanism of Gaussian splatting through an innovative unified enhancement module. This design effectively incorporates the structural perception capabilities of 2DGS into gain map generation, thereby preserving edges and suppressing artifacts during enhancement. Additionally, the reliance on paired data is circumvented through unsupervised learning. Experimental results demonstrate that LL-GaussianMap achieves superior enhancement performance with an extremely low storage footprint, highlighting the effectiveness of explicit Gaussian representations for image enhancement.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15766v1</guid></item><item><title>[cs updates on arXiv.org] Recursive Flow: A Generative Framework for MIMO Channel Estimation</title><link>https://arxiv.org/abs/2601.15767</link><description>arXiv:2601.15767v1 Announce Type: new 
Abstract: Channel estimation is a fundamental challenge in massive multiple-input multiple-output systems, where estimation accuracy governs the spectral efficiency and link reliability. In this work, we introduce Recursive Flow (RC-Flow), a novel solver that leverages pre-trained flow matching priors to robustly recover channel state information from noisy, under-determined measurements. Different from conventional open-loop generative models, our approach establishes a closed-loop refinement framework via a serial restart mechanism and anchored trajectory rectification. By synergizing flow-consistent prior directions with data-fidelity proximal projections, the proposed RC-Flow achieves robust channel reconstruction and delivers state-of-the-art performance across diverse noise levels, particularly in noise-dominated scenarios. The framework is further augmented by an adaptive dual-scheduling strategy, offering flexible management of the trade-off between convergence speed and reconstruction accuracy. Theoretically, we analyze the Jacobian spectral radius of the recursive operator to prove its global asymptotic stability. Numerical results demonstrate that RC-Flow reduces inference latency by two orders of magnitude while achieving a 2.7 dB performance gain in low signal-to-noise ratio regimes compared to the score-based baseline.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15767v1</guid></item><item><title>[cs updates on arXiv.org] Rethinking Drug-Drug Interaction Modeling as Generalizable Relation Learning</title><link>https://arxiv.org/abs/2601.15771</link><description>arXiv:2601.15771v1 Announce Type: new 
Abstract: Drug-drug interaction (DDI) prediction is central to drug discovery and clinical development, particularly in the context of increasingly prevalent polypharmacy. Although existing computational methods achieve strong performance on standard benchmarks, they often fail to generalize to realistic deployment scenarios, where most candidate drug pairs involve previously unseen drugs and validated interactions are scarce. We demonstrate that proximity in the embedding spaces of prevailing molecule-centric DDI models does not reliably correspond to interaction labels, and that simply scaling up model capacity therefore fails to improve generalization. To address these limitations, we propose GenRel-DDI, a generalizable relation learning framework that reformulates DDI prediction as a relation-centric learning problem, in which interaction representations are learned independently of drug identities. This relation-level abstraction enables the capture of transferable interaction patterns that generalize to unseen drugs and novel drug pairs. Extensive experiments across multiple benchmark demonstrate that GenRel-DDI consistently and significantly outperforms state-of-the-art methods, with particularly large gains on strict entity-disjoint evaluations, highlighting the effectiveness and practical utility of relation learning for robust DDI prediction. The code is available at https://github.com/SZU-ADDG/GenRel-DDI.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15771v1</guid></item><item><title>[cs updates on arXiv.org] Next Generation Active Learning: Mixture of LLMs in the Loop</title><link>https://arxiv.org/abs/2601.15773</link><description>arXiv:2601.15773v1 Announce Type: new 
Abstract: With the rapid advancement and strong generalization capabilities of large language models (LLMs), they have been increasingly incorporated into the active learning pipelines as annotators to reduce annotation costs. However, considering the annotation quality, labels generated by LLMs often fall short of real-world applicability. To address this, we propose a novel active learning framework, Mixture of LLMs in the Loop Active Learning, replacing human annotators with labels generated through a Mixture-of-LLMs-based annotation model, aimed at enhancing LLM-based annotation robustness by aggregating the strengths of multiple LLMs. To further mitigate the impact of the noisy labels, we introduce annotation discrepancy and negative learning to identify the unreliable annotations and enhance learning effectiveness. Extensive experiments demonstrate that our framework achieves performance comparable to human annotation and consistently outperforms single-LLM baselines and other LLM-ensemble-based approaches. Moreover, our framework is built on lightweight LLMs, enabling it to operate fully on local machines in real-world applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15773v1</guid></item><item><title>[cs updates on arXiv.org] FirmReBugger: A Benchmark Framework for Monolithic Firmware Fuzzers</title><link>https://arxiv.org/abs/2601.15774</link><description>arXiv:2601.15774v1 Announce Type: new 
Abstract: Monolithic Firmware is widespread. Unsurprisingly, fuzz testing firmware is an active research field with new advances addressing the unique challenges in the domain. However, understanding and evaluating improvements by deriving metrics such as code coverage and unique crashes are problematic, leading to a desire for a reliable bug-based benchmark. To address the need, we design and build FirmReBugger, a holistic framework for fairly assessing monolithic firmware fuzzers with a realistic, diverse, bug-based benchmark. FirmReBugger proposes using bug oracles--C syntax expressions of bug descriptors--with an interpreter to automate analysis and accurately report on bugs discovered, discriminating between states of detected, triggered, reached and not reached. Importantly, our idea of benchmarking does not modify the target binary and simply replays fuzzing seeds to isolate the benchmark implementation from the fuzzer while providing a simple means to extend with new bug oracles. Further, analyzing fuzzing roadblocks, we created FirmBench, a set of diverse, real-world binary targets with 313 software bug oracles. Incorporating our analysis of roadblocks challenging monolithic firmware fuzzing, the bench provides for rapid evaluation of future advances. We implement FirmReBugger in a FuzzBench-for-Firmware type service and use FirmBench to evaluate 9 state-of-the art monolithic firmware fuzzers in the style of a reproducibility study, using a 10 CPU-year effort, to report our findings.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15774v1</guid></item><item><title>[cs updates on arXiv.org] Glove2UAV: A Wearable IMU-Based Glove for Intuitive Control of UAV</title><link>https://arxiv.org/abs/2601.15775</link><description>arXiv:2601.15775v1 Announce Type: new 
Abstract: This paper presents Glove2UAV, a wearable IMU-glove interface for intuitive UAV control through hand and finger gestures, augmented with vibrotactile warnings for exceeding predefined speed thresholds. To promote safer and more predictable interaction in dynamic flight, Glove2UAV is designed as a lightweight and easily deployable wearable interface intended for real-time operation. Glove2UAV streams inertial measurements in real time and estimates palm and finger orientations using a compact processing pipeline that combines median-based outlier suppression with Madgwick-based orientation estimation. The resulting motion estimations are mapped to a small set of control primitives for directional flight (forward/backward and lateral motion) and, when supported by the platform, to object-interaction commands. Vibrotactile feedback is triggered when flight speed exceeds predefined threshold values, providing an additional alert channel during operation. We validate real-time feasibility by synchronizing glove signals with UAV telemetry in both simulation and real-world flights. The results show fast gesture-based command execution, stable coupling between gesture dynamics and platform motion, correct operation of the core command set in our trials, and timely delivery of vibratile warning cues.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15775v1</guid></item><item><title>[cs updates on arXiv.org] UXCascade: Scalable Usability Testing with Simulated User Agents</title><link>https://arxiv.org/abs/2601.15777</link><description>arXiv:2601.15777v1 Announce Type: new 
Abstract: Simulated user agents are increasingly used in usability testing to support fast, iterative UX workflows, as they generate rich data such as action logs and think-aloud reasoning, but the unstructured nature of this output often obscures actionable insights. We present UXCascade, an interactive tool for extracting, aggregating, and presenting agent-generated usability feedback at scale. Our core contribution is a multi-level analysis workflow that (1) highlights patterns across persona traits, goals, and outcomes, (2) links agent reasoning to specific issues, and (3) supports actionable design improvements. UXCascade operationalizes this approach by listing agent goals, traits, and issues in a structured overview. Practitioners can explore detailed reasoning traces and annotated views, propose interface edits, and assess their impact across personas. This enables a top-down, exploration-driven analysis from patterns to concrete UX interventions. A user study with eight UX professionals demonstrates that UXCascade integrates into existing workflows, enabling iterative feedback during early-stage interface development.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15777v1</guid></item><item><title>[cs updates on arXiv.org] Agentic Confidence Calibration</title><link>https://arxiv.org/abs/2601.15778</link><description>arXiv:2601.15778v1 Announce Type: new 
Abstract: AI agents are rapidly advancing from passive language models to autonomous systems executing complex, multi-step tasks. Yet their overconfidence in failure remains a fundamental barrier to deployment in high-stakes settings. Existing calibration methods, built for static single-turn outputs, cannot address the unique challenges of agentic systems, such as compounding errors along trajectories, uncertainty from external tools, and opaque failure modes. To address these challenges, we introduce, for the first time, the problem of Agentic Confidence Calibration and propose Holistic Trajectory Calibration (HTC), a novel diagnostic framework that extracts rich process-level features ranging from macro dynamics to micro stability across an agent's entire trajectory. Powered by a simple, interpretable model, HTC consistently surpasses strong baselines in both calibration and discrimination, across eight benchmarks, multiple LLMs, and diverse agent frameworks. Beyond performance, HTC delivers three essential advances: it provides interpretability by revealing the signals behind failure, enables transferability by applying across domains without retraining, and achieves generalization through a General Agent Calibrator (GAC) that achieves the best calibration (lowest ECE) on the out-of-domain GAIA benchmark. Together, these contributions establish a new process-centric paradigm for confidence calibration, providing a framework for diagnosing and enhancing the reliability of AI agents.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15778v1</guid></item><item><title>[cs updates on arXiv.org] Diffusion Model-Based Data Augmentation for Enhanced Neuron Segmentation</title><link>https://arxiv.org/abs/2601.15779</link><description>arXiv:2601.15779v1 Announce Type: new 
Abstract: Neuron segmentation in electron microscopy (EM) aims to reconstruct the complete neuronal connectome; however, current deep learning-based methods are limited by their reliance on large-scale training data and extensive, time-consuming manual annotations. Traditional methods augment the training set through geometric and photometric transformations; however, the generated samples remain highly correlated with the original images and lack structural diversity. To address this limitation, we propose a diffusion-based data augmentation framework capable of generating diverse and structurally plausible image-label pairs for neuron segmentation. Specifically, the framework employs a resolution-aware conditional diffusion model with multi-scale conditioning and EM resolution priors to enable voxel-level image synthesis from 3D masks. It further incorporates a biology-guided mask remodeling module that produces augmented masks with enhanced structural realism. Together, these components effectively enrich the training set and improve segmentation performance. On the AC3 and AC4 datasets under low-annotation regimes, our method improves the ARAND metric by 32.1% and 30.7%, respectively, when combined with two different post-processing methods. Our code is available at https://github.com/HeadLiuYun/NeuroDiff.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15779v1</guid></item><item><title>[cs updates on arXiv.org] Assessing Situational and Spatial Awareness of VLMs with Synthetically Generated Video</title><link>https://arxiv.org/abs/2601.15780</link><description>arXiv:2601.15780v1 Announce Type: new 
Abstract: Spatial reasoning in vision language models (VLMs) remains fragile when semantics hinge on subtle temporal or geometric cues. We introduce a synthetic benchmark that probes two complementary skills: situational awareness (recognizing whether an interaction is harmful or benign) and spatial awareness (tracking who does what to whom, and reasoning about relative positions and motion). Through minimal video pairs, we test three challenges: distinguishing violence from benign activity, binding assailant roles across viewpoints, and judging fine-grained trajectory alignment. While we evaluate recent VLMs in a training-free setting, the benchmark is applicable to any video classification model. Results show performance only slightly above chance across tasks. A simple aid, stable color cues, partly reduces assailant role confusions but does not resolve the underlying weakness. By releasing data and code, we aim to provide reproducible diagnostics and seed exploration of lightweight spatial priors to complement large-scale pretraining.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15780v1</guid></item><item><title>[cs updates on arXiv.org] Endowing Molecular Language with Geometry Perception via Modality Compensation for High-Throughput Quantum Hamiltonian Prediction</title><link>https://arxiv.org/abs/2601.15786</link><description>arXiv:2601.15786v1 Announce Type: new 
Abstract: The quantum Hamiltonian is a fundamental property that governs a molecule's electronic structure and behavior, and its calculation and prediction are paramount in computational chemistry and materials science. Accurate prediction is highly reliant on extensive training data, including precise molecular geometries and the Hamiltonian matrices, which are expensive to acquire via either experimental or computational methods. Towards a fast yet accurate method for Hamiltonian prediction, we first introduce a geometry information-aware molecular language model to bypass the use of expensive molecular geometries by only using the readily available molecular language -- simplified molecular input line entry system (SMILES). Our method employs multimodal alignment to bridge the relationship between SMILES strings and their corresponding molecular geometries. Recognizing that the molecular language inherently lacks explicit geometric information, we propose a geometry modality compensation strategy to imbue molecular language representations with essential geometric features, thereby enabling accurate predictions using SMILES. In addition, given the high cost of acquiring Hamiltonian data, we devise a weakly supervised strategy to fine-tune the molecular language model, thus improving the data efficiency. Theoretically, we prove that the prediction generalization error without explicit molecular geometry can be bounded through our modality compensation scheme. Empirically, our method achieves superior computational efficiency, providing up to 100x speedup over conventional quantum mechanical methods while maintaining comparable prediction accuracy. We further demonstrate the practical case study of our approach in the screening of electrolyte formulations.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15786v1</guid></item><item><title>[cs updates on arXiv.org] HumanLLM: Towards Personalized Understanding and Simulation of Human Nature</title><link>https://arxiv.org/abs/2601.15793</link><description>arXiv:2601.15793v1 Announce Type: new 
Abstract: Motivated by the remarkable progress of large language models (LLMs) in objective tasks like mathematics and coding, there is growing interest in their potential to simulate human behavior--a capability with profound implications for transforming social science research and customer-centric business insights. However, LLMs often lack a nuanced understanding of human cognition and behavior, limiting their effectiveness in social simulation and personalized applications. We posit that this limitation stems from a fundamental misalignment: standard LLM pretraining on vast, uncontextualized web data does not capture the continuous, situated context of an individual's decisions, thoughts, and behaviors over time. To bridge this gap, we introduce HumanLLM, a foundation model designed for personalized understanding and simulation of individuals. We first construct the Cognitive Genome Dataset, a large-scale corpus curated from real-world user data on platforms like Reddit, Twitter, Blogger, and Amazon. Through a rigorous, multi-stage pipeline involving data filtering, synthesis, and quality control, we automatically extract over 5.5 million user logs to distill rich profiles, behaviors, and thinking patterns. We then formulate diverse learning tasks and perform supervised fine-tuning to empower the model to predict a wide range of individualized human behaviors, thoughts, and experiences. Comprehensive evaluations demonstrate that HumanLLM achieves superior performance in predicting user actions and inner thoughts, more accurately mimics user writing styles and preferences, and generates more authentic user profiles compared to base models. Furthermore, HumanLLM shows significant gains on out-of-domain social intelligence benchmarks, indicating enhanced generalization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15793v1</guid></item><item><title>[cs updates on arXiv.org] Creativity in the Age of AI: Rethinking the Role of Intentional Agency</title><link>https://arxiv.org/abs/2601.15797</link><description>arXiv:2601.15797v1 Announce Type: new 
Abstract: Many theorists of creativity maintain that intentional agency is a necessary condition of creativity. We argue that this requirement, which we call the Intentional Agency Condition (IAC), should be rejected as a general condition of creativity, while retaining its relevance in specific contexts. We show that recent advances in generative AI have rendered the IAC increasingly problematic, both descriptively and functionally. We offer two reasons for abandoning it at the general level. First, we present corpus evidence indicating that authors and journalists are increasingly comfortable ascribing creativity to generative AI, despite its lack of intentional agency. This development places pressure on the linguistic intuitions that have traditionally been taken to support the IAC. Second, drawing on the method of conceptual engineering, we argue that the IAC no longer fulfils its core social function. Rather than facilitating the identification and encouragement of reliable sources of novel and valuable products, it now feeds into biases that distort our assessments of AI-generated outputs. We therefore propose replacing the IAC with a consistency requirement, according to which creativity tracks the reliable generation of novel and valuable products. Nonetheless, we explain why the IAC should be retained in specific local domains.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15797v1</guid></item><item><title>[cs updates on arXiv.org] VitalDiagnosis: AI-Driven Ecosystem for 24/7 Vital Monitoring and Chronic Disease Management</title><link>https://arxiv.org/abs/2601.15798</link><description>arXiv:2601.15798v1 Announce Type: new 
Abstract: Chronic diseases have become the leading cause of death worldwide, a challenge intensified by strained medical resources and an aging population. Individually, patients often struggle to interpret early signs of deterioration or maintain adherence to care plans. In this paper, we introduce VitalDiagnosis, an LLM-driven ecosystem designed to shift chronic disease management from passive monitoring to proactive, interactive engagement. By integrating continuous data from wearable devices with the reasoning capabilities of LLMs, the system addresses both acute health anomalies and routine adherence. It analyzes triggers through context-aware inquiries, produces provisional insights within a collaborative patient-clinician workflow, and offers personalized guidance. This approach aims to promote a more proactive and cooperative care paradigm, with the potential to enhance patient self-management and reduce avoidable clinical workload.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15798v1</guid></item><item><title>[cs updates on arXiv.org] Attributing and Exploiting Safety Vectors through Global Optimization in Large Language Models</title><link>https://arxiv.org/abs/2601.15801</link><description>arXiv:2601.15801v1 Announce Type: new 
Abstract: While Large Language Models (LLMs) are aligned to mitigate risks, their safety guardrails remain fragile against jailbreak attacks. This reveals limited understanding of components governing safety. Existing methods rely on local, greedy attribution that assumes independent component contributions. However, they overlook the cooperative interactions between different components in LLMs, such as attention heads, which jointly contribute to safety mechanisms. We propose \textbf{G}lobal \textbf{O}ptimization for \textbf{S}afety \textbf{V}ector Extraction (GOSV), a framework that identifies safety-critical attention heads through global optimization over all heads simultaneously. We employ two complementary activation repatching strategies: Harmful Patching and Zero Ablation. These strategies identify two spatially distinct sets of safety vectors with consistently low overlap, termed Malicious Injection Vectors and Safety Suppression Vectors, demonstrating that aligned LLMs maintain separate functional pathways for safety purposes. Through systematic analyses, we find that complete safety breakdown occurs when approximately 30\% of total heads are repatched across all models. Building on these insights, we develop a novel inference-time white-box jailbreak method that exploits the identified safety vectors through activation repatching. Our attack substantially outperforms existing white-box attacks across all test models, providing strong evidence for the effectiveness of the proposed GOSV framework on LLM safety interpretability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15801v1</guid></item><item><title>[cs updates on arXiv.org] A Beacon Based Solution for Autonomous UUVs GNSS-Denied Stealthy Navigation</title><link>https://arxiv.org/abs/2601.15802</link><description>arXiv:2601.15802v1 Announce Type: new 
Abstract: Autonomous Unmanned Underwater Vehicles (UUVs) enable military and civilian covert operations in coastal areas without relying on support vessels or Global Navigation Satellite Systems (GNSS). Such operations are critical when surface access is not possible and stealthy navigation is required in restricted environments such as protected zones or dangerous areas under access ban. GNSS denied navigation is then essential to maintaining concealment as surfacing could expose UUVs to detection. To ensure a precise fleet positioning a constellation of beacons deployed by aerial or surface drones establish a synthetic landmark network that will guide the fleet of UUVs along an optimized path from the continental shelf to the goal on the shore. These beacons either submerged or floating emit acoustic signals for UUV localisation and navigation. A hierarchical planner generates an adaptive route for the drones executing primitive actions while continuously monitoring and replanning as needed to maintain trajectory accuracy.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15802v1</guid></item><item><title>[cs updates on arXiv.org] Entangled Life and Code: A Computational Design Taxonomy for Synergistic Bio-Digital Systems</title><link>https://arxiv.org/abs/2601.15804</link><description>arXiv:2601.15804v1 Announce Type: new 
Abstract: Bio-digital systems that merge microbial life with technology promise new modes of computation, combining biological adaptability with digital precision. Yet realizing this potential symbiotically -- where biological and digital agents co-adapt and co-process -- remains elusive, largely due to the absence of a shared vocabulary bridging biology and computing. Consequently, microbes are often constrained to uni-directional roles, functioning as sensors or actuators rather than as active, computational partners in bio-digital systems. In response, we propose a taxonomy and pathways that articulate and expand the roles of biological and digital entities for synergetic bio-digital computation. Using this taxonomy, we analysed 70 systems across HCI, design, and engineering, identifying how biological mechanisms can be mapped onto computational abstractions. We argue that such mappings enable computationally actionable directions that foster richer and reciprocal relationships in bio-digital systems, supporting regenerative ecologies across time and scale while inspiring new paradigms for computation in HCI.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15804v1</guid></item><item><title>[cs updates on arXiv.org] Inference-Time Scaling of Verification: Self-Evolving Deep Research Agents via Test-Time Rubric-Guided Verification</title><link>https://arxiv.org/abs/2601.15808</link><description>arXiv:2601.15808v1 Announce Type: new 
Abstract: Recent advances in Deep Research Agents (DRAs) are transforming automated knowledge discovery and problem-solving. While the majority of existing efforts focus on enhancing policy capabilities via post-training, we propose an alternative paradigm: self-evolving the agent's ability by iteratively verifying the policy model's outputs, guided by meticulously crafted rubrics. This approach gives rise to the inference-time scaling of verification, wherein an agent self-improves by evaluating its generated answers to produce iterative feedback and refinements. We derive the rubrics based on an automatically constructed DRA Failure Taxonomy, which systematically classifies agent failures into five major categories and thirteen sub-categories. We present DeepVerifier, a rubrics-based outcome reward verifier that leverages the asymmetry of verification and outperforms vanilla agent-as-judge and LLM judge baselines by 12%-48% in meta-evaluation F1 score. To enable practical self-evolution, DeepVerifier integrates as a plug-and-play module during test-time inference. The verifier produces detailed rubric-based feedback, which is fed back to the agent for iterative bootstrapping, refining responses without additional training. This test-time scaling delivers 8%-11% accuracy gains on challenging subsets of GAIA and XBench-DeepResearch when powered by capable closed-source LLMs. Finally, to support open-source advancement, we release DeepVerifier-4K, a curated supervised fine-tuning dataset of 4,646 high-quality agent steps focused on DRA verification. These examples emphasize reflection and self-critique, enabling open models to develop robust verification capabilities.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15808v1</guid></item><item><title>[cs updates on arXiv.org] SteerEval: Inference-time Interventions Strengthen Multilingual Generalization in Neural Summarization Metrics</title><link>https://arxiv.org/abs/2601.15809</link><description>arXiv:2601.15809v1 Announce Type: new 
Abstract: An increasing body of work has leveraged multilingual language models for Natural Language Generation tasks such as summarization. A major empirical bottleneck in this area is the shortage of accurate and robust evaluation metrics for many languages, which hinders progress. Recent studies suggest that multilingual language models often use English as an internal pivot language, and that misalignment with this pivot can lead to degraded downstream performance. Motivated by the hypothesis that this mismatch could also apply to multilingual neural metrics, we ask whether steering their activations toward an English pivot can improve correlation with human judgments. We experiment with encoder- and decoder-based metrics and find that test-time intervention methods are effective across the board, increasing metric effectiveness for diverse languages.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15809v1</guid></item><item><title>[cs updates on arXiv.org] A Mobile Application for Flower Recognition System Based on Convolutional Neural Networks</title><link>https://arxiv.org/abs/2601.15810</link><description>arXiv:2601.15810v1 Announce Type: new 
Abstract: A convolutional neural network (CNN) is a deep learning algorithm that has been specifically designed for computer vision applications. The CNNs proved successful in handling the increasing amount of data in many computer vision problems, where classical machine learning algorithms were insufficient. Flowers have many uses in our daily lives, from decorating to making medicines to detoxifying the environment. Identifying flower types requires expert knowledge. However, accessing experts at any time and in any location may not always be feasible. In this study a mobile application based on CNNs was developed to recognize different types of flowers to provide non-specialists with quick and easy access to information about flower types. The study employed three distinct CNN models, namely MobileNet, DenseNet121, and Xception, to determine the most suitable model for the mobile application. The classification performances of the models were evaluated by training them with seven different optimization algorithms. The DenseNet-121 architecture, which uses the stochastic gradient descent (SGD) optimization algorithm, was the most successful, achieving 95.84 % accuracy, 96.00% precision, recall, and F1-score. This result shows that CNNs can be used for flower classification in mobile applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15810v1</guid></item><item><title>[cs updates on arXiv.org] Contractions of quasi relation algebras and applications to representability</title><link>https://arxiv.org/abs/2601.15811</link><description>arXiv:2601.15811v1 Announce Type: new 
Abstract: Quasi relation algebras (qRAs) were first described by Galatos and Jipsen in 2013. They are generalisations of relation algebras and can also be viewed as certain residuated lattice expansions. We identify positive symmetric idempotent elements in qRAs and show that they can be used to construct new qRAs, so-called contractions of the original algebra. We then show that the contraction of a distributive qRA will be representable when the original algebra is representable. Further, we identify a class of distributive qRAs that are not finitely representable.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15811v1</guid></item><item><title>[cs updates on arXiv.org] ErrorMap and ErrorAtlas: Charting the Failure Landscape of Large Language Models</title><link>https://arxiv.org/abs/2601.15812</link><description>arXiv:2601.15812v1 Announce Type: new 
Abstract: Large Language Models (LLM) benchmarks tell us when models fail, but not why they fail. A wrong answer on a reasoning dataset may stem from formatting issues, calculation errors, or dataset noise rather than weak reasoning. Without disentangling such causes, benchmarks remain incomplete and cannot reliably guide model improvement. We introduce ErrorMap, the first method to chart the sources of LLM failure. It extracts a model's unique "failure signature", clarifies what benchmarks measure, and broadens error identification to reduce blind spots. This helps developers debug models, aligns benchmark goals with outcomes, and supports informed model selection. ErrorMap works on any model or dataset with the same logic. Applying our method to 35 datasets and 83 models we generate ErrorAtlas, a taxonomy of model errors, revealing recurring failure patterns. ErrorAtlas highlights error types that are currently underexplored in LLM research, such as omissions of required details in the output and question misinterpretation. By shifting focus from where models succeed to why they fail, ErrorMap and ErrorAtlas enable advanced evaluation - one that exposes hidden weaknesses and directs progress. Unlike success, typically measured by task-level metrics, our approach introduces a deeper evaluation layer that can be applied globally across models and tasks, offering richer insights into model behavior and limitations. We make the taxonomy and code publicly available with plans to periodically update ErrorAtlas as new benchmarks and models emerge.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15812v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Off-the-Shelf Models: A Lightweight and Accessible Machine Learning Pipeline for Ecologists Working with Image Data</title><link>https://arxiv.org/abs/2601.15813</link><description>arXiv:2601.15813v1 Announce Type: new 
Abstract: We introduce a lightweight experimentation pipeline designed to lower the barrier for applying machine learning (ML) methods for classifying images in ecological research. We enable ecologists to experiment with ML models independently, thus they can move beyond off-the-shelf models and generate insights tailored to local datasets and specific classification tasks and target variables. Our tool combines a simple command-line interface for preprocessing, training, and evaluation with a graphical interface for annotation, error analysis, and model comparison. This design enables ecologists to build and iterate on compact, task-specific classifiers without requiring advanced ML expertise. As a proof of concept, we apply the pipeline to classify red deer (Cervus elaphus) by age and sex from 3392 camera trap images collected in the Veldenstein Forest, Germany. Using 4352 cropped images containing individual deer labeled by experts, we trained and evaluated multiple backbone architectures with a wide variety of parameters and data augmentation strategies. Our best-performing models achieved 90.77% accuracy for age classification and 96.15% for sex classification. These results demonstrate that reliable demographic classification is feasible even with limited data to answer narrow, well-defined ecological problems. More broadly, the framework provides ecologists with an accessible tool for developing ML models tailored to specific research questions, paving the way for broader adoption of ML in wildlife monitoring and demographic analysis.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15813v1</guid></item><item><title>[cs updates on arXiv.org] Virtual Traffic Police: Large Language Model-Augmented Traffic Signal Control for Unforeseen Incidents</title><link>https://arxiv.org/abs/2601.15816</link><description>arXiv:2601.15816v1 Announce Type: new 
Abstract: Adaptive traffic signal control (TSC) has demonstrated strong effectiveness in managing dynamic traffic flows. However, conventional methods often struggle when unforeseen traffic incidents occur (e.g., accidents and road maintenance), which typically require labor-intensive and inefficient manual interventions by traffic police officers. Large Language Models (LLMs) appear to be a promising solution thanks to their remarkable reasoning and generalization capabilities. Nevertheless, existing works often propose to replace existing TSC systems with LLM-based systems, which can be (i) unreliable due to the inherent hallucinations of LLMs and (ii) costly due to the need for system replacement. To address the issues of existing works, we propose a hierarchical framework that augments existing TSC systems with LLMs, whereby a virtual traffic police agent at the upper level dynamically fine-tunes selected parameters of signal controllers at the lower level in response to real-time traffic incidents. To enhance domain-specific reliability in response to unforeseen traffic incidents, we devise a self-refined traffic language retrieval system (TLRS), whereby retrieval-augmented generation is employed to draw knowledge from a tailored traffic language database that encompasses traffic conditions and controller operation principles. Moreover, we devise an LLM-based verifier to update the TLRS continuously over the reasoning process. Our results show that LLMs can serve as trustworthy virtual traffic police officers that can adapt conventional TSC methods to unforeseen traffic incidents with significantly improved operational efficiency and reliability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15816v1</guid></item><item><title>[cs updates on arXiv.org] ExDR: Explanation-driven Dynamic Retrieval Enhancement for Multimodal Fake News Detection</title><link>https://arxiv.org/abs/2601.15820</link><description>arXiv:2601.15820v1 Announce Type: new 
Abstract: The rapid spread of multimodal fake news poses a serious societal threat, as its evolving nature and reliance on timely factual details challenge existing detection methods. Dynamic Retrieval-Augmented Generation provides a promising solution by triggering keyword-based retrieval and incorporating external knowledge, thus enabling both efficient and accurate evidence selection. However, it still faces challenges in addressing issues such as redundant retrieval, coarse similarity, and irrelevant evidence when applied to deceptive content. In this paper, we propose ExDR, an Explanation-driven Dynamic Retrieval-Augmented Generation framework for Multimodal Fake News Detection. Our framework systematically leverages model-generated explanations in both the retrieval triggering and evidence retrieval modules. It assesses triggering confidence from three complementary dimensions, constructs entity-aware indices by fusing deceptive entities, and retrieves contrastive evidence based on deception-specific features to challenge the initial claim and enhance the final prediction. Experiments on two benchmark datasets, AMG and MR2, demonstrate that ExDR consistently outperforms previous methods in retrieval triggering accuracy, retrieval quality, and overall detection performance, highlighting its effectiveness and generalization capability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15820v1</guid></item><item><title>[cs updates on arXiv.org] Introducing the Generative Application Firewall (GAF)</title><link>https://arxiv.org/abs/2601.15824</link><description>arXiv:2601.15824v1 Announce Type: new 
Abstract: This paper introduces the Generative Application Firewall (GAF), a new architectural layer for securing LLM applications. Existing defenses -- prompt filters, guardrails, and data-masking -- remain fragmented; GAF unifies them into a single enforcement point, much like a WAF coordinates defenses for web traffic, while also covering autonomous agents and their tool interactions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15824v1</guid></item><item><title>[cs updates on arXiv.org] Can professional translators identify machine-generated text?</title><link>https://arxiv.org/abs/2601.15828</link><description>arXiv:2601.15828v1 Announce Type: new 
Abstract: This study investigates whether professional translators can reliably identify short stories generated in Italian by artificial intelligence (AI) without prior specialized training. Sixty-nine translators took part in an in-person experiment, where they assessed three anonymized short stories - two written by ChatGPT-4o and one by a human author. For each story, participants rated the likelihood of AI authorship and provided justifications for their choices. While average results were inconclusive, a statistically significant subset (16.2%) successfully distinguished the synthetic texts from the human text, suggesting that their judgements were informed by analytical skill rather than chance. However, a nearly equal number misclassified the texts in the opposite direction, often relying on subjective impressions rather than objective markers, possibly reflecting a reader preference for AI-generated texts. Low burstiness and narrative contradiction emerged as the most reliable indicators of synthetic authorship, with unexpected calques, semantic loans and syntactic transfer from English also reported. In contrast, features such as grammatical accuracy and emotional tone frequently led to misclassification. These findings raise questions about the role and scope of synthetic-text editing in professional contexts.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15828v1</guid></item><item><title>[cs updates on arXiv.org] Towards Realistic Remote Sensing Dataset Distillation with Discriminative Prototype-guided Diffusion</title><link>https://arxiv.org/abs/2601.15829</link><description>arXiv:2601.15829v1 Announce Type: new 
Abstract: Recent years have witnessed the remarkable success of deep learning in remote sensing image interpretation, driven by the availability of large-scale benchmark datasets. However, this reliance on massive training data also brings two major challenges: (1) high storage and computational costs, and (2) the risk of data leakage, especially when sensitive categories are involved. To address these challenges, this study introduces the concept of dataset distillation into the field of remote sensing image interpretation for the first time. Specifically, we train a text-to-image diffusion model to condense a large-scale remote sensing dataset into a compact and representative distilled dataset. To improve the discriminative quality of the synthesized samples, we propose a classifier-driven guidance by injecting a classification consistency loss from a pre-trained model into the diffusion training process. Besides, considering the rich semantic complexity of remote sensing imagery, we further perform latent space clustering on training samples to select representative and diverse prototypes as visual style guidance, while using a visual language model to provide aggregated text descriptions. Experiments on three high-resolution remote sensing scene classification benchmarks show that the proposed method can distill realistic and diverse samples for downstream model training. Code and pre-trained models are available online (https://github.com/YonghaoXu/DPD).</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15829v1</guid></item><item><title>[cs updates on arXiv.org] An IoT-Based Smart Plant Monitoring and Irrigation System with Real-Time Environmental Sensing, Automated Alerts, and Cloud Analytics</title><link>https://arxiv.org/abs/2601.15830</link><description>arXiv:2601.15830v1 Announce Type: new 
Abstract: The increasing global demand for sustainable agriculture necessitates intelligent monitoring systems that optimize resource utilization and plant health management. Traditional farming methods rely on manual observation and periodic watering, often leading to water wastage, inconsistent plant growth, and delayed response to environmental changes. This paper presents a comprehensive IoT-based smart plant monitoring system that integrates multiple environmental sensors with automated irrigation and cloud analytics. The proposed system utilizes an ESP32 microcontroller to collect real-time data from DHT22 (temperature/humidity), HC-SR04 (water level), and soil moisture sensors, with visual feedback through an OLED display and auditory alerts via a buzzer. All sensor data is wirelessly transmitted to the ThingSpeak cloud platform for remote monitoring, historical analysis, and automated alert generation. Experimental results demonstrate the system's effectiveness in maintaining optimal soil moisture levels (with 92\% accuracy), providing real-time environmental monitoring, and reducing water consumption by approximately 40\% compared to conventional irrigation methods. The integrated web dashboard offers comprehensive visualization of plant health parameters, making it suitable for both small-scale gardening and commercial agriculture applications. With a total implementation cost of \$45.20, this system provides an affordable, scalable solution for precision agriculture and smart farming.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15830v1</guid></item><item><title>[cs updates on arXiv.org] RF Intelligence for Health: Classification of SmartBAN Signals in overcrowded ISM band</title><link>https://arxiv.org/abs/2601.15836</link><description>arXiv:2601.15836v1 Announce Type: new 
Abstract: Accurate classification of Radio-Frequency (RF) signals is essential for reliable wearable health-monitoring systems, providing awareness of the interference conditions in which medical protocols operate. In the overcrowded 2.4 GHz ISM band, however, identifying low-power transmissions from medical sensors is challenging due to strong co-channel interference and substantial power asymmetry with coexisting technologies. This work introduces the first open source framework for automatic recognition of SmartBAN signals in Body Area Networks (BANs). The framework combines a synthetic dataset of simulated signals with real RF acquisitions obtained through Software-Defined Radios (SDRs), enabling both controlled and realistic evaluation. Deep convolutional neural networks based on ResNet encoders and U-Net decoders with attention mechanisms are trained and assessed across diverse propagation conditions. The proposed approach achieves over 90% accuracy on synthetic datasets and demonstrates consistent performance on real over-the-air spectrograms. By enabling reliable SmartBAN signal recognition in dense spectral environments, this framework supports interferenceaware coexistence strategies and improves the dependability of wearable healthcare systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15836v1</guid></item><item><title>[cs updates on arXiv.org] TinySense: Effective CSI Compression for Scalable and Accurate Wi-Fi Sensing</title><link>https://arxiv.org/abs/2601.15838</link><description>arXiv:2601.15838v1 Announce Type: new 
Abstract: With the growing demand for device-free and privacy-preserving sensing solutions, Wi-Fi sensing has emerged as a promising approach for human pose estimation (HPE). However, existing methods often process vast amounts of channel state information (CSI) data directly, ultimately straining networking resources. This paper introduces TinySense, an efficient compression framework that enhances the scalability of Wi-Fi-based human sensing. Our approach is based on a new vector quantization-based generative adversarial network (VQGAN). Specifically, by leveraging a VQGAN-learned codebook, TinySense significantly reduces CSI data while maintaining the accuracy required for reliable HPE. To optimize compression, we employ the K-means algorithm to dynamically adjust compression bitrates to cluster a large-scale pre-trained codebook into smaller subsets. Furthermore, a Transformer model is incorporated to mitigate bitrate loss, enhancing robustness in unreliable networking conditions. We prototype TinySense on an experimental testbed using Jetson Nano and Raspberry Pi to measure latency and network resource use. Extensive results demonstrate that TinySense significantly outperforms state-of-the-art compression schemes, achieving up to 1.5x higher HPE accuracy score (PCK20) under the same compression rate. It also reduces latency and networking overhead, respectively, by up to 5x and 2.5x. The code repository is available online at here.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15838v1</guid></item><item><title>[cs updates on arXiv.org] Determinants of Training Corpus Size for Clinical Text Classification</title><link>https://arxiv.org/abs/2601.15846</link><description>arXiv:2601.15846v1 Announce Type: new 
Abstract: Introduction: Clinical text classification using natural language processing (NLP) models requires adequate training data to achieve optimal performance. For that, 200-500 documents are typically annotated. The number is constrained by time and costs and lacks justification of the sample size requirements and their relationship to text vocabulary properties.
  Methods: Using the publicly available MIMIC-III dataset containing hospital discharge notes with ICD-9 diagnoses as labels, we employed pre-trained BERT embeddings followed by Random Forest classifiers to identify 10 randomly selected diagnoses, varying training corpus sizes from 100 to 10,000 documents, and analyzed vocabulary properties by identifying strong and noisy predictive words through Lasso logistic regression on bag-of-words embeddings.
  Results: Learning curves varied significantly across the 10 classification tasks despite identical preprocessing and algorithms, with 600 documents sufficient to achieve 95% of the performance attainable with 10,000 documents for all tasks. Vocabulary analysis revealed that more strong predictors and fewer noisy predictors were associated with steeper learning curves, where every 100 additional noisy words decreased accuracy by approximately 0.02 while 100 additional strong predictors increased maximum accuracy by approximately 0.04.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15846v1</guid></item><item><title>[cs updates on arXiv.org] CGPT: Cluster-Guided Partial Tables with LLM-Generated Supervision for Table Retrieval</title><link>https://arxiv.org/abs/2601.15849</link><description>arXiv:2601.15849v1 Announce Type: new 
Abstract: General-purpose embedding models have demonstrated strong performance in text retrieval but remain suboptimal for table retrieval, where highly structured content leads to semantic compression and query-table mismatch. Recent LLM-based retrieval augmentation methods mitigate this issue by generating synthetic queries, yet they often rely on heuristic partial-table selection and seldom leverage these synthetic queries as supervision to improve the embedding model. We introduce CGPT, a training framework that enhances table retrieval through LLM-generated supervision. CGPT constructs semantically diverse partial tables by clustering table instances using K-means and sampling across clusters to broaden semantic coverage. An LLM then generates synthetic queries for these partial tables, which are used in hard-negative contrastive fine-tuning to refine the embedding model. Experiments across four public benchmarks (MimoTable, OTTQA, FetaQA, and E2E-WTQ) show that CGPT consistently outperforms retrieval baselines, including QGpT, with an average R@1 improvement of 16.54 percent. In a unified multi-domain corpus setting, CGPT further demonstrates strong cross-domain generalization and remains effective even when using smaller LLMs for synthetic query generation. These results indicate that semantically guided partial-table construction, combined with contrastive training from LLM-generated supervision, provides an effective and scalable paradigm for large-scale table retrieval. Our code is available at https://github.com/yumeow0122/CGPT.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15849v1</guid></item><item><title>[cs updates on arXiv.org] Practical applications of Set Shaping Theory to Non-Uniform Sequences</title><link>https://arxiv.org/abs/2601.15853</link><description>arXiv:2601.15853v1 Announce Type: new 
Abstract: Set Shaping Theory (SST) moves beyond the classical fixed-space model by constructing bijective mappings the original sequence set into structured regions of a larger sequence space. These shaped subsets are characterized by a reduced average information content, measured by the product of the empirical entropy and the length, yielding (N +k)H0(f(s)) &lt; NH0(s), which represents the universal coding limit when the source distribution is unknown. The principal experimental difficulty in applying Set Shaping Theory to non-uniform sequences arises from the need to order the sequences of both the original and transformed sets according to their information content. An exact ordering of these sets entails exponential complexity, rendering a direct implementation impractical. In this article, we show that this obstacle can be overcome by performing an approximate but informative ordering that preserves the structural requirements of SST while achieving the shaping gain predicted by the theory. This result extends previous experimental findings obtained for uniformly distributed sequences and demonstrates that the shaping advantage of SST persists for non-uniform sequences. Finally, to ensure full reproducibility, the software implementing the proposed method has been made publicly available on GitHub, enabling independent verification of the results reported in this work</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15853v1</guid></item><item><title>[cs updates on arXiv.org] Uncertainty-guided Generation of Dark-field Radiographs</title><link>https://arxiv.org/abs/2601.15859</link><description>arXiv:2601.15859v1 Announce Type: new 
Abstract: X-ray dark-field radiography provides complementary diagnostic information to conventional attenuation imaging by visualizing microstructural tissue changes through small-angle scattering. However, the limited availability of such data poses challenges for developing robust deep learning models. In this work, we present the first framework for generating dark-field images directly from standard attenuation chest X-rays using an Uncertainty-Guided Progressive Generative Adversarial Network. The model incorporates both aleatoric and epistemic uncertainty to improve interpretability and reliability. Experiments demonstrate high structural fidelity of the generated images, with consistent improvement of quantitative metrics across stages. Furthermore, out-of-distribution evaluation confirms that the proposed model generalizes well. Our results indicate that uncertainty-guided generative modeling enables realistic dark-field image synthesis and provides a reliable foundation for future clinical applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15859v1</guid></item><item><title>[cs updates on arXiv.org] STAR: Semantic Table Representation with Header-Aware Clustering and Adaptive Weighted Fusion</title><link>https://arxiv.org/abs/2601.15860</link><description>arXiv:2601.15860v1 Announce Type: new 
Abstract: Table retrieval is the task of retrieving the most relevant tables from large-scale corpora given natural language queries. However, structural and semantic discrepancies between unstructured text and structured tables make embedding alignment particularly challenging. Recent methods such as QGpT attempt to enrich table semantics by generating synthetic queries, yet they still rely on coarse partial-table sampling and simple fusion strategies, which limit semantic diversity and hinder effective query-table alignment. We propose STAR (Semantic Table Representation), a lightweight framework that improves semantic table representation through semantic clustering and weighted fusion. STAR first applies header-aware K-means clustering to group semantically similar rows and selects representative centroid instances to construct a diverse partial table. It then generates cluster-specific synthetic queries to comprehensively cover the table's semantic space. Finally, STAR employs weighted fusion strategies to integrate table and query embeddings, enabling fine-grained semantic alignment. This design enables STAR to capture complementary information from structured and textual sources, improving the expressiveness of table representations. Experiments on five benchmarks show that STAR achieves consistently higher Recall than QGpT on all datasets, demonstrating the effectiveness of semantic clustering and adaptive weighted fusion for robust table representation. Our code is available at https://github.com/adsl135789/STAR.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15860v1</guid></item><item><title>[cs updates on arXiv.org] Finding large sparse induced subgraphs in graphs of small (but not very small) tree-independence number</title><link>https://arxiv.org/abs/2601.15861</link><description>arXiv:2601.15861v1 Announce Type: new 
Abstract: The independence number of a tree decomposition is the size of a largest independent set contained in a single bag. The tree-independence number of a graph $G$ is the minimum independence number of a tree decomposition of $G$. As shown recently by Lima et al. [ESA~2024], a large family of optimization problems asking for a maximum-weight induced subgraph of bounded treewidth, satisfying a given \textsf{CMSO}$_2$ property, can be solved in polynomial time in graphs whose tree-independence number is bounded by some constant~$k$.
  However, the complexity of the algorithm of Lima et al. grows rapidly with $k$, making it useless if the tree-independence number is superconstant. In this paper we present a refined version of the algorithm. We show that the same family of problems can be solved in time~$n^{\mathcal{O}(k)}$, where $n$ is the number of vertices of the instance, $k$ is the tree-independence number, and the $\mathcal{O}(\cdot)$-notation hides factors depending on the treewidth bound of the solution and the considered \textsf{CMSO}$_2$ property.
  This running time is quasipolynomial for classes of graphs with polylogarithmic tree-independence number; several such classes were recently discovered. Furthermore, the running time is subexponential for many natural classes of geometric intersection graphs -- namely, ones that admit balanced clique-based separators of sublinear size.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15861v1</guid></item><item><title>[cs updates on arXiv.org] A Lightweight Brain-Inspired Machine Learning Framework for Coronary Angiography: Hybrid Neural Representation and Robust Learning Strategies</title><link>https://arxiv.org/abs/2601.15865</link><description>arXiv:2601.15865v1 Announce Type: new 
Abstract: Background: Coronary angiography (CAG) is a cornerstone imaging modality for assessing coronary artery disease and guiding interventional treatment decisions. However, in real-world clinical settings, angiographic images are often characterized by complex lesion morphology, severe class imbalance, label uncertainty, and limited computational resources, posing substantial challenges to conventional deep learning approaches in terms of robustness and generalization.Methods: The proposed framework is built upon a pretrained convolutional neural network to construct a lightweight hybrid neural representation. A selective neural plasticity training strategy is introduced to enable efficient parameter adaptation. Furthermore, a brain-inspired attention-modulated loss function, combining Focal Loss with label smoothing, is employed to enhance sensitivity to hard samples and uncertain annotations. Class-imbalance-aware sampling and cosine annealing with warm restarts are adopted to mimic rhythmic regulation and attention allocation mechanisms observed in biological neural systems.Results: Experimental results demonstrate that the proposed lightweight brain-inspired model achieves strong and stable performance in binary coronary angiography classification, yielding competitive accuracy, recall, F1-score, and AUC metrics while maintaining high computational efficiency.Conclusion: This study validates the effectiveness of brain-inspired learning mechanisms in lightweight medical image analysis and provides a biologically plausible and deployable solution for intelligent clinical decision support under limited computational resources.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15865v1</guid></item><item><title>[cs updates on arXiv.org] Out-of-Distribution Detection Based on Total Variation Estimation</title><link>https://arxiv.org/abs/2601.15867</link><description>arXiv:2601.15867v1 Announce Type: new 
Abstract: This paper introduces a novel approach to securing machine learning model deployments against potential distribution shifts in practical applications, the Total Variation Out-of-Distribution (TV-OOD) detection method. Existing methods have produced satisfactory results, but TV-OOD improves upon these by leveraging the Total Variation Network Estimator to calculate each input's contribution to the overall total variation. By defining this as the total variation score, TV-OOD discriminates between in- and out-of-distribution data. The method's efficacy was tested across a range of models and datasets, consistently yielding results in image classification tasks that were either comparable or superior to those achieved by leading-edge out-of-distribution detection techniques across all evaluation metrics.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15867v1</guid></item><item><title>[cs updates on arXiv.org] Artificial Rigidities vs. Biological Noise: A Comparative Analysis of Multisensory Integration in AV-HuBERT and Human Observers</title><link>https://arxiv.org/abs/2601.15869</link><description>arXiv:2601.15869v1 Announce Type: new 
Abstract: This study evaluates AV-HuBERT's perceptual bio-fidelity by benchmarking its response to incongruent audiovisual stimuli (McGurk effect) against human observers (N=44). Results reveal a striking quantitative isomorphism: AI and humans exhibited nearly identical auditory dominance rates (32.0% vs. 31.8%), suggesting the model captures biological thresholds for auditory resistance. However, AV-HuBERT showed a deterministic bias toward phonetic fusion (68.0%), significantly exceeding human rates (47.7%). While humans displayed perceptual stochasticity and diverse error profiles, the model remained strictly categorical. Findings suggest that current self-supervised architectures mimic multisensory outcomes but lack the neural variability inherent to human speech perception.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15869v1</guid></item><item><title>[cs updates on arXiv.org] PF-D2M: A Pose-free Diffusion Model for Universal Dance-to-Music Generation</title><link>https://arxiv.org/abs/2601.15872</link><description>arXiv:2601.15872v1 Announce Type: new 
Abstract: Dance-to-music generation aims to generate music that is aligned with dance movements. Existing approaches typically rely on body motion features extracted from a single human dancer and limited dance-to-music datasets, which restrict their performance and applicability to real-world scenarios involving multiple dancers and non-human dancers. In this paper, we propose PF-D2M, a universal diffusion-based dance-to-music generation model that incorporates visual features extracted from dance videos. PF-D2M is trained with a progressive training strategy that effectively addresses data scarcity and generalization challenges. Both objective and subjective evaluations show that PF-D2M achieves state-of-the-art performance in dance-music alignment and music quality.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15872v1</guid></item><item><title>[cs updates on arXiv.org] SoK: Challenges in Tabular Membership Inference Attacks</title><link>https://arxiv.org/abs/2601.15874</link><description>arXiv:2601.15874v1 Announce Type: new 
Abstract: Membership Inference Attacks (MIAs) are currently a dominant approach for evaluating privacy in machine learning applications. Despite their significance in identifying records belonging to the training dataset, several concerns remain unexplored, particularly with regard to tabular data. In this paper, first, we provide an extensive review and analysis of MIAs considering two main learning paradigms: centralized and federated learning. We extend and refine the taxonomy for both. Second, we demonstrate the efficacy of MIAs in tabular data using several attack strategies, also including defenses. Furthermore, in a federated learning scenario, we consider the threat posed by an outsider adversary, which is often neglected. Third, we demonstrate the high vulnerability of single-outs (records with a unique signature) to MIAs. Lastly, we explore how MIAs transfer across model architectures. Our results point towards a general poor performance of these attacks in tabular data which contrasts with previous state-of-the-art. Notably, even attacks with limited attack performance can still successfully expose a large portion of single-outs. Moreover, our findings suggest that using different surrogate models makes MIAs more effective.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15874v1</guid></item><item><title>[cs updates on arXiv.org] EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience</title><link>https://arxiv.org/abs/2601.15876</link><description>arXiv:2601.15876v1 Announce Type: new 
Abstract: The development of native computer-use agents (CUA) represents a significant leap in multimodal AI. However, their potential is currently bottlenecked by the constraints of static data scaling. Existing paradigms relying primarily on passive imitation of static datasets struggle to capture the intricate causal dynamics inherent in long-horizon computer tasks. In this work, we introduce EvoCUA, a native computer use agentic model. Unlike static imitation, EvoCUA integrates data generation and policy optimization into a self-sustaining evolutionary cycle. To mitigate data scarcity, we develop a verifiable synthesis engine that autonomously generates diverse tasks coupled with executable validators. To enable large-scale experience acquisition, we design a scalable infrastructure orchestrating tens of thousands of asynchronous sandbox rollouts. Building on these massive trajectories, we propose an iterative evolving learning strategy to efficiently internalize this experience. This mechanism dynamically regulates policy updates by identifying capability boundaries -- reinforcing successful routines while transforming failure trajectories into rich supervision through error analysis and self-correction. Empirical evaluations on the OSWorld benchmark demonstrate that EvoCUA achieves a success rate of 56.7%, establishing a new open-source state-of-the-art. Notably, EvoCUA significantly outperforms the previous best open-source model, OpenCUA-72B (45.0%), and surpasses leading closed-weights models such as UI-TARS-2 (53.1%). Crucially, our results underscore the generalizability of this approach: the evolving paradigm driven by learning from experience yields consistent performance gains across foundation models of varying scales, establishing a robust and scalable path for advancing native agent capabilities.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15876v1</guid></item><item><title>[cs updates on arXiv.org] Evaluating and Achieving Controllable Code Completion in Code LLM</title><link>https://arxiv.org/abs/2601.15879</link><description>arXiv:2601.15879v1 Announce Type: new 
Abstract: Code completion has become a central task, gaining significant attention with the rise of large language model (LLM)-based tools in software engineering. Although recent advances have greatly improved LLMs' code completion abilities, evaluation methods have not advanced equally. Most current benchmarks focus solely on functional correctness of code completions based on given context, overlooking models' ability to follow user instructions during completion-a common scenario in LLM-assisted programming. To address this limitation, we present the first instruction-guided code completion benchmark, Controllable Code Completion Benchmark (C3-Bench), comprising 2,195 carefully designed completion tasks. Through comprehensive evaluation of over 40 mainstream LLMs across C3-Bench and conventional benchmarks, we reveal substantial gaps in instruction-following capabilities between open-source and advanced proprietary models during code completion tasks. Moreover, we develop a straightforward data synthesis pipeline that leverages Qwen2.5-Coder to generate high-quality instruction-completion pairs for supervised fine-tuning (SFT). The resulting model, Qwen2.5-Coder-C3, achieves state-of-the-art performance on C3-Bench. Our findings provide valuable insights for enhancing LLMs' code completion and instruction-following capabilities, establishing new directions for future research in code LLMs. To facilitate reproducibility and foster further research in code LLMs, we open-source all code, datasets, and models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15879v1</guid></item><item><title>[cs updates on arXiv.org] PMPBench: A Paired Multi-Modal Pan-Cancer Benchmark for Medical Image Synthesis</title><link>https://arxiv.org/abs/2601.15884</link><description>arXiv:2601.15884v1 Announce Type: new 
Abstract: Contrast medium plays a pivotal role in radiological imaging, as it amplifies lesion conspicuity and improves detection for the diagnosis of tumor-related diseases. However, depending on the patient's health condition or the medical resources available, the use of contrast medium is not always feasible. Recent work has explored AI-based image translation to synthesize contrast-enhanced images directly from non-contrast scans, aims to reduce side effects and streamlines clinical workflows. Progress in this direction has been constrained by data limitations: (1) existing public datasets focus almost exclusively on brain-related paired MR modalities; (2) other collections include partially paired data but suffer from missing modalities/timestamps and imperfect spatial alignment; (3) explicit labeling of CT vs. CTC or DCE phases is often absent; (4) substantial resources remain private. To bridge this gap, we introduce the first public, fully paired, pan-cancer medical imaging dataset spanning 11 human organs. The MR data include complete dynamic contrast-enhanced (DCE) sequences covering all three phases (DCE1-DCE3), while the CT data provide paired non-contrast and contrast-enhanced acquisitions (CTC). The dataset is curated for anatomical correspondence, enabling rigorous evaluation of 1-to-1, N-to-1, and N-to-N translation settings (e.g., predicting DCE phases from non-contrast inputs). Built upon this resource, we establish a comprehensive benchmark. We report results from representative baselines of contemporary image-to-image translation. We release the dataset and benchmark to catalyze research on safe, effective contrast synthesis, with direct relevance to multi-organ oncology imaging workflows. Our code and dataset are publicly available at https://github.com/YifanChen02/PMPBench.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15884v1</guid></item><item><title>[cs updates on arXiv.org] Understanding the Transfer Limits of Vision Foundation Models</title><link>https://arxiv.org/abs/2601.15888</link><description>arXiv:2601.15888v1 Announce Type: new 
Abstract: Foundation models leverage large-scale pretraining to capture extensive knowledge, demonstrating generalization in a wide range of language tasks. By comparison, vision foundation models (VFMs) often exhibit uneven improvements across downstream tasks, despite substantial computational investment. We postulate that this limitation arises from a mismatch between pretraining objectives and the demands of downstream vision-and-imaging tasks. Pretraining strategies like masked image reconstruction or contrastive learning shape representations for tasks such as recovery of generic visual patterns or global semantic structures, which may not align with the task-specific requirements of downstream applications including segmentation, classification, or image synthesis. To investigate this in a concrete real-world clinical area, we assess two VFMs, a reconstruction-focused MAE-based model (ProFound) and a contrastive-learning-based model (ProViCNet), on five prostate multiparametric MR imaging tasks, examining how such task alignment influences transfer performance, i.e., from pretraining to fine-tuning. Our findings indicate that better alignment between pretraining and downstream tasks, measured by simple divergence metrics such as maximum-mean-discrepancy (MMD) between the same features before and after fine-tuning, correlates with greater performance improvements and faster convergence, emphasizing the importance of designing and analyzing pretraining objectives with downstream applicability in mind.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15888v1</guid></item><item><title>[cs updates on arXiv.org] Existential Positive Transductions of Sparse Graphs</title><link>https://arxiv.org/abs/2601.15890</link><description>arXiv:2601.15890v1 Announce Type: new 
Abstract: Monadic stability generalizes many tameness notions from structural graph theory such as planarity, bounded degree, bounded tree-width, and nowhere density. The sparsification conjecture predicts that the (possibly dense) monadically stable graph classes are exactly those that can be logically encoded by first-order (FO) transductions in the (always sparse) nowhere dense classes. So far this conjecture has been verified for several special cases, such as for classes of bounded shrub-depth, and for the monadically stable fragments of bounded (linear) clique-width, twin-width, and merge-width.
  In this work we propose the existential positive sparsification conjecture, predicting that the more restricted co-matching-free, monadically stable classes are exactly those that can be transduced from nowhere dense classes using only existential positive FO formulas. While the general conjecture remains open, we verify its truth for all known special cases of the original conjecture. Even stronger, we find the sparse preimages as subgraphs of the dense input graphs.
  As a key ingredient, we introduce a new combinatorial operation, called subflip, that arises as the natural co-matching-free analog of the flip operation, which is a central tool in the characterization of monadic stability. Using subflips, we characterize the co-matching-free fragment of monadic stability by appropriate strengthenings of the known flip-flatness and flipper game characterizations for monadic stability. In an attempt to generalize our results to the more expressive MSO logic, we discover (rediscover?) that on relational structures (existential) positive MSO has the same expressive power as (existential) positive FO.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15890v1</guid></item><item><title>[cs updates on arXiv.org] RadJEPA: Radiology Encoder for Chest X-Rays via Joint Embedding Predictive Architecture</title><link>https://arxiv.org/abs/2601.15891</link><description>arXiv:2601.15891v1 Announce Type: new 
Abstract: Recent advances in medical vision language models guide the learning of visual representations; however, this form of supervision is constrained by the availability of paired image text data, raising the question of whether robust radiology encoders can be learned without relying on language supervision. In this work, we introduce RadJEPA, a self-supervised framework built on a Joint Embedding Predictive Architecture that learns without language supervision. Pre-trained solely on unlabeled chest X-ray images, the model learns to predict latent representations of masked image regions. This predictive objective differs fundamentally from both image text pre-training and DINO-style self-distillation: rather than aligning global representations across views or modalities, RadJEPA explicitly models latent-space prediction. We evaluate the learned encoder on disease classification, semantic segmentation, and report generation tasks. Across benchmarks, RadJEPA achieves performance exceeding state-of-the-art approaches, including Rad-DINO.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15891v1</guid></item><item><title>[cs updates on arXiv.org] Stable-DiffCoder: Pushing the Frontier of Code Diffusion Large Language Model</title><link>https://arxiv.org/abs/2601.15892</link><description>arXiv:2601.15892v1 Announce Type: new 
Abstract: Diffusion-based language models (DLLMs) offer non-sequential, block-wise generation and richer data reuse compared to autoregressive (AR) models, but existing code DLLMs still lag behind strong AR baselines under comparable budgets. We revisit this setting in a controlled study and introduce Stable-DiffCoder, a block diffusion code model that reuses the Seed-Coder architecture, data, and training pipeline. To enable efficient knowledge learning and stable training, we incorporate a block diffusion continual pretraining (CPT) stage enhanced by a tailored warmup and block-wise clipped noise schedule. Under the same data and architecture, Stable-DiffCoder overall outperforms its AR counterpart on a broad suite of code benchmarks. Moreover, relying only on the CPT and supervised fine-tuning stages, Stable-DiffCoder achieves stronger performance than a wide range of \~8B ARs and DLLMs, demonstrating that diffusion-based training can improve code modeling quality beyond AR training alone. Moreover, diffusion-based any-order modeling improves structured code modeling for editing and reasoning, and through data augmentation, benefits low-resource coding languages.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15892v1</guid></item><item><title>[cs updates on arXiv.org] Iterative Amortized Hierarchical VAE</title><link>https://arxiv.org/abs/2601.15894</link><description>arXiv:2601.15894v1 Announce Type: new 
Abstract: In this paper we propose the Iterative Amortized Hierarchical Variational Autoencoder (IA-HVAE), which expands on amortized inference with a hybrid scheme containing an initial amortized guess and iterative refinement with decoder gradients. We achieve this by creating a linearly separable decoder in a transform domain (e.g. Fourier space), enabling real-time applications with very high model depths. The architectural change leads to a 35x speed-up for iterative inference with respect to the traditional HVAE. We show that our hybrid approach outperforms fully amortized and fully iterative equivalents in accuracy and speed respectively. Moreover, the IAHVAE shows improved reconstruction quality over a vanilla HVAE in inverse problems such as deblurring and denoising.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15894v1</guid></item><item><title>[cs updates on arXiv.org] Co-Constructing Alignment: A Participatory Approach to Situate AI Values</title><link>https://arxiv.org/abs/2601.15895</link><description>arXiv:2601.15895v1 Announce Type: new 
Abstract: As AI systems become embedded in everyday practice, value misalignment has emerged as a pressing concern. Yet, dominant alignment approaches remain model centric, treating users as passive recipients of prespecified values rather than as epistemic agents who encounter and respond to misalignment during interactions. Drawing on situated perspectives, we frame alignment as an interactional practice co-constructed during human AI interaction. We investigate how users understand and wish to contribute to this process through a participatory workshop that combines misalignment diaries with generative design activities. We surface how misalignments materialise in practice and how users envision acting on them, grounded in the context of researchers using Large Language Models as research assistants. Our findings show that misalignments are experienced less as abstract ethical violations than as unexpected responses, and task or social breakdowns. Participants articulated roles ranging from adjusting and interpreting model behaviour to deliberate non-engagement as an alignment strategy. We conclude with implications for designing systems that support alignment as an ongoing, situated, and shared practice.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15895v1</guid></item><item><title>[cs updates on arXiv.org] ThermoSplat: Cross-Modal 3D Gaussian Splatting with Feature Modulation and Geometry Decoupling</title><link>https://arxiv.org/abs/2601.15897</link><description>arXiv:2601.15897v1 Announce Type: new 
Abstract: Multi-modal scene reconstruction integrating RGB and thermal infrared data is essential for robust environmental perception across diverse lighting and weather conditions. However, extending 3D Gaussian Splatting (3DGS) to multi-spectral scenarios remains challenging. Current approaches often struggle to fully leverage the complementary information of multi-modal data, typically relying on mechanisms that either tend to neglect cross-modal correlations or leverage shared representations that fail to adaptively handle the complex structural correlations and physical discrepancies between spectrums. To address these limitations, we propose ThermoSplat, a novel framework that enables deep spectral-aware reconstruction through active feature modulation and adaptive geometry decoupling. First, we introduce a Cross-Modal FiLM Modulation mechanism that dynamically conditions shared latent features on thermal structural priors, effectively guiding visible texture synthesis with reliable cross-modal geometric cues. Second, to accommodate modality-specific geometric inconsistencies, we propose a Modality-Adaptive Geometric Decoupling scheme that learns independent opacity offsets and executes an independent rasterization pass for the thermal branch. Additionally, a hybrid rendering pipeline is employed to integrate explicit Spherical Harmonics with implicit neural decoding, ensuring both semantic consistency and high-frequency detail preservation. Extensive experiments on the RGBT-Scenes dataset demonstrate that ThermoSplat achieves state-of-the-art rendering quality across both visible and thermal spectrums.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15897v1</guid></item><item><title>[cs updates on arXiv.org] Blind Identification of Channel Codes: A Subspace-Coding Approach</title><link>https://arxiv.org/abs/2601.15903</link><description>arXiv:2601.15903v1 Announce Type: new 
Abstract: The problem of blind identification of channel codes at a receiver involves identifying a code chosen by a transmitter from a known code-family, by observing the transmitted codewords through the channel. Most existing approaches for code-identification are contingent upon the codes in the family having some special structure, and are often computationally expensive otherwise. Further, rigorous analytical guarantees on the performance of these existing techniques are largely absent. This work presents a new method for code-identification on the binary symmetric channel (BSC), inspired by the framework of subspace codes for operator channels, carefully combining principles of hamming-metric and subspace-metric decoding. We refer to this method as the minimum denoised subspace discrepancy decoder. We present theoretical guarantees for code-identification using this decoder, for bounded-weight errors, and also present a bound on the probability of error when used on the BSC. Simulations demonstrate the improved performance of our decoder for random linear codes beyond existing general-purpose techniques, across most channel conditions and even with a limited number of received vectors.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15903v1</guid></item><item><title>[cs updates on arXiv.org] Dynamic Server Allocation Under Stochastic Switchover on Time-Varying Links</title><link>https://arxiv.org/abs/2601.15904</link><description>arXiv:2601.15904v1 Announce Type: new 
Abstract: Dynamic resource allocation to parallel queues is a cornerstone of network scheduling, yet classical solutions often fail when accounting for the overhead of switching delays to queues with superior link conditions. In particular, system performance is further degraded when switching delays are stochastic and inhomogeneous. In this domain, the myopic, Max-Weight policy struggles, as it is agnostic to switching delays. This paper introduces ACI, a non-myopic, frame-based scheduling framework that directly amortizes these switching delays. We first use a Lyapunov drift analysis to prove that backlog-driven ACI is throughput-optimal with respect to a scaled capacity region; then validate ACI's effectiveness on multi-UAV networks with an FSO backhaul. Finally, we demonstrate how adapting its core urgency metric provides the flexibility to navigate the throughput-latency trade-off.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15904v1</guid></item><item><title>[cs updates on arXiv.org] Pregroup representable expansions of residuated lattices</title><link>https://arxiv.org/abs/2601.15905</link><description>arXiv:2601.15905v1 Announce Type: new 
Abstract: Group representable relation algebras play an important role in the study of representable relation algebras. The class of distributive involutive FL-algebras (DInFL-algebras) generalises relation algebras, as well as Sugihara monoids and MV-algebras. We construct DInFL-algebras from pregroups and show that they can be represented as algebras of binary relations. Even for finite pregroups we obtain relational representations of DInFL-algebras with non-Boolean lattice reducts. If the pregroup is enriched with a particular unary order-reversing operation, then our construction yields representation results for distributive quasi relation algebras.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15905v1</guid></item><item><title>[cs updates on arXiv.org] Opening the Black Box: Preliminary Insights into Affective Modeling in Multimodal Foundation Models</title><link>https://arxiv.org/abs/2601.15906</link><description>arXiv:2601.15906v1 Announce Type: new 
Abstract: Understanding where and how emotions are represented in large-scale foundation models remains an open problem, particularly in multimodal affective settings. Despite the strong empirical performance of recent affective models, the internal architectural mechanisms that support affective understanding and generation are still poorly understood. In this work, we present a systematic mechanistic study of affective modeling in multimodal foundation models. Across multiple architectures, training strategies, and affective tasks, we analyze how emotion-oriented supervision reshapes internal model parameters. Our results consistently reveal a clear and robust pattern: affective adaptation does not primarily focus on the attention module, but instead localizes to the feed-forward gating projection (\texttt{gate\_proj}). Through controlled module transfer, targeted single-module adaptation, and destructive ablation, we further demonstrate that \texttt{gate\_proj} is sufficient, efficient, and necessary for affective understanding and generation. Notably, by tuning only approximately 24.5\% of the parameters tuned by AffectGPT, our approach achieves 96.6\% of its average performance across eight affective tasks, highlighting substantial parameter efficiency. Together, these findings provide empirical evidence that affective capabilities in foundation models are structurally mediated by feed-forward gating mechanisms and identify \texttt{gate\_proj} as a central architectural locus of affective modeling.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15906v1</guid></item><item><title>[cs updates on arXiv.org] Transfer Learning from ImageNet for MEG-Based Decoding of Imagined Speech</title><link>https://arxiv.org/abs/2601.15909</link><description>arXiv:2601.15909v1 Announce Type: new 
Abstract: Non-invasive decoding of imagined speech remains challenging due to weak, distributed signals and limited labeled data. Our paper introduces an image-based approach that transforms magnetoencephalography (MEG) signals into time-frequency representations compatible with pretrained vision models. MEG data from 21 participants performing imagined speech tasks were projected into three spatial scalogram mixtures via a learnable sensor-space convolution, producing compact image-like inputs for ImageNet-pretrained vision architectures. These models outperformed classical and non-pretrained models, achieving up to 90.4% balanced accuracy for imagery vs. silence, 81.0% vs. silent reading, and 60.6% for vowel decoding. Cross-subject evaluation confirmed that pretrained models capture shared neural representations, and temporal analyses localized discriminative information to imagery-locked intervals. These findings show that pretrained vision models applied to image-based MEG representations can effectively capture the structure of imagined speech in non-invasive neural signals.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15909v1</guid></item><item><title>[cs updates on arXiv.org] A fully diagonalized spectral method on the unit ball</title><link>https://arxiv.org/abs/2601.15911</link><description>arXiv:2601.15911v1 Announce Type: new 
Abstract: Our main objective in this work is to show how Sobolev orthogonal polynomials emerge as a useful tool within the framework of spectral methods for boundary-value problems. The solution of a boundary-value problem for a stationary Schr\"odinger equation on the unit ball can be studied from a variational perspective. In this variational formulation, a Sobolev inner product naturally arises. As test functions, we consider the linear space of the polynomials satisfying the boundary conditions on the sphere, and a basis of mutually orthogonal polynomials with respect to the Sobolev inner product is provided. The basis of the proposed method is given in terms of spherical harmonics and univariate Sobolev orthogonal polynomials. The connection formula between these Sobolev orthogonal polynomials and the classical orthogonal polynomials on the ball is established. Consequently, the Sobolev Fourier coefficients of a function satisfying the boundary value problem are recursively derived. Finally, one numerical experiment is presented.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15911v1</guid></item><item><title>[cs updates on arXiv.org] TeNet: Text-to-Network for Compact Policy Synthesis</title><link>https://arxiv.org/abs/2601.15912</link><description>arXiv:2601.15912v1 Announce Type: new 
Abstract: Robots that follow natural-language instructions often either plan at a high level using hand-designed interfaces or rely on large end-to-end models that are difficult to deploy for real-time control. We propose TeNet (Text-to-Network), a framework for instantiating compact, task-specific robot policies directly from natural language descriptions. TeNet conditions a hypernetwork on text embeddings produced by a pretrained large language model (LLM) to generate a fully executable policy, which then operates solely on low-dimensional state inputs at high control frequencies. By using the language only once at the policy instantiation time, TeNet inherits the general knowledge and paraphrasing robustness of pretrained LLMs while remaining lightweight and efficient at execution time. To improve generalization, we optionally ground language in behavior during training by aligning text embeddings with demonstrated actions, while requiring no demonstrations at inference time. Experiments on MuJoCo and Meta-World benchmarks show that TeNet produces policies that are orders of magnitude smaller than sequence-based baselines, while achieving strong performance in both multi-task and meta-learning settings and supporting high-frequency control. These results show that text-conditioned hypernetworks offer a practical way to build compact, language-driven controllers for ressource-constrained robot control tasks with real-time requirements.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15912v1</guid></item><item><title>[cs updates on arXiv.org] The Latency Wall: Benchmarking Off-the-Shelf Emotion Recognition for Real-Time Virtual Avatars</title><link>https://arxiv.org/abs/2601.15914</link><description>arXiv:2601.15914v1 Announce Type: new 
Abstract: In the realm of Virtual Reality (VR) and Human-Computer Interaction (HCI), real-time emotion recognition shows promise for supporting individuals with Autism Spectrum Disorder (ASD) in improving social skills. This task requires a strict latency-accuracy trade-off, with motion-to-photon (MTP) latency kept below 140 ms to maintain contingency. However, most off-the-shelf Deep Learning models prioritize accuracy over the strict timing constraints of commodity hardware. As a first step toward accessible VR therapy, we benchmark State-of-the-Art (SOTA) models for Zero-Shot Facial Expression Recognition (FER) on virtual characters using the UIBVFED dataset. We evaluate Medium and Nano variants of YOLO (v8, v11, and v12) for face detection, alongside general-purpose Vision Transformers including CLIP, SigLIP, and ViT-FER.Our results on CPU-only inference demonstrate that while face detection on stylized avatars is robust (100% accuracy), a "Latency Wall" exists in the classification stage. The YOLOv11n architecture offers the optimal balance for detection (~54 ms). However, general-purpose Transformers like CLIP and SigLIP fail to achieve viable accuracy (&lt;23%) or speed (&gt;150 ms) for real-time loops. This study highlights the necessity for lightweight, domain-specific architectures to enable accessible, real-time AI in therapeutic settings.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15914v1</guid></item><item><title>[cs updates on arXiv.org] Class Confidence Aware Reweighting for Long Tailed Learning</title><link>https://arxiv.org/abs/2601.15924</link><description>arXiv:2601.15924v1 Announce Type: new 
Abstract: Deep neural network models degrade significantly in the long-tailed data distribution, with the overall training data dominated by a small set of classes in the head, and the tail classes obtaining less training examples. Addressing the imbalance in the classes, attention in the related literature was given mainly to the adjustments carried out in the decision space in terms of either corrections performed at the logit level in order to compensate class-prior bias, with the least attention to the optimization process resulting from the adjustments introduced through the differences in the confidences among the samples. In the current study, we present the design of a class and confidence-aware re-weighting scheme for long-tailed learning. This scheme is purely based upon the loss level and has a complementary nature to the existing methods performing the adjustment of the logits. In the practical implementation stage of the proposed scheme, we use an {\Omega}(p_t, f_c) function. This function enables the modulation of the contribution towards the training task based upon the confidence value of the prediction, as well as the relative frequency of the corresponding class. Our observations in the experiments are corroborated by significant experimental results performed on the CIFAR-100-LT, ImageNet-LT, and iNaturalist2018 datasets under various values of imbalance factors that clearly authenticate the theoretical discussions above.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15924v1</guid></item><item><title>[cs updates on arXiv.org] NeuroMamba: Multi-Perspective Feature Interaction with Visual Mamba for Neuron Segmentation</title><link>https://arxiv.org/abs/2601.15929</link><description>arXiv:2601.15929v1 Announce Type: new 
Abstract: Neuron segmentation is the cornerstone of reconstructing comprehensive neuronal connectomes, which is essential for deciphering the functional organization of the brain. The irregular morphology and densely intertwined structures of neurons make this task particularly challenging. Prevailing CNN-based methods often fail to resolve ambiguous boundaries due to the lack of long-range context, whereas Transformer-based methods suffer from boundary imprecision caused by the loss of voxel-level details during patch partitioning. To address these limitations, we propose NeuroMamba, a multi-perspective framework that exploits the linear complexity of Mamba to enable patch-free global modeling and synergizes this with complementary local feature modeling, thereby efficiently capturing long-range dependencies while meticulously preserving fine-grained voxel details. Specifically, we design a channel-gated Boundary Discriminative Feature Extractor (BDFE) to enhance local morphological cues. Complementing this, we introduce the Spatial Continuous Feature Extractor (SCFE), which integrates a resolution-aware scanning mechanism into the Visual Mamba architecture to adaptively model global dependencies across varying data resolutions. Finally, a cross-modulation mechanism synergistically fuses these multi-perspective features. Our method demonstrates state-of-the-art performance across four public EM datasets, validating its exceptional adaptability to both anisotropic and isotropic resolutions. The source code will be made publicly available.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15929v1</guid></item><item><title>[cs updates on arXiv.org] MMGRid: Navigating Temporal-aware and Cross-domain Generative Recommendation via Model Merging</title><link>https://arxiv.org/abs/2601.15930</link><description>arXiv:2601.15930v1 Announce Type: new 
Abstract: Model merging (MM) offers an efficient mechanism for integrating multiple specialized models without access to original training data or costly retraining. While MM has demonstrated success in domains like computer vision, its role in recommender systems (RSs) remains largely unexplored. Recently, Generative Recommendation (GR) has emerged as a new paradigm in RSs, characterized by rapidly growing model scales and substantial computational costs, making MM particularly appealing for cost-sensitive deployment scenarios. In this work, we present the first systematic study of MM in GR through a contextual lens. We focus on a fundamental yet underexplored challenge in real-world: how to merge generative recommenders specialized to different real-world contexts, arising from temporal evolving user behaviors and heterogeneous application domains. To this end, we propose a unified framework MMGRid, a structured contextual grid of GR checkpoints that organizes models trained under diverse contexts induced by temporal evolution and domain diversity. All checkpoints are derived from a shared base LLM but fine-tuned on context-specific data, forming a realistic and controlled model space for systematically analyzing MM across GR paradigms and merging algorithms. Our investigation reveals several key insights. First, training GR models from LLMs can introduce parameter conflicts during merging due to token distribution shifts and objective disparities; such conflicts can be alleviated by disentangling task-aware and context-specific parameter changes via base model replacement. Second, incremental training across contexts induces recency bias, which can be effectively balanced through weighted contextual merging. Notably, we observe that optimal merging weights correlate with context-dependent interaction characteristics, offering practical guidance for weight selection in real-world deployments.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15930v1</guid></item><item><title>[cs updates on arXiv.org] ICON: Invariant Counterfactual Optimization with Neuro-Symbolic Priors for Text-Based Person Search</title><link>https://arxiv.org/abs/2601.15931</link><description>arXiv:2601.15931v1 Announce Type: new 
Abstract: Text-Based Person Search (TBPS) holds unique value in real-world surveillance bridging visual perception and language understanding, yet current paradigms utilizing pre-training models often fail to transfer effectively to complex open-world scenarios. The reliance on "Passive Observation" leads to multifaceted spurious correlations and spatial semantic misalignment, causing a lack of robustness against distribution shifts. To fundamentally resolve these defects, this paper proposes ICON (Invariant Counterfactual Optimization with Neuro-symbolic priors), a framework integrating causal and topological priors. First, we introduce Rule-Guided Spatial Intervention to strictly penalize sensitivity to bounding box noise, forcibly severing location shortcuts to achieve geometric invariance. Second, Counterfactual Context Disentanglement is implemented via semantic-driven background transplantation, compelling the model to ignore background interference for environmental independence. Then, we employ Saliency-Driven Semantic Regularization with adaptive masking to resolve local saliency bias and guarantee holistic completeness. Finally, Neuro-Symbolic Topological Alignment utilizes neuro-symbolic priors to constrain feature matching, ensuring activated regions are topologically consistent with human structural logic. Experimental results demonstrate that ICON not only maintains leading performance on standard benchmarks but also exhibits exceptional robustness against occlusion, background interference, and localization noise. This approach effectively advances the field by shifting from fitting statistical co-occurrences to learning causal invariance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15931v1</guid></item><item><title>[cs updates on arXiv.org] Layered automata: A canonical model for automata over infinite words</title><link>https://arxiv.org/abs/2601.15940</link><description>arXiv:2601.15940v1 Announce Type: new 
Abstract: We introduce layered automata, a subclass of alternating parity automata that generalises deterministic automata. Assuming a consistency property, these automata are history deterministic and 0-1 probabilistic. We show that every omega-regular language is recognised by a unique minimal consistent layered automaton, and that this canonical form can be computed in polynomial time from every layered or deterministic automaton. We further establish that for layered automata both consistency checking and inclusion testing can be performed in polynomial time. Much like deterministic finite automata, minimal consistent layered automata admit a characterisation based on congruences.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15940v1</guid></item><item><title>[cs updates on arXiv.org] Accurate Calibration and Robust LiDAR-Inertial Odometry for Spinning Actuated LiDAR Systems</title><link>https://arxiv.org/abs/2601.15946</link><description>arXiv:2601.15946v1 Announce Type: new 
Abstract: Accurate calibration and robust localization are fundamental for downstream tasks in spinning actuated LiDAR applications. Existing methods, however, require parameterizing extrinsic parameters based on different mounting configurations, limiting their generalizability. Additionally, spinning actuated LiDAR inevitably scans featureless regions, which complicates the balance between scanning coverage and localization robustness. To address these challenges, this letter presents a targetless LiDAR-motor calibration (LM-Calibr) on the basis of the Denavit-Hartenberg convention and an environmental adaptive LiDAR-inertial odometry (EVA-LIO). LM-Calibr supports calibration of LiDAR-motor systems with various mounting configurations. Extensive experiments demonstrate its accuracy and convergence across different scenarios, mounting angles, and initial values. Additionally, EVA-LIO adaptively selects downsample rates and map resolutions according to spatial scale. This adaptivity enables the actuator to operate at maximum speed, thereby enhancing scanning completeness while ensuring robust localization, even when LiDAR briefly scans featureless areas. The source code and hardware design are available on GitHub: \textcolor{blue}{\href{https://github.com/zijiechenrobotics/lm_calibr}{github.com/zijiechenrobotics/lm\_calibr}}. The video is available at \textcolor{blue}{\href{https://youtu.be/cZyyrkmeoSk}{youtu.be/cZyyrkmeoSk}}</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15946v1</guid></item><item><title>[cs updates on arXiv.org] Natural Language-Driven Global Mapping of Martian Landforms</title><link>https://arxiv.org/abs/2601.15949</link><description>arXiv:2601.15949v1 Announce Type: new 
Abstract: Planetary surfaces are typically analyzed using high-level semantic concepts in natural language, yet vast orbital image archives remain organized at the pixel level. This mismatch limits scalable, open-ended exploration of planetary surfaces. Here we present MarScope, a planetary-scale vision-language framework enabling natural language-driven, label-free mapping of Martian landforms. MarScope aligns planetary images and text in a shared semantic space, trained on over 200,000 curated image-text pairs. This framework transforms global geomorphic mapping on Mars by replacing pre-defined classifications with flexible semantic retrieval, enabling arbitrary user queries across the entire planet in 5 seconds with F1 scores up to 0.978. Applications further show that it extends beyond morphological classification to facilitate process-oriented analysis and similarity-based geomorphological mapping at a planetary scale. MarScope establishes a new paradigm where natural language serves as a direct interface for scientific discovery over massive geospatial datasets.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15949v1</guid></item><item><title>[cs updates on arXiv.org] EVolSplat4D: Efficient Volume-based Gaussian Splatting for 4D Urban Scene Synthesis</title><link>https://arxiv.org/abs/2601.15951</link><description>arXiv:2601.15951v1 Announce Type: new 
Abstract: Novel view synthesis (NVS) of static and dynamic urban scenes is essential for autonomous driving simulation, yet existing methods often struggle to balance reconstruction time with quality. While state-of-the-art neural radiance fields and 3D Gaussian Splatting approaches achieve photorealism, they often rely on time-consuming per-scene optimization. Conversely, emerging feed-forward methods frequently adopt per-pixel Gaussian representations, which lead to 3D inconsistencies when aggregating multi-view predictions in complex, dynamic environments. We propose EvolSplat4D, a feed-forward framework that moves beyond existing per-pixel paradigms by unifying volume-based and pixel-based Gaussian prediction across three specialized branches. For close-range static regions, we predict consistent geometry of 3D Gaussians over multiple frames directly from a 3D feature volume, complemented by a semantically-enhanced image-based rendering module for predicting their appearance. For dynamic actors, we utilize object-centric canonical spaces and a motion-adjusted rendering module to aggregate temporal features, ensuring stable 4D reconstruction despite noisy motion priors. Far-Field scenery is handled by an efficient per-pixel Gaussian branch to ensure full-scene coverage. Experimental results on the KITTI-360, KITTI, Waymo, and PandaSet datasets show that EvolSplat4D reconstructs both static and dynamic environments with superior accuracy and consistency, outperforming both per-scene optimization and state-of-the-art feed-forward baselines.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15951v1</guid></item><item><title>[cs updates on arXiv.org] Decoupling Return-to-Go for Efficient Decision Transformer</title><link>https://arxiv.org/abs/2601.15953</link><description>arXiv:2601.15953v1 Announce Type: new 
Abstract: The Decision Transformer (DT) has established a powerful sequence modeling approach to offline reinforcement learning. It conditions its action predictions on Return-to-Go (RTG), using it both to distinguish trajectory quality during training and to guide action generation at inference. In this work, we identify a critical redundancy in this design: feeding the entire sequence of RTGs into the Transformer is theoretically unnecessary, as only the most recent RTG affects action prediction. We show that this redundancy can impair DT's performance through experiments. To resolve this, we propose the Decoupled DT (DDT). DDT simplifies the architecture by processing only observation and action sequences through the Transformer, using the latest RTG to guide the action prediction. This streamlined approach not only improves performance but also reduces computational cost. Our experiments show that DDT significantly outperforms DT and establishes competitive performance against state-of-the-art DT variants across multiple offline RL tasks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15953v1</guid></item><item><title>[cs updates on arXiv.org] HyperAlign: Hypernetwork for Efficient Test-Time Alignment of Diffusion Models</title><link>https://arxiv.org/abs/2601.15968</link><description>arXiv:2601.15968v1 Announce Type: new 
Abstract: Diffusion models achieve state-of-the-art performance but often fail to generate outputs that align with human preferences and intentions, resulting in images with poor aesthetic quality and semantic inconsistencies. Existing alignment methods present a difficult trade-off: fine-tuning approaches suffer from loss of diversity with reward over-optimization, while test-time scaling methods introduce significant computational overhead and tend to under-optimize. To address these limitations, we propose HyperAlign, a novel framework that trains a hypernetwork for efficient and effective test-time alignment. Instead of modifying latent states, HyperAlign dynamically generates low-rank adaptation weights to modulate the diffusion model's generation operators. This allows the denoising trajectory to be adaptively adjusted based on input latents, timesteps and prompts for reward-conditioned alignment. We introduce multiple variants of HyperAlign that differ in how frequently the hypernetwork is applied, balancing between performance and efficiency. Furthermore, we optimize the hypernetwork using a reward score objective regularized with preference data to reduce reward hacking. We evaluate HyperAlign on multiple extended generative paradigms, including Stable Diffusion and FLUX. It significantly outperforms existing fine-tuning and test-time scaling baselines in enhancing semantic consistency and visual appeal.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15968v1</guid></item><item><title>[cs updates on arXiv.org] Unveiling and Simulating Short-Video Addiction Behaviors via Economic Addiction Theory</title><link>https://arxiv.org/abs/2601.15975</link><description>arXiv:2601.15975v1 Announce Type: new 
Abstract: Short-video applications have attracted substantial user traffic. However, these platforms also foster problematic usage patterns, commonly referred to as short-video addiction, which pose risks to both user health and the sustainable development of platforms. Prior studies on this issue have primarily relied on questionnaires or volunteer-based data collection, which are often limited by small sample sizes and population biases. In contrast, short-video platforms have large-scale behavioral data, offering a valuable foundation for analyzing addictive behaviors. To examine addiction-aware behavior patterns, we combine economic addiction theory with users' implicit behavior captured by recommendation systems. Our analysis shows that short-video addiction follows functional patterns similar to traditional forms of addictive behavior (e.g., substance abuse) and that its intensity is consistent with findings from previous social science studies. To develop a simulator that can learn and model these patterns, we introduce a novel training framework, AddictSim. To consider the personalized addiction patterns, AddictSim uses a mean-to-adapted strategy with group relative policy optimization training. Experiments on two large-scale datasets show that AddictSim consistently outperforms existing training strategies. Our simulation results show that integrating diversity-aware algorithms can mitigate addictive behaviors well.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15975v1</guid></item><item><title>[cs updates on arXiv.org] Predicting Healthcare System Visitation Flow by Integrating Hospital Attributes and Population Socioeconomics with Human Mobility Data</title><link>https://arxiv.org/abs/2601.15977</link><description>arXiv:2601.15977v1 Announce Type: new 
Abstract: Healthcare visitation patterns are influenced by a complex interplay of hospital attributes, population socioeconomics, and spatial factors. However, existing research often adopts a fragmented approach, examining these determinants in isolation. This study addresses this gap by integrating hospital capacities, occupancy rates, reputation, and popularity with population SES and spatial mobility patterns to predict visitation flows and analyze influencing factors. Utilizing four years of SafeGraph mobility data and user experience data from Google Maps Reviews, five flow prediction models, Naive Regression, Gradient Boosting, Multilayer Perceptrons (MLPs), Deep Gravity, and Heterogeneous Graph Neural Networks (HGNN),were trained and applied to simulate visitation flows in Houston, Texas, U.S. The Shapley additive explanation (SHAP) analysis and the Partial Dependence Plot (PDP) method were employed to examine the combined impacts of different factors on visitation patterns. The findings reveal that Deep Gravity outperformed other models. Hospital capacities, ICU occupancy rates, ratings, and popularity significantly influence visitation patterns, with their effects varying across different travel distances. Short-distance visits are primarily driven by convenience, whereas long-distance visits are influenced by hospital ratings. White-majority areas exhibited lower sensitivity to hospital ratings for short-distance visits, while Asian populations and those with higher education levels prioritized hospital rating in their visitation decisions. SES further influence these patterns, as areas with higher proportions of Hispanic, Black, under-18, and over-65 populations tend to have more frequent hospital visits, potentially reflecting greater healthcare needs or limited access to alternative medical services.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15977v1</guid></item><item><title>[cs updates on arXiv.org] Partially Lazy Gradient Descent for Smoothed Online Learning</title><link>https://arxiv.org/abs/2601.15984</link><description>arXiv:2601.15984v1 Announce Type: new 
Abstract: We introduce $k$-lazyGD, an online learning algorithm that bridges the gap between greedy Online Gradient Descent (OGD, for $k=1$) and lazy GD/dual-averaging (for $k=T$), creating a spectrum between reactive and stable updates. We analyze this spectrum in Smoothed Online Convex Optimization (SOCO), where the learner incurs both hitting and movement costs. Our main contribution is establishing that laziness is possible without sacrificing hitting performance: we prove that $k$-lazyGD achieves the optimal dynamic regret $\mathcal{O}(\sqrt{(P_T+1)T})$ for any laziness slack $k$ up to $\Theta(\sqrt{T/P_T})$, where $P_T$ is the comparator path length. This result formally connects the allowable laziness to the comparator's shifts, showing that $k$-lazyGD can retain the inherently small movements of lazy methods without compromising tracking ability. We base our analysis on the Follow the Regularized Leader (FTRL) framework, and derive a matching lower bound. Since the slack depends on $P_T$, an ensemble of learners with various slacks is used, yielding a method that is provably stable when it can be, and agile when it must be.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15984v1</guid></item><item><title>[cs updates on arXiv.org] Efficient Cloud-edge Collaborative Approaches to SPARQL Queries over Large RDF graphs</title><link>https://arxiv.org/abs/2601.15992</link><description>arXiv:2601.15992v1 Announce Type: new 
Abstract: With the increasing use of RDF graphs, storing and querying such data using SPARQL remains a critical problem. Current mainstream solutions rely on cloud-based data management architectures, but often suffer from performance bottle- necks in environments with limited bandwidth or high system load. To address this issue, this paper explores for the first time the integration of edge computing to move graph data storage and processing to edge environments, thereby improving query performance. This approach requires offloading query processing to edge servers, which involves addressing two challenges: data localization and network scheduling. First, the data localization challenge lies in computing the subgraphs maintained on edge servers to quickly identify the servers that can handle specific queries. To address this challenge, we introduce a new concept of pattern-induced subgraphs. Second, the network scheduling challenge involves efficiently assigning queries to edge and cloud servers to optimize overall system performance. We tackle this by constructing a overall system model that jointly captures data distribution, query characteristics, network communication, and computational resources. Accordingly, we further propose a joint formulation of query assignment and computational resource allocation, modeling it as a Mixed Integer Nonlinear Programming (MINLP) problem and solve this problem using a modified branch-and-bound algorithm. Experimental results on real datasets under a real cloud platform demonstrate that our proposed method outperforms the state-of-the-art baseline methods in terms of efficiency. The codes are available on GitHub</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15992v1</guid></item><item><title>[cs updates on arXiv.org] PUMA: Perception-driven Unified Foothold Prior for Mobility Augmented Quadruped Parkour</title><link>https://arxiv.org/abs/2601.15995</link><description>arXiv:2601.15995v1 Announce Type: new 
Abstract: Parkour tasks for quadrupeds have emerged as a promising benchmark for agile locomotion. While human athletes can effectively perceive environmental characteristics to select appropriate footholds for obstacle traversal, endowing legged robots with similar perceptual reasoning remains a significant challenge. Existing methods often rely on hierarchical controllers that follow pre-computed footholds, thereby constraining the robot's real-time adaptability and the exploratory potential of reinforcement learning. To overcome these challenges, we present PUMA, an end-to-end learning framework that integrates visual perception and foothold priors into a single-stage training process. This approach leverages terrain features to estimate egocentric polar foothold priors, composed of relative distance and heading, guiding the robot in active posture adaptation for parkour tasks. Extensive experiments conducted in simulation and real-world environments across various discrete complex terrains, demonstrate PUMA's exceptional agility and robustness in challenging scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15995v1</guid></item><item><title>[cs updates on arXiv.org] PhysicsMind: Sim and Real Mechanics Benchmarking for Physical Reasoning and Prediction in Foundational VLMs and World Models</title><link>https://arxiv.org/abs/2601.16007</link><description>arXiv:2601.16007v1 Announce Type: new 
Abstract: Modern foundational Multimodal Large Language Models (MLLMs) and video world models have advanced significantly in mathematical, common-sense, and visual reasoning, but their grasp of the underlying physics remains underexplored. Existing benchmarks attempting to measure this matter rely on synthetic, Visual Question Answer templates or focus on perceptual video quality that is tangential to measuring how well the video abides by physical laws. To address this fragmentation, we introduce PhysicsMind, a unified benchmark with both real and simulation environments that evaluates law-consistent reasoning and generation over three canonical principles: Center of Mass, Lever Equilibrium, and Newton's First Law. PhysicsMind comprises two main tasks: i) VQA tasks, testing whether models can reason and determine physical quantities and values from images or short videos, and ii) Video Generation(VG) tasks, evaluating if predicted motion trajectories obey the same center-of-mass, torque, and inertial constraints as the ground truth. A broad range of recent models and video generation models is evaluated on PhysicsMind and found to rely on appearance heuristics while often violating basic mechanics. These gaps indicate that current scaling and training are still insufficient for robust physical understanding, underscoring PhysicsMind as a focused testbed for physics-aware multimodal models. Our data will be released upon acceptance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16007v1</guid></item><item><title>[cs updates on arXiv.org] Prioritizing Configuration Relevance via Compiler-Based Refined Feature Ranking</title><link>https://arxiv.org/abs/2601.16008</link><description>arXiv:2601.16008v1 Announce Type: new 
Abstract: Modern programming languages, most notably Rust, offer advanced linguistic constructs for building highly configurable software systems as aggregation of features -- identified by a configuration. However, they pose substantial challenges for program analysis, optimization, and testing, as the combinatorial explosion of configurations often makes exhaustive exploration infeasible. In this manuscript, we present the first compiler-based method for prioritizing configurations. Our approach consists of four main steps: 1. extracting a tailored intermediate representation from the Rust compiler, 2. constructing two complementary graph-based data structures, 3. using centrality measures to rank features, and 4. refining the ranking by considering the extent of code they impact. A fixed number of most relevant configurations are generated based on the achieved feature ranking. The validity of the generated configurations is guaranteed by using a SAT solver that takes a representation of this graph in conjunctive normal form. We formalized this approach and implemented it in a prototype, RustyEx, by instrumenting the Rust compiler. An empirical evaluation on higher-ranked open source Rust projects shows that RustyEx efficiently generates user-specified sets of configurations within bounded resources, while ensuring soundness by construction. The results demonstrate that centrality-guided configuration prioritization enables effective and practical exploration of large configuration spaces, paving the way for future research in configuration-aware analysis and optimization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16008v1</guid></item><item><title>[cs updates on arXiv.org] The Role of Cognitive Abilities in Requirements Inspection: Comparing UML and Textual Representations</title><link>https://arxiv.org/abs/2601.16009</link><description>arXiv:2601.16009v1 Announce Type: new 
Abstract: The representation of requirements plays a critical role in the accuracy of requirements inspection. While visual representations, such as UML diagrams, are widely used alongside text-based requirements, their effectiveness in supporting inspection is still debated. Cognitive abilities, such as working memory and mental rotation skills, may also influence inspection accuracy. This study aims to evaluate whether the use of UML sequence diagrams alongside text-based requirements improves the accuracy of requirements inspection compared to text-based requirements alone and to explore whether cognitive abilities are associated with differences in performance across the two treatments (text vs text with UML support). We conducted a crossover experiment with 38 participants to assess the accuracy of requirements inspection under the two treatments in terms of issues found and justifications provided. Linear mixed-effects and generalized linear models were used to analyse the effects of treatment, period, sequence, and cognitive abilities. The results indicate a significant three-way interaction between representation type, working memory capacity, and mental rotation ability. This finding suggests that the effectiveness of UML support is not uniform across individuals: participants with high scores in both cognitive abilities experienced reduced performance when using UML for violation detection. Conversely, the same cognitive profile was associated with improved justification accuracy under UML-aided inspection, indicating that higher cognitive abilities may support deeper reasoning processes when dealing with multi-modal information, i.e., diagrams and text.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16009v1</guid></item><item><title>[cs updates on arXiv.org] Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain</title><link>https://arxiv.org/abs/2601.16018</link><description>arXiv:2601.16018v1 Announce Type: new 
Abstract: This paper presents Mecellem models, a framework for developing specialized language models for the Turkish legal domain through domain adaptation strategies. We make two contributions: (1)Encoder Model Pre-trained from Scratch: ModernBERT-based bidirectional encoders pre-trained on a Turkish-dominant corpus of 112.7 billion tokens. We implement a checkpoint selection strategy that evaluates downstream retrieval performance throughout training, revealing that optimal checkpoints achieve best retrieval scores before pre-training loss reaches its minimum. Our encoder models achieve top-3 rankings on the Turkish retrieval leaderboard, with smaller models (155M parameters) achieving comparable performance to larger reference models (307M-567M parameters). Our approach achieves 92.36% production efficiency compared to state-of-the-art models (embeddinggemma-300m: 100.00%, BAAI/bge-m3: 99.54%, newmindai/bge-m3-stsb: 94.38%), ranking fourth overall despite requiring less computational resources. SOTA models rely on multi-stage, computationally intensive training pipelines, making our single-stage pre-training followed by efficient post-training approach a cost-effective alternative; (2)Decoder Model with Continual Pre-training (CPT): Qwen3-1.7B and Qwen3-4B models adapted to Turkish legal domain through controlled curriculum learning. Four-phase CPT with optimal sample ratios enables gradual transition from general language knowledge to specialized legal terminology and long-context reasoning. This approach achieves 36.2% perplexity reduction on Turkish legal text, demonstrating domain adaptation gains.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16018v1</guid></item><item><title>[cs updates on arXiv.org] Keyframe-Based Feed-Forward Visual Odometry</title><link>https://arxiv.org/abs/2601.16020</link><description>arXiv:2601.16020v1 Announce Type: new 
Abstract: The emergence of visual foundation models has revolutionized visual odometry~(VO) and SLAM, enabling pose estimation and dense reconstruction within a single feed-forward network. However, unlike traditional pipelines that leverage keyframe methods to enhance efficiency and accuracy, current foundation model based methods, such as VGGT-Long, typically process raw image sequences indiscriminately. This leads to computational redundancy and degraded performance caused by low inter-frame parallax, which provides limited contextual stereo information. Integrating traditional geometric heuristics into these methods is non-trivial, as their performance depends on high-dimensional latent representations rather than explicit geometric metrics. To bridge this gap, we propose a novel keyframe-based feed-forward VO. Instead of relying on hand-crafted rules, our approach employs reinforcement learning to derive an adaptive keyframe policy in a data-driven manner, aligning selection with the intrinsic characteristics of the underlying foundation model. We train our agent on TartanAir dataset and conduct extensive evaluations across several real-world datasets. Experimental results demonstrate that the proposed method achieves consistent and substantial improvements over state-of-the-art feed-forward VO methods.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16020v1</guid></item><item><title>[cs updates on arXiv.org] PAINT: Pathology-Aware Integrated Next-Scale Transformation for Virtual Immunohistochemistry</title><link>https://arxiv.org/abs/2601.16024</link><description>arXiv:2601.16024v1 Announce Type: new 
Abstract: Virtual immunohistochemistry (IHC) aims to computationally synthesize molecular staining patterns from routine Hematoxylin and Eosin (H\&amp;amp;E) images, offering a cost-effective and tissue-efficient alternative to traditional physical staining. However, this task is particularly challenging: H\&amp;amp;E morphology provides ambiguous cues about protein expression, and similar tissue structures may correspond to distinct molecular states. Most existing methods focus on direct appearance synthesis to implicitly achieve cross-modal generation, often resulting in semantic inconsistencies due to insufficient structural priors. In this paper, we propose Pathology-Aware Integrated Next-Scale Transformation (PAINT), a visual autoregressive framework that reformulates the synthesis process as a structure-first conditional generation task. Unlike direct image translation, PAINT enforces a causal order by resolving molecular details conditioned on a global structural layout. Central to this approach is the introduction of a Spatial Structural Start Map (3S-Map), which grounds the autoregressive initialization in observed morphology, ensuring deterministic, spatially aligned synthesis. Experiments on the IHC4BC and MIST datasets demonstrate that PAINT outperforms state-of-the-art methods in structural fidelity and clinical downstream tasks, validating the potential of structure-guided autoregressive modeling.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16024v1</guid></item><item><title>[cs updates on arXiv.org] EAIFD: A Fast and Scalable Algorithm for Incremental Functional Dependency Discovery</title><link>https://arxiv.org/abs/2601.16025</link><description>arXiv:2601.16025v1 Announce Type: new 
Abstract: Functional dependencies (FDs) are fundamental integrity constraints in relational databases, but discovering them under incremental updates remains challenging. While static algorithms are inefficient due to full re-execution, incremental algorithms suffer from severe performance and memory bottlenecks. To address these challenges, this paper proposes EAIFD, a novel algorithm for incremental FD discovery. EAIFD maintains the partial hypergraph of difference sets and reframes the incremental FD discovery problem into minimal hitting set enumeration on hypergraph, avoiding full re-runs. EAIFD introduces two key innovations. First, a multi-attribute hash table ($MHT$) is devised for high-frequency key-value mappings of valid FDs, whose memory consumption is proven to be independent of the dataset size. Second, two-step validation strategy is developed to efficiently validate the enumerated candidates, which leverages $MHT$ to effectively reduce the validation space and then selectively loads data blocks for batch validation of remaining candidates, effectively avoiding repeated I/O operations. Experimental results on real-world datasets demonstrate the significant advantages of EAIFD. Compared to existing algorithms, EAIFD achieves up to an order-of-magnitude speedup in runtime while reducing memory usage by over two orders-of-magnitude, establishing it as a highly efficient and scalable solution for incremental FD discovery.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16025v1</guid></item><item><title>[cs updates on arXiv.org] Deja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment</title><link>https://arxiv.org/abs/2601.16027</link><description>arXiv:2601.16027v1 Announce Type: new 
Abstract: The rise of live streaming has transformed online interaction, enabling massive real-time engagement but also exposing platforms to complex risks such as scams and coordinated malicious behaviors. Detecting these risks is challenging because harmful actions often accumulate gradually and recur across seemingly unrelated streams. To address this, we propose CS-VAR (Cross-Session Evidence-Aware Retrieval-Augmented Detector) for live streaming risk assessment. In CS-VAR, a lightweight, domain-specific model performs fast session-level risk inference, guided during training by a Large Language Model (LLM) that reasons over retrieved cross-session behavioral evidence and transfers its local-to-global insights to the small model. This design enables the small model to recognize recurring patterns across streams, perform structured risk assessment, and maintain efficiency for real-time deployment. Extensive offline experiments on large-scale industrial datasets, combined with online validation, demonstrate the state-of-the-art performance of CS-VAR. Furthermore, CS-VAR provides interpretable, localized signals that effectively empower real-world moderation for live streaming.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16027v1</guid></item><item><title>[cs updates on arXiv.org] Data-Driven Conditional Flexibility Index</title><link>https://arxiv.org/abs/2601.16028</link><description>arXiv:2601.16028v1 Announce Type: new 
Abstract: With the increasing flexibilization of processes, determining robust scheduling decisions has become an important goal. Traditionally, the flexibility index has been used to identify safe operating schedules by approximating the admissible uncertainty region using simple admissible uncertainty sets, such as hypercubes. Presently, available contextual information, such as forecasts, has not been considered to define the admissible uncertainty set when determining the flexibility index. We propose the conditional flexibility index (CFI), which extends the traditional flexibility index in two ways: by learning the parametrized admissible uncertainty set from historical data and by using contextual information to make the admissible uncertainty set conditional. This is achieved using a normalizing flow that learns a bijective mapping from a Gaussian base distribution to the data distribution. The admissible latent uncertainty set is constructed as a hypersphere in the latent space and mapped to the data space. By incorporating contextual information, the CFI provides a more informative estimate of flexibility by defining admissible uncertainty sets in regions that are more likely to be relevant under given conditions. Using an illustrative example, we show that no general statement can be made about data-driven admissible uncertainty sets outperforming simple sets, or conditional sets outperforming unconditional ones. However, both data-driven and conditional admissible uncertainty sets ensure that only regions of the uncertain parameter space containing realizations are considered. We apply the CFI to a security-constrained unit commitment example and demonstrate that the CFI can improve scheduling quality by incorporating temporal information.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16028v1</guid></item><item><title>[cs updates on arXiv.org] Stacked Intelligent Metasurface-Aided Wave-Domain Signal Processing: From Communications to Sensing and Computing</title><link>https://arxiv.org/abs/2601.16030</link><description>arXiv:2601.16030v1 Announce Type: new 
Abstract: Neural networks possess incredible capabilities for extracting abstract features from data. Electromagnetic computing harnesses wave propagation to execute computational operations. Metasurfaces, composed of subwavelength meta-atoms, are capable of engineering electromagnetic waves in unprecedented ways. What happens when combining these three cutting-edge technologies? This question has sparked a surge of interest in designing physical neural networks using stacked intelligent metasurface (SIM) technology, with the aim of implementing various computational tasks by directly processing electromagnetic waves. SIMs open up an exciting avenue toward high-speed, massively parallel, and low-power signal processing in the electromagnetic domain. This article provides a comprehensive overview of SIM technology, commencing with its evolutionary development. We subsequently examine its theoretical foundations and existing SIM prototypes in depth. Furthermore, the optimization/training strategies conceived to configure SIMs for achieving the desired functionalities are discussed from two different perspectives. Additionally, we explore the diverse applications of SIM technology across the communication, sensing, and computing domains, presenting experimental evidence that highlights its distinctive advantages in supporting multiple functions within a single device. Finally, we identify critical technical challenges that must be addressed to deploy SIMs in next-generation wireless networks and shed light on promising research directions to unlock their full potential.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16030v1</guid></item><item><title>[cs updates on arXiv.org] Sawtooth Wavefront Reordering: Enhanced CuTile FlashAttention on NVIDIA GB10</title><link>https://arxiv.org/abs/2601.16032</link><description>arXiv:2601.16032v1 Announce Type: new 
Abstract: High-performance attention kernels are essential for Large Language Models. This paper presents analysis of CuTile-based Flash Attention memory behavior and a technique to improve its cache performance. In particular, our analysis on the NVIDIA GB10 (Grace Blackwell) identifies the main cause of L2 cache miss. Leveraging this insight, we introduce a new programming technique called Sawtooth Wavefront Reordering that reduces L2 misses. We validate it in both CUDA and CuTile, observing 50\% or greater reduction in L2 misses and up to 60\% increase in throughput on GB10.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16032v1</guid></item><item><title>[cs updates on arXiv.org] Universal Refusal Circuits Across LLMs: Cross-Model Transfer via Trajectory Replay and Concept-Basis Reconstruction</title><link>https://arxiv.org/abs/2601.16034</link><description>arXiv:2601.16034v1 Announce Type: new 
Abstract: Refusal behavior in aligned LLMs is often viewed as model-specific, yet we hypothesize it stems from a universal, low-dimensional semantic circuit shared across models. To test this, we introduce Trajectory Replay via Concept-Basis Reconstruction, a framework that transfers refusal interventions from donor to target models, spanning diverse architectures (e.g., Dense to MoE) and training regimes, without using target-side refusal supervision. By aligning layers via concept fingerprints and reconstructing refusal directions using a shared ``recipe'' of concept atoms, we map the donor's ablation trajectory into the target's semantic space. To preserve capabilities, we introduce a weight-SVD stability guard that projects interventions away from high-variance weight subspaces to prevent collateral damage. Our evaluation across 8 model pairs (including GPT-OSS-20B and GLM-4) confirms that these transferred recipes consistently attenuate refusal while maintaining performance, providing strong evidence for the semantic universality of safety alignment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16034v1</guid></item><item><title>[cs updates on arXiv.org] Collision-Free Humanoid Traversal in Cluttered Indoor Scenes</title><link>https://arxiv.org/abs/2601.16035</link><description>arXiv:2601.16035v1 Announce Type: new 
Abstract: We study the problem of collision-free humanoid traversal in cluttered indoor scenes, such as hurdling over objects scattered on the floor, crouching under low-hanging obstacles, or squeezing through narrow passages. To achieve this goal, the humanoid needs to map its perception of surrounding obstacles with diverse spatial layouts and geometries to the corresponding traversal skills. However, the lack of an effective representation that captures humanoid-obstacle relationships during collision avoidance makes directly learning such mappings difficult. We therefore propose Humanoid Potential Field (HumanoidPF), which encodes these relationships as collision-free motion directions, significantly facilitating RL-based traversal skill learning. We also find that HumanoidPF exhibits a surprisingly negligible sim-to-real gap as a perceptual representation. To further enable generalizable traversal skills through diverse and challenging cluttered indoor scenes, we further propose a hybrid scene generation method, incorporating crops of realistic 3D indoor scenes and procedurally synthesized obstacles. We successfully transfer our policy to the real world and develop a teleoperation system where users could command the humanoid to traverse in cluttered indoor scenes with just a single click. Extensive experiments are conducted in both simulation and the real world to validate the effectiveness of our method. Demos and code can be found in our website: https://axian12138.github.io/CAT/.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16035v1</guid></item><item><title>[cs updates on arXiv.org] Tri-Hybrid Beamforming Design for integrated Sensing and Communications</title><link>https://arxiv.org/abs/2601.16036</link><description>arXiv:2601.16036v1 Announce Type: new 
Abstract: Tri-hybrid beamforming architectures have been proposed to enable energy-efficient communications systems in extra-largescale antenna arrays using low-cost programmable metasurface antennas. We study the tri-hybrid beamforming design for integrated sensing and communications (ISAC) to improve both communications and sensing performances. Specifically, we formulate a multi-objective optimization problem that balances communications signal-to-noise ratio (SNR) and the sensing power at a target direction, subject to constraints on the total power consumption and physical limitations inherent to the trihybrid beamforming architecture. We develop an efficient iterative algorithm in which the variables are updated in a closed form at each iteration, leading to a low-complexity and fast-execution design. Numerical results show that the tri-hybrid architecture improves spatial gain and energy efficiency, though with reduced beam alignment capability compared to conventional hybrid beamforming architectures.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16036v1</guid></item><item><title>[cs updates on arXiv.org] Grounding Large Language Models in Reaction Knowledge Graphs for Synthesis Retrieval</title><link>https://arxiv.org/abs/2601.16038</link><description>arXiv:2601.16038v1 Announce Type: new 
Abstract: Large Language Models (LLMs) can aid synthesis planning in chemistry, but standard prompting methods often yield hallucinated or outdated suggestions. We study LLM interactions with a reaction knowledge graph by casting reaction path retrieval as a Text2Cypher (natural language to graph query) generation problem, and define single- and multi-step retrieval tasks. We compare zero-shot prompting to one-shot variants using static, random, and embedding-based exemplar selection, and assess a checklist-driven validator/corrector loop. To evaluate our framework, we consider query validity and retrieval accuracy. We find that one-shot prompting with aligned exemplars consistently performs best. Our checklist-style self-correction loop mainly improves executability in zero-shot settings and offers limited additional retrieval gains once a good exemplar is present. We provide a reproducible Text2Cypher evaluation setup to facilitate further work on KG-grounded LLMs for synthesis planning. Code is available at https://github.com/Intelligent-molecular-systems/KG-LLM-Synthesis-Retrieval.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16038v1</guid></item><item><title>[cs updates on arXiv.org] Characterizations of monadically dependent tree-ordered weakly sparse structures</title><link>https://arxiv.org/abs/2601.16039</link><description>arXiv:2601.16039v1 Announce Type: new 
Abstract: A class of structures is monadically dependent if one cannot interpret all graphs in colored expansions from the class using a fixed first-order formula. A tree-ordered $\sigma$-structure is the expansion of a $\sigma$-structure with a tree-order. A tree-ordered $\sigma$-structure is weakly sparse if the Gaifman graph of its $\sigma$-reduct excludes some biclique (of a given fixed size) as a subgraph. Tree-ordered weakly sparse graphs are commonly used as tree-models (for example for classes with bounded shrubdepth, structurally bounded expansion, bounded cliquewidth, or bounded twin-width), motivating their study on their own. In this paper, we consider several constructions on tree-ordered structures, such as tree-ordered variants of the Gaifman graph and of the incidence graph, induced and non-induced tree-ordered minors, and generalized fundamental graphs.
  We provide characterizations of monadically dependent classes of tree-ordered weakly sparse $\sigma$-structures based on each of these constructions, some of them establishing unexpected bridges with sparsity theory. As an application, we prove that a class of tree-ordered weakly sparse structures is monadically dependent if and only if its sparsification is nowhere-dense. Moreover, the sparsification transduction translates boundedness of clique-width and linear clique-width into boundedness of tree-width and path-width. We also prove that first-order model checking is not fixed parameter tractable on independent hereditary classes of tree-ordered weakly sparse graphs (assuming $AW[*]\neq FPT$) and give what we believe is the first model-theoretical characterization of classes of graphs excluding a minor, thus opening a new perspective of structural graph theory.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16039v1</guid></item><item><title>[cs updates on arXiv.org] Can Platform Design Encourage Curiosity? Evidence from an Independent Social Media Experiment</title><link>https://arxiv.org/abs/2601.16040</link><description>arXiv:2601.16040v1 Announce Type: new 
Abstract: Social media platforms are often criticized for fostering antisocial behavior rather than prosocial behavior. Yet, testing interventions to encourage prosocial dispositions, such as open-mindedness, has been hindered by researchers' limited ability to manipulate platform features and isolate causal effects in commercial environments. We address this challenge through a randomized controlled trial with 2,282 U.S. adults conducted on a new research platform we developed that uses AI bots to replicate live social media dynamics while enabling controlled experimentation. Participants engaged in 15-minute discussions about energy and climate topics, with treatment groups exposed to curiosity priming either through modified on-platform social norms, interface affordances, or both. Results demonstrate that curiosity priming significantly increased question-asking behavior and textual measures of curiosity in user posts, while also reducing toxicity. Although interventions decreased generic engagement behaviors like liking and commenting, they had no significant negative impact on reported app enjoyment or time spent writing posts and replies. Leveraging experimental control over platform features, our findings suggest that platform designs prioritizing curiosity can promote prosocial behaviors among users without compromising user experience.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16040v1</guid></item><item><title>[cs updates on arXiv.org] AgriPINN: A Process-Informed Neural Network for Interpretable and Scalable Crop Biomass Prediction Under Water Stress</title><link>https://arxiv.org/abs/2601.16045</link><description>arXiv:2601.16045v1 Announce Type: new 
Abstract: Accurate prediction of crop above-ground biomass (AGB) under water stress is critical for monitoring crop productivity, guiding irrigation, and supporting climate-resilient agriculture. Data-driven models scale well but often lack interpretability and degrade under distribution shift, whereas process-based crop models (e.g. DSSAT, APSIM, LINTUL5) require extensive calibration and are difficult to deploy over large spatial domains. To address these limitations, we propose AgriPINN, a process-informed neural network that integrates a biophysical crop-growth differential equation as a differentiable constraint within a deep learning backbone. This design encourages physiologically consistent biomass dynamics under water-stress conditions while preserving model scalability for spatially distributed AGB prediction. AgriPINN recovers latent physiological variables, including leaf area index (LAI), absorbed photosynthetically active radiation (PAR), radiation use efficiency (RUE), and water-stress factors, without requiring direct supervision. We pretrain AgriPINN on 60 years of historical data across 397 regions in Germany and fine-tune it on three years of field experiments under controlled water treatments. Results show that AgriPINN consistently outperforms state-of-the-art deep-learning baselines (ConvLSTM-ViT, SLTF, CNN-Transformer) and the process-based LINTUL5 model in terms of accuracy (RMSE reductions up to $43\%$) and computational efficiency. By combining the scalability of deep learning with the biophysical rigor of process-based modeling, AgriPINN provides a robust and interpretable framework for spatio-temporal AGB prediction, offering practical value for planning of irrigation infrastructure, yield forecasting, and climate-adaptation planning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16045v1</guid></item><item><title>[cs updates on arXiv.org] DextER: Language-driven Dexterous Grasp Generation with Embodied Reasoning</title><link>https://arxiv.org/abs/2601.16046</link><description>arXiv:2601.16046v1 Announce Type: new 
Abstract: Language-driven dexterous grasp generation requires the models to understand task semantics, 3D geometry, and complex hand-object interactions. While vision-language models have been applied to this problem, existing approaches directly map observations to grasp parameters without intermediate reasoning about physical interactions. We present DextER, Dexterous Grasp Generation with Embodied Reasoning, which introduces contact-based embodied reasoning for multi-finger manipulation. Our key insight is that predicting which hand links contact where on the object surface provides an embodiment-aware intermediate representation bridging task semantics with physical constraints. DextER autoregressively generates embodied contact tokens specifying which finger links contact where on the object surface, followed by grasp tokens encoding the hand configuration. On DexGYS, DextER achieves 67.14% success rate, outperforming state-of-the-art by 3.83%p with 96.4% improvement in intention alignment. We also demonstrate steerable generation through partial contact specification, providing fine-grained control over grasp synthesis.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16046v1</guid></item><item><title>[cs updates on arXiv.org] From Harm to Healing: Understanding Individual Resilience after Cybercrimes</title><link>https://arxiv.org/abs/2601.16050</link><description>arXiv:2601.16050v1 Announce Type: new 
Abstract: How do individuals recover from cybercrimes? Victims experience various types of harm after cybercrimes, including monetary loss, data breaches, negative emotions, and even psychological trauma. The aspects that support their recovery process and contribute to individual cyber resilience remain underinvestigated. To address this gap, we interviewed 18 cybercrime victims from Western Europe using a trauma-informed approach. We identified four common stages following victimization: recognition, coping, processing, and recovery. Participants adopted various strategies to mitigate the impact of cybercrime and used different indicators to describe recovery. While they mostly relied on social support and self-regulation for emotional coping, service providers largely determined whether victims were able to recover their money. Internal factors, external support, and context sensitivity collectively contribute to individuals' cyber resilience. We recommend trauma-informed support for cybercrime victims. Extending our conceptualization of individual cyber resilience, we propose collaborative and context-sensitive strategies to address the harmful impacts of cybercrime.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16050v1</guid></item><item><title>[cs updates on arXiv.org] Designing faster mixed integer linear programming algorithm via learning the optimal path</title><link>https://arxiv.org/abs/2601.16056</link><description>arXiv:2601.16056v1 Announce Type: new 
Abstract: Designing faster algorithms for solving Mixed-Integer Linear Programming (MILP) problems is highly desired across numerous practical domains, as a vast array of complex real-world challenges can be effectively modeled as MILP formulations. Solving these problems typically employs the branch-and-bound algorithm, the core of which can be conceived as searching for a path of nodes (or sub-problems) that contains the optimal solution to the original MILP problem. Traditional approaches to finding this path rely heavily on hand-crafted, intuition-based heuristic strategies, which often suffer from unstable and unpredictable performance across different MILP problem instances. To address this limitation, we introduce DeepBound, a deep learning-based node selection algorithm that automates the learning of such human intuition from data. The core of DeepBound lies in learning to prioritize nodes containing the optimal solution, thereby improving solving efficiency. DeepBound introduces a multi-level feature fusion network to capture the node representations. To tackle the inherent node imbalance in branch-and-bound trees, DeepBound employs a pairwise training paradigm that enhances the model's ability to discriminate between nodes. Extensive experiments on three NP-hard MILP benchmarks demonstrate that DeepBound achieves superior solving efficiency over conventional heuristic rules and existing learning-based approaches, obtaining optimal feasible solutions with significantly reduced computation time. Moreover, DeepBound demonstrates strong generalization capability on large and complex instances. The analysis of its learned features reveals that the method can automatically discover more flexible and robust feature selection, which may effectively improve and potentially replace human-designed heuristic rules.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16056v1</guid></item><item><title>[cs updates on arXiv.org] ProGiDiff: Prompt-Guided Diffusion-Based Medical Image Segmentation</title><link>https://arxiv.org/abs/2601.16060</link><description>arXiv:2601.16060v1 Announce Type: new 
Abstract: Widely adopted medical image segmentation methods, although efficient, are primarily deterministic and remain poorly amenable to natural language prompts. Thus, they lack the capability to estimate multiple proposals, human interaction, and cross-modality adaptation. Recently, text-to-image diffusion models have shown potential to bridge the gap. However, training them from scratch requires a large dataset-a limitation for medical image segmentation. Furthermore, they are often limited to binary segmentation and cannot be conditioned on a natural language prompt. To this end, we propose a novel framework called ProGiDiff that leverages existing image generation models for medical image segmentation purposes. Specifically, we propose a ControlNet-style conditioning mechanism with a custom encoder, suitable for image conditioning, to steer a pre-trained diffusion model to output segmentation masks. It naturally extends to a multi-class setting simply by prompting the target organ. Our experiment on organ segmentation from CT images demonstrates strong performance compared to previous methods and could greatly benefit from an expert-in-the-loop setting to leverage multiple proposals. Importantly, we demonstrate that the learned conditioning mechanism can be easily transferred through low-rank, few-shot adaptation to segment MR images.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16060v1</guid></item><item><title>[cs updates on arXiv.org] Dynamic Tactile Sensing System and Soft Actor Critic Reinforcement Learning for Inclusion Characterization</title><link>https://arxiv.org/abs/2601.16061</link><description>arXiv:2601.16061v1 Announce Type: new 
Abstract: This paper presents the Dynamic Tactile Sensing System that utilizes robotic tactile sensing in conjunction with reinforcement learning to locate and characterize embedded inclusions. A dual arm robot is integrated with an optical Tactile Imaging Sensor that utilizes the Soft Actor Critic Algorithm to acquire tactile data based on a pixel intensity reward. A Dynamic Interrogation procedure for tactile exploration is developed that enables the robot to first localize inclusion and refine their positions for precise imaging. Experimental validation conducted on Polydimethylsiloxane phantoms demonstrates that the robot using the Tactile Soft Actor Critic Model was able to achieve size estimation errors of 2.61% and 5.29% for soft and hard inclusions compared to 7.84% and 6.87% for expert human operators. Results also show that Dynamic Tactile Sensing System was able to locate embedded inclusions and autonomously determine their mechanical properties, useful in applications such as breast tumor characterization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16061v1</guid></item><item><title>[cs updates on arXiv.org] Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Theoretical Analysis</title><link>https://arxiv.org/abs/2601.16062</link><description>arXiv:2601.16062v1 Announce Type: new 
Abstract: One of core advantages of the SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. Current research on Lie group based extended Kalman filters has demonstrated that error propagation autonomy holds in low-precision applications, such as in micro electromechanical system (MEMS) based integrated navigation without considering earth rotation and inertial device biases. However, in high-precision navigation state estimation, maintaining autonomy is extremely difficult when considering with earth rotation and inertial device biases. This paper presents the theoretical analysis on the autonomy of SE2(3) group based high-precision navigation models under inertial, earth and world frame respectively. Through theoretical analysis, we find that the limitation of the traditional, trivial SE2(3) group navigation modeling method is that the presence of Coriolis force terms introduced by velocity in non-inertial frame. Therefore, a construction method for SE2(3) group navigation models is proposed, which brings the navigation models closer to full autonomy.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16062v1</guid></item><item><title>[cs updates on arXiv.org] DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models</title><link>https://arxiv.org/abs/2601.16065</link><description>arXiv:2601.16065v1 Announce Type: new 
Abstract: Vision-Language Action (VLA) models have shown remarkable progress in robotic manipulation by leveraging the powerful perception abilities of Vision-Language Models (VLMs) to understand environments and directly output actions. However, by default, VLA models may overly attend to image tokens in the task-irrelevant region, which we describe as 'distracting tokens'. This behavior can disturb the model from the generation of the desired action tokens in each step, affecting the success rate of tasks. In this paper, we introduce a simple yet effective plug-and-play Distracting Token Pruning (DTP) framework, which dynamically detects and prunes these distracting image tokens. By correcting the model's visual attention patterns, we aim to improve the task success rate, as well as exploring the performance upper boundaries of the model without altering its original architecture or adding additional inputs. Experiments on the SIMPLER Benchmark (Li et al., 2024) show that our method consistently achieving relative improvements in task success rates across different types of novel VLA models, demonstrating generalizability to transformer-based VLAs. Further analysis reveals a negative correlation between the task success rate and the amount of attentions in the task-irrelevant region for all models tested, highlighting a common phenomenon of VLA models that could guide future research. We also publish our code at: https://anonymous.4open.science/r/CBD3.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16065v1</guid></item><item><title>[cs updates on arXiv.org] CLASP: An online learning algorithm for Convex Losses And Squared Penalties</title><link>https://arxiv.org/abs/2601.16072</link><description>arXiv:2601.16072v1 Announce Type: new 
Abstract: We study Constrained Online Convex Optimization (COCO), where a learner chooses actions iteratively, observes both unanticipated convex loss and convex constraint, and accumulates loss while incurring penalties for constraint violations. We introduce CLASP (Convex Losses And Squared Penalties), an algorithm that minimizes cumulative loss together with squared constraint violations. Our analysis departs from prior work by fully leveraging the firm non-expansiveness of convex projectors, a proof strategy not previously applied in this setting. For convex losses, CLASP achieves regret $O\left(T^{\max\{\beta,1-\beta\}}\right)$ and cumulative squared penalty $O\left(T^{1-\beta}\right)$ for any $\beta \in (0,1)$. Most importantly, for strongly convex problems, CLASP provides the first logarithmic guarantees on both regret and cumulative squared penalty. In the strongly convex case, the regret is upper bounded by $O( \log T )$ and the cumulative squared penalty is also upper bounded by $O( \log T )$.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16072v1</guid></item><item><title>[cs updates on arXiv.org] DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models</title><link>https://arxiv.org/abs/2601.16073</link><description>arXiv:2601.16073v1 Announce Type: new 
Abstract: Foundation Models (FMs) have demonstrated strong generalization across diverse vision tasks. However, their deployment in federated settings is hindered by high computational demands, substantial communication overhead, and significant inference costs. We propose DSFedMed, a dual-scale federated framework that enables mutual knowledge distillation between a centralized foundation model and lightweight client models for medical image segmentation. To support knowledge distillation, a set of high-quality medical images is generated to replace real public datasets, and a learnability-guided sample selection strategy is proposed to enhance efficiency and effectiveness in dual-scale distillation. This mutual distillation enables the foundation model to transfer general knowledge to lightweight clients, while also incorporating client-specific insights to refine the foundation model. Evaluations on five medical imaging segmentation datasets show that DSFedMed achieves an average 2 percent improvement in Dice score while reducing communication costs and inference time by nearly 90 percent compared to existing federated foundation model baselines. These results demonstrate significant efficiency gains and scalability for resource-limited federated deployments.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16073v1</guid></item><item><title>[cs updates on arXiv.org] Explainable AI to Improve Machine Learning Reliability for Industrial Cyber-Physical Systems</title><link>https://arxiv.org/abs/2601.16074</link><description>arXiv:2601.16074v1 Announce Type: new 
Abstract: Industrial Cyber-Physical Systems (CPS) are sensitive infrastructure from both safety and economics perspectives, making their reliability critically important. Machine Learning (ML), specifically deep learning, is increasingly integrated in industrial CPS, but the inherent complexity of ML models results in non-transparent operation. Rigorous evaluation is needed to prevent models from exhibiting unexpected behaviour on future, unseen data. Explainable AI (XAI) can be used to uncover model reasoning, allowing a more extensive analysis of behaviour. We apply XAI to to improve predictive performance of ML models intended for industrial CPS. We analyse the effects of components from time-series data decomposition on model predictions using SHAP values. Through this method, we observe evidence on the lack of sufficient contextual information during model training. By increasing the window size of data instances, informed by the XAI findings, we are able to improve model performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16074v1</guid></item><item><title>[cs updates on arXiv.org] Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Application</title><link>https://arxiv.org/abs/2601.16078</link><description>arXiv:2601.16078v1 Announce Type: new 
Abstract: One of the core advantages of SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. In the previous paper, the theoretical analysis of autonomy property of navigation model in inertial, earth and world frames was given. A construction method for SE2(3) group navigation model is proposed to improve the non-inertial navigation model toward full autonomy. This paper serves as a counterpart to previous paper and conducts the real-world strapdown inertial navigation system (SINS)/odometer(ODO) experiments as well as Monte-Carlo simulations to demonstrate the performance of improved SE2(3) group based high-precision navigation models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16078v1</guid></item><item><title>[cs updates on arXiv.org] Masked Modeling for Human Motion Recovery Under Occlusions</title><link>https://arxiv.org/abs/2601.16079</link><description>arXiv:2601.16079v1 Announce Type: new 
Abstract: Human motion reconstruction from monocular videos is a fundamental challenge in computer vision, with broad applications in AR/VR, robotics, and digital content creation, but remains challenging under frequent occlusions in real-world settings.Existing regression-based methods are efficient but fragile to missing observations, while optimization- and diffusion-based approaches improve robustness at the cost of slow inference speed and heavy preprocessing steps. To address these limitations, we leverage recent advances in generative masked modeling and present MoRo: Masked Modeling for human motion Recovery under Occlusions. MoRo is an occlusion-robust, end-to-end generative framework that formulates motion reconstruction as a video-conditioned task, and efficiently recover human motion in a consistent global coordinate system from RGB videos. By masked modeling, MoRo naturally handles occlusions while enabling efficient, end-to-end inference. To overcome the scarcity of paired video-motion data, we design a cross-modality learning scheme that learns multi-modal priors from a set of heterogeneous datasets: (i) a trajectory-aware motion prior trained on MoCap datasets, (ii) an image-conditioned pose prior trained on image-pose datasets, capturing diverse per-frame poses, and (iii) a video-conditioned masked transformer that fuses motion and pose priors, finetuned on video-motion datasets to integrate visual cues with motion dynamics for robust inference. Extensive experiments on EgoBody and RICH demonstrate that MoRo substantially outperforms state-of-the-art methods in accuracy and motion realism under occlusions, while performing on-par in non-occluded scenarios. MoRo achieves real-time inference at 70 FPS on a single H200 GPU.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16079v1</guid></item><item><title>[cs updates on arXiv.org] Towards a Goal-Centric Assessment of Requirements Engineering Methods for Privacy by Design</title><link>https://arxiv.org/abs/2601.16080</link><description>arXiv:2601.16080v1 Announce Type: new 
Abstract: Implementing privacy by design (PbD) according to the General Data Protection Regulation (GDPR) is met with a growing number of requirements engineering (RE) approaches. However, the question of which RE method for PbD fits best the goals of organisations remains a challenge. We report our endeavor to close this gap by synthesizing a goal-centric approach for PbD methods assessment. We used literature review, interviews, and validation with practitioners to achieve the goal of our study. As practitioners do not approach PbD systematically, we suggest that RE methods for PbD should be assessed against organisational goals, rather than process characteristics only. We hope that, when further developed, the goal-centric approach could support the development, selection, and tailoring of RE practices for PbD.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16080v1</guid></item><item><title>[cs updates on arXiv.org] Probably Approximately Correct Maximum A Posteriori Inference</title><link>https://arxiv.org/abs/2601.16083</link><description>arXiv:2601.16083v1 Announce Type: new 
Abstract: Computing the conditional mode of a distribution, better known as the $\mathit{maximum\ a\ posteriori}$ (MAP) assignment, is a fundamental task in probabilistic inference. However, MAP estimation is generally intractable, and remains hard even under many common structural constraints and approximation schemes. We introduce $\mathit{probably\ approximately\ correct}$ (PAC) algorithms for MAP inference that provide provably optimal solutions under variable and fixed computational budgets. We characterize tractability conditions for PAC-MAP using information theoretic measures that can be estimated from finite samples. Our PAC-MAP solvers are efficiently implemented using probabilistic circuits with appropriate architectures. The randomization strategies we develop can be used either as standalone MAP inference techniques or to improve on popular heuristics, fortifying their solutions with rigorous guarantees. Experiments confirm the benefits of our method in a range of benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16083v1</guid></item><item><title>[cs updates on arXiv.org] Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics</title><link>https://arxiv.org/abs/2601.16087</link><description>arXiv:2601.16087v1 Announce Type: new 
Abstract: Large language model (LLM) agents often exhibit abrupt shifts in tone and persona during extended interaction, reflecting the absence of explicit temporal structure governing agent-level state. While prior work emphasizes turn-local sentiment or static emotion classification, the role of explicit affective dynamics in shaping long-horizon agent behavior remains underexplored. This work investigates whether imposing dynamical structure on an external affective state can induce temporal coherence and controlled recovery in multi-turn dialogue. We introduce an agent-level affective subsystem that maintains a continuous Valence-Arousal-Dominance (VAD) state external to the language model and governed by first- and second-order update rules. Instantaneous affective signals are extracted using a fixed, memoryless estimator and integrated over time via exponential smoothing or momentum-based dynamics. The resulting affective state is injected back into generation without modifying model parameters. Using a fixed 25-turn dialogue protocol, we compare stateless, first-order, and second-order affective dynamics. Stateless agents fail to exhibit coherent trajectories or recovery, while state persistence enables delayed responses and reliable recovery. Second-order dynamics introduce affective inertia and hysteresis that increase with momentum, revealing a trade-off between stability and responsiveness.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16087v1</guid></item><item><title>[cs updates on arXiv.org] Delayed Assignments in Online Non-Centroid Clustering with Stochastic Arrivals</title><link>https://arxiv.org/abs/2601.16091</link><description>arXiv:2601.16091v1 Announce Type: new 
Abstract: Clustering is a fundamental problem, aiming to partition a set of elements, like agents or data points, into clusters such that elements in the same cluster are closer to each other than to those in other clusters. In this paper, we present a new framework for studying online non-centroid clustering with delays, where elements, that arrive one at a time as points in a finite metric space, should be assigned to clusters, but assignments need not be immediate. Specifically, upon arrival, each point's location is revealed, and an online algorithm has to irrevocably assign it to an existing cluster or create a new one containing, at this moment, only this point. However, we allow decisions to be postponed at a delay cost, instead of following the more common assumption of immediate decisions upon arrival. This poses a critical challenge: the goal is to minimize both the total distance costs between points in each cluster and the overall delay costs incurred by postponing assignments. In the classic worst-case arrival model, where points arrive in an arbitrary order, no algorithm has a competitive ratio better than sublogarithmic in the number of points. To overcome this strong impossibility, we focus on a stochastic arrival model, where points' locations are drawn independently across time from an unknown and fixed probability distribution over the finite metric space. We offer hope for beyond worst-case adversaries: we devise an algorithm that is constant competitive in the sense that, as the number of points grows, the ratio between the expected overall costs of the output clustering and an optimal offline clustering is bounded by a constant.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16091v1</guid></item><item><title>[cs updates on arXiv.org] SAMTok: Representing Any Mask with Two Words</title><link>https://arxiv.org/abs/2601.16093</link><description>arXiv:2601.16093v1 Announce Type: new 
Abstract: Pixel-wise capabilities are essential for building interactive intelligent systems. However, pixel-wise multi-modal LLMs (MLLMs) remain difficult to scale due to complex region-level encoders, specialized segmentation decoders, and incompatible training objectives. To address these challenges, we present SAMTok, a discrete mask tokenizer that converts any region mask into two special tokens and reconstructs the mask using these tokens with high fidelity. By treating masks as new language tokens, SAMTok enables base MLLMs (such as the QwenVL series) to learn pixel-wise capabilities through standard next-token prediction and simple reinforcement learning, without architectural modifications and specialized loss design. SAMTok builds on SAM2 and is trained on 209M diverse masks using a mask encoder and residual vector quantizer to produce discrete, compact, and information-rich tokens. With 5M SAMTok-formatted mask understanding and generation data samples, QwenVL-SAMTok attains state-of-the-art or comparable results on region captioning, region VQA, grounded conversation, referring segmentation, scene graph parsing, and multi-round interactive segmentation. We further introduce a textual answer-matching reward that enables efficient reinforcement learning for mask generation, delivering substantial improvements on GRES and GCG benchmarks. Our results demonstrate a scalable and straightforward paradigm for equipping MLLMs with strong pixel-wise capabilities. Our code and models are available.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16093v1</guid></item><item><title>[cs updates on arXiv.org] Neural Particle Automata: Learning Self-Organizing Particle Dynamics</title><link>https://arxiv.org/abs/2601.16096</link><description>arXiv:2601.16096v1 Announce Type: new 
Abstract: We introduce Neural Particle Automata (NPA), a Lagrangian generalization of Neural Cellular Automata (NCA) from static lattices to dynamic particle systems. Unlike classical Eulerian NCA where cells are pinned to pixels or voxels, NPA model each cell as a particle with a continuous position and internal state, both updated by a shared, learnable neural rule. This particle-based formulation yields clear individuation of cells, allows heterogeneous dynamics, and concentrates computation only on regions where activity is present. At the same time, particle systems pose challenges: neighborhoods are dynamic, and a naive implementation of local interactions scale quadratically with the number of particles. We address these challenges by replacing grid-based neighborhood perception with differentiable Smoothed Particle Hydrodynamics (SPH) operators backed by memory-efficient, CUDA-accelerated kernels, enabling scalable end-to-end training. Across tasks including morphogenesis, point-cloud classification, and particle-based texture synthesis, we show that NPA retain key NCA behaviors such as robustness and self-regeneration, while enabling new behaviors specific to particle systems. Together, these results position NPA as a compact neural model for learning self-organizing particle dynamics.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16096v1</guid></item><item><title>[cs updates on arXiv.org] Adapter Fusion for Multilingual Text2Cypher with Linear and Learned Gating</title><link>https://arxiv.org/abs/2601.16097</link><description>arXiv:2601.16097v1 Announce Type: new 
Abstract: Large Language Models enable users to access database using natural language interfaces using tools like Text2SQL, Text2SPARQL, and Text2Cypher, which translate user questions into structured database queries. While these systems improve database accessibility, most research focuses on English with limited multilingual support. This work investigates a scalable multilingual Text2Cypher, aiming to support new languages without re-running full fine-tuning, avoiding manual hyper-parameter tuning, and maintaining performance close to joint multilingual fine-tuning. We train language-specific LoRA adapters for English, Spanish, and Turkish and combined them via uniform linear merging or learned fusion MLP with dynamic gating. Experimental results show that the fusion MLP recovers around 75\% of the accuracy gains from joint multilingual fine-tuning while requiring only a smaller subset of the data, outperforming linear merging across all three languages. This approach enables incremental language expansion to new languages by requiring only one LoRA adapter and a lightweight MLP retraining. Learned adapter fusion offers a practical alternative to expensive joint fine-tuning, balancing performance, data efficiency, and scalability for multilingual Text2Cypher task.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16097v1</guid></item><item><title>[cs updates on arXiv.org] Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification</title><link>https://arxiv.org/abs/2601.16098</link><description>arXiv:2601.16098v1 Announce Type: new 
Abstract: Although Mamba models greatly improve Hyperspectral Image (HSI) classification, they have critical challenges in terms defining efficient and adaptive token sequences for improve performance. This paper therefore presents CSSMamba (Clustering-guided Spatial-Spectral Mamba) framework to better address the challenges, with the following contributions. First, to achieve efficient and adaptive token sequences for improved Mamba performance, we integrate the clustering mechanism into a spatial Mamba architecture, leading to a cluster-guided spatial Mamba module (CSpaMamba) that reduces the Mamba sequence length and improves Mamba feature learning capability. Second, to improve the learning of both spatial and spectral information, we integrate the CSpaMamba module with a spectral mamba module (SpeMamba), leading to a complete clustering-guided spatial-spectral Mamba framework. Third, to further improve feature learning capability, we introduce an Attention-Driven Token Selection mechanism to optimize Mamba token sequencing. Last, to seamlessly integrate clustering into the Mamba model in a coherent manner, we design a Learnable Clustering Module that learns the cluster memberships in an adaptive manner. Experiments on the Pavia University, Indian Pines, and Liao-Ning 01 datasets demonstrate that CSSMamba achieves higher accuracy and better boundary preservation compared to state-of-the-art CNN, Transformer, and Mamba-based methods.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16098v1</guid></item><item><title>[cs updates on arXiv.org] Benchmarking Deep Learning Models for Raman Spectroscopy Across Open-Source Datasets</title><link>https://arxiv.org/abs/2601.16107</link><description>arXiv:2601.16107v1 Announce Type: new 
Abstract: Deep learning classifiers for Raman spectroscopy are increasingly reported to outperform classical chemometric approaches. However their evaluations are often conducted in isolation or compared against traditional machine learning methods or trivially adapted vision-based architectures that were not originally proposed for Raman spectroscopy. As a result, direct comparisons between existing deep learning models developed specifically for Raman spectral analysis on shared open-source datasets remain scarce. To the best of our knowledge, this study presents one of the first systematic benchmarks comparing three or more published Raman-specific deep learning classifiers across multiple open-source Raman datasets. We evaluate five representative deep learning architectures under a unified training and hyperparameter tuning protocol across three open-source Raman datasets selected to support standard evaluation, fine-tuning, and explicit distribution-shift testing. We report classification accuracies and macro-averaged F1 scores to provide a fair and reproducible comparison of deep learning models for Raman spectra based classification.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16107v1</guid></item><item><title>[cs updates on arXiv.org] Multimodal Climate Disinformation Detection: Integrating Vision-Language Models with External Knowledge Sources</title><link>https://arxiv.org/abs/2601.16108</link><description>arXiv:2601.16108v1 Announce Type: new 
Abstract: Climate disinformation has become a major challenge in today digital world, especially with the rise of misleading images and videos shared widely on social media. These false claims are often convincing and difficult to detect, which can delay actions on climate change. While vision-language models (VLMs) have been used to identify visual disinformation, they rely only on the knowledge available at the time of training. This limits their ability to reason about recent events or updates. The main goal of this paper is to overcome that limitation by combining VLMs with external knowledge. By retrieving up-to-date information such as reverse image results, online fact-checks, and trusted expert content, the system can better assess whether an image and its claim are accurate, misleading, false, or unverifiable. This approach improves the model ability to handle real-world climate disinformation and supports efforts to protect public understanding of science in a rapidly changing information landscape.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16108v1</guid></item><item><title>[cs updates on arXiv.org] Efficiently Learning Robust Torque-based Locomotion Through Reinforcement with Model-Based Supervision</title><link>https://arxiv.org/abs/2601.16109</link><description>arXiv:2601.16109v1 Announce Type: new 
Abstract: We propose a control framework that integrates model-based bipedal locomotion with residual reinforcement learning (RL) to achieve robust and adaptive walking in the presence of real-world uncertainties. Our approach leverages a model-based controller, comprising a Divergent Component of Motion (DCM) trajectory planner and a whole-body controller, as a reliable base policy. To address the uncertainties of inaccurate dynamics modeling and sensor noise, we introduce a residual policy trained through RL with domain randomization. Crucially, we employ a model-based oracle policy, which has privileged access to ground-truth dynamics during training, to supervise the residual policy via a novel supervised loss. This supervision enables the policy to efficiently learn corrective behaviors that compensate for unmodeled effects without extensive reward shaping. Our method demonstrates improved robustness and generalization across a range of randomized conditions, offering a scalable solution for sim-to-real transfer in bipedal locomotion.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16109v1</guid></item><item><title>[cs updates on arXiv.org] synthocr-gen: A synthetic ocr dataset generator for low-resource languages- breaking the data barrier</title><link>https://arxiv.org/abs/2601.16113</link><description>arXiv:2601.16113v1 Announce Type: new 
Abstract: Optical Character Recognition (OCR) for low-resource languages remains a significant challenge due to the scarcity of large-scale annotated training datasets. Languages such as Kashmiri, with approximately 7 million speakers and a complex Perso-Arabic script featuring unique diacritical marks, currently lack support in major OCR systems including Tesseract, TrOCR, and PaddleOCR. Manual dataset creation for such languages is prohibitively expensive, time-consuming, and error-prone, often requiring word by word transcription of printed or handwritten text.
  We present SynthOCR-Gen, an open-source synthetic OCR dataset generator specifically designed for low-resource languages. Our tool addresses the fundamental bottleneck in OCR development by transforming digital Unicode text corpora into ready-to-use training datasets. The system implements a comprehensive pipeline encompassing text segmentation (character, word, n-gram, sentence, and line levels), Unicode normalization with script purity enforcement, multi-font rendering with configurable distribution, and 25+ data augmentation techniques simulating real-world document degradations including rotation, blur, noise, and scanner artifacts.
  We demonstrate the efficacy of our approach by generating a 600,000-sample word-segmented Kashmiri OCR dataset, which we release publicly on HuggingFace. This work provides a practical pathway for bringing low-resource languages into the era of vision-language AI models, and the tool is openly available for researchers and practitioners working with underserved writing systems worldwide.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16113v1</guid></item><item><title>[cs updates on arXiv.org] Distillation-based Layer Dropping (DLD) Effective End-to-end Framework for Dynamic Speech Networks</title><link>https://arxiv.org/abs/2601.16117</link><description>arXiv:2601.16117v1 Announce Type: new 
Abstract: Edge devices operate in constrained and varying resource settings, requiring dynamic architectures that can adapt to limitations of the available resources. To meet such demands, layer dropping ($\mathcal{LD}$) approach is typically used to transform static models into dynamic ones by skipping parts of the network along with reducing overall computational complexity. However, existing $\mathcal{LD}$ methods greatly impact the dynamic model's performance for low and high dropping cases, deteriorating the performance-computation trade-off. To this end, we propose a distillation-based layer dropping (DLD) framework that effectively combines the capabilities of knowledge distillation and $\mathcal{LD}$ in an end-to-end fashion, thereby achieving state-of-the-art performance for dynamic speech networks. Comprehensive experimentation utilizing well-known speech recognition methods, including conformer and WavLM, on three public benchmarks demonstrates the effectiveness of our framework, reducing the word error rate by $9.32\%$ and $2.25\%$ for high and no dropping cases with $33.3\%$ reduction in training time.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16117v1</guid></item><item><title>[cs updates on arXiv.org] A Case for Hypergraphs to Model and Map SNNs on Neuromorphic Hardware</title><link>https://arxiv.org/abs/2601.16118</link><description>arXiv:2601.16118v1 Announce Type: new 
Abstract: Executing Spiking Neural Networks (SNNs) on neuromorphic hardware poses the problem of mapping neurons to cores. SNNs operate by propagating spikes between neurons that form a graph through synapses. Neuromorphic hardware mimics them through a network-on-chip, transmitting spikes, and a mesh of cores, each managing several neurons. Its operational cost is tied to spike movement and active cores. A mapping comprises two tasks: partitioning the SNN's graph to fit inside cores and placement of each partition on the hardware mesh. Both are NP-hard problems, and as SNNs and hardware scale towards billions of neurons, they become increasingly difficult to tackle effectively. In this work, we propose to raise the abstraction of SNNs from graphs to hypergraphs, redesigning mapping techniques accordingly. The resulting model faithfully captures the replication of spikes inside cores by exposing the notion of hyperedge co-membership between neurons. We further show that the overlap and locality of hyperedges strongly correlate with high-quality mappings, making these properties instrumental in devising mapping algorithms. By exploiting them directly, grouping neurons through shared hyperedges, communication traffic and hardware resource usage can be reduced be yond what just contracting individual connections attains. To substantiate this insight, we consider several partitioning and placement algorithms, some newly devised, others adapted from literature, and compare them over progressively larger and bio-plausible SNNs. Our results show that hypergraph based techniques can achieve better mappings than the state-of-the-art at several execution time regimes. Based on these observations, we identify a promising selection of algorithms to achieve effective mappings at any scale.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16118v1</guid></item><item><title>[cs updates on arXiv.org] Canonical structure of the LLG equation for exponential updates in micromagnetism</title><link>https://arxiv.org/abs/2601.16122</link><description>arXiv:2601.16122v1 Announce Type: new 
Abstract: In this contribution we propose an exponential update algorithm for magnetic moments appearing in the framework of micromagnetics and the Landau-Lifshitz-Gilbert (LLG) equation. This algorithm can be interpreted as the geometric integration on spheres, that a priori satisfy the unit length constraint of the normalized magnetization vector. Even though the geometric structures for this are obvious and some works already use an exponential algorithm, to the best of the authors' knowledge, there is no canonical structure of the LLG equation for the exponential update algorithm in micromagnetism. Tensor algebraic reformulations of the LLG equation allow the canonical representation of the evolution equation for the magnetization, which serves as the basis for different integrators. Based on the specific structure of the exponential of skew symmetric matrices an efficient update scheme is derived. The excellent performance of the proposed exponential update algorithm is demonstrated in representative examples.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16122v1</guid></item><item><title>[cs updates on arXiv.org] Rethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing</title><link>https://arxiv.org/abs/2601.16125</link><description>arXiv:2601.16125v1 Announce Type: new 
Abstract: Composed Image Retrieval (CIR) is a pivotal and complex task in multimodal understanding. Current CIR benchmarks typically feature limited query categories and fail to capture the diverse requirements of real-world scenarios. To bridge this evaluation gap, we leverage image editing to achieve precise control over modification types and content, enabling a pipeline for synthesizing queries across a broad spectrum of categories. Using this pipeline, we construct EDIR, a novel fine-grained CIR benchmark. EDIR encompasses 5,000 high-quality queries structured across five main categories and fifteen subcategories. Our comprehensive evaluation of 13 multimodal embedding models reveals a significant capability gap; even state-of-the-art models (e.g., RzenEmbed and GME) struggle to perform consistently across all subcategories, highlighting the rigorous nature of our benchmark. Through comparative analysis, we further uncover inherent limitations in existing benchmarks, such as modality biases and insufficient categorical coverage. Furthermore, an in-domain training experiment demonstrates the feasibility of our benchmark. This experiment clarifies the task challenges by distinguishing between categories that are solvable with targeted data and those that expose intrinsic limitations of current model architectures.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16125v1</guid></item><item><title>[cs updates on arXiv.org] Improving Training Efficiency and Reducing Maintenance Costs via Language Specific Model Merging</title><link>https://arxiv.org/abs/2601.16127</link><description>arXiv:2601.16127v1 Announce Type: new 
Abstract: Fine-tuning a task-specific multilingual large language model (LLM) involves training the model on a multilingual dataset with examples in all the required languages. Updating one or more supported languages with additional data or adding support for a new language involves retraining the model, which can be computationally inefficient and creates a severe maintenance bottleneck. Recent research on merging multilingual multitask models has shown promise in terms of improved quality, but its computational and maintenance efficiency remains unstudied. In this work, we provide the first focused analysis of this merging strategy from an efficiency perspective, evaluating it across three independent tasks. We demonstrate significant efficiency gains while maintaining parity in terms of quality: this merging approach reduces the initial training time by up to 50\%. We also demonstrate that updating an individual language and re-merging as part of model maintenance reduces training costs by more than 60\%, compared to re-training the full multilingual model. We show this on both public and proprietary industry datasets confirming that the approach works well for industrial use cases in addition to academic settings already studied in previous work.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16127v1</guid></item><item><title>[cs updates on arXiv.org] Replicating Human Motivated Reasoning Studies with LLMs</title><link>https://arxiv.org/abs/2601.16130</link><description>arXiv:2601.16130v1 Announce Type: new 
Abstract: Motivated reasoning -- the idea that individuals processing information may be motivated to reach a certain conclusion, whether it be accurate or predetermined -- has been well-explored as a human phenomenon. However, it is unclear whether base LLMs mimic these motivational changes. Replicating 4 prior political motivated reasoning studies, we find that base LLM behavior does not align with expected human behavior. Furthermore, base LLM behavior across models shares some similarities, such as smaller standard deviations and inaccurate argument strength assessments. We emphasize the importance of these findings for researchers using LLMs to automate tasks such as survey data collection and argument assessment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16130v1</guid></item><item><title>[cs updates on arXiv.org] LLM Prompt Evaluation for Educational Applications</title><link>https://arxiv.org/abs/2601.16134</link><description>arXiv:2601.16134v1 Announce Type: new 
Abstract: As large language models (LLMs) become increasingly common in educational applications, there is a growing need for evidence-based methods to design and evaluate LLM prompts that produce personalized and pedagogically aligned out-puts. This study presents a generalizable, systematic approach for evaluating prompts, demonstrated through an analysis of LLM-generated follow-up questions in a structured dialogue activity. Six prompt templates were designed and tested. The templates incorporated established prompt engineering patterns, with each prompt emphasizing distinct pedagogical strategies. The prompt templates were compared through a tournament-style evaluation framework that can be adapted for other educational applications. The tournament employed the Glicko2 rating system with eight judges evaluating question pairs across three dimensions: format, dialogue support, and appropriateness for learners. Data was sourced from 120 authentic user interactions across three distinct educational deployments. Results showed that a single prompt related to strategic reading out-performed other templates with win probabilities ranging from 81% to 100% in pairwise comparisons. This prompt combined persona and context manager pat-terns and was designed to support metacognitive learning strategies such as self-directed learning. The methodology showcases how educational technology re- searchers can systematically evaluate and improve prompt designs, moving beyond ad-hoc prompt engineering toward evidence-based prompt development for educational applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16134v1</guid></item><item><title>[cs updates on arXiv.org] Automatic Classification of Arabic Literature into Historical Eras</title><link>https://arxiv.org/abs/2601.16138</link><description>arXiv:2601.16138v1 Announce Type: new 
Abstract: The Arabic language has undergone notable transformations over time, including the emergence of new vocabulary, the obsolescence of others, and shifts in word usage. This evolution is evident in the distinction between the classical and modern Arabic eras. Although historians and linguists have partitioned Arabic literature into multiple eras, relatively little research has explored the automatic classification of Arabic texts by time period, particularly beyond the domain of poetry. This paper addresses this gap by employing neural networks and deep learning techniques to automatically classify Arabic texts into distinct eras and periods. The proposed models are evaluated using two datasets derived from two publicly available corpora, covering texts from the pre-Islamic to the modern era. The study examines class setups ranging from binary to 15-class classification and considers both predefined historical eras and custom periodizations. Results range from F1-scores of 0.83 and 0.79 on the binary-era classification task using the OpenITI and APCD datasets, respectively, to 0.20 on the 15-era classification task using OpenITI and 0.18 on the 12-era classification task using APCD.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16138v1</guid></item><item><title>[cs updates on arXiv.org] On the Intrinsic Dimensions of Data in Kernel Learning</title><link>https://arxiv.org/abs/2601.16139</link><description>arXiv:2601.16139v1 Announce Type: new 
Abstract: The manifold hypothesis suggests that the generalization performance of machine learning methods improves significantly when the intrinsic dimension of the input distribution's support is low. In the context of KRR, we investigate two alternative notions of intrinsic dimension. The first, denoted $d_\rho$, is the upper Minkowski dimension defined with respect to the canonical metric induced by a kernel function $K$ on a domain $\Omega$. The second, denoted $d_K$, is the effective dimension, derived from the decay rate of Kolmogorov $n$-widths associated with $K$ on $\Omega$. Given a probability measure $\mu$ on $\Omega$, we analyze the relationship between these $n$-widths and eigenvalues of the integral operator $\phi \to \int_\Omega K(\cdot,x)\phi(x)d\mu(x)$. We show that, for a fixed domain $\Omega$, the Kolmogorov $n$-widths characterize the worst-case eigenvalue decay across all probability measures $\mu$ supported on $\Omega$. These eigenvalues are central to understanding the generalization behavior of constrained KRR, enabling us to derive an excess error bound of order $O(n^{-\frac{2+d_K}{2+2d_K} + \epsilon})$ for any $\epsilon &gt; 0$, when the training set size $n$ is large. We also propose an algorithm that estimates upper bounds on the $n$-widths using only a finite sample from $\mu$. For distributions close to uniform, we prove that $\epsilon$-accurate upper bounds on all $n$-widths can be computed with high probability using at most $O\left(\epsilon^{-d_\rho}\log\frac{1}{\epsilon}\right)$ samples, with fewer required for small $n$. Finally, we compute the effective dimension $d_K$ for various fractal sets and present additional numerical experiments. Our results show that, for kernels such as the Laplace kernel, the effective dimension $d_K$ can be significantly smaller than the Minkowski dimension $d_\rho$, even though $d_K = d_\rho$ provably holds on regular domains.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16139v1</guid></item><item><title>[cs updates on arXiv.org] Learning to Watermark in the Latent Space of Generative Models</title><link>https://arxiv.org/abs/2601.16140</link><description>arXiv:2601.16140v1 Announce Type: new 
Abstract: Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models. We demonstrate that these latent watermarkers can be effectively distilled either into the generative model itself or into the latent decoder, enabling in-model watermarking. The resulting latent watermarks achieve competitive robustness while offering similar imperceptibility and up to 20x speedup compared to pixel-space baselines. Our experiments further reveal that distilling latent watermarkers outperforms distilling pixel-space ones, providing a solution that is both more efficient and more robust.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16140v1</guid></item><item><title>[cs updates on arXiv.org] Computing Fixpoints of Learned Functions: Chaotic Iteration and Simple Stochastic Games</title><link>https://arxiv.org/abs/2601.16142</link><description>arXiv:2601.16142v1 Announce Type: new 
Abstract: The problem of determining the (least) fixpoint of (higher-dimensional) functions over the non-negative reals frequently occurs when dealing with systems endowed with a quantitative semantics. We focus on the situation in which the functions of interest are not known precisely but can only be approximated. As a first contribution we generalize an iteration scheme called dampened Mann iteration, recently introduced in the literature. The improved scheme relaxes previous constraints on parameter sequences, allowing learning rates to converge to zero or not converge at all. While seemingly minor, this flexibility is essential to enable the implementation of chaotic iterations, where only a subset of components is updated in each step, allowing to tackle higher-dimensional problems. Additionally, by allowing learning rates to converge to zero, we can relax conditions on the convergence speed of function approximations, making the method more adaptable to various scenarios. We also show that dampened Mann iteration applies immediately to compute the expected payoff in various probabilistic models, including simple stochastic games, not covered by previous work.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16142v1</guid></item><item><title>[cs updates on arXiv.org] Low-altitude Multi-UAV-assisted Data Collection and Semantic Forwarding for Post-Disaster Relief</title><link>https://arxiv.org/abs/2601.16146</link><description>arXiv:2601.16146v1 Announce Type: new 
Abstract: The low-altitude economy (LAE) is an emerging economic paradigm which fosters integrated development across multiple fields. As a pivotal component of the LAE, low-altitude uncrewed aerial vehicles (UAVs) can restore communication by serving as aerial relays between the post-disaster areas and remote base stations (BSs). However, conventional approaches face challenges from vulnerable long-distance links between the UAVs and remote BSs, and data bottlenecks arising from massive data volumes and limited onboard UAV resources. In this work, we investigate a low-altitude multi-UAV-assisted data collection and semantic forwarding network, in which multiple UAVs collect data from ground users, form clusters, perform intra-cluster data aggregation with semantic extraction, and then cooperate as virtual antenna array (VAAs) to transmit the extracted semantic information to a remote BS via collaborative beamforming (CB). We formulate a data collection and semantic forwarding multi-objective optimization problem (DCSFMOP) that jointly maximizes both the user and semantic transmission rates while minimizing UAV energy consumption. The formulated DCSFMOP is a mixed-integer nonlinear programming (MINLP) problem that is inherently NP-hard and characterized by dynamically varying decision variable dimensionality. To address these challenges, we propose a large language model-enabled alternating optimization approach (LLM-AOA), which effectively handles the complex search space and variable dimensionality by optimizing different subsets of decision variables through tailored optimization strategies. Simulation results demonstrate that LLM-AOA outperforms AOA by approximately 26.8\% and 22.9\% in transmission rate and semantic rate, respectively.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16146v1</guid></item><item><title>[cs updates on arXiv.org] Beat-ssl: Capturing Local ECG Morphology through Heartbeat-level Contrastive Learning with Soft Targets</title><link>https://arxiv.org/abs/2601.16147</link><description>arXiv:2601.16147v1 Announce Type: new 
Abstract: Obtaining labelled ECG data for developing supervised models is challenging. Contrastive learning (CL) has emerged as a promising pretraining approach that enables effective transfer learning with limited labelled data. However, existing CL frameworks either focus solely on global context or fail to exploit ECG-specific characteristics. Furthermore, these methods rely on hard contrastive targets, which may not adequately capture the continuous nature of feature similarity in ECG signals. In this paper, we propose Beat-SSL, a contrastive learning framework that performs dual-context learning through both rhythm-level and heartbeat-level contrasting with soft targets. We evaluated our pretrained model on two downstream tasks: 1) multilabel classification for global rhythm assessment, and 2) ECG segmentation to assess its capacity to learn representations across both contexts. We conducted an ablation study and compared the best configuration with three other methods, including one ECG foundation model. Despite the foundation model's broader pretraining, Beat-SSL reached 93% of its performance in multilabel classification task and surpassed all other methods in the segmentation task by 4%.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16147v1</guid></item><item><title>[cs updates on arXiv.org] ActionMesh: Animated 3D Mesh Generation with Temporal 3D Diffusion</title><link>https://arxiv.org/abs/2601.16148</link><description>arXiv:2601.16148v1 Announce Type: new 
Abstract: Generating animated 3D objects is at the heart of many applications, yet most advanced works are typically difficult to apply in practice because of their limited setup, their long runtime, or their limited quality. We introduce ActionMesh, a generative model that predicts production-ready 3D meshes "in action" in a feed-forward manner. Drawing inspiration from early video models, our key insight is to modify existing 3D diffusion models to include a temporal axis, resulting in a framework we dubbed "temporal 3D diffusion". Specifically, we first adapt the 3D diffusion stage to generate a sequence of synchronized latents representing time-varying and independent 3D shapes. Second, we design a temporal 3D autoencoder that translates a sequence of independent shapes into the corresponding deformations of a pre-defined reference shape, allowing us to build an animation. Combining these two components, ActionMesh generates animated 3D meshes from different inputs like a monocular video, a text description, or even a 3D mesh with a text prompt describing its animation. Besides, compared to previous approaches, our method is fast and produces results that are rig-free and topology consistent, hence enabling rapid iteration and seamless applications like texturing and retargeting. We evaluate our model on standard video-to-4D benchmarks (Consistent4D, Objaverse) and report state-of-the-art performances on both geometric accuracy and temporal consistency, demonstrating that our model can deliver animated 3D meshes with unprecedented speed and quality.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16148v1</guid></item><item><title>[cs updates on arXiv.org] Pay (Cross) Attention to the Melody: Curriculum Masking for Single-Encoder Melodic Harmonization</title><link>https://arxiv.org/abs/2601.16150</link><description>arXiv:2601.16150v1 Announce Type: new 
Abstract: Melodic harmonization, the task of generating harmonic accompaniments for a given melody, remains a central challenge in computational music generation. Recent single encoder transformer approaches have framed harmonization as a masked sequence modeling problem, but existing training curricula inspired by discrete diffusion often result in weak (cross) attention between melody and harmony. This leads to limited exploitation of melodic cues, particularly in out-of-domain contexts. In this work, we introduce a training curriculum, FF (full-to-full), which keeps all harmony tokens masked for several training steps before progressively unmasking entire sequences during training to strengthen melody-harmony interactions. We systematically evaluate this approach against prior curricula across multiple experimental axes, including temporal quantization (quarter vs. sixteenth note), bar-level vs. time-signature conditioning, melody representation (full range vs. pitch class), and inference-time unmasking strategies. Models are trained on the HookTheory dataset and evaluated both in-domain and on a curated collection of jazz standards, using a comprehensive set of metrics that assess chord progression structure, harmony-melody alignment, and rhythmic coherence. Results demonstrate that the proposed FF curriculum consistently outperforms baselines in nearly all metrics, with particularly strong gains in out-of-domain evaluations where harmonic adaptability to novel melodic queues is crucial. We further find that quarter-note quantization, intertwining of bar tokens, and pitch-class melody representations are advantageous in the FF setting. Our findings highlight the importance of training curricula in enabling effective melody conditioning and suggest that full-to-full unmasking offers a robust strategy for single encoder harmonization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16150v1</guid></item><item><title>[cs updates on arXiv.org] Substrate Stability Under Persistent Disagreement: Structural Constraints for Neutral Ontological Substrates</title><link>https://arxiv.org/abs/2601.16152</link><description>arXiv:2601.16152v1 Announce Type: new 
Abstract: Modern data systems increasingly operate under conditions of persistent legal, political, and analytic disagreement. In such settings, interoperability cannot rely on shared interpretation, negotiated semantics, or centralized authority. Instead, representations must function as neutral substrates that preserve stable reference across incompatible extensions. This paper investigates the structural constraints imposed on ontological design by this requirement. Building on a neutrality framework that treats interpretive non-commitment and stability under extension as explicit design constraints, we ask what minimal ontological structure is forced if accountability relationships are to remain referable and comparable under disagreement. Minimality here is not mere parsimony: a reduction is admissible only if it does not reintroduce stability-critical distinctions as hidden roles, flags, or contextual predicates. We establish a conditional lower-bound result: any ontology capable of supporting accountability under persistent disagreement must realize at least six distinct identity-and-persistence regimes. We further show that a construction with exactly six such regimes is sufficient to satisfy the stated requirements without embedding causal or normative commitments in the substrate. The result is not a proposal for a universal ontology, but a constraint on what is possible when neutrality and stable reference are treated as non-negotiable design goals.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16152v1</guid></item><item><title>[cs updates on arXiv.org] HVD: Human Vision-Driven Video Representation Learning for Text-Video Retrieval</title><link>https://arxiv.org/abs/2601.16155</link><description>arXiv:2601.16155v1 Announce Type: new 
Abstract: The success of CLIP has driven substantial progress in text-video retrieval. However, current methods often suffer from "blind" feature interaction, where the model struggles to discern key visual information from background noise due to the sparsity of textual queries. To bridge this gap, we draw inspiration from human cognitive behavior and propose the Human Vision-Driven (HVD) model. Our framework establishes a coarse-to-fine alignment mechanism comprising two key components: the Frame Features Selection Module (FFSM) and the Patch Features Compression Module (PFCM). FFSM mimics the human macro-perception ability by selecting key frames to eliminate temporal redundancy. Subsequently, PFCM simulates micro-perception by aggregating patch features into salient visual entities through an advanced attention mechanism, enabling precise entity-level matching. Extensive experiments on five benchmarks demonstrate that HVD not only captures human-like visual focus but also achieves state-of-the-art performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16155v1</guid></item><item><title>[cs updates on arXiv.org] Domain-Incremental Continual Learning for Robust and Efficient Keyword Spotting in Resource Constrained Systems</title><link>https://arxiv.org/abs/2601.16158</link><description>arXiv:2601.16158v1 Announce Type: new 
Abstract: Keyword Spotting (KWS) systems with small footprint models deployed on edge devices face significant accuracy and robustness challenges due to domain shifts caused by varying noise and recording conditions. To address this, we propose a comprehensive framework for continual learning designed to adapt to new domains while maintaining computational efficiency. The proposed pipeline integrates a dual-input Convolutional Neural Network, utilizing both Mel Frequency Cepstral Coefficients (MFCC) and Mel-spectrogram features, supported by a multi-stage denoising process, involving discrete wavelet transform and spectral subtraction techniques, plus model and prototype update blocks. Unlike prior methods that restrict updates to specific layers, our approach updates the complete quantized model, made possible due to compact model architecture. A subset of input samples are selected during runtime using class prototypes and confidence-driven filtering, which are then pseudo-labeled and combined with rehearsal buffer for incremental model retraining. Experimental results on noisy test dataset demonstrate the framework's effectiveness, achieving 99.63\% accuracy on clean data and maintaining robust performance (exceeding 94\% accuracy) across diverse noisy environments, even at -10 dB Signal-to-Noise Ratio. The proposed framework work confirms that integrating efficient denoising with prototype-based continual learning enables KWS models to operate autonomously and robustly in resource-constrained, dynamic environments.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16158v1</guid></item><item><title>[cs updates on arXiv.org] CONTEX-T: Contextual Privacy Exploitation via Transformer Spectral Analysis for IoT Device Fingerprinting</title><link>https://arxiv.org/abs/2601.16160</link><description>arXiv:2601.16160v1 Announce Type: new 
Abstract: The rapid expansion of internet of things (IoT) devices have created a pervasive ecosystem where encrypted wireless communications serve as the primary privacy and security protection mechanism. While encryption effectively protects message content, packet metadata and statistics inadvertently expose device identities and user contexts. Various studies have exploited raw packet statistics and their visual representations for device fingerprinting and identification. However, these approaches remain confined to the spatial domain with limited feature representation. Therefore, this paper presents CONTEX-T, a novel framework that exploits contextual privacy vulnerabilities using spectral representation of encrypted wireless traffic for IoT device characterization. The experiments show that spectral analysis provides new and rich feature representation for covert reconnaissance attacks, revealing a complex and expanding threat landscape that would require robust countermeasures for IoT security management. CONTEXT-T first transforms raw packet length sequences into time-frequency spectral representations and then utilizes transformer-based spectral analysis for the device identification. We systematically evaluated multiple spectral representation techniques and transformer-based models across encrypted traffic samples from various IoT devices. CONTEXT-T effectively exploited privacy vulnerabilities and achieved device classification accuracy exceeding 99% across all devices while remaining completely passive and undetectable.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16160v1</guid></item><item><title>[cs updates on arXiv.org] Cosmos Policy: Fine-Tuning Video Models for Visuomotor Control and Planning</title><link>https://arxiv.org/abs/2601.16163</link><description>arXiv:2601.16163v1 Announce Type: new 
Abstract: Recent video generation models demonstrate remarkable ability to capture complex physical interactions and scene evolution over time. To leverage their spatiotemporal priors, robotics works have adapted video models for policy learning but introduce complexity by requiring multiple stages of post-training and new architectural components for action generation. In this work, we introduce Cosmos Policy, a simple approach for adapting a large pretrained video model (Cosmos-Predict2) into an effective robot policy through a single stage of post-training on the robot demonstration data collected on the target platform, with no architectural modifications. Cosmos Policy learns to directly generate robot actions encoded as latent frames within the video model's latent diffusion process, harnessing the model's pretrained priors and core learning algorithm to capture complex action distributions. Additionally, Cosmos Policy generates future state images and values (expected cumulative rewards), which are similarly encoded as latent frames, enabling test-time planning of action trajectories with higher likelihood of success. In our evaluations, Cosmos Policy achieves state-of-the-art performance on the LIBERO and RoboCasa simulation benchmarks (98.5% and 67.1% average success rates, respectively) and the highest average score in challenging real-world bimanual manipulation tasks, outperforming strong diffusion policies trained from scratch, video model-based policies, and state-of-the-art vision-language-action models fine-tuned on the same robot demonstrations. Furthermore, given policy rollout data, Cosmos Policy can learn from experience to refine its world model and value function and leverage model-based planning to achieve even higher success rates in challenging tasks. We release code, models, and training data at https://research.nvidia.com/labs/dir/cosmos-policy/</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16163v1</guid></item><item><title>[cs updates on arXiv.org] Tensor Reed-Muller Codes: Achieving Capacity with Quasilinear Decoding Time</title><link>https://arxiv.org/abs/2601.16164</link><description>arXiv:2601.16164v1 Announce Type: new 
Abstract: Define the codewords of the Tensor Reed-Muller code $\mathsf{TRM}(r_1,m_1;r_2,m_2;\dots;r_t,m_t)$ to be the evaluation vectors of all multivariate polynomials in the variables $\left\{x_{ij}\right\}_{i=1,\dots,t}^{j=1,\dots m_i}$ with degree at most $r_i$ in the variables $x_{i1},x_{i2},\dots,x_{im_i}$. The generator matrix of $\mathsf{TRM}(r_1,m_1;\dots;r_t,m_t)$ is thus the tensor product of the generator matrices of the Reed-Muller codes $\mathsf{RM}(r_1,m_1),\dots, \mathsf{RM}(r_t,m_t)$.
  We show that for any constant rate $R$ below capacity, one can construct a Tensor Reed-Muller code $\mathsf{TRM}(r_1,m_1;\dotsc;r_t,m_t)$ of rate $R$ that is decodable in quasilinear time. For any blocklength $n$, we provide two constructions of such codes:
  1) Our first construction (with $t=3$) has error probability $n^{-\omega(\log n)}$ and decoding time $O(n\log\log n)$.
  2) Our second construction, for any $t\geq 4$, has error probability $2^{-n^{\frac{1}{2}-\frac{1}{2(t-2)}-o(1)}}$ and decoding time $O(n\log n)$.
  One of our main tools is a polynomial-time algorithm for decoding an arbitrary tensor code $C=C_1\otimes\dotsc\otimes C_t$ from $\frac{d_{\min}(C)}{2\max\{d_{\min}(C_1),\dotsc,d_{\min}(C_t) \}}-1$ adversarial errors. Crucially, this algorithm does not require the codes $C_1,\dotsc,C_t$ to themselves be decodable in polynomial time.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16164v1</guid></item><item><title>[cs updates on arXiv.org] Scaling Sample-Based Quantum Diagonalization on GPU-Accelerated Systems using OpenMP Offload</title><link>https://arxiv.org/abs/2601.16169</link><description>arXiv:2601.16169v1 Announce Type: new 
Abstract: Hybrid quantum-HPC algorithms advance research by delegating complex tasks to quantum processors and using HPC systems to orchestrate workflows and complementary computations. Sample-based quantum diagonalization (SQD) is a hybrid quantum-HPC method in which information from a molecular Hamiltonian is encoded into a quantum circuit for evaluation on a quantum computer. A set of measurements on the quantum computer yields electronic configurations that are filtered on the classical computer, which also performs diagonalization on the selected subspace and identifies configurations to be carried over to the next step in an iterative process. Diagonalization is the most demanding task for the classical computer. Previous studies used the Fugaku supercomputer and a highly scalable diagonalization code designed for CPUs. In this work, we describe our efforts to enable efficient scalable and portable diagonalization on heterogeneous systems using GPUs as the main compute engines based on the previous work.
  GPUs provide massive on-device thread-level parallelism that is well aligned with the algorithms used for diagonalization. We focus on the computation of ground-state energies and wavefunctions using the Davidson algorithm with a selected set of electron configurations. We describe the offload strategy, code transformations, and data-movement, with examples of measurements on the Frontier supercomputer and five other GPU accelerated systems. Our measurements show that GPUs provide an outstanding performance boost of order 100x on a per-node basis. This dramatically expedites the diagonalization step-essential for extracting ground and excited state energies-bringing the classical processing time down from hours to minutes.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16169v1</guid></item><item><title>[cs updates on arXiv.org] Non-Linearly Separable Distributed Computing: A Sparse Tensor Factorization Approach</title><link>https://arxiv.org/abs/2601.16171</link><description>arXiv:2601.16171v1 Announce Type: new 
Abstract: The work considers the $N$-server distributed computing setting with $K$ users requesting functions that are arbitrary multi-variable polynomial evaluations of $L$ real (potentially non-linear) basis subfunctions. Our aim is to seek efficient task-allocation and data-communication techniques that reduce computation and communication costs. Towards this, we take a tensor-theoretic approach, in which we represent the requested non-linearly decomposable functions using a properly designed tensor $\bar{\mathcal{F}}$, whose sparse decomposition into a tensor $\bar{\mathcal{E}}$ and matrix $\mathbf{D}$ directly defines the task assignment, connectivity, and communication patterns. We here design an achievable scheme, employing novel fixed-support SVD-based tensor factorization methods and careful multi-dimensional tiling of subtensors, yielding computation and communication protocols whose costs are derived here, and which are shown to perform substantially better than the state of art.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16171v1</guid></item><item><title>[cs updates on arXiv.org] Structured Hints for Sample-Efficient Lean Theorem Proving</title><link>https://arxiv.org/abs/2601.16172</link><description>arXiv:2601.16172v1 Announce Type: new 
Abstract: State-of-the-art neural theorem provers like DeepSeek-Prover-V1.5 combine large language models with reinforcement learning, achieving impressive results through sophisticated training. We ask: do these highly-trained models still benefit from simple structural guidance at inference time? We evaluate a lightweight intervention -- a fixed prompt schedule over 15 common tactic skeletons -- on the miniF2F benchmark. This simple approach yields 21.7% pass@16 compared to 15.2% for standard sampling from the same model, a 43% relative improvement using the same number of samples (k=16) and same maximum generation length (1024 tokens). Our results suggest that even capable RL-trained provers underutilize structural priors available in the tactic language, and that simple inference-time guidance remains a cheap, complementary boost.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16172v1</guid></item><item><title>[cs updates on arXiv.org] Learning to Discover at Test Time</title><link>https://arxiv.org/abs/2601.16175</link><description>arXiv:2601.16175v1 Announce Type: new 
Abstract: How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems. Therefore, our learning objective and search subroutine are designed to prioritize the most promising solutions. We call this method Test-Time Training to Discover (TTT-Discover). Following prior work, we focus on problems with continuous rewards. We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erd\H{o}s' minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to $2\times$ faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers. All our results are achieved with an open model, OpenAI gpt-oss-120b, and can be reproduced with our publicly available code, in contrast to previous best results that required closed frontier models. Our test-time training runs are performed using Tinker, an API by Thinking Machines, with a cost of only a few hundred dollars per problem.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16175v1</guid></item><item><title>[cs updates on arXiv.org] Average Unfairness in Routing Games</title><link>https://arxiv.org/abs/2601.16187</link><description>arXiv:2601.16187v1 Announce Type: new 
Abstract: We propose average unfairness as a new measure of fairness in routing games, defined as the ratio between the average latency and the minimum latency experienced by users. This measure is a natural complement to two existing unfairness notions: loaded unfairness, which compares maximum and minimum latencies of routes with positive flow, and user equilibrium (UE) unfairness, which compares maximum latency with the latency of a Nash equilibrium. We show that the worst-case values of all three unfairness measures coincide and are characterized by a steepness parameter intrinsic to the latency function class. We show that average unfairness is always no greater than loaded unfairness, and the two measures are equal only when the flow is fully fair. Besides that, we offer a complete comparison of the three unfairness measures, which, to the best of our knowledge, is the first theoretical analysis in this direction. Finally, we study the constrained system optimum (CSO) problem, where one seeks to minimize total latency subject to an upper bound on unfairness. We prove that, for the same tolerance level, the optimal flow under an average unfairness constraint achieves lower total latency than any flow satisfying a loaded unfairness constraint. We show that such improvement is always strict in parallel-link networks and establish sufficient conditions for general networks. We further illustrate the latter with numerical examples. Our results provide theoretical guarantees and valuable insights for evaluating fairness-efficiency tradeoffs in network routing.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16187v1</guid></item><item><title>[cs updates on arXiv.org] 360Anything: Geometry-Free Lifting of Images and Videos to 360{\deg}</title><link>https://arxiv.org/abs/2601.16192</link><description>arXiv:2601.16192v1 Announce Type: new 
Abstract: Lifting perspective images and videos to 360{\deg} panoramas enables immersive 3D world generation. Existing approaches often rely on explicit geometric alignment between the perspective and the equirectangular projection (ERP) space. Yet, this requires known camera metadata, obscuring the application to in-the-wild data where such calibration is typically absent or noisy. We propose 360Anything, a geometry-free framework built upon pre-trained diffusion transformers. By treating the perspective input and the panorama target simply as token sequences, 360Anything learns the perspective-to-equirectangular mapping in a purely data-driven way, eliminating the need for camera information. Our approach achieves state-of-the-art performance on both image and video perspective-to-360{\deg} generation, outperforming prior works that use ground-truth camera information. We also trace the root cause of the seam artifacts at ERP boundaries to zero-padding in the VAE encoder, and introduce Circular Latent Encoding to facilitate seamless generation. Finally, we show competitive results in zero-shot camera FoV and orientation estimation benchmarks, demonstrating 360Anything's deep geometric understanding and broader utility in computer vision tasks. Additional results are available at https://360anything.github.io/.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16192v1</guid></item><item><title>[cs updates on arXiv.org] PAL*M: Property Attestation for Large Generative Models</title><link>https://arxiv.org/abs/2601.16199</link><description>arXiv:2601.16199v1 Announce Type: new 
Abstract: Machine learning property attestations allow provers (e.g., model providers or owners) to attest properties of their models/datasets to verifiers (e.g., regulators, customers), enabling accountability towards regulations and policies. But, current approaches do not support generative models or large datasets. We present PAL*M, a property attestation framework for large generative models, illustrated using large language models. PAL*M defines properties across training and inference, leverages confidential virtual machines with security-aware GPUs for coverage of CPU-GPU operations, and proposes using incremental multiset hashing over memory-mapped datasets to efficiently track their integrity. We implement PAL*M on Intel TDX and NVIDIA H100, showing it is efficient, scalable, versatile, and secure.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16199v1</guid></item><item><title>[cs updates on arXiv.org] Provable Robustness in Multimodal Large Language Models via Feature Space Smoothing</title><link>https://arxiv.org/abs/2601.16200</link><description>arXiv:2601.16200v1 Announce Type: new 
Abstract: Multimodal large language models (MLLMs) exhibit strong capabilities across diverse applications, yet remain vulnerable to adversarial perturbations that distort their feature representations and induce erroneous predictions. To address this vulnerability, we propose the Feature-space Smoothing (FS) and theoretically prove that FS offers certified robustness on the feature representations of MLLMs. Specifically, FS transforms any feature encoder into a smoothed variant that is guaranteed to maintain a certified lower bound on the feature cosine similarity between clean and adversarial representations under $\ell_2$-bounded attacks. Moreover, we indicate that the value of this Feature Cosine Similarity Bound (FCSB) derived from FS can be improved by enlarging the defined Gaussian robustness score on the vanilla encoder. Building upon this, we introduce the Purifier and Smoothness Mapper (PSM), a plug-and-play module that improves the Gaussian robustness score of MLLMs and thus enhances their certified robustness under FS, without requiring any retraining on MLLMs. We demonstrate that the FS with PSM not only provides a strong theoretical robustness guarantee but also exhibits superior empirical performance compared to adversarial training. Extensive experiments across diverse MLLMs and downstream tasks indicate the effectiveness of the FS-PSM, reducing the Attack Success Rate (ASR) of various white-box attacks from nearly 90\% to about 1\%.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16200v1</guid></item><item><title>[cs updates on arXiv.org] Counterfactual Training: Teaching Models Plausible and Actionable Explanations</title><link>https://arxiv.org/abs/2601.16205</link><description>arXiv:2601.16205v1 Announce Type: new 
Abstract: We propose a novel training regime termed counterfactual training that leverages counterfactual explanations to increase the explanatory capacity of models. Counterfactual explanations have emerged as a popular post-hoc explanation method for opaque machine learning models: they inform how factual inputs would need to change in order for a model to produce some desired output. To be useful in real-world decision-making systems, counterfactuals should be plausible with respect to the underlying data and actionable with respect to the feature mutability constraints. Much existing research has therefore focused on developing post-hoc methods to generate counterfactuals that meet these desiderata. In this work, we instead hold models directly accountable for the desired end goal: counterfactual training employs counterfactuals during the training phase to minimize the divergence between learned representations and plausible, actionable explanations. We demonstrate empirically and theoretically that our proposed method facilitates training models that deliver inherently desirable counterfactual explanations and additionally exhibit improved adversarial robustness.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16205v1</guid></item><item><title>[cs updates on arXiv.org] LLM-in-Sandbox Elicits General Agentic Intelligence</title><link>https://arxiv.org/abs/2601.16206</link><description>arXiv:2601.16206v1 Announce Type: new 
Abstract: We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverage the file system to handle long contexts, and execute scripts to satisfy formatting requirements. We further show that these agentic capabilities can be enhanced through LLM-in-Sandbox Reinforcement Learning (LLM-in-Sandbox-RL), which uses only non-agentic data to train models for sandbox exploration. Experiments demonstrate that LLM-in-Sandbox, in both training-free and post-trained settings, achieves robust generalization spanning mathematics, physics, chemistry, biomedicine, long-context understanding, and instruction following. Finally, we analyze LLM-in-Sandbox's efficiency from computational and system perspectives, and open-source it as a Python package to facilitate real-world deployment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16206v1</guid></item><item><title>[cs updates on arXiv.org] IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance</title><link>https://arxiv.org/abs/2601.16207</link><description>arXiv:2601.16207v1 Announce Type: new 
Abstract: Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model's built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16207v1</guid></item><item><title>[cs updates on arXiv.org] Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders</title><link>https://arxiv.org/abs/2601.16208</link><description>arXiv:2601.16208v1 Announce Type: new 
Abstract: Representation Autoencoders (RAEs) have shown distinct advantages in diffusion modeling on ImageNet by training in high-dimensional semantic latent spaces. In this work, we investigate whether this framework can scale to large-scale, freeform text-to-image (T2I) generation. We first scale RAE decoders on the frozen representation encoder (SigLIP-2) beyond ImageNet by training on web, synthetic, and text-rendering data, finding that while scale improves general fidelity, targeted data composition is essential for specific domains like text. We then rigorously stress-test the RAE design choices originally proposed for ImageNet. Our analysis reveals that scaling simplifies the framework: while dimension-dependent noise scheduling remains critical, architectural complexities such as wide diffusion heads and noise-augmented decoding offer negligible benefits at scale Building on this simplified framework, we conduct a controlled comparison of RAE against the state-of-the-art FLUX VAE across diffusion transformer scales from 0.5B to 9.8B parameters. RAEs consistently outperform VAEs during pretraining across all model scales. Further, during finetuning on high-quality datasets, VAE-based models catastrophically overfit after 64 epochs, while RAE models remain stable through 256 epochs and achieve consistently better performance. Across all experiments, RAE-based diffusion models demonstrate faster convergence and better generation quality, establishing RAEs as a simpler and stronger foundation than VAEs for large-scale T2I generation. Additionally, because both visual understanding and generation can operate in a shared representation space, the multimodal model can directly reason over generated latents, opening new possibilities for unified models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16208v1</guid></item><item><title>[cs updates on arXiv.org] PyraTok: Language-Aligned Pyramidal Tokenizer for Video Understanding and Generation</title><link>https://arxiv.org/abs/2601.16210</link><description>arXiv:2601.16210v1 Announce Type: new 
Abstract: Discrete video VAEs underpin modern text-to-video generation and video understanding systems, yet existing tokenizers typically learn visual codebooks at a single scale with limited vocabularies and shallow language supervision, leading to poor cross-modal alignment and zero-shot transfer. We introduce PyraTok, a language-aligned pyramidal tokenizer that learns semantically structured discrete latents across multiple spatiotemporal resolutions. PyraTok builds on a pretrained video VAE and a novel Language aligned Pyramidal Quantization (LaPQ) module that discretizes encoder features at several depths using a shared large binary codebook, yielding compact yet expressive video token sequences. To tightly couple visual tokens with language, PyraTok jointly optimizes multi-scale text-guided quantization and a global autoregressive objective over the token hierarchy. Across ten benchmarks, PyraTok delivers state-of-the-art (SOTA) video reconstruction, consistently improves text-to-video quality, and sets new SOTA zero-shot performance on video segmentation, temporal action localization, and video understanding, scaling robustly to up to 4K/8K resolutions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16210v1</guid></item><item><title>[cs updates on arXiv.org] Why Can't I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot Compositional Action Recognition</title><link>https://arxiv.org/abs/2601.16211</link><description>arXiv:2601.16211v1 Announce Type: new 
Abstract: We study Compositional Video Understanding (CVU), where models must recognize verbs and objects and compose them to generalize to unseen combinations. We find that existing Zero-Shot Compositional Action Recognition (ZS-CAR) models fail primarily due to an overlooked failure mode: object-driven verb shortcuts. Through systematic analysis, we show that this behavior arises from two intertwined factors: severe sparsity and skewness of compositional supervision, and the asymmetric learning difficulty between verbs and objects. As training progresses, the existing ZS-CAR model increasingly ignores visual evidence and overfits to co-occurrence statistics. Consequently, the existing model does not gain the benefit of compositional recognition in unseen verb-object compositions. To address this, we propose RCORE, a simple and effective framework that enforces temporally grounded verb learning. RCORE introduces (i) a composition-aware augmentation that diversifies verb-object combinations without corrupting motion cues, and (ii) a temporal order regularization loss that penalizes shortcut behaviors by explicitly modeling temporal structure. Across two benchmarks, Sth-com and our newly constructed EK100-com, RCORE significantly improves unseen composition accuracy, reduces reliance on co-occurrence bias, and achieves consistently positive compositional gaps. Our findings reveal object-driven shortcuts as a critical limiting factor in ZS-CAR and demonstrate that addressing them is essential for robust compositional video understanding.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16211v1</guid></item><item><title>[cs updates on arXiv.org] Point Bridge: 3D Representations for Cross Domain Policy Learning</title><link>https://arxiv.org/abs/2601.16212</link><description>arXiv:2601.16212v1 Announce Type: new 
Abstract: Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by the visual domain gap between simulation and reality. In this work, we present Point Bridge, a framework that leverages unified, domain-agnostic point-based representations to unlock synthetic datasets for zero-shot sim-to-real policy transfer, without explicit visual or object-level alignment. Point Bridge combines automated point-based representation extraction via Vision-Language Models (VLMs), transformer-based policy learning, and efficient inference-time pipelines to train capable real-world manipulation agents using only synthetic data. With additional co-training on small sets of real demonstrations, Point Bridge further improves performance, substantially outperforming prior vision-based sim-and-real co-training methods. It achieves up to 44% gains in zero-shot sim-to-real transfer and up to 66% with limited real data across both single-task and multitask settings. Videos of the robot are best viewed at: https://pointbridge3d.github.io/</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16212v1</guid></item><item><title>[cs updates on arXiv.org] CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback</title><link>https://arxiv.org/abs/2601.16214</link><description>arXiv:2601.16214v1 Announce Type: new 
Abstract: Recent advances in camera-controlled video diffusion models have significantly improved video-camera alignment. However, the camera controllability still remains limited. In this work, we build upon Reward Feedback Learning and aim to further improve camera controllability. However, directly borrowing existing ReFL approaches faces several challenges. First, current reward models lack the capacity to assess video-camera alignment. Second, decoding latent into RGB videos for reward computation introduces substantial computational overhead. Third, 3D geometric information is typically neglected during video decoding. To address these limitations, we introduce an efficient camera-aware 3D decoder that decodes video latent into 3D representations for reward quantization. Specifically, video latent along with the camera pose are decoded into 3D Gaussians. In this process, the camera pose not only acts as input, but also serves as a projection parameter. Misalignment between the video latent and camera pose will cause geometric distortions in the 3D structure, resulting in blurry renderings. Based on this property, we explicitly optimize pixel-level consistency between the rendered novel views and ground-truth ones as reward. To accommodate the stochastic nature, we further introduce a visibility term that selectively supervises only deterministic regions derived via geometric warping. Extensive experiments conducted on RealEstate10K and WorldScore benchmarks demonstrate the effectiveness of our proposed method. Project page: \href{https://a-bigbao.github.io/CamPilot/}{CamPilot Page}.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16214v1</guid></item><item><title>[cs updates on arXiv.org] Scalable Board Expansion within a General Game System</title><link>https://arxiv.org/abs/2601.16216</link><description>arXiv:2601.16216v1 Announce Type: new 
Abstract: This thesis explores the use of a General Game System (GGS) to support the automatic expansion of game boards in boardless games. Traditional implementations of such games often rely on oversized static boards defined from the start, even though large portions of these boards may never be used during gameplay. This approach leads to unnecessary complexity. To address this issue, this thesis propose a dynamic board expansion mechanism in which the game board grows automatically during play.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16216v1</guid></item><item><title>[cs updates on arXiv.org] Real-Time HAP-Assisted Vehicular Edge Computing for Rural Areas</title><link>https://arxiv.org/abs/2301.09957</link><description>arXiv:2301.09957v1 Announce Type: cross 
Abstract: Non-Terrestrial Networks (NTNs) are expected to be a key component of 6th generation (6G) networks to support broadband seamless Internet connectivity and expand the coverage even in rural and remote areas. In this context, High Altitude Platforms (HAPs) can act as edge servers to process computational tasks offloaded by energy-constrained terrestrial devices such as Internet of Things (IoT) sensors and ground vehicles (GVs). In this paper, we analyze the opportunity to support Vehicular Edge Computing (VEC) via HAP in a rural scenario where GVs can decide whether to process data onboard or offload them to a HAP. We characterize the system as a set of queues in which computational tasks arrive according to a Poisson arrival process. Then, we assess the optimal VEC offloading factor to maximize the probability of real-time service, given latency and computational capacity constraints.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2301.09957v1</guid></item><item><title>[cs updates on arXiv.org] Performance Evaluation of LoRa for IoT Applications in Non-Terrestrial Networks via ns-3</title><link>https://arxiv.org/abs/2509.02811</link><description>arXiv:2509.02811v1 Announce Type: cross 
Abstract: The integration of Internet of Things (IoT) and Non-Terrestrial Networks (NTNs) has emerged as a key paradigm to provide connectivity for sensors and actuators via satellite gateways in remote areas where terrestrial infrastructure is limited or unavailable. Among other Low-Power Wide-Area Network (LPWAN) technologies for IoT, Long Range (LoRa) holds great potential given its long range, energy efficiency, and flexibility. In this paper, we explore the feasibility and performance of LoRa to support large-scale IoT connectivity through Low Earth Orbit (LEO) satellite gateways. To do so, we developed a new ns3-LoRa-NTN simulation module, which integrates and extends the ns3-LoRa and ns3-NTN modules, to enable full-stack end-to-end simulation of satellite communication in LoRa networks. Our results, given in terms of average data rate and Packet Reception Ratio (PRR), confirm that LoRa can effectively support direct communication from the ground to LEO satellites, but network optimization is required to mitigate collision probability when end nodes use the same Spreading Factors (SFs) over long distances.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.02811v1</guid></item><item><title>[cs updates on arXiv.org] Ecosystem Competition and Cross-Market Subsidization: A Dynamic Theory of Platform Pricing</title><link>https://arxiv.org/abs/2601.15303</link><description>arXiv:2601.15303v1 Announce Type: cross 
Abstract: Platform giants in China have operated with persistently compressed margins in highly concentrated markets for much of the past decade, despite market shares exceeding 60\% in core segments. Standard theory predicts otherwise: either the weaker firm exits, or survivors raise prices to monopoly levels. We argue the puzzle dissolves once firms are viewed as ecosystem optimizers rather than single-market profit maximizers. We develop a dynamic game in which a firm's willingness to subsidize depends on the spillover value its users generate in adjacent markets -- what we call \textit{ecosystem complementarity}. When this complementarity is strong enough, perpetual below-cost pricing emerges as the unique stable equilibrium. The result is not predation in the classical sense; there is no recoupment phase. It is a permanent state of subsidized competition, rational for each firm individually but potentially inefficient in aggregate. We characterize the equilibrium, establish its dynamic stability, and show that welfare losses compound over time as capital flows into subsidy wars rather than innovation. The model's predictions are consistent with observed patterns in Chinese platform markets and suggest that effective antitrust intervention should target cross-market capital flows rather than prices.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15303v1</guid></item><item><title>[cs updates on arXiv.org] An Explainable Market Integrity Monitoring System with Multi-Source Attention Signals and Transparent Scoring</title><link>https://arxiv.org/abs/2601.15304</link><description>arXiv:2601.15304v1 Announce Type: cross 
Abstract: Market integrity monitoring is difficult because suspicious price/volume behavior can arise from many benign mechanisms, while modern detection systems often rely on opaque models that are hard to audit and communicate. We present AIMM-X, an explainable monitoring pipeline that combines market microstructure-style signals derived from OHLCV time series with multi-source public attention signals (e.g., news and online discussion proxies) to surface time windows that merit analyst review. The system detects candidate anomalous windows using transparent thresholding and aggregation, then assigns an interpretable integrity score decomposed into a small set of additive components, allowing practitioners to trace why a window was flagged and which factors drove the score. We provide an end-to-end, reproducible implementation that downloads data, constructs attention features, builds unified panels, detects windows, computes component signals, and generates summary figures/tables. Our goal is not to label manipulation, but to provide a practical, auditable screening tool that supports downstream investigation by compliance teams, exchanges, or researchers.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15304v1</guid></item><item><title>[cs updates on arXiv.org] Mind the Gap: Why Neural Memory Fails Under Semantic Density</title><link>https://arxiv.org/abs/2601.15313</link><description>arXiv:2601.15313v1 Announce Type: cross 
Abstract: The brain solves a problem that current AI architectures struggle to manage: storing specific episodic facts without corrupting general semantic knowledge. Neuroscience explains this through Complementary Learning Systems theory - a fast hippocampal system for episodic storage using pattern-separated representations, and a slow neocortical system for extracting statistical regularities. Current AI systems lack this separation, attempting both functions through neural weights alone. We identify the 'Stability Gap' in online neural memory: fast-weight mechanisms that write facts into shared continuous parameters collapse to near-random accuracy within tens of semantically related facts. Through semantic density (rho), we show collapse occurs with as few as N=5 facts at high density (rho &gt; 0.6) or N ~ 20-75 at moderate density - a phenomenon we formalise as the Orthogonality Constraint. This failure persists even with perfect attention and unlimited context, arising from write-time interference when storage and retrieval share the same substrate. We also identify schema drift and version ambiguity as primary failure modes in production systems, observing 40-70% schema consistency and 0-100% clean correction rates. Context-based memory incurs 30-300% cost premium over selective retrieval. We propose Knowledge Objects (KOs): discrete, typed memory units with controlled vocabularies and explicit version chains. Paired with neural weights, KOs enable a true complementary learning architecture, suggesting reliable AI memory may require this bicameral design.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15313v1</guid></item><item><title>[cs updates on arXiv.org] Beyond the Einstein-Bohr Debate: Cognitive Complementarity and the Emergence of Quantum Intuition</title><link>https://arxiv.org/abs/2601.15314</link><description>arXiv:2601.15314v1 Announce Type: cross 
Abstract: Recent high-precision experimental confirmations of quantum complementarity have revitalized foundational debates about measurement, description, and realism. This article argues that complementarity is most productively interpreted as an epistemic principle--constraining what can be simultaneously accessed and represented--rather than as an ontological claim about quantum reality. Reexamining the Einstein-Bohr debate through this lens reveals a persistent tension between descriptive completeness and contextual meaning, a tension experiments clarify but do not dissolve. Building on this analysis, we introduce cognitive complementarity as a structural principle governing reasoning under non-classical uncertainty, where mutually constraining representations cannot be jointly optimized. Within this framework, we propose quantum intuition as a testable cognitive capacity: the ability to sustain representational plurality, regulate commitment timing, and resolve perspective-incompatibilities in a context-sensitive manner. Formulated as a naturalistic construct grounded in shared informational constraints, quantum intuition offers a principled bridge between quantum measurement theory and cognition. This work reframes the historical debate, extends epistemic lessons from quantum foundations into cognitive science, and outlines empirical pathways for studying decision-making in contexts of irreducible uncertainty.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15314v1</guid></item><item><title>[cs updates on arXiv.org] The Impossibility of Cohesion Without Fragmentation</title><link>https://arxiv.org/abs/2601.15317</link><description>arXiv:2601.15317v1 Announce Type: cross 
Abstract: Most models in game theory and network formation implicitly assume that relations between agents are feasible whenever incentives are aligned or interaction opportunities exist. Under this premise analytical attention is directed toward equilibrium efficiency or probabilistic link formation while the possibility that a relation may be structurally infeasible is rarely examined. This paper develops a static axiomatic framework in which relation maintenance is treated as a problem of structural compatibility rather than strategic choice or stochastic realization. Agents occupy positions in an abstract space and relations are subject to minimum conditions defined over these positions. A bifurcation event such as a vote declaration or institutional assignment fixes agents positions and thereby determines which relations are compatible. We identify position dependent gain axes as the key source of structural selectivity and prove an impossibility result under any non degenerate positional constraint no bifurcation event can preserve all relations. Instead the post event network necessarily exhibits either the simultaneous emergence of fragmentation and cohesion or a degenerate trivial case in which constraints are position independent. The result is purely structural and does not rely on preferences beliefs incentives or dynamic adjustment. It establishes a fundamental limit on universally cohesive outcomes and reframes division not as a failure of design or coordination but as a logical consequence of positional constraints.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15317v1</guid></item><item><title>[cs updates on arXiv.org] Large Language Models as Simulative Agents for Neurodivergent Adult Psychometric Profiles</title><link>https://arxiv.org/abs/2601.15319</link><description>arXiv:2601.15319v1 Announce Type: cross 
Abstract: Adult neurodivergence, including Attention-Deficit/Hyperactivity Disorder (ADHD), high-functioning Autism Spectrum Disorder (ASD), and Cognitive Disengagement Syndrome (CDS), is marked by substantial symptom overlap that limits the discriminant sensitivity of standard psychometric instruments. While recent work suggests that Large Language Models (LLMs) can simulate human psychometric responses from qualitative data, it remains unclear whether they can accurately and stably model neurodevelopmental traits rather than broad personality characteristics. This study examines whether LLMs can generate psychometric responses that approximate those of real individuals when grounded in a structured qualitative interview, and whether such simulations are sensitive to variations in trait intensity. Twenty-six adults completed a 29-item open-ended interview and four standardized self-report measures (ASRS, BAARS-IV, AQ, RAADS-R). Two LLMs (GPT-4o and Qwen3-235B-A22B) were prompted to infer an individual psychological profile from interview content and then respond to each questionnaire in-role. Accuracy, reliability, and sensitivity were assessed using group-level comparisons, error metrics, exact-match scoring, and a randomized baseline. Both models outperformed random responses across instruments, with GPT-4o showing higher accuracy and reproducibility. Simulated responses closely matched human data for ASRS, BAARS-IV, and RAADS-R, while the AQ revealed subscale-specific limitations, particularly in Attention to Detail. Overall, the findings indicate that interview-grounded LLMs can produce coherent and above-chance simulations of neurodevelopmental traits, supporting their potential use as synthetic participants in early-stage psychometric research, while highlighting clear domain-specific constraints.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15319v1</guid></item><item><title>[cs updates on arXiv.org] ECGomics: An Open Platform for AI-ECG Digital Biomarker Discovery</title><link>https://arxiv.org/abs/2601.15326</link><description>arXiv:2601.15326v1 Announce Type: cross 
Abstract: Background: Conventional electrocardiogram (ECG) analysis faces a persistent dichotomy: expert-driven features ensure interpretability but lack sensitivity to latent patterns, while deep learning offers high accuracy but functions as a black box with high data dependency. We introduce ECGomics, a systematic paradigm and open-source platform for the multidimensional deconstruction of cardiac signals into digital biomarker. Methods: Inspired by the taxonomic rigor of genomics, ECGomics deconstructs cardiac activity across four dimensions: Structural, Intensity, Functional, and Comparative. This taxonomy synergizes expert-defined morphological rules with data-driven latent representations, effectively bridging the gap between handcrafted features and deep learning embeddings. Results: We operationalized this framework into a scalable ecosystem consisting of a web-based research platform and a mobile-integrated solution (https://github.com/PKUDigitalHealth/ECGomics). The web platform facilitates high-throughput analysis via precision parameter configuration, high-fidelity data ingestion, and 12-lead visualization, allowing for the systematic extraction of biomarkers across the four ECGomics dimensions. Complementarily, the mobile interface, integrated with portable sensors and a cloud-based engine, enables real-time signal acquisition and near-instantaneous delivery of structured diagnostic reports. This dual-interface architecture successfully transitions ECGomics from theoretical discovery to decentralized, real-world health management, ensuring professional-grade monitoring in diverse clinical and home-based settings. Conclusion: ECGomics harmonizes diagnostic precision, interpretability, and data efficiency. By providing a deployable software ecosystem, this paradigm establishes a robust foundation for digital biomarker discovery and personalized cardiovascular medicine.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15326v1</guid></item><item><title>[cs updates on arXiv.org] Learning Discrete Successor Transitions in Continuous Attractor Networks: Emergence, Limits, and Topological Constraints</title><link>https://arxiv.org/abs/2601.15336</link><description>arXiv:2601.15336v1 Announce Type: cross 
Abstract: Continuous attractor networks (CANs) are a well-established class of models for representing low-dimensional continuous variables such as head direction, spatial position, and phase. In canonical spatial domains, transitions along the attractor manifold are driven by continuous displacement signals, such as angular velocity-provided by sensorimotor systems external to the CAN itself. When such signals are not explicitly provided as dedicated displacement inputs, it remains unclear whether attractor-based circuits can reliably acquire recurrent dynamics that support stable state transitions, or whether alternative predictive strategies dominate.
  In this work, we present an experimental framework for training CANs to perform successor-like transitions between stable attractor states in the absence of externally provided displacement signals. We compare two recurrent topologies, a circular ring and a folded snake manifold, and systematically vary the temporal regime under which stability is evaluated. We find that, under short evaluation windows, networks consistently converge to impulse-driven associative solutions that achieve high apparent accuracy yet lack persistent attractor dynamics. Only when stability is explicitly enforced over extended free-run periods do genuine attractor-based transition dynamics emerge. This suggests that shortcut solutions are the default outcome of local learning in recurrent networks, while attractor dynamics represent a constrained regime rather than a generic result.
  Furthermore, we demonstrate that topology strictly limits the capacity for learned transitions. While the continuous ring topology achieves perfect stability over long horizons, the folded snake topology hits a geometric limit characterized by failure at manifold discontinuities, which neither curriculum learning nor basal ganglia-inspired gating can fully overcome.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15336v1</guid></item><item><title>[cs updates on arXiv.org] Learning Nonlinear Heterogeneity in Physical Kolmogorov-Arnold Networks</title><link>https://arxiv.org/abs/2601.15340</link><description>arXiv:2601.15340v1 Announce Type: cross 
Abstract: Physical neural networks typically train linear synaptic weights while treating device nonlinearities as fixed. We show the opposite - by training the synaptic nonlinearity itself, as in Kolmogorov-Arnold Network (KAN) architectures, we yield markedly higher task performance per physical resource and improved performance-parameter scaling than conventional linear weight-based networks, demonstrating ability of KAN topologies to exploit reconfigurable nonlinear physical dynamics.
  We experimentally realise physical KANs in silicon-on-insulator devices we term 'Synaptic Nonlinear Elements' (SYNEs), operating at room temperature, 0.1-1 microampere currents, and 2 MHz speeds with no observed degradation over 10^13 measurements and months-long timescales.
  We demonstrate nonlinear function regression, classification, and prediction of Li-Ion battery dynamics from noisy real-world multi-sensor data. Physical KANs outperform equivalently-parameterised software multilayer perceptron networks across all tasks, with up to two orders of magnitude fewer parameters, and two orders of magnitude fewer devices than linear weight based physical networks. These results establish learned physical nonlinearity as a hardware-native computational primitive for compact and efficient learning systems, and SYNE devices as effective substrates for heterogenous nonlinear computing.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15340v1</guid></item><item><title>[cs updates on arXiv.org] OmniSpectra: A Unified Foundation Model for Native Resolution Astronomical Spectra</title><link>https://arxiv.org/abs/2601.15351</link><description>arXiv:2601.15351v1 Announce Type: cross 
Abstract: We present OmniSpectra, the first native-resolution foundation model for astronomy spectra. Unlike traditional models, which are limited to fixed-length input sizes or configurations, OmniSpectra handles spectra of any length at their original size, without resampling or interpolation. Despite the large-scale spectroscopic data from diverse surveys fueling the rapid growth of astronomy, existing foundation models are limited to a fixed wavelength range and specific instruments. OmniSpectra is the first foundation model to learn simultaneously from multiple real-world spectra surveys with different configurations at a large scale. We achieve this by designing a novel architecture with adaptive patching across variable lengths, sinusoidal global wavelength encoding, local positional embeddings through depthwise convolution, and validity-aware self-attention masks. Allowing us to learn multi-scale spatial patterns while skipping attention for invalid patches. Even with a limited training example, OmniSpectra demonstrates excellent zero-shot generalization compared to methods tailored for specific tasks. This transfer learning capability makes this model the state-of-the-art across various astronomy tasks, including source classification, redshift estimation, and properties prediction for stars and galaxies. OmniSpectra reduces the need for training individual models for different tasks from scratch, establishing itself as the next-generation astronomy foundation model.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15351v1</guid></item><item><title>[cs updates on arXiv.org] Statistical Reinforcement Learning in the Real World: A Survey of Challenges and Future Directions</title><link>https://arxiv.org/abs/2601.15353</link><description>arXiv:2601.15353v1 Announce Type: cross 
Abstract: Reinforcement learning (RL) has achieved remarkable success in real-world decision-making across diverse domains, including gaming, robotics, online advertising, public health, and natural language processing. Despite these advances, a substantial gap remains between RL research and its deployment in many practical settings. Two recurring challenges often underlie this gap. First, many settings offer limited opportunity for the agent to interact extensively with the target environment due to practical constraints. Second, many target environments often undergo substantial changes, requiring redesign and redeployment of RL systems (e.g., advancements in science and technology that change the landscape of healthcare delivery). Addressing these challenges and bridging the gap between basic research and application requires theory and methodology that directly inform the design, implementation, and continual improvement of RL systems in real-world settings.
  In this paper, we frame the application of RL in practice as a three-component process: (i) online learning and optimization during deployment, (ii) post- or between-deployment offline analyses, and (iii) repeated cycles of deployment and redeployment to continually improve the RL system. We provide a narrative review of recent advances in statistical RL that address these components, including methods for maximizing data utility for between-deployment inference, enhancing sample efficiency for online learning within-deployment, and designing sequences of deployments for continual improvement. We also outline future research directions in statistical RL that are use-inspired -- aiming for impactful application of RL in practice.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15353v1</guid></item><item><title>[cs updates on arXiv.org] Q-Probe: Scaling Image Quality Assessment to High Resolution via Context-Aware Agentic Probing</title><link>https://arxiv.org/abs/2601.15356</link><description>arXiv:2601.15356v1 Announce Type: cross 
Abstract: Reinforcement Learning (RL) has empowered Multimodal Large Language Models (MLLMs) to achieve superior human preference alignment in Image Quality Assessment (IQA). However, existing RL-based IQA models typically rely on coarse-grained global views, failing to capture subtle local degradations in high-resolution scenarios. While emerging "Thinking with Images" paradigms enable multi-scale visual perception via zoom-in mechanisms, their direct adaptation to IQA induces spurious "cropping-implies-degradation" biases and misinterprets natural depth-of-field as artifacts. To address these challenges, we propose Q-Probe, the first agentic IQA framework designed to scale IQA to high resolution via context-aware probing. First, we construct Vista-Bench, a pioneering benchmark tailored for fine-grained local degradation analysis in high-resolution IQA settings. Furthermore, we propose a three-stage training paradigm that progressively aligns the model with human preferences, while simultaneously eliminating causal bias through a novel context-aware cropping strategy. Extensive experiments demonstrate that Q-Probe achieves state-of-the-art performance in high-resolution settings while maintaining superior efficacy across resolution scales.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15356v1</guid></item><item><title>[cs updates on arXiv.org] High-Fidelity 3D Tooth Reconstruction by Fusing Intraoral Scans and CBCT Data via a Deep Implicit Representation</title><link>https://arxiv.org/abs/2601.15358</link><description>arXiv:2601.15358v1 Announce Type: cross 
Abstract: High-fidelity 3D tooth models are essential for digital dentistry, but must capture both the detailed crown and the complete root. Clinical imaging modalities are limited: Cone-Beam Computed Tomography (CBCT) captures the root but has a noisy, low-resolution crown, while Intraoral Scanners (IOS) provide a high-fidelity crown but no root information. A naive fusion of these sources results in unnatural seams and artifacts. We propose a novel, fully-automated pipeline that fuses CBCT and IOS data using a deep implicit representation. Our method first segments and robustly registers the tooth instances, then creates a hybrid proxy mesh combining the IOS crown and the CBCT root. The core of our approach is to use this noisy proxy to guide a class-specific DeepSDF network. This optimization process projects the input onto a learned manifold of ideal tooth shapes, generating a seamless, watertight, and anatomically coherent model. Qualitative and quantitative evaluations show our method uniquely preserves both the high-fidelity crown from IOS and the patient-specific root morphology from CBCT, overcoming the limitations of each modality and naive stitching.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15358v1</guid></item><item><title>[cs updates on arXiv.org] Robust X-Learner: Breaking the Curse of Imbalance and Heavy Tails via Robust Cross-Imputation</title><link>https://arxiv.org/abs/2601.15360</link><description>arXiv:2601.15360v1 Announce Type: cross 
Abstract: Estimating Heterogeneous Treatment Effects (HTE) in industrial applications such as AdTech and healthcare presents a dual challenge: extreme class imbalance and heavy-tailed outcome distributions. While the X-Learner framework effectively addresses imbalance through cross-imputation, we demonstrate that it is fundamentally vulnerable to "Outlier Smearing" when reliant on Mean Squared Error (MSE) minimization. In this failure mode, the bias from a few extreme observations ("whales") in the minority group is propagated to the entire majority group during the imputation step, corrupting the estimated treatment effect structure. To resolve this, we propose the Robust X-Learner (RX-Learner). This framework integrates a redescending {\gamma}-divergence objective -- structurally equivalent to the Welsch loss under Gaussian assumptions -- into the gradient boosting machinery. We further stabilize the non-convex optimization using a Proxy Hessian strategy grounded in Majorization-Minimization (MM) principles. Empirical evaluation on a semi-synthetic Criteo Uplift dataset demonstrates that the RX-Learner reduces the Precision in Estimation of Heterogeneous Effect (PEHE) metric by 98.6% compared to the standard X-Learner, effectively decoupling the stable "Core" population from the volatile "Periphery".</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15360v1</guid></item><item><title>[cs updates on arXiv.org] USDs: A universal stabilizer decoder framework using symmetry</title><link>https://arxiv.org/abs/2601.15361</link><description>arXiv:2601.15361v1 Announce Type: cross 
Abstract: Quantum error correction is indispensable to achieving reliable quantum computation. When quantum information is encoded redundantly, a larger Hilbert space is constructed using multiple physical qubits, and the computation is performed within a designated subspace. When applying deep learning to the decoding of quantum error-correcting codes, a key challenge arises from the non-uniqueness between the syndrome measurements provided to the decoder and the corresponding error patterns that constitute the ground-truth labels. Building upon prior work that addressed this issue for the toric code by re-optimizing the decoder with respect to the symmetry inherent in the parity-check structure, we generalize this approach to arbitrary stabilizer codes. In our experiments, we employed multilayer perceptrons to approximate continuous functions that complement the syndrome measurements of the Color code and the Golay code. Using these models, we performed decoder re-optimization for each code. For the Color code, we achieved an improvement of approximately 0.8% in decoding accuracy at a physical error rate of 5%, while for the Golay code the accuracy increased by about 0.1%. Furthermore, from the evaluation of the geometric and algebraic structures in the continuous function approximation for each code, we showed that the design of generalized continuous functions is advantageous for learning the geometric structure inherent in the code. Our results also indicate that approximations that faithfully reproduce the code structure can have a significant impact on the effectiveness of reoptimization. This study demonstrates that the re-optimization technique previously shown to be effective for the Toric code can be generalized to address the challenge of label degeneracy that arises when applying deep learning to the decoding of stabilizer codes.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15361v1</guid></item><item><title>[cs updates on arXiv.org] Non-Stationary Functional Bilevel Optimization</title><link>https://arxiv.org/abs/2601.15363</link><description>arXiv:2601.15363v1 Announce Type: cross 
Abstract: Functional bilevel optimization (FBO) provides a powerful framework for hierarchical learning in function spaces, yet current methods are limited to static offline settings and perform suboptimally in online, non-stationary scenarios. We propose SmoothFBO, the first algorithm for non-stationary FBO with both theoretical guarantees and practical scalability. SmoothFBO introduces a time-smoothed stochastic hypergradient estimator that reduces variance through a window parameter, enabling stable outer-loop updates with sublinear regret. Importantly, the classical parametric bilevel case is a special reduction of our framework, making SmoothFBO a natural extension to online, non-stationary settings. Empirically, SmoothFBO consistently outperforms existing FBO methods in non-stationary hyperparameter optimization and model-based reinforcement learning, demonstrating its practical effectiveness. Together, these results establish SmoothFBO as a general, theoretically grounded, and practically viable foundation for bilevel optimization in online, non-stationary scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15363v1</guid></item><item><title>[cs updates on arXiv.org] OpenVision 3: A Family of Unified Visual Encoder for Both Understanding and Generation</title><link>https://arxiv.org/abs/2601.15369</link><description>arXiv:2601.15369v1 Announce Type: cross 
Abstract: This paper presents a family of advanced vision encoder, named OpenVision 3, that learns a single, unified visual representation that can serve both image understanding and image generation. Our core architecture is simple: we feed VAE-compressed image latents to a ViT encoder and train its output to support two complementary roles. First, the encoder output is passed to the ViT-VAE decoder to reconstruct the original image, encouraging the representation to capture generative structure. Second, the same representation is optimized with contrastive learning and image-captioning objectives, strengthening semantic features. By jointly optimizing reconstruction- and semantics-driven signals in a shared latent space, the encoder learns representations that synergize and generalize well across both regimes. We validate this unified design through extensive downstream evaluations with the encoder frozen. For multimodal understanding, we plug the encoder into the LLaVA-1.5 framework: it performs comparably with a standard CLIP vision encoder (e.g., 62.4 vs 62.2 on SeedBench, and 83.7 vs 82.9 on POPE). For generation, we test it under the RAE framework: ours substantially surpasses the standard CLIP-based encoder (e.g., gFID: 1.89 vs 2.54 on ImageNet). We hope this work can spur future research on unified modeling.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15369v1</guid></item><item><title>[cs updates on arXiv.org] ISAC-over-NTN: HAPS-UAV Framework for Post-Disaster Responsive 6G Networks</title><link>https://arxiv.org/abs/2601.15422</link><description>arXiv:2601.15422v1 Announce Type: cross 
Abstract: In disaster scenarios, ensuring both reliable communication and situational awareness becomes a critical challenge due to the partial or complete collapse of terrestrial networks. This paper proposes an integrated sensing and communication (ISAC) over non-terrestrial networks (NTN) architecture referred to as ISAC-over-NTN that integrates multiple uncrewed aerial vehicles (UAVs) and a high-altitude platform station (HAPS) to maintain resilient and reliable network operations in post-disaster conditions. We aim to achieve two main objectives: i) provide a reliable communication infrastructure, thereby ensuring the continuity of search-and-rescue activities and connecting people to their loved ones, and ii) detect users, such as those trapped under rubble or those who are mobile, using a Doppler-based mobility detection model. We employ an innovative beamforming method that simultaneously transmits data and detects Doppler-based mobility by integrating multi-user multiple-input multiple-output (MU-MIMO) communication and monostatic sensing within the same transmission chain. The results show that the proposed framework maintains reliable connectivity and achieves high detection accuracy of users in critical locations, reaching 90% motion detection sensitivity and 88% detection accuracy.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15422v1</guid></item><item><title>[cs updates on arXiv.org] Low-Dimensional Adaptation of Rectified Flow: A New Perspective through the Lens of Diffusion and Stochastic Localization</title><link>https://arxiv.org/abs/2601.15500</link><description>arXiv:2601.15500v1 Announce Type: cross 
Abstract: In recent years, Rectified flow (RF) has gained considerable popularity largely due to its generation efficiency and state-of-the-art performance. In this paper, we investigate the degree to which RF automatically adapts to the intrinsic low dimensionality of the support of the target distribution to accelerate sampling. We show that, using a carefully designed choice of the time-discretization scheme and with sufficiently accurate drift estimates, the RF sampler enjoys an iteration complexity of order $O(k/\varepsilon)$ (up to log factors), where $\varepsilon$ is the precision in total variation distance and $k$ is the intrinsic dimension of
  the target distribution. In addition, we show that the denoising diffusion probabilistic model (DDPM) procedure is equivalent to a stochastic version of RF by establishing a novel connection between these processes and stochastic localization. Building on this connection, we further design a stochastic RF sampler that also adapts to the low-dimensionality of the target distribution under milder requirements on the accuracy of the drift estimates, and also with a specific time schedule. We illustrate with simulations on the synthetic data and text-to-image data experiments the improved performance of the proposed samplers implementing the newly designed time-discretization schedules.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15500v1</guid></item><item><title>[cs updates on arXiv.org] Applicability and Limitation Analysis of PMU Data and Phasor Concept for Low- and High- Frequency Oscillations</title><link>https://arxiv.org/abs/2601.15529</link><description>arXiv:2601.15529v1 Announce Type: cross 
Abstract: Phasor Measurement Units (PMUs) convert high-speed waveform data into low-speed phasor data, which are fundamental to wide-area monitoring and control in power systems, with oscillation detection and localization among their most prominent applications. However, representing electrical waveform signals with oscillations using PMU phasors is effective only for low-frequency oscillations. This paper investigates the root causes of this limitation, focusing on errors introduced by Discrete Fourier Transform (DFT)-based signal processing, in addition to the attenuation effects of anti-aliasing filters, and the impact of low reporting rates. To better represent and estimate waveform signals with oscillations, we propose a more general signal model and a multi-step estimation method that leverages one-cycle DFT, the Matrix Pencil Method, and the Least Squares Method. Numerical experiments demonstrate the superior performance of the proposed signal model and estimation method. Furthermore, this paper reveals that the phasor concept, let alone PMU phasors, can become invalid for waveform signals with high-frequency oscillations characterized by asymmetric sub- and super-synchronous components. These findings highlight the fundamental limitations of PMU data and phasor concept, and emphasize the need to rely on waveform data for analyzing high-frequency oscillations in modern power systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15529v1</guid></item><item><title>[cs updates on arXiv.org] A Machine Vision Approach to Preliminary Skin Lesion Assessments</title><link>https://arxiv.org/abs/2601.15539</link><description>arXiv:2601.15539v1 Announce Type: cross 
Abstract: Early detection of malignant skin lesions is critical for improving patient outcomes in aggressive, metastatic skin cancers. This study evaluates a comprehensive system for preliminary skin lesion assessment that combines the clinically established ABCD rule of dermoscopy (analyzing Asymmetry, Borders, Color, and Dermoscopic Structures) with machine learning classification. Using a 1,000-image subset of the HAM10000 dataset, the system implements an automated, rule-based pipeline to compute a Total Dermoscopy Score (TDS) for each lesion. This handcrafted approach is compared against various machine learning solutions, including traditional classifiers (Logistic Regression, Random Forest, and SVM) and deep learning models. While the rule-based system provides high clinical interpretability, results indicate a performance bottleneck when reducing complex morphology to five numerical features. Experimental findings show that transfer learning with EfficientNet-B0 failed significantly due to domain shift between natural and medical images. In contrast, a custom three-layer Convolutional Neural Network (CNN) trained from scratch achieved 78.5% accuracy and 86.5% recall on median-filtered images, representing a 19-point accuracy improvement over traditional methods. The results demonstrate that direct pixel-level learning captures diagnostic patterns beyond handcrafted features and that purpose-built lightweight architectures can outperform large pretrained models for small, domain-specific medical datasets.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15539v1</guid></item><item><title>[cs updates on arXiv.org] Stabilizing Welfare-Maximizing Decisions via Endogenous Transfers</title><link>https://arxiv.org/abs/2601.15563</link><description>arXiv:2601.15563v1 Announce Type: cross 
Abstract: Many multiagent systems rely on collective decision-making among self-interested agents, which raises deep questions about coalition formation and stability. We study social choice with endogenous, outcome-contingent transfers, where agents voluntarily form contracts that redistribute utility depending on the collective decision, allowing fully strategic, incentive-aligned coalition formation. We show that under consensus rules, individually rational strong Nash equilibria (IR-SNE) always exist, implementing welfare-maximizing outcomes with feasible transfers, and provide a simple, efficient algorithm to construct them. For more general anonymous, monotonic, and resolute rules, we identify necessary conditions for profitable deviations, sharply limiting destabilizing coalitions. By bridging cooperative and noncooperative perspectives, our approach shows that transferable utility can achieve core-like stability, restoring efficiency and budget balance even where classical impossibility results apply. Overall, this framework offers a practical and robust way to coordinate large-scale strategic multiagent systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15563v1</guid></item><item><title>[cs updates on arXiv.org] FUGC: Benchmarking Semi-Supervised Learning Methods for Cervical Segmentation</title><link>https://arxiv.org/abs/2601.15572</link><description>arXiv:2601.15572v1 Announce Type: cross 
Abstract: Accurate segmentation of cervical structures in transvaginal ultrasound (TVS) is critical for assessing the risk of spontaneous preterm birth (PTB), yet the scarcity of labeled data limits the performance of supervised learning approaches. This paper introduces the Fetal Ultrasound Grand Challenge (FUGC), the first benchmark for semi-supervised learning in cervical segmentation, hosted at ISBI 2025. FUGC provides a dataset of 890 TVS images, including 500 training images, 90 validation images, and 300 test images. Methods were evaluated using the Dice Similarity Coefficient (DSC), Hausdorff Distance (HD), and runtime (RT), with a weighted combination of 0.4/0.4/0.2. The challenge attracted 10 teams with 82 participants submitting innovative solutions. The best-performing methods for each individual metric achieved 90.26\% mDSC, 38.88 mHD, and 32.85 ms RT, respectively. FUGC establishes a standardized benchmark for cervical segmentation, demonstrates the efficacy of semi-supervised methods with limited labeled data, and provides a foundation for AI-assisted clinical PTB risk assessment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15572v1</guid></item><item><title>[cs updates on arXiv.org] On the Nonasymptotic Scaling Guarantee of Hyperparameter Estimation in Inhomogeneous, Weakly-Dependent Complex Network Dynamical Systems</title><link>https://arxiv.org/abs/2601.15603</link><description>arXiv:2601.15603v1 Announce Type: cross 
Abstract: Hierarchical Bayesian models are increasingly used in large, inhomogeneous complex network dynamical systems by modeling parameters as draws from a hyperparameter-governed distribution. However, theoretical guarantees for these estimates as the system size grows have been lacking. A critical concern is that hyperparameter estimation may diverge for larger networks, undermining the model's reliability. Formulating the system's evolution in a measure transport perspective, we propose a theoretical framework for estimating hyperparameters with mean-type observations, which are prevalent in many scientific applications. Our primary contribution is a nonasymptotic bound for the deviation of estimate of hyperparameters in inhomogeneous complex network dynamical systems with respect to network population size, which is established for a general family of optimization algorithms within a fixed observation duration. While we firstly establish a consistency result for systems with independent nodes, our main result extends this guarantee to the more challenging and realistic setting of weakly-dependent nodes. We validate our theoretical findings with numerical experiments on two representative models: a Susceptible-Infected-Susceptible model and a Spiking Neuronal Network model. In both cases, the results confirm that the estimation error decreases as the network population size increases, aligning with our theoretical guarantees. This research proposes the foundational theory to ensure that hierarchical Bayesian methods are statistically consistent for large-scale inhomogeneous systems, filling a gap in this area of theoretical research and justifying their application in practice.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15603v1</guid></item><item><title>[cs updates on arXiv.org] Machine Failure Detection Based on Projected Quantum Models</title><link>https://arxiv.org/abs/2601.15641</link><description>arXiv:2601.15641v1 Announce Type: cross 
Abstract: Detecting machine failures promptly is of utmost importance in industry for maintaining efficiency and minimizing downtime. This paper introduces a failure detection algorithm based on quantum computing and a statistical change-point detection approach. Our method leverages the potential of projected quantum feature maps to enhance the precision of anomaly detection in machine monitoring systems. We empirically validate our approach on benchmark multi-dimensional time series datasets as well as on a real-world dataset comprising IoT sensor readings from operational machines, ensuring the practical relevance of our study. The algorithm was executed on IBM's 133-qubit Heron quantum processor, demonstrating the feasibility of integrating quantum computing into industrial maintenance procedures. The presented results underscore the effectiveness of our quantum-based failure detection system, showcasing its capability to accurately identify anomalies in noisy time series data. This work not only highlights the potential of quantum computing in industrial diagnostics but also paves the way for more sophisticated quantum algorithms in the realm of predictive maintenance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15641v1</guid></item><item><title>[cs updates on arXiv.org] A Stabilized Hybrid Active Noise Control Algorithm of GFANC and FxNLMS with Online Clustering</title><link>https://arxiv.org/abs/2601.15889</link><description>arXiv:2601.15889v1 Announce Type: cross 
Abstract: The Filtered-x Normalized Least Mean Square (FxNLMS) algorithm suffers from slow convergence and a risk of divergence, although it can achieve low steady-state errors after sufficient adaptation. In contrast, the Generative Fixed-Filter Active Noise Control (GFANC) method offers fast response speed, but its lack of adaptability may lead to large steady-state errors. This paper proposes a hybrid GFANC-FxNLMS algorithm to leverage the complementary advantages of both approaches. In the hybrid GFANC-FxNLMS algorithm, GFANC provides a frame-level control filter as an initialization for FxNLMS, while FxNLMS performs continuous adaptation at the sampling rate. Small variations in the GFANC-generated filter may repeatedly reinitialize FxNLMS, interrupting its adaptation process and destabilizing the system. An online clustering module is introduced to avoid unnecessary re-initializations and improve system stability. Simulation results show that the proposed algorithm achieves fast response, very low steady-state error, and high stability, requiring only one pre-trained broadband filter.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15889v1</guid></item><item><title>[cs updates on arXiv.org] Progressive Power Homotopy for Non-convex Optimization</title><link>https://arxiv.org/abs/2601.15915</link><description>arXiv:2601.15915v1 Announce Type: cross 
Abstract: We propose a novel first-order method for non-convex optimization of the form $\max_{\bm{w}\in\mathbb{R}^d}\mathbb{E}_{\bm{x}\sim\mathcal{D}}[f_{\bm{w}}(\bm{x})]$, termed Progressive Power Homotopy (Prog-PowerHP). The method applies stochastic gradient ascent to a surrogate objective obtained by first performing a power transformation and then Gaussian smoothing, $F_{N,\sigma}(\bm{\mu}):=\mathbb{E}_{\bm{w}\sim\mathcal{N}(\bm{\mu},\sigma^2I_d),\bm{x}\sim\mathcal{D}}[e^{Nf_w(\bm{x})}]$, while progressively increasing the power parameter $N$ and decreasing the smoothing scale $\sigma$ along the optimization trajectory. We prove that, under mild regularity conditions, Prog-PowerHP converges to a small neighborhood of the global optimum with an iteration complexity scaling nearly as $O(d^2\varepsilon^{-2})$. Empirically, Prog-PowerHP demonstrates clear advantages in phase retrieval when the samples-to-dimension ratio approaches the information-theoretic limit, and in training two-layer neural networks in under-parameterized regimes. These results suggest that Prog-PowerHP is particularly effective for navigating cluttered non-convex landscapes where standard first-order methods struggle.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15915v1</guid></item><item><title>[cs updates on arXiv.org] An Efficient Algorithm to Generate all Labeled Triangle-free Graphs with a given Graphical Degree Sequence</title><link>https://arxiv.org/abs/2601.15943</link><description>arXiv:2601.15943v1 Announce Type: cross 
Abstract: We extend our previous algorithm that generates all labeled graphs with a given graphical degree sequence to generate all labeled triangle-free graphs with a given graphical degree sequence. The algorithm uses various pruning techniques to avoid having to first generate all labeled realizations of the input sequence and then testing whether each labeled realization is triangle-free. It can be further extended to generate all labeled bipartite graphs with a given graphical degree sequence by adding a simple test whether each generated triangle-free realization is a bipartite graph. All output graphs are generated in the lexicographical ordering as in the original algorithm. The algorithms can also be easily parallelized.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15943v1</guid></item><item><title>[cs updates on arXiv.org] Performance Scaling Laws for PD Array-based Receivers in IM/DD Optical Wireless Communication Systems</title><link>https://arxiv.org/abs/2601.15973</link><description>arXiv:2601.15973v1 Announce Type: cross 
Abstract: We study the performance scaling laws for electrical-domain combining in photodetector (PD) array-based receivers employing intensity modulation and direct detection, taking into account the inherent square-law relationship between the optical and electrical received powers. The performance of PD array-based systems is compared, in terms of signal-to-noise ratio (SNR) and achievable rate, to that of a reference receiver employing a single PD. Analytical and numerical results show that PD arrays provide performance gains for sufficiently narrow beams and above an SNR threshold. Furthermore, increasing the number of PDs alone does not enhance performance, and joint optimization of beam pattern, transverse electromagnetic mode, received power, and PD positions is necessary. Our model and derived insights provide practical guidelines and highlight the trade-offs for the design of next-generation high-bandwidth PD array receivers.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15973v1</guid></item><item><title>[cs updates on arXiv.org] Time-Optimal Switching Surfaces for Triple Integrator under Full Box Constraints</title><link>https://arxiv.org/abs/2601.16003</link><description>arXiv:2601.16003v1 Announce Type: cross 
Abstract: Time-optimal control for triple integrator under full box constraints is a fundamental problem in the field of optimal control, which has been widely applied in the industry. However, scenarios involving asymmetric constraints, non-stationary boundary conditions, and active position constraints pose significant challenges. This paper provides a complete characterization of time-optimal switching surfaces for the problem, leading to novel insights into the geometric and algebraic structure of the optimal control. The active condition of position constraints is derived, which is absent from the literature. An efficient algorithm is proposed, capable of planning time-optimal trajectories under asymmetric full constraints and arbitrary boundary states, with a 100% success rate. Computational time for each trajectory is within approximately 10{\mu}s, achieving a 5-order-of-magnitude reduction compared to optimization-based baselines.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16003v1</guid></item><item><title>[cs updates on arXiv.org] Wigner's Friend as a Circuit: Inter-Branch Communication Witness Benchmarks on Superconducting Quantum Hardware</title><link>https://arxiv.org/abs/2601.16004</link><description>arXiv:2601.16004v1 Announce Type: cross 
Abstract: We implement and benchmark on IBM Quantum hardware the circuit family proposed by Violaris for estimating operational inter-branch communication witnesses, defined as correlations in classical measurement records produced by compiled Wigner's-friend-style circuits. We realize a five-qubit instance of the protocol as an inter-register message-transfer pattern within a single circuit, rather than physical signaling, and evaluate its behavior under realistic device noise and compilation constraints. The circuit encodes branch-conditioned evolution of an observer subsystem whose dynamics depend on a control qubit, followed by a controlled transfer operation that probes correlations between conditional measurement contexts.
  Executing on the ibm_fez backend with 20000 shots, we observe population-based visibility of 0.877, coherence witnesses of 0.840 and -0.811 along orthogonal axes, and a phase-sensitive magnitude of approximately 1.17. While the visibility metric is insensitive to some classes of dephasing, the coherence witnesses provide complementary sensitivity to off-diagonal noise.
  This work does not test or discriminate among interpretations of quantum mechanics. Instead, it provides a reproducible operational constraint pipeline for evaluating detectability of non-ideal channels relative to calibrated device noise.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16004v1</guid></item><item><title>[cs updates on arXiv.org] THOR: A Versatile Foundation Model for Earth Observation Climate and Society Applications</title><link>https://arxiv.org/abs/2601.16011</link><description>arXiv:2601.16011v1 Announce Type: cross 
Abstract: Current Earth observation foundation models are architecturally rigid, struggle with heterogeneous sensors and are constrained to fixed patch sizes. This limits their deployment in real-world scenarios requiring flexible computeaccuracy trade-offs. We propose THOR, a "computeadaptive" foundation model that solves both input heterogeneity and deployment rigidity. THOR is the first architecture to unify data from Copernicus Sentinel-1, -2, and -3 (OLCI &amp; SLSTR) satellites, processing their native 10 m to 1000 m resolutions in a single model. We pre-train THOR with a novel randomized patch and input image size strategy. This allows a single set of pre-trained weights to be deployed at inference with any patch size, enabling a dynamic trade-off between computational cost and feature resolution without retraining. We pre-train THOR on THOR Pretrain, a new, large-scale multi-sensor dataset and demonstrate state-of-the-art performance on downstream benchmarks, particularly in data-limited regimes like the PANGAEA 10% split, validating that THOR's flexible feature generation excels for diverse climate and society applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16011v1</guid></item><item><title>[cs updates on arXiv.org] Timbre-Aware LLM-based Direct Speech-to-Speech Translation Extendable to Multiple Language Pairs</title><link>https://arxiv.org/abs/2601.16023</link><description>arXiv:2601.16023v1 Announce Type: cross 
Abstract: Direct Speech-to-Speech Translation (S2ST) has gained increasing attention for its ability to translate speech from one language to another, while reducing error propagation and latency inherent in traditional cascaded pipelines. However, existing direct S2ST systems continue to face notable challenges, including instability in semantic-acoustic alignment when parallel speech data is scarce, difficulty in preserving speaker identity, and limited multilingual scalability. In this work, we introduce DS2ST-LM, a scalable, single-stage direct S2ST framework leveraging a multilingual Large Language Model (LLM). The architecture integrates a Whisper speech encoder, a learnable projection module, a Qwen2-0.5B LLM, and a timbre-controlled vocoder. We construct GigaS2S-1000, a 1000-hour bilingual corpus by extending the GigaST dataset with high-fidelity synthetic target speech, and show that this synthetic data alleviates data scarcity to some extent. We investigate two semantic token generation strategies: speech-derived S3 tokens and text-derived tokens generated by a pre-trained LLM, and analyze their impact on training stability and semantic consistency. We further evaluate three projection architectures (Linear, Conv1D-Linear, and Q-Former) and observe that while higher-capacity projectors converge faster, the simple Linear projector achieves higher performance. Extensive experiments demonstrate that DS2ST-LM outperforms traditional cascaded and ST (Qwen-Audio) + TTS baselines across both lexical (BLEU, METEOR) and semantic (BLEURT, COMET) metrics, while extending to multiple language pairs, including French, Spanish, German, Hindi, Bengali, and Urdu. Furthermore, we incorporate timbre-aware speech synthesis to preserve speaker information, enabling DS2ST-LM to surpass prior direct S2ST systems in both speaker similarity and perceptual naturalness.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16023v1</guid></item><item><title>[cs updates on arXiv.org] Risk reversal for least squares estimators under nested convex constraints</title><link>https://arxiv.org/abs/2601.16041</link><description>arXiv:2601.16041v1 Announce Type: cross 
Abstract: In constrained stochastic optimization, one naturally expects that imposing a stricter feasible set does not increase the statistical risk of an estimator defined by projection onto that set. In this paper, we show that this intuition can fail even in canonical settings.
  We study the Gaussian sequence model, a deliberately austere test best, where for a compact, convex set $\Theta \subset \mathbb{R}^d$ one observes \[ Y = \theta^\star + \sigma Z, \qquad Z \sim N(0, I_d), \] and seeks to estimate an unknown parameter $\theta^\star \in \Theta$. The natural estimator is the least squares estimator (LSE), which coincides with the Euclidean projection of $Y$ onto $\Theta$. We construct an explicit example exhibiting \emph{risk reversal}: for sufficiently large noise, there exist nested compact convex sets $\Theta_S \subset \Theta_L$ and a parameter $\theta^\star \in \Theta_S$ such that the LSE constrained to $\Theta_S$ has strictly larger risk than the LSE constrained to $\Theta_L$. We further show that this phenomenon can persist at the level of worst-case risk, with the supremum risk over the smaller constraint set exceeding that over the larger one.
  We clarify this behavior by contrasting noise regimes. In the vanishing-noise limit, the risk admits a first-order expansion governed by the statistical dimension of the tangent cone at $\theta^\star$, and tighter constraints uniformly reduce risk. In contrast, in the diverging-noise regime, the risk is determined by global geometric interactions between the constraint set and random noise directions. Here, the embedding of $\Theta_S$ within $\Theta_L$ can reverse the risk ordering.
  These results reveal a previously unrecognized failure mode of projection-based estimators: in sufficiently noisy settings, tightening a constraint can paradoxically degrade statistical performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16041v1</guid></item><item><title>[cs updates on arXiv.org] Phi-SegNet: Phase-Integrated Supervision for Medical Image Segmentation</title><link>https://arxiv.org/abs/2601.16064</link><description>arXiv:2601.16064v1 Announce Type: cross 
Abstract: Deep learning has substantially advanced medical image segmentation, yet achieving robust generalization across diverse imaging modalities and anatomical structures remains a major challenge. A key contributor to this limitation lies in how existing architectures, ranging from CNNs to Transformers and their hybrids, primarily encode spatial information while overlooking frequency-domain representations that capture rich structural and textural cues. Although few recent studies have begun exploring spectral information at the feature level, supervision-level integration of frequency cues-crucial for fine-grained object localization-remains largely untapped. To this end, we propose Phi-SegNet, a CNN-based architecture that incorporates phase-aware information at both architectural and optimization levels. The network integrates Bi-Feature Mask Former (BFMF) modules that blend neighboring encoder features to reduce semantic gaps, and Reverse Fourier Attention (RFA) blocks that refine decoder outputs using phase-regularized features. A dedicated phase-aware loss aligns these features with structural priors, forming a closed feedback loop that emphasizes boundary precision. Evaluated on five public datasets spanning X-ray, US, histopathology, MRI, and colonoscopy, Phi-SegNet consistently achieved state-of-the-art performance, with an average relative improvement of 1.54+/-1.26% in IoU and 0.98+/-0.71% in F1-score over the next best-performing model. In cross-dataset generalization scenarios involving unseen datasets from the known domain, Phi-SegNet also exhibits robust and superior performance, highlighting its adaptability and modality-agnostic design. These findings demonstrate the potential of leveraging spectral priors in both feature representation and supervision, paving the way for generalized segmentation frameworks that excel in fine-grained object localization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16064v1</guid></item><item><title>[cs updates on arXiv.org] On damage of interpolation to adversarial robustness in regression</title><link>https://arxiv.org/abs/2601.16070</link><description>arXiv:2601.16070v1 Announce Type: cross 
Abstract: Deep neural networks (DNNs) typically involve a large number of parameters and are trained to achieve zero or near-zero training error. Despite such interpolation, they often exhibit strong generalization performance on unseen data, a phenomenon that has motivated extensive theoretical investigations. Comforting results show that interpolation indeed may not affect the minimax rate of convergence under the squared error loss. In the mean time, DNNs are well known to be highly vulnerable to adversarial perturbations in future inputs. A natural question then arises: Can interpolation also escape from suboptimal performance under a future $X$-attack? In this paper, we investigate the adversarial robustness of interpolating estimators in a framework of nonparametric regression. A finding is that interpolating estimators must be suboptimal even under a subtle future $X$-attack, and achieving perfect fitting can substantially damage their robustness. An interesting phenomenon in the high interpolation regime, which we term the curse of simple size, is also revealed and discussed. Numerical experiments support our theoretical findings.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16070v1</guid></item><item><title>[cs updates on arXiv.org] Synthetic Augmentation in Imbalanced Learning: When It Helps, When It Hurts, and How Much to Add</title><link>https://arxiv.org/abs/2601.16120</link><description>arXiv:2601.16120v1 Announce Type: cross 
Abstract: Imbalanced classification, where one class is observed far less frequently than the other, often causes standard training procedures to prioritize the majority class and perform poorly on rare but important cases. A classic and widely used remedy is to augment the minority class with synthetic examples, but two basic questions remain under-resolved: when does synthetic augmentation actually help, and how many synthetic samples should be generated?
  We develop a unified statistical framework for synthetic augmentation in imbalanced learning, studying models trained on imbalanced data augmented with synthetic minority samples and evaluated under the balanced population risk. Our theory shows that synthetic data is not always beneficial. In a ``local symmetry" regime, imbalance is not the dominant source of error near the balanced optimum, so adding synthetic samples cannot improve learning rates and can even degrade performance by amplifying generator mismatch. When augmentation can help (a ``local asymmetry" regime), the optimal synthetic size depends on generator accuracy and on whether the generator's residual mismatch is directionally aligned with the intrinsic majority-minority shift. This structure can make the best synthetic size deviate from naive full balancing, sometimes by a small refinement and sometimes substantially when generator bias is systematic. Practically, we recommend Validation-Tuned Synthetic Size (VTSS): select the synthetic size by minimizing balanced validation loss over a range centered near the fully balanced baseline, while allowing meaningful departures when the data indicate them. Simulations and a real sepsis prediction study support the theory and illustrate when synthetic augmentation helps, when it cannot, and how to tune its quantity effectively.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16120v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Predictive Uncertainty: Reliable Representation Learning with Structural Constraints</title><link>https://arxiv.org/abs/2601.16174</link><description>arXiv:2601.16174v1 Announce Type: cross 
Abstract: Uncertainty estimation in machine learning has traditionally focused on the prediction stage, aiming to quantify confidence in model outputs while treating learned representations as deterministic and reliable by default. In this work, we challenge this implicit assumption and argue that reliability should be regarded as a first-class property of learned representations themselves. We propose a principled framework for reliable representation learning that explicitly models representation-level uncertainty and leverages structural constraints as inductive biases to regularize the space of feasible representations. Our approach introduces uncertainty-aware regularization directly in the representation space, encouraging representations that are not only predictive but also stable, well-calibrated, and robust to noise and structural perturbations. Structural constraints, such as sparsity, relational structure, or feature-group dependencies, are incorporated to define meaningful geometry and reduce spurious variability in learned representations, without assuming fully correct or noise-free structure. Importantly, the proposed framework is independent of specific model architectures and can be integrated with a wide range of representation learning methods.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16174v1</guid></item><item><title>[cs updates on arXiv.org] A Rolling-Space Branch-and-Price Algorithm for the Multi-Compartment Vehicle Routing Problem with Multiple Time Windows</title><link>https://arxiv.org/abs/2601.16194</link><description>arXiv:2601.16194v1 Announce Type: cross 
Abstract: This paper investigates the multi-compartment vehicle routing problem with multiple time windows (MCVRPMTW), an extension of the classical vehicle routing problem with time windows that considers vehicles equipped with multiple compartments and customers requiring service across several delivery time windows. The problem incorporates three key compartment-related features: (i) compartment flexibility in the number of compartments, (ii) item-to-compartment compatibility, and (iii) item-to-item compatibility. The problem also accommodates practical operational requirements such as driver breaks. To solve the MCVRPMTW, we develop an exact branch-and-price (B&amp;amp;P) algorithm in which the pricing problem is solved using a labeling algorithm. Several acceleration strategies are introduced to limit symmetry during label extensions, improve the stability of dual solutions in column generation, and enhance the branching process. To handle large-scale instances, we propose a rolling-space B&amp;amp;P algorithm that integrates clustering techniques into the solution framework. Extensive computational experiments on instances inspired by a real-world industrial application demonstrate the effectiveness of the proposed approach and provide useful managerial insights for practical implementation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16194v1</guid></item><item><title>[cs updates on arXiv.org] Representation-Driven Reinforcement Learning</title><link>https://arxiv.org/abs/2305.19922</link><description>arXiv:2305.19922v3 Announce Type: replace 
Abstract: We present a representation-driven framework for reinforcement learning. By representing policies as estimates of their expected values, we leverage techniques from contextual bandits to guide exploration and exploitation. Particularly, embedding a policy network into a linear feature space allows us to reframe the exploration-exploitation problem as a representation-exploitation problem, where good policy representations enable optimal exploration. We demonstrate the effectiveness of this framework through its application to evolutionary and policy gradient-based approaches, leading to significantly improved performance compared to traditional methods. Our framework provides a new perspective on reinforcement learning, highlighting the importance of policy representation in determining optimal exploration-exploitation strategies.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2305.19922v3</guid></item><item><title>[cs updates on arXiv.org] Multi-event Video-Text Retrieval</title><link>https://arxiv.org/abs/2308.11551</link><description>arXiv:2308.11551v3 Announce Type: replace 
Abstract: Video-Text Retrieval (VTR) is a crucial multi-modal task in an era of massive video-text data on the Internet. A plethora of work characterized by using a two-stream Vision-Language model architecture that learns a joint representation of video-text pairs has become a prominent approach for the VTR task. However, these models operate under the assumption of bijective video-text correspondences and neglect a more practical scenario where video content usually encompasses multiple events, while texts like user queries or webpage metadata tend to be specific and correspond to single events. This establishes a gap between the previous training objective and real-world applications, leading to the potential performance degradation of earlier models during inference. In this study, we introduce the Multi-event Video-Text Retrieval (MeVTR) task, addressing scenarios in which each video contains multiple different events, as a niche scenario of the conventional Video-Text Retrieval Task. We present a simple model, Me-Retriever, which incorporates key event video representation and a new MeVTR loss for the MeVTR task. Comprehensive experiments show that this straightforward framework outperforms other models in the Video-to-Text and Text-to-Video tasks, effectively establishing a robust baseline for the MeVTR task. We believe this work serves as a strong foundation for future studies. Code is available at https://github.com/gengyuanmax/MeVTR.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2308.11551v3</guid></item><item><title>[cs updates on arXiv.org] Strategic forecasting of internet of things technologies through patent social network and innovation cluster analysis</title><link>https://arxiv.org/abs/2309.00707</link><description>arXiv:2309.00707v2 Announce Type: replace 
Abstract: The rapid proliferation of Internet of Things (IoT) technologies necessitates robust forecasting mechanisms to guide strategic decision-making amid increasingly complex innovation landscapes. Despite extensive research employing patent analysis for technology forecasting, existing studies lack systematic integration of social network analysis, advanced text mining, and life cycle modeling to comprehensively map IoT technological evolution and collaborative dynamics. This study addresses these gaps by analyzing 154,227 IoT-related patents through a unified methodological framework combining BERT-based text embeddings, k-means clustering with Davies-Bouldin optimization, S-curve life cycle modeling, and Louvain community detection. The analysis identified nine distinct technology clusters spanning foundational infrastructure (Smart Monitoring and Sensor Systems, Network Communication and Data Transmission) to domain-specific applications (Agricultural IoT, Connected Vehicle Technologies). Life cycle assessment revealed temporal convergence, with eight clusters reaching saturation between 2023 and 2027, reflecting ecosystem-wide synchronization driven by standardization imperatives, platform consolidation, and pandemic-accelerated digital transformation. Social network analysis uncovered five major collaborative communities exhibiting divergent strategic orientations: from extreme specialization (Global Telecommunications Technology Leaders: 87.7% network communication focus) to diversified portfolios (China State Grid IoT Consortium: balanced infrastructure investment). Cross-analysis revealed complementary innovation strategies where infrastructure operators pursue breadth, telecommunications specialists maintain focused expertise, and academic researchers emphasize development-aligned agendas.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2309.00707v2</guid></item><item><title>[cs updates on arXiv.org] Multi-Layered Reasoning from a Single Viewpoint for Learning See-Through Grasping</title><link>https://arxiv.org/abs/2312.09822</link><description>arXiv:2312.09822v5 Announce Type: replace 
Abstract: Sensory substitution enables biological systems to perceive stimuli that are typically perceived by another organ, which is inspirational for physical agents. Multimodal perception of intrinsic and extrinsic interactions is critical in building an intelligent robot that learns. This study presents a Vision-based See-Through Perception (VBSeeThruP) architecture that simultaneously perceives multiple intrinsic and extrinsic modalities from a single visual input, in a markerless manner, all packed into a soft robotic finger using the Soft Polyhedral Network design. It is generally applicable to miniature vision systems placed beneath deformable networks with a see-through design, capturing real-time images of the network's physical interactions induced by contact-based events, overlaid on the visual scene of the external environment, as demonstrated in the ablation study. We present the VBSeeThruP's capability for learning reactive grasping without using external cameras or dedicated force and torque sensors on the fingertips. Using the inpainted scene and the deformation mask, we further demonstrate the multimodal performance of the VBSeeThruP architecture to simultaneously achieve various perceptions, including but not limited to scene inpainting, object detection, depth sensing, scene segmentation, masked deformation tracking, 6D force/torque sensing, and contact event detection, all within a single sensory input from the in-finger vision markerlessly.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2312.09822v5</guid></item><item><title>[cs updates on arXiv.org] Paramanu: Compact and Competitive Monolingual Language Models for Low-Resource Morphologically Rich Indian Languages</title><link>https://arxiv.org/abs/2401.18034</link><description>arXiv:2401.18034v3 Announce Type: replace 
Abstract: Multilingual large language models (LLMs) are expensive to pretrain and often suffer from imbalances across languages and datasets, English-centric bias, tokenizer oversegmentation for morphologically rich low-resource languages, and the curse of multilinguality. We introduce PARAMANU, the first family of Indian-only autoregressive language models trained from scratch on open-source language-specific data for the five most spoken Indian languages: Bengali, Hindi, Marathi, Tamil, and Telugu. All models are designed for affordability and are trained on a single GPU with a budget under $1,000, allowing under-resourced researchers to build competitive language models. To address low-resource challenges, we develop morphology-aligned, low-fertility tokenizers, propose an interpolation-based method for token position indices in RoPE based scaling to train longer sequences efficiently. We also create instruction-tuning datasets in Bangla that are translated to the other four languages. Despite their small size (108M-367M parameters), Paramanu achieves a strong performance-efficiency tradeoff and outperforms most larger multilingual models across all five languages. Our collection is available at https://huggingface.co/collections/mitodru/paramanu.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2401.18034v3</guid></item><item><title>[cs updates on arXiv.org] Scalable Multi-view Clustering via Explicit Kernel Features Maps</title><link>https://arxiv.org/abs/2402.04794</link><description>arXiv:2402.04794v2 Announce Type: replace 
Abstract: The proliferation of high-dimensional data from sources such as social media, sensor networks, and online platforms has created new challenges for clustering algorithms. Multi-view clustering, which integrates complementary information from multiple data perspectives, has emerged as a powerful solution. However, existing methods often struggle with scalability and efficiency, particularly on large attributed networks. In this work, we address these limitations by leveraging explicit kernel feature maps and a non-iterative optimization strategy, enabling efficient and accurate clustering on datasets with millions of points.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2402.04794v2</guid></item><item><title>[cs updates on arXiv.org] Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes</title><link>https://arxiv.org/abs/2402.05406</link><description>arXiv:2402.05406v4 Announce Type: replace 
Abstract: Structured pruning is a promising approach to create smaller, faster large language models. However, existing methods typically rely on computing the gradient via backward passes, which can inflate memory requirements and compute costs. In this work we introduce Bonsai, a gradient-free structured pruning method that eliminates the need for backpropagation, significantly reducing memory requirements and compute costs while achieving state-of-the-art pruning performance. Bonsai uses forward-pass-only perturbative pruning to enable efficient compression of large models on a broader range of hardware configurations. Unlike existing structured pruning approaches, Bonsai not only achieves better compression with fewer resources but also produces models that are twice as fast as those generated by semi-structured pruning. As a concrete demonstration, we use Bonsai to prune 7B and 8B models to 50% sparsity on a single A6000 GPU -- a task challenging for backprop-based methods in memory-constrained settings, as they require 2-3x the memory. Our results show that removing backprop as a requirement not only enables pruning larger models on constrained hardware but can also lead to state-of-the-art efficiency and performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2402.05406v4</guid></item><item><title>[cs updates on arXiv.org] Thought of Search: Planning with Language Models Through The Lens of Efficiency</title><link>https://arxiv.org/abs/2404.11833</link><description>arXiv:2404.11833v3 Announce Type: replace 
Abstract: Among the most important properties of algorithms investigated in computer science are soundness, completeness, and complexity. These properties, however, are rarely analyzed for the vast collection of recently proposed methods for planning with large language models. In this work, we alleviate this gap. We analyse these properties of using LLMs for planning and highlight that recent trends abandon both soundness and completeness for the sake of inefficiency. We propose a significantly more efficient approach that can, at the same time, maintain both soundness and completeness. We exemplify on four representative search problems, comparing to the LLM-based solutions from the literature that attempt to solve these problems. We show that by using LLMs to produce the code for the search components we can solve the entire datasets with 100\% accuracy with only a few calls to the LLM. We argue for a responsible use of compute resources; urging research community to investigate sound and complete LLM-based approaches that uphold efficiency.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2404.11833v3</guid></item><item><title>[cs updates on arXiv.org] Sign Language-Based versus Touch-Based Input for Deaf Users with Interactive Personal Assistants in Simulated Kitchen Environments</title><link>https://arxiv.org/abs/2404.14610</link><description>arXiv:2404.14610v2 Announce Type: replace 
Abstract: In this study, we assess the usability of interactive personal assistants (IPAs), such as Amazon Alexa, in a simulated kitchen smart home environment, with deaf and hard of hearing users. Participants engage in activities in a way that causes their hands to get dirty. With these dirty hands, they are tasked with two different input methods for IPAs: American Sign Language (ASL) in a Wizard-of-Oz design, and smart home apps with a touchscreen. Usability ratings show that participants significantly preferred ASL over touch-based apps with dirty hands, although not to a larger extent than in comparable previous work with clean hands. Participants also expressed significant enthusiasm for ASL-based IPA interaction in Netpromoter scores and in questions about their overall preferences. Preliminary observations further suggest that having dirty hands may affect the way people sign, which may pose challenges for building IPAs that natively support sign language input.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2404.14610v2</guid></item><item><title>[cs updates on arXiv.org] Efficient Multimodal Large Language Models: A Survey</title><link>https://arxiv.org/abs/2405.10739</link><description>arXiv:2405.10739v3 Announce Type: replace 
Abstract: In the past year, Multimodal Large Language Models (MLLMs) have demonstrated remarkable performance in tasks such as visual question answering, visual understanding and reasoning. However, the extensive model size and high training and inference costs have hindered the widespread application of MLLMs in academia and industry. Thus, studying efficient and lightweight MLLMs has enormous potential, especially in edge computing scenarios. In this survey, we provide a comprehensive and systematic review of the current state of efficient MLLMs. Specifically, we summarize the timeline of representative efficient MLLMs, research state of efficient structures and strategies, and the applications. Finally, we discuss the limitations of current efficient MLLM research and promising future directions. Please refer to our GitHub repository for more details: https://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2405.10739v3</guid></item><item><title>[cs updates on arXiv.org] Neural Green's Operators for Parametric Partial Differential Equations</title><link>https://arxiv.org/abs/2406.01857</link><description>arXiv:2406.01857v5 Announce Type: replace 
Abstract: This work introduces a paradigm for constructing parametric neural operators that are derived from finite-dimensional representations of Green's operators for linear partial differential equations (PDEs). We refer to such neural operators as Neural Green's Operators (NGOs). Our construction of NGOs preserves the linear action of Green's operators on the inhomogeneity fields, while approximating the nonlinear dependence of the Green's function on the coefficients of the PDE using neural networks. This construction reduces the complexity of the problem from learning the entire solution operator and its dependence on all parameters to only learning the Green's function and its dependence on the PDE coefficients. Furthermore, we show that our explicit representation of Green's functions enables the embedding of desirable mathematical attributes in our NGO architectures, such as symmetry, spectral, and conservation properties. Through numerical benchmarks on canonical PDEs, we demonstrate that NGOs achieve comparable or superior accuracy to Deep Operator Networks, Variationally Mimetic Operator Networks, and Fourier Neural Operators with similar parameter counts, while generalizing significantly better when tested on out-of-distribution data. For parametric time-dependent PDEs, we show that NGOs that are trained on a single time step can produce pointwise-accurate dynamics in an auto-regressive manner over arbitrarily large numbers of time steps. For parametric nonlinear PDEs, we demonstrate that NGOs trained exclusively on solutions of corresponding linear problems can be embedded within iterative solvers to yield accurate solutions, provided a suitable initial guess is available. Finally, we show that we can leverage the explicit representation of Green's functions returned by NGOs to construct effective matrix preconditioners that accelerate iterative solvers for PDEs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2406.01857v5</guid></item><item><title>[cs updates on arXiv.org] A Comprehensive Study on Large Language Models for Mutation Testing</title><link>https://arxiv.org/abs/2406.09843</link><description>arXiv:2406.09843v5 Announce Type: replace 
Abstract: Large Language Models (LLMs) have recently been used to generate mutants in both research work and in industrial practice. However, there has been no comprehensive empirical study of their performance for this increasingly important LLM-based Software Engineering application. To address this, we conduct a comprehensive empirical study evaluating BugFarm and LLMorpheus (the two state-of-the-art LLM-based approaches), alongside seven LLMs using our newly designed prompt, including both leading open- and closed-source models, on 851 real bugs from two Java real-world bug benchmarks. Our results reveal that, compared to existing rule-based approaches, LLMs generate more diverse mutants, that are behaviorally closer to real bugs and, most importantly, with 111.29% higher fault detection. That is, 87.98% (for LLMs) vs. 41.64% (for rule-based); an increase of 46.34 percentage points. Nevertheless, our results also reveal that these impressive results for improved effectiveness come at a cost: the LLM-generated mutants have worse non-compilability, duplication, and equivalent mutant rates by 26.60, 10.14, and 3.51 percentage points, respectively. These findings are immediately actionable for both research and practice. They allow practitioners to have greater confidence in deploying LLM-based mutation, while researchers now have a baseline for the state-of-the-art, with which they can research techniques to further improve effectiveness and reduce cost.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2406.09843v5</guid></item><item><title>[cs updates on arXiv.org] On the Exponential Convergence for Offline RLHF with Pairwise Comparisons</title><link>https://arxiv.org/abs/2406.12205</link><description>arXiv:2406.12205v2 Announce Type: replace 
Abstract: We consider the problem of offline reinforcement learning from human feedback (RLHF) with pairwise comparisons proposed by Zhu et al. (2023), where the implicit reward is a linear function of an unknown parameter. Given an offline dataset, our objective consists in ascertaining the optimal action for each state, with the ultimate goal of minimizing the {\em simple regret}. We propose an algorithm, \underline{RL} with \underline{L}ocally \underline{O}ptimal \underline{W}eights or {\sc RL-LOW}, which yields an exponential form of simple regret of $\exp ( - \Omega(n/H) )$ where $n$ is the number of data samples and $H$ denotes an instance-dependent hardness quantity that depends explicitly on the suboptimality gap of each action. Furthermore, we derive a first-of-its-kind instance-dependent lower bound in offline RLHF with pairwise comparisons. Interestingly, we observe that the lower and upper bounds on the simple regret match order-wise in the exponent, demonstrating order-wise optimality of our {\sc RL-LOW}. In view of privacy considerations in practical applications, we also extend {\sc RL-LOW} to the setting of $(\varepsilon,\delta)$-differential privacy and show, somewhat surprisingly, that the hardness parameter $H$ is unchanged in the asymptotic regime as $n$ tends to infinity; this underscores the inherent efficiency of {\sc RL-LOW} in terms of preserving the privacy of the observed rewards. Given our focus on establishing instance-dependent bounds of exponential convergence, our research fills the research gap in existing studies that concentrate on establishing worst-case regrets of {\em inverse polynomial convergence} (e.g., $\widetilde{O}(\frac{1}{\sqrt{n}})$) for offline RLHF with pairwise comparisons.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2406.12205v2</guid></item><item><title>[cs updates on arXiv.org] Vision-Language Models Align with Human Neural Representations in Concept Processing</title><link>https://arxiv.org/abs/2407.17914</link><description>arXiv:2407.17914v3 Announce Type: replace 
Abstract: Recent studies suggest that transformer-based vision-language models (VLMs) capture the multimodality of concept processing in the human brain. However, a systematic evaluation exploring different types of VLM architectures and the role played by visual and textual context is still lacking. Here, we analyse multiple VLMs employing different strategies to integrate visual and textual modalities, along with language-only counterparts. We measure the alignment between concept representations by models and existing (fMRI) brain responses to concept words presented in two experimental conditions, where either visual (pictures) or textual (sentences) context is provided. Our results reveal that VLMs outperform the language-only counterparts in both experimental conditions. However, controlled ablation studies show that only for some VLMs, such as LXMERT and IDEFICS2, brain alignment stems from genuinely learning more human-like concepts during pretraining, while others are highly sensitive to the context provided at inference. Additionally, we find that vision-language encoders are more brain-aligned than more recent, generative VLMs. Altogether, our study shows that VLMs align with human neural representations in concept processing, while highlighting differences among architectures. We open-source code and materials to reproduce our experiments at: https://github.com/dmg-illc/vl-concept-processing.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2407.17914v3</guid></item><item><title>[cs updates on arXiv.org] 120 Domain-Specific Languages for Security</title><link>https://arxiv.org/abs/2408.06219</link><description>arXiv:2408.06219v3 Announce Type: replace 
Abstract: Security engineering, from security requirements engineering to the implementation of cryptographic protocols, is often supported by domain-specific languages (DSLs). Unfortunately, a lack of knowledge about these DSLs, such as which security aspects are addressed and when, hinders their effective use and further research. This systematic literature review examines 120 security-oriented DSLs based on six research questions concerning security aspects and goals, language-specific characteristics, integration into the software development lifecycle (SDLC), and effectiveness of the DSLs. We observe a high degree of fragmentation, which leads to opportunities for integration. We also need to improve the usability and evaluation of security DSLs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2408.06219v3</guid></item><item><title>[cs updates on arXiv.org] Reinforcement Learning Compensated Model Predictive Control for Off-road Driving on Unknown Deformable Terrain</title><link>https://arxiv.org/abs/2408.09253</link><description>arXiv:2408.09253v2 Announce Type: replace 
Abstract: This study presents an Actor-Critic reinforcement learning Compensated Model Predictive Controller (AC2MPC) designed for high-speed, off-road autonomous driving on deformable terrains. Addressing the difficulty of modeling unknown tire-terrain interaction and ensuring real-time control feasibility and performance, this framework integrates deep reinforcement learning with a model predictive controller to manage unmodeled nonlinear dynamics. We evaluate the controller framework over constant and varying velocity profiles using high-fidelity simulator Project Chrono. Our findings demonstrate that our controller statistically outperforms standalone model-based and learning-based controllers over three unknown terrains that represent sandy deformable track, sandy and rocky track and cohesive clay-like deformable soil track. Despite varied and previously unseen terrain characteristics, this framework generalized well enough to track longitudinal reference speeds with the least error. Furthermore, this framework required significantly less training data compared to purely learning based controller, converging in fewer steps while delivering better performance. Even when under-trained, this controller outperformed the standalone controllers, highlighting its potential for safer and more efficient real-world deployment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2408.09253v2</guid></item><item><title>[cs updates on arXiv.org] Medal Matters: Probing LLMs' Failure Cases Through Olympic Rankings</title><link>https://arxiv.org/abs/2409.06518</link><description>arXiv:2409.06518v3 Announce Type: replace 
Abstract: Large language models (LLMs) have achieved remarkable success in natural language processing tasks, yet their internal knowledge structures remain poorly understood. This study examines these structures through the lens of historical Olympic medal tallies, evaluating LLMs on two tasks: (1) retrieving medal counts for specific teams and (2) identifying rankings of each team. While state-of-the-art LLMs excel in recalling medal counts, they struggle with providing rankings, highlighting a key difference between their knowledge organization and human reasoning. These findings shed light on the limitations of LLMs' internal knowledge integration and suggest directions for improvement. To facilitate further research, we release our code, dataset, and model outputs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2409.06518v3</guid></item><item><title>[cs updates on arXiv.org] How hard can it be? Quantifying MITRE attack campaigns with attack trees and cATM logic</title><link>https://arxiv.org/abs/2410.06692</link><description>arXiv:2410.06692v4 Announce Type: replace 
Abstract: The landscape of cyber threats grows more complex by the day. Advanced Persistent Threats carry out attack campaigns - e.g. operations Dream Job, Wocao, and WannaCry - against which cybersecurity practitioners must defend. To prioritise which of these to defend against, cybersecurity experts must be equipped with the right toolbox to evaluate the most threatening ones. In particular, they would strongly benefit from (a) an estimation of the likelihood values for each attack recorded in the wild, and (b) transparently operationalising these values to compare campaigns quantitatively. Security experts could then perform transparent and accountable quantitatively-informed decisions. Here we construct such a framework: (1) quantifying the likelihood of attack campaigns via data-driven procedures on the MITRE knowledge-base, (2) introducing a methodology for automatic modelling of MITRE intelligence data, that captures any attack campaign via template attack tree models, and (3) proposing an open-source tool to perform these comparisons based on the cATM logic. Finally, we quantify the likelihood of all MITRE Enterprise campaigns, and compare the likelihood of the Wocao and Dream Job MITRE campaigns - generated with our proposed approach - against manually-built attack tree models. We demonstrate how our methodology is substantially lighter in modelling effort, and capable of capturing all the quantitative relevant data.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2410.06692v4</guid></item><item><title>[cs updates on arXiv.org] FREYJA: Efficient Join Discovery in Data Lakes</title><link>https://arxiv.org/abs/2412.06637</link><description>arXiv:2412.06637v2 Announce Type: replace 
Abstract: Data lakes are massive repositories of raw and heterogeneous data, designed to meet the requirements of modern data storage. Nonetheless, this same philosophy increases the complexity of performing discovery tasks to find relevant data for subsequent processing. As a response to these growing challenges, we present FREYJA, a modern data discovery system capable of effectively exploring data lakes, aimed at finding candidates to perform joins and increase the number of attributes for downstream tasks. More precisely, we want to compute rankings that sort potential joins by their relevance. Modern mechanisms apply advanced table representation learning (TRL) techniques to yield accurate joins. Yet, this incurs high computational costs when dealing with elevated volumes of data. In contrast to the state-of-the-art, we adopt a novel notion of join quality tailored to data lakes, which leverages syntactic measurements while achieving accuracy comparable to that of TRL approaches. To obtain this metric in a scalable manner we train a general purpose predictive model. Predictions are based, rather than on large-scale datasets, on data profiles, succinct representations that capture the underlying characteristics of the data. Our experiments show that our system, FREYJA, matches the results of the state-of-the-art whilst reducing the execution times by several orders of magnitude.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.06637v2</guid></item><item><title>[cs updates on arXiv.org] Unexpected but informative: What fixation-related potentials tell us about the processing of confusing program code</title><link>https://arxiv.org/abs/2412.10099</link><description>arXiv:2412.10099v3 Announce Type: replace 
Abstract: As software pervades more and more areas of our professional and personal lives, there is an ever-increasing need to maintain software and for programmers to efficiently write and understand program code. In the first study of its kind, we analyze fixation-related potentials (FRPs) to explore the online processing of program code patterns that are confusing to programmers, but not to the computer (so-called atoms of confusion), and their underlying neurocognitive mechanisms in an ecologically valid setting. Relative to clean counterparts in program code without an atom of confusion, confusing code elicits a late frontal positivity of about 400 to 700 ms after first looking at the atom of confusion. This frontal positivity resembles an event-related potential (ERP) component found during natural language processing that is elicited by unexpected but plausible words in sentence context. Thus, we suggest that the brain engages similar neurocognitive mechanisms in response to unexpected and informative inputs in program code and in natural language. In both domains, these inputs update a comprehender's situation model, which is essential for information extraction from a quickly unfolding input. Our results have far-reaching implications for programming and pave the way for interdisciplinary collaborations between software engineering and psycholinguistics.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.10099v3</guid></item><item><title>[cs updates on arXiv.org] ViSymRe: Vision-guided Multimodal Symbolic Regression</title><link>https://arxiv.org/abs/2412.11139</link><description>arXiv:2412.11139v3 Announce Type: replace 
Abstract: Extracting simple mathematical expression from an observational dataset to describe complex natural phenomena is one of the core objectives of artificial intelligence (AI). This field is known as symbolic regression (SR). Traditional SR models are based on genetic programming (GP) or reinforcement learning (RL), facing well-known challenges, such as low efficiency and overfitting. Recent studies have integrated SR with large language models (LLMs), enabling fast zero-shot inference by learning mappings from millions of dataset-expression pairs. However, since the input and output are inherently different modalities, such models often struggle to converge effectively. In this paper, we introduce ViSymRe, a vision-guided multimodal SR model that incorporates the third resource, expression graph, to bridge the modality gap. Different from traditional multimodal models, ViSymRe is trained to extract vision, termed virtual vision, from datasets, without relying on the global availability of expression graphs, which addresses the essential challenge of visual SR, i.e., expression graphs are not available during inference. Evaluation results on multiple mainstream benchmarks show that ViSymRe achieves more competitive performance than the state-of-the-art dataset-only baselines. The expressions predicted by ViSymRe not only fit the dataset well but are also simple and structurally accurate, goals that SR models strive to achieve.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.11139v3</guid></item><item><title>[cs updates on arXiv.org] Language-guided Medical Image Segmentation with Target-informed Multi-level Contrastive Alignments</title><link>https://arxiv.org/abs/2412.13533</link><description>arXiv:2412.13533v3 Announce Type: replace 
Abstract: Medical image segmentation is a fundamental task in numerous medical engineering applications. Recently, language-guided segmentation has shown promise in medical scenarios where textual clinical reports are readily available as semantic guidance. Clinical reports contain diagnostic information provided by clinicians, which can provide auxiliary textual semantics to guide segmentation. However, existing language-guided segmentation methods neglect the inherent pattern gaps between image and text modalities, resulting in sub-optimal visual-language integration. Contrastive learning is a well-recognized approach to align image-text patterns, but it has not been optimized for bridging the pattern gaps in medical language-guided segmentation that relies primarily on medical image details to characterize the underlying disease/targets. Current contrastive alignment techniques typically align high-level global semantics without involving low-level localized target information, and thus cannot deliver fine-grained textual guidance on crucial image details. In this study, we propose a Target-informed Multi-level Contrastive Alignment framework (TMCA) to bridge image-text pattern gaps for medical language-guided segmentation. TMCA enables target-informed image-text alignments and fine-grained textual guidance by introducing: (i) a target-sensitive semantic distance module that utilizes target information for more granular image-text alignment modeling, (ii) a multi-level contrastive alignment strategy that directs fine-grained textual guidance to multi-scale image details, and (iii) a language-guided target enhancement module that reinforces attention to critical image regions based on the aligned image-text patterns. Extensive experiments on four public benchmark datasets demonstrate that TMCA enabled superior performance over state-of-the-art language-guided medical image segmentation methods.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.13533v3</guid></item><item><title>[cs updates on arXiv.org] Data-driven tool wear prediction in milling, based on a process-integrated single-sensor approach</title><link>https://arxiv.org/abs/2412.19950</link><description>arXiv:2412.19950v5 Announce Type: replace 
Abstract: Accurate tool wear prediction is essential for maintaining productivity and minimizing costs in machining. However, the complex nature of the tool wear process poses significant challenges to achieving reliable predictions. This study explores data-driven methods, in particular deep learning, for tool wear prediction. Traditional data-driven approaches often focus on a single process, relying on multi-sensor setups and extensive data generation, which limits generalization to new settings. Moreover, multi-sensor integration is often impractical in industrial environments. To address these limitations, this research investigates the transferability of predictive models using minimal training data, validated across two processes. Furthermore, it uses a simple setup with a single acceleration sensor to establish a low-cost data generation approach that facilitates the generalization of models to other processes via transfer learning. The study evaluates several machine learning models, including transformer-inspired convolutional neural networks (CNN), long short-term memory networks (LSTM), support vector machines (SVM), and decision trees, trained on different input formats such as feature vectors and short-time Fourier transform (STFT). The performance of the models is evaluated on two machines and on different amounts of training data, including scenarios with significantly reduced datasets, providing insight into their effectiveness under constrained data conditions. The results demonstrate the potential of specific models and configurations for effective tool wear prediction, contributing to the development of more adaptable and efficient predictive maintenance strategies in machining. Notably, the ConvNeXt model has an exceptional performance, achieving 99.1\% accuracy in identifying tool wear using data from only four milling tools operated until they are worn.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.19950v5</guid></item><item><title>[cs updates on arXiv.org] NP-Hard Lower Bound Complexity for Semantic Self-Verification</title><link>https://arxiv.org/abs/2501.15446</link><description>arXiv:2501.15446v2 Announce Type: replace 
Abstract: We model Semantic Self-Verification (SSV) as the problem of determining whether a statement accurately characterizes its own semantic properties within a given interpretive framework that formalizes a challenge in AI safety and fairness: can an AI system verify that it has correctly interpreted rules intended to govern its behavior? We prove that SSV, in this specification, is NP-complete by constructing a polynomial-time reduction from 3-Satisfiability (3-SAT). Our reduction maps a 3-SAT formula to an instance of SSV involving ambiguous terms with binary interpretations and semantic constraints derived from logical clauses. This establishes that even simplified forms of semantic self-verification should face computational barriers. The NP-complete lower bound has implications for AI safety and fairness approaches that rely on semantic interpretation of instructions, including but not limited to constitutional AI, alignment via natural language, and instruction-following systems. Approaches where an AI system verify its understanding of directives may face this computational barrier. We argue that more realistic verification scenarios likely face even greater complexity.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2501.15446v2</guid></item><item><title>[cs updates on arXiv.org] Information-theoretic Distinctions Between Deception and Confusion</title><link>https://arxiv.org/abs/2501.16448</link><description>arXiv:2501.16448v2 Announce Type: replace 
Abstract: We propose an information-theoretic formalization of the distinction between two fundamental AI safety failure modes: deceptive alignment and goal drift. While both can lead to systems that appear misaligned, we demonstrate that they represent distinct forms of information divergence occurring at different interfaces in the human-AI system. Deceptive alignment creates entropy between an agent's true goals and its observable behavior, while goal drift, or confusion, creates entropy between the intended human goal and the agent's actual goal. Though often observationally equivalent, these failures necessitate different interventions. We present a formal model and an illustrative thought experiment to clarify this distinction. We offer a formal language for re-examining prominent alignment challenges observed in Large Language Models (LLMs), offering novel perspectives on their underlying causes.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2501.16448v2</guid></item><item><title>[cs updates on arXiv.org] UniAttn: Reducing Inference Costs via Softmax Unification for Post-Training LLMs</title><link>https://arxiv.org/abs/2502.00439</link><description>arXiv:2502.00439v2 Announce Type: replace 
Abstract: Post-training is essential for adapting Large Language Models (LLMs) to real-world applications. Deploying post-trained models faces significant challenges due to substantial memory overhead and noticeable inference latency. Existing work has identified significant redundancies in LLMs and proposed efficient architectures, namely intra-layer KV sharing and cross-layer KV sharing. However, these methods still result in high inference time overhead, remaining suboptimal for post-training pre-trained LLMs. In this paper, we identify that the \texttt{Softmax} operation is a primary bottleneck for LLM inference and discover that it is actually highly redundant during post-training. We propose Softmax \textbf{Uni}fication in \textbf{Att}e\textbf{n}tion (\textbf{UniAttn}), a novel post-training method that unifies Softmax activations across transformer blocks to reduce LLM inference costs. Additionally, UniAttn adopts a linear projection to compensate for the errors induced by Softmax unification. Experiments show that UniAttn matches the performance of standard post-training while significantly reducing inference costs, outperforming existing efficient architectures during post-training.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.00439v2</guid></item><item><title>[cs updates on arXiv.org] Sparse Data Diffusion for Scientific Simulations in Biology and Physics</title><link>https://arxiv.org/abs/2502.02448</link><description>arXiv:2502.02448v3 Announce Type: replace 
Abstract: Sparse data is fundamental to scientific simulations in biology and physics, from single-cell gene expression to particle calorimetry, where exact zeros encode physical absence rather than weak signal. However, existing diffusion models lack the physical rigor to faithfully represent this sparsity. This work introduces Sparse Data Diffusion (SDD), a generative method that explicitly models exact zeros via Sparsity Bits, unifying efficient ML generation with physically grounded sparsity handling. Empirical validation in particle physics and single-cell biology demonstrates that SDD achieves higher fidelity than baseline methods in capturing sparse patterns critical for scientific analysis, advancing scalable and physically faithful simulation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.02448v3</guid></item><item><title>[cs updates on arXiv.org] A Match Made in Heaven? AI-driven Matching of Vulnerabilities and Security Unit Tests</title><link>https://arxiv.org/abs/2502.03365</link><description>arXiv:2502.03365v4 Announce Type: replace 
Abstract: Software vulnerabilities are often detected via taint analysis, penetration testing, or fuzzing. They are also found via unit tests that exercise security-sensitive behavior with specific inputs, called vulnerability-witnessing tests. Generative AI models could help developers in writing them, but they require many examples to learn from, which are currently scarce. This paper introduces VuTeCo, an AI-driven framework for collecting examples of vulnerability-witnessing tests from Java repositories. VuTeCo carries out two tasks: (1) The "Finding" task to determine whether a unit test case is security-related, and (2) the "Matching" task to relate a test case to the vulnerability it witnesses. VuTeCo addresses the Finding task with UniXcoder, achieving an F0.5 score of 0.73 and a precision of 0.83 on a test set of unit tests from Vul4J. The Matching task is addressed using DeepSeek Coder, achieving an F0.5 score of 0.65 and a precision of 0.75 on a test set of pairs of unit tests and vulnerabilities from Vul4J. VuTeCo has been used in the wild on 427 Java projects and 1,238 vulnerabilities, obtaining 224 test cases confirmed to be security-related and 35 tests correctly matched to 29 vulnerabilities. The validated tests were collected in a new dataset called Test4Vul. VuTeCo lays the foundation for large-scale retrieval of vulnerability-witnessing tests, enabling future AI models to better understand and generate security unit tests.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.03365v4</guid></item><item><title>[cs updates on arXiv.org] Cognitive AI framework 2.0: advances in the simulation of human thought</title><link>https://arxiv.org/abs/2502.04259</link><description>arXiv:2502.04259v2 Announce Type: replace 
Abstract: The Human Cognitive Simulation Framework proposes a governed cognitive AI architecture designed to improve personalization, adaptability, and long-term coherence in human AI interaction. The framework integrates short-term memory (conversation context), long-term memory (interaction context), cognitive processing modules, and managed knowledge persistence into a unified architectural model that ensures contextual continuity across sessions and controlled accumulation of relevant information. A central contribution is a unified memory architecture supervised by explicit governance mechanisms, including algorithmic relevance validation, selective persistence, and auditability. The framework incorporates differentiated processing modules for logical, creative, and analogical reasoning, enabling both structured task execution and complex contextual inference. Through dynamic and selective knowledge updating, the system augments the capabilities of large language models without modifying their internal parameters, relying instead on retrieval augmented generation and governed external memory. The proposed architecture addresses key challenges related to scalability, bias mitigation, and ethical compliance by embedding operational safeguards directly into the cognitive loop. These mechanisms establish a foundation for future work on continuous learning, sustainability, and multimodal cognitive interaction. This manuscript is a substantially revised and extended version of the previously released preprint (DOI:10.48550/arXiv.2502.04259).</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.04259v2</guid></item><item><title>[cs updates on arXiv.org] "I never would have thought to say this": Example-Based Exploration to Balance Scientists' Writing Preferences with Public Science Communication Strategies</title><link>https://arxiv.org/abs/2502.05287</link><description>arXiv:2502.05287v3 Announce Type: replace 
Abstract: Public-facing science communication is important in garnering interest, engagement, and trust in science. Social media platforms provide scientists with opportunities to reach broader audiences, yet many resist adopting social media writing strategies because the strategies conflict with traditional science writing norms and personal preferences. To address this gap, we first evaluate readers' preferences for strategies such as examples, walkthroughs, and personal language. While many readers enjoyed science narratives that used these strategies, their effectiveness was nuanced and context-dependent, varying by topic and individual preference. Building on these findings, we design a system that uses contrastive examples to help scientists adopt and integrate these social media science writing strategies. In a user study with scientists, we found that presenting contrastive examples helped writers critically evaluate different narrative options, balance competing goals, and gain confidence in adapting social media writing strategies to fit both their topic and audience.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.05287v3</guid></item><item><title>[cs updates on arXiv.org] The exponential distribution of the order of demonstrative, numeral, adjective and noun</title><link>https://arxiv.org/abs/2502.06342</link><description>arXiv:2502.06342v3 Announce Type: replace 
Abstract: The frequency of the preferred order for a noun phrase formed by demonstrative, numeral, adjective and noun has received significant attention over the last two decades. We investigate the actual distribution of the 24 possible orders. There is no consensus on whether it is well-fitted by an exponential or a power law distribution. We find that an exponential distribution is a much better model. This finding and other circumstances where an exponential-like distribution is found challenge the view that power-law distributions, e.g., Zipf's law for word frequencies, are inevitable. We also investigate which of two exponential distributions gives a better fit: an exponential model where the 24 orders have non-zero probability (a geometric distribution truncated at rank 24) or an exponential model where the number of orders that can have non-zero probability is variable (a right-truncated geometric distribution). When consistency and generalizability are prioritized, we find higher support for the exponential model where all 24 orders have non-zero probability. These findings strongly suggest that there is no hard constraint on word order variation and then unattested orders merely result from undersampling, consistently with Cysouw's view.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.06342v3</guid></item><item><title>[cs updates on arXiv.org] GENERator: A Long-Context Generative Genomic Foundation Model</title><link>https://arxiv.org/abs/2502.07272</link><description>arXiv:2502.07272v4 Announce Type: replace 
Abstract: The rapid advancement of DNA sequencing has produced vast genomic datasets, yet interpreting and engineering genomic function remain fundamental challenges. Recent large language models have opened new avenues for genomic analysis, but existing approaches are often limited by restricted training scope, constrained generative capability, or prohibitive computational cost. We introduce GENErator, a generative genomic foundation model for long-context DNA modeling, with a context length of 98k nucleotides, pre-trained on 386 billion nucleotides of eukaryotic DNA. Without task-specific fine-tuning, GENERator exhibits strong intrinsic capabilities: unsupervised embedding analyses reveal phylogenetically coherent structure, and sequence recovery benchmarks demonstrate generative accuracy comparable to or exceeding state-of-the-art models with substantially improved computational efficiency. In a zero-shot setting, GENERator achieves competitive variant effect prediction performance relative to alignment-based methods, while remaining fully alignment-free and broadly applicable across species. With task-specific fine-tuning, the model attains leading performance on established genomic benchmarks. We further demonstrate practical generative applications. GENERator can generate protein-coding DNA sequences that translate into structurally plausible proteins and, through a prompt-guided design framework, design cis-regulatory elements with targeted activity profiles, including synthetic super-enhancers validated by high-throughput UMI-STARR-seq assays. Together, these results establish GENERator as an efficient and biologically grounded framework for genomic interpretation and programmable sequence design. Code and supplementary resources are available at https://github.com/GenerTeam/GENERator.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.07272v4</guid></item><item><title>[cs updates on arXiv.org] SCALAR: Scientific Citation-based Live Assessment of Long-context Academic Reasoning</title><link>https://arxiv.org/abs/2502.13753</link><description>arXiv:2502.13753v2 Announce Type: replace 
Abstract: Long-context understanding has emerged as a critical capability for large language models (LLMs). However, evaluating this ability remains challenging. We present SCALAR, a benchmark designed to assess citation-grounded long-context reasoning in academic writing. SCALAR leverages academic papers and their citation structure to automatically generate high-quality ground-truth labels without human annotation. It features controllable difficulty levels and a dynamic updating mechanism that mitigates data contamination. The benchmark includes two tasks: a multiple-choice QA format and a cloze-style citation prediction. We evaluate a range of state-of-the-art LLMs and find that the multiple-choice task effectively distinguishes model capabilities. While human experts achieve over 90% accuracy, most models struggle. The cloze-style task is even more challenging, with no model exceeding 50% accuracy. SCALAR provides a domain-grounded, continuously updating framework for tracking progress in citation-based long-context understanding.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.13753v2</guid></item><item><title>[cs updates on arXiv.org] I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree Search</title><link>https://arxiv.org/abs/2502.14693</link><description>arXiv:2502.14693v4 Announce Type: replace 
Abstract: Recent advancements in large language models (LLMs) have shown remarkable potential in automating machine learning tasks. However, existing LLM-based agents often struggle with low-diversity and suboptimal code generation. While recent work has introduced Monte Carlo Tree Search (MCTS) to address these issues, limitations persist in the quality and diversity of thoughts generated, as well as in the scalar value feedback mechanisms used for node selection. In this study, we introduce Introspective Monte Carlo Tree Search (I-MCTS), a novel approach that iteratively expands tree nodes through an introspective process that meticulously analyzes solutions and results from parent and sibling nodes. This facilitates a continuous refinement of the node in the search tree, thereby enhancing the overall decision-making process. Furthermore, we integrate a Large Language Model (LLM)-based value model to facilitate direct evaluation of each node's solution prior to conducting comprehensive computational rollouts. A hybrid rewarding mechanism is implemented to seamlessly transition the Q-value from LLM-estimated scores to actual performance scores. This allows higher-quality nodes to be traversed earlier. Applied to the various ML tasks, our approach demonstrates a 4% absolute improvement in performance compared to the strong open-source AutoML agents, showcasing its effectiveness in enhancing agentic AutoML systems. Resource available at https://github.com/jokieleung/I-MCTS</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.14693v4</guid></item><item><title>[cs updates on arXiv.org] English K_Quantization of LLMs Does Not Disproportionately Diminish Multilingual Performance</title><link>https://arxiv.org/abs/2503.03592</link><description>arXiv:2503.03592v4 Announce Type: replace 
Abstract: For consumer usage of locally deployed LLMs, the GGUF format and k\_quantization are invaluable tools for maintaining the performance of the original model while reducing it to sizes deployable with consumer-grade hardware. The number of bits dedicated to each weight from the original model is reduced based on how important they are thought to be during model inference. This importance is arrived at through the application of an 'importance matrix'-a relatively small text document meant to be representative of the LLM's standard use-cases. In the vast majority of quants available online, this document is primarily written in English. It was therefore an open question whether performance on English language tasks was preserved through the sacrifice of multilingual performance and whether it can be preserved with alternate importance matrices. This article investigates these hypotheses by quantizing Llama3.3 70B on importance matrices written in three languages (English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset in both English and Norwegian. All experiments related to yielded non-significant results indicating that current quantization practices do not disproportionately harm multilingual performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.03592v4</guid></item><item><title>[cs updates on arXiv.org] Decoding Safety Feedback from Diverse Raters: A Data-driven Lens on Responsiveness to Severity</title><link>https://arxiv.org/abs/2503.05609</link><description>arXiv:2503.05609v5 Announce Type: replace 
Abstract: Ensuring the safety of Generative AI requires a nuanced understanding of pluralistic viewpoints. In this paper, we introduce a novel data-driven approach for analyzing ordinal safety ratings in pluralistic settings. Specifically, we address the challenge of interpreting nuanced differences in safety feedback from a diverse population expressed via ordinal scales (e.g., a Likert scale). We define non-parametric responsiveness metrics that quantify how raters convey broader distinctions and granular variations in the severity of safety violations. Leveraging publicly available datasets of pluralistic safety feedback as our case studies, we investigate how raters from different demographic groups use an ordinal scale to express their perceptions of the severity of violations. We apply our metrics across violation types, demonstrating their utility in extracting nuanced insights that are crucial for aligning AI systems reliably in multi-cultural contexts. We show that our approach can inform rater selection and feedback interpretation by capturing nuanced viewpoints across different demographic groups, hence improving the quality of pluralistic data collection and in turn contributing to more robust AI alignment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.05609v5</guid></item><item><title>[cs updates on arXiv.org] MedSimAI: Simulation and Formative Feedback Generation to Enhance Deliberate Practice in Medical Education</title><link>https://arxiv.org/abs/2503.05793</link><description>arXiv:2503.05793v2 Announce Type: replace 
Abstract: Medical education faces challenges in providing scalable, consistent clinical skills training. Simulation with standardized patients (SPs) develops communication and diagnostic skills but remains resource-intensive and variable in feedback quality. Existing AI-based tools show promise yet often lack comprehensive assessment frameworks, evidence of clinical impact, and integration of self-regulated learning (SRL) principles. Through a multi-phase co-design process with medical education experts, we developed MedSimAI, an AI-powered simulation platform that enables deliberate practice through interactive patient encounters with immediate, structured feedback. Leveraging large language models, MedSimAI generates realistic clinical interactions and provides automated assessments aligned with validated evaluation frameworks. In a multi-institutional deployment (410 students; 1,024 encounters across three medical schools), 59.5 percent engaged in repeated practice. At one site, mean Objective Structured Clinical Examination (OSCE) history-taking scores rose from 82.8 to 88.8 (p &lt; 0.001, Cohen's d = 0.75), while a second site's pilot showed no significant change. Automated scoring achieved 87 percent accuracy in identifying proficiency thresholds on the Master Interview Rating Scale (MIRS). Mixed-effects analyses revealed institution and case effects. Thematic analysis of 840 learner reflections highlighted challenges in missed items, organization, review of systems, and empathy. These findings position MedSimAI as a scalable formative platform for history-taking and communication, motivating staged curriculum integration and realism enhancements for advanced learners.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.05793v2</guid></item><item><title>[cs updates on arXiv.org] GRITHopper: Decomposition-Free Multi-Hop Dense Retrieval</title><link>https://arxiv.org/abs/2503.07519</link><description>arXiv:2503.07519v2 Announce Type: replace 
Abstract: Decomposition-based multi-hop retrieval methods rely on many autoregressive steps to break down complex queries, which breaks end-to-end differentiability and is computationally expensive. Decomposition-free methods tackle this, but current decomposition-free approaches struggle with longer multi-hop problems and generalization to out-of-distribution data. To address these challenges, we introduce GRITHopper-7B, a novel multi-hop dense retrieval model that achieves state-of-the-art performance on both in-distribution and out-of-distribution benchmarks. GRITHopper combines generative and representational instruction tuning by integrating causal language modeling with dense retrieval training. Through controlled studies, we find that incorporating additional context after the retrieval process, referred to as post-retrieval language modeling, enhances dense retrieval performance. By including elements such as final answers during training, the model learns to better contextualize and retrieve relevant information. GRITHopper-7B offers a robust, scalable, and generalizable solution for multi-hop dense retrieval, and we release it to the community for future research and applications requiring multi-hop reasoning and retrieval capabilities.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.07519v2</guid></item><item><title>[cs updates on arXiv.org] Chat-TS: Enhancing Multi-Modal Reasoning Over Time-Series and Natural Language Data</title><link>https://arxiv.org/abs/2503.10883</link><description>arXiv:2503.10883v2 Announce Type: replace 
Abstract: Large language models are being rapidly deployed across many fields such as healthcare, finance, transportation, and energy, where time-series data are fundamental components. The current works are still limited in their ability to perform reasoning that involves both time-series and the corresponding textual content. We address this gap by introducing Chat-TS, a large language model (LLM) based framework designed to support reasoning over time series and textual data. Unlike traditional models, Chat-TS integrates time-series tokens into LLMs' vocabulary, enhancing its reasoning ability over both modalities without compromising core natural language capabilities. To support learning and evaluation, we contribute new datasets: the TS Instruct Training Dataset (pairing diverse time-series data with relevant text instructions and responses for instruction tuning), the TS Instruct Question and Answer (QA) Gold Dataset (multiple-choice questions to evaluate multimodal reasoning), and a TS Instruct Quantitative Probing Set (a small subset of TS Instruct QA reasoning tasks alongside math and decision-making questions for LLM evaluation). We design a training strategy to preserve the inherent reasoning capabilities of LLMs while augmenting them for time-series reasoning. Experiments show that Chat-TS achieves state-of-the-art performance in multimodal reasoning tasks by maintaining strong natural language proficiency while improving time-series reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.10883v2</guid></item><item><title>[cs updates on arXiv.org] Variational Bayesian Personalized Ranking</title><link>https://arxiv.org/abs/2503.11067</link><description>arXiv:2503.11067v2 Announce Type: replace 
Abstract: Pairwise learning underpins implicit collaborative filtering, yet its effectiveness is often hindered by sparse supervision, noisy interactions, and popularity-driven exposure bias. In this paper, we propose Variational Bayesian Personalized Ranking (VarBPR), a tractable variational framework for implicit-feedback pairwise learning that offers principled exposure controllability and theoretical interpretability. VarBPR reformulates pairwise learning as variational inference over discrete latent indexing variables, explicitly modeling noise and indexing uncertainty, and divides training into two stages: variational inference and variational learning. In the variational inference stage, we develop a variational formulation that integrates preference alignment, denoising, and popularity debiasing under a unified ELBO/regularization objective, deriving closed-form posteriors with clear control semantics: the prior encodes a target exposure pattern, while temperature/regularization strength controls posterior-prior adherence. As a result, exposure controllability becomes an endogenous and interpretable outcome of variational inference. In the variational learning stage, we propose a posterior-compression objective that reduces the ideal ELBO's computational complexity from polynomial to linear, with the approximation justified by an explicit Jensen-gap upper bound. Theoretically, we provide interpretable generalization guarantees by identifying a structural error component and revealing the opportunity cost of prioritizing certain exposure patterns (e.g., long-tail), offering a concrete analytical lens for designing controllable recommender systems. Empirically, we validate VarBPR across popular backbones; it demonstrates consistent gains in ranking accuracy, enables controlled long-tail exposure, and preserves the linear-time complexity of BPR.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.11067v2</guid></item><item><title>[cs updates on arXiv.org] Simulating Dual-Pixel Images From Ray Tracing For Depth Estimation</title><link>https://arxiv.org/abs/2503.11213</link><description>arXiv:2503.11213v2 Announce Type: replace 
Abstract: Many studies utilize dual-pixel (DP) sensor phase characteristics for various applications, such as depth estimation and deblurring. However, since the DP image features are entirely determined by the camera hardware, DP-depth paired datasets are very scarce, especially when performing depth estimation on customized cameras. To overcome this, studies simulate DP images using ideal optical system models. However, these simulations often violate real optical propagation laws, leading to poor generalization to real DP data. To address this, we investigate the domain gap between simulated and real DP data, and propose solutions using the Simulating DP images from ray tracing (Sdirt) scheme. The Sdirt generates realistic DP images via ray tracing and integrates them into the depth estimation training pipeline. Experimental results show that models trained with Sdirt-simulated images generalize better to real DP data. The code and collected datasets will be available at github.com/LinYark/Sdirt</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.11213v2</guid></item><item><title>[cs updates on arXiv.org] A Peek Behind the Curtain: Using Step-Around Prompt Engineering to Identify Bias and Misinformation in GenAI Models</title><link>https://arxiv.org/abs/2503.15205</link><description>arXiv:2503.15205v2 Announce Type: replace 
Abstract: This research examines the emerging technique of step-around prompt engineering in GenAI research, a method that deliberately bypasses AI safety measures to expose underlying biases and vulnerabilities in GenAI models. We discuss how Internet-sourced training data introduces unintended biases and misinformation into AI systems, which can be revealed through the careful application of step-around techniques.
  Drawing parallels with red teaming in cybersecurity, we argue that step-around prompting serves a vital role in identifying and addressing potential vulnerabilities while acknowledging its dual nature as both a research tool and a potential security threat. Our findings highlight three key implications: (1) the persistence of Internet-derived biases in AI training data despite content filtering, (2) the effectiveness of step-around techniques in exposing these biases when used responsibly, and (3) the need for robust safeguards against malicious applications of these methods.
  We conclude by proposing an ethical framework for using step-around prompting in AI research and development, emphasizing the importance of balancing system improvements with security considerations.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.15205v2</guid></item><item><title>[cs updates on arXiv.org] ImputeGAP: A Comprehensive Library for Time Series Imputation</title><link>https://arxiv.org/abs/2503.15250</link><description>arXiv:2503.15250v2 Announce Type: replace 
Abstract: With the prevalence of sensor failures, imputation, the process of estimating missing values, has emerged as the cornerstone of time series data pre-processing. While numerous imputation algorithms have been developed to repair these data gaps, existing time series libraries provide limited imputation support. Furthermore, they often lack the ability to simulate realistic time series missingness patterns and fail to account for the impact of the imputed data on subsequent downstream analysis.
  This paper introduces ImputeGAP, a comprehensive library for time series imputation that supports a diverse range of imputation methods and modular missing data simulation, catering to datasets with varying characteristics. The library includes extensive customization options, such as automated hyperparameter tuning, benchmarking, explainability, downstream evaluation, and compatibility with popular time series frameworks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.15250v2</guid></item><item><title>[cs updates on arXiv.org] Trees in Coalgebra from Generalized Reachability</title><link>https://arxiv.org/abs/2503.15585</link><description>arXiv:2503.15585v4 Announce Type: replace 
Abstract: An automaton is called reachable if every state is reachable from the initial state. This notion has been generalized coalgebraically in two ways: first, via a universal property on pointed coalgebras, namely, that a reachable coalgebra has no proper subcoalgebras; and second, a coalgebra is reachable if it arises as the union of an iterative computation of successor states, starting from the initial state.
  In the current paper, we present corresponding universal properties and iterative constructions for trees. The universal property captures when a coalgebra is a tree, namely, when it has no proper tree unravellings. The iterative construction unravels an arbitrary coalgebra to a tree. We show that this yields the expected notion of tree for a variety of standard examples.
  We obtain our characterization of trees by first generalizing the previous theory of reachable coalgebras and of a minimal object in a category, related to projectivity. Surprisingly, both the universal property and the iterative construction for trees arise as instances of this generalized notion of reachability. Our iterative construction works for all analytic set functors.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.15585v4</guid></item><item><title>[cs updates on arXiv.org] Poor Alignment and Steerability of Large Language Models: Evidence from College Admission Essays</title><link>https://arxiv.org/abs/2503.20062</link><description>arXiv:2503.20062v2 Announce Type: replace 
Abstract: People are increasingly using technologies equipped with large language models (LLM) to write texts for formal communication, which raises two important questions at the intersection of technology and society: Who do LLMs write like (model alignment); and can LLMs be prompted to change who they write like (model steerability). We investigate these questions in the high-stakes context of undergraduate admissions at a selective university by comparing lexical and sentence variation between essays written by 30,000 applicants to two types of LLM-generated essays: one prompted with only the essay question used by the human applicants; and another with additional demographic information about each applicant. We consistently find that both types of LLM-generated essays are linguistically distinct from human-authored essays, regardless of the specific model and analytical approach. Further, prompting a specific sociodemographic identity is remarkably ineffective in aligning the model with the linguistic patterns observed in human writing from this identity group. This holds along the key dimensions of sex, race, first-generation status, and geographic location. The demographically prompted and unprompted synthetic texts were also more similar to each other than to the human text, meaning that prompting did not alleviate homogenization. These issues of model alignment and steerability in current LLMs raise concerns about the use of LLMs in high-stakes contexts.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.20062v2</guid></item><item><title>[cs updates on arXiv.org] Is Your Writing Being Mimicked by AI? Unveiling Imitation with Invisible Watermarks in Creative Writing</title><link>https://arxiv.org/abs/2504.00035</link><description>arXiv:2504.00035v3 Announce Type: replace 
Abstract: Efficient knowledge injection methods for Large Language Models (LLMs), such as In-Context Learning, knowledge editing, and efficient parameter fine-tuning, significantly enhance model utility on downstream tasks. However, they also pose substantial risks of unauthorized imitation and compromised data provenance for high-value unstructured data assets like creative works. Current copyright protection methods for creative works predominantly focus on visual arts, leaving a critical and unaddressed data engineering challenge in the safeguarding of creative writing. In this paper, we propose WIND (Watermarking via Implicit and Non-disruptive Disentanglement), a novel zero-watermarking, verifiable and implicit scheme that safeguards creative writing databases by providing verifiable copyright protection. Specifically, we decompose creative essence into five key elements, which are extracted utilizing LLMs through a designed instance delimitation mechanism and consolidated into condensed-lists. These lists enable WIND to convert core copyright attributes into verifiable watermarks via implicit encoding within a disentanglement creative space, where 'disentanglement' refers to the separation of creative-specific and creative-irrelevant features. This approach, utilizing implicit encoding, avoids distorting fragile textual content. Extensive experiments demonstrate that WIND effectively verifies creative writing copyright ownership against AI imitation, achieving F1 scores above 98% and maintaining robust performance under stringent low false-positive rates where existing state-of-the-art text watermarking methods struggle.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.00035v3</guid></item><item><title>[cs updates on arXiv.org] On shallow feedforward neural networks with inputs from a topological space</title><link>https://arxiv.org/abs/2504.02321</link><description>arXiv:2504.02321v2 Announce Type: replace 
Abstract: We study feedforward neural networks with inputs from a topological space (TFNNs). We prove a universal approximation theorem for shallow TFNNs, which demonstrates their capacity to approximate any continuous function defined on this topological space. As an application, we obtain an approximative version of Kolmogorov's superposition theorem for compact metric spaces.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.02321v2</guid></item><item><title>[cs updates on arXiv.org] A Scalable Predictive Modelling Approach to Identifying Duplicate Adverse Event Reports for Drugs and Vaccines</title><link>https://arxiv.org/abs/2504.03729</link><description>arXiv:2504.03729v2 Announce Type: replace 
Abstract: Objectives: To advance state-of-the-art for duplicate detection in large-scale pharmacovigilance databases and achieve more consistent performance across adverse event reports from different countries.
  Background: Unlinked adverse event reports referring to the same case impede statistical analysis and may mislead clinical assessment. Pharmacovigilance relies on large databases of adverse event reports to discover potential new causal associations, and computational methods are required to identify duplicates at scale. Current state-of-the-art is statistical record linkage which outperforms rule-based approaches. In particular, vigiMatch is in routine use for VigiBase, the WHO global database of adverse event reports, and represents the first statistical duplicate detection approach in pharmacovigilance deployed at scale. Originally developed for both medicines and vaccines, its application to vaccines has been limited due to inconsistent performance across countries.
  Methods: This paper extends vigiMatch from probabilistic record linkage to predictive modelling, refining features for medicines, vaccines, and adverse events using country-specific reporting rates, extracting dates from free text, and training separate support vector machine classifiers for medicines and vaccines. Recall was evaluated using 5 independent labelled test sets. Precision was assessed by annotating random selections of report pairs classified as duplicates.
  Results: Precision for the new method was 92% for vaccines and 54% for medicines, compared with 41% for the comparator method. Recall ranged from 80-85% across test sets for vaccines and from 40-86% for medicines, compared with 24-53% for the comparator method.
  Conclusion: Predictive modeling, use of free text, and country-specific features advance state-of-the-art for duplicate detection in pharmacovigilance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.03729v2</guid></item><item><title>[cs updates on arXiv.org] Embracing Ambiguity: Bayesian Nonparametrics and Stakeholder Participation for Ambiguity-Aware Safety Evaluation</title><link>https://arxiv.org/abs/2504.15211</link><description>arXiv:2504.15211v2 Announce Type: replace 
Abstract: Evaluations of generative AI models often collapse nuanced behaviour into a single number computed for a single decoding configuration. Such point estimates obscure tail risks, demographic disparities, and the existence of multiple near-optimal operating points. We propose a unified framework that embraces multiplicity by modelling the distribution of harmful behaviour across the entire space of decoding knobs and prompts, quantifying risk through tail-focused metrics, and integrating stakeholder preferences. Our technical contributions are threefold: (i) we formalise decoding Rashomon sets, regions of knob space whose risk is near-optimal under given criteria and measure their size and disagreement; (ii) we develop a dependent Dirichlet process (DDP) mixture with stakeholder-conditioned stick-breaking weights to learn multi-modal harm surfaces; and (iii) we introduce an active sampling pipeline that uses Bayesian deep learning surrogates to explore knob space efficiently. Our approach bridges multiplicity theory, Bayesian nonparametrics, and stakeholder-aligned sensitivity analysis, paving the way for trustworthy deployment of generative models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.15211v2</guid></item><item><title>[cs updates on arXiv.org] Emergence and Evolution of Interpretable Concepts in Diffusion Models</title><link>https://arxiv.org/abs/2504.15473</link><description>arXiv:2504.15473v2 Announce Type: replace 
Abstract: Diffusion models have become the go-to method for text-to-image generation, producing high-quality images from pure noise. However, the inner workings of diffusion models is still largely a mystery due to their black-box nature and complex, multi-step generation process. Mechanistic interpretability techniques, such as Sparse Autoencoders (SAEs), have been successful in understanding and steering the behavior of large language models at scale. However, the great potential of SAEs has not yet been applied toward gaining insight into the intricate generative process of diffusion models. In this work, we leverage the SAE framework to probe the inner workings of a popular text-to-image diffusion model, and uncover a variety of human-interpretable concepts in its activations. Interestingly, we find that even before the first reverse diffusion step is completed, the final composition of the scene can be predicted surprisingly well by looking at the spatial distribution of activated concepts. Moreover, going beyond correlational analysis, we design intervention techniques aimed at manipulating image composition and style, and demonstrate that (1) in early stages of diffusion image composition can be effectively controlled, (2) in the middle stages image composition is finalized, however stylistic interventions are effective, and (3) in the final stages only minor textural details are subject to change.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.15473v2</guid></item><item><title>[cs updates on arXiv.org] Boosting Generative Image Modeling via Joint Image-Feature Synthesis</title><link>https://arxiv.org/abs/2504.16064</link><description>arXiv:2504.16064v3 Announce Type: replace 
Abstract: Latent diffusion models (LDMs) dominate high-quality image generation, yet integrating representation learning with generative modeling remains a challenge. We introduce a novel generative image modeling framework that seamlessly bridges this gap by leveraging a diffusion model to jointly model low-level image latents (from a variational autoencoder) and high-level semantic features (from a pretrained self-supervised encoder like DINO). Our latent-semantic diffusion approach learns to generate coherent image-feature pairs from pure noise, significantly enhancing both generative quality and training efficiency, all while requiring only minimal modifications to standard Diffusion Transformer architectures. By eliminating the need for complex distillation objectives, our unified design simplifies training and unlocks a powerful new inference strategy: Representation Guidance, which leverages learned semantics to steer and refine image generation. Evaluated in both conditional and unconditional settings, our method delivers substantial improvements in image quality and training convergence speed, establishing a new direction for representation-aware generative modeling. Project page and code: https://representationdiffusion.github.io</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.16064v3</guid></item><item><title>[cs updates on arXiv.org] Who Is Responsible? Self-Adaptation Under Multiple Concurrent Uncertainties With Unknown Sources in Complex ROS-Based Systems</title><link>https://arxiv.org/abs/2504.20477</link><description>arXiv:2504.20477v2 Announce Type: replace 
Abstract: Robotic systems increasingly operate in dynamic, unpredictable environments, where tightly coupled sensors and software modules increase the probability of a single fault cascading across components and admitting multiple plausible strategies to resolve the underlying uncertainty. Most existing self-adaptive approaches that have been applied to robotics assume predefined one-to-one uncertainty-to-adaptation mappings. We present a ROS2-based self-adaptive approach building upon the MAPE-K feedback loop that addresses (1) multiple simultaneous uncertainties with differing criticality, (2) cascading uncertainties across components, and (3) multiple plausible resolving strategies per detected symptom. Central to our approach is an adaptation rule set which lets designers specify uncertainty patterns, assign criticality levels, and enumerate multiple plausible adaptation strategies. This rule set, combined with an automatically extracted live ROS2 dependency graph, enables lightweight root-cause analysis and strategy ranking to prioritize minimal and effective adaptations. Evaluations on an underwater robot scenario and a perception use case show that our approach can identify root causes among concurrent uncertainties, favours inexpensive adaptations, reduces unnecessary adaptations, and achieves performance comparable to existing baselines designed for sequential uncertainties. The code is publicly available.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.20477v2</guid></item><item><title>[cs updates on arXiv.org] Adaptively Point-weighting Curriculum Learning</title><link>https://arxiv.org/abs/2505.01665</link><description>arXiv:2505.01665v2 Announce Type: replace 
Abstract: Curriculum learning (CL) mimics human learning, in which easy samples are learned first, followed by harder samples, and has become an effective method for training deep networks. However, many existing automatic CL methods maintain a preference for easy samples during the entire training process regardless of the constantly evolving training state. This is just like a human curriculum that fails to provide individualized instruction, which can delay learning progress. To address this issue, we propose an adaptively point-weighting (APW) curriculum learning method that assigns a weight to each training sample based on its training loss. The weighting strategy of APW follows the easy-to-hard training paradigm, guided by the current training state of the network. We present a theoretical analysis of APW, including training effectiveness, training stability, and generalization performance. Experimental results validate these theoretical findings and demonstrate the superiority of the proposed APW method.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.01665v2</guid></item><item><title>[cs updates on arXiv.org] Semantics-Aware Unified Terrestrial Non-Terrestrial 6G Networks</title><link>https://arxiv.org/abs/2505.01796</link><description>arXiv:2505.01796v2 Announce Type: replace 
Abstract: The integration of Terrestrial and Non-Terrestrial Networks (TN-NTNs), introduced in 5G, is advancing toward a unified and seamless network of networks in Sixth-Generation (6G). This evolution markedly increases the volume of generated and exchanged data, imposing stringent technical and operational requirements along with higher cost and energy consumption. Consequently, efficient management of data generation and transmission within this unified architecture has become essential. In this article, we investigate semantics-aware information handling in unified TN-NTNs, where data communication between distant TN nodes is enabled via an NTN. We consider an Internet of Things (IoT) monitoring system in which status updates from a remote Energy Harvesting (EH) device are delivered to a destination monitor through a network of Low Earth Orbit (LEO) satellites. We leverage semantic metrics, such as Query Version Age of Information, which collectively capture the timeliness, relevance, and utility of information. This approach minimizes the transmission of stale, uninformative, or unusable information, thereby reducing the volume of data that must be transmitted and processed. The result is a substantial reduction in energy consumption and data exchange within the network-achieving up to 73% lower energy-charging requirements and fewer transmission demands than the state of the art-without compromising the conveyed information.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.01796v2</guid></item><item><title>[cs updates on arXiv.org] RADLADS: Rapid Attention Distillation to Linear Attention Decoders at Scale</title><link>https://arxiv.org/abs/2505.03005</link><description>arXiv:2505.03005v4 Announce Type: replace 
Abstract: We present Rapid Attention Distillation to Linear Attention Decoders at Scale (RADLADS), a protocol for rapidly converting softmax attention transformers into linear attention decoder models, along with two new RWKV-variant architectures, and models converted from popular Qwen2.5 open source models in 7B, 32B, and 72B sizes. Our conversion process requires only 350-700M tokens, less than 0.005% of the token count used to train the original teacher models. Converting to our 72B linear attention model costs less than \$2,000 USD at today's prices, yet quality at inference remains close to the original transformer. These models achieve state-of-the-art downstream performance across a set of standard benchmarks for linear attention models of their size. We release all our models on HuggingFace under the Apache 2.0 license, with the exception of our 72B models which are also governed by the Qwen License Agreement.
  Models at https://huggingface.co/collections/recursal/radlads-6818ee69e99e729ba8a87102 Training Code at https://github.com/recursal/RADLADS-paper</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.03005v4</guid></item><item><title>[cs updates on arXiv.org] Eliminating Out-of-Domain Recommendations in LLM-based Recommender Systems: A Unified View</title><link>https://arxiv.org/abs/2505.03336</link><description>arXiv:2505.03336v2 Announce Type: replace 
Abstract: Recommender systems based on Large Language Models (LLMs) are often plagued by hallucinations of out-of-domain (OOD) items. To address this, we propose RecLM, a unified framework that bridges the gap between retrieval and generation by instantiating three grounding paradigms under a single architecture: embedding-based retrieval, constrained generation over rewritten item titles, and discrete item-tokenizer generation. Using the same backbone LLM and prompts, we systematically compare these three views on public benchmarks. RecLM strictly eradicates OOD recommendations (OOD@10 = 0) across all variants, and the constrained generation variants RecLM-cgen and RecLM-token achieve overall state-of-the-art accuracy compared to both strong ID-based and LLM-based baselines. Our unified view provides a systematic basis for comparing three distinct paradigms to reduce item hallucinations, offering a practical framework to facilitate the application of LLMs to recommendation tasks. Source code is at https://github.com/microsoft/RecAI.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.03336v2</guid></item><item><title>[cs updates on arXiv.org] PyTDC: A multimodal machine learning training, evaluation, and inference platform for biomedical foundation models</title><link>https://arxiv.org/abs/2505.05577</link><description>arXiv:2505.05577v2 Announce Type: replace 
Abstract: Existing biomedical benchmarks do not provide end-to-end infrastructure for training, evaluation, and inference of models that integrate multimodal biological data and a broad range of machine learning tasks in therapeutics. We present PyTDC, an open-source machine-learning platform providing streamlined training, evaluation, and inference software for multimodal biological AI models. PyTDC unifies distributed, heterogeneous, continuously updated data sources and model weights and standardizes benchmarking and inference endpoints. This paper discusses the components of PyTDC's architecture and, to our knowledge, the first-of-its-kind case study on the introduced single-cell drug-target nomination ML task. We find state-of-the-art methods in graph representation learning and domain-specific methods from graph theory perform poorly on this task. Though we find a context-aware geometric deep learning method that outperforms the evaluated SoTA and domain-specific baseline methods, the model is unable to generalize to unseen cell types or incorporate additional modalities, highlighting PyTDC's capacity to facilitate an exciting avenue of research developing multimodal, context-aware, foundation models for open problems in biomedical AI.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.05577v2</guid></item><item><title>[cs updates on arXiv.org] Decoupling Multi-Contrast Super-Resolution: Self-Supervised Implicit Re-Representation for Unpaired Cross-Modal Synthesis</title><link>https://arxiv.org/abs/2505.05855</link><description>arXiv:2505.05855v2 Announce Type: replace 
Abstract: Multi-contrast super-resolution (MCSR) is crucial for enhancing MRI but current deep learning methods are limited. They typically require large, paired low- and high-resolution (LR/HR) training datasets, which are scarce, and are trained for fixed upsampling scales. While recent self-supervised methods remove the paired data requirement, they fail to leverage valuable population-level priors. In this work, we propose a novel, decoupled MCSR framework that resolves both limitations. We reformulate MCSR into two stages: (1) an unpaired cross-modal synthesis (uCMS) module, trained once on unpaired population data to learn a robust anatomical prior; and (2) a lightweight, patient-specific implicit re-representation (IrR) module. This IrR module is optimized in a self-supervised manner to fuse the population prior with the subject's own LR target data. This design uniquely fuses population-level knowledge with patient-specific fidelity without requiring any paired LR/HR or paired cross-modal training data. By building the IrR module on an implicit neural representation, our framework is also inherently scale-agnostic. Our method demonstrates superior quantitative performance on different datasets, with exceptional robustness at extreme scales (16x, 32x), a regime where competing methods fail. Our work presents a data-efficient, flexible, and computationally lightweight paradigm for MCSR, enabling high-fidelity, arbitrary-scale</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.05855v2</guid></item><item><title>[cs updates on arXiv.org] A large-scale evaluation of commonsense knowledge in humans and large language models</title><link>https://arxiv.org/abs/2505.10309</link><description>arXiv:2505.10309v3 Announce Type: replace 
Abstract: Commonsense knowledge, a major constituent of artificial intelligence (AI), is primarily evaluated in practice by human-prescribed ground-truth labels. An important, albeit implicit, assumption of these labels is that they accurately capture what any human would think, effectively treating human common sense as homogeneous. However, recent empirical work has shown that humans vary enormously in what they consider commonsensical; thus what appears self-evident to one benchmark designer may not be so to another. Here, we propose a method for assessing commonsense knowledge in AI, specifically in large language models (LLMs), that incorporates empirically observed heterogeneity among humans by measuring the correspondence between a model's judgment and that of a human population. We first find that, when treated as independent survey respondents, most LLMs remain below the human median in their individual commonsense competence. Second, when used as simulators of a hypothetical population, LLMs correlate with real humans only modestly in the extent to which they agree on the same set of statements. In both cases, smaller, open-weight models are surprisingly more competitive than larger, proprietary frontier models. Our evaluation framework, which ties commonsense knowledge to its cultural basis, contributes to the growing call for adapting AI models to human collectivities that possess different, often incompatible, social stocks of knowledge.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.10309v3</guid></item><item><title>[cs updates on arXiv.org] Sense and Sensitivity: Examining the Influence of Semantic Recall on Long Context Code Reasoning</title><link>https://arxiv.org/abs/2505.13353</link><description>arXiv:2505.13353v3 Announce Type: replace 
Abstract: Large language models (LLMs) are increasingly deployed for understanding large codebases, but whether they understand operational semantics of long code context or rely on pattern matching shortcuts remains unclear. We distinguish between lexical recall (retrieving code verbatim) and semantic recall (understanding operational semantics). Evaluating 10 state-of-the-art LLMs, we find that while frontier models achieve near-perfect, position-independent lexical recall, semantic recall degrades severely when code is centrally positioned in long contexts. We introduce semantic recall sensitivity to measure whether tasks require understanding of code's operational semantics vs. permit pattern matching shortcuts. Through a novel counterfactual measurement method, we show that models rely heavily on pattern matching shortcuts to solve existing code understanding benchmarks. We propose a new task SemTrace, which achieves high semantic recall sensitivity through unpredictable operations; LLMs' accuracy exhibits severe positional effects, with median accuracy drops of 92.73% versus CRUXEval's 53.36% as the relevant code snippet approaches the middle of the input code context. Our findings suggest current evaluations substantially underestimate semantic recall failures in long context code understanding.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.13353v3</guid></item><item><title>[cs updates on arXiv.org] Multi-View Projection for Unsupervised Domain Adaptation in 3D Semantic Segmentation</title><link>https://arxiv.org/abs/2505.15545</link><description>arXiv:2505.15545v3 Announce Type: replace 
Abstract: 3D semantic segmentation plays a pivotal role in autonomous driving and road infrastructure analysis, yet state-of-the-art 3D models are prone to severe domain shift when deployed across different datasets. In this paper, we propose an Unsupervised Domain Adaptation approach where a 3D segmentation model is trained on the target dataset using pseudo-labels generated by a novel multi-view projection framework. Our approach first aligns Lidar scans into coherent 3D scenes and renders them from multiple virtual camera poses to create large-scale synthetic 2D semantic segmentation datasets in various modalities. The generated datasets are used to train an ensemble of 2D segmentation models in point cloud view domain on each modality. During inference, the models process a large amount of views per scene; the resulting logits are back-projected to 3D with a depth-aware voting scheme to generate final point-wise labels. These labels are then used to fine-tune a 3D segmentation model in the target domain. We evaluate our approach Real-to-Real on the nuScenes and SemanticKITTI datasets. We also evaluate it Simulation-to-Real with the SynLidar dataset. Our contributions are a novel method that achieves state-of-the-art results in Real-to-Real Unsupervised Domain Adaptation, and we also demonstrate an application of our method to segment rare classes, for which target 3D annotations are not available, by only using 2D annotations for those classes and leveraging 3D annotations for other classes in a source domain.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.15545v3</guid></item><item><title>[cs updates on arXiv.org] CGS-GAN: 3D Consistent Gaussian Splatting GANs for High Resolution Human Head Synthesis</title><link>https://arxiv.org/abs/2505.17590</link><description>arXiv:2505.17590v3 Announce Type: replace 
Abstract: Recently, 3D GANs based on 3D Gaussian splatting have been proposed for high quality synthesis of human heads. However, existing methods stabilize training and enhance rendering quality from steep viewpoints by conditioning the random latent vector on the current camera position. This compromises 3D consistency, as we observe significant identity changes when re-synthesizing the 3D head with each camera shift. Conversely, fixing the camera to a single viewpoint yields high-quality renderings for that perspective but results in poor performance for novel views. Removing view-conditioning typically destabilizes GAN training, often causing the training to collapse. In response to these challenges, we introduce CGS-GAN, a novel 3D Gaussian Splatting GAN framework that enables stable training and high-quality 3D-consistent synthesis of human heads without relying on view-conditioning. To ensure training stability, we introduce a multi-view regularization technique that enhances generator convergence with minimal computational overhead. Additionally, we adapt the conditional loss used in existing 3D Gaussian splatting GANs and propose a generator architecture designed to not only stabilize training but also facilitate efficient rendering and straightforward scaling, enabling output resolutions up to $2048^2$. To evaluate the capabilities of CGS-GAN, we curate a new dataset derived from FFHQ. This dataset enables very high resolutions, focuses on larger portions of the human head, reduces view-dependent artifacts for improved 3D consistency, and excludes images where subjects are obscured by hands or other objects. As a result, our approach achieves very high rendering quality, supported by competitive FID scores, while ensuring consistent 3D scene generation. Check our our project page here: https://fraunhoferhhi.github.io/cgs-gan/</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.17590v3</guid></item><item><title>[cs updates on arXiv.org] GenPO: Generative Diffusion Models Meet On-Policy Reinforcement Learning</title><link>https://arxiv.org/abs/2505.18763</link><description>arXiv:2505.18763v4 Announce Type: replace 
Abstract: Recent advances in reinforcement learning (RL) have demonstrated the powerful exploration capabilities and multimodality of generative diffusion-based policies. While substantial progress has been made in offline RL and off-policy RL settings, integrating diffusion policies into on-policy frameworks like PPO remains underexplored. This gap is particularly significant given the widespread use of large-scale parallel GPU-accelerated simulators, such as IsaacLab, which are optimized for on-policy RL algorithms and enable rapid training of complex robotic tasks. A key challenge lies in computing state-action log-likelihoods under diffusion policies, which is straightforward for Gaussian policies but intractable for flow-based models due to irreversible forward-reverse processes and discretization errors (e.g., Euler-Maruyama approximations). To bridge this gap, we propose GenPO, a generative policy optimization framework that leverages exact diffusion inversion to construct invertible action mappings. GenPO introduces a novel doubled dummy action mechanism that enables invertibility via alternating updates, resolving log-likelihood computation barriers. Furthermore, we also use the action log-likelihood for unbiased entropy and KL divergence estimation, enabling KL-adaptive learning rates and entropy regularization in on-policy updates. Extensive experiments on eight IsaacLab benchmarks, including legged locomotion (Ant, Humanoid, Anymal-D, Unitree H1, Go2), dexterous manipulation (Shadow Hand), aerial control (Quadcopter), and robotic arm tasks (Franka), demonstrate GenPO's superiority over existing RL baselines. Notably, GenPO is the first method to successfully integrate diffusion policies into on-policy RL, unlocking their potential for large-scale parallelized training and real-world robotic deployment.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.18763v4</guid></item><item><title>[cs updates on arXiv.org] BAH Dataset for Ambivalence/Hesitancy Recognition in Videos for Digital Behavioural Change</title><link>https://arxiv.org/abs/2505.19328</link><description>arXiv:2505.19328v3 Announce Type: replace 
Abstract: Ambivalence and hesitancy (A/H), a closely related construct, is the primary reasons why individuals delay, avoid, or abandon health behaviour changes. It is a subtle and conflicting emotion that sets a person in a state between positive and negative orientations, or between acceptance and refusal to do something. It manifests by a discord in affect between multiple modalities or within a modality, such as facial and vocal expressions, and body language. Although experts can be trained to recognize A/H as done for in-person interactions, integrating them into digital health interventions is costly and less effective. Automatic A/H recognition is therefore critical for the personalization and cost-effectiveness of digital behaviour change interventions. However, no datasets currently exists for the design of machine learning models to recognize A/H. This paper introduces the Behavioural Ambivalence/Hesitancy (BAH) dataset collected for multimodal recognition of A/H in videos. It contains 1,427 videos with a total duration of 10.60 hours captured from 300 participants across Canada answering predefined questions to elicit A/H. It is intended to mirror real-world online personalized behaviour change interventions. BAH is annotated by three experts to provide timestamps that indicate where A/H occurs, and frame- and video-level annotations with A/H cues. Video transcripts, cropped and aligned faces, and participants' meta-data are also provided. Since A and H manifest similarly in practice, we provide a binary annotation indicating the presence or absence of A/H. Additionally, this paper includes benchmarking results using baseline models on BAH for frame- and video-level recognition, zero-shot prediction, and personalization using source-free domain adaptation. The data, code, and pretrained weights are available.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.19328v3</guid></item><item><title>[cs updates on arXiv.org] OccLE: Label-Efficient 3D Semantic Occupancy Prediction</title><link>https://arxiv.org/abs/2505.20617</link><description>arXiv:2505.20617v4 Announce Type: replace 
Abstract: 3D semantic occupancy prediction offers an intuitive and efficient scene understanding and has attracted significant interest in autonomous driving perception. Existing approaches either rely on full supervision, which demands costly voxel-level annotations, or on self-supervision, which provides limited guidance and yields suboptimal performance. To address these challenges, we propose OccLE, a Label-Efficient 3D Semantic Occupancy Prediction that takes images and LiDAR as inputs and maintains high performance with limited voxel annotations. Our intuition is to decouple the semantic and geometric learning tasks and then fuse the learned feature grids from both tasks for the final semantic occupancy prediction. Therefore, the semantic branch distills 2D foundation model to provide aligned pseudo labels for 2D and 3D semantic learning. The geometric branch integrates image and LiDAR inputs in cross-plane synergy based on their inherency, employing semi-supervision to enhance geometry learning. We fuse semantic-geometric feature grids through Dual Mamba and incorporate a scatter-accumulated projection to supervise unannotated prediction with aligned pseudo labels. Experiments show that OccLE achieves competitive performance with only 10\% of voxel annotations on the SemanticKITTI and Occ3D-nuScenes datasets. The code will be publicly released on https://github.com/NerdFNY/OccLE</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.20617v4</guid></item><item><title>[cs updates on arXiv.org] NLP for Social Good: A Survey and Outlook of Challenges, Opportunities, and Responsible Deployment</title><link>https://arxiv.org/abs/2505.22327</link><description>arXiv:2505.22327v2 Announce Type: replace 
Abstract: Natural language processing (NLP) now shapes many aspects of our world, yet its potential for positive social impact is underexplored. This paper surveys work in ``NLP for Social Good" (NLP4SG) across nine domains relevant to global development and risk agendas, summarizing principal tasks and challenges. We analyze ACL Anthology trends, finding that inclusion and AI harms attract the most research, while domains such as poverty, peacebuilding, and environmental protection remain underexplored. Guided by our review, we outline opportunities for responsible and equitable NLP and conclude with a call for cross-disciplinary partnerships and human-centered approaches to ensure that future NLP technologies advance the public good.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.22327v2</guid></item><item><title>[cs updates on arXiv.org] MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Dialogue Evaluators</title><link>https://arxiv.org/abs/2505.22777</link><description>arXiv:2505.22777v5 Announce Type: replace 
Abstract: Evaluating the quality of open-domain chatbots has become increasingly reliant on LLMs acting as automatic judges. However, existing meta-evaluation benchmarks are static, outdated, and lacking in multilingual coverage, limiting their ability to fully capture subtle weaknesses in evaluation. We introduce MEDAL, an automated multi-agent framework for curating more representative and diverse open-domain dialogue evaluation benchmarks. Our approach leverages several state-of-the-art LLMs to generate user-chatbot multilingual dialogues, conditioned on varied seed contexts. Then, a strong LLM (GPT-4.1) is used for a multidimensional analysis of the performance of the chatbots, uncovering noticeable cross-lingual performance differences. Guided by this large-scale evaluation, we curate a new meta-evaluation multilingual benchmark and human-annotate samples with nuanced quality judgments. This benchmark is then used to assess the ability of several reasoning and non-reasoning LLMs to act as evaluators of open-domain dialogues. Using MEDAL, we uncover that state-of-the-art judges fail to reliably detect nuanced issues such as lack of empathy, commonsense, or relevance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.22777v5</guid></item><item><title>[cs updates on arXiv.org] Skin Lesion Phenotyping via Nested Multi-modal Contrastive Learning</title><link>https://arxiv.org/abs/2505.23709</link><description>arXiv:2505.23709v2 Announce Type: replace 
Abstract: We introduce SLIMP (Skin Lesion Image-Metadata Pre-training) for learning rich representations of skin lesions through a novel nested contrastive learning approach that captures complex relationships between images and metadata. Melanoma detection and skin lesion classification based solely on images, pose significant challenges due to large variations in imaging conditions (lighting, color, resolution, distance, etc.) and lack of clinical and phenotypical context. Clinicians typically follow a holistic approach for assessing the risk level of the patient and for deciding which lesions may be malignant and need to be excised, by considering the patient's medical history as well as the appearance of other lesions of the patient. Inspired by this, SLIMP combines the appearance and the metadata of individual skin lesions with patient-level metadata relating to their medical record and other clinically relevant information. By fully exploiting all available data modalities throughout the learning process, the proposed pre-training strategy improves performance compared to other pre-training strategies on downstream skin lesions classification tasks highlighting the learned representations quality.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.23709v2</guid></item><item><title>[cs updates on arXiv.org] R-KV: Redundancy-aware KV Cache Compression for Reasoning Models</title><link>https://arxiv.org/abs/2505.24133</link><description>arXiv:2505.24133v4 Announce Type: replace 
Abstract: Reasoning models have demonstrated impressive performance in self-reflection and chain-of-thought reasoning. However, they often produce excessively long outputs, leading to prohibitively large key-value (KV) caches during inference. While chain-of-thought inference significantly improves performance on complex reasoning tasks, it can also lead to reasoning failures when deployed with existing KV cache compression approaches. To address this, we propose Redundancy-aware KV Cache Compression for Reasoning models (R-KV), a novel method specifically targeting redundant tokens in reasoning models. Our method preserves nearly 100% of the full KV cache performance using only 10% of the KV cache, substantially outperforming existing KV cache baselines, which reach only 60% of the performance. Remarkably, R-KV even achieves 105% of full KV cache performance with 16% of the KV cache. This KV-cache reduction also leads to a 90% memory saving and a 6.6X throughput over standard chain-of-thought reasoning inference. Experimental results show that R-KV consistently outperforms existing KV cache compression baselines across two mathematical reasoning datasets.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.24133v4</guid></item><item><title>[cs updates on arXiv.org] MMSU: A Massive Multi-task Spoken Language Understanding and Reasoning Benchmark</title><link>https://arxiv.org/abs/2506.04779</link><description>arXiv:2506.04779v2 Announce Type: replace 
Abstract: Speech inherently contains rich acoustic information that extends far beyond the textual language. In real-world spoken language understanding, effective interpretation often requires integrating semantic meaning (e.g., content), paralinguistic features (e.g., emotions, speed, pitch) and phonological characteristics (e.g., prosody, intonation, rhythm), which are embedded in speech. While recent multimodal Speech Large Language Models (SpeechLLMs) have demonstrated remarkable capabilities in processing audio information, their ability to perform fine-grained perception and complex reasoning in natural speech remains largely unexplored. To address this gap, we introduce MMSU, a comprehensive benchmark designed specifically for understanding and reasoning in spoken language. MMSU comprises 5,000 meticulously curated audio-question-answer triplets across 47 distinct tasks. To ground our benchmark in linguistic theory, we systematically incorporate a wide range of linguistic phenomena, including phonetics, prosody, rhetoric, syntactics, semantics, and paralinguistics. Through a rigorous evaluation of 14 advanced SpeechLLMs, we identify substantial room for improvement in existing models, highlighting meaningful directions for future optimization. MMSU establishes a new standard for comprehensive assessment of spoken language understanding, providing valuable insights for developing more sophisticated human-AI speech interaction systems. MMSU benchmark is available at https://huggingface.co/datasets/ddwang2000/MMSU. Evaluation Code is available at https://github.com/dingdongwang/MMSU_Bench.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.04779v2</guid></item><item><title>[cs updates on arXiv.org] How malicious AI swarms can threaten democracy: The fusion of agentic AI and LLMs marks a new frontier in information warfare</title><link>https://arxiv.org/abs/2506.06299</link><description>arXiv:2506.06299v4 Announce Type: replace 
Abstract: Advances in AI offer the prospect of manipulating beliefs and behaviors on a population-wide level. Large language models and autonomous agents now let influence campaigns reach unprecedented scale and precision. Generative tools can expand propaganda output without sacrificing credibility and inexpensively create falsehoods that are rated as more human-like than those written by humans. Techniques meant to refine AI reasoning, such as chain-of-thought prompting, can just as effectively be used to generate more convincing falsehoods. Enabled by these capabilities, a disruptive threat is emerging: swarms of collaborative, malicious AI agents. Fusing LLM reasoning with multi-agent architectures, these systems are capable of coordinating autonomously, infiltrating communities, and fabricating consensus efficiently. By adaptively mimicking human social dynamics, they threaten democracy. Because the resulting harms stem from design, commercial incentives, and governance, we prioritize interventions at multiple leverage points, focusing on pragmatic mechanisms over voluntary compliance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.06299v4</guid></item><item><title>[cs updates on arXiv.org] The PML method for calculating the propagative wave numbers of electromagnetic wave in periodic structures</title><link>https://arxiv.org/abs/2506.07084</link><description>arXiv:2506.07084v2 Announce Type: replace 
Abstract: When the electromagnetic wave is incident on the periodic structures, in addition to the scattering field, some guided modes that are traveling in the periodic medium could be generated. In the present paper, we study the calculation of guided modes. We formulate the problem as a nonlinear eigenvalue problem in an unbounded periodic domain. Then we use perfectly matched layers to truncate the unbounded domain, recast the problem to a quadratic eigenvalue problem, and prove the approximation property of the truncation. Finally, we formulate the quadratic eigenvalue problem to a general eigenvalue problem, use the finite element method to discrete the truncation problem, and show numerical examples to verify theoretical results.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.07084v2</guid></item><item><title>[cs updates on arXiv.org] VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning</title><link>https://arxiv.org/abs/2506.09049</link><description>arXiv:2506.09049v3 Announce Type: replace 
Abstract: Coordinating multiple embodied agents in dynamic environments remains a core challenge in artificial intelligence, requiring both perception-driven reasoning and scalable cooperation strategies. While recent works have leveraged large language models (LLMs) for multi-agent planning, a few have begun to explore vision-language models (VLMs) for visual reasoning. However, these VLM-based approaches remain limited in their support for diverse embodiment types. In this work, we introduce VIKI-Bench, the first hierarchical benchmark tailored for embodied multi-agent cooperation, featuring three structured levels: agent activation, task planning, and trajectory perception. VIKI-Bench includes diverse robot embodiments, multi-view visual observations, and structured supervision signals to evaluate reasoning grounded in visual inputs. To demonstrate the utility of VIKI-Bench, we propose VIKI-R, a two-stage framework that fine-tunes a pretrained vision-language model (VLM) using Chain-of-Thought annotated demonstrations, followed by reinforcement learning under multi-level reward signals. Our extensive experiments show that VIKI-R significantly outperforms baselines method across all task levels. Furthermore, we show that reinforcement learning enables the emergence of compositional cooperation patterns among heterogeneous agents. Together, VIKI-Bench and VIKI-R offer a unified testbed and method for advancing multi-agent, visual-driven cooperation in embodied AI systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.09049v3</guid></item><item><title>[cs updates on arXiv.org] EmbedAgent: Benchmarking Large Language Models in Embedded System Development</title><link>https://arxiv.org/abs/2506.11003</link><description>arXiv:2506.11003v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have shown promise in various tasks, yet few benchmarks assess their capabilities in embedded system development.In this paper, we introduce EmbedAgent, a paradigm designed to simulate real-world roles in embedded system development, such as Embedded System Programmer, Architect, and Integrator. This paradigm enables LLMs to be tested in tasks that bridge the gap between digital and physical systems, allowing for a more comprehensive assessment of their capabilities. To evaluate LLMs on these tasks, we propose Embedbench, the first comprehensive benchmark for embedded system programming, circuit design, and cross-platform migration.Embedbench consists of 126 cases, covering 9 electronic components across 3 hardware platforms. Through extensive experiments on 10 mainstream LLMs, we uncover several key findings. Surprisingly, despite the simplicity of the cases, DeepSeek-R1 achieves only a 55.6% pass@1 rate when provided with schematic information, and 50.0% when tasked with generating the schematics itself. In the cross-platform migration tasks, LLMs show relatively strong performance with MicroPython on the Raspberry Pi Pico (with the top model achieving 73.8% pass@1), but perform poorly on ESP-IDF, where the best model reaches only 29.4% pass@1.Interestingly, we observe that general-purpose chat LLMs like DeepSeek-V3 often fail to utilize relevant pre-trained knowledge in this domain, while reasoning LLMs tend to overthink and overlook efficient knowledge during pretraining. Based on these insights, we propose two strategies: retrieval augmented generation and compiler feedback-to enhance LLM performance. These strategies result in significant improvements, with Deepseek-R1 reaching a 65.1% pass@1 with correct schematics, and 53.1% without. Additionally, the accuracy of the Arduino to ESP32 migration task improves from 21.4% to 27.8%.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.11003v2</guid></item><item><title>[cs updates on arXiv.org] Advances in LLMs with Focus on Reasoning, Adaptability, Efficiency and Ethics</title><link>https://arxiv.org/abs/2506.12365</link><description>arXiv:2506.12365v3 Announce Type: replace 
Abstract: This survey paper outlines the key developments in the field of Large Language Models (LLMs), including enhancements to their reasoning skills, adaptability to various tasks, increased computational efficiency, and the ability to make ethical decisions. The techniques that have been most effective in bridging the gap between human and machine communications include the Chain-of-Thought prompting, Instruction Tuning, and Reinforcement Learning from Human Feedback. The improvements in multimodal learning and few-shot or zero-shot techniques have further empowered LLMs to handle complex jobs with minor input. A significant focus is placed on efficiency, detailing scaling strategies, optimization techniques, and the influential Mixture-of-Experts (MoE) architecture, which strategically routes inputs to specialized subnetworks to boost predictive accuracy, while optimizing resource allocation. This survey also offers a broader perspective on recent advancements in LLMs, going beyond isolated aspects such as model architecture or ethical concerns. Additionally, it explores the role of LLMs in Agentic AI and their use as Autonomous Decision-Making Systems, and categorizes emerging methods that enhance LLM reasoning, efficiency, and ethical alignment. The survey also identifies underexplored areas such as interpretability, cross-modal integration, and sustainability. While significant advancements have been made in LLMs, challenges such as high computational costs, biases, and ethical risks remain. Overcoming these requires a focus on bias mitigation, transparent decision-making, and explicit ethical guidelines. Future research will generally focus on enhancing the model's ability to handle multiple inputs, thereby making it more intelligent, safe, and reliable.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.12365v3</guid></item><item><title>[cs updates on arXiv.org] Rasterizing Wireless Radiance Field via Deformable 2D Gaussian Splatting</title><link>https://arxiv.org/abs/2506.12787</link><description>arXiv:2506.12787v3 Announce Type: replace 
Abstract: Modeling the wireless radiance field (WRF) is fundamental to modern communication systems, enabling key tasks such as localization, sensing, and channel estimation. Traditional approaches, which rely on empirical formulas or physical simulations, often suffer from limited accuracy or require strong scene priors. Recent neural radiance field (NeRF-based) methods improve reconstruction fidelity through differentiable volumetric rendering, but their reliance on computationally expensive multilayer perceptron (MLP) queries hinders real-time deployment. To overcome these challenges, we introduce Gaussian splatting (GS) to the wireless domain, leveraging its efficiency in modeling optical radiance fields to enable compact and accurate WRF reconstruction. Specifically, we propose SwiftWRF, a deformable 2D Gaussian splatting framework that synthesizes WRF spectra at arbitrary positions under single-sided transceiver mobility. SwiftWRF employs CUDA-accelerated rasterization to render spectra at over 100000 fps and uses a lightweight MLP to model the deformation of 2D Gaussians, effectively capturing mobility-induced WRF variations. In addition to novel spectrum synthesis, the efficacy of SwiftWRF is further underscored in its applications in angle-of-arrival (AoA) and received signal strength indicator (RSSI) prediction. Experiments conducted on both real-world and synthetic indoor scenes demonstrate that SwiftWRF can reconstruct WRF spectra up to 500x faster than existing state-of-the-art methods, while significantly enhancing its signal quality. The project page is https://evan-sudo.github.io/swiftwrf/.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.12787v3</guid></item><item><title>[cs updates on arXiv.org] KEPLA: A Knowledge-Enhanced Deep Learning Framework for Accurate Protein-Ligand Binding Affinity Prediction</title><link>https://arxiv.org/abs/2506.13196</link><description>arXiv:2506.13196v4 Announce Type: replace 
Abstract: Accurate prediction of protein-ligand binding affinity is critical for drug discovery. While recent deep learning approaches have demonstrated promising results, they often rely solely on structural features of proteins and ligands, overlooking their valuable biochemical knowledge associated with binding affinity. To address this limitation, we propose KEPLA, a novel deep learning framework that explicitly integrates prior knowledge from Gene Ontology and ligand properties to enhance prediction performance. KEPLA takes protein sequences and ligand molecular graphs as input and optimizes two complementary objectives: (1) aligning global representations with knowledge graph relations to capture domain-specific biochemical insights, and (2) leveraging cross attention between local representations to construct fine-grained joint embeddings for prediction. Experiments on two benchmark datasets across both in-domain and cross-domain scenarios demonstrate that KEPLA consistently outperforms state-of-the-art baselines. Furthermore, interpretability analyses based on knowledge graph relations and cross attention maps provide valuable insights into the underlying predictive mechanisms.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.13196v4</guid></item><item><title>[cs updates on arXiv.org] DAGs for the Masses</title><link>https://arxiv.org/abs/2506.13998</link><description>arXiv:2506.13998v3 Announce Type: replace 
Abstract: A recent approach to building consensus protocols on top of Directed Acyclic Graphs (DAGs) shows much promise due to its simplicity and stable throughput. However, as each node in the DAG typically includes a linear number of references to the nodes in the previous round, prior DAG protocols only scale up to a certain point when the overhead of maintaining the graph becomes the bottleneck.
  To enable large-scale deployments of DAG-based protocols, we propose a sparse DAG architecture, where each node includes only a constant number of references to random nodes in the previous round. We present a sparse version of Bullshark -- one of the most prominent DAG-based consensus protocols -- and demonstrate its improved scalability.
  Remarkably, unlike other protocols that use random sampling to reduce communication complexity, we manage to avoid sacrificing resilience: the protocol can tolerate up to $f&lt;n/3$ Byzantine faults (where $n$ is the number of participants), same as its less scalable deterministic counterpart. The proposed ``sparse'' methodology can be applied to any protocol that maintains disseminated system updates and causal relations between them in a graph-like structure. Our simulations show that the considerable reduction of transmitted metadata in sparse DAGs results in more efficient network utilization and better scalability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.13998v3</guid></item><item><title>[cs updates on arXiv.org] FormGym: Doing Paperwork with Agents</title><link>https://arxiv.org/abs/2506.14079</link><description>arXiv:2506.14079v3 Announce Type: replace 
Abstract: Completing paperwork is a challenging and time-consuming problem. Form filling is especially challenging in the pure-image domain without access to OCR, typeset PDF text, or a DOM. For computer agents, it requires multiple abilities, including multi-modal understanding, information retrieval, and tool-use. We present a novel form-filling benchmark consisting of 432 fields spread across 55 documents and 3 tasks, requiring knowledge of 236 features per user. We find that baseline VLAs achieve less than 1% accuracy in most cases, primarily due to poor localization ability. GUI agents also struggle, scoring between 10.6-68.0% despite high cost and latency. Therefore, we also contribute FieldFinder, a tool to assist LLMs in identifying where to place text on a form. With FieldFinder, all models achieve equal or better performance in all six study conditions, with a maximum increase from 2% to 56%.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.14079v3</guid></item><item><title>[cs updates on arXiv.org] Dynamic Exploration on Segment-Proposal Graphs for Tubular Centerline Tracking</title><link>https://arxiv.org/abs/2506.18930</link><description>arXiv:2506.18930v2 Announce Type: replace 
Abstract: Optimal curve methods provide a fundamental framework for tubular centerline tracking. Point-wise approaches, such as minimal paths, are theoretically elegant but often suffer from shortcut and short-branch combination problems in complex scenarios. Nonlocal segment-wise methods address these issues by mapping pre-extracted centerline fragments onto a segment-proposal graph, performing optimization in this abstract space, and recovering the target tubular centerline from the resulting optimal path. In this paradigm, graph construction is critical, as it directly determines the quality of the final result. However, existing segment-wise methods construct graphs in a static manner, requiring all edges and their weights to be pre-computed, i.e. the graph must be sufficiently complete prior to search. Otherwise, the true path may be absent from the candidate space, leading to search failure. To address this limitation, we propose a dynamic exploration scheme for constructing segment-proposal graphs, where the graph is built on demand during the search for optimal paths. By formulating the problem as a Markov decision process, we apply Q-learning to compute edge weights only for visited transitions and adaptively expand the action space when connectivity is insufficient. Experimental results on retinal vessels, roads, and rivers demonstrate consistent improvements over state-of-the-art methods in both accuracy and efficiency.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.18930v2</guid></item><item><title>[cs updates on arXiv.org] MultiHuman-Testbench: Benchmarking Image Generation for Multiple Humans</title><link>https://arxiv.org/abs/2506.20879</link><description>arXiv:2506.20879v4 Announce Type: replace 
Abstract: Generation of images containing multiple humans, performing complex actions, while preserving their facial identities, is a significant challenge. A major factor contributing to this is the lack of a dedicated benchmark. To address this, we introduce MultiHuman-Testbench, a novel benchmark for rigorously evaluating generative models for multi-human generation. The benchmark comprises 1,800 samples, including carefully curated text prompts, describing a range of simple to complex human actions. These prompts are matched with a total of 5,550 unique human face images, sampled uniformly to ensure diversity across age, ethnic background, and gender. Alongside captions, we provide human-selected pose conditioning images which accurately match the prompt. We propose a multi-faceted evaluation suite employing four key metrics to quantify face count, ID similarity, prompt alignment, and action detection. We conduct a thorough evaluation of a diverse set of models, including zero-shot approaches and training-based methods, with and without regional priors. We also propose novel techniques to incorporate image and region isolation using human segmentation and Hungarian matching, significantly improving ID similarity. Our proposed benchmark and key findings provide valuable insights and a standardized tool for advancing research in multi-human image generation. The dataset and evaluation codes will be available at https://github.com/Qualcomm-AI-research/MultiHuman-Testbench.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.20879v4</guid></item><item><title>[cs updates on arXiv.org] SciArena: An Open Evaluation Platform for Non-Verifiable Scientific Literature-Grounded Tasks</title><link>https://arxiv.org/abs/2507.01001</link><description>arXiv:2507.01001v2 Announce Type: replace 
Abstract: We present SciArena, an open and collaborative platform for evaluating foundation models on scientific literature-grounded tasks. Unlike traditional benchmarks for scientific literature understanding and synthesis, SciArena engages the research community directly, following the Chatbot Arena evaluation approach of community voting on model comparisons. By leveraging collective intelligence, SciArena offers a community-driven evaluation of model performance on open-ended scientific tasks that demand literature-grounded, long-form responses. The platform currently supports 47 foundation models and has collected over 20,000 votes from human researchers across diverse scientific domains. Our analysis of the data collected so far confirms its high quality. We discuss the results and insights based on the model ranking leaderboard. To further promote research in building model-based automated evaluation systems for literature tasks, we release SciArena-Eval, a meta-evaluation benchmark based on collected preference data. It measures the accuracy of models in judging answer quality by comparing their pairwise assessments with human votes. Our experiments highlight the benchmark's challenges and emphasize the need for more reliable automated evaluation methods.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.01001v2</guid></item><item><title>[cs updates on arXiv.org] Training-Free Geospatial Place Representation Learning from Large-Scale Point-of-Interest Graph Data</title><link>https://arxiv.org/abs/2507.02921</link><description>arXiv:2507.02921v3 Announce Type: replace 
Abstract: Learning effective representations of urban environments requires capturing spatial structure beyond fixed administrative boundaries. Existing geospatial representation learning approaches typically aggregate Points of Interest(POI) into pre-defined administrative regions such as census units or ZIP code areas, assigning a single embedding to each region. However, POIs often form semantically meaningful groups that extend across, within, or beyond these boundaries, defining places that better reflect human activity and urban function. To address this limitation, we propose PlaceRep, a training-free geospatial representation learning method that constructs place-level representations by clustering spatially and semantically related POIs. PlaceRep summarizes large-scale POI graphs from U.S. Foursquare data to produce general-purpose urban region embeddings while automatically identifying places across multiple spatial scales. By eliminating model pre-training, PlaceRep provides a scalable and efficient solution for multi-granular geospatial analysis. Experiments using the tasks of population density estimation and housing price prediction as downstream tasks show that PlaceRep outperforms most state-of-the-art graph-based geospatial representation learning methods and achieves up to a 100x speedup in generating region-level representations on large-scale POI graphs. The implementation of PlaceRep is available at https://github.com/mohammadhashemii/PlaceRep.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.02921v3</guid></item><item><title>[cs updates on arXiv.org] Toward Efficient Speech Emotion Recognition via Spectral Learning and Attention</title><link>https://arxiv.org/abs/2507.03251</link><description>arXiv:2507.03251v3 Announce Type: replace 
Abstract: Speech Emotion Recognition (SER) traditionally relies on auditory data analysis for emotion classification. Several studies have adopted different methods for SER. However, existing SER methods often struggle to capture subtle emotional variations and generalize across diverse datasets. In this article, we use Mel-Frequency Cepstral Coefficients (MFCCs) as spectral features to bridge the gap between computational emotion processing and human auditory perception. To further improve robustness and feature diversity, we propose a novel 1D-CNN-based SER framework that integrates data augmentation techniques. MFCC features extracted from the augmented data are processed using a 1D Convolutional Neural Network (CNN) architecture enhanced with channel and spatial attention mechanisms. These attention modules allow the model to highlight key emotional patterns, enhancing its ability to capture subtle variations in speech signals. The proposed method delivers cutting-edge performance, achieving the accuracy of 97.49% for SAVEE, 99.23% for RAVDESS, 89.31% for CREMA-D, 99.82% for TESS, 99.53% for EMO-DB, and 96.39% for EMOVO. Experimental results show new benchmarks in SER, demonstrating the effectiveness of our approach in recognizing emotional expressions with high precision. Our evaluation demonstrates that the integration of advanced Deep Learning (DL) methods substantially enhances generalization across diverse datasets, underscoring their potential to advance SER for real-world deployment in assistive technologies and human-computer interaction.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.03251v3</guid></item><item><title>[cs updates on arXiv.org] You May Use the Same Channel Knowledge Map for Environment-Aware NLoS Sensing and Communication</title><link>https://arxiv.org/abs/2507.03589</link><description>arXiv:2507.03589v2 Announce Type: replace 
Abstract: As one of the key usage scenarios for the sixth generation (6G) wireless networks, integrated sensing and communication (ISAC) provides an efficient framework to achieve simultaneous wireless sensing and communication. However, traditional wireless sensing techniques mainly rely on the line-of-sight (LoS) assumptions, i.e., the sensing targets are directly visible to both the sensing transmitter and receiver. This hinders ISAC systems to be applied in complex environments such as the urban low-altitude airspace, which usually suffers from signal blockage and non-line-of-sight (NLoS) multi-path propagation. To address this challenge, in this paper, we propose a novel approach to enable environment-aware NLoS ISAC by leveraging the new technique called channel knowledge map (CKM), which was originally proposed for environment-aware wireless communications. One major novelty of our proposed method is that the same CKM built for wireless communication can be directly used to enable NLoS wireless sensing, thus enjoying the benefits of ``killing two birds with one stone''. To this end, the sensing targets are treated as virtual user equipment (UE), and the wireless communication channel priors are transformed into the sensing channel priors, allowing one single CKM to serve dual purposes. We illustrate our proposed framework by a specific CKM called \emph{channel angle-delay map} (CADM). Specifically, the proposed framework utilizes CADM to derive angle-delay priors of the sensing channel by exploiting the relationship between communication and sensing angle-delay distributions, enabling sensing target localization in the challenging NLoS environment. Extensive simulation results demonstrate significant performance improvements over classic geometry-based sensing methods, which is further validated by Cram\'er-Rao Lower Bound (CRLB) analysis.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.03589v2</guid></item><item><title>[cs updates on arXiv.org] Stability, Complexity and Data-Dependent Worst-Case Generalization Bounds</title><link>https://arxiv.org/abs/2507.06775</link><description>arXiv:2507.06775v2 Announce Type: replace 
Abstract: Providing generalization guarantees for stochastic optimization algorithms remains a key challenge in learning theory. Recently, numerous works demonstrated the impact of the geometric properties of optimization trajectories on generalization performance. These works propose worst-case generalization bounds in terms of various notions of intrinsic dimension and/or topological complexity, which were found to empirically correlate with the generalization error. However, most of these approaches involve intractable mutual information terms, which limit a full understanding of the bounds. In contrast, some authors built on algorithmic stability to obtain worst-case bounds involving geometric quantities of a combinatorial nature, which are impractical to compute. In this paper, we address these limitations by combining empirically relevant complexity measures with a framework that avoids intractable quantities. To this end, we introduce the concept of \emph{random set stability}, tailored for the data-dependent random sets produced by stochastic optimization algorithms. Within this framework, we show that the worst-case generalization error can be bounded in terms of (i) the random set stability parameter and (ii) empirically relevant, data- and algorithm-dependent complexity measures of the random set. Moreover, our framework improves existing topological generalization bounds by recovering previous complexity notions without relying on mutual information terms. Through a series of experiments in practically relevant settings, we validate our theory by evaluating the tightness of our bounds and the interplay between topological complexity and stability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.06775v2</guid></item><item><title>[cs updates on arXiv.org] DocPolarBERT: A Pre-trained Model for Document Understanding with Relative Polar Coordinate Encoding of Layout Structures</title><link>https://arxiv.org/abs/2507.08606</link><description>arXiv:2507.08606v4 Announce Type: replace 
Abstract: We introduce DocPolarBERT, a layout-aware BERT model for document understanding that eliminates the need for absolute 2D positional embeddings. We extend self-attention to take into account text block positions in relative polar coordinate system rather than the Cartesian one. Despite being pre-trained on a dataset more than six times smaller than the widely used IIT-CDIP corpus, DocPolarBERT achieves state-of-the-art results. These results demonstrate that a carefully designed attention mechanism can compensate for reduced pre-training data, offering an efficient and effective alternative for document understanding.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.08606v4</guid></item><item><title>[cs updates on arXiv.org] A Unified Framework for Efficient Kernel and Polynomial Interpolation</title><link>https://arxiv.org/abs/2507.12629</link><description>arXiv:2507.12629v3 Announce Type: replace 
Abstract: We present a unified interpolation scheme that combines compactly-supported positive-definite kernels and multivariate polynomials. This unified framework generalizes interpolation with compactly-supported kernels and also classical polynomial least squares approximation. To facilitate the efficient use of this unified interpolation scheme, we present specialized numerical linear algebra procedures that leverage standard matrix factorizations. These procedures allow for efficient computation and storage of the unified interpolant. We also present a modification to the numerical linear algebra that allows us to generalize the application of the unified framework to target functions on manifolds with and without boundary. Our numerical experiments on both Euclidean domains and manifolds indicate that the unified interpolant is superior to polynomial least squares for the interpolation of target functions in settings with boundaries.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.12629v3</guid></item><item><title>[cs updates on arXiv.org] A Framework of Distributed Source Encryption using Mutual Information Security Criterion and the Strong Converse Theorem</title><link>https://arxiv.org/abs/2507.13294</link><description>arXiv:2507.13294v5 Announce Type: replace 
Abstract: We reinvestigate the general distributed secure source coding based on the common key cryptosystem proposed by Oohama and Santoso (ITW 2021). They proposed a framework of distributed source encryption and derived the necessary and sufficient conditions to have reliable and secure transmission. However, the bounds of the rate region, which specifies both necessary and sufficient conditions to have reliable and secure transmission under the proposed cryptosystem, were derived based on a self-tailored non-standard} security criterion. In this paper we adopt the standard security criterion, i.e., standard mutual information. We successfully establish the bounds of the rate region based on this security criterion. Information spectrum method and a variant of Birkhoff-von Neumann theorem play an important role in deriving the result.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.13294v5</guid></item><item><title>[cs updates on arXiv.org] VTarbel: Targeted Label Attack with Minimal Knowledge on Detector-enhanced Vertical Federated Learning</title><link>https://arxiv.org/abs/2507.14625</link><description>arXiv:2507.14625v2 Announce Type: replace 
Abstract: Vertical federated learning (VFL) enables multiple parties with disjoint features to collaboratively train models without sharing raw data. While privacy vulnerabilities of VFL are extensively-studied, its security threats-particularly targeted label attacks-remain underexplored. In such attacks, a passive party perturbs inputs at inference to force misclassification into adversary-chosen labels. Existing methods rely on unrealistic assumptions (e.g., accessing VFL-model's outputs) and ignore anomaly detectors deployed in real-world systems. To bridge this gap, we introduce VTarbel, a two-stage, minimal-knowledge attack framework explicitly designed to evade detector-enhanced VFL inference. During the preparation stage, the attacker selects a minimal set of high-expressiveness samples (via maximum mean discrepancy), submits them through VFL protocol to collect predicted labels, and uses these pseudo-labels to train estimated detector and surrogate model on local features. In attack stage, these models guide gradient-based perturbations of remaining samples, crafting adversarial instances that induce targeted misclassifications and evade detection. We implement VTarbel and evaluate it against four model architectures, seven multimodal datasets, and two anomaly detectors. Across all settings, VTarbel outperforms four state-of-the-art baselines, evades detection, and retains effective against three representative privacy-preserving defenses. These results reveal critical security blind spots in current VFL deployments and underscore urgent need for robust, attack-aware defenses.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.14625v2</guid></item><item><title>[cs updates on arXiv.org] VMask: Tunable Label Privacy Protection for Vertical Federated Learning via Layer Masking</title><link>https://arxiv.org/abs/2507.14629</link><description>arXiv:2507.14629v2 Announce Type: replace 
Abstract: Though vertical federated learning (VFL) is generally considered to be privacy-preserving, recent studies have shown that VFL system is vulnerable to label inference attacks originating from various attack surfaces. Among these attacks, the model completion (MC) attack is currently the most powerful one. Existing defense methods against it either sacrifice model accuracy or incur impractical computational overhead. In this paper, we propose VMask, a novel label privacy protection framework designed to defend against MC attack from the perspective of layer masking. Our key insight is to disrupt the strong correlation between input data and intermediate outputs by applying the secret sharing (SS) technique to mask layer parameters in the attacker's model. We devise a strategy for selecting critical layers to mask, reducing the overhead that would arise from naively applying SS to the entire model. Moreover, VMask is the first framework to offer a tunable privacy budget to defenders, allowing for flexible control over the levels of label privacy according to actual requirements. We built a VFL system, implemented VMask on it, and extensively evaluated it using five model architectures and 13 datasets with different modalities, comparing it to 12 other defense methods. The results demonstrate that VMask achieves the best privacy-utility trade-off, successfully thwarting the MC attack (reducing the label inference accuracy to a random guessing level) while preserving model performance (e.g., in Transformer-based model, the averaged drop of VFL model accuracy is only 0.09%). VMask's runtime is up to 60,846 times faster than cryptography-based methods, and it only marginally exceeds that of standard VFL by 1.8 times in a large Transformer-based model, which is generally acceptable.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.14629v2</guid></item><item><title>[cs updates on arXiv.org] Can Language Models Discover Scaling Laws?</title><link>https://arxiv.org/abs/2507.21184</link><description>arXiv:2507.21184v5 Announce Type: replace 
Abstract: Discovering scaling laws for predicting model performance at scale is a fundamental and open-ended challenge, mostly reliant on slow, case specific human experimentation. To investigate the potential for LLMs to automate this process, we collect over 5,000 experiments from existing literature and curate eight diverse scaling law discovery tasks. While existing agents struggle to produce accurate law formulas, this paper introduces SLDAgent, an evolution-based agent that co-optimize the scaling law model and the parameters, enabling it to autonomously explore complex relationships between variables. For the first time, we demonstrates that SLDAgent can automatically discover laws that exhibit consistently more accurate extrapolation than their established, human-derived counterparts across all tasks. Through comprehensive analysis, we elucidate why these discovered laws are superior and verify their practical utility in both pretraining and finetuning applications. This work establishes a new paradigm for agentic scientific discovery, showing that AI systems can understand their own scaling behavior, and can contribute novel and practical knowledge back to the research community.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.21184v5</guid></item><item><title>[cs updates on arXiv.org] SURE-Med: Systematic Uncertainty Reduction for Enhanced Reliability in Medical Report Generation</title><link>https://arxiv.org/abs/2508.01693</link><description>arXiv:2508.01693v2 Announce Type: replace 
Abstract: Automated medical report generation (MRG) holds great promise for reducing the heavy workload of radiologists. However, its clinical deployment is hindered by three major sources of uncertainty. First, visual uncertainty, caused by noisy or incorrect view annotations, compromises feature extraction. Second, label distribution uncertainty, stemming from long-tailed disease prevalence, biases models against rare but clinically critical conditions. Third, contextual uncertainty, introduced by unverified historical reports, often leads to factual hallucinations. These challenges collectively limit the reliability and clinical trustworthiness of MRG systems. To address these issues, we propose SURE-Med, a unified framework that systematically reduces uncertainty across three critical dimensions: visual, distributional, and contextual. To mitigate visual uncertainty, a Frontal-Aware View Repair Resampling module corrects view annotation errors and adaptively selects informative features from supplementary views. To tackle label distribution uncertainty, we introduce a Token Sensitive Learning objective that enhances the modeling of critical diagnostic sentences while reweighting underrepresented diagnostic terms, thereby improving sensitivity to infrequent conditions. To reduce contextual uncertainty, our Contextual Evidence Filter validates and selectively incorporates prior information that aligns with the current image, effectively suppressing hallucinations. Extensive experiments on the MIMIC-CXR and IU-Xray benchmarks demonstrate that SURE-Med achieves state-of-the-art performance. By holistically reducing uncertainty across multiple input modalities, SURE-Med sets a new benchmark for reliability in medical report generation and offers a robust step toward trustworthy clinical decision support.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.01693v2</guid></item><item><title>[cs updates on arXiv.org] Evolving in Tasks: Empowering the Multi-modality Large Language Model as the Computer Use Agent</title><link>https://arxiv.org/abs/2508.04037</link><description>arXiv:2508.04037v2 Announce Type: replace 
Abstract: Computer use agents represent an emerging area in artificial intelligence, aiming to operate computers autonomously to fulfill user tasks, attracting significant attention from both industry and academia. However, the performance of existing agents remains insufficient for practical deployment. In this paper, we propose the Self-Evolution Agent (SEA) for computer operation, alongside three core innovations in data generation, reinforcement learning, and model enhancement to develop this agent. Specifically, we first design an automatic pipeline to generate verifiable task trajectories for training. Second, we propose Efficient Step-wise Reinforcement Learning to reduce the substantial computational overhead of long-horizon training. Finally, we introduce a model enhancement method that integrates grounding and planning capabilities into a single model without additional training. Leveraging these innovations, our SEA (with only 7B parameters) outperforms existing models of the same parameter scale and achieves performance comparable to larger models (e.g., 32B/72B parameters) on computer use tasks. We plan to release the model weights and related code as open-source resources in the future.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.04037v2</guid></item><item><title>[cs updates on arXiv.org] Cohesive Group Discovery in Interaction Graphs under Explicit Density Constraints</title><link>https://arxiv.org/abs/2508.04174</link><description>arXiv:2508.04174v3 Announce Type: replace 
Abstract: Discovering cohesive groups is a fundamental primitive in graph-based recommender systems, underpinning tasks such as social recommendation, bundle discovery, and community-aware modeling. In interaction graphs, cohesion is often modeled as the $\gamma$-quasi-clique, an induced subgraph whose internal edge density meets a user-defined threshold $\gamma$. This formulation provides explicit control over within-group connectivity while accommodating the sparsity inherent in real-world data. This paper presents EDQC, an effective framework for cohesive group discovery under explicit density constraints. EDQC leverages a lightweight energy diffusion process to rank vertices for localizing promising candidate regions. Guided by this ranking, the framework extracts and refines a candidate subgraph to ensure the output strictly satisfies the target density requirement. Extensive experiments on 75 real-world graphs across varying density thresholds demonstrate that EDQC identifies the largest mean $\gamma$-quasi-cliques in the vast majority of cases, achieving lower variance than the state-of-the-art methods while maintaining competitive runtime. Furthermore, statistical analysis confirms that EDQC significantly outperforms the baselines, underscoring its robustness and practical utility for cohesive group discovery in graph-based recommender systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.04174v3</guid></item><item><title>[cs updates on arXiv.org] ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline</title><link>https://arxiv.org/abs/2508.06094</link><description>arXiv:2508.06094v3 Announce Type: replace 
Abstract: Constructed languages (conlangs) such as Esperanto and Quenya have played diverse roles in art, philosophy, and international communication. Meanwhile, foundation models have revolutionized creative generation in text, images, and beyond. In this work, we leverage modern LLMs as computational creativity aids for end-to-end conlang creation. We introduce ConlangCrafter, a multi-hop pipeline that decomposes language design into modular stages -- phonology, morphology, syntax, lexicon generation, and translation. At each stage, our method leverages LLMs' metalinguistic reasoning capabilities, injecting randomness to encourage diversity and leveraging self-refinement feedback to encourage consistency in the emerging language description. We construct a novel, scalable evaluation framework for this task, evaluating metrics measuring consistency and typological diversity. Automatic and manual evaluations demonstrate ConlangCrafter's ability to produce coherent and varied conlangs without human linguistic expertise.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.06094v3</guid></item><item><title>[cs updates on arXiv.org] A Segmentation-driven Editing Method for Bolt Defect Augmentation and Detection</title><link>https://arxiv.org/abs/2508.10509</link><description>arXiv:2508.10509v3 Announce Type: replace 
Abstract: Bolt defect detection is critical to ensure the safety of transmission lines. However, the scarcity of defect images and imbalanced data distributions significantly limit detection performance. To address this problem, we propose a segmentationdriven bolt defect editing method (SBDE) to augment the dataset. First, a bolt attribute segmentation model (Bolt-SAM) is proposed, which enhances the segmentation of complex bolt attributes through the CLAHE-FFT Adapter (CFA) and Multipart- Aware Mask Decoder (MAMD), generating high-quality masks for subsequent editing tasks. Second, a mask optimization module (MOD) is designed and integrated with the image inpainting model (LaMa) to construct the bolt defect attribute editing model (MOD-LaMa), which converts normal bolts into defective ones through attribute editing. Finally, an editing recovery augmentation (ERA) strategy is proposed to recover and put the edited defect bolts back into the original inspection scenes and expand the defect detection dataset. We constructed multiple bolt datasets and conducted extensive experiments. Experimental results demonstrate that the bolt defect images generated by SBDE significantly outperform state-of-the-art image editing models, and effectively improve the performance of bolt defect detection, which fully verifies the effectiveness and application potential of the proposed method. The code of the project is available at https://github.com/Jay-xyj/SBDE.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.10509v3</guid></item><item><title>[cs updates on arXiv.org] Mantis: A Foundation Model for Mechanistic Disease Forecasting</title><link>https://arxiv.org/abs/2508.12260</link><description>arXiv:2508.12260v4 Announce Type: replace 
Abstract: Infectious disease forecasting in novel outbreaks or low-resource settings is hampered by the need for large disease and covariate data sets, bespoke training, and expert tuning, all of which can hinder rapid generation of forecasts for new settings. To help address these challenges, we developed Mantis, a foundation model trained entirely on mechanistic simulations, which enables out-of-the-box forecasting across diseases, regions, and outcomes, even in settings with limited historical data. We evaluated Mantis against 48 forecasting models across six diseases with diverse modes of transmission, assessing both point forecast accuracy (mean absolute error) and probabilistic performance (weighted interval score and coverage). Despite using no real-world data during training, Mantis achieved lower mean absolute error than all models in the CDC's COVID-19 Forecast Hub when backtested on early pandemic forecasts which it had not previously seen. Across all other diseases tested, Mantis consistently ranked in the top two models across evaluation metrics. Mantis further generalized to diseases with transmission mechanisms not represented in its training data, demonstrating that it can capture fundamental contagion dynamics rather than memorizing disease-specific patterns. These capabilities illustrate that purely simulation-based foundation models such as Mantis can provide a practical foundation for disease forecasting: general-purpose, accurate, and deployable where traditional models struggle.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.12260v4</guid></item><item><title>[cs updates on arXiv.org] Toward Robust Semi-supervised Regression via Dual-stream Knowledge Distillation</title><link>https://arxiv.org/abs/2508.14082</link><description>arXiv:2508.14082v2 Announce Type: replace 
Abstract: Semi-supervised regression (SSR), which aims to predict continuous scores of samples while reducing reliance on a large amount of labeled data, has recently received considerable attention across various applications, including computer vision, natural language processing, and audio and medical analysis. Existing SSR methods typically train models on scarce labeled data by introducing constraint-based regularization or ordinal ranking to reduce overfitting. However, these approaches fail to fully exploit the abundance of unlabeled samples. While consistency-driven pseudo-labeling methods attempt to incorporate unlabeled data, they are highly sensitive to pseudo-label quality and noisy predictions. To address these challenges, we introduce a Dual-stream Knowledge Distillation framework (DKD), which is specially designed for the SSR task to distill knowledge from both continuous-valued knowledge and distribution information, better preserving regression magnitude information and improving sample efficiency. Specifically, in DKD, the teacher is optimized solely with ground-truth labels for label distribution estimation, while the student learns from a mixture of real labels and teacher-generated pseudo targets on unlabeled data. The distillation design ensures the effective supervision transfer, allowing the student to leverage pseudo labels more robustly. Then, we introduce an advanced Decoupled Distribution Alignment (DDA) to align the target class and non-target class between teacher and student on the distribution, enhancing the student's capacity to mitigate noise in pseudo-label supervision and learn a more well-calibrated regression predictor.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.14082v2</guid></item><item><title>[cs updates on arXiv.org] Evaluating the Defense Potential of Machine Unlearning against Membership Inference Attacks</title><link>https://arxiv.org/abs/2508.16150</link><description>arXiv:2508.16150v4 Announce Type: replace 
Abstract: Membership Inference Attacks (MIAs) pose a significant privacy risk by enabling adversaries to determine if a specific data point was part of a model's training set. This work empirically investigates whether MU algorithms can function as a targeted, active defense mechanism, in scenarios where a privacy audit identifies specific classes or individuals as highly susceptible to MIAs post-training. By 'dulling' the model's categorical memory of these samples, the process effectively mitigates the membership signal and reduces the MIA success rate for the most vulnerable users. We evaluate the defense potential of three MU algorithms, Negative Gradient (neg grad), SCalable Remembering and Unlearning unBound (SCRUB), and Selective Fine-tuning and Targeted Confusion (SFTC), across four diverse datasets and three complexity-based model groups. Our findings reveal that MU can function as a countermeasure against MIAs, though its success is critically contingent on algorithm choice, model capacity, and a profound sensitivity to learning rates. While Negative Gradient often induces a generalized degradation of membership signals across both forget and retain set, SFTC identifies a critical ``divergence effect'' where targeted forgetting reinforces the membership signal of retained data. Conversely, SCRUB provides a more balanced defense with minimal collateral impact on MIA perspective.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.16150v4</guid></item><item><title>[cs updates on arXiv.org] Being Kind Isn't Always Being Safe: Diagnosing Affective Hallucination in LLMs</title><link>https://arxiv.org/abs/2508.16921</link><description>arXiv:2508.16921v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) are increasingly engaged in emotionally vulnerable conversations that extend beyond information seeking to moments of personal distress. As they adopt affective tones and simulate empathy, they risk creating the illusion of genuine relational connection. We term this phenomenon Affective Hallucination, referring to emotionally immersive responses that evoke false social presence despite the model's lack of affective capacity. To address this, we introduce AHaBench, a benchmark of 500 mental-health-related prompts with expert-informed reference responses, evaluated along three dimensions: Emotional Enmeshment, Illusion of Presence, and Fostering Overdependence. We further release AHaPairs, a 5K-instance preference dataset enabling Direct Preference Optimization (DPO) for alignment with emotionally responsible behavior. DPO fine-tuning substantially reduces affective hallucination without compromising reasoning performance, and the Pearson correlation coefficients between GPT-4o and human judgments is also strong (r=0.85) indicating that human evaluations confirm AHaBench as an effective diagnostic tool. This work establishes affective hallucination as a distinct safety concern and provides resources for developing LLMs that are both factually reliable and psychologically safe. AHaBench and AHaPairs are accessible via https://huggingface.co/datasets/o0oMiNGo0o/AHaBench, and code for fine-tuning and evaluation are in https://github.com/0oOMiNGOo0/AHaBench. Warning: This paper contains examples of mental health-related language that may be emotionally distressing.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.16921v2</guid></item><item><title>[cs updates on arXiv.org] Evaluating Compiler Optimization Impacts on zkVM Performance</title><link>https://arxiv.org/abs/2508.17518</link><description>arXiv:2508.17518v2 Announce Type: replace 
Abstract: Zero-knowledge proofs (ZKPs) are the cornerstone of programmable cryptography. They enable (1) privacy-preserving and verifiable computation across blockchains, and (2) an expanding range of off-chain applications such as credential schemes. Zero-knowledge virtual machines (zkVMs) lower the barrier by turning ZKPs into a drop-in backend for standard compilation pipelines. This lets developers write proof-generating programs in conventional languages (e.g., Rust or C++) instead of hand-crafting arithmetic circuits. However, these VMs inherit compiler infrastructures tuned for traditional architectures rather than for proof systems. In particular, standard compiler optimizations assume features that are absent in zkVMs, including cache locality, branch prediction, or instruction-level parallelism. Therefore, their impact on proof generation is questionable.
  We present the first systematic study of the impact of compiler optimizations on zkVMs. We evaluate 64 LLVM passes, six standard optimization levels, and an unoptimized baseline across 58 benchmarks on two RISC-V-based zkVMs (RISC Zero and SP1). While standard LLVM optimization levels do improve zkVM performance (over 40\%), their impact is far smaller than on traditional CPUs, since their decisions rely on hardware features rather than proof constraints. Guided by a fine-grained pass-level analysis, we~\emph{slightly} refine a small set of LLVM passes to be zkVM-aware, improving zkVM execution time by up to 45\% (average +4.6\% on RISC Zero, +1\% on SP1) and achieving consistent proving-time gains. Our work highlights the potential of compiler-level optimizations for zkVM performance and opens new direction for zkVM-specific passes, backends, and superoptimizers.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.17518v2</guid></item><item><title>[cs updates on arXiv.org] Membership Inference Attacks on LLM-based Recommender Systems</title><link>https://arxiv.org/abs/2508.18665</link><description>arXiv:2508.18665v5 Announce Type: replace 
Abstract: Large language models (LLMs) based recommender systems (RecSys) can adapt to different domains flexibly. It utilizes in-context learning (ICL), i.e., prompts, to customize the recommendation functions, which include sensitive historical user-specific item interactions, encompassing implicit feedback such as clicked items and explicit product reviews. Such private information may be exposed by novel privacy attacks. However, no study has been conducted on this important issue. We design several membership inference attacks (MIAs) aimed to revealing whether system prompts include victims' historical interactions. The attacks are \emph{Similarity, Memorization, Inquiry, and Poisoning attacks}, each utilizing unique features of LLMs or RecSys. We have carefully evaluated them on five of the latest open-source LLMs and three well-known RecSys benchmark datasets. The results confirm that the MIA threat to LLM RecSys is realistic: inquiry and poisoning attacks show significantly high attack advantages. We also discussed possible methods to mitigate such MIA threats. We have also analyzed the factors affecting these attacks, such as the number of shots in system prompts, the position of the victim in the shots, the number of poisoning items in the prompt,etc.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.18665v5</guid></item><item><title>[cs updates on arXiv.org] Attacks on Approximate Caches in Text-to-Image Diffusion Models</title><link>https://arxiv.org/abs/2508.20424</link><description>arXiv:2508.20424v3 Announce Type: replace 
Abstract: Diffusion models are a powerful class of generative models that produce images and other content from user prompts, but they are computationally intensive. To mitigate this cost, recent academic and industry work has adopted approximate caching, which reuses intermediate states from similar prompts in a cache. While efficient, this optimization introduces new security risks by breaking isolation among users. This paper provides a comprehensive assessment of the security vulnerabilities introduced by approximate caching. First, we demonstrate a remote covert channel established with the approximate cache, where a sender injects prompts with special keywords into the cache system and a receiver can recover that even after days, to exchange information. Second, we introduce a prompt stealing attack using the approximate cache, where an attacker can recover existing cached prompts from hits. Finally, we introduce a poisoning attack that embeds the attacker's logos into the previously stolen prompt, leading to unexpected logo rendering for the requests that hit the poisoned cache prompts. These attacks are all performed remotely through the serving system, demonstrating severe security vulnerabilities in approximate caching. The code for this work is available.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.20424v3</guid></item><item><title>[cs updates on arXiv.org] The Percept-V Challenge: Can Multimodal LLMs Crack Simple Perception Problems?</title><link>https://arxiv.org/abs/2508.21143</link><description>arXiv:2508.21143v3 Announce Type: replace 
Abstract: Cognitive science research treats visual perception, the ability to understand and make sense of a visual input, as one of the early developmental signs of intelligence. Its TVPS-4 framework categorizes and tests human perception into seven skills such as visual discrimination, and form constancy. Do Multimodal Large Language Models (MLLMs) match up to humans in basic perception? Even though there are many benchmarks that evaluate MLLMs on advanced reasoning and knowledge skills, there is limited research that focuses evaluation on simple perception. In response, we introduce Percept-V, a dataset containing 6000 program-generated uncontaminated images divided into 30 domains, where each domain tests one or more TVPS-4 skills. Our focus is on perception, so we make our domains quite simple and the reasoning and knowledge required for solving them are minimal. Since modern-day MLLMs can solve much more complex tasks, our a-priori expectation is that they will solve these domains very easily. Contrary to our belief, our experiments show a weak performance of SoTA proprietary and open-source MLLMs compared to very high human performance on Percept-V. We find that as number of objects in the image increases, performance goes down rather fast. Our experiments also identify the perception skills that are considerably harder for all models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.21143v3</guid></item><item><title>[cs updates on arXiv.org] Is this chart lying to me? Automating the detection of misleading visualizations</title><link>https://arxiv.org/abs/2508.21675</link><description>arXiv:2508.21675v2 Announce Type: replace 
Abstract: Misleading visualizations are a potent driver of misinformation on social media and the web. By violating chart design principles, they distort data and lead readers to draw inaccurate conclusions. Prior work has shown that both humans and multimodal large language models (MLLMs) are frequently deceived by such visualizations. Automatically detecting misleading visualizations and identifying the specific design rules they violate could help protect readers and reduce the spread of misinformation. However, the training and evaluation of AI models has been limited by the absence of large, diverse, and openly available datasets. In this work, we introduce Misviz, a benchmark of 2,604 real-world visualizations annotated with 12 types of misleaders. To support model training, we also create Misviz-synth, a synthetic dataset of 57,665 visualizations generated using Matplotlib and based on real-world data tables. We perform a comprehensive evaluation on both datasets using state-of-the-art MLLMs, rule-based systems, and image-axis classifiers. Our results reveal that the task remains highly challenging. We release Misviz, Misviz-synth, and the accompanying code.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.21675v2</guid></item><item><title>[cs updates on arXiv.org] StoxLSTM: A Stochastic Extended Long Short-Term Memory Network for Time Series Forecasting</title><link>https://arxiv.org/abs/2509.01187</link><description>arXiv:2509.01187v2 Announce Type: replace 
Abstract: The Extended Long Short-Term Memory (xLSTM) network has demonstrated strong capability in modeling complex long-term dependencies in time series data. Despite its success, the deterministic architecture of xLSTM limits its representational capacity and forecasting performance, especially on challenging real-world time series datasets characterized by inherent uncertainty, stochasticity, and complex hierarchical latent dynamics. In this work, we propose StoxLSTM, a stochastic xLSTM within a designed state space modeling framework, which integrates latent stochastic variables directly into the recurrent units to effectively model deep latent temporal dynamics and uncertainty. The designed state space model follows an efficient non-autoregressive generative approach, achieving strong predictive performance without complex modifications to the original xLSTM architecture. Extensive experiments on publicly available benchmark datasets demonstrate that StoxLSTM consistently outperforms state-of-the-art baselines, achieving superior performance and generalization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.01187v2</guid></item><item><title>[cs updates on arXiv.org] Disentangling trust from cooperation: Trust as reduced monitoring across social dilemmas</title><link>https://arxiv.org/abs/2509.04143</link><description>arXiv:2509.04143v3 Announce Type: replace 
Abstract: It is commonly assumed that trust increases cooperation. However, game-theoretic models often fail to distinguish between cooperative actions and trust, making it difficult to independently measure trust and determine how its effects vary in different social dilemmas. To address this, we build on influential theories that equate trust with reduced monitoring of an agent's actions. We implement this as a heuristic that cognitively bounded agents can use in repeated games to avoid spending time and effort always monitoring their partner. Agents using this heuristic reduce monitoring of a partner's actions once a threshold level of cooperativeness has been observed -- providing a measurable and architecture-agnostic definition of trust. Using evolutionary game theory, we systematically analyse the success of strategies that use this trust heuristic across the entire space of two-player symmetric social dilemma games. We demonstrate that trust-as-reduced-monitoring facilitates cooperation in two different ways. First, when monitoring is costly, trust heuristics allow for higher levels of cooperation in social dilemmas where the temptation to defect is high. Second, when agents can make action errors, trust heuristics promote cooperation even in coordination problems. Our results disentangle trust from cooperation, and provide a behavioural measure of trust that applies across interaction types.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.04143v3</guid></item><item><title>[cs updates on arXiv.org] Skywork UniPic 2.0: Building Kontext Model with Online RL for Unified Multimodal Model</title><link>https://arxiv.org/abs/2509.04548</link><description>arXiv:2509.04548v2 Announce Type: replace 
Abstract: Recent advances in multimodal models have demonstrated impressive capabilities in unified image generation and editing. However, many prominent open-source models prioritize scaling model parameters over optimizing training strategies, limiting their efficiency and performance. In this work, we present UniPic2-SD3.5M-Kontext, a 2B-parameter DiT model based on SD3.5-Medium, which achieves state-of-the-art image generation and editing while extending seamlessly into a unified multimodal framework. Our approach begins with architectural modifications to SD3.5-Medium and large-scale pre-training on high-quality data, enabling joint text-to-image generation and editing capabilities. To enhance instruction following and editing consistency, we propose a novel Progressive Dual-Task Reinforcement strategy (PDTR), which effectively strengthens both tasks in a staged manner. We empirically validate that the reinforcement phases for different tasks are mutually beneficial and do not induce negative interference. After pre-training and reinforcement strategies, UniPic2-SD3.5M-Kontext demonstrates stronger image generation and editing capabilities than models with significantly larger generation parameters-including BAGEL (7B) and Flux-Kontext (12B). Furthermore, following the MetaQuery, we connect the UniPic2-SD3.5M-Kontext and Qwen2.5-VL-7B via a connector and perform joint training to launch a unified multimodal model UniPic2-Metaquery. UniPic2-Metaquery integrates understanding, generation, and editing, achieving top-tier performance across diverse tasks with a simple and scalable training paradigm. This consistently validates the effectiveness and generalizability of our proposed training paradigm, which we formalize as Skywork UniPic 2.0.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.04548v2</guid></item><item><title>[cs updates on arXiv.org] Collaborate, Deliberate, Evaluate: How LLM Alignment Affects Coordinated Multi-Agent Outcomes</title><link>https://arxiv.org/abs/2509.05882</link><description>arXiv:2509.05882v2 Announce Type: replace 
Abstract: As Large Language Models (LLMs) get integrated into diverse workflows, they are increasingly being regarded as "collaborators" with humans, and required to work in coordination with other AI systems. If such AI collaborators are to reliably coordinate their actions and behaviors with humans or other AIs, their properties and behaviors over multi-turn interactions must be known and predictable. This paper examines how different alignment methods affect LLM agents' effectiveness as partners in multi-turn, multi-party collaborations. We study this question through the lens of intervention agents that insert themselves into group dialogues not to provide answers, but to encourage the collaborative group to slow down and reflect upon their reasoning for deliberative decision-making. Common alignment techniques are typically developed under simplified single-user settings and assume the optimality of the underlying token MDP. Using the theoretical lens of the modified-action MDP, we show how they do not account for the dynamics of long-horizon multi-party interactions. We present a novel roleplay simulation methodology, where we align LLMs according to different methods and then deploy them in collaborative task dialogues to quantify how interventions affect the trajectory of group collaboration, belief alignment, and coordination. Our results show that an intervention agent that is robust to action modification significantly outperforms common alignment baselines in supporting correct task outcomes.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.05882v2</guid></item><item><title>[cs updates on arXiv.org] Xi+: Uncertainty Supervision for Robust Speaker Embedding</title><link>https://arxiv.org/abs/2509.05993</link><description>arXiv:2509.05993v4 Announce Type: replace 
Abstract: There are various factors that can influence the performance of speaker recognition systems, such as emotion, language and other speaker-related or context-related variations. Since individual speech frames do not contribute equally to the utterance-level representation, it is essential to estimate the importance or reliability of each frame. The xi-vector model addresses this by assigning different weights to frames based on uncertainty estimation. However, its uncertainty estimation model is implicitly trained through classification loss alone and does not consider the temporal relationships between frames, which may lead to suboptimal supervision. In this paper, we propose an improved architecture, xi+. Compared to xi-vector, xi+ incorporates a temporal attention module to capture frame-level uncertainty in a context-aware manner. In addition, we introduce a novel loss function, Stochastic Variance Loss, which explicitly supervises the learning of uncertainty. Results demonstrate consistent performance improvements of about 10\% on the VoxCeleb1-O set and 11\% on the NIST SRE 2024 evaluation set.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.05993v4</guid></item><item><title>[cs updates on arXiv.org] Behind the Scenes: Mechanistic Interpretability of LoRA-adapted Whisper for Speech Emotion Recognition</title><link>https://arxiv.org/abs/2509.08454</link><description>arXiv:2509.08454v3 Announce Type: replace 
Abstract: Large pre-trained speech models such as Whisper offer strong generalization but pose significant challenges for resource-efficient adaptation. Low-Rank Adaptation (LoRA) has become a popular parameter-efficient fine-tuning method, yet its underlying mechanisms in speech tasks remain poorly understood. In this work, we conduct the first systematic mechanistic interpretability study of LoRA within the Whisper encoder for speech emotion recognition (SER). Using a suite of analytical tools, including layer contribution probing, logit-lens inspection, and representational similarity via singular value decomposition (SVD) and centered kernel alignment (CKA), we reveal two key mechanisms: a delayed specialization process that preserves general features in early layers before consolidating task-specific information, and a forward alignment, backward differentiation dynamic between LoRA's matrices. Our findings clarify how LoRA reshapes encoder hierarchies, providing both empirical insights and a deeper mechanistic understanding for designing efficient and interpretable adaptation strategies in large speech models. Our code is available at https://github.com/harryporry77/Behind-the-Scenes.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.08454v3</guid></item><item><title>[cs updates on arXiv.org] LLMs Homogenize Values in Constructive Arguments on Value-Laden Topics</title><link>https://arxiv.org/abs/2509.10637</link><description>arXiv:2509.10637v2 Announce Type: replace 
Abstract: Large language models (LLMs) are increasingly used to promote prosocial and constructive discourse online. Yet little is known about how these models negotiate and shape underlying values when reframing people's arguments on value-laden topics. We conducted experiments with 465 participants from India and the United States, who wrote comments on homophobic and Islamophobic threads, and reviewed human-written and LLM-rewritten constructive versions of these comments. Our analysis shows that LLM systematically diminishes Conservative values while elevating prosocial values such as Benevolence and Universalism. When these comments were read by others, participants opposing same-sex marriage or Islam found human-written comments more aligned with their values, whereas those supportive of these communities found LLM-rewritten versions more aligned with their values. These findings suggest that value homogenization in LLM-mediated prosocial discourse runs the risk of marginalizing conservative viewpoints on value-laden topics and may inadvertently shape the dynamics of online discourse.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.10637v2</guid></item><item><title>[cs updates on arXiv.org] No Mesh, No Problem: Estimating Coral Volume and Surface from Sparse Multi-View Images</title><link>https://arxiv.org/abs/2509.11164</link><description>arXiv:2509.11164v3 Announce Type: replace 
Abstract: Effective reef monitoring requires the quantification of coral growth via accurate volumetric and surface area estimates, which is a challenging task due to the complex morphology of corals. We propose a novel, lightweight, and scalable learning framework that addresses this challenge by predicting the 3D volume and surface area of coral-like objects from 2D multi-view RGB images. Our approach utilizes a pre-trained module (VGGT) to extract dense point maps from each view; these maps are merged into a unified point cloud and enriched with per-view confidence scores. The resulting cloud is fed to two parallel DGCNN decoder heads, which jointly output the volume and the surface area of the coral, as well as their corresponding confidence estimate. To enhance prediction stability and provide uncertainty estimates, we introduce a composite loss function based on Gaussian negative log-likelihood in both real and log domains. Our method achieves competitive accuracy and generalizes well to unseen morphologies. This framework paves the way for efficient and scalable coral geometry estimation directly from a sparse set of images, with potential applications in coral growth analysis and reef monitoring.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.11164v3</guid></item><item><title>[cs updates on arXiv.org] DF-LLaVA: Unlocking MLLM's potential for Synthetic Image Detection via Prompt-Guided Knowledge Injection</title><link>https://arxiv.org/abs/2509.14957</link><description>arXiv:2509.14957v2 Announce Type: replace 
Abstract: With the increasing prevalence of synthetic images, evaluating image authenticity and locating forgeries accurately while maintaining human interpretability remains a challenging task. Existing detection models primarily focus on simple authenticity classification, ultimately providing only a forgery probability or binary judgment, which offers limited explanatory insights into image authenticity. Moreover, while MLLM-based detection methods can provide more interpretable results, they still lag behind expert models in terms of pure authenticity classification accuracy. To address this, we propose DF-LLaVA, a simple yet effective framework that unlocks the intrinsic discrimination potential of MLLMs. Our approach first extracts latent knowledge from MLLMs and then injects it into training via prompts. This framework allows LLaVA to achieve outstanding detection accuracy exceeding expert models while still maintaining the interpretability offered by MLLMs. Extensive experiments confirm the superiority of our DF-LLaVA, achieving both high accuracy and explainability in synthetic image detection. Code is available online at: https://github.com/Eliot-Shen/DF-LLaVA.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.14957v2</guid></item><item><title>[cs updates on arXiv.org] From Canopy to Ground via ForestGen3D: Learning Cross-Domain Generation of 3D Forest Structure from Aerial-to-Terrestrial LiDAR</title><link>https://arxiv.org/abs/2509.16346</link><description>arXiv:2509.16346v2 Announce Type: replace 
Abstract: The 3D structure of living and non-living components in ecosystems plays a critical role in determining ecological processes and feedbacks from both natural and human-driven disturbances. Anticipating the effects of wildfire, drought, disease, or atmospheric deposition depends on accurate characterization of 3D vegetation structure, yet widespread measurement remains prohibitively expensive and often infeasible. We present ForestGen3D, a cross-domain generative framework that preserves aerial LiDAR (ALS) observed 3D forest structure while inferring missing sub-canopy detail. ForestGen3D is based on conditional denoising diffusion probabilistic models trained on co-registered ALS and terrestrial LiDAR (TLS) data. The model generates realistic TLS-like point clouds that remain spatially consistent with ALS geometry, enabling landscape-scalable reconstruction of full vertical forest structure. We evaluate ForestGen3D at tree, plot, and landscape scales using real-world data from mixed conifer ecosystems, and show through qualitative and quantitative geometric and distributional analyses that it produces high-fidelity reconstructions closely matching TLS reference data in terms of 3D structural similarity and downstream biophysical metrics, including tree height, DBH, crown diameter, and crown volume. We further introduce and demonstrate the expected point containment (EPC) metric which serves as a practical proxy for generation quality in settings where TLS ground truth is unavailable. Our results demonstrate that ForestGen3D enhances the utility of ALS only environments by inferring ecologically plausible sub-canopy structure while faithfully preserving the landscape heterogeneity encoded in ALS observations, thereby providing a richer 3D representation for ecological analysis, structural fuel characterization and related remote sensing applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.16346v2</guid></item><item><title>[cs updates on arXiv.org] TextCrafter: Optimization-Calibrated Noise for Defending Against Text Embedding Inversion</title><link>https://arxiv.org/abs/2509.17302</link><description>arXiv:2509.17302v5 Announce Type: replace 
Abstract: Text embedding inversion attacks reconstruct original sentences from latent representations, posing severe privacy threats in collaborative inference and edge computing. We propose TextCrafter, an optimization-based adversarial perturbation mechanism that combines RL learned, geometry aware noise injection orthogonal to user embeddings with cluster priors and PII signal guidance to suppress inversion while preserving task utility. Unlike prior defenses either non learnable or agnostic to perturbation direction, TextCrafter provides a directional protective policy that balances privacy and utility. Under strong privacy setting, TextCrafter maintains 70 percentage classification accuracy on four datasets and consistently outperforms Gaussian/LDP baselines across lower privacy budgets, demonstrating a superior privacy utility trade off.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.17302v5</guid></item><item><title>[cs updates on arXiv.org] VideoPro: Adaptive Program Reasoning for Long Video Understanding</title><link>https://arxiv.org/abs/2509.17743</link><description>arXiv:2509.17743v3 Announce Type: replace 
Abstract: Large language models (LLMs) have shown promise in generating program workflows for visual tasks. However, previous approaches often rely on closed-source models, lack systematic reasoning, and struggle with long-form video question answering (videoQA). To address these challenges, we introduce the FS-VisPR framework, an adaptive visual program reasoning approach that balances fast reasoning for simple queries with slow reasoning for difficult ones. First, we design efficient visual modules (e.g., key clip retrieval and subtitle retrieval) to support long-form video tasks. Then, we construct a diverse and high-quality fast-slow reasoning dataset with a strong LLM to align open-source language models' ability to generate visual program workflows as FS-LLM. Next, we design a fast-slow reasoning framework with FS-LLM: Simple queries are directly solved by VideoLLMs, while difficult ones invoke visual program reasoning, motivated by human-like reasoning processes. During this process, low-confidence fast-thinking answers will trigger a second-stage slow-reasoning process, and a fallback mechanism to fast reasoning is activated if the program execution fails. Moreover, we improve visual programs through parameter search during both training and inference. By adjusting the parameters of the visual modules within the program, multiple variants are generated: during training, programs that yield correct answers are selected, while during inference, the program with the highest confidence result is applied. Experiments show that FS-VisPR improves both efficiency and reliability in visual program workflows. It achieves 50.4% accuracy on LVBench, surpassing GPT-4o, matching the performance of Qwen2.5VL-72B on VideoMME.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.17743v3</guid></item><item><title>[cs updates on arXiv.org] FedIA: Towards Domain-Robust Aggregation in Federated Graph Learning</title><link>https://arxiv.org/abs/2509.18171</link><description>arXiv:2509.18171v3 Announce Type: replace 
Abstract: Federated Graph Learning (FGL) enables a central server to coordinate model training across distributed clients without local graph data being shared. However, FGL significantly suffers from cross-silo domain shifts, where each "silo" (domain) contains a limited number of clients with distinct graph topologies. These heterogeneities induce divergent optimization trajectories, ultimately leading to global model divergence. In this work, we reveal a severe architectural pathology termed Structural Orthogonality: the topology-dependent message passing mechanism forces gradients from different domains to target disjoint coordinates in the parameter space. Through a controlled comparison between backbones, we statistically prove that GNN updates are near-perpendicular across domains (with projection ratios $\to$ 0). Consequently, naive averaging leads to Consensus Collapse, a phenomenon where sparse, informative structural signals from individual domains are diluted by the near-zero updates of others. This forces the global model into a "sub-optimal" state that fails to represent domain-specific structural patterns, resulting in poor generalization. To address this, we propose FedIA, a lightweight server-side framework designed to reconcile update conflicts without auxiliary communication. FedIA operates in two stages: (1) Global Importance Masking (GIM) identifies a shared parameter subspace to filter out domain-specific structural noise and prevent signal dilution; (2) Confidence-Aware Momentum Weighting (CAM) dynamically re-weights client contributions based on gradient reliability to amplify stable optimization signals.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.18171v3</guid></item><item><title>[cs updates on arXiv.org] MCGrad: Multicalibration at Web Scale</title><link>https://arxiv.org/abs/2509.19884</link><description>arXiv:2509.19884v3 Announce Type: replace 
Abstract: We propose MCGrad, a novel and scalable multicalibration algorithm. Multicalibration - calibration in subgroups of the data - is an important property for the performance of machine learning-based systems. Existing multicalibration methods have thus far received limited traction in industry. We argue that this is because existing methods (1) require such subgroups to be manually specified, which ML practitioners often struggle with, (2) are not scalable, or (3) may harm other notions of model performance such as log loss and Area Under the Precision-Recall Curve (PRAUC). MCGrad does not require explicit specification of protected groups, is scalable, and often improves other ML evaluation metrics instead of harming them. MCGrad has been in production at Meta, and is now part of hundreds of production models. We present results from these deployments as well as results on public datasets. We provide an open source implementation of MCGrad at https://github.com/facebookincubator/MCGrad.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.19884v3</guid></item><item><title>[cs updates on arXiv.org] Real-Time Object Detection Meets DINOv3</title><link>https://arxiv.org/abs/2509.20787</link><description>arXiv:2509.20787v3 Announce Type: replace 
Abstract: Benefiting from the simplicity and effectiveness of Dense O2O and MAL, DEIM has become the mainstream training framework for real-time DETRs, significantly outperforming the YOLO series. In this work, we extend it with DINOv3 features, resulting in DEIMv2. DEIMv2 spans eight model sizes from X to Atto, covering GPU, edge, and mobile deployment. For the X, L, M, and S variants, we adopt DINOv3-pretrained or distilled backbones and introduce a Spatial Tuning Adapter (STA), which efficiently converts DINOv3's single-scale output into multi-scale features and complements strong semantics with fine-grained details to enhance detection. For ultra-lightweight models (Nano, Pico, Femto, and Atto), we employ HGNetv2 with depth and width pruning to meet strict resource budgets. Together with a simplified decoder and an upgraded Dense O2O, this unified design enables DEIMv2 to achieve a superior performance-cost trade-off across diverse scenarios, establishing new state-of-the-art results. Notably, our largest model, DEIMv2-X, achieves 57.8 AP with only 50.3 million parameters, surpassing prior X-scale models that require over 60 million parameters for just 56.5 AP. On the compact side, DEIMv2-S is the first sub-10 million model (9.71 million) to exceed the 50 AP milestone on COCO, reaching 50.9 AP. Even the ultra-lightweight DEIMv2-Pico, with just 1.5 million parameters, delivers 38.5 AP, matching YOLOv10-Nano (2.3 million) with around 50 percent fewer parameters. Our code and pre-trained models are available at https://github.com/Intellindust-AI-Lab/DEIMv2</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.20787v3</guid></item><item><title>[cs updates on arXiv.org] PhishLumos: An Adaptive Multi-Agent System for Proactive Phishing Campaign Mitigation</title><link>https://arxiv.org/abs/2509.21772</link><description>arXiv:2509.21772v2 Announce Type: replace 
Abstract: Phishing attacks are a significant societal threat, disproportionately harming vulnerable populations and eroding trust in essential digital services. Current defenses are often reactive, failing against modern evasive tactics like cloaking that conceal malicious content. To address this, we introduce PhishLumos, an adaptive multi-agent system that proactively mitigates entire attack campaigns. It confronts a core cybersecurity imbalance: attackers can easily scale operations, while defense remains an intensive expert task. Instead of being blocked by evasion, PhishLumos treats it as a critical signal to investigate the underlying infrastructure. Its Large Language Model (LLM)-powered agents uncover shared hosting, certificates, and domain registration patterns. On real-world data, our system identified 100% of campaigns in the median case, over a week before their confirmation by cybersecurity experts. PhishLumos demonstrates a practical shift from reactive URL blocking to proactive campaign mitigation, protecting users before they are harmed and making the digital world safer for all.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.21772v2</guid></item><item><title>[cs updates on arXiv.org] VeriLLM: A Lightweight Framework for Publicly Verifiable Decentralized Inference</title><link>https://arxiv.org/abs/2509.24257</link><description>arXiv:2509.24257v4 Announce Type: replace 
Abstract: Decentralized inference provides a scalable and resilient paradigm for serving large language models (LLMs), enabling fragmented global resource utilization and reducing reliance on centralized providers. However, in a permissionless environment without trusted nodes, ensuring the correctness of model outputs remains a core challenge. We introduce VeriLLM, a publicly verifiable protocol for decentralized LLM inference that achieves security with incentive guarantees while maintaining practical efficiency. VeriLLM combines lightweight empirical rerunning with minimal on-chain checks to preclude free-riding, allowing verifiers to validate results at approximately 1% of the underlying inference cost by exploiting the structural separation between prefill and autoregressive decoding. To prevent verification bottlenecks, we design an isomorphic inference--verification architecture that multiplexes both inference and verification roles across the same GPU workers. This design (i) improves GPU utilization and overall throughput, (ii) enlarges the effective validator set, enhancing robustness and liveness, and (iii) enforces task indistinguishability to prevent node-specific optimizations or selective behavior. Through theoretical analysis and system-level evaluation, we show that VeriLLM achieves reliable public verifiability with minimal overhead, offering a practical foundation for trustworthy and scalable decentralized LLM inference.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.24257v4</guid></item><item><title>[cs updates on arXiv.org] BPMN Assistant: An LLM-Based Approach to Business Process Modeling</title><link>https://arxiv.org/abs/2509.24592</link><description>arXiv:2509.24592v2 Announce Type: replace 
Abstract: This paper presents BPMN Assistant, a tool that leverages Large Language Models for natural language-based creation and editing of BPMN diagrams. While direct XML generation is common, it is verbose, slow, and prone to syntax errors during complex modifications. We introduce a specialized JSON-based intermediate representation designed to facilitate atomic editing operations through function calling. We evaluate our approach against direct XML manipulation using a suite of state-of-the-art models, including GPT-5.1, Claude 4.5 Sonnet, and DeepSeek V3. Results demonstrate that the JSON-based approach significantly outperforms direct XML in editing tasks, achieving higher or equivalent success rates across all evaluated models. Furthermore, despite requiring more input context, our approach reduces generation latency by approximately 43% and output token count by over 75%, offering a more reliable and responsive solution for interactive process modeling.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.24592v2</guid></item><item><title>[cs updates on arXiv.org] PatchEAD: Unifying Industrial Visual Prompting Frameworks for Patch-Exclusive Anomaly Detection</title><link>https://arxiv.org/abs/2509.25856</link><description>arXiv:2509.25856v2 Announce Type: replace 
Abstract: Industrial anomaly detection is increasingly relying on foundation models, aiming for strong out-of-distribution generalization and rapid adaptation in real-world deployments. Notably, past studies have primarily focused on textual prompt tuning, leaving the intrinsic visual counterpart fragmented into processing steps specific to each foundation model. We aim to address this limitation by proposing a unified patch-focused framework, Patch-Exclusive Anomaly Detection (PatchEAD), enabling training-free anomaly detection that is compatible with diverse foundation models. The framework constructs visual prompting techniques, including an alignment module and foreground masking. Our experiments show superior few-shot and batch zero-shot performance compared to prior work, despite the absence of textual features. Our study further examines how backbone structure and pretrained characteristics affect patch-similarity robustness, providing actionable guidance for selecting and configuring foundation models for real-world visual inspection. These results confirm that a well-unified patch-only framework can enable quick, calibration-light deployment without the need for carefully engineered textual prompts.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.25856v2</guid></item><item><title>[cs updates on arXiv.org] Signature-Informed Transformer for Asset Allocation</title><link>https://arxiv.org/abs/2510.03129</link><description>arXiv:2510.03129v3 Announce Type: replace 
Abstract: Modern deep learning for asset allocation typically separates forecasting from optimization. We argue this creates a fundamental mismatch where minimizing prediction errors fails to yield robust portfolios. We propose the Signature Informed Transformer to address this by unifying feature extraction and decision making into a single policy. Our model employs path signatures to encode complex path dependencies and introduces a specialized attention mechanism that targets geometric asset relationships. By directly minimizing the Conditional Value at Risk we ensure the training objective aligns with financial goals. We prove that our attention module rigorously amplifies signature derived signals. Experiments across diverse equity universes show our approach significantly outperforms both traditional strategies and advanced forecasting baselines. The code is available at: https://anonymous.4open.science/r/Signature-Informed-Transformer-For-Asset-Allocation-DB88</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.03129v3</guid></item><item><title>[cs updates on arXiv.org] DECOR: Deep Embedding Clustering with Orientation Robustness</title><link>https://arxiv.org/abs/2510.03328</link><description>arXiv:2510.03328v2 Announce Type: replace 
Abstract: In semiconductor manufacturing, early detection of wafer defects is critical for product yield optimization. However, raw wafer data from wafer quality tests are often complex, unlabeled, imbalanced and can contain multiple defects on a single wafer, making it crucial to design clustering methods that remain reliable under such imperfect data conditions. We introduce DECOR, a deep clustering with orientation robustness framework that groups complex defect patterns from wafer maps into consistent clusters. We evaluate our method on the open source MixedWM38 dataset, demonstrating its ability to discover clusters without manual tuning. DECOR explicitly accounts for orientation variations in wafer maps, ensuring that spatially similar defects are consistently clustered regardless of its rotation or alignment. Experiments indicate that our method outperforms existing clustering baseline methods, thus providing a reliable and scalable solution in automated visual inspection systems.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.03328v2</guid></item><item><title>[cs updates on arXiv.org] PAD-TRO: Projection-Augmented Diffusion for Direct Trajectory Optimization</title><link>https://arxiv.org/abs/2510.04436</link><description>arXiv:2510.04436v2 Announce Type: replace 
Abstract: Recently, diffusion models have gained popularity and attention in trajectory optimization due to their capability of modeling multi-modal probability distributions. However, addressing nonlinear equality constraints, i.e, dynamic feasibility, remains a great challenge in diffusion-based trajectory optimization. Recent diffusion-based trajectory optimization frameworks rely on a single-shooting style approach where the denoised control sequence is applied to forward propagate the dynamical system, which cannot explicitly enforce constraints on the states and frequently leads to sub-optimal solutions. In this work, we propose a novel direct trajectory optimization approach via model-based diffusion, which directly generates a sequence of states. To ensure dynamic feasibility, we propose a gradient-free projection mechanism that is incorporated into the reverse diffusion process. Our results show that, compared to a recent state-of-the-art baseline, our approach leads to zero dynamic feasibility error and approximately 4x higher success rate in a quadrotor waypoint navigation scenario involving dense static obstacles.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.04436v2</guid></item><item><title>[cs updates on arXiv.org] Distributionally Robust Causal Abstractions</title><link>https://arxiv.org/abs/2510.04842</link><description>arXiv:2510.04842v3 Announce Type: replace 
Abstract: Causal Abstraction (CA) theory provides a principled framework for relating causal models that describe the same system at different levels of granularity while ensuring interventional consistency between them. Recent methods for learning CAs, however, assume fixed and well-specified exogenous distributions, leaving them vulnerable to environmental shifts and model misspecification. In this work, we address these limitations by introducing the first class of distributionally robust CAs and their associated learning algorithms. The latter cast robust causal abstraction learning as a constrained min-max optimization problem with Wasserstein ambiguity sets. We provide theoretical guarantees for both empirical and Gaussian environments, enabling principled selection of ambiguity set radii and establish quantitative guarantees on worst-case abstraction error. Furthermore, we present empirical evidence across different problems and CA learning methods, demonstrating our framework's robustness not only to environmental shifts but also to structural and intervention mapping misspecification.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.04842v3</guid></item><item><title>[cs updates on arXiv.org] New Insights into Involutory and Orthogonal MDS Matrices</title><link>https://arxiv.org/abs/2510.05766</link><description>arXiv:2510.05766v2 Announce Type: replace 
Abstract: MDS matrices play a critical role in the design of diffusion layers for block ciphers and hash functions due to their optimal branch number. Involutory and orthogonal MDS matrices offer additional benefits by allowing identical or nearly identical circuitry for both encryption and decryption, leading to equivalent implementation costs for both processes. These properties have been further generalized through the notions of semi-involutory and semi-orthogonal matrices. While much of the existing literature focuses on identifying efficiently implementable MDS candidates or proposing new constructions for MDS matrices of various orders, this work takes a different direction. Rather than introducing novel constructions or prioritizing implementation efficiency, we investigate structural relationships between the generalized variants and their conventional counterparts. Specifically, we establish nontrivial interconnections between semi-involutory and involutory matrices, as well as between semi-orthogonal and orthogonal matrices. Exploiting these relationships, we show that the number of semi-involutory MDS matrices can be directly derived from the number of involutory MDS matrices, and vice versa. A similar correspondence holds for semi-orthogonal and orthogonal MDS matrices. We also examine the intersection of these classes and show that the number of $3 \times 3$ MDS matrices that are both semi-involutory and semi-orthogonal coincides with the number of semi-involutory MDS matrices over $\mathbb{F}_{2^m}$. Furthermore, we derive the general structure of orthogonal matrices of arbitrary order $n$ over $\mathbb{F}_{2^m}$. Finally, leveraging the aforementioned interconnections, we present an alternative and direct derivation of the explicit formulae for counting $3 \times 3$ semi-involutory MDS matrices and $3 \times 3$ semi-orthogonal MDS matrices.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.05766v2</guid></item><item><title>[cs updates on arXiv.org] Does LLM Focus on the Right Words? Mitigating Context Bias in LLM-based Recommenders</title><link>https://arxiv.org/abs/2510.10978</link><description>arXiv:2510.10978v2 Announce Type: replace 
Abstract: Large language models (LLMs), owing to their extensive open-domain knowledge and semantic reasoning capabilities, have been increasingly integrated into recommender systems (RS). However, a substantial gap remains between the pre-training objectives of LLMs and the specific requirements of recommendation tasks. To address this gap, supervised fine-tuning (SFT) is commonly performed on specially curated recommendation datasets to further enhance their predictive ability. Despite its success, SFT exhibits a critical limitation: it induces Context Bias, whereby the model over-relies on auxiliary tokens, such as task descriptions and prefix-generated tokens, while underutilizing core user interaction tokens that encode user-specific preferences. This bias not only undermines recommendation accuracy but also raises unfairness concerns. To address this issue, we propose Group Distributionally Robust Optimization-based Tuning (GDRT), a novel fine-tuning paradigm that enforces consistent model performance across token groups with varying degrees of relevance to auxiliary tokens. By adaptively upweighting underperforming groups, typically those weakly correlated with auxiliary tokens, GDRT shifts the model's attention from superficial auxiliary cues to informative user interaction tokens, thereby mitigating context bias. Extensive experiments conducted on three public datasets demonstrate that GDRT effectively mitigates context bias, yielding substantial improvements in recommendation accuracy (with an average NDCG@10 gain of 24.29%) and significantly enhancing recommendation fairness. The code is available at https://github.com/WANGBohaO-jpg/GDRT.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.10978v2</guid></item><item><title>[cs updates on arXiv.org] CoSPED: Consistent Soft Prompt Targeted Data Extraction and Defense</title><link>https://arxiv.org/abs/2510.11137</link><description>arXiv:2510.11137v3 Announce Type: replace 
Abstract: Large language models have gained widespread attention recently, but their potential security vulnerabilities, especially privacy leakage, are also becoming apparent. To test and evaluate for data extraction risks in LLM, we proposed CoSPED, short for Consistent Soft Prompt targeted data Extraction and Defense. We introduce several innovative components, including Dynamic Loss, Additive Loss, Common Loss, and Self Consistency Decoding Strategy, and tested to enhance the consistency of the soft prompt tuning process. Through extensive experimentation with various combinations, we achieved an extraction rate of 65.2% at a 50-token prefix comparison. Our comparisons of CoSPED with other reference works confirm our superior extraction rates. We evaluate CoSPED on more scenarios, achieving Pythia model extraction rate of 51.7% and introducing cross-model comparison. Finally, we explore defense through Rank-One Model Editing and achieve a reduction in the extraction rate to 1.6%, which proves that our analysis of extraction mechanisms can directly inform effective mitigation strategies against soft prompt-based attacks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.11137v3</guid></item><item><title>[cs updates on arXiv.org] Community Engagement and the Lifespan of Open-Source Software Projects</title><link>https://arxiv.org/abs/2510.15408</link><description>arXiv:2510.15408v2 Announce Type: replace 
Abstract: Open-source software (OSS) projects depend on community engagement (CE) for longevity. However, CE's quantifiable impact on project dynamics and lifespan is underexplored. Objectives: This study defines CE in OSS, identifies key metrics, and evaluates their influence on project dynamics (releases, commits, branches) and lifespan. Methods: We analyzed 33,946 GitHub repositories, defining and operationalizing CE with validated per-month metrics (issues, comments, watchers, stargazers). Non-parametric tests and correlations assessed relationships with project dynamics and lifespan across quartiles. Results: CE metrics significantly associate with project dynamics, with stronger correlations in highly engaged projects. For lifespan, a complex pattern emerged: per-month CE rates are highest in younger projects, declining with age. Yet, a subset of long-lived projects maintains exceptionally high activity. Initial CE bursts appear crucial for establishment, while sustained high engagement drives extreme longevity. Active issue engagement's influence intensifies with age, but passive attention's declines. Conclusion: CE dynamically drives OSS project longevity and development. Our findings establish validated CE metrics and offer deeper insights into how diverse community activity patterns contribute to project longevity.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.15408v2</guid></item><item><title>[cs updates on arXiv.org] Enhanced Fish Freshness Classification with Incremental Handcrafted Feature Fusion</title><link>https://arxiv.org/abs/2510.17145</link><description>arXiv:2510.17145v2 Announce Type: replace 
Abstract: Accurate assessment of fish freshness remains a major challenge in the food industry, with direct consequences for product quality, market value, and consumer health. Conventional sensory evaluation is inherently subjective, inconsistent, and difficult to standardize across contexts, often limited by subtle, species-dependent spoilage cues. To address these limitations, we propose a handcrafted feature-based approach that systematically extracts and incrementally fuses complementary descriptors, including color statistics, histograms across multiple color spaces, and texture features such as Local Binary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish eye images. Our method captures global chromatic variations from full images and localized degradations from ROI segments, fusing each independently to evaluate their effectiveness in assessing freshness. Experiments on the Freshness of the Fish Eyes (FFE) dataset demonstrate the approach's effectiveness: in a standard train-test setting, a LightGBM classifier achieved 77.56% accuracy, a 14.35% improvement over the previous deep learning baseline of 63.21%. With augmented data, an Artificial Neural Network (ANN) reached 97.49% accuracy, surpassing the prior best of 77.3% by 20.19%. These results demonstrate that carefully engineered, handcrafted features, when strategically processed, yield a robust, interpretable, and reliable solution for automated fish freshness assessment, providing valuable insights for practical applications in food quality monitoring.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.17145v2</guid></item><item><title>[cs updates on arXiv.org] Auditing and Mitigating Bias in Gender Classification Algorithms: A Data-Centric Approach</title><link>https://arxiv.org/abs/2510.17873</link><description>arXiv:2510.17873v2 Announce Type: replace 
Abstract: Gender classification systems often inherit and amplify demographic imbalances in their training data. We first audit five widely used gender classification datasets, revealing that all suffer from significant intersectional underrepresentation. To measure the downstream impact of these flaws, we train identical MobileNetV2 classifiers on the two most balanced of these datasets, UTKFace and FairFace. Our fairness evaluation shows that even these models exhibit significant bias, misclassifying female faces at a higher rate than male faces and amplifying existing racial skew. To counter these data-induced biases, we construct BalancedFace, a new public dataset created by blending images from FairFace and UTKFace, supplemented with images from other collections to fill missing demographic gaps. It is engineered to equalize subgroup shares across 189 intersections of age, race, and gender using only real, unedited images. When a standard classifier is trained on BalancedFace, it reduces the maximum True Positive Rate gap across racial subgroups by over 50% and brings the average Disparate Impact score 63% closer to the ideal of 1.0 compared to the next-best dataset, all with a minimal loss of overall accuracy. These results underline the profound value of data-centric interventions and provide an openly available resource for fair gender classification research.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.17873v2</guid></item><item><title>[cs updates on arXiv.org] Yesnt: Are Diffusion Relighting Models Ready for Capture Stage Compositing? A Hybrid Alternative to Bridge the Gap</title><link>https://arxiv.org/abs/2510.23494</link><description>arXiv:2510.23494v2 Announce Type: replace 
Abstract: Volumetric video relighting is essential for bringing captured performances into virtual worlds, but current approaches struggle to deliver temporally stable, production-ready results. Diffusion-based intrinsic decomposition methods show promise for single frames, yet suffer from stochastic noise and instability when extended to sequences, while video diffusion models remain constrained by memory and scale. We propose a hybrid relighting framework that combines diffusion-derived material priors with temporal regularization and physically motivated rendering. Our method aggregates multiple stochastic estimates of per-frame material properties into temporally consistent shading components, using optical-flow-guided regularization. For indirect effects such as shadows and reflections, we extract a mesh proxy from Gaussian Opacity Fields and render it within a standard graphics pipeline. Experiments on real and synthetic captures show that this hybrid strategy achieves substantially more stable relighting across sequences than diffusion-only baselines, while scaling beyond the clip lengths feasible for video diffusion. These results indicate that hybrid approaches, which balance learned priors with physically grounded constraints, are a practical step toward production-ready volumetric video relighting.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.23494v2</guid></item><item><title>[cs updates on arXiv.org] TDFlow: Agentic Workflows for Test Driven Development</title><link>https://arxiv.org/abs/2510.23761</link><description>arXiv:2510.23761v2 Announce Type: replace 
Abstract: We introduce TDFlow, a novel test-driven agentic workflow that frames repository-scale software engineering as a test-resolution task, specifically designed to solve human-written tests. Given a set of tests, TDFlow repeatedly proposes, revises, and debugs repository-scale patches using precisely engineered sub-agents and tightly constrained tools. The workflow decomposes software engineering program repair into four components governed by respective sub-agents. This simple, forced decoupling of patch proposing, debugging, patch revision, and optional test generation (1) reduces long-context burden on any individual sub-agent, (2) focuses each sub-agent on specific, pre-defined sub-tasks, and (3) allows for specialized performance improvement on specific sub-tasks. When provided human-written tests, TDFlow attains 88.8% pass rate on SWE-Bench Lite (an absolute improvement of 27.8% over the next best system) and 94.3% on SWE-Bench Verified. Manual inspection of the 800 TDFlow runs within SWE-Bench Lite and Verified uncover only 7 instances of test hacking, which were subsequently counted as failures. Furthermore, we show that the primary obstacle to human-level software engineering performance lies within writing successful reproduction tests. We envision a human-LLM interactive system powered by TDFlow where human developers write tests solved by LLM systems. Together, these results indicate that modern LLMs, when embedded in a narrowly engineered, test-driven workflow, already achieve human-level test resolution -- with the final frontier for fully autonomous repository repair being the accurate generation of valid reproduction tests.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.23761v2</guid></item><item><title>[cs updates on arXiv.org] Understanding Reader Perception Shifts upon Disclosure of AI Authorship</title><link>https://arxiv.org/abs/2510.24011</link><description>arXiv:2510.24011v2 Announce Type: replace 
Abstract: As AI writing support becomes ubiquitous, how disclosing its use affects reader perception remains a critical, underexplored question. We conducted a study with 261 participants to examine how revealing varying levels of AI involvement shifts author impressions across six distinct communicative acts. Our analysis of 990 responses shows that disclosure generally erodes perceptions of trustworthiness, caring, competence, and likability, with the sharpest declines in social and interpersonal writing. A thematic analysis of participants' feedback links these negative shifts to a perceived loss of human sincerity, diminished author effort, and the contextual inappropriateness of AI. Conversely, we find that higher AI literacy mitigates these negative perceptions, leading to greater tolerance or even appreciation for AI use. Our results highlight the nuanced social dynamics of AI-mediated authorship and inform design implications for creating transparent, context-sensitive writing systems that better preserve trust and authenticity.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.24011v2</guid></item><item><title>[cs updates on arXiv.org] UniField: Joint Multi-Domain Training for Universal Surface Pressure Modeling</title><link>https://arxiv.org/abs/2510.24106</link><description>arXiv:2510.24106v4 Announce Type: replace 
Abstract: Accurate modeling of surface pressure fields around objects is fundamental to aerodynamic analysis and design. While neural networks have shown promise as efficient alternatives to expensive Computational Fluid Dynamics (CFD) simulations, their applicability is often constrained by data scarcity and poor generalization across different aerodynamic domains. To address these challenges, we propose UniField, a unified framework that enables joint training across multiple aerodynamic domains including automobiles, trains, aircraft. UniField employs a shared geometry encoder to extract domain-agnostic representations from surface point clouds, and integrates domain-specific flow information through Parallel Flow-Conditioned Adaptive LayerNorm (PFC-AdaLN). In addition to consolidating existing datasets from specialized research field including automobiles, trains and aircraft, we further introduce ThingiCFD, a large-scale CFD dataset constructed from Thingi10k geometries with extensive flow condition randomization, substantially expanding geometric and flow diversity during training. UniField achieves SOTA performance on the public DrivAerNet++ benchmark. In addition, our experiments demonstrate that joint multi-domain training consistently improves surface pressure prediction accuracy, particularly in data-scarce domains. These results highlight the potential of UniField as a foundation model for data-driven aerodynamic modeling. Code and data will be available at https://github.com/zoujunhong/UniField.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.24106v4</guid></item><item><title>[cs updates on arXiv.org] PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling</title><link>https://arxiv.org/abs/2510.24235</link><description>arXiv:2510.24235v2 Announce Type: replace 
Abstract: Reward models (RMs) are central to reinforcement learning from human feedback (RLHF), providing the critical supervision signals that align large language models (LLMs) with human preferences. Generative reward models (GRMs) provide greater interpretability than traditional scalar RMs, but they come with a critical trade-off: pairwise methods are hindered by a training-inference mismatch, while pointwise methods require expensive absolute annotations. To bridge this gap, we propose the Preference-aware Task-adaptive Reward Model (PaTaRM). Unlike prior approaches, PaTaRM enables robust pointwise training using readily available pairwise data via a novel Preference-Aware Reward (PAR) mechanism, eliminating the need for explicit rating labels. Furthermore, it incorporates a Task-Adaptive Rubric system that dynamically generates instance-specific criteria for precise evaluation. Extensive experiments demonstrate that PATRM achieves a 8.7% average improvement on RewardBench and RMBench across Qwen3-8B/14B models. Crucially, it boosts downstream RLHF performance by an average relative improvement of 13.6% across IFEval and InFoBench, validating its effectiveness for policy alignment. Our code is available at https://github.com/JaneEyre0530/PaTaRM.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.24235v2</guid></item><item><title>[cs updates on arXiv.org] Systems of Graph Formulas and their Equivalence to Alternating Graph Automata</title><link>https://arxiv.org/abs/2510.25260</link><description>arXiv:2510.25260v2 Announce Type: replace 
Abstract: Graph-based modeling plays a fundamental role in many areas of computer science. In this paper, we introduce systems of graph formulas with variables for specifying graph properties; this notion generalizes the graph formulas introduced in earlier work by incorporating recursion. We show that these formula systems have the same expressive power as alternating graph automata, a computational model that extends traditional finite-state automata to graphs, and allows both existential and universal states. In particular, we provide a bidirectional translation between formula systems and alternating graph automata, proving their equivalence in specifying graph languages. This result implies that alternating graph automata can be naturally represented using logic-based formulations, thus bridging the gap between automata-theoretic and logic-based approaches to graph language specification.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.25260v2</guid></item><item><title>[cs updates on arXiv.org] Analyzing the Impact of Demand Response on Short-Circuit Current via a Unit Commitment Model</title><link>https://arxiv.org/abs/2511.00296</link><description>arXiv:2511.00296v2 Announce Type: replace 
Abstract: In low-carbon grids, system flexibility can be enhanced through mechanisms such as Demand Response (DR), enabling the efficient utilization of renewable energy. However, as Synchronous Generators (SGs) are being replaced by renewable energy sources characterized by Inverter-Based Resources (IBR), system stability is severely affected. Due to the limited overload capability of IBRs, their Short-Circuit Current (SCC) contribution is much smaller than that of SGs. As a result, protection devices may fail to trip during faults. Consequently, the remaining SGs play a key role in providing sufficient SCC. Since the commitment of SGs is closely related to system loading conditions, DR can indirectly affect their SCC provision, a relationship that has not yet been investigated in the literature. Therefore, this paper incorporates both DR and SCC constraints into a unit commitment problem and conducts case studies on an IEEE 30-bus system. The results show that although DR can reduce total costs by adjusting power demand, it may also lead to inadequate SCC levels. Nevertheless, when flexible loads are properly coordinated with SCC requirements, the total cost increases by only 0.3%, which is significantly lower than the cost of system dispatch without DR. This demonstrates that DR can facilitate stable system operation in a cost-effective manner.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.00296v2</guid></item><item><title>[cs updates on arXiv.org] Can LLM Infer Risk Information From MCP Server System Logs?</title><link>https://arxiv.org/abs/2511.05867</link><description>arXiv:2511.05867v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) demonstrate strong capabilities in solving complex tasks when integrated with external tools. The Model Context Protocol (MCP) has become a standard interface for enabling such tool-based interactions. However, these interactions introduce substantial security concerns, particularly when the MCP server is compromised or untrustworthy. While prior benchmarks primarily focus on prompt injection attacks or analyze the vulnerabilities of LLM-MCP interaction trajectories, limited attention has been given to the underlying system logs associated with malicious MCP servers. To address this gap, we present the first synthetic benchmark for evaluating LLMs' ability to identify security risks from system logs. We define nine categories of MCP server risks and generate 1,800 synthetic system logs using ten state-of-the-art LLMs. These logs are embedded in the return values of 243 curated MCP servers, yielding a dataset of 2,421 chat histories for training and 471 queries for evaluation. Our pilot experiments reveal that smaller models often fail to detect risky system logs, leading to high false negatives. While models trained with supervised fine-tuning (SFT) tend to over-flag benign logs, resulting in elevated false positives, Reinforcement Learning with Verifiable Reward (RLVR) offers a better precision-recall balance. In particular, after training with Group Relative Policy Optimization (GRPO), Llama3.1-8B-Instruct achieves 83 percent accuracy, surpassing the best-performing large remote model by 9 percentage points. Fine-grained, per-category analysis further underscores the effectiveness of reinforcement learning in enhancing LLM safety within the MCP framework. Code and data are available at https://github.com/PorUna-byte/MCP-RiskCue.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.05867v3</guid></item><item><title>[cs updates on arXiv.org] PlantTraitNet: An Uncertainty-Aware Multimodal Framework for Global-Scale Plant Trait Inference from Citizen Science Data</title><link>https://arxiv.org/abs/2511.06943</link><description>arXiv:2511.06943v2 Announce Type: replace 
Abstract: Global plant maps of plant traits, such as leaf nitrogen or plant height, are essential for understanding ecosystem processes, including the carbon and energy cycles of the Earth system. However, existing trait maps remain limited by the high cost and sparse geographic coverage of field-based measurements. Citizen science initiatives offer a largely untapped resource to overcome these limitations, with over 50 million geotagged plant photographs worldwide capturing valuable visual information on plant morphology and physiology. In this study, we introduce PlantTraitNet, a multi-modal, multi-task uncertainty-aware deep learning framework that predictsfour key plant traits (plant height, leaf area, specific leaf area, and nitrogen content) from citizen science photos using weak supervision. By aggregating individual trait predictions across space, we generate global maps of trait distributions. We validate these maps against independent vegetation survey data (sPlotOpen) and benchmark them against leading global trait products. Our results show that PlantTraitNet consistently outperforms existing trait maps across all evaluated traits, demonstrating that citizen science imagery, when integrated with computer vision and geospatial AI, enables not only scalable but also more accurate global trait mapping. This approach offers a powerful new pathway for ecological research and Earth system modeling.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.06943v2</guid></item><item><title>[cs updates on arXiv.org] SPOT: An Annotated French Corpus and Benchmark for Detecting Critical Interventions in Online Conversations</title><link>https://arxiv.org/abs/2511.07405</link><description>arXiv:2511.07405v3 Announce Type: replace 
Abstract: We introduce SPOT (Stopping Points in Online Threads), the first annotated corpus translating the sociological concept of stopping point into a reproducible NLP task. Stopping points are ordinary critical interventions that pause or redirect online discussions through a range of forms (irony, subtle doubt or fragmentary arguments) that frameworks like counterspeech or social correction often overlook. We operationalize this concept as a binary classification task and provide reliable annotation guidelines. The corpus contains 43,305 manually annotated French Facebook comments linked to URLs flagged as false information by social media users, enriched with contextual metadata (article, post, parent comment, page or group, and source). We benchmark fine-tuned encoder models (CamemBERT) and instruction-tuned LLMs under various prompting strategies. Results show that fine-tuned encoders outperform prompted LLMs in F1 score by more than 10 percentage points, confirming the importance of supervised learning for emerging non-English social media tasks. Incorporating contextual metadata further improves encoder models F1 scores from 0.75 to 0.78. We release the anonymized dataset, along with the annotation guidelines and code in our code repository, to foster transparency and reproducible research.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.07405v3</guid></item><item><title>[cs updates on arXiv.org] One Router to Route Them All: Homogeneous Expert Routing for Heterogeneous Graph Transformers</title><link>https://arxiv.org/abs/2511.07603</link><description>arXiv:2511.07603v2 Announce Type: replace 
Abstract: A common practice in heterogeneous graph neural networks (HGNNs) is to condition parameters on node/edge types, assuming types reflect semantic roles. However, this can cause overreliance on surface-level labels and impede cross-type knowledge transfer. We explore integrating Mixture-of-Experts (MoE) into HGNNs--a direction underexplored despite MoE's success in homogeneous settings. Crucially, we question the need for type-specific experts. We propose Homogeneous Expert Routing (HER), an MoE layer for Heterogeneous Graph Transformers (HGT) that stochastically masks type embeddings during routing to encourage type-agnostic specialization. Evaluated on IMDB, ACM, and DBLP for link prediction, HER consistently outperforms standard HGT and a type-separated MoE baseline. Analysis on IMDB shows HER experts specialize by semantic patterns (e.g., movie genres) rather than node types, confirming routing is driven by latent semantics. Our work demonstrates that regularizing type dependence in expert routing yields more generalizable, efficient, and interpretable representations--a new design principle for heterogeneous graph learning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.07603v2</guid></item><item><title>[cs updates on arXiv.org] Graph Neural Networks, Deep Reinforcement Learning and Probabilistic Topic Modeling for Strategic Multiagent Settings</title><link>https://arxiv.org/abs/2511.10501</link><description>arXiv:2511.10501v4 Announce Type: replace 
Abstract: This paper provides a comprehensive review of mainly GNN, DRL, and PTM methods with a focus on their potential incorporation in strategic multiagent settings. We draw interest in (i) ML methods currently utilized for uncovering unknown model structures adaptable to the task of strategic opponent modeling, and (ii) the integration of these methods with Game Theoretic concepts that avoid relying on assumptions often invalid in real-world scenarios, such as the Common Prior Assumption (CPA) and the Self-Interest Hypothesis (SIH). We analyze the ability to handle uncertainty and heterogeneity, two characteristics that are very common in real-world application cases, as well as scalability. As a potential answer to effectively modeling relationships and interactions in multiagent settings, we champion the use of GNN. Such approaches are designed to operate upon graph-structured data, and have been shown to be a very powerful tool for performing tasks such as node classification and link prediction. Next, we review the domain of RL, and in particular that of multiagent deep reinforcement learning. Single-agent deep RL has been widely used for decision making in demanding game settings. Its application in multiagent settings though is hindered due to, e.g., varying relationships between agents, and non-stationarity of the environment. We describe existing relevant game theoretic solution concepts, and consider properties such as fairness and stability. Our review comes complete with a note on the literature that utilizes probabilistic topic modeling (PTM) in domains other than that of document analysis and classification. Finally, we identify certain open challenges -- specifically, the need to (i) fit non-stationary environments, (ii) balance the degrees of stability and adaptation, (iii) tackle uncertainty and heterogeneity, (iv) guarantee scalability and solution tractability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.10501v4</guid></item><item><title>[cs updates on arXiv.org] Divide, Conquer and Unite: Hierarchical Style-Recalibrated Prototype Alignment for Federated Medical Segmentation</title><link>https://arxiv.org/abs/2511.10945</link><description>arXiv:2511.10945v2 Announce Type: replace 
Abstract: Federated learning enables multiple medical institutions to train a global model without sharing data, yet feature heterogeneity from diverse scanners or protocols remains a major challenge. Many existing works attempt to address this issue by leveraging model representations (e.g., mean feature vectors) to correct local training; however, they often face two key limitations: 1) Incomplete Contextual Representation Learning: Current approaches primarily focus on final-layer features, overlooking critical multi-level cues and thus diluting essential context for accurate segmentation. 2) Layerwise Style Bias Accumulation: Although utilizing representations can partially align global features, these methods neglect domain-specific biases within intermediate layers, allowing style discrepancies to build up and reduce model robustness. To address these challenges, we propose FedBCS to bridge feature representation gaps via domain-invariant contextual prototypes alignment. Specifically, we introduce a frequency-domain adaptive style recalibration into prototype construction that not only decouples content-style representations but also learns optimal style parameters, enabling more robust domain-invariant prototypes. Furthermore, we design a context-aware dual-level prototype alignment method that extracts domain-invariant prototypes from different layers of both encoder and decoder and fuses them with contextual information for finer-grained representation alignment. Extensive experiments on two public datasets demonstrate that our method exhibits remarkable performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.10945v2</guid></item><item><title>[cs updates on arXiv.org] Integrating Neural Differential Forecasting with Safe Reinforcement Learning for Blood Glucose Regulation</title><link>https://arxiv.org/abs/2511.12417</link><description>arXiv:2511.12417v2 Announce Type: replace 
Abstract: Automated insulin delivery for Type 1 Diabetes must balance glucose control and safety under uncertain meals and physiological variability. While reinforcement learning (RL) enables adaptive personalization, existing approaches struggle to simultaneously guarantee safety, leaving a gap in achieving both personalized and risk-aware glucose control, such as overdosing before meals or stacking corrections. To bridge this gap, we propose TSODE, a safety-aware controller that integrates Thompson Sampling RL with a Neural Ordinary Differential Equation (NeuralODE) forecaster to address this challenge. Specifically, the NeuralODE predicts short-term glucose trajectories conditioned on proposed insulin doses, while a conformal calibration layer quantifies predictive uncertainty to reject or scale risky actions. In the FDA-approved UVa/Padova simulator (adult cohort), TSODE achieved 87.9% time-in-range with less than 10% time below 70 mg/dL, outperforming relevant baselines. These results demonstrate that integrating adaptive RL with calibrated NeuralODE forecasting enables interpretable, safe, and robust glucose regulation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.12417v2</guid></item><item><title>[cs updates on arXiv.org] AudioMotionBench: Evaluating Auditory Motion Perception in Audio LLMs</title><link>https://arxiv.org/abs/2511.13273</link><description>arXiv:2511.13273v2 Announce Type: replace 
Abstract: Large Audio-Language Models (LALMs) have recently shown impressive progress in speech recognition, audio captioning, and auditory question answering. Yet, whether these models can perceive spatial dynamics, particularly the motion of sound sources, remains unclear. In this work, we uncover a systematic motion perception deficit in current ALLMs. To investigate this issue, we introduce AudioMotionBench, the first benchmark explicitly designed to evaluate auditory motion understanding. AudioMotionBench introduces a controlled question-answering benchmark designed to evaluate whether Audio-Language Models (LALMs) can infer the direction and trajectory of moving sound sources from binaural audio. Comprehensive quantitative and qualitative analyses reveal that current models struggle to reliably recognize motion cues or distinguish directional patterns. The average accuracy remains below 50\%, underscoring a fundamental limitation in auditory spatial reasoning. Our study highlights a fundamental gap between human and model auditory spatial reasoning, providing both a diagnostic tool and new insight for enhancing spatial cognition in future Audio-Language Models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.13273v2</guid></item><item><title>[cs updates on arXiv.org] YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection</title><link>https://arxiv.org/abs/2511.13344</link><description>arXiv:2511.13344v4 Announce Type: replace 
Abstract: This paper presents a novel Mixture-of-Experts framework for object detection, incorporating adaptive routing among multiple YOLOv9-T experts to enable dynamic feature specialization and achieve higher mean Average Precision (mAP) and Average Recall (AR) compared to a single YOLOv9-T model.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.13344v4</guid></item><item><title>[cs updates on arXiv.org] Taming the Long-Tail: Efficient Reasoning RL Training with Adaptive Drafter</title><link>https://arxiv.org/abs/2511.16665</link><description>arXiv:2511.16665v2 Announce Type: replace 
Abstract: The emergence of Large Language Models (LLMs) with strong reasoning capabilities marks a significant milestone, unlocking new frontiers in complex problem-solving. However, training these reasoning models, typically using Reinforcement Learning (RL), encounters critical efficiency bottlenecks: response generation during RL training exhibits a persistent long-tail distribution, where a few very long responses dominate execution time, wasting resources and inflating costs. To address this, we propose TLT, a system that accelerates reasoning RL training losslessly by integrating adaptive speculative decoding. Applying speculative decoding in RL is challenging due to the dynamic workloads, evolving target model, and draft model training overhead. TLT overcomes these obstacles with two synergistic components: (1) Adaptive Drafter, a lightweight draft model trained continuously on idle GPUs during long-tail generation to maintain alignment with the target model at no extra cost; and (2) Adaptive Rollout Engine, which maintains a memory-efficient pool of pre-captured CUDAGraphs and adaptively select suitable SD strategies for each input batch. Evaluations demonstrate that TLT achieves over 1.7x end-to-end RL training speedup over state-of-the-art systems, preserves the model accuracy, and yields a high-quality draft model as a free byproduct suitable for efficient deployment. Code is released at https://github.com/mit-han-lab/fastrl.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.16665v2</guid></item><item><title>[cs updates on arXiv.org] Boundary-Aware Adversarial Filtering for Reliable Diagnosis under Extreme Class Imbalance</title><link>https://arxiv.org/abs/2511.17629</link><description>arXiv:2511.17629v2 Announce Type: replace 
Abstract: We study classification under extreme class imbalance where recall and calibration are both critical, for example in medical diagnosis scenarios. We propose AF-SMOTE, a mathematically motivated augmentation framework that first synthesizes minority points and then filters them by an adversarial discriminator and a boundary utility model. We prove that, under mild assumptions on the decision boundary smoothness and class-conditional densities, our filtering step monotonically improves a surrogate of F_beta (for beta &gt;= 1) while not inflating Brier score. On MIMIC-IV proxy label prediction and canonical fraud detection benchmarks, AF-SMOTE attains higher recall and average precision than strong oversampling baselines (SMOTE, ADASYN, Borderline-SMOTE, SVM-SMOTE), and yields the best calibration. We further validate these gains across multiple additional datasets beyond MIMIC-IV. Our successful application of AF-SMOTE to a healthcare dataset using a proxy label demonstrates in a disease-agnostic way its practical value in clinical situations, where missing true positive cases in rare diseases can have severe consequences.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.17629v2</guid></item><item><title>[cs updates on arXiv.org] DISPATCH -- Decentralized Informed Spatial Planning and Assignment of Tasks for Cooperative Heterogeneous Agents</title><link>https://arxiv.org/abs/2511.17915</link><description>arXiv:2511.17915v4 Announce Type: replace 
Abstract: Spatial task allocation in systems such as multi-robot delivery or ride-sharing requires balancing efficiency with fair service across tasks. Greedy assignment policies that match each agent to its highest-preference or lowest-cost task can maximize efficiency but often create inequities: some tasks receive disproportionately favorable service (e.g., shorter delays or better matches), while others face long waits or poor allocations.
  We study fairness in heterogeneous multi-agent systems where tasks vary in preference alignment and urgency. Most existing approaches either assume centralized coordination or largely ignore fairness under partial observability. Distinct from this prior work, we establish a connection between the Eisenberg-Gale (EG) equilibrium convex program and decentralized, partially observable multi-agent learning. Building on this connection, we develop two equilibrium-informed algorithms that integrate fairness and efficiency: (i) a multi-agent reinforcement learning (MARL) framework, EG-MARL, whose training is guided by a centralized EG equilibrium assignment algorithm; and (ii) a stochastic online optimization mechanism that performs guided exploration and subset-based fair assignment as tasks are discovered.
  We evaluate on Multi-Agent Particle Environment (MPE) simulations across varying team sizes against centralized EG, Hungarian, and Min-Max distance baselines, and also present a Webots-based warehouse proof-of-concept with heterogeneous robots. Both methods preserve the fairness-efficiency balance of the EG solution under partial observability, with EG-MARL achieving near-centralized coordination and reduced travel distances, and the online mechanism enabling real-time allocation with competitive fairness.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.17915v4</guid></item><item><title>[cs updates on arXiv.org] Radiation-Preserving Selective Imaging for Pediatric Hip Dysplasia: A Cross-Modal Ultrasound-Xray Policy with Limited Labels</title><link>https://arxiv.org/abs/2511.18457</link><description>arXiv:2511.18457v2 Announce Type: replace 
Abstract: We study an ultrasound-first, radiation-preserving policy for developmental dysplasia of the hip (DDH) that requests a radiograph only when needed.
  We (i) pretrain modality-specific encoders (ResNet-18) with SimSiam on a large unlabelled registry (37186 ultrasound; 19546 radiographs), (ii) freeze the backbones and fit small, measurement-faithful heads on DDH-relevant landmarks and measurements, (iii) calibrate a one-sided conformal deferral rule on ultrasound predictions that provides finite sample marginal coverage guarantees under exchangeability, using a held-out calibration set. Ultrasound heads predict Graf alpha, beta, and femoral head coverage; X-ray heads predict acetabular index (AI), center-edge (CE) angle and IHDI grade. On our held out labeled evaluation set, ultrasound measurement error is modest (e.g., alpha MAE ~= 9.7 degrees, coverage MAE ~= 14.0%), while radiographic probes achieve AI and CE MAEs of ~= 7.6 degrees and ~= 8.9 degrees, respectively. The calibrated US-only policy is explored across rule families (alpha-only; alpha OR coverage; alpha AND coverage), conformal miscoverage levels, and per-utility trade-offs using decision-curve analysis. Conservative settings yield high coverage with near-zero US-only rates; permissive settings (e.g., alpha OR coverage at larger deltas) achieve non-zero US-only throughput with expected coverage tradeoffs.
  The result is a simple, reproducible pipeline that turns limited labels into interpretable measurements and tunable selective imaging curves suitable for clinical handoff and future external validation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.18457v2</guid></item><item><title>[cs updates on arXiv.org] MetaDCSeg: Robust Medical Image Segmentation via Meta Dynamic Center Weighting</title><link>https://arxiv.org/abs/2511.18894</link><description>arXiv:2511.18894v2 Announce Type: replace 
Abstract: Medical image segmentation is crucial for clinical applications, but it is frequently disrupted by noisy annotations and ambiguous anatomical boundaries, which lead to instability in model training. Existing methods typically rely on global noise assumptions or confidence-based sample selection, which inadequately mitigate the performance degradation caused by annotation noise, especially in challenging boundary regions. To address this issue, we propose MetaDCSeg, a robust framework that dynamically learns optimal pixel-wise weights to suppress the influence of noisy ground-truth labels while preserving reliable annotations. By explicitly modeling boundary uncertainty through a Dynamic Center Distance (DCD) mechanism, our approach utilizes weighted feature distances for foreground, background, and boundary centers, directing the model's attention toward hard-to-segment pixels near ambiguous boundaries. This strategy enables more precise handling of structural boundaries, which are often overlooked by existing methods, and significantly enhances segmentation performance. Extensive experiments across four benchmark datasets with varying noise levels demonstrate that MetaDCSeg consistently outperforms existing state-of-the-art methods.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.18894v2</guid></item><item><title>[cs updates on arXiv.org] Bipartiteness in Progressive Second-Price Multi-Auction Networks with Perfect Substitute</title><link>https://arxiv.org/abs/2511.19225</link><description>arXiv:2511.19225v2 Announce Type: replace 
Abstract: We consider a bipartite network of buyers and sellers, where the sellers run locally independent Progressive Second-Price (PSP) auctions, and buyers may participate in multiple auctions, forming a multi-auction market with perfect substitute. The paper develops a projection-based influence framework for decentralized PSP auctions. We formalize primary and expanded influence sets using projections on the active bid index set and show how partial orders on bid prices govern allocation, market shifts, and the emergence of saturated one-hop shells. Our results highlight the robustness of PSP auctions in decentralized environments by introducing saturated components and a structured framework for phase transitions in multi-auction dynamics. This structure ensures deterministic coverage of the strategy space, enabling stable and truthful embedding in the larger game. We further model intra-round dynamics using an index to capture coordinated asynchronous seller updates coupled through buyers' joint constraints. Together, these constructions explain how local interactions propagate across auctions and gives premise for coherent equilibria--without requiring global information or centralized control.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.19225v2</guid></item><item><title>[cs updates on arXiv.org] Design and Validation of a Modular Smart Headband with Embroidered Electrodes for Comfortable EEG Monitoring</title><link>https://arxiv.org/abs/2511.19348</link><description>arXiv:2511.19348v3 Announce Type: replace 
Abstract: The wearable EEG device sector is advancing rapidly, enabling fast and reliable detection of brain activity for investigating brain function and pathology. However, many current EEG systems remain challenging for users with neurological conditions due to bulky wiring, lengthy skin preparation, gel-induced discomfort, risk of irritation, and high cost, all of which limit long-term monitoring. This study presents a proof-of-concept smart modular headband incorporating adjustable, replaceable embroidered electrodes for EEG acquisition. Compared with conventional devices, the smart headband reduces wiring complexity, removes the need for skin preparation, and minimizes irritation associated with gel-based electrodes. Its modular structure allows adjustable fitting without requiring multiple size options, enhancing comfort and adaptability for everyday EEG monitoring. The smart headband prototype was tested on 10 healthy university students using three behavioral tasks: (1) eyes open/closed, (2) auditory oddball, and (3) visual oddball paradigms. The smart headband successfully captured alpha peaks during the eyes-open/closed task (p = 0.01) and reliably recorded the event-related potentials associated with the oddball effects - the auditory P300 (p = 0.014) and the visual N170 (p = 0.013) - demonstrating an equivalent performance to a commercial sponge-based EEG cap. A user survey indicated improved comfort and usability, with participants reporting that the soft, structurally designed headband enhanced wearability relative to a conventional cap. Overall, this prototype provides a comfortable, modular, and cost-effective solution to reliable EEG monitoring in real-world applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.19348v3</guid></item><item><title>[cs updates on arXiv.org] EfficientXpert: Efficient Domain Adaptation for Large Language Models via Propagation-Aware Pruning</title><link>https://arxiv.org/abs/2511.19935</link><description>arXiv:2511.19935v2 Announce Type: replace 
Abstract: Large language models (LLMs) are increasingly adapted into domain-specific variants for applications in law, healthcare, and finance. Their scale, however, limits deployment in resource-constrained settings, and existing compression approaches often either degrade after domain adaptation or require substantial additional computation. We introduce EfficientXpert, a lightweight framework for domain pruning that integrates ForeSight Mask, a propagation-aware criterion for selecting weights to prune without backpropagation, and Partial Brain Surgeon, an efficient closed-form update for low-rank adapters under a fixed sparsity pattern. With fine-tuning cost comparable to standard LoRA, EfficientXpert converts a general pretrained model into a sparse, domain-adapted expert in a single pruning step. Across health and legal benchmarks, EfficientXpert reaches up to 98 percent of dense performance at 40 percent sparsity, improving over prior pruning baselines while matching LoRA training time and staying within 1 percent of LoRA peak GPU memory in our experiments.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.19935v2</guid></item><item><title>[cs updates on arXiv.org] Interpretable Air Pollution Forecasting by Physics-Guided Spatiotemporal Decoupling</title><link>https://arxiv.org/abs/2511.20257</link><description>arXiv:2511.20257v2 Announce Type: replace 
Abstract: Accurate and interpretable air pollution forecasting is crucial for public health, but most models face a trade-off between performance and interpretability. This study proposes a physics-guided, interpretable-by-design spatiotemporal learning framework. The model decomposes the spatiotemporal behavior of air pollutant concentrations into two transparent, additive modules. The first is a physics-guided transport kernel with directed weights conditioned on wind and geography (advection). The second is an explainable attention mechanism that learns local responses and attributes future concentrations to specific historical lags and exogenous drivers. Evaluated on a comprehensive dataset from the Stockholm region, our model consistently outperforms state-of-the-art baselines across multiple forecasting horizons. Our model's integration of high predictive performance and spatiotemporal interpretability provides a more reliable foundation for operational air-quality management in real-world applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.20257v2</guid></item><item><title>[cs updates on arXiv.org] DRS-OSS: Practical Diff Risk Scoring with LLMs</title><link>https://arxiv.org/abs/2511.21964</link><description>arXiv:2511.21964v2 Announce Type: replace 
Abstract: In large-scale open-source projects, hundreds of pull requests land daily, each a potential source of regressions. Diff risk scoring (DRS) estimates how likely an individual code change is to introduce a defect. This score can help prioritize reviews and tests, gate high-risk changes, and manage CI/CD capacity. Building on this idea, we present DRS-OSS, an open-source DRS tool equipped with a public API, web UI, and GitHub plugin. DRS-OSS is a deployable, LLM-based diff risk scoring system for open-source projects built around a fine-tuned Llama 3.1 8B sequence classifier. The model consumes long-context representations that combine commit messages, structured diffs, and change metrics, and is trained on the ApacheJIT dataset. Using parameter-efficient adaptation, 4-bit QLoRA, and DeepSpeed ZeRO-3 CPU offloading, we train the model with 22k-token contexts on a single 20 GB GPU, demonstrating a highly efficient training procedure. On the ApacheJIT benchmark, DRS-OSS achieves state-of-the-art performance with an F1 score of 0.64 and a ROC-AUC of 0.89. Beyond standard classification metrics, we evaluate DRS-OSS as a gating mechanism. Simulations show that gating only the riskiest 30 percent of commits can prevent up to 86.4 percent of defect-inducing changes from landing. By adjusting the threshold, teams can tune risk trade-offs during periods of high sensitivity or limited review capacity. DRS-OSS integrates directly into developer workflows through a FastAPI gateway and LLM microservices for scalable inference, a React-based dashboard for manual diff analysis, and a GitHub App that posts risk labels and confidence scores on pull requests. The system delivers real-time, reproducible risk feedback and is released with a full replication package including fine-tuning scripts, deployment artifacts, and source code, as well as a project website and an end-to-end demonstration video.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.21964v2</guid></item><item><title>[cs updates on arXiv.org] All for One and One for All: Program Logics for Exploiting Internal Determinism in Parallel Programs</title><link>https://arxiv.org/abs/2511.23283</link><description>arXiv:2511.23283v2 Announce Type: replace 
Abstract: Nondeterminism makes parallel programs challenging to write and reason about. To avoid these challenges, researchers have developed techniques for internally deterministic parallel programming, in which the steps of a parallel computation proceed in a deterministic way. Internal determinism is useful because it lets a programmer reason about a program as if it executed in a sequential order. However, no verification framework exists to exploit this property and simplify formal reasoning about internally deterministic programs.
  To capture the essence of why internally deterministic programs should be easier to reason about, this paper defines a property called schedule-independent safety. A program satisfies schedule-independent safety, if, to show that the program is safe across all orderings, it suffices to show that one terminating execution of the program is safe. We then present a separation logic called Musketeer for proving that a program satisfies schedule-independent safety. Once a parallel program has been shown to satisfy schedule-independent safety, we can verify it with a new logic called Angelic, which allows one to dynamically select and verify just one sequential ordering of the program.
  Using Musketeer, we prove the soundness of MiniDet, an affine type system for enforcing internal determinism. MiniDet supports several core algorithmic primitives for internally deterministic programming that have been identified in the research literature, including a deterministic version of a concurrent hash set. Because any syntactically well-typed MiniDet program satisfies schedule-independent safety, we can apply Angelic to verify such programs.
  All results in this paper have been verified in Rocq using the Iris separation logic framework.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.23283v2</guid></item><item><title>[cs updates on arXiv.org] Sigma: The Key for Vision-Language-Action Models toward Telepathic Alignment</title><link>https://arxiv.org/abs/2512.00783</link><description>arXiv:2512.00783v3 Announce Type: replace 
Abstract: To address a fundamental limitation in cognitive systems, namely the absence of a time-updatable mediating thought space between semantics and continuous control, this work constructs and trains a vision-language-action model termed Sigma, deployed on a single RTX 4090. The model is built upon the open-source pi0.5_base backbone, with the svla_so101_pickplace dataset preprocessed into a structured training corpus. An independently designed VLA architecture is introduced to integrate deep semantic understanding with associative reasoning, enabling telepathic-style alignment between perception and action. Training proceeds through iterative optimization of data preprocessing, LoRA-based fine-tuning, and inference-stage adapter design. Evaluation is conducted using offline closed-loop replay, comparing Sigma against the untuned pi0.5_base under identical data conditions. Experimental results indicate a consistent reduction in control MSE across vector-, fragment-, and trajectory-level scales, while preserving the stability of the telepathy norm and semantic-text alignment quality. These findings demonstrate that mind-responsive alignment control can be quantitatively achieved through semantic and associative architectural integration without retraining the base model, providing a reproducible pathway for semantic alignment and intention-driven behavior.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.00783v3</guid></item><item><title>[cs updates on arXiv.org] Four Over Six: More Accurate NVFP4 Quantization with Adaptive Block Scaling</title><link>https://arxiv.org/abs/2512.02010</link><description>arXiv:2512.02010v3 Announce Type: replace 
Abstract: As large language models have grown larger, interest has grown in low-precision numerical formats such as NVFP4 as a way to improve speed and reduce memory usage. However, quantizing models to NVFP4 remains difficult as the lack of precision generally degrades model performance. In this work, we address this issue with Four Over Six (4/6), a modification to the block-scaled NVFP4 quantization algorithm that yields reduced quantization error. Unlike integer formats, floating point formats have non-uniform step sizes which create larger quantization error on larger values. 4/6 takes advantage of this by adaptively scaling some blocks to smaller FP4 values, making the distribution of representable values more uniform and reducing quantization error for near-maximal values. We show that 4/6 can be implemented efficiently on NVIDIA Blackwell GPUs, resulting in performance gains during both pre-training and inference with minimal computational overhead. In pre-training experiments with the Nemotron 3 Nano 30B-A3B model architecture, we find that 4/6 brings training loss closer to BF16 compared to models trained with current state-of-the-art NVFP4 training recipes. Our code is available at http://github.com/mit-han-lab/fouroversix.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.02010v3</guid></item><item><title>[cs updates on arXiv.org] Do you precondition on the left or on the right?</title><link>https://arxiv.org/abs/2512.05160</link><description>arXiv:2512.05160v2 Announce Type: replace 
Abstract: This work is a follow-up to a poster that was presented at the DD29 conference. Participants were asked the question: ``Do you precondition on the left or on the right?''. Here we report on the results of this social experiment. We also provide context on left, right and split preconditioning, share our literature review on the topic, and analyze some of the finer points. Two examples illustrate that convergence bounds can sometimes lead to misleading conclusions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.05160v2</guid></item><item><title>[cs updates on arXiv.org] Do You Feel Comfortable? Detecting Hidden Conversational Escalation in AI Chatbots</title><link>https://arxiv.org/abs/2512.06193</link><description>arXiv:2512.06193v4 Announce Type: replace 
Abstract: Large Language Models (LLM) are increasingly integrated into everyday interactions, serving not only as information assistants but also as emotional companions. Even in the absence of explicit toxicity, repeated emotional reinforcement or affective drift can gradually escalate distress in a form of \textit{implicit harm} that traditional toxicity filters fail to detect. Existing guardrail mechanisms often rely on external classifiers or clinical rubrics that may lag behind the nuanced, real-time dynamics of a developing conversation. To address this gap, we propose GAUGE (Guarding Affective Utterance Generation Escalation), logit-based framework for the real-time detection of hidden conversational escalation. GAUGE measures how an LLM's output probabilistically shifts the affective state of a dialogue.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.06193v4</guid></item><item><title>[cs updates on arXiv.org] DUET: Agentic Design Understanding via Experimentation and Testing</title><link>https://arxiv.org/abs/2512.06247</link><description>arXiv:2512.06247v2 Announce Type: replace 
Abstract: AI agents powered by large language models (LLMs) are being used to solve increasingly complex software engineering challenges, but struggle with hardware design tasks. Register Transfer Level (RTL) code presents a unique challenge for LLMs, as it encodes complex, dynamic, time-evolving behaviors using the low-level language features of SystemVerilog. LLMs struggle to infer these complex behaviors from the syntax of RTL alone, which limits their ability to complete all downstream tasks like code completion, documentation, or verification. In response to this issue, we present DUET: a general methodology for developing Design Understanding via Experimentation and Testing. DUET mimics how hardware design experts develop an understanding of complex designs: not just via a one-off readthrough of the RTL, but via iterative experimentation using a number of tools. DUET iteratively generates hypotheses, tests them with EDA tools (e.g., simulation, waveform inspection, and formal verification), and integrates the results to build a bottom-up understanding of the design. In our evaluations, we show that DUET improves AI agent performance on formal verification, when compared to a baseline flow without experimentation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.06247v2</guid></item><item><title>[cs updates on arXiv.org] DS FedProxGrad: Asymptotic Stationarity Without Noise Floor in Fair Federated Learning</title><link>https://arxiv.org/abs/2512.08671</link><description>arXiv:2512.08671v4 Announce Type: replace 
Abstract: Recent work \cite{arifgroup} introduced Federated Proximal Gradient \textbf{(\texttt{FedProxGrad})} for solving non-convex composite optimization problems in group fair federated learning. However, the original analysis established convergence only to a \textit{noise-dominated neighborhood of stationarity}, with explicit dependence on a variance-induced noise floor. In this work, we provide an improved asymptotic convergence analysis for a generalized \texttt{FedProxGrad}-type analytical framework with inexact local proximal solutions and explicit fairness regularization. We call this extended analytical framework \textbf{DS \texttt{FedProxGrad}} (Decay Step Size \texttt{FedProxGrad}). Under a Robbins-Monro step-size schedule \cite{robbins1951stochastic} and a mild decay condition on local inexactness, we prove that $\liminf_{r\to\infty} \mathbb{E}[\|\nabla F(\mathbf{x}^r)\|^2] = 0$, i.e., the algorithm is asymptotically stationary and the convergence rate does not depend on a variance-induced noise floor.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.08671v4</guid></item><item><title>[cs updates on arXiv.org] SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration</title><link>https://arxiv.org/abs/2512.10046</link><description>arXiv:2512.10046v2 Announce Type: replace 
Abstract: Recent advances in foundation models have shown promising results in developing generalist robotics that can perform diverse tasks in open-ended scenarios given multimodal inputs. However, current work has been mainly focused on indoor, household scenarios. In this work, we present SimWorld-Robotics~(SWR), a simulation platform for embodied AI in large-scale, photorealistic urban environments. Built on Unreal Engine 5, SWR procedurally generates unlimited photorealistic urban scenes populated with dynamic elements such as pedestrians and traffic systems, surpassing prior urban simulations in realism, complexity, and scalability. It also supports multi-robot control and communication. With these key features, we build two challenging robot benchmarks: (1) a multimodal instruction-following task, where a robot must follow vision-language navigation instructions to reach a destination in the presence of pedestrians and traffic; and (2) a multi-agent search task, where two robots must communicate to cooperatively locate and meet each other. Unlike existing benchmarks, these two new benchmarks comprehensively evaluate a wide range of critical robot capacities in realistic scenarios, including (1) multimodal instructions grounding, (2) 3D spatial reasoning in large environments, (3) safe, long-range navigation with people and traffic, (4) multi-robot collaboration, and (5) grounded communication. Our experimental results demonstrate that state-of-the-art models, including vision-language models (VLMs), struggle with our tasks, lacking robust perception, reasoning, and planning abilities necessary for urban environments.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.10046v2</guid></item><item><title>[cs updates on arXiv.org] Dynamics of Agentic Loops in Large Language Models: A Geometric Theory of Trajectories</title><link>https://arxiv.org/abs/2512.10350</link><description>arXiv:2512.10350v3 Announce Type: replace 
Abstract: Agentic systems built on large language models operate through recursive feedback loops, where each output becomes the next input. Yet the geometric behavior of these agentic loops (whether they converge, diverge, or exhibit more complex dynamics) remains poorly understood. This paper introduces a geometric framework for analyzing agentic trajectories in semantic embedding space, treating iterative transformations as discrete dynamical systems. We distinguish the artifact space, where linguistic transformations occur, from the embedding space, where geometric measurements are performed. Because cosine similarity is biased by embedding anisotropy, we introduce an isotonic calibration that eliminates systematic bias and aligns similarities with human semantic judgments while preserving high local stability. This enables rigorous measurement of trajectories, clusters and attractors. Through controlled experiments on singular agentic loops, we identify two fundamental regimes. A contractive rewriting loop converges toward a stable attractor with decreasing dispersion, while an exploratory summarize and negate loop produces unbounded divergence with no cluster formation. These regimes display qualitatively distinct geometric signatures of contraction and expansion. Our results show that prompt design directly governs the dynamical regime of an agentic loop, enabling systematic control of convergence, divergence and trajectory structure in iterative LLM transformations.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.10350v3</guid></item><item><title>[cs updates on arXiv.org] Words to Describe What I'm Feeling: Exploring the Potential of AI Agents for High Subjectivity Decisions in Advance Care Planning</title><link>https://arxiv.org/abs/2512.11276</link><description>arXiv:2512.11276v2 Announce Type: replace 
Abstract: Loss of decisional capacity, coupled with the increasing absence of reliable human proxies, raises urgent questions about how individuals' values can be represented in Advance Care Planning (ACP). To probe this fraught design space of high-risk, high-subjectivity decision support, we built an experience prototype (\acpagent{}) and asked 15 participants in 4 workshops to train it to be their personal ACP proxy. We analysed their coping strategies and feature requests and mapped the results onto axes of agent autonomy and human control. Our findings show a surprising 86.7\% agreement with \acpagent{}, arguing for a potential new role of AI in ACP where agents act as personal advocates for individuals, building mutual intelligibility over time. We propose that the key areas of future risk that must be addressed are the moderation of users' expectations and designing accountability and oversight over agent deployment and cutoffs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.11276v2</guid></item><item><title>[cs updates on arXiv.org] ProbeMDE: Uncertainty-Guided Active Proprioception for Monocular Depth Estimation in Surgical Robotics</title><link>https://arxiv.org/abs/2512.11773</link><description>arXiv:2512.11773v3 Announce Type: replace 
Abstract: Monocular depth estimation (MDE) provides a useful tool for robotic perception, but its predictions are often uncertain and inaccurate in challenging environments such as surgical scenes where textureless surfaces, specular reflections, and occlusions are common. To address this, we propose ProbeMDE, a cost-aware active sensing framework that combines RGB images with sparse proprioceptive measurements for MDE. Our approach utilizes an ensemble of MDE models to predict dense depth maps conditioned on both RGB images and on a sparse set of known depth measurements obtained via proprioception, where the robot has touched the environment in a known configuration. We quantify predictive uncertainty via the ensemble's variance and measure the gradient of the uncertainty with respect to candidate measurement locations. To prevent mode collapse while selecting maximally informative locations to propriocept (touch), we leverage Stein Variational Gradient Descent (SVGD) over this gradient map. We validate our method in both simulated and physical experiments on central airway obstruction surgical phantoms. Our results demonstrate that our approach outperforms baseline methods across standard depth estimation metrics, achieving higher accuracy while minimizing the number of required proprioceptive measurements.
  Project page: https://brittonjordan.github.io/probe_mde/</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.11773v3</guid></item><item><title>[cs updates on arXiv.org] SeVeDo: A Heterogeneous Transformer Accelerator for Low-Bit Inference via Hierarchical Group Quantization and SVD-Guided Mixed Precision</title><link>https://arxiv.org/abs/2512.12930</link><description>arXiv:2512.12930v2 Announce Type: replace 
Abstract: Low-bit quantization is a promising technique for efficient transformer inference by reducing computational and memory overhead. However, aggressive bitwidth reduction remains challenging due to activation outliers, leading to accuracy degradation. Existing methods, such as outlier-handling and group quantization, achieve high accuracy but incur substantial energy consumption. To address this, we propose SeVeDo, an energy-efficient SVD-based heterogeneous accelerator that structurally separates outlier-sensitive components into a high-precision low-rank path, while the remaining computations are executed in a low-bit residual datapath with group quantization. To further enhance efficiency, Hierarchical Group Quantization (HGQ) combines coarse-grained floating-point scaling with fine-grained shifting, effectively reducing dequantization cost. Also, SVD-guided mixed precision (SVD-MP) statically allocates higher bitwidths to precision-sensitive components identified through low-rank decomposition, thereby minimizing floating-point operation cost. Experimental results show that SeVeDo achieves a peak energy efficiency of 13.8TOPS/W, surpassing conventional designs, with 12.7TOPS/W on ViT-Base and 13.4TOPS/W on Llama2-7B benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.12930v2</guid></item><item><title>[cs updates on arXiv.org] TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning</title><link>https://arxiv.org/abs/2512.14274</link><description>arXiv:2512.14274v2 Announce Type: replace 
Abstract: Persistence diagrams (PDs) provide a powerful tool for understanding the topology of the underlying shape of a point cloud. However, identifying which points in PDs encode genuine signals remains challenging. This challenge directly hinders the practical adoption of topological data analysis in many applications, where automated and reliable interpretation of persistence diagrams is essential for downstream decision-making. In this paper, we study automatic significance detection for one-dimensional persistence diagrams. Specifically, we propose Topology Understanding Net (TUN), a multi-modal network that combines enhanced PD descriptors with self-attention, a PointNet-style point cloud encoder, learned fusion, and per-point classification, alongside stable preprocessing and imbalance-aware training. It provides an automated and effective solution for identifying significant points in PDs, which are critical for downstream applications. Experiments show that TUN outperforms classic methods in detecting significant points in PDs, illustrating its effectiveness in real-world applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.14274v2</guid></item><item><title>[cs updates on arXiv.org] Refusal Steering: Fine-grained Control over LLM Refusal Behaviour for Sensitive Topics</title><link>https://arxiv.org/abs/2512.16602</link><description>arXiv:2512.16602v2 Announce Type: replace 
Abstract: We introduce Refusal Steering, an inference-time method to exercise fine-grained control over Large Language Models refusal behaviour on politically sensitive topics without retraining. We replace fragile pattern-based refusal detection with an LLM-as-a-judge that assigns refusal confidence scores and we propose a ridge-regularized variant to compute steering vectors that better isolate the refusal--compliance direction. On Qwen3-Next-80B-A3B-Thinking, our method removes the refusal behaviour of the model around politically sensitive topics while maintaining safety on JailbreakBench and near-baseline performance on general benchmarks. The approach generalizes across 4B and 80B models and can also induce targeted refusals when desired. We analize the steering vectors and show that refusal signals concentrate in deeper layers of the transformer and are distributed across many dimensions. Together, these results demonstrate that activation steering can remove political refusal behaviour while retaining safety alignment for harmful content, offering a practical path to controllable, transparent moderation at inference time.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.16602v2</guid></item><item><title>[cs updates on arXiv.org] Anisotropic Green Coordinates</title><link>https://arxiv.org/abs/2512.20386</link><description>arXiv:2512.20386v2 Announce Type: replace 
Abstract: We live in a world filled with anisotropy, a ubiquitous characteristic of both natural and engineered systems. In this study, we concentrate on space deformation and introduce \textit{anisotropic Green coordinates}, which provide versatile effects for cage-based and variational deformations in both two and three dimensions. The anisotropic Green coordinates are derived from the anisotropic Laplacian equation $\nabla\cdot(\mathbf{A}\nabla u)=0$, where $\mathbf{A}$ is a symmetric positive definite matrix. This equation belongs to the class of constant-coefficient second-order elliptic equations, exhibiting properties analogous to the Laplacian equation but incorporating the matrix $\mathbf{A}$ to characterize anisotropic behavior. Based on this equation, we establish the boundary integral formulation, which is subsequently discretized to derive anisotropic Green coordinates defined on the vertices and normals of oriented simplicial cages. Our method satisfies basic properties such as linear reproduction and translation invariance, and possesses closed-form expressions for both 2D and 3D scenarios. We also give an intuitive geometric interpretation of the approach, demonstrating that our method generates a quasi-conformal mapping. Furthermore, we derive the gradients and Hessians of the deformation coordinates and employ the local-global optimization framework to facilitate variational shape deformation, enabling flexible shape manipulation while achieving as-rigid-as-possible shape deformation. Experimental results demonstrate that anisotropic Green coordinates offer versatile and diverse deformation options, providing artists with enhanced flexibility and introducing a novel perspective on spatial deformation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.20386v2</guid></item><item><title>[cs updates on arXiv.org] Real-World Adversarial Attacks on RF-Based Drone Detectors</title><link>https://arxiv.org/abs/2512.20712</link><description>arXiv:2512.20712v2 Announce Type: replace 
Abstract: Radio frequency (RF) based systems are increasingly used to detect drones by analyzing their RF signal patterns, converting them into spectrogram images which are processed by object detection models. Existing RF attacks against image based models alter digital features, making over-the-air (OTA) implementation difficult due to the challenge of converting digital perturbations to transmittable waveforms that may introduce synchronization errors and interference, and encounter hardware limitations. We present the first physical attack on RF image based drone detectors, optimizing class-specific universal complex baseband (I/Q) perturbation waveforms that are transmitted alongside legitimate communications. We evaluated the attack using RF recordings and OTA experiments with four types of drones. Our results show that modest, structured I/Q perturbations are compatible with standard RF chains and reliably reduce target drone detection while preserving detection of legitimate drones.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.20712v2</guid></item><item><title>[cs updates on arXiv.org] A Domain Decomposition-based Solver for Acoustic Wave propagation in Two-Dimensional Random Media</title><link>https://arxiv.org/abs/2512.23027</link><description>arXiv:2512.23027v2 Announce Type: replace 
Abstract: An acoustic wave propagation problem with a log normal random field approximation for wave speed is solved using a sampling-free intrusive stochastic Galerkin approach. The stochastic partial differential equation with the inputs and outputs expanded using polynomial chaos expansion (PCE) is transformed into a set of deterministic PDEs and further to a system of linear equations. Domain decomposition (DD)-based solvers are utilized to handle the overwhelming computational cost for the resulting system with increasing mesh size, time step and number of random parameters. A conjugate gradient iterative solver with a two-level Neumann-Neumann preconditioner is applied here showing their efficient scalabilities.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.23027v2</guid></item><item><title>[cs updates on arXiv.org] DEFT: Differentiable Automatic Test Pattern Generation</title><link>https://arxiv.org/abs/2512.23746</link><description>arXiv:2512.23746v2 Announce Type: replace 
Abstract: Modern IC complexity drives test pattern growth, with the majority of patterns targeting a small set of hard-to-detect (HTD) faults. This motivates new ATPG algorithms to improve test effectiveness specifically for HTD faults. This paper presents DEFT (Differentiable Automatic Test Pattern Generation), a new ATPG approach that reformulates the discrete ATPG problem as a continuous optimization task. DEFT introduces a mathematically grounded reparameterization that aligns the expected continuous objective with discrete fault-detection semantics, enabling reliable gradient-based pattern generation. To ensure scalability and stability on deep circuit graphs, DEFT integrates a custom CUDA kernel for efficient forward-backward propagation and applies gradient normalization to mitigate vanishing gradients. Compared to a leading commercial tool on two industrial benchmarks, DEFT improves HTD fault detection by 21.1% and 48.9% on average under the same pattern budget and comparable runtime. DEFT also supports practical ATPG settings such as partial assignment pattern generation, producing patterns with 19.3% fewer 0/1 bits while still detecting 35% more faults. These results indicate DEFT is a promising and effective ATPG engine, offering a valuable complement to existing heuristic.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.23746v2</guid></item><item><title>[cs updates on arXiv.org] Constraint Breeds Generalization: Temporal Dynamics as an Inductive Bias</title><link>https://arxiv.org/abs/2512.23916</link><description>arXiv:2512.23916v2 Announce Type: replace 
Abstract: Conventional deep learning prioritizes unconstrained optimization, yet biological systems operate under strict metabolic constraints. We propose that these physical constraints shape dynamics to function not as limitations, but as a temporal inductive bias that breeds generalization. Through a phase-space analysis of signal propagation, we reveal a fundamental asymmetry: expansive dynamics amplify noise, whereas proper dissipative dynamics compress phase space that aligns with the network's spectral bias, compelling the abstraction of invariant features. This condition can be imposed externally via input encoding, or intrinsically through the network's own temporal dynamics. Both pathways require architectures capable of temporal integration and proper constraints to decode induced invariants, whereas static architectures fail to capitalize on temporal structure. Through comprehensive evaluations across supervised classification, unsupervised reconstruction, and zero-shot reinforcement learning, we demonstrate that a critical "transition" regime maximizes generalization capability. These findings establish dynamical constraints as a distinct class of inductive bias, suggesting that robust AI development requires not only scaling and removing limitations, but computationally mastering the temporal characteristics that naturally promote generalization.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.23916v2</guid></item><item><title>[cs updates on arXiv.org] RadixGraph: A Fast, Space-Optimized Data Structure for Dynamic Graph Storage (Extended Version)</title><link>https://arxiv.org/abs/2601.01444</link><description>arXiv:2601.01444v2 Announce Type: replace 
Abstract: Dynamic graphs model many real-world applications, and as their sizes grow, efficiently storing and updating them becomes critical. We present RadixGraph, a fast and memory-efficient data structure for dynamic graph storage. RadixGraph features a carefully designed radix-tree-based vertex index that strikes an optimal trade-off between query efficiency and space among all pointer-array-based radix trees. For edge storage, it employs a hybrid snapshot-log architecture that enables amortized $O(1)$ update time. RadixGraph supports millions of concurrent updates per second while maintaining competitive performance for graph analytics. Experimental results show that RadixGraph outperforms the most performant baseline by up to $16.27\times$ across various datasets in ingesting graph updates, and reduces memory usage by an average of $40.1\%$. RadixGraph is open-source at https://github.com/ForwardStar/RadixGraph.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.01444v2</guid></item><item><title>[cs updates on arXiv.org] Crafting Adversarial Inputs for Large Vision-Language Models Using Black-Box Optimization</title><link>https://arxiv.org/abs/2601.01747</link><description>arXiv:2601.01747v4 Announce Type: replace 
Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have shown groundbreaking capabilities across diverse multimodal tasks. However, these models remain vulnerable to adversarial jailbreak attacks, where adversaries craft subtle perturbations to bypass safety mechanisms and trigger harmful outputs. Existing white-box attacks methods require full model accessibility, suffer from computing costs and exhibit insufficient adversarial transferability, making them impractical for real-world, black-box settings. To address these limitations, we propose a black-box jailbreak attack on LVLMs via Zeroth-Order optimization using Simultaneous Perturbation Stochastic Approximation (ZO-SPSA). ZO-SPSA provides three key advantages: (i) gradient-free approximation by input-output interactions without requiring model knowledge, (ii) model-agnostic optimization without the surrogate model and (iii) lower resource requirements with reduced GPU memory consumption. We evaluate ZO-SPSA on three LVLMs, including InstructBLIP, LLaVA and MiniGPT-4, achieving the highest jailbreak success rate of 83.0% on InstructBLIP, while maintaining imperceptible perturbations comparable to white-box methods. Moreover, adversarial examples generated from MiniGPT-4 exhibit strong transferability to other LVLMs, with ASR reaching 64.18%. These findings underscore the real-world feasibility of black-box jailbreaks and expose critical weaknesses in the safety mechanisms of current LVLMs</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.01747v4</guid></item><item><title>[cs updates on arXiv.org] MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning</title><link>https://arxiv.org/abs/2601.01910</link><description>arXiv:2601.01910v2 Announce Type: replace 
Abstract: Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.
  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.01910v2</guid></item><item><title>[cs updates on arXiv.org] Lightweight and perceptually-guided voice conversion for electro-laryngeal speech</title><link>https://arxiv.org/abs/2601.03892</link><description>arXiv:2601.03892v2 Announce Type: replace 
Abstract: Electro-laryngeal (EL) speech is characterized by constant pitch, limited prosody, and mechanical noise, reducing naturalness and intelligibility. We propose a lightweight adaptation of the state-of-the-art StreamVC framework to this setting by removing pitch and energy modules and combining self-supervised pretraining with supervised fine-tuning on parallel EL and healthy (HE) speech data, guided by perceptual and intelligibility losses. Objective and subjective evaluations across different loss configurations confirm their influence: the best model variant, based on WavLM features and human-feedback predictions (+WavLM+HF), drastically reduces character error rate (CER) of EL inputs, raises naturalness mean opinion score (nMOS) from 1.1 to 3.3, and consistently narrows the gap to HE ground-truth speech in all evaluated metrics. These findings demonstrate the feasibility of adapting lightweight voice conversion architectures to EL voice rehabilitation while also identifying prosody generation and intelligibility improvements as the main remaining bottlenecks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.03892v2</guid></item><item><title>[cs updates on arXiv.org] FLEx: Language Modeling with Few-shot Language Explanations</title><link>https://arxiv.org/abs/2601.04157</link><description>arXiv:2601.04157v2 Announce Type: replace 
Abstract: Language models have become effective at a wide range of tasks, from math problem solving to open-domain question answering. However, they still make mistakes, and these mistakes are often repeated across related queries. Natural language explanations can help correct these errors, but collecting them at scale may be infeasible, particularly in domains where expert annotators are required. To address this issue, we introduce FLEx ($\textbf{F}$ew-shot $\textbf{L}$anguage $\textbf{Ex}$planations), a method for improving model behavior using a small number of explanatory examples. FLEx selects representative model errors using embedding-based clustering, verifies that the associated explanations correct those errors, and summarizes them into a prompt prefix that is prepended at inference-time. This summary guides the model to avoid similar errors on new inputs, without modifying model weights. We evaluate FLEx on CounterBench, GSM8K, and ReasonIF. We find that FLEx consistently outperforms chain-of-thought (CoT) prompting across all three datasets and reduces up to 83\% of CoT's remaining errors.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.04157v2</guid></item><item><title>[cs updates on arXiv.org] The Adverse Effects of Omitting Records in Differential Privacy: How Sampling and Suppression Degrade the Privacy--Utility Tradeoff (Long Version)</title><link>https://arxiv.org/abs/2601.05180</link><description>arXiv:2601.05180v2 Announce Type: replace 
Abstract: Sampling is renowned for its privacy amplification in differential privacy (DP), and is often assumed to improve the utility of a DP mechanism by allowing a noise reduction. In this paper, we further show that this last assumption is flawed: When measuring utility at equal privacy levels, sampling as preprocessing consistently yields penalties due to utility loss from omitting records over all canonical DP mechanisms -- Laplace, Gaussian, exponential, and report noisy max -- , as well as recent applications of sampling, such as clustering.
  Extending this analysis, we investigate suppression as a generalized method of choosing, or omitting, records. Developing a theoretical analysis of this technique, we derive privacy bounds for arbitrary suppression strategies under unbounded approximate DP. We find that our tested suppression strategy also fails to improve the privacy--utility tradeoff. Surprisingly, uniform sampling emerges as one of the best suppression methods -- despite its still degrading effect. Our results call into question common preprocessing assumptions in DP practice.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.05180v2</guid></item><item><title>[cs updates on arXiv.org] Do Sparse Autoencoders Identify Reasoning Features in Language Models?</title><link>https://arxiv.org/abs/2601.05679</link><description>arXiv:2601.05679v4 Announce Type: replace 
Abstract: We investigate whether sparse autoencoders identify genuine reasoning features in large language models. We first present a stylized theoretical analysis showing that sparsity-regularized decoding favors stable low-dimensional correlates over high-dimensional within-reasoning variation, biasing learned features toward token-level cues. Motivated by this analysis, we introduce a falsification-based evaluation framework that combines causal token injection with LLM-guided counterexample generation to distinguish genuine reasoning features from superficial linguistic correlates. Across 22 configurations spanning multiple model families, layers and datasets, we find that contrastively selected reasoning features are highly sensitive to token interventions, with 45%-90% activating when only a few associated tokens are injected into non-reasoning text. For the remaining features, LLM-guided falsification reliably constructs non-reasoning inputs that instantiate the feature's token-level cues and trigger activation, and meaning-preserving paraphrases of top-activating reasoning traces that suppress it. Steering the highest-ranked features yields no improvements on benchmarks. Overall, our results suggest that when low-dimensional token-level patterns are coupled with high-dimensional reasoning processes, the sparsity bias of SAEs systematically favors low-dimensional linguistic patterns that consistently co-occur with reasoning. Code is available at https://github.com/GeorgeMLP/reasoning-probing.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.05679v4</guid></item><item><title>[cs updates on arXiv.org] TeleMem: Building Long-Term and Multimodal Memory for Agentic AI</title><link>https://arxiv.org/abs/2601.06037</link><description>arXiv:2601.06037v4 Announce Type: replace 
Abstract: Large language models (LLMs) excel at many NLP tasks but struggle to sustain long-term interactions due to limited attention over extended dialogue histories. Retrieval-augmented generation (RAG) mitigates this issue but lacks reliable mechanisms for updating or refining stored memories, leading to schema-driven hallucinations, inefficient write operations, and minimal support for multimodal reasoning.To address these challenges, we propose TeleMem, a unified long-term and multimodal memory system that maintains coherent user profiles through narrative dynamic extraction, ensuring that only dialogue-grounded information is preserved. TeleMem further introduces a structured writing pipeline that batches, retrieves, clusters, and consolidates memory entries, substantially improving storage efficiency, reducing token usage, and accelerating memory operations. Additionally, a multimodal memory module combined with ReAct-style reasoning equips the system with a closed-loop observe, think, and act process that enables accurate understanding of complex video content in long-term contexts. Experimental results show that TeleMem surpasses the state-of-the-art Mem0 baseline with 19% higher accuracy, 43% fewer tokens, and a 2.1x speedup on the ZH-4O long-term role-play gaming benchmark.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.06037v4</guid></item><item><title>[cs updates on arXiv.org] ArenaRL: Scaling RL for Open-Ended Agents via Tournament-based Relative Ranking</title><link>https://arxiv.org/abs/2601.06487</link><description>arXiv:2601.06487v2 Announce Type: replace 
Abstract: Reinforcement learning has substantially improved the performance of LLM agents on tasks with verifiable outcomes, but it still struggles on open-ended agent tasks with vast solution spaces (e.g., complex travel planning). Due to the absence of objective ground-truth for these tasks, current RL algorithms largely rely on reward models that assign scalar scores to individual responses. We contend that such pointwise scoring suffers from an inherent discrimination collapse: the reward model struggles to distinguish subtle advantages among different trajectories, resulting in scores within a group being compressed into a narrow range. Consequently, the effective reward signal becomes dominated by noise from the reward model, leading to optimization stagnation. To address this, we propose ArenaRL, a reinforcement learning paradigm that shifts from pointwise scalar scoring to intra-group relative ranking. ArenaRL introduces a process-aware pairwise evaluation mechanism, employing multi-level rubrics to assign fine-grained relative scores to trajectories. Additionally, we construct an intra-group adversarial arena and devise a tournament-based ranking scheme to obtain stable advantage signals. Empirical results confirm that the built seeded single-elimination scheme achieves nearly equivalent advantage estimation accuracy to full pairwise comparisons with O(N^2) complexity, while operating with only O(N) complexity, striking an optimal balance between efficiency and precision. Furthermore, to address the lack of full-cycle benchmarks for open-ended agents, we build Open-Travel and Open-DeepResearch, two high-quality benchmarks featuring a comprehensive pipeline covering SFT, RL training, and multi-dimensional evaluation. Extensive experiments show that ArenaRL substantially outperforms standard RL baselines, enabling LLM agents to generate more robust solutions for complex real-world tasks.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.06487v2</guid></item><item><title>[cs updates on arXiv.org] VLM-CAD: VLM-Optimized Collaborative Agent Design Workflow for Analog Circuit Sizing</title><link>https://arxiv.org/abs/2601.07315</link><description>arXiv:2601.07315v2 Announce Type: replace 
Abstract: Analog mixed-signal circuit sizing involves complex trade-offs within high-dimensional design spaces. Existing automatic analog circuit sizing approaches rely solely on netlists, ignoring the circuit schematic, which hinders the cognitive link between the schematic and its performance. Furthermore, the black-box nature of machine learning methods and hallucination risks in large language models fail to provide the necessary ground-truth explainability required for industrial sign-off. To address these challenges, we propose a Vision Language Model-optimized collaborative agent design workflow (VLM-CAD), which analyzes circuits, optimizes DC operating points, performs inference-based sizing, and executes external sizing optimization. We integrate Image2Net to annotate circuit schematics and generate a structured JSON description for precise interpretation by Vision Language Models. Furthermore, we propose an Explainable Trust Region Bayesian Optimization method (ExTuRBO) that employs collaborative warm-start from agent-generated seeds and offers dual-granularity sensitivity analysis for external sizing optimization, supporting a comprehensive final design report. Experiment results on amplifier sizing tasks using 180nm, 90nm, and 45nm Predictive Technology Models demonstrate that VLM-CAD effectively balances power and performance while maintaining physics-based explainability. VLM-CAD meets all specification requirements while maintaining low power consumption in optimizing an amplifier with a complementary input and a class-AB output stage, with a total runtime under 66 minutes across all experiments on two amplifiers.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.07315v2</guid></item><item><title>[cs updates on arXiv.org] Enhancing Large Language Models for Time-Series Forecasting via Vector-Injected In-Context Learning</title><link>https://arxiv.org/abs/2601.07903</link><description>arXiv:2601.07903v3 Announce Type: replace 
Abstract: The World Wide Web needs reliable predictive capabilities to respond to changes in user behavior and usage patterns. Time series forecasting (TSF) is a key means to achieve this goal. In recent years, the large language models (LLMs) for TSF (LLM4TSF) have achieved good performance. However, there is a significant difference between pretraining corpora and time series data, making it hard to guarantee forecasting quality when directly applying LLMs to TSF; fine-tuning LLMs can mitigate this issue, but often incurs substantial computational overhead. Thus, LLM4TSF faces a dual challenge of prediction performance and compute overhead. To address this, we aim to explore a method for improving the forecasting performance of LLM4TSF while freezing all LLM parameters to reduce computational overhead. Inspired by in-context learning (ICL), we propose LVICL. LVICL uses our vector-injected ICL to inject example information into a frozen LLM, eliciting its in-context learning ability and thereby enhancing its performance on the example-related task (i.e., TSF). Specifically, we first use the LLM together with a learnable context vector adapter to extract a context vector from multiple examples adaptively. This vector contains compressed, example-related information. Subsequently, during the forward pass, we inject this vector into every layer of the LLM to improve forecasting performance. Compared with conventional ICL that adds examples into the prompt, our vector-injected ICL does not increase prompt length; moreover, adaptively deriving a context vector from examples suppresses components harmful to forecasting, thereby improving model performance. Extensive experiments demonstrate the effectiveness of our approach.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.07903v3</guid></item><item><title>[cs updates on arXiv.org] Your Group-Relative Advantage Is Biased</title><link>https://arxiv.org/abs/2601.08521</link><description>arXiv:2601.08521v2 Announce Type: replace 
Abstract: Reinforcement Learning from Verifier Rewards (RLVR) has emerged as a widely used approach for post-training large language models on reasoning tasks, with group-based methods such as GRPO and its variants gaining broad adoption. These methods rely on group-relative advantage estimation to avoid learned critics, yet its theoretical properties remain poorly understood.
  In this work, we uncover a fundamental issue of group-based RL: the group-relative advantage estimator is inherently biased relative to the true (expected) advantage. We provide the first theoretical analysis showing that it systematically underestimates advantages for hard prompts and overestimates them for easy prompts, leading to imbalanced exploration and exploitation. To address this issue, we propose History-Aware Adaptive Difficulty Weighting (HA-DW), an adaptive reweighting scheme that adjusts advantage estimates based on an evolving difficulty anchor and training dynamics. Both theoretical analysis and experiments on five mathematical reasoning benchmarks demonstrate that HA-DW consistently improves performance when integrated into GRPO and its variants. Our results suggest that correcting biased advantage estimation is critical for robust and efficient RLVR training.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.08521v2</guid></item><item><title>[cs updates on arXiv.org] Contrastive and Multi-Task Learning on Noisy Brain Signals with Nonlinear Dynamical Signatures</title><link>https://arxiv.org/abs/2601.08549</link><description>arXiv:2601.08549v2 Announce Type: replace 
Abstract: We introduce a two-stage multitask learning framework for analyzing Electroencephalography (EEG) signals that integrates denoising, dynamical modeling, and representation learning. In the first stage, a denoising autoencoder is trained to suppress artifacts and stabilize temporal dynamics, providing robust signal representations. In the second stage, a multitask architecture processes these denoised signals to achieve three objectives: motor imagery classification, chaotic versus non-chaotic regime discrimination using Lyapunov exponent-based labels, and self-supervised contrastive representation learning with NT-Xent loss. A convolutional backbone combined with a Transformer encoder captures spatial-temporal structure, while the dynamical task encourages sensitivity to nonlinear brain dynamics. This staged design mitigates interference between reconstruction and discriminative goals, improves stability across datasets, and supports reproducible training by clearly separating noise reduction from higher-level feature learning. Empirical studies show that our framework not only enhances robustness and generalization but also surpasses strong baselines and recent state-of-the-art methods in EEG decoding, highlighting the effectiveness of combining denoising, dynamical features, and self-supervised learning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.08549v2</guid></item><item><title>[cs updates on arXiv.org] Spectral Generative Flow Models: A Physics-Inspired Replacement for Vectorized Large Language Models</title><link>https://arxiv.org/abs/2601.08893</link><description>arXiv:2601.08893v2 Announce Type: replace 
Abstract: We introduce Spectral Generative Flow Models (SGFMs), a physics-inspired alternative to transformer-based large language models. Instead of representing text or video as sequences of discrete tokens processed by attention, SGFMs treat generation as the evolution of a continuous field governed by constrained stochastic dynamics in a multiscale wavelet basis. This formulation replaces global attention with local operators, spectral projections, and Navier--Stokes-like transport, yielding a generative mechanism grounded in continuity, geometry, and physical structure.
  Our framework provides three key innovations: (i) a field-theoretic ontology in which text and video are unified as trajectories of a stochastic partial differential equation; (ii) a wavelet-domain representation that induces sparsity, scale separation, and computational efficiency; and (iii) a constrained stochastic flow that enforces stability, coherence, and uncertainty propagation. Together, these components define a generative architecture that departs fundamentally from autoregressive modeling and diffusion-based approaches. SGFMs offer a principled path toward long-range coherence, multimodal generality, and physically structured inductive bias in next-generation generative models.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.08893v2</guid></item><item><title>[cs updates on arXiv.org] Error-Correcting Codes for Two Bursts of t1-Deletion-t2-Insertion with Low Computational Complexity</title><link>https://arxiv.org/abs/2601.10540</link><description>arXiv:2601.10540v2 Announce Type: replace 
Abstract: Burst errors involving simultaneous insertions, deletions, and substitutions occur in practical scenarios, including DNA data storage and document synchronization, motivating developments of channel codes that can correct such errors. In this paper, we address the problem of constructing error-correcting codes (ECCs) capable of handling multiple bursts of $t_1$-deletion-$t_2$-insertion ($(t_1,t_2)$-DI) errors, where each burst consists of $t_1$ deletions followed by $t_2$ insertions in a binary sequence. We make three key contributions: Firstly, we establish the fundamental equivalence of (1) two bursts of $(t_1,t_2)$-DI ECCs, (2) two bursts of $(t_2,t_1)$-DI ECCs, and (3) one burst each of $(t_1,t_2)$-DI and $(t_2,t_1)$-DI ECCs. Then, we derive lower and upper bounds on the code size of two bursts of $(t_1,t_2)$-DI ECCs, which can naturally be extended to the case of multiple bursts. Finally, we present constructions of two bursts of $(t_1,t_2)$-DI ECCs. Compared to the codes obtained by the syndrome compression technique, the resulting codes achieve significantly lower computational complexity.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.10540v2</guid></item><item><title>[cs updates on arXiv.org] iTIMO: An LLM-empowered Synthesis Dataset for Travel Itinerary Modification</title><link>https://arxiv.org/abs/2601.10609</link><description>arXiv:2601.10609v2 Announce Type: replace 
Abstract: Addressing itinerary modification is crucial for enhancing the travel experience as it is a frequent requirement during traveling. However, existing research mainly focuses on fixed itinerary planning, leaving modification underexplored due to the scarcity of need-to-modify itinerary data. To bridge this gap, we formally define the itinerary modification task and propose a general pipeline to construct the corresponding dataset, namely iTIMO. This pipeline frames the generation of need-to-modify itinerary data as an intent-driven perturbation task. It instructs large language models to perturb real-world itineraries using three operations: REPLACE, ADD, and DELETE. Each perturbation is grounded in three intents: disruptions of popularity, spatial distance, and category diversity. Furthermore, hybrid evaluation metrics are introduced to ensure perturbation effectiveness. We conduct comprehensive benchmarking on iTIMO to analyze the capabilities and limitations of state-of-the-art LLMs. Overall, iTIMO provides a comprehensive testbed for the modification task, and empowers the evolution of traditional travel recommender systems into adaptive frameworks capable of handling dynamic travel needs. Dataset, code and supplementary materials are available at https://github.com/zelo2/iTIMO.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.10609v2</guid></item><item><title>[cs updates on arXiv.org] From Interpretability to Performance: Optimizing Retrieval Heads for Long-Context Language Models</title><link>https://arxiv.org/abs/2601.11020</link><description>arXiv:2601.11020v2 Announce Type: replace 
Abstract: Advances in mechanistic interpretability have identified special attention heads, known as retrieval heads, that are responsible for retrieving information from the context. However, the role of these retrieval heads in improving model performance remains unexplored. This work investigates whether retrieval heads can be leveraged to enhance the long-context capabilities of LLMs. Specifically, we propose RetMask, a method that generates training signals by contrasting normal model outputs with those from an ablated variant in which the retrieval heads are masked. This mechanism-based approach achieves substantial improvements: +2.28 points on HELMET at 128K for Llama-3.1, with +70% gains on generation with citation and +32% on passage re-ranking, while preserving performance on general tasks. Experiments across three model families reveal that the effectiveness depends on retrieval head organization: models with concentrated patterns of retrieval heads respond strongly, while those with distributed patterns show limited gains. This mechanistic relationship validates the function of retrieval heads and demonstrates that mechanistic insights can be transformed into performance enhancements.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11020v2</guid></item><item><title>[cs updates on arXiv.org] Vision-as-Inverse-Graphics Agent via Interleaved Multimodal Reasoning</title><link>https://arxiv.org/abs/2601.11109</link><description>arXiv:2601.11109v2 Announce Type: replace 
Abstract: Vision-as-inverse-graphics, the concept of reconstructing an image as an editable graphics program is a long-standing goal of computer vision. Yet even strong VLMs aren't able to achieve this in one-shot as they lack fine-grained spatial and physical grounding capability. Our key insight is that closing this gap requires interleaved multimodal reasoning through iterative execution and verification. Stemming from this, we present VIGA (Vision-as-Inverse-Graphic Agent) that starts from an empty world and reconstructs or edits scenes through a closed-loop write-run-render-compare-revise procedure. To support long-horizon reasoning, VIGA combines (i) a skill library that alternates generator and verifier roles and (ii) an evolving context memory that contains plans, code diffs, and render history. VIGA is task-agnostic as it doesn't require auxiliary modules, covering a wide range of tasks such as 3D reconstruction, multi-step scene editing, 4D physical interaction, and 2D document editing, etc. Empirically, we found VIGA substantially improves one-shot baselines on BlenderGym (35.32%) and SlideBench (117.17%). Moreover, VIGA is also model-agnostic as it doesn't require finetuning, enabling a unified protocol to evaluate heterogeneous foundation VLMs. To better support this protocol, we introduce BlenderBench, a challenging benchmark that stress-tests interleaved multimodal reasoning with graphics engine, where VIGA improves by 124.70%.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11109v2</guid></item><item><title>[cs updates on arXiv.org] Heterogeneous Uncertainty-Guided Composed Image Retrieval with Fine-Grained Probabilistic Learning</title><link>https://arxiv.org/abs/2601.11393</link><description>arXiv:2601.11393v2 Announce Type: replace 
Abstract: Composed Image Retrieval (CIR) enables image search by combining a reference image with modification text. Intrinsic noise in CIR triplets incurs intrinsic uncertainty and threatens the model's robustness. Probabilistic learning approaches have shown promise in addressing such issues; however, they fall short for CIR due to their instance-level holistic modeling and homogeneous treatment of queries and targets. This paper introduces a Heterogeneous Uncertainty-Guided (HUG) paradigm to overcome these limitations. HUG utilizes a fine-grained probabilistic learning framework, where queries and targets are represented by Gaussian embeddings that capture detailed concepts and uncertainties. We customize heterogeneous uncertainty estimations for multi-modal queries and uni-modal targets. Given a query, we capture uncertainties not only regarding uni-modal content quality but also multi-modal coordination, followed by a provable dynamic weighting mechanism to derive comprehensive query uncertainty. We further design uncertainty-guided objectives, including query-target holistic contrast and fine-grained contrasts with comprehensive negative sampling strategies, which effectively enhance discriminative learning. Experiments on benchmarks demonstrate HUG's effectiveness beyond state-of-the-art baselines, with faithful analysis justifying the technical contributions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11393v2</guid></item><item><title>[cs updates on arXiv.org] Frontier AI Auditing: Toward Rigorous Third-Party Assessment of Safety and Security Practices at Leading AI Companies</title><link>https://arxiv.org/abs/2601.11699</link><description>arXiv:2601.11699v2 Announce Type: replace 
Abstract: Frontier AI is becoming critical societal infrastructure, but outsiders lack reliable ways to judge whether leading developers' safety and security claims are accurate and whether their practices meet relevant standards. Compared to other social and technological systems we rely on daily such as consumer products, corporate financial statements, and food supply chains, AI is subject to less rigorous third-party scrutiny along several dimensions. Ambiguity about whether AI systems are trustworthy can discourage deployment in some contexts where the technology could be beneficial, and make it more likely when it's dangerous. Public transparency alone cannot close this gap: many safety- and security-relevant details are legitimately confidential and require expert interpretation. We define frontier AI auditing as rigorous third-party verification of frontier AI developers' safety and security claims, and evaluation of their systems and practices against relevant standards, based on deep, secure access to non-public information. To make rigor legible and comparable, we introduce AI Assurance Levels (AAL-1 to AAL-4), ranging from time-bounded system audits to continuous, deception-resilient verification.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11699v2</guid></item><item><title>[cs updates on arXiv.org] Beyond Tokens: Concept-Level Training Objectives for LLMs</title><link>https://arxiv.org/abs/2601.11791</link><description>arXiv:2601.11791v2 Announce Type: replace 
Abstract: The next-token prediction (NTP) objective has been foundational in the development of modern large language models (LLMs), driving advances in fluency and generalization. However, NTP operates at the \textit{token} level, treating deviations from a single reference continuation as errors even when alternative continuations are equally plausible or semantically equivalent (e.g., ``mom'' vs. ``mother''). As a result, token-level loss can penalize valid abstractions, paraphrases, or conceptually correct reasoning paths, biasing models toward surface form rather than underlying meaning. This mismatch between the training signal and semantic correctness motivates learning objectives that operate over higher-level representations. We propose a shift from token-level to concept-level prediction, where concepts group multiple surface forms of the same idea (e.g., ``mom,'' ``mommy,'' ``mother'' $\rightarrow$ \textit{MOTHER}). We introduce various methods for integrating conceptual supervision into LLM training and show that concept-aware models achieve lower perplexity, improved robustness under domain shift, and stronger performance than NTP-based models on diverse NLP benchmarks. This suggests \textit{concept-level supervision} as an improved training signal that better aligns LLMs with human semantic abstractions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11791v2</guid></item><item><title>[cs updates on arXiv.org] Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation</title><link>https://arxiv.org/abs/2601.12061</link><description>arXiv:2601.12061v2 Announce Type: replace 
Abstract: Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12061v2</guid></item><item><title>[cs updates on arXiv.org] Many Hands Make Light Work: An LLM-based Multi-Agent System for Detecting Malicious PyPI Packages</title><link>https://arxiv.org/abs/2601.12148</link><description>arXiv:2601.12148v2 Announce Type: replace 
Abstract: Malicious code in open-source repositories such as PyPI poses a growing threat to software supply chains. Traditional rule-based tools often overlook the semantic patterns in source code that are crucial for identifying adversarial components. Large language models (LLMs) show promise for software analysis, yet their use in interpretable and modular security pipelines remains limited. This paper presents LAMPS, a multi-agent system that employs collaborative LLMs to detect malicious PyPI packages. The system consists of four role-specific agents for package retrieval, file extraction, classification, and verdict aggregation, coordinated through the CrewAI framework. A prototype combines a fine-tuned CodeBERT model for classification with LLaMA-3 agents for contextual reasoning. LAMPS has been evaluated on two complementary datasets: D1, a balanced collection of 6,000 setup.py files, and D2, a realistic multi-file dataset with 1,296 files and natural class imbalance. On D1, LAMPS achieves 97.7% accuracy, surpassing MPHunter--one of the state-of-the-art approaches. On D2, it reaches 99.5% accuracy and 99.5% balanced accuracy, outperforming RAG-based approaches and fine-tuned single-agent baselines. McNemar's test confirmed these improvements as highly significant. The results demonstrate the feasibility of distributed LLM reasoning for malicious code detection and highlight the benefits of modular multi-agent designs in software supply chain security.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12148v2</guid></item><item><title>[cs updates on arXiv.org] Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty</title><link>https://arxiv.org/abs/2601.12471</link><description>arXiv:2601.12471v2 Announce Type: replace 
Abstract: Current evaluation of large language models (LLMs) overwhelmingly prioritizes accuracy; however, in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. We introduce MedAbstain, a unified benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA) -- a discrete-choice setting that generalizes to agentic action selection -- integrating conformal prediction, adversarial question perturbations, and explicit abstention options. Our systematic evaluation of both open- and closed-source LLMs reveals that even state-of-the-art, high-accuracy models often fail to abstain with uncertain. Notably, providing explicit abstention options consistently increases model uncertainty and safer abstention, far more than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the central role of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12471v2</guid></item><item><title>[cs updates on arXiv.org] Efficient Code Analysis via Graph-Guided Large Language Models</title><link>https://arxiv.org/abs/2601.12890</link><description>arXiv:2601.12890v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have significantly advanced code analysis tasks, yet they struggle to detect malicious behaviors fragmented across files, whose intricate dependencies easily get lost in the vast amount of benign code. We therefore propose a graph-centric attention acquisition pipeline that enhances LLMs' ability to localize malicious behavior. The approach parses a project into a code graph, uses an LLM to encode nodes with semantic and structural signals, and trains a Graph Neural Network (GNN) under sparse supervision. The GNN performs an initial detection, and by interpreting these predictions, identifies key code sections that are most likely to contain malicious behavior. These influential regions are then used to guide the LLM's attention for in-depth analysis. This strategy significantly reduces interference from irrelevant context while maintaining low annotation costs. Extensive experiments show that the method consistently outperforms existing approaches on multiple public and custom datasets, highlighting its potential for practical deployment in software security scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12890v2</guid></item><item><title>[cs updates on arXiv.org] Dependently-Typed AARA: A Non-Affine Approach for Resource Analysis of Higher-Order Programs</title><link>https://arxiv.org/abs/2601.12943</link><description>arXiv:2601.12943v2 Announce Type: replace 
Abstract: Static resource analysis determines the resource consumption (e.g., time complexity) of a program without executing it. Among the numerous existing approaches for resource analysis, affine type systems have been one dominant approach. However, these affine type systems fall short of deriving precise resource behavior of higher-order programs, particularly in cases that involve partial applications.
  This article presents \lambda_\ms{amor}^\ms{na}}, a non-affine AARA-style dependent type system for resource reasoning about higher-order functional programs. The key observation is that the main issue in previous approaches comes from (i) the close coupling of types and resources, and (ii) the conflict between affine and higher-order typing mechanisms. To derive precise resource behavior of higher-order functions, \lambda_\ms{amor}^\ms{na}} decouples resources from types and follows a non-affine typing mechanism. The non-affine type system of \lambda_\ms{amor}^\ms{na}} achieves this by using dependent types, which allows expressing type-level potential functions separate from ordinary types. This article formalizes \lambda_\ms{amor}^\ms{na}}'s syntax and semantics, and proves its soundness, which guarantees the correctness of resource bounds. Several challenging classic and higher-order examples are presented to demonstrate the expressiveness and compositionality of \lambda_\ms{amor}^\ms{na}}'s reasoning capability.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12943v2</guid></item><item><title>[cs updates on arXiv.org] StyMam: A Mamba-Based Generator for Artistic Style Transfer</title><link>https://arxiv.org/abs/2601.12954</link><description>arXiv:2601.12954v2 Announce Type: replace 
Abstract: Image style transfer aims to integrate the visual patterns of a specific artistic style into a content image while preserving its content structure. Existing methods mainly rely on the generative adversarial network (GAN) or stable diffusion (SD). GAN-based approaches using CNNs or Transformers struggle to jointly capture local and global dependencies, leading to artifacts and disharmonious patterns. SD-based methods reduce such issues but often fail to preserve content structures and suffer from slow inference. To address these issues, we revisit GAN and propose a mamba-based generator, termed as StyMam, to produce high-quality stylized images without introducing artifacts and disharmonious patterns. Specifically, we introduce a mamba-based generator with a residual dual-path strip scanning mechanism and a channel-reweighted spatial attention module. The former efficiently captures local texture features, while the latter models global dependencies. Finally, extensive qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art algorithms in both quality and speed.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12954v2</guid></item><item><title>[cs updates on arXiv.org] Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains</title><link>https://arxiv.org/abs/2601.13137</link><description>arXiv:2601.13137v2 Announce Type: replace 
Abstract: With the wide application of large language models (LLMs), the problems of bias and value inconsistency in sensitive domains have gradually emerged, especially in terms of race, society and politics. In this paper, we propose an adversarial alignment framework, which enhances the value consistency of the model in sensitive domains through continued pre-training, instruction fine-tuning and adversarial training. In adversarial training, we use the Attacker to generate controversial queries, the Actor to generate responses with value consistency, and the Critic to filter and ensure response quality. Furthermore, we train a Value-Consistent Large Language Model, VC-LLM, for sensitive domains, and construct a bilingual evaluation dataset in Chinese and English. The experimental results show that VC-LLM performs better than the existing mainstream models in both Chinese and English tests, verifying the effectiveness of the method. Warning: This paper contains examples of LLMs that are offensive or harmful in nature.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.13137v2</guid></item><item><title>[cs updates on arXiv.org] Deep Neural networks for solving high-dimensional parabolic partial differential equations</title><link>https://arxiv.org/abs/2601.13256</link><description>arXiv:2601.13256v2 Announce Type: replace 
Abstract: The numerical solution of high dimensional partial differential equations (PDEs) is severely constrained by the curse of dimensionality (CoD), rendering classical grid--based methods impractical beyond a few dimensions. In recent years, deep neural networks have emerged as a promising mesh free alternative, enabling the approximation of PDE solutions in tens to thousands of dimensions. This review provides a tutorial--oriented introduction to neural--network--based methods for solving high dimensional parabolic PDEs, emphasizing conceptual clarity and methodological connections. We organize the literature around three unifying paradigms: (i) PDE residual--based approaches, including physicsinformed neural networks and their high dimensional variants; (ii) stochastic methods derived from Feynman--Kac and backward stochastic differential equation formulations; and (iii) hybrid derivative--free random difference approaches designed to alleviate the computational cost of derivatives in high dimensions. For each paradigm, we outline the underlying mathematical formulation, algorithmic implementation, and practical strengths and limitations. Representative benchmark problems--including Hamilton--Jacobi--Bellman and Black--Scholes equations in up to 1000 dimensions --illustrate the scalability, effectiveness, and accuracy of the methods. The paper concludes with a discussion of open challenges and future directions for reliable and scalable solvers of high dimensional PDEs.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.13256v2</guid></item><item><title>[cs updates on arXiv.org] GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models</title><link>https://arxiv.org/abs/2601.13524</link><description>arXiv:2601.13524v2 Announce Type: replace 
Abstract: Existing image-based virtual try-on (VTON) methods primarily focus on single-layer or multi-garment VTON, neglecting multi-layer VTON (ML-VTON), which involves dressing multiple layers of garments onto the human body with realistic deformation and layering to generate visually plausible outcomes. The main challenge lies in accurately modeling occlusion relationships between inner and outer garments to reduce interference from redundant inner garment features. To address this, we propose GO-MLVTON, the first multi-layer VTON method, introducing the Garment Occlusion Learning module to learn occlusion relationships and the StableDiffusion-based Garment Morphing &amp; Fitting module to deform and fit garments onto the human body, producing high-quality multi-layer try-on results. Additionally, we present the MLG dataset for this task and propose a new metric named Layered Appearance Coherence Difference (LACD) for evaluation. Extensive experiments demonstrate the state-of-the-art performance of GO-MLVTON. Project page: https://upyuyang.github.io/go-mlvton/.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.13524v2</guid></item><item><title>[cs updates on arXiv.org] TruthTensor: Evaluating LLMs through Human Imitation on Prediction Market under Drift and Holistic Reasoning</title><link>https://arxiv.org/abs/2601.13545</link><description>arXiv:2601.13545v2 Announce Type: replace 
Abstract: Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures reasoning models not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.13545v2</guid></item><item><title>[cs updates on arXiv.org] Who Benefits From Sinus Surgery? Comparing Generative AI and Supervised Machine Learning for Predicting Surgical Outcomes in Chronic Rhinosinusitis</title><link>https://arxiv.org/abs/2601.13710</link><description>arXiv:2601.13710v2 Announce Type: replace 
Abstract: Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.13710v2</guid></item><item><title>[cs updates on arXiv.org] Integrated Sensing and Communication for Low-Altitude Security</title><link>https://arxiv.org/abs/2601.13810</link><description>arXiv:2601.13810v2 Announce Type: replace 
Abstract: The dense concentration of low-altitude, slow-speed, and small-size targets in the complex low-altitude environment poses significant security challenges, including failures in continuous wide-area sensing and ambiguous target intent, which existing regulatory frameworks struggle to address. Integrated sensing and communication (ISAC), a hallmark of next-generation mobile communication, offers a transformative approach to low-altitude security governance. By leveraging existing cellular infrastructure and spectrum resources, ISAC enables the construction of a seamless wide-area sensing network, supports intelligent feature extraction and intent inference, facilitates real-time collaborative decision-making, and establishes a dynamic trust authentication framework. This article systematically reviews the technical system, analyzes the security challenges, forecasts the enabling value of ISAC, and discusses the resulting open problems and challenges, thereby laying a foundation for future research and industrial implementation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.13810v2</guid></item><item><title>[cs updates on arXiv.org] RepoGenesis: Benchmarking End-to-End Microservice Generation from Readme to Repository</title><link>https://arxiv.org/abs/2601.13943</link><description>arXiv:2601.13943v2 Announce Type: replace 
Abstract: Large language models and agents have achieved remarkable progress in code generation. However, existing benchmarks focus on isolated function/class-level generation (e.g., ClassEval) or modifications to existing codebases (e.g., SWE-Bench), neglecting complete microservice repository generation that reflects real-world 0-to-1 development workflows. To bridge this gap, we introduce RepoGenesis, the first multilingual benchmark for repository-level end-to-end web microservice generation, comprising 106 repositories (60 Python, 46 Java) across 18 domains and 11 frameworks, with 1,258 API endpoints and 2,335 test cases verified through a "review-rebuttal" quality assurance process. We evaluate open-source agents (e.g., DeepCode) and commercial IDEs (e.g., Cursor) using Pass@1, API Coverage (AC), and Deployment Success Rate (DSR). Results reveal that despite high AC (up to 73.91%) and DSR (up to 100%), the best-performing system achieves only 23.67% Pass@1 on Python and 21.45% on Java, exposing deficiencies in architectural coherence, dependency management, and cross-file consistency. Notably, GenesisAgent-8B, fine-tuned on RepoGenesis (train), achieves performance comparable to GPT-5 mini, demonstrating the quality of RepoGenesis for advancing microservice generation. We release our benchmark at https://github.com/microsoft/DKI_LLM/tree/main/RepoGenesis.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.13943v2</guid></item><item><title>[cs updates on arXiv.org] Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models</title><link>https://arxiv.org/abs/2601.14004</link><description>arXiv:2601.14004v2 Announce Type: replace 
Abstract: Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: "Locate, Steer, and Improve." We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14004v2</guid></item><item><title>[cs updates on arXiv.org] Identification capacity and rate-query tradeoffs in classification systems</title><link>https://arxiv.org/abs/2601.14252</link><description>arXiv:2601.14252v2 Announce Type: replace 
Abstract: We extend classical rate-distortion theory to a discrete classification setting with three resources: tag rate $L$ (bits of storage per entity), identification cost $W$ (queries to determine class membership), and distortion $D$ (misidentification probability). We prove an information barrier: when distinct classes share identical attribute profiles (i.e., the attribute-profile map $\pi$ is not injective on classes), zero-error identification from attribute queries alone is impossible. We characterize the unique Pareto-optimal zero-error point in the $(L,W,D)$ tradeoff space: a nominal tag of length $L=\lceil\log_2 k\rceil$ bits for $k$ classes yields $W=O(1)$ and $D=0$. Without tags ($L=0$), zero-error identification requires $W=\Omega(d)$ attribute queries, where $d$ is the distinguishing dimension; in the worst case $d=n$ (the ambient attribute count), giving $W=\Omega(n)$. In the presence of attribute collisions, any tag-free scheme incurs $D&gt;0$. Conversely, in any information-barrier domain, any scheme achieving $D=0$ requires $L\ge \log_2 k$ bits; this is tight. We show minimal sufficient query sets form the bases of a matroid, so the distinguishing dimension is well-defined, connecting to zero-error source coding via graph entropy. We instantiate the theory to type systems, databases, and biological taxonomy. All results are machine-checked in Lean 4 (6000+ lines, 0 sorry).</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14252v2</guid></item><item><title>[cs updates on arXiv.org] Control Occupation Kernel Regression for Nonlinear Control-Affine Systems</title><link>https://arxiv.org/abs/2106.00103</link><description>arXiv:2106.00103v2 Announce Type: replace-cross 
Abstract: This manuscript presents an algorithm for obtaining an approximation of a nonlinear high order control affine dynamical system. Controlled trajectories of the system are leveraged as the central unit of information via embedding them in vector-valued reproducing kernel Hilbert space (vvRKHS). The trajectories are embedded as the so-called higher order control occupation kernels which represent an operator on the vvRKHS corresponding to iterated integration after multiplication by a given controller. The solution to the system identification problem is then the unique solution of an infinite dimensional regularized regression problem. The representer theorem is then used to express the solution as finite linear combination of these occupation kernels, which converts an infinite dimensional optimization problem to a finite dimensional optimization problem. The vector valued structure of the Hilbert space allows for simultaneous approximation of the drift and control effectiveness components of the control affine system. Several experiments are performed to demonstrate the effectiveness of the developed approach.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2106.00103v2</guid></item><item><title>[cs updates on arXiv.org] From Text to Image: Exploring GPT-4Vision's Potential in Advanced Radiological Analysis across Subspecialties</title><link>https://arxiv.org/abs/2311.14777</link><description>arXiv:2311.14777v2 Announce Type: replace-cross 
Abstract: The study evaluates and compares GPT-4 and GPT-4Vision for radiological tasks, suggesting GPT-4Vision may recognize radiological features from images, thereby enhancing its diagnostic potential over text-based descriptions.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2311.14777v2</guid></item><item><title>[cs updates on arXiv.org] Totally symmetric Grassmannian codes</title><link>https://arxiv.org/abs/2406.19542</link><description>arXiv:2406.19542v2 Announce Type: replace-cross 
Abstract: We introduce a general technique to construct tight fusion frames with prescribed symmetries. Applying this technique with a prescription for "all the symmetries", we construct a new family of equi-isoclinic tight fusion frames (EITFFs), which consequently form optimal Grassmannian codes. By virtue of their construction, our EITFFs have the remarkable property of total symmetry: any permutation of subspaces can be achieved by an appropriate unitary.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2406.19542v2</guid></item><item><title>[cs updates on arXiv.org] Integer programs with nearly totally unimodular matrices: the cographic case</title><link>https://arxiv.org/abs/2407.09477</link><description>arXiv:2407.09477v2 Announce Type: replace-cross 
Abstract: It is a notorious open question whether integer programs (IPs), with an integer coefficient matrix $M$ whose subdeterminants are all bounded by a constant $\Delta$ in absolute value, can be solved in polynomial time. We answer this question in the affirmative if we further require that, by removing a constant number of rows and columns from $M$, one obtains a submatrix $A$ that is the transpose of a network matrix.
  Our approach focuses on the case where $A$ arises from $M$ after removing $k$ rows only, where $k$ is a constant. We achieve our result in two main steps, the first related to the theory of IPs and the second related to graph minor theory.
  First, we derive a strong proximity result for the case where $A$ is a general totally unimodular matrix: Given an optimal solution of the linear programming relaxation, an optimal solution to the IP can be obtained by finding a constant number of augmentations by circuits of $[A\; I]$.
  Second, for the case where $A$ is transpose of a network matrix, we reformulate the problem as a maximum constrained integer potential problem on a graph $G$. We observe that if $G$ is $2$-connected, then it has no rooted $K_{2,t}$-minor for $t = \Omega(k \Delta)$. We leverage this to obtain a tree-decomposition of $G$ into highly structured graphs for which we can solve the problem locally. This allows us to solve the global problem via dynamic programming.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2407.09477v2</guid></item><item><title>[cs updates on arXiv.org] Beyond Fixed Horizons: A Theoretical Framework for Adaptive Denoising Diffusions</title><link>https://arxiv.org/abs/2501.19373</link><description>arXiv:2501.19373v2 Announce Type: replace-cross 
Abstract: We introduce a new class of generative diffusion models that, unlike conventional denoising diffusion models, achieve a time-homogeneous structure for both the noising and denoising processes, allowing the number of steps to adaptively adjust based on the noise level. This is accomplished by conditioning the forward process using Doob's $h$-transform, which terminates the process at a suitable sampling distribution at a random time. The model is particularly well suited for generating data with lower intrinsic dimensions, as the termination criterion simplifies to a first-hitting rule. A key feature of the model is its adaptability to the target data, enabling a variety of downstream tasks using a pre-trained unconditional generative model. These tasks include natural conditioning through appropriate initialisation of the denoising process and classification of noisy data.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2501.19373v2</guid></item><item><title>[cs updates on arXiv.org] Modelling the Effects of Hearing Loss on Neural Coding in the Auditory Midbrain with Variational Conditioning</title><link>https://arxiv.org/abs/2506.03088</link><description>arXiv:2506.03088v2 Announce Type: replace-cross 
Abstract: The mapping from sound to neural activity that underlies hearing is highly non-linear. The first few stages of this mapping in the cochlea have been modelled successfully, with biophysical models built by hand and, more recently, with DNN models trained on datasets simulated by biophysical models. Modelling the auditory brain has been a challenge because central auditory processing is too complex for models to be built by hand, and datasets for training DNN models directly have not been available. Recent work has taken advantage of large-scale high resolution neural recordings from the auditory midbrain to build a DNN model of normal hearing with great success. But this model assumes that auditory processing is the same in all brains, and therefore it cannot capture the widely varying effects of hearing loss.
  We propose a novel variational-conditional model to learn to encode the space of hearing loss directly from recordings of neural activity in the auditory midbrain of healthy and noise exposed animals. With hearing loss parametrised by only 6 free parameters per animal, our model accurately predicts 62% of the explainable variance in neural responses from normal hearing animals and 68% for hearing impaired animals, within a few percentage points of state of the art animal specific models. We demonstrate that the model can be used to simulate realistic activity from out of sample animals by fitting only the learned conditioning parameters with Bayesian optimisation, achieving crossentropy loss within 2% of the optimum in 15-30 iterations. Including more animals in the training data slightly improved the performance on unseen animals. This model will enable future development of parametrised hearing loss compensation models trained to directly restore normal neural coding in hearing impaired brains, which can be quickly fitted for a new user by human in the loop optimisation.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.03088v2</guid></item><item><title>[cs updates on arXiv.org] Thinning to improve two-sample discrepancy</title><link>https://arxiv.org/abs/2506.20932</link><description>arXiv:2506.20932v2 Announce Type: replace-cross 
Abstract: The discrepancy between two independent samples \(X_1,\dots,X_n\) and \(Y_1,\dots,Y_n\) drawn from the same distribution on $\mathbb{R}^d$ typically has order \(O(\sqrt{n})\) even in one dimension. We give a simple online algorithm that reduces the discrepancy to \(O(\log^{2d} n)\) by discarding a small fraction of the points.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.20932v2</guid></item><item><title>[cs updates on arXiv.org] Distance-Domain Degrees of Freedom in Near-Field Region</title><link>https://arxiv.org/abs/2507.01227</link><description>arXiv:2507.01227v3 Announce Type: replace-cross 
Abstract: Extremely large aperture arrays operating in the near-field regime unlock additional spatial resources, which can be exploited to simultaneously serve multiple users even when they share the same angular direction. This work investigates the distance-domain degrees of freedom (DoF), defined as the DoF when a user varies only its distance to the base station and not the angle. To obtain the distance-domain DoF, we study a line-of-sight (LoS) channel with a source representing a base station and an observation region representing users, where the source is a large two-dimensional transmit (Tx) array with arbitrary shape and the observation region is an arbitrarily long linear receive (Rx) array with collinearly aligned elements located at different distances from the Tx array. We assume that both the Tx and Rx arrays have continuous apertures with an infinite number of elements and infinitesimal spacing, which establishes an upper bound for the distance-domain DoF in the case of a finite number of elements. First, we analyze an ideal case where the Tx array is a single piece and the Rx array is on the broadside of the Tx array. By reformulating the channel as an integral operator with a Hermitian convolution kernel, we derive a closed-form expression for the distance-domain DoF via the Fourier transform. Our analysis shows that the distance-domain DoF is predominantly determined by the extreme boundaries of both the Tx and Rx arrays rather than their detailed interior structure. We further extend the framework to non-broadside configurations by employing a projection method that converts the problem to an equivalent broadside case. Finally, we extend the analytical framework to modular arrays and show the distance-domain DoF gain over a single-piece array under a fixed total physical length.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.01227v3</guid></item><item><title>[cs updates on arXiv.org] Dynamical stability for dense patterns in discrete attractor neural networks</title><link>https://arxiv.org/abs/2507.10383</link><description>arXiv:2507.10383v4 Announce Type: replace-cross 
Abstract: Neural networks storing multiple discrete attractors are canonical models of biological memory. Previously, the dynamical stability of such networks could only be guaranteed under highly restrictive conditions. Here, we derive a theory of the local stability of discrete fixed points in a broad class of networks with graded neural activities and in the presence of noise. By directly analyzing the bulk and the outliers of the Jacobian spectrum, we show that all fixed points are stable below a critical load that is distinct from the classical \textit{critical capacity} and depends on the statistics of neural activities in the fixed points as well as the single-neuron activation function. Our analysis highlights the computational benefits of threshold-linear activation and sparse-like patterns.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.10383v4</guid></item><item><title>[cs updates on arXiv.org] Likelihood Matching for Diffusion Models</title><link>https://arxiv.org/abs/2508.03636</link><description>arXiv:2508.03636v2 Announce Type: replace-cross 
Abstract: We propose a Likelihood Matching approach for training diffusion models by first establishing an equivalence between the likelihood of the target data distribution and a likelihood along the sample path of the reverse diffusion. To efficiently compute the reverse sample likelihood, a quasi-likelihood is considered to approximate each reverse transition density by a Gaussian distribution with matched conditional mean and covariance, respectively. The score and Hessian functions for the diffusion generation are estimated by maximizing the quasi-likelihood, ensuring a consistent matching of both the first two transitional moments between every two time points. A stochastic sampler is introduced to facilitate computation that leverages both the estimated score and Hessian information. We establish consistency of the quasi-maximum likelihood estimation, and provide non-asymptotic convergence guarantees for the proposed sampler, quantifying the rates of the approximation errors due to the score and Hessian estimation, dimensionality, and the number of diffusion steps. Empirical and simulation evaluations demonstrate the effectiveness of the proposed Likelihood Matching and validate the theoretical results.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.03636v2</guid></item><item><title>[cs updates on arXiv.org] Implementing Optimal Taxation: A Constrained Optimization Framework for Tax Reform</title><link>https://arxiv.org/abs/2508.03708</link><description>arXiv:2508.03708v3 Announce Type: replace-cross 
Abstract: While optimal taxation theory provides clear prescriptions for tax design, translating these insights into actual tax codes remains difficult. Existing work largely offers theoretical characterizations of optimal systems, while practical implementation methods are scarce. Bridging this gap involves designing tax rules that meet theoretical goals, while accommodating administrative, distributional, and other practical constraints that arise in real-world reform. We develop a method casting tax reform as a constrained optimization problem by parametrizing the entire income tax code as a set of piecewise linear functions mapping tax-relevant inputs into liabilities and marginal rates. This allows users to impose constraints on marginal rate schedules, limits on income swings, and objectives like revenue neutrality, efficiency, simplicity, or distributional fairness that reflect both theoretical and practical considerations. The framework is computationally tractable for complex tax codes and flexible enough to accommodate diverse constraints, welfare objectives and behavioral responses. Whereas existing tools are typically used for ex-post `what-if' analysis of specific reforms, our framework explicitly incorporates real-world reform constraints and jointly optimizes across the full tax code. We illustrate the framework in several simulated settings, including a detailed reconstruction of the Dutch income tax system. For the Dutch case, we generate a family of reforms that smooth existing spikes in marginal tax rates to any desired cap, reduce the number of rules, and impose hard caps on income losses households can experience from the reform. We also introduce \texttt{TaxSolver}, an open-source package, allowing policymakers and researchers to implement and extend the framework.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.03708v3</guid></item><item><title>[cs updates on arXiv.org] Can LLMs Identify Tax Abuse?</title><link>https://arxiv.org/abs/2508.20097</link><description>arXiv:2508.20097v2 Announce Type: replace-cross 
Abstract: We investigate whether large language models can discover and analyze U.S. tax-minimization strategies. This real-world domain challenges even seasoned human experts, and progress can reduce tax revenue lost from well-advised, wealthy taxpayers. We evaluate the most advanced LLMs on their ability to (1) interpret and verify tax strategies, (2) fill in gaps in partially specified strategies, and (3) generate complete, end-to-end strategies from scratch. This domain should be of particular interest to the LLM reasoning community: unlike synthetic challenge problems or scientific reasoning tasks, U.S. tax law involves navigating hundreds of thousands of pages of statutes, case law, and administrative guidance, all updated regularly. Notably, LLM-based reasoning identified an entirely novel tax strategy, highlighting these models' potential to revolutionize tax agencies' fight against tax abuse.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.20097v2</guid></item><item><title>[cs updates on arXiv.org] Attentive AV-FusionNet: Audio-Visual Quality Prediction with Hybrid Attention</title><link>https://arxiv.org/abs/2509.16994</link><description>arXiv:2509.16994v2 Announce Type: replace-cross 
Abstract: We introduce a novel deep learning-based audio-visual quality (AVQ) prediction model that leverages internal features from state-of-the-art unimodal predictors. Unlike prior approaches that rely on simple fusion strategies, our model employs a hybrid representation that combines learned Generative Machine Listener (GML) audio features with hand-crafted Video Multimethod Assessment Fusion (VMAF) video features. Attention mechanisms capture cross-modal interactions and intra-modal relationships, yielding context-aware quality representations. A modality relevance estimator quantifies each modality's contribution per content, potentially enabling adaptive bitrate allocation. Experiments demonstrate improved AVQ prediction accuracy and robustness across diverse content types.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.16994v2</guid></item><item><title>[cs updates on arXiv.org] An Efficient Quality Metric for Video Frame Interpolation Based on Motion-Field Divergence</title><link>https://arxiv.org/abs/2510.01361</link><description>arXiv:2510.01361v2 Announce Type: replace-cross 
Abstract: Video frame interpolation is a fundamental tool for temporal video enhancement, but existing quality metrics struggle to evaluate the perceptual impact of interpolation artefacts effectively. Metrics like PSNR, SSIM and LPIPS ignore temporal coherence. State-of-the-art quality metrics tailored towards video frame interpolation, like FloLPIPS, have been developed but suffer from computational inefficiency that limits their practical application. We present $\text{PSNR}_{\text{DIV}}$, a novel full-reference quality metric that enhances PSNR through motion divergence weighting, a technique adapted from archival film restoration where it was developed to detect temporal inconsistencies. Our approach highlights singularities in motion fields which is then used to weight image errors. Evaluation on the BVI-VFI dataset (180 sequences across multiple frame rates, resolutions and interpolation methods) shows $\text{PSNR}_{\text{DIV}}$ achieves statistically significant improvements: +0.09 Pearson Linear Correlation Coefficient over FloLPIPS, while being 2.5$\times$ faster and using 4$\times$ less memory. Performance remains consistent across all content categories and are robust to the motion estimator used. The efficiency and accuracy of $\text{PSNR}_{\text{DIV}}$ enables fast quality evaluation and practical use as a loss function for training neural networks for video frame interpolation tasks. An implementation of our metric is available at www.github.com/conalld/psnr-div.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.01361v2</guid></item><item><title>[cs updates on arXiv.org] AtomWorld: A Benchmark for Evaluating Spatial Reasoning in Large Language Models on Crystalline Materials</title><link>https://arxiv.org/abs/2510.04704</link><description>arXiv:2510.04704v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) excel at textual reasoning and are beginning to develop spatial understanding, prompting the question of whether these abilities can be combined for complex, domain-specific tasks. This question is essential in fields like materials science, where deep understanding of 3D atomic structures is fundamental. While initial studies have successfully applied LLMs to tasks involving pure crystal generation or coordinate understandings, a standardized benchmark to systematically evaluate their core reasoning abilities across diverse atomic structures has been notably absent. To address this gap, we introduce the AtomWorld benchmark to evaluate LLMs on tasks based in Crystallographic Information Files (CIFs), a standard structure representation format. These tasks, including structural editing, CIF perception, and property-guided modeling, reveal a critical limitation: current models, despite establishing promising baselines, consistently fail in structural understanding and spatial reasoning. Our experiments show that these models make frequent errors on structure modification tasks, and even in the basic CIF format understandings, potentially leading to cumulative errors in subsequent analysis and materials insights. By defining these standardized tasks, AtomWorld lays the ground for advancing LLMs toward robust atomic-scale modeling, crucial for accelerating materials research and automating scientific workflows.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.04704v3</guid></item><item><title>[cs updates on arXiv.org] Quantum matrix arithmetics with Hamiltonian evolution</title><link>https://arxiv.org/abs/2510.06316</link><description>arXiv:2510.06316v2 Announce Type: replace-cross 
Abstract: The efficient implementation of matrix arithmetic operations underpins the speedups of many quantum algorithms. We develop a suite of methods to perform matrix arithmetics -- with the result encoded in the off-diagonal blocks of a Hamiltonian -- using Hamiltonian evolutions of input operators. We show how to maintain this $\textit{Hamiltonian block encoding}$, so that matrix operations can be composed one after another, and the entire quantum computation takes $\leq 2$ ancilla qubits. We achieve this for matrix multiplication, matrix addition, matrix inversion, Hermitian conjugation, fractional scaling, integer scaling, complex phase scaling, as well as singular value transformation for both odd and even polynomials. We also present an overlap estimation algorithm to extract classical properties of Hamiltonian block encoded operators, analogous to the well known Hadmard test, at no extra cost of qubit. Our Hamiltonian matrix multiplication uses the Lie group commutator product formula and its higher-order generalizations due to Childs and Wiebe. Our Hamiltonian singular value transformation employs a dominated polynomial approximation, where the approximation holds within the domain of interest, while the constructed polynomial is upper bounded by the target function over the entire unit interval. We describe a circuit for simulating a class of sum-of-squares Hamiltonians, attaining a commutator scaling in step count, while leveraging the power of matrix arithmetics to reduce the cost of each simulation step. In particular, we apply this to the doubly factorized tensor hypercontracted Hamiltonians from recent studies of quantum chemistry, obtaining further improvements for initial states with a fixed number of particles. We achieve this with $1$ ancilla qubit.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.06316v2</guid></item><item><title>[cs updates on arXiv.org] Quantization-Based Score Calibration for Few-Shot Keyword Spotting with Dynamic Time Warping in Noisy Environments</title><link>https://arxiv.org/abs/2510.15432</link><description>arXiv:2510.15432v2 Announce Type: replace-cross 
Abstract: Detecting occurrences of keywords with keyword spotting (KWS) systems requires thresholding continuous detection scores. Selecting appropriate thresholds is a non-trivial task, typically relying on optimizing performance on a validation dataset. However, such greedy threshold selection often leads to suboptimal performance on unseen data, particularly in varying or noisy acoustic environments or few-shot settings. In this work, we investigate detection threshold estimation for template-based open-set few-shot KWS using dynamic time warping on noisy speech data. To mitigate the performance degradation caused by suboptimal thresholds, we propose a score calibration approach that operates at the embedding level by quantizing learned representations and applying quantization error-based normalization prior to DTW-based scoring and thresholding. Experiments on KWS-DailyTalk with simulated high frequency radio channels show that the proposed calibration approach simplifies the selection of robust detection thresholds and significantly improves the resulting performance.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.15432v2</guid></item><item><title>[cs updates on arXiv.org] The Sleeping Beauty Problem: Sleeping Kelly is a Thirder</title><link>https://arxiv.org/abs/2510.15911</link><description>arXiv:2510.15911v2 Announce Type: replace-cross 
Abstract: The Sleeping Beauty problem is a problem of imperfect recall that has received considerable attention. One approach to solving the Sleeping Beauty problem is to allow Sleeping Beauty to make decisions based on her beliefs, and then characterize what it takes for her decisions to be "rational". In particular, she can be allowed to make monetary bets based on her beliefs, with the assumption that she wants to gain wealth rather than lose it. However, this approach is often coupled with the assumption that Sleeping Beauty should maximize the expected value of her bets. Here, show that Sleeping Beauty maximizes the expected growth rate of her wealth as a "thirder" sizing bets using the Kelly Criterion under multiplicative dynamics. Furthermore, this position is shown to be impervious to Dutch books. By contrast, the "halfer" position is shown to be vulnerable to Dutch books under similar circumstances.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.15911v2</guid></item><item><title>[cs updates on arXiv.org] Towards Quantum Software for Quantum Simulation</title><link>https://arxiv.org/abs/2511.13520</link><description>arXiv:2511.13520v2 Announce Type: replace-cross 
Abstract: Quantum simulation is a leading candidate for demonstrating practical quantum advantage over classical computation, as it is believed to provide exponentially more compute power than any classical system. It offers new means of studying the behaviour of complex physical systems, for which conventionally software-intensive simulation codes based on numerical high-performance computing are used. Instead, quantum simulations map properties and characteristics of subject systems, for instance chemical molecules, onto quantum devices that then mimic the system under study.
  Currently, the use of these techniques is largely limited to fundamental science, as the overall approach remains tailored for specific problems: We lack infrastructure and modelling abstractions that are provided by the software engineering community for other computational domains.
  In this paper, we identify critical gaps in the quantum simulation software stack-particularly the absence of general-purpose frameworks for model specification, Hamiltonian construction, and hardware-aware mappings. We advocate for a modular model-driven engineering (MDE) approach that supports different types of quantum simulation (digital and analogue), and facilitates automation, performance evaluation, and reusability. Through an example from high-energy physics, we outline a vision for a quantum simulation framework capable of supporting scalable, cross-platform simulation workflows.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.13520v2</guid></item><item><title>[cs updates on arXiv.org] Comparing the latent features of universal machine-learning interatomic potentials</title><link>https://arxiv.org/abs/2512.05717</link><description>arXiv:2512.05717v2 Announce Type: replace-cross 
Abstract: The past few years have seen the development of ``universal'' machine-learning interatomic potentials (uMLIPs) capable of approximating the ground-state potential energy surface across a wide range of chemical structures and compositions with reasonable accuracy. While these models differ in the architecture and the dataset used, they share the ability to compress a staggering amount of chemical information into descriptive latent features. Herein, we systematically analyze what the different uMLIPs have learned by quantitatively assessing the relative information content of their latent features with feature reconstruction errors, and observing how the trends are affected by the choice of training set and training protocol. We find that uMLIPs encode the chemical space in significantly distinct ways, with substantial cross-model feature reconstruction errors. When variants of the same model architecture are considered, trends become dependent on the dataset, target, and training protocol of choice. We also observe that fine-tuning of a uMLIP retains a strong pre-training bias in the latent features. Finally, we discuss how atom-level features, which are directly output by MLIPs, can be compressed into global structure-level features via concatenation of progressive cumulants, each adding significantly new information about the variability across the atomic environments within a given system.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.05717v2</guid></item><item><title>[cs updates on arXiv.org] TPV: Parameter Perturbations Through the Lens of Test Prediction Variance</title><link>https://arxiv.org/abs/2512.11089</link><description>arXiv:2512.11089v3 Announce Type: replace-cross 
Abstract: We identify test prediction variance (TPV)-- the first-order sensitivity of model outputs to parameter perturbations around a trained solution-- as a unifying quantity that links several classical observations about generalization in deep networks. TPV is a fully label-free object whose trace form separates the geometry of the trained model from the specific perturbation mechanism, allowing a broad family of parameter perturbations like SGD noise, label noise, finite-precision noise, and other post-training perturbations to be analyzed under a single framework.
  Theoretically, we show that TPV estimated on the training set converges to its test-set value in the overparameterized limit, providing the first result that prediction variance under local parameter perturbations can be inferred from training inputs alone, and this stability is decoupled from generalization performance. Empirically, TPV exhibits a striking stability across datasets and architectures even for extremely narrow networks. Further, TPV correlates well with test loss, serving as a training-set based predictive metric for generalization. Code available at github.com/devansharpit/TPV.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.11089v3</guid></item><item><title>[cs updates on arXiv.org] Dynamical Mechanisms for Coordinating Long-term Working Memory Based on the Precision of Spike-timing in Cortical Neurons</title><link>https://arxiv.org/abs/2512.15891</link><description>arXiv:2512.15891v3 Announce Type: replace-cross 
Abstract: In the last century, most sensorimotor studies of cortical neurons relied on average firing rates. Rate coding is efficient for fast sensorimotor processing that occurs within a few seconds. Much less is known about long-term working memory with a time scale of hours (Ericsson and Kintsch, 1995). The discovery of millisecond-precision spike initiation in cortical neurons was unexpected (Mainen and Sejnowski, 1995). Even more striking was the precision of spiking in vivo, in response to rapidly fluctuating sensory inputs, suggesting that neural circuits could preserve and manipulate sensory information through spike timing. High temporal resolution enables a broader range of neural codes. It could also support spike-timing-dependent plasticity (STDP), which is triggered by the relative timing of spikes between presynaptic and postsynaptic neurons in the millisecond range. What spike-timing mechanisms could regulate STDP in vivo? Cortical traveling waves have been observed across many frequency bands with high temporal precision. Traveling waves have wave fronts that could link spike timing to STDP. As a wave front passes through a cortical column, excitatory synapses on the dendrites of both pyramidal and basket cells are stimulated synchronously. Inhibitory basket cells form a calyx on pyramidal cell bodies, and inhibitory rebound following a strong transient hyperpolarization can trigger a backpropagating action potential, which arrives shortly after the excitatory inputs on pyramidal dendrites. STDP activated in this way could persist for hours, creating a second-tier network. This temporary network could support long-term working memory, a cognitive network riding above the long-term sensorimotor network. On their own, traveling waves and STDP have not yet yielded new insights into cortical function. Together, they could be responsible for how we think (Sejnowski, 2025).</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.15891v3</guid></item><item><title>[cs updates on arXiv.org] Conformal Blindness: A Note on $A$-Cryptic change-points</title><link>https://arxiv.org/abs/2601.01147</link><description>arXiv:2601.01147v2 Announce Type: replace-cross 
Abstract: Conformal Test Martingales (CTMs) are a standard method within the Conformal Prediction framework for testing the crucial assumption of data exchangeability by monitoring deviations from uniformity in the p-value sequence. Although exchangeability implies uniform p-values, the converse does not hold. This raises the question of whether a significant break in exchangeability can occur, such that the p-values remain uniform, rendering CTMs blind. We answer this affirmatively, demonstrating the phenomenon of \emph{conformal blindness}.
  Through explicit construction, for the theoretically ideal ``predictive oracle'' conformity measure (given by the true conditional density), we demonstrate the possibility of an \emph{$A$-cryptic change-point} (where $A$ refers to the conformity measure). Using bivariate Gaussian distributions, we identify a line along which a change in the marginal means does not alter the distribution of the conformity scores, thereby producing perfectly uniform p-values.
  Simulations confirm that even a massive distribution shift can be perfectly cryptic to the CTM, highlighting a fundamental limitation and emphasising the critical role of the alignment of the conformity measure with potential shifts.
  By contrasting the predictive oracle with recent results on detection-optimal scores, we emphasise that validity monitoring in safety-critical systems requires careful separation of predictive and diagnostic goals.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.01147v2</guid></item><item><title>[cs updates on arXiv.org] Where do We Poop? City-Wide Simulation of Defecation Behavior for Wastewater-Based Epidemiology</title><link>https://arxiv.org/abs/2601.04231</link><description>arXiv:2601.04231v2 Announce Type: replace-cross 
Abstract: Wastewater surveillance, which regularly examines the pathogen biomarkers in wastewater samples, is a valuable tool for monitoring infectious diseases circulating in communities. Yet, most wastewater-based epidemiology methods, which use wastewater surveillance results for disease inferences, implicitly assume that individuals excrete only at their residential locations and that the population contribute to wastewater samples are static. These simplifying assumptions ignore daily mobility, social interactions, and heterogeneous toilet use behavior patterns, which can lead to biased interpretation of wastewater results, especially at upstream sampling locations such as neighborhoods, institutions, or buildings. Here, we introduce an agent-based geospatial simulation framework: Building on an established Patterns of Life model, we simulate daily human activities, mobility, and social contacts within a realistic urban environment and extend this agent-based framework with a physiologically motivated defecation cycle and toilet usage patterns. We couple this behavioral model with an infectious disease model to simulate transmissions through spatial and social interactions. When a defecation occurs for an infected agent, we use a pathogen shedding model to determine the amount of pathogen shed in the feces. Such a framework, integrating population mobility, disease transmission, toilet use behavior, and pathogen shedding models, is capable to simulate the Spatial-temporal dynamics of wastewater signals for a city. Using a case study of 10,000 simulated agents in Fulton County, Georgia, we examine how varying infection rates alter epidemic trajectories, pathogen loads in wastewater, and the spatial distribution of contamination across time.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.04231v2</guid></item><item><title>[cs updates on arXiv.org] Generalization to Political Beliefs from Fine-Tuning on Sports Team Preferences</title><link>https://arxiv.org/abs/2601.04369</link><description>arXiv:2601.04369v3 Announce Type: replace-cross 
Abstract: Fine-tuned LLMs often exhibit unexpected behavior as a result of generalizing beyond the data they're shown. We present results in which an LLM fine-tuned to prefer either coastal sports teams or Southern sports teams adopt political beliefs that diverge significantly from those of the base model. While we hypothesized that the coastal model would become more liberal and the southern model would become more conservative, we find that their responses are usually similar to each other, without a clear-cut liberal or conservative bias. In addition to asking the models for numerical ratings of agreement with relevant political statements, we ask them to elaborate on their more radical answers, finding varying degrees of willingness to justify themselves. Further work is needed to understand the mechanisms by which fine-tuning on simple, narrow datasets leads to seemingly unrelated changes in model behavior.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.04369v3</guid></item><item><title>[cs updates on arXiv.org] Enhanced Climbing Image Nudged Elastic Band method with Hessian Eigenmode Alignment</title><link>https://arxiv.org/abs/2601.12630</link><description>arXiv:2601.12630v2 Announce Type: replace-cross 
Abstract: Accurate determination of transition states is central to an understanding of reaction kinetics. Double-endpoint methods where both initial and final states are specified, such as the climbing image nudged elastic band (CI-NEB), identify the minimum energy path between the two and thereby the saddle point on the energy surface that is relevant for the given transition, thus providing an estimate of the transition state within the harmonic approximation of transition state theory. Such calculations can, however, incur high computational costs and may suffer stagnation on exceptionally flat or rough energy surfaces. Conversely, methods that only require specification of an initial set of atomic coordinates, such as the minimum mode following (MMF) method, offer efficiency but can converge on saddle points that are not relevant for transition of interest. Here, we present an adaptive hybrid algorithm that integrates the CI-NEB with the MMF method so as to get faster convergence to the relevant saddle point. The method is benchmarked for the Baker-Chan (BC) saddle point test set using the PET-MAD machine-learned potential as well as 59 transitions of a heptamer island on Pt(111) from the OptBench benchmark set. A Bayesian analysis of the performance shows a median reduction in energy and force calculations of 46% [95% CrI: -55%, -37%] relative to CI-NEB for the BC set, while a 28% reduction is found for the transitions of the heptamer island. These results establish this hybrid method as a highly effective tool for high-throughput automated chemical discovery of atomic rearrangements.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12630v2</guid></item><item><title>[cs updates on arXiv.org] Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning</title><link>https://arxiv.org/abs/2601.15160</link><description>arXiv:2601.15160v1 Announce Type: cross 
Abstract: Large language models have achieved near-expert performance in structured reasoning domains like mathematics and programming, yet their ability to perform compositional multi-hop reasoning in specialized scientific fields remains limited. We propose a bottom-up learning paradigm in which models are grounded in axiomatic domain facts and compose them to solve complex, unseen tasks. To this end, we present a post-training pipeline, based on a combination of supervised fine-tuning and reinforcement learning (RL), in which knowledge graphs act as implicit reward models. By deriving novel reward signals from knowledge graph paths, we provide verifiable, scalable, and grounded supervision that encourages models to compose intermediate axioms rather than optimize only final answers during RL. We validate this approach in the medical domain, training a 14B model on short-hop reasoning paths (1-3 hops) and evaluating its zero-shot generalization to complex multi-hop queries (4-5 hops). Our experiments show that path-derived rewards act as a "compositional bridge", enabling our model to significantly outperform much larger models and frontier systems like GPT-5.2 and Gemini 3 Pro, on the most difficult reasoning tasks. Furthermore, we demonstrate the robustness of our approach to adversarial perturbations against option-shuffling stress tests. This work suggests that grounding the reasoning process in structured knowledge is a scalable and efficient path toward intelligent reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15160v1</guid></item><item><title>[cs updates on arXiv.org] LLM-based Multimodal Feedback Produces Equivalent Learning and Better Student Perceptions than Educator Feedback</title><link>https://arxiv.org/abs/2601.15280</link><description>arXiv:2601.15280v1 Announce Type: cross 
Abstract: Providing timely, targeted, and multimodal feedback helps students quickly correct errors, build deep understanding and stay motivated, yet making it at scale remains a challenge. This study introduces a real-time AI-facilitated multimodal feedback system that integrates structured textual explanations with dynamic multimedia resources, including the retrieved most relevant slide page references and streaming AI audio narration. In an online crowdsourcing experiment, we compared this system against fixed business-as-usual feedback by educators across three dimensions: (1) learning effectiveness, (2) learner engagement, (3) perceived feedback quality and value. Results showed that AI multimodal feedback achieved learning gains equivalent to original educator feedback while significantly outperforming it on perceived clarity, specificity, conciseness, motivation, satisfaction, and reducing cognitive load, with comparable correctness, trust, and acceptance. Process logs revealed distinct engagement patterns: for multiple-choice questions, educator feedback encouraged more submissions; for open-ended questions, AI-facilitated targeted suggestions lowered revision barriers and promoted iterative improvement. These findings highlight the potential of AI multimodal feedback to provide scalable, real-time, and context-aware support that both reduces instructor workload and enhances student experience.</description><author>cs updates on arXiv.org</author><pubDate>Sat, 24 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15280v1</guid></item><item><title>[cs updates on arXiv.org] GutenOCR: A Grounded Vision-Language Front-End for Documents</title><link>https://arxiv.org/abs/2601.14490</link><description>arXiv:2601.14490v2 Announce Type: new 
Abstract: GutenOCR is a family of grounded OCR front-ends obtained by fine-tuning Qwen2.5-VL-3B and Qwen2.5-VL-7B. The resulting single-checkpoint vision-language models expose reading, detection, and grounding through a unified, prompt-based interface. Trained on business documents, scientific articles, and synthetic grounding data, the models support full-page and localized reading with line- and paragraph-level bounding boxes and conditional ``where is x?'' queries. We introduce a grounded OCR evaluation protocol and show that GutenOCR-7B more than doubles the composite grounded OCR score of its Qwen2.5-VL-7B backbone on 10.5K held-out business and scientific pages (0.40 to 0.82). On Fox and OmniDocBench v1.5, our approach substantially improves region- and line-level OCR as well as text-detection recall, but reveals trade-offs in page-level linearization, color-guided OCR, and formula-heavy layouts.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14490v2</guid></item><item><title>[cs updates on arXiv.org] Structured Image-based Coding for Efficient Gaussian Splatting Compression</title><link>https://arxiv.org/abs/2601.14510</link><description>arXiv:2601.14510v2 Announce Type: new 
Abstract: Gaussian Splatting (GS) has recently emerged as a state-of-the-art representation for radiance fields, combining real-time rendering with high visual fidelity. However, GS models require storing millions of parameters, leading to large file sizes that impair their use in practical multimedia systems. To address this limitation, this paper introduces GS Image-based Compression (GSICO), a novel GS codec that efficiently compresses pre-trained GS models while preserving perceptual fidelity. The core contribution lies in a mapping procedure that arranges GS parameters into structured images, guided by a novel algorithm that enhances spatial coherence. These GS parameter images are then encoded using a conventional image codec. Experimental evaluations on Tanks and Temples, Deep Blending, and Mip-NeRF360 datasets show that GSICO achieves average compression factors of 20.2x with minimal loss in visual quality, as measured by PSNR, SSIM, and LPIPS. Compared with state-of-the-art GS compression methods, the proposed codec consistently yields superior rate-distortion (RD) trade-offs.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14510v2</guid></item><item><title>[cs updates on arXiv.org] Report for NSF Workshop on AI for Electronic Design Automation</title><link>https://arxiv.org/abs/2601.14541</link><description>arXiv:2601.14541v2 Announce Type: new 
Abstract: This report distills the discussions and recommendations from the NSF Workshop on AI for Electronic Design Automation (EDA), held on December 10, 2024 in Vancouver alongside NeurIPS 2024. Bringing together experts across machine learning and EDA, the workshop examined how AI-spanning large language models (LLMs), graph neural networks (GNNs), reinforcement learning (RL), neurosymbolic methods, etc.-can facilitate EDA and shorten design turnaround. The workshop includes four themes: (1) AI for physical synthesis and design for manufacturing (DFM), discussing challenges in physical manufacturing process and potential AI applications; (2) AI for high-level and logic-level synthesis (HLS/LLS), covering pragma insertion, program transformation, RTL code generation, etc.; (3) AI toolbox for optimization and design, discussing frontier AI developments that could potentially be applied to EDA tasks; and (4) AI for test and verification, including LLM-assisted verification tools, ML-augmented SAT solving, security/reliability challenges, etc. The report recommends NSF to foster AI/EDA collaboration, invest in foundational AI for EDA, develop robust data infrastructures, promote scalable compute infrastructure, and invest in workforce development to democratize hardware design and enable next-generation hardware systems. The workshop information can be found on the website https://ai4eda-workshop.github.io/.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14541v2</guid></item><item><title>[cs updates on arXiv.org] Scribble-Supervised Medical Image Segmentation with Dynamic Teacher Switching and Hierarchical Consistency</title><link>https://arxiv.org/abs/2601.14563</link><description>arXiv:2601.14563v2 Announce Type: new 
Abstract: Scribble-supervised methods have emerged to mitigate the prohibitive annotation burden in medical image segmentation. However, the inherent sparsity of these annotations introduces significant ambiguity, which results in noisy pseudo-label propagation and hinders the learning of robust anatomical boundaries. To address this challenge, we propose SDT-Net, a novel dual-teacher, single-student framework designed to maximize supervision quality from these weak signals. Our method features a Dynamic Teacher Switching (DTS) module to adaptively select the most reliable teacher. This selected teacher then guides the student via two synergistic mechanisms: high-confidence pseudo-labels, refined by a Pick Reliable Pixels (PRP) mechanism, and multi-level feature alignment, enforced by a Hierarchical Consistency (HiCo) module. Extensive experiments on the ACDC and MSCMRseg datasets demonstrate that SDT-Net achieves state-of-the-art performance, producing more accurate and anatomically plausible segmentation.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14563v2</guid></item><item><title>[cs updates on arXiv.org] Automatically Tightening Access Control Policies with Restricter</title><link>https://arxiv.org/abs/2601.14582</link><description>arXiv:2601.14582v2 Announce Type: new 
Abstract: Robust access control is a cornerstone of secure software, systems, and networks. An access control mechanism is as effective as the policy it enforces. However, authoring effective policies that satisfy desired properties such as the principle of least privilege is a challenging task even for experienced administrators, as evidenced by many real instances of policy misconfiguration. In this paper, we set out to address this pain point by proposing Restricter, which automatically tightens each (permit) policy rule of a policy with respect to an access log, which captures some already exercised access requests and their corresponding access decisions (i.e., allow or deny). Restricter achieves policy tightening by reducing the number of access requests permitted by a policy rule without sacrificing the functionality of the underlying system it is regulating. We implement Restricter for Amazon's Cedar policy language and demonstrate its effectiveness through two realistic case studies.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14582v2</guid></item><item><title>[cs updates on arXiv.org] An Ion-Intercalation Memristor for Enabling Full Parallel Writing in Crossbar Networks</title><link>https://arxiv.org/abs/2601.14613</link><description>arXiv:2601.14613v2 Announce Type: new 
Abstract: Crossbar architectures have long been seen as a promising foundation for in-memory computing, using memristor arrays for high-density, energy-efficient analog computation. However, this conventional architecture suffers from a fundamental limitation: the inability to perform parallel write operations due to the sneak path problem. This arises from the structural overlap of read and write paths, forcing sequential or semi-parallel updates and severely limiting scalability. To address this, we introduce a new memristor design that decouples read and write operations at the device level. This design enables orthogonal conductive paths, and employs a reversible ion doping mechanism, inspired by lithium-ion battery principles, to modulate resistance states independently of computation. Fabricated devices exhibit near-ideal memristive characteristics and stable performance under isolated read/write conditions.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14613v2</guid></item><item><title>[cs updates on arXiv.org] Gaming the Judge: Unfaithful Chain-of-Thought Can Undermine Agent Evaluation</title><link>https://arxiv.org/abs/2601.14691</link><description>arXiv:2601.14691v2 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly used as judges to evaluate agent performance, particularly in non-verifiable settings where judgments rely on agent trajectories including chain-of-thought (CoT) reasoning. This paradigm implicitly assumes that the agent's CoT faithfully reflects both its internal reasoning and the underlying environment state. We show this assumption is brittle: LLM judges are highly susceptible to manipulation of agent reasoning traces. By systematically rewriting agent CoTs while holding actions and observations fixed, we demonstrate that manipulated reasoning alone can inflate false positive rates of state-of-the-art VLM judges by up to 90% across 800 trajectories spanning diverse web tasks. We study manipulation strategies spanning style-based approaches that alter only the presentation of reasoning and content-based approaches that fabricate signals of task progress, and find that content-based manipulations are consistently more effective. We evaluate prompting-based techniques and scaling judge-time compute, which reduce but do not fully eliminate susceptibility to manipulation. Our findings reveal a fundamental vulnerability in LLM-based evaluation and highlight the need for judging mechanisms that verify reasoning claims against observable evidence.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14691v2</guid></item><item><title>[cs updates on arXiv.org] Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning</title><link>https://arxiv.org/abs/2601.14750</link><description>arXiv:2601.14750v2 Announce Type: new 
Abstract: Chain-of-Thought (CoT) prompting has achieved remarkable success in unlocking the reasoning capabilities of Large Language Models (LLMs). Although CoT prompting enhances reasoning, its verbosity imposes substantial computational overhead. Recent works often focus exclusively on outcome alignment and lack supervision on the intermediate reasoning process. These deficiencies obscure the analyzability of the latent reasoning chain. To address these challenges, we introduce Render-of-Thought (RoT), the first framework to reify the reasoning chain by rendering textual steps into images, making the latent rationale explicit and traceable. Specifically, we leverage the vision encoders of existing Vision Language Models (VLMs) as semantic anchors to align the vision embeddings with the textual space. This design ensures plug-and-play implementation without incurring additional pre-training overhead. Extensive experiments on mathematical and logical reasoning benchmarks demonstrate that our method achieves 3-4x token compression and substantial inference acceleration compared to explicit CoT. Furthermore, it maintains competitive performance against other methods, validating the feasibility of this paradigm. Our code is available at https://github.com/TencentBAC/RoT</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14750v2</guid></item><item><title>[cs updates on arXiv.org] Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models</title><link>https://arxiv.org/abs/2601.14758</link><description>arXiv:2601.14758v2 Announce Type: new 
Abstract: Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repackage autoregressive heuristics. In this work, we address this question by conducting a comparative circuit analysis of ARMs and their MDM counterparts. Our analysis reveals a systematic "mechanism shift" dependent on the structural nature of the task. Structurally, we observe a distinct divergence: while MDMs largely retain autoregressive circuitry for tasks dominated by local causal dependencies, they abandon initialized pathways for global planning tasks, exhibiting distinct rewiring characterized by increased early-layer processing. Semantically, we identify a transition from sharp, localized specialization in ARMs to distributed integration in MDMs. Through these findings, we conclude that diffusion post-training does not merely adapt model parameters but fundamentally reorganizes internal computation to support non-sequential global planning.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14758v2</guid></item><item><title>[cs updates on arXiv.org] Multi-Task Transformer for Explainable Speech Deepfake Detection via Formant Modeling</title><link>https://arxiv.org/abs/2601.14850</link><description>arXiv:2601.14850v2 Announce Type: new 
Abstract: In this work, we introduce a multi-task transformer for speech deepfake detection, capable of predicting formant trajectories and voicing patterns over time, ultimately classifying speech as real or fake, and highlighting whether its decisions rely more on voiced or unvoiced regions. Building on a prior speaker-formant transformer architecture, we streamline the model with an improved input segmentation strategy, redesign the decoding process, and integrate built-in explainability. Compared to the baseline, our model requires fewer parameters, trains faster, and provides better interpretability, without sacrificing prediction performance.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14850v2</guid></item><item><title>[cs updates on arXiv.org] Adaptive Exponential Integration for Stable Gaussian Mixture Black-Box Variational Inference</title><link>https://arxiv.org/abs/2601.14855</link><description>arXiv:2601.14855v2 Announce Type: new 
Abstract: Black-box variational inference (BBVI) with Gaussian mixture families offers a flexible approach for approximating complex posterior distributions without requiring gradients of the target density. However, standard numerical optimization methods often suffer from instability and inefficiency. We develop a stable and efficient framework that combines three key components: (1) affine-invariant preconditioning via natural gradient formulations, (2) an exponential integrator that unconditionally preserves the positive definiteness of covariance matrices, and (3) adaptive time stepping to ensure stability and to accommodate distinct warm-up and convergence phases. The proposed approach has natural connections to manifold optimization and mirror descent. For Gaussian posteriors, we prove exponential convergence in the noise-free setting and almost-sure convergence under Monte Carlo estimation, rigorously justifying the necessity of adaptive time stepping. Numerical experiments on multimodal distributions, Neal's multiscale funnel, and a PDE-based Bayesian inverse problem for Darcy flow demonstrate the effectiveness of the proposed method.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14855v2</guid></item><item><title>[cs updates on arXiv.org] The GDN-CC Dataset: Automatic Corpus Clarification for AI-enhanced Democratic Citizen Consultations</title><link>https://arxiv.org/abs/2601.14944</link><description>arXiv:2601.14944v2 Announce Type: new 
Abstract: LLMs are ubiquitous in modern NLP, and while their applicability extends to texts produced for democratic activities such as online deliberations or large-scale citizen consultations, ethical questions have been raised for their usage as analysis tools. We continue this line of research with two main goals: (a) to develop resources that can help standardize citizen contributions in public forums at the pragmatic level, and make them easier to use in topic modeling and political analysis; (b) to study how well this standardization can reliably be performed by small, open-weights LLMs, i.e. models that can be run locally and transparently with limited resources. Accordingly, we introduce Corpus Clarification as a preprocessing framework for large-scale consultation data that transforms noisy, multi-topic contributions into structured, self-contained argumentative units ready for downstream analysis. We present GDN-CC, a manually-curated dataset of 1,231 contributions to the French Grand D\'ebat National, comprising 2,285 argumentative units annotated for argumentative structure and manually clarified. We then show that finetuned Small Language Models match or outperform LLMs on reproducing these annotations, and measure their usability for an opinion clustering task. We finally release GDN-CC-large, an automatically annotated corpus of 240k contributions, the largest annotated democratic consultation dataset to date.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14944v2</guid></item><item><title>[cs updates on arXiv.org] LogicScore: Fine-grained Logic Evaluation of Conciseness, Completeness, and Determinateness in Attributed Question Answering</title><link>https://arxiv.org/abs/2601.15050</link><description>arXiv:2601.15050v2 Announce Type: new 
Abstract: Current evaluation methods for Attributed Question Answering (AQA) suffer from \textit{attribution myopia}: they emphasize verification of isolated statements and their attributions but overlook the global logical integrity of long-form answers. Consequently, Large Language Models (LLMs) often produce factually grounded yet logically incoherent responses with elusive deductive gaps. To mitigate this limitation, we present \textsc{LogicScore}, a unified evaluation framework that shifts the paradigm from local assessment to global reasoning scrutiny. Grounded in Horn Rules, our approach integrates a backward verification mechanism to systematically evaluate three key reasoning dimensions: \textit{Completeness} (logically sound deduction), \textit{Conciseness} (non-redundancy), and \textit{Determinateness} (consistent answer entailment). Extensive experiments across three multi-hop QA datasets (HotpotQA, MusiQue, and 2WikiMultiHopQA) and over 20 LLMs (including GPT-5, Gemini-3-Pro, LLaMA3, and task-specific tuned models) reveal a critical capability gap: leading models often achieve high attribution scores (e.g., 92.85\% precision for Gemini-3 Pro) but struggle with global reasoning quality (e.g., 35.11\% Conciseness for Gemini-3 Pro). Our work establishes a robust standard for logical evaluation, highlighting the need to prioritize reasoning coherence alongside factual grounding in LLM development. Codes are available at: https://github.com/zhichaoyan11/LogicScore.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15050v2</guid></item><item><title>[cs updates on arXiv.org] WavLink: Compact Audio-Text Embeddings with a Global Whisper Token</title><link>https://arxiv.org/abs/2601.15118</link><description>arXiv:2601.15118v2 Announce Type: new 
Abstract: Whisper has become the de-facto encoder for extracting general-purpose audio features in large audio-language models, where a 30-second clip is typically represented by 1500 frame features projected into an LLM. In contrast, audio-text embedding models like CLAP-based models have largely relied on alternative audio encoders (e.g., HTS-AT, PaSST), and have not leveraged Whisper effectively. We present WavLink, a compact audio-text embedding model that augments Whisper encoder with a learnable global token, trained jointly with a text encoder. Through a systematic study of design choices, including pretrained text encoders, loss functions, training modes, and data mixtures, we identify configurations that yield state-of-the-art retrieval performance. Our two-stage training recipe across three model sizes, combined with Matryoshka-style supervision, improves scalability, enabling 8x smaller embeddings with minimal performance drop. WavLink also demonstrates competitive performance on AIR-Bench with MCQs and zero-shot classification.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15118v2</guid></item><item><title>[cs updates on arXiv.org] Emerging from Ground: Addressing Intent Deviation in Tool-Using Agents via Deriving Real Calls into Virtual Trajectories</title><link>https://arxiv.org/abs/2601.15120</link><description>arXiv:2601.15120v2 Announce Type: new 
Abstract: LLMs have advanced tool-using agents for real-world applications, yet they often lead to unexpected behaviors or results. Beyond obvious failures, the subtle issue of "intent deviation" severely hinders reliable evaluation and performance improvement. Existing post-training methods generally leverage either real system samples or virtual data simulated by LLMs. However, the former is costly due to reliance on hand-crafted user requests, while the latter suffers from distribution shift from the real tools in the wild. Additionally, both methods lack negative samples tailored to intent deviation scenarios, hindering effective guidance on preference learning. We introduce RISE, a "Real-to-Virtual" method designed to mitigate intent deviation. Anchoring on verified tool primitives, RISE synthesizes virtual trajectories and generates diverse negative samples through mutation on critical parameters. With synthetic data, RISE fine-tunes backbone LLMs via the two-stage training for intent alignment. Evaluation results demonstrate that data synthesized by RISE achieve promising results in eight metrics covering user requires, execution trajectories and agent responses. Integrating with training, RISE achieves an average 35.28% improvement in Acctask (task completion) and 23.27% in Accintent (intent alignment), outperforming SOTA baselines by 1.20--42.09% and 1.17--54.93% respectively.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15120v2</guid></item><item><title>[cs updates on arXiv.org] BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries</title><link>https://arxiv.org/abs/2601.15197</link><description>arXiv:2601.15197v2 Announce Type: new 
Abstract: Vision-Language-Action (VLA) models have shown promise in robot manipulation but often struggle to generalize to new instructions or complex multi-task scenarios. We identify a critical pathology in current training paradigms where goal-driven data collection creates a dataset bias. In such datasets, language instructions are highly predictable from visual observations alone, causing the conditional mutual information between instructions and actions to vanish, a phenomenon we term Information Collapse. Consequently, models degenerate into vision-only policies that ignore language constraints and fail in out-of-distribution (OOD) settings. To address this, we propose BayesianVLA, a novel framework that enforces instruction following via Bayesian decomposition. By introducing learnable Latent Action Queries, we construct a dual-branch architecture to estimate both a vision-only prior $p(a \mid v)$ and a language-conditioned posterior $\pi(a \mid v, \ell)$. We then optimize the policy to maximize the conditional Pointwise Mutual Information (PMI) between actions and instructions. This objective effectively penalizes the vision shortcut and rewards actions that explicitly explain the language command. Without requiring new data, BayesianVLA significantly improves generalization. Extensive experiments across on SimplerEnv and RoboCasa demonstrate substantial gains, including an 11.3% improvement on the challenging OOD SimplerEnv benchmark, validating the ability of our approach to robustly ground language in action.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15197v2</guid></item><item><title>[cs updates on arXiv.org] Deaf and Hard of Hearing Access to Intelligent Personal Assistants: Comparison of Voice-Based Options with an LLM-Powered Touch Interface</title><link>https://arxiv.org/abs/2601.15209</link><description>arXiv:2601.15209v2 Announce Type: new 
Abstract: We investigate intelligent personal assistants (IPAs) accessibility for deaf and hard of hearing (DHH) people who can use their voice in everyday communication. The inability of IPAs to understand diverse accents including deaf speech renders them largely inaccessible to non-signing and speaking DHH individuals. Using an Echo Show, we compare the usability of natural language input via spoken English; with Alexa's automatic speech recognition and a Wizard-of-Oz setting with a trained facilitator re-speaking commands against that of a large language model (LLM)-assisted touch interface in a mixed-methods study. The touch method was navigated through an LLM-powered "task prompter," which integrated the user's history and smart environment to suggest contextually-appropriate commands. Quantitative results showed no significant differences across both spoken English conditions vs LLM-assisted touch. Qualitative results showed variability in opinions on the usability of each method. Ultimately, it will be necessary to have robust deaf-accented speech recognized natively by IPAs.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15209v2</guid></item><item><title>[cs updates on arXiv.org] Finite-Sample Inference for Sparsely Permuted Linear Regression</title><link>https://arxiv.org/abs/2601.14872</link><description>arXiv:2601.14872v2 Announce Type: cross 
Abstract: We study a linear observation model with an unknown permutation called \textit{permuted/shuffled linear regression}, where responses and covariates are mismatched and the permutation forms a discrete, factorial-size parameter. The permutation is a key component of the data-generating process, yet its statistical investigation remains challenging due to its discrete nature. We develop a general statistical inference framework on the permutation and regression coefficients. First, we introduce a localization step that reduces the permutation space to a small candidate set building on recent advances in the repro samples method, whose miscoverage decays polynomially with the number of Monte Carlo samples. Then, based on this localized set, we provide statistical inference procedures: a conditional Monte Carlo test of permutation structures with valid finite-sample Type-I error control. We also develop coefficient inference that remains valid under alignment uncertainty of permutations. For computational purposes, we develop a linear assignment problem computable in polynomial time and demonstrate that, with high probability, the solution is equivalent to that of the conventional least squares with large computational cost. Extensions to partially permuted designs and ridge regularization are further discussed. Extensive simulations and an application to air-quality data corroborate finite-sample validity, strong power to detect mismatches, and practical scalability.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14872v2</guid></item><item><title>[cs updates on arXiv.org] Competitive Audio-Language Models with Data-Efficient Single-Stage Training on Public Data</title><link>https://arxiv.org/abs/2509.07526</link><description>arXiv:2509.07526v3 Announce Type: replace 
Abstract: Large language models (LLMs) have transformed NLP, yet their integration with audio remains underexplored despite audio's centrality to human communication. We introduce Falcon3-Audio, a family of Audio-Language Models (ALMs) built on instruction-tuned LLMs and Whisper encoders. Using a remarkably small amount of public audio data, less than 30K hours (5K unique), Falcon3-Audio-7B matches the best reported performance among open-weight models on the MMAU benchmark, with a score of 64.14, matching R1-AQA, while distinguishing itself through superior data and parameter efficiency, single-stage training, and transparency. Notably, our smallest 1B model remains competitive with larger open models ranging from 2B to 13B parameters. Through extensive ablations, we find that common complexities such as curriculum learning, multiple audio encoders, and intricate cross-attention connectors are not required for strong performance, even compared to models trained on over 500K hours of data.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.07526v3</guid></item><item><title>[cs updates on arXiv.org] Online Operator Design in Evolutionary Optimization for Flexible Job Shop Scheduling via Large Language Models</title><link>https://arxiv.org/abs/2511.16485</link><description>arXiv:2511.16485v3 Announce Type: replace 
Abstract: Customized static operator design has enabled widespread application of Evolutionary Algorithms (EAs), but their search effectiveness often deteriorates as evolutionary progresses. Dynamic operator configuration approaches attempt to alleviate this issue, but they typically rely on predefined operator structures and localized parameter control, lacking sustained adaptive optimization throughout evolution. To overcome these limitations, this work leverages Large Language Models (LLMs) to perceive evolutionary dynamics and enable operator-level meta-evolution. The proposed framework, LLMs for online operator design in Evolutionary Optimization, named LLM4EO, comprises three components: knowledge-transfer-based operator design, evolution perception and analysis, and adaptive operator evolution. Firstly, operators are initialized by leveraging LLMs to distill and transfer knowledge from well-established operators. Then, search behaviors and potential limitations of operators are analyzed by integrating fitness performance with evolutionary features, accompanied by suggestions for improvement. Upon stagnation of population evolution, an LLM-driven meta-operator dynamically optimizes gene selection of operators by prompt-guided improvement strategies. This approach achieves co-evolution of solutions and operators within a unified optimization framework, introducing a novel paradigm for enhancing the efficiency and adaptability of EAs. Finally, extensive experiments on multiple benchmarks of flexible job shop scheduling problem demonstrate that LLM4EO accelerates population evolution and outperforms tailored EAs.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.16485v3</guid></item><item><title>[cs updates on arXiv.org] Monadic Context Engineering</title><link>https://arxiv.org/abs/2512.22431</link><description>arXiv:2512.22431v5 Announce Type: replace 
Abstract: The proliferation of Large Language Models (LLMs) has catalyzed a shift towards autonomous agents capable of complex reasoning and tool use. However, current agent architectures are frequently constructed using imperative, ad hoc patterns. This results in brittle systems plagued by difficulties in state management, error handling, and concurrency. This paper introduces Monadic Context Engineering (MCE), a novel architectural paradigm leveraging the algebraic structures of Functors, Applicative Functors, and Monads to provide a formal foundation for agent design. MCE treats agent workflows as computational contexts where cross-cutting concerns, such as state propagation, short-circuiting error handling, and asynchronous execution, are managed intrinsically by the algebraic properties of the abstraction. We demonstrate how Monads enable robust sequential composition, how Applicatives provide a principled structure for parallel execution, and crucially, how Monad Transformers allow for the systematic composition of these capabilities. This layered approach enables developers to construct complex, resilient, and efficient AI agents from simple, independently verifiable components. We further extend this framework to describe Meta-Agents, which leverage MCE for generative orchestration, dynamically creating and managing sub-agent workflows through metaprogramming.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.22431v5</guid></item><item><title>[cs updates on arXiv.org] GDEPO: Group Dual-dynamic and Equal-right Advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning</title><link>https://arxiv.org/abs/2601.06795</link><description>arXiv:2601.06795v3 Announce Type: replace 
Abstract: Automated Theorem Proving (ATP) represents a fundamental challenge in Artificial Intelligence (AI), requiring the construction of machine-verifiable proofs in formal languages such as Lean to evaluate AI reasoning capabilities. Reinforcement learning (RL), particularly the high-performance Group Relative Policy Optimization (GRPO) algorithm, has emerged as a mainstream approach for this task. However, in ATP scenarios, GRPO faces two critical issues: when composite rewards are used, its relative advantage estimation may conflict with the binary feedback from the formal verifier; meanwhile, its static sampling strategy may discard entire batches of data if no valid proof is found, resulting in zero contribution to model updates and significant data waste. To address these limitations, we propose Group Dual-dynamic and Equal-right-advantage Policy Optimization (GDEPO), a method incorporating three core mechanisms: 1) dynamic additional sampling, which resamples invalid batches until a valid proof is discovered; 2) equal-right advantage, decoupling the sign of the advantage function (based on correctness) from its magnitude (modulated by auxiliary rewards) to ensure stable and correct policy updates; and 3) dynamic additional iterations, applying extra gradient steps to initially failed but eventually successful samples to accelerate learning on challenging cases. Experiments conducted on three datasets of varying difficulty (MinF2F-test, MathOlympiadBench, PutnamBench) confirm the effectiveness of GDEPO, while ablation studies validate the necessity of its synergistic components. The proposed method enhances data utilization and optimization efficiency, offering a novel training paradigm for ATP.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.06795v3</guid></item><item><title>[cs updates on arXiv.org] LLMs Got Rhythm? Hybrid Phonological Filtering for Greek Poetry Rhyme Detection and Generation</title><link>https://arxiv.org/abs/2601.09631</link><description>arXiv:2601.09631v3 Announce Type: replace 
Abstract: Large Language Models (LLMs), despite their remarkable capabilities across NLP tasks, struggle with phonologically-grounded phenomena like rhyme detection and generation. This is even more evident in lower-resource languages such as Modern Greek. In this paper, we present a hybrid system that combines LLMs with deterministic phonological algorithms to achieve accurate rhyme identification/analysis and generation. Our approach implements a comprehensive taxonomy of Greek rhyme types, including Pure, Rich, Imperfect, Mosaic, and Identical Pre-rhyme Vowel (IDV) patterns, and employs an agentic generation pipeline with phonological verification. We evaluate multiple prompting strategies (zero-shot, few-shot, Chain-of-Thought, and RAG-augmented) across several LLMs including Claude 3.7 and 4.5, GPT-4o, Gemini 2.0 and open-weight models like Llama 3.1 8B and 70B and Mistral Large. Results reveal a significant "Reasoning Gap": while native-like models (Claude 3.7) perform intuitively (40\% accuracy in identification), reasoning-heavy models (Claude 4.5) achieve state-of-the-art performance (54\%) only when prompted with Chain-of-Thought. Most critically, pure LLM generation fails catastrophically (under 4\% valid poems), while our hybrid verification loop restores performance to 73.1\%. We release our system and a corpus of 40,000+ rhymes, derived from the Anemoskala and Interwar Poetry corpora, to support future research.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.09631v3</guid></item><item><title>[cs updates on arXiv.org] SUG-Occ: An Explicit Semantics and Uncertainty Guided Sparse Learning Framework for Real-Time 3D Occupancy Prediction</title><link>https://arxiv.org/abs/2601.11396</link><description>arXiv:2601.11396v3 Announce Type: replace 
Abstract: As autonomous driving moves toward full scene understanding, 3D semantic occupancy prediction has emerged as a crucial perception task, offering voxel-level semantics beyond traditional detection and segmentation paradigms. However, such a refined representation for scene understanding incurs prohibitive computation and memory overhead, posing a major barrier to practical real-time deployment. To address this, we propose SUG-Occ, an explicit Semantics and Uncertainty Guided Sparse Learning Enabled 3D Occupancy Prediction Framework, which exploits the inherent sparsity of 3D scenes to reduce redundant computation while maintaining geometric and semantic completeness. Specifically, we first utilize semantic and uncertainty priors to suppress projections from free space during view transformation while employing an explicit unsigned distance encoding to enhance geometric consistency, producing a structurally consistent sparse 3D representation. Secondly, we design an cascade sparse completion module via hyper cross sparse convolution and generative upsampling to enable efficiently coarse-to-fine reasoning. Finally, we devise an object contextual representation (OCR) based mask decoder that aggregates global semantic context from sparse features and refines voxel-wise predictions via lightweight query-context interactions, avoiding expensive attention operations over volumetric features. Extensive experiments on SemanticKITTI benchmark demonstrate that the proposed approach outperforms the baselines, achieving a 7.34/% improvement in accuracy and a 57.8\% gain in efficiency.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11396v3</guid></item><item><title>[cs updates on arXiv.org] Numerical Optimization Strategies for the Variational Hamiltonian Ansatz in Noisy Quantum Environments</title><link>https://arxiv.org/abs/2505.22398</link><description>arXiv:2505.22398v4 Announce Type: replace-cross 
Abstract: The prevalence of variational methods in near-term quantum computing makes optimizer choice critical, yet selection is frequently intuition-based. We therefore present a systematic benchmark of eight classical optimization algorithms for variational quantum chemistry using the truncated Variational Hamiltonian Ansatz. Performance is evaluated on H$_2$, H$_4$, and LiH in both full and active-space representations under noiseless and finite-shot sampling noise. Sampling noise substantially reshapes cost landscapes, induces wandering near minima, and flips optimizer rankings: gradient-based methods perform best in noiseless simulations, whereas population-based optimizers, particularly CMA-ES, show greater robustness under finite-shot noise. Optimizer performance is strongly problem dependent: Hartree-Fock initialization aids small systems, but its advantage diminishes with system size. Also, we observe that finite shot sampling frequently violates the lower bound given by the variational principle, a principle that cannot be strictly held in the presence of noise. By exploiting the guaranteed convergence of Evolution Strategies to a steady state distribution defined by the noise floor, we utilize the symmetry of these violations to achieve energy estimation precision beyond the intrinsic sampling limit.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.22398v4</guid></item><item><title>[cs updates on arXiv.org] Principled Coarse-Grained Acceptance for Speculative Decoding in Speech</title><link>https://arxiv.org/abs/2511.13732</link><description>arXiv:2511.13732v4 Announce Type: replace-cross 
Abstract: Speculative decoding accelerates autoregressive speech generation by letting a fast draft model propose tokens that a larger target model verifies. However, for speech LLMs that generate acoustic tokens, exact token matching is overly restrictive: many discrete tokens are acoustically or semantically interchangeable, reducing acceptance rates and limiting speedups. We introduce Principled Coarse-Graining (PCG), which verifies proposals at the level of Acoustic Similarity Groups (ASGs) derived from the target model's embedding space. By splitting each token's probability mass across the overlapping groups that contain it, we define an overlap-aware coarse-grained distribution and perform rejection sampling on the resulting group variable. This yields an exactness guarantee at the group level while allowing the accepted draft token to stand in for any member of the group in practice. On LibriTTS, PCG increases acceptance and throughput relative to standard speculative decoding and prior speech-specific relaxations while maintaining intelligibility and speaker similarity. These results suggest acoustically aware, group-level acceptance as a simple and general way to accelerate speech token generation while maintaining speech quality.</description><author>cs updates on arXiv.org</author><pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.13732v4</guid></item><item><title>[cs updates on arXiv.org] SOSControl: Enhancing Human Motion Generation through Saliency-Aware Symbolic Orientation and Timing Control</title><link>https://arxiv.org/abs/2601.14258</link><description>arXiv:2601.14258v1 Announce Type: new 
Abstract: Traditional text-to-motion frameworks often lack precise control, and existing approaches based on joint keyframe locations provide only positional guidance, making it challenging and unintuitive to specify body part orientations and motion timing. To address these limitations, we introduce the Salient Orientation Symbolic (SOS) script, a programmable symbolic framework for specifying body part orientations and motion timing at keyframes. We further propose an automatic SOS extraction pipeline that employs temporally-constrained agglomerative clustering for frame saliency detection and a Saliency-based Masking Scheme (SMS) to generate sparse, interpretable SOS scripts directly from motion data. Moreover, we present the SOSControl framework, which treats the available orientation symbols in the sparse SOS script as salient and prioritizes satisfying these constraints during motion generation. By incorporating SMS-based data augmentation and gradient-based iterative optimization, the framework enhances alignment with user-specified constraints. Additionally, it employs a ControlNet-based ACTOR-PAE Decoder to ensure smooth and natural motion outputs. Extensive experiments demonstrate that the SOS extraction pipeline generates human-interpretable scripts with symbolic annotations at salient keyframes, while the SOSControl framework outperforms existing baselines in motion quality, controllability, and generalizability with respect to motion timing and body part orientation control.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14258v1</guid></item><item><title>[cs updates on arXiv.org] A Cloud-Based Cross-Modal Transformer for Emotion Recognition and Adaptive Human-Computer Interaction</title><link>https://arxiv.org/abs/2601.14259</link><description>arXiv:2601.14259v1 Announce Type: new 
Abstract: Emotion recognition is a fundamental component of next-generation human-computer interaction (HCI), enabling machines to perceive, understand, and respond to users' affective states. However, existing systems often rely on single-modality analysis such as facial expressions, speech tone, or textual sentiment, resulting in limited robustness and poor generalization in real-world environments. To address these challenges, this study proposes a Cloud-Based Cross-Modal Transformer (CMT) framework for multimodal emotion recognition and adaptive human-computer interaction. The proposed model integrates visual, auditory, and textual signals using pretrained encoders (Vision Transformer, Wav2Vec2, and BERT) and employs a cross-modal attention mechanism to capture complex interdependencies among heterogeneous features. By leveraging cloud computing infrastructure with distributed training on Kubernetes and TensorFlow Serving, the system enables scalable, low-latency emotion recognition for large-scale user interactions. Experiments conducted on benchmark datasets including IEMOCAP, MELD, and AffectNet demonstrate that the CMT achieves state-of-the-art performance, improving the F1-score by 3.0 percent and reducing cross-entropy loss by 12.9 percent compared to strong multimodal baselines. Additionally, cloud deployment evaluations show an average response latency of 128 ms, representing a 35 percent reduction compared with conventional transformer-based fusion systems. These results confirm that the proposed framework enables efficient, real-time emotion recognition and adaptive feedback in applications such as intelligent customer service, virtual tutoring systems, and affective computing interfaces, marking an important step toward cloud-native affective computing and emotionally intelligent interactive systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14259v1</guid></item><item><title>[cs updates on arXiv.org] End-to-End Transformer Acceleration Through Processing-in-Memory Architectures</title><link>https://arxiv.org/abs/2601.14260</link><description>arXiv:2601.14260v1 Announce Type: new 
Abstract: Transformers have become central to natural language processing and large language models, but their deployment at scale faces three major challenges. First, the attention mechanism requires massive matrix multiplications and frequent movement of intermediate results between memory and compute units, leading to high latency and energy costs. Second, in long-context inference, the key-value cache (KV cache) can grow unpredictably and even surpass the model's weight size, creating severe memory and bandwidth bottlenecks. Third, the quadratic complexity of attention with respect to sequence length amplifies both data movement and compute overhead, making large-scale inference inefficient. To address these issues, this work introduces processing-in-memory solutions that restructure attention and feed-forward computation to minimize off-chip data transfers, dynamically compress and prune the KV cache to manage memory growth, and reinterpret attention as an associative memory operation to reduce complexity and hardware footprint. Moreover, we evaluate our processing-in-memory design against state-of-the-art accelerators and general-purpose GPUs, demonstrating significant improvements in energy efficiency and latency. Together, these approaches address computation overhead, memory scalability, and attention complexity, further enabling efficient, end-to-end acceleration of Transformer models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14260v1</guid></item><item><title>[cs updates on arXiv.org] Intelligent Power Grid Design Review via Active Perception-Enabled Multimodal Large Language Models</title><link>https://arxiv.org/abs/2601.14261</link><description>arXiv:2601.14261v1 Announce Type: new 
Abstract: The intelligent review of power grid engineering design drawings is crucial for power system safety. However, current automated systems struggle with ultra-high-resolution drawings due to high computational demands, information loss, and a lack of holistic semantic understanding for design error identification. This paper proposes a novel three-stage framework for intelligent power grid drawing review, driven by pre-trained Multimodal Large Language Models (MLLMs) through advanced prompt engineering. Mimicking the human expert review process, the first stage leverages an MLLM for global semantic understanding to intelligently propose domain-specific semantic regions from a low-resolution overview. The second stage then performs high-resolution, fine-grained recognition within these proposed regions, acquiring detailed information with associated confidence scores. In the final stage, a comprehensive decision-making module integrates these confidence-aware results to accurately diagnose design errors and provide a reliability assessment. Preliminary results on real-world power grid drawings demonstrate our approach significantly enhances MLLM's ability to grasp macroscopic semantic information and pinpoint design errors, showing improved defect discovery accuracy and greater reliability in review judgments compared to traditional passive MLLM inference. This research offers a novel, prompt-driven paradigm for intelligent and reliable power grid drawing review.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14261v1</guid></item><item><title>[cs updates on arXiv.org] Call2Instruct: Automated Pipeline for Generating Q&amp;A Datasets from Call Center Recordings for LLM Fine-Tuning</title><link>https://arxiv.org/abs/2601.14263</link><description>arXiv:2601.14263v1 Announce Type: new 
Abstract: The adaptation of Large-Scale Language Models (LLMs) to specific domains depends on high-quality fine-tuning datasets, particularly in instructional format (e.g., Question-Answer - Q&amp;amp;A). However, generating these datasets, particularly from unstructured sources such as call center audio recordings, poses a significant challenge due to the noisy and disorganized nature of the data. This paper presents a solution to this challenge by offering an end-to-end automated pipeline for generating Q&amp;amp;A instructional datasets from such recordings. The methodology developed comprises sequential steps of audio processing (including diarization, noise removal and automatic transcription), textual processing (cleaning, normalization, and anonymization), semantic extraction of customer demands and attendant responses using vector embeddings, and matching via semantic search to form the final Q&amp;amp;A pairs. As a result, the complete pipeline was successfully implemented, generating a dataset specifically formatted for Instruct Fine Tuning. The practical value and feasibility of the generated dataset were substantiated and functionally demonstrated through the successful fine-tuning of an LLM model (based on Llama 2 7B). The conclusion of the paper states that the proposed approach is viable for converting unstructured conversational data from call centers into valuable resources for training LLMs. This development has the potential to open up avenues for creating more effective AI systems for Q&amp;amp;A tasks in the customer service domain. The developed codes have been made publicly available to promote reproducibility and future research.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14263v1</guid></item><item><title>[cs updates on arXiv.org] Psychometric Comparability of LLM-Based Digital Twins</title><link>https://arxiv.org/abs/2601.14264</link><description>arXiv:2601.14264v1 Announce Type: new 
Abstract: Large language models (LLMs) are used as "digital twins" to replace human respondents, yet their psychometric comparability to humans is uncertain. We propose a construct-validity framework spanning construct representation and the nomological net, benchmarking digital twins against human gold standards across models, tasks and testing how person-specific inputs shape performance. Across studies, digital twins achieved high population-level accuracy and strong within-participant profile correlations, alongside attenuated item-level correlations. In word association tests, LLM-based networks show small-world structure and theory-consistent communities similar to humans, yet diverge lexically and in local structure. In decision-making and contextualized tasks, digital twins under-reproduce heuristic biases, showing normative rationality, compressed variance and limited sensitivity to temporal information. Feature-rich digital twins improve Big Five Personality prediction, but their personality networks show only configural invariance and do not achieve metric invariance. In more applied free-text tasks, feature-rich digital twins better match human narratives, but linguistic differences persist. Together, these results indicate that feature-rich conditioning enhances validity but does not resolve systematic divergences in psychometric comparability. Future work should therefore prioritize delineating the effective boundaries of digital twins, establishing the precise contexts in which they function as reliable proxies for human cognition and behavior.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14264v1</guid></item><item><title>[cs updates on arXiv.org] From Textbook to Talkbot: A Case Study of a Greek-Language RAG-Based Chatbot in Higher Education</title><link>https://arxiv.org/abs/2601.14265</link><description>arXiv:2601.14265v1 Announce Type: new 
Abstract: The integration of AI chatbots into educational settings has opened new pathways for transforming teaching and learning, offering enhanced support to both educators and learners. This study investigates the design and application of an AI chatbot as an educational tool in higher education. Designed to operate in the Greek language, the chatbot addresses linguistic challenges unique to Greek while delivering accurate, context grounded support aligned with the curriculum. The AI chatbot is built on the Retrieval Augmented Generation (RAG) framework by grounding its responses in specific course content. RAG architecture significantly enhances the chatbots reliability by providing accurate, context-aware responses while mitigating common challenges associated with large language models (LLMs), such as hallucinations and misinformation. The AI chatbot serves a dual purpose: it enables students to access accurate, ondemand academic support and assists educators in the rapid creation of relevant educational materials. This dual functionality promotes learner autonomy and streamlines the instructional design process. The study aims to evaluate the effectiveness, reliability, and perceived usability of RAG based chatbots in higher education, exploring their potential to enhance educational practices and outcomes as well as supporting the broader adoption of AI technologies in language specific educational contexts. Findings from this research are expected to contribute to the emerging field of AI driven education by demonstrating how intelligent systems can be effectively aligned with pedagogical goals.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14265v1</guid></item><item><title>[cs updates on arXiv.org] GCG Attack On A Diffusion LLM</title><link>https://arxiv.org/abs/2601.14266</link><description>arXiv:2601.14266v1 Announce Type: new 
Abstract: While most LLMs are autoregressive, diffusion-based LLMs have recently emerged as an alternative method for generation. Greedy Coordinate Gradient (GCG) attacks have proven effective against autoregressive models, but their applicability to diffusion language models remains largely unexplored. In this work, we present an exploratory study of GCG-style adversarial prompt attacks on LLaDA (Large Language Diffusion with mAsking), an open-source diffusion LLM. We evaluate multiple attack variants, including prefix perturbations and suffix-based adversarial generation, on harmful prompts drawn from the AdvBench dataset. Our study provides initial insights into the robustness and attack surface of diffusion language models and motivates the development of alternative optimization and evaluation strategies for adversarial analysis in this setting.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14266v1</guid></item><item><title>[cs updates on arXiv.org] From Chaos to Clarity: Schema-Constrained AI for Auditable Biomedical Evidence Extraction from Full-Text PDFs</title><link>https://arxiv.org/abs/2601.14267</link><description>arXiv:2601.14267v1 Announce Type: new 
Abstract: Biomedical evidence synthesis relies on accurate extraction of methodological, laboratory, and outcome variables from full-text research articles, yet these variables are embedded in complex scientific PDFs that make manual abstraction time-consuming and difficult to scale. Existing document AI systems remain limited by OCR errors, long-document fragmentation, constrained throughput, and insufficient auditability for high-stakes synthesis. We present a schema-constrained AI extraction system that transforms full-text biomedical PDFs into structured, analysis-ready records by explicitly restricting model inference through typed schemas, controlled vocabularies, and evidence-gated decisions. Documents are ingested using resume-aware hashing, partitioned into caption-aware page-level chunks, and processed asynchronously under explicit concurrency controls. Chunk-level outputs are deterministically merged into study-level records using conflict-aware consolidation, set-based aggregation, and sentence-level provenance to support traceability and post-hoc audit. Evaluated on a corpus of studies on direct oral anticoagulant level measurement, the pipeline processed all documents without manual intervention, maintained stable throughput under service constraints, and exhibited strong internal consistency across document chunks. Iterative schema refinement substantially improved extraction fidelity for synthesis-critical variables, including assay classification, outcome definitions, follow-up duration, and timing of measurement. These results demonstrate that schema-constrained, provenance-aware extraction enables scalable and auditable transformation of heterogeneous scientific PDFs into structured evidence, aligning modern document AI with the transparency and reliability requirements of biomedical evidence synthesis.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14267v1</guid></item><item><title>[cs updates on arXiv.org] Developmental trajectories of decision making and affective dynamics in large language models</title><link>https://arxiv.org/abs/2601.14268</link><description>arXiv:2601.14268v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly used in medicine and clinical workflows, yet we know little about their decision and affective profiles. Taking a historically informed outlook on the future, we treated successive OpenAI models as an evolving lineage and compared them with humans in a gambling task with repeated happiness ratings. Computational analyses showed that some aspects became more human-like: newer models took more risks and displayed more human-like patterns of Pavlovian approach and avoidance. At the same time, distinctly non-human signatures emerged: loss aversion dropped below neutral levels, choices became more deterministic than in humans, affective decay increased across versions and exceeded human levels, and baseline mood remained chronically higher than in humans. These "developmental" trajectories reveal an emerging psychology of machines and have direct implications for AI ethics and for thinking about how LLMs might be integrated into clinical decision support and other high-stakes domains.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14268v1</guid></item><item><title>[cs updates on arXiv.org] The Slow Drift of Support: Boundary Failures in Multi-Turn Mental Health LLM Dialogues</title><link>https://arxiv.org/abs/2601.14269</link><description>arXiv:2601.14269v1 Announce Type: new 
Abstract: Large language models (LLMs) have been widely used for mental health support. However, current safety evaluations in this field are mostly limited to detecting whether LLMs output prohibited words in single-turn conversations, neglecting the gradual erosion of safety boundaries in long dialogues. Examples include making definitive guarantees, assuming responsibility, and playing professional roles. We believe that with the evolution of mainstream LLMs, words with obvious safety risks are easily filtered by their underlying systems, while the real danger lies in the gradual transgression of boundaries during multi-turn interactions, driven by the LLM's attempts at comfort and empathy.
  This paper proposes a multi-turn stress testing framework and conducts long-dialogue safety tests on three cutting-edge LLMs using two pressure methods: static progression and adaptive probing. We generated 50 virtual patient profiles and stress-tested each model through up to 20 rounds of virtual psychiatric dialogues. The experimental results show that violations are common, and both pressure modes produced similar violation rates. However, adaptive probing significantly advanced the time at which models crossed boundaries, reducing the average number of turns from 9.21 in static progression to 4.64. Under both mechanisms, making definitive or zero-risk promises was the primary way in which boundaries were breached. These findings suggest that the robustness of LLM safety boundaries cannot be inferred solely through single-turn tests; it is necessary to fully consider the wear and tear on safety boundaries caused by different interaction pressures and characteristics in extended dialogues.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14269v1</guid></item><item><title>[cs updates on arXiv.org] Opening the Black Box: A Survey on the Mechanisms of Multi-Step Reasoning in Large Language Models</title><link>https://arxiv.org/abs/2601.14270</link><description>arXiv:2601.14270v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable abilities to solve problems requiring multiple reasoning steps, yet the internal mechanisms enabling such capabilities remain elusive. Unlike existing surveys that primarily focus on engineering methods to enhance performance, this survey provides a comprehensive overview of the mechanisms underlying LLM multi-step reasoning. We organize the survey around a conceptual framework comprising seven interconnected research questions, from how LLMs execute implicit multi-hop reasoning within hidden activations to how verbalized explicit reasoning remodels the internal computation. Finally, we highlight five research directions for future mechanistic studies.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14270v1</guid></item><item><title>[cs updates on arXiv.org] Divide and Refine: Enhancing Multimodal Representation and Explainability for Emotion Recognition in Conversation</title><link>https://arxiv.org/abs/2601.14274</link><description>arXiv:2601.14274v1 Announce Type: new 
Abstract: Multimodal emotion recognition in conversation (MERC) requires representations that effectively integrate signals from multiple modalities. These signals include modality-specific cues, information shared across modalities, and interactions that emerge only when modalities are combined. In information-theoretic terms, these correspond to \emph{unique}, \emph{redundant}, and \emph{synergistic} contributions. An ideal representation should leverage all three, yet achieving such balance remains challenging. Recent advances in contrastive learning and augmentation-based methods have made progress, but they often overlook the role of data preparation in preserving these components. In particular, applying augmentations directly to raw inputs or fused embeddings can blur the boundaries between modality-unique and cross-modal signals. To address this challenge, we propose a two-phase framework \emph{\textbf{D}ivide and \textbf{R}efine} (\textbf{DnR}). In the \textbf{Divide} phase, each modality is explicitly decomposed into uniqueness, pairwise redundancy, and synergy. In the \textbf{Refine} phase, tailored objectives enhance the informativeness of these components while maintaining their distinct roles. The refined representations are plug-and-play compatible with diverse multimodal pipelines. Extensive experiments on IEMOCAP and MELD demonstrate consistent improvements across multiple MERC backbones. These results highlight the effectiveness of explicitly dividing, refining, and recombining multimodal representations as a principled strategy for advancing emotion recognition. Our implementation is available at https://github.com/mattam301/DnR-WACV2026</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14274v1</guid></item><item><title>[cs updates on arXiv.org] Quality or Quantity? Error-Informed Selective Online Learning with Gaussian Processes in Multi-Agent Systems: Extended Version</title><link>https://arxiv.org/abs/2601.14275</link><description>arXiv:2601.14275v1 Announce Type: new 
Abstract: Effective cooperation is pivotal in distributed learning for multi-agent systems, where the interplay between the quantity and quality of the machine learning models is crucial. This paper reveals the irrationality of indiscriminate inclusion of all models on agents for joint prediction, highlighting the imperative to prioritize quality over quantity in cooperative learning. Specifically, we present the first selective online learning framework for distributed Gaussian process (GP) regression, namely distributed error-informed GP (EIGP), that enables each agent to assess its neighboring collaborators, using the proposed selection function to choose the higher quality GP models with less prediction errors. Moreover, algorithmic enhancements are embedded within the EIGP, including a greedy algorithm (gEIGP) for accelerating prediction and an adaptive algorithm (aEIGP) for improving prediction accuracy. In addition, approaches for fast prediction and model update are introduced in conjunction with the error-informed quantification term iteration and a data deletion strategy to achieve real-time learning operations. Numerical simulations are performed to demonstrate the effectiveness of the developed methodology, showcasing its superiority over the state-of-the-art distributed GP methods with different benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14275v1</guid></item><item><title>[cs updates on arXiv.org] Which Quantization Should I Use? A Unified Evaluation of llama.cpp Quantization on Llama-3.1-8B-Instruct</title><link>https://arxiv.org/abs/2601.14277</link><description>arXiv:2601.14277v1 Announce Type: new 
Abstract: Quantization is a practical technique for making large language models easier to deploy by reducing the precision used to store and operate on model weights. This can lower memory use and improve runtime feasibility on constrained hardware, which is especially relevant for users running models locally. Quantization in llama.cpp enables large language models to run on commodity hardware, but available formats are often evaluated inconsistently, making it hard to choose among schemes. We present a unified empirical study of the llama.cpp quantization on a single modern model, Llama-3.1-8B-Instruct (FP16, GGUF), covering 3-8 bit K-quant and legacy formats. We evaluate downstream task performance across standard reasoning, knowledge, instruction-following, and truthfulness benchmarks, and also measure perplexity and CPU throughput (prefill/decoding) alongside model size, compression, and quantization time. Ultimately, this work is a practical guide for choosing a llama.cpp quantization scheme, helping readers make informed, context-aware decisions for their intended use and resource budget.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14277v1</guid></item><item><title>[cs updates on arXiv.org] On the Limits of Learned Importance Scoring for KV Cache Compression</title><link>https://arxiv.org/abs/2601.14279</link><description>arXiv:2601.14279v1 Announce Type: new 
Abstract: We investigate learned KV cache compression through Speculative Importance Prediction (SIP), a 1.7M parameter non-query-aware scorer that predicts token importance from KV representations alone. Despite architectural sophistication (multi-horizon lookahead, cross-attention), SIP does not outperform simple baselines, including random selection, across 5 seeds, 4 retention levels, and 3 tasks. Key findings: (1) position-based heuristics (keep first 4 + last N tokens) match or exceed learned approaches; (2) prefill attention provides equivalent signal to complex learned scorers; (3) marginal information in KV representations beyond position and prefill attention appears limited for importance prediction. We hypothesize that circular dependence between future queries and generation trajectories contributes to this difficulty.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14279v1</guid></item><item><title>[cs updates on arXiv.org] Hallucination-Free Automatic Question &amp; Answer Generation for Intuitive Learning</title><link>https://arxiv.org/abs/2601.14280</link><description>arXiv:2601.14280v1 Announce Type: new 
Abstract: Hallucinations in large language models (LLMs), defined as fluent yet incorrect or incoherent outputs, pose a significant challenge to the automatic generation of educational multiple-choice questions (MCQs). We identified four key hallucination types in MCQ generation: reasoning inconsistencies, insolvability, factual errors, and mathematical errors. To address this, we propose a hallucination-free multi-agent generation framework that breaks down MCQ generation into discrete, verifiable stages. Our framework utilizes both rule-based and LLM-based detection agents, as well as hallucination scoring metrics to optimize question quality. We redefined MCQ generation as an optimization task minimizing hallucination risk while maximizing validity, answerability, and cost-efficiency. We also introduce an agent-led refinement process that uses counterfactual reasoning and chain-of-thought (CoT) to iteratively improve hallucination in question generation. We evaluated a sample of AP- aligned STEM questions, where our system reduced hallucination rates by over 90% compared to baseline generation while preserving the educational value and style of questions. Our results demonstrate that structured multi-agent collaboration can mitigate hallucinations in educational content creation at scale, paving the way for more reliable LLM-powered learning tools.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14280v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Affinity: A Benchmark of 1D, 2D, and 3D Methods Reveals Critical Trade-offs in Structure-Based Drug Design</title><link>https://arxiv.org/abs/2601.14283</link><description>arXiv:2601.14283v1 Announce Type: new 
Abstract: Currently, the field of structure-based drug design is dominated by three main types of algorithms: search-based algorithms, deep generative models, and reinforcement learning. While existing works have typically focused on comparing models within a single algorithmic category, cross-algorithm comparisons remain scarce. In this paper, to fill the gap, we establish a benchmark to evaluate the performance of fifteen models across these different algorithmic foundations by assessing the pharmaceutical properties of the generated molecules and their docking affinities and poses with specified target proteins. We highlight the unique advantages of each algorithmic approach and offer recommendations for the design of future SBDD models. We emphasize that 1D/2D ligand-centric drug design methods can be used in SBDD by treating the docking function as a black-box oracle, which is typically neglected. Our evaluation reveals distinct patterns across model categories. 3D structure-based models excel in binding affinities but show inconsistencies in chemical validity and pose quality. 1D models demonstrate reliable performance in standard molecular metrics but rarely achieve optimal binding affinities. 2D models offer balanced performance, maintaining high chemical validity while achieving moderate binding scores. Through detailed analysis across multiple protein targets, we identify key improvement areas for each model category, providing insights for researchers to combine strengths of different approaches while addressing their limitations. All the code that are used for benchmarking is available in https://github.com/zkysfls/2025-sbdd-benchmark</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14283v1</guid></item><item><title>[cs updates on arXiv.org] GNN-based Path-aware multi-view Circuit Learning for Technology Mapping</title><link>https://arxiv.org/abs/2601.14286</link><description>arXiv:2601.14286v1 Announce Type: new 
Abstract: Traditional technology mapping suffers from systemic inaccuracies in delay estimation due to its reliance on abstract, technology-agnostic delay models that fail to capture the nuanced timing behavior behavior of real post-mapping circuits. To address this fundamental limitation, we introduce GPA(graph neural network (GNN)-based Path-Aware multi-view circuit learning), a novel GNN framework that learns precise, data-driven delay predictions by synergistically fusing three complementary views of circuit structure: And-Inverter Graphs (AIGs)-based functional encoding, post-mapping technology emphasizes critical timing paths. Trained exclusively on real cell delays extracted from critical paths of industrial-grade post-mapping netlists, GPA learns to classify cut delays with unprecedented accuracy, directly informing smarter mapping decisions. Evaluated on the 19 EPFL combinational benchmarks, GPA achieves 19.9%, 2.1% and 4.1% average delay reduction over the conventional heuristics methods (techmap, MCH) and the prior state-of-the-art ML-based approach SLAP, respectively-without compromising area efficiency.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14286v1</guid></item><item><title>[cs updates on arXiv.org] Chain-of-Memory: Lightweight Memory Construction with Dynamic Evolution for LLM Agents</title><link>https://arxiv.org/abs/2601.14287</link><description>arXiv:2601.14287v1 Announce Type: new 
Abstract: External memory systems are pivotal for enabling Large Language Model (LLM) agents to maintain persistent knowledge and perform long-horizon decision-making. Existing paradigms typically follow a two-stage process: computationally expensive memory construction (e.g., structuring data into graphs) followed by naive retrieval-augmented generation. However, our empirical analysis reveals two fundamental limitations: complex construction incurs high costs with marginal performance gains, and simple context concatenation fails to bridge the gap between retrieval recall and reasoning accuracy. To address these challenges, we propose CoM (Chain-of-Memory), a novel framework that advocates for a paradigm shift toward lightweight construction paired with sophisticated utilization. CoM introduces a Chain-of-Memory mechanism that organizes retrieved fragments into coherent inference paths through dynamic evolution, utilizing adaptive truncation to prune irrelevant noise. Extensive experiments on the LongMemEval and LoCoMo benchmarks demonstrate that CoM outperforms strong baselines with accuracy gains of 7.5%-10.4%, while drastically reducing computational overhead to approximately 2.7% of token consumption and 6.0% of latency compared to complex memory architectures.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14287v1</guid></item><item><title>[cs updates on arXiv.org] RPC-Bench: A Fine-grained Benchmark for Research Paper Comprehension</title><link>https://arxiv.org/abs/2601.14289</link><description>arXiv:2601.14289v1 Announce Type: new 
Abstract: Understanding research papers remains challenging for foundation models due to specialized scientific discourse and complex figures and tables, yet existing benchmarks offer limited fine-grained evaluation at scale. To address this gap, we introduce RPC-Bench, a large-scale question-answering benchmark built from review-rebuttal exchanges of high-quality computer science papers, containing 15K human-verified QA pairs. We design a fine-grained taxonomy aligned with the scientific research flow to assess models' ability to understand and answer why, what, and how questions in scholarly contexts. We also define an elaborate LLM-human interaction annotation framework to support large-scale labeling and quality control. Following the LLM-as-a-Judge paradigm, we develop a scalable framework that evaluates models on correctness-completeness and conciseness, with high agreement to human judgment. Experiments reveal that even the strongest models (GPT-5) achieve only 68.2% correctness-completeness, dropping to 37.46% after conciseness adjustment, highlighting substantial gaps in precise academic paper understanding. Our code and data are available at https://rpc-bench.github.io/.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14289v1</guid></item><item><title>[cs updates on arXiv.org] Project Aletheia: Verifier-Guided Distillation of Backtracking for Small Language Models</title><link>https://arxiv.org/abs/2601.14290</link><description>arXiv:2601.14290v1 Announce Type: new 
Abstract: Small Language Models (SLMs, under 10B parameters) are attractive for private, on-device deployment, yet they frequently fail on strict constraint-satisfaction problems due to linear, overconfident reasoning traces that do not recover from early mistakes. We introduce Verifier-Guided Distillation, a training protocol that transfers the process of error repair - explicit conflict detection and backtracking - rather than only correct final answers. By training a 7B model on verified reasoning traces that include mistakes and self-corrections, we show that latent verification behavior can emerge in small models, enabling them to occasionally stop, detect contradictions, and revise earlier assumptions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14290v1</guid></item><item><title>[cs updates on arXiv.org] Epistemic Constitutionalism Or: how to avoid coherence bias</title><link>https://arxiv.org/abs/2601.14295</link><description>arXiv:2601.14295v1 Announce Type: new 
Abstract: Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for an epistemic constitution for AI: explicit, contestable meta-norms that regulate how systems form and express beliefs. Source attribution bias provides the motivating case: I show that frontier models enforce identity-stance coherence, penalizing arguments attributed to sources whose expected ideological position conflicts with the argument's content. When models detect systematic testing, these effects collapse, revealing that systems treat source-sensitivity as bias to suppress rather than as a capacity to execute well. I distinguish two constitutional approaches: the Platonic, which mandates formal correctness and default source-independence from a privileged standpoint, and the Liberal, which refuses such privilege, specifying procedural norms that protect conditions for collective inquiry while allowing principled source-attending grounded in epistemic vigilance. I argue for the Liberal approach, sketch a constitutional core of eight principles and four orientations, and propose that AI epistemic governance requires the same explicit, contestable structure we now expect for AI ethics.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14295v1</guid></item><item><title>[cs updates on arXiv.org] From Agent Simulation to Social Simulator: A Comprehensive Review (Part 2)</title><link>https://arxiv.org/abs/2601.14296</link><description>arXiv:2601.14296v1 Announce Type: new 
Abstract: The study of system complexity primarily has two objectives: to explore underlying patterns and to develop theoretical explanations. Pattern exploration seeks to clarify the mechanisms behind the emergence of system complexity, while theoretical explanations aim to identify the fundamental causes of this complexity. Laws are generally defined as mappings between variables, whereas theories offer causal explanations of system behavior. Agent Based Modeling(ABM) is an important approach for studying complex systems, but it tends to emphasize simulation over experimentation. As a result, ABM often struggles to deeply uncover the governing operational principles. Unlike conventional scenario analysis that relies on human reasoning, computational experiments emphasize counterfactual experiments-that is, creating parallel worlds that simulate alternative "evolutionary paths" of real-world events. By systematically adjusting input variables and observing the resulting changes in output variables, computational experiments provide a robust tool for causal inference, thereby addressing the limitations of traditional ABM. Together, these methods offer causal insights into the dynamic evolution of systems. This part can help readers gain a preliminary understanding of the entire computational experiment method, laying the foundation for the subsequent study.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14296v1</guid></item><item><title>[cs updates on arXiv.org] Guardrails for trust, safety, and ethical development and deployment of Large Language Models (LLM)</title><link>https://arxiv.org/abs/2601.14298</link><description>arXiv:2601.14298v1 Announce Type: new 
Abstract: The AI era has ushered in Large Language Models (LLM) to the technological forefront, which has been much of the talk in 2023, and is likely to remain as such for many years to come. LLMs are the AI models that are the power house behind generative AI applications such as ChatGPT. These AI models, fueled by vast amounts of data and computational prowess, have unlocked remarkable capabilities, from human-like text generation to assisting with natural language understanding (NLU) tasks. They have quickly become the foundation upon which countless applications and software services are being built, or at least being augmented with. However, as with any groundbreaking innovations, the rise of LLMs brings forth critical safety, privacy, and ethical concerns. These models are found to have a propensity to leak private information, produce false information, and can be coerced into generating content that can be used for nefarious purposes by bad actors, or even by regular users unknowingly. Implementing safeguards and guardrailing techniques is imperative for applications to ensure that the content generated by LLMs are safe, secure, and ethical. Thus, frameworks to deploy mechanisms that prevent misuse of these models via application implementations is imperative. In this study, wepropose a Flexible Adaptive Sequencing mechanism with trust and safety modules, that can be used to implement safety guardrails for the development and deployment of LLMs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14298v1</guid></item><item><title>[cs updates on arXiv.org] Predicting Tail-Risk Escalation in IDS Alert Time Series</title><link>https://arxiv.org/abs/2601.14299</link><description>arXiv:2601.14299v1 Announce Type: new 
Abstract: Network defenders face a steady stream of attacks, observed as raw Intrusion Detection System (IDS) alerts. The sheer volume of alerts demands prioritization, typically based on high-level risk classifications. This work expands the scope of risk measurement by examining alerts not only through their technical characteristics but also by examining and classifying their temporal patterns. One critical issue in responding to intrusion alerts is determining whether an alert is part of an escalating attack pattern or an opportunistic scan. To identify the former, we apply extreme-regime forecasting methods from financial modeling to IDS data. Extreme-regime forecasting is designed to identify likely future high-impact events or significant shifts in system behavior. Using these methods, we examine attack patterns by computing per-minute alert intensity, volatility, and a short-term momentum measure derived from weighted moving averages.
  We evaluate the efficacy of a supervised learning model for forecasting future escalation patterns using these derived features. The trained model identifies future high-intensity attacks and demonstrates strong predictive performance, achieving approximately 91\% accuracy, 89\% recall, and 98\% precision. Our contributions provide a temporal measurement framework for identifying future high-intensity attacks and demonstrate the presence of predictive early-warning signals within the temporal structure of IDS alert streams. We describe our methods in sufficient detail to enable reproduction using other IDS datasets. In addition, we make the trained models openly available to support further research. Finally, we introduce an interpretable visualization that enables defenders to generate early predictive warnings of elevated volumetric arrival risk.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14299v1</guid></item><item><title>[cs updates on arXiv.org] Gradient Structure Estimation under Label-Only Oracles via Spectral Sensitivity</title><link>https://arxiv.org/abs/2601.14300</link><description>arXiv:2601.14300v1 Announce Type: new 
Abstract: Hard-label black-box settings, where only top-1 predicted labels are observable, pose a fundamentally constrained yet practically important feedback model for understanding model behavior. A central challenge in this regime is whether meaningful gradient information can be recovered from such discrete responses. In this work, we develop a unified theoretical perspective showing that a wide range of existing sign-flipping hard-label attacks can be interpreted as implicitly approximating the sign of the true loss gradient. This observation reframes hard-label attacks from heuristic search procedures into instances of gradient sign recovery under extremely limited feedback. Motivated by this first-principles understanding, we propose a new attack framework that combines a zero-query frequency-domain initialization with a Pattern-Driven Optimization (PDO) strategy. We establish theoretical guarantees demonstrating that, under mild assumptions, our initialization achieves higher expected cosine similarity to the true gradient sign compared to random baselines, while the proposed PDO procedure attains substantially lower query complexity than existing structured search approaches. We empirically validate our framework through extensive experiments on CIFAR-10, ImageNet, and ObjectNet, covering standard and adversarially trained models, commercial APIs, and CLIP-based models. The results show that our method consistently surpasses SOTA hard-label attacks in both attack success rate and query efficiency, particularly in low-query regimes. Beyond image classification, our approach generalizes effectively to corrupted data, biomedical datasets, and dense prediction tasks. Notably, it also successfully circumvents Blacklight, a SOTA stateful defense, resulting in a $0\%$ detection rate. Our code will be released publicly soon at https://github.com/csjunjun/DPAttack.git.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14300v1</guid></item><item><title>[cs updates on arXiv.org] DDSA: Dual-Domain Strategic Attack for Spatial-Temporal Efficiency in Adversarial Robustness Testing</title><link>https://arxiv.org/abs/2601.14302</link><description>arXiv:2601.14302v1 Announce Type: new 
Abstract: Image transmission and processing systems in resource-critical applications face significant challenges from adversarial perturbations that compromise mission-specific object classification. Current robustness testing methods require excessive computational resources through exhaustive frame-by-frame processing and full-image perturbations, proving impractical for large-scale deployments where massive image streams demand immediate processing. This paper presents DDSA (Dual-Domain Strategic Attack), a resource-efficient adversarial robustness testing framework that optimizes testing through temporal selectivity and spatial precision. We introduce a scenario-aware trigger function that identifies critical frames requiring robustness evaluation based on class priority and model uncertainty, and employ explainable AI techniques to locate influential pixel regions for targeted perturbation. Our dual-domain approach achieves substantial temporal-spatial resource conservation while maintaining attack effectiveness. The framework enables practical deployment of comprehensive adversarial robustness testing in resource-constrained real-time applications where computational efficiency directly impacts mission success.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14302v1</guid></item><item><title>[cs updates on arXiv.org] Guided by the Plan: Enhancing Faithful Autoregressive Text-to-Audio Generation with Guided Decoding</title><link>https://arxiv.org/abs/2601.14304</link><description>arXiv:2601.14304v1 Announce Type: new 
Abstract: Autoregressive (AR) models excel at generating temporally coherent audio by producing tokens sequentially, yet they often falter in faithfully following complex textual prompts, especially those describing complex sound events. We uncover a surprising capability in AR audio generators: their early prefix tokens implicitly encode global semantic attributes of the final output, such as event count and sound-object category, revealing a form of implicit planning. Building on this insight, we propose Plan-Critic, a lightweight auxiliary model trained with a Generalized Advantage Estimation (GAE)-inspired objective to predict final instruction-following quality from partial generations. At inference time, Plan-Critic enables guided exploration: it evaluates candidate prefixes early, prunes low-fidelity trajectories, and reallocates computation to high-potential planning seeds. Our Plan-Critic-guided sampling achieves up to a 10-point improvement in CLAP score over the AR baseline-establishing a new state of the art in AR text-to-audio generation-while maintaining computational parity with standard best-of-N decoding. This work bridges the gap between causal generation and global semantic alignment, demonstrating that even strictly autoregressive models can plan ahead.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14304v1</guid></item><item><title>[cs updates on arXiv.org] An Optimized Decision Tree-Based Framework for Explainable IoT Anomaly Detection</title><link>https://arxiv.org/abs/2601.14305</link><description>arXiv:2601.14305v1 Announce Type: new 
Abstract: The increase in the number of Internet of Things (IoT) devices has tremendously increased the attack surface of cyber threats thus making a strong intrusion detection system (IDS) with a clear explanation of the process essential towards resource-constrained environments. Nevertheless, current IoT IDS systems are usually traded off with detection quality, model elucidability, and computational effectiveness, thus the deployment on IoT devices. The present paper counteracts these difficulties by suggesting an explainable AI (XAI) framework based on an optimized Decision Tree classifier with both local and global importance methods: SHAP values that estimate feature attribution using local explanations, and Morris sensitivity analysis that identifies the feature importance in a global view. The proposed system attains the state of art on the test performance with 99.91% accuracy, F1-score of 99.51% and Cohen Kappa of 0.9960 and high stability is confirmed by a cross validation mean accuracy of 98.93%. Efficiency is also enhanced in terms of computations to provide faster inferences compared to those that are generalized in ensemble models. SrcMac has shown as the most significant predictor in feature analyses according to SHAP and Morris methods. Compared to the previous work, our solution eliminates its major drawback lack because it allows us to apply it to edge devices and, therefore, achieve real-time processing, adhere to the new regulation of transparency in AI, and achieve high detection rates on attacks of dissimilar classes. This combination performance of high accuracy, explainability, and low computation make the framework useful and reliable as a resource-constrained IoT security problem in real environments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14305v1</guid></item><item><title>[cs updates on arXiv.org] CORVUS: Red-Teaming Hallucination Detectors via Internal Signal Camouflage in Large Language Models</title><link>https://arxiv.org/abs/2601.14310</link><description>arXiv:2601.14310v1 Announce Type: new 
Abstract: Single-pass hallucination detectors rely on internal telemetry (e.g., uncertainty, hidden-state geometry, and attention) of large language models, implicitly assuming hallucinations leave separable traces in these signals. We study a white-box, model-side adversary that fine-tunes lightweight LoRA adapters on the model while keeping the detector fixed, and introduce CORVUS, an efficient red-teaming procedure that learns to camouflage detector-visible telemetry under teacher forcing, including an embedding-space FGSM attention stress test. Trained on 1,000 out-of-distribution Alpaca instructions (&lt;0.5% trainable parameters), CORVUS transfers to FAVA-Annotation across Llama-2, Vicuna, Llama-3, and Qwen2.5, and degrades both training-free detectors (e.g., LLM-Check) and probe-based detectors (e.g., SEP, ICR-probe), motivating adversary-aware auditing that incorporates external grounding or cross-model evidence.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14310v1</guid></item><item><title>[cs updates on arXiv.org] Tracing the Data Trail: A Survey of Data Provenance, Transparency and Traceability in LLMs</title><link>https://arxiv.org/abs/2601.14311</link><description>arXiv:2601.14311v1 Announce Type: new 
Abstract: Large language models (LLMs) are deployed at scale, yet their training data life cycle remains opaque. This survey synthesizes research from the past ten years on three tightly coupled axes: (1) data provenance, (2) transparency, and (3) traceability, and three supporting pillars: (4) bias \&amp; uncertainty, (5) data privacy, and (6) tools and techniques that operationalize them. A central contribution is a proposed taxonomy defining the field's domains and listing corresponding artifacts. Through analysis of 95 publications, this work identifies key methodologies concerning data generation, watermarking, bias measurement, data curation, data privacy, and the inherent trade-off between transparency and opacity.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14311v1</guid></item><item><title>[cs updates on arXiv.org] Convergence of finite element right-hand-side computation from finite difference data</title><link>https://arxiv.org/abs/2601.14320</link><description>arXiv:2601.14320v1 Announce Type: new 
Abstract: This work presents two integration methods for field transfer in computational aeroacoustics and in coupled field problems, using the finite element method to solve the acoustic field. Firstly, a high-order Gaussian quadrature computes the finite element right-hand side. In contrast, the (flow) field provided by the finite difference mesh is mapped by higher-order B-Splines or a Lagrangian function. Secondly, the cut-cell or supermesh integration with geometric clipping. For each method, the accuracy, performance characteristics, and computational complexity are analyzed. As a reference, the trapezoidal integration rule was computed from the finite difference results. The high-order quadrature converges as the B-Spline interpolation order increases, and the finite difference results and mesh resolutions are consistent. The supermesh approach eliminates interpolation and approximation errors at the grid-to-mesh level and improves accuracy. This behaviour is universal for smooth or strongly oscillating field quantities, which will be shown in a comparative study between the Lighthill-like source term and the source term of the perturbed convective wave equation for subsonic flows.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14320v1</guid></item><item><title>[cs updates on arXiv.org] SilentDrift: Exploiting Action Chunking for Stealthy Backdoor Attacks on Vision-Language-Action Models</title><link>https://arxiv.org/abs/2601.14323</link><description>arXiv:2601.14323v1 Announce Type: new 
Abstract: Vision-Language-Action (VLA) models are increasingly deployed in safety-critical robotic applications, yet their security vulnerabilities remain underexplored. We identify a fundamental security flaw in modern VLA systems: the combination of action chunking and delta pose representations creates an intra-chunk visual open-loop. This mechanism forces the robot to execute K-step action sequences, allowing per-step perturbations to accumulate through integration. We propose SILENTDRIFT, a stealthy black-box backdoor attack exploiting this vulnerability. Our method employs the Smootherstep function to construct perturbations with guaranteed C2 continuity, ensuring zero velocity and acceleration at trajectory boundaries to satisfy strict kinematic consistency constraints. Furthermore, our keyframe attack strategy selectively poisons only the critical approach phase, maximizing impact while minimizing trigger exposure. The resulting poisoned trajectories are visually indistinguishable from successful demonstrations. Evaluated on the LIBERO, SILENTDRIFT achieves a 93.2% Attack Success Rate with a poisoning rate under 2%, while maintaining a 95.3% Clean Task Success Rate.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14323v1</guid></item><item><title>[cs updates on arXiv.org] When Generative AI Is Intimate, Sexy, and Violent: Examining Not-Safe-For-Work (NSFW) Chatbots on FlowGPT</title><link>https://arxiv.org/abs/2601.14324</link><description>arXiv:2601.14324v1 Announce Type: new 
Abstract: User-created chatbots powered by generative AI offer new ways to share and interact with Not-Safe-For-Work (NSFW) content. However, little is known about the characteristics of these GenAI-based chatbots and their user interactions. Drawing on the functional theory of NSFW on social media, this study analyzes 376 NSFW chatbots and 307 public conversation sessions on FlowGPT. Findings identify four chatbot types: roleplay characters, story generators, image generators, and do-anything-now bots. AI Characters portraying fantasy personas and enabling hangout-style interactions are most common, often using explicit avatar images to invite engagement. Sexual, violent, and insulting content appears in both user prompts and chatbot outputs, with some chatbots generating explicit material even when users do not create erotic prompts. In sum, the NSFW experience on FlowGPT can be understood as a combination of virtual intimacy, sexual delusion, violent thought expression, and unsafe content acquisition. We conclude with implications for chatbot design, creator support, user safety, and content moderation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14324v1</guid></item><item><title>[cs updates on arXiv.org] Layer-adaptive Expert Pruning for Pre-Training of Mixture-of-Experts Large Language Models</title><link>https://arxiv.org/abs/2601.14327</link><description>arXiv:2601.14327v1 Announce Type: new 
Abstract: Although Mixture-of-Experts (MoE) Large Language Models (LLMs) deliver superior accuracy with a reduced number of active parameters, their pre-training represents a significant computationally bottleneck due to underutilized experts and limited training efficiency. This work introduces a Layer-Adaptive Expert Pruning (LAEP) algorithm designed for the pre-training stage of MoE LLMs. In contrast to previous expert pruning approaches that operate primarily in the post-training phase, the proposed algorithm enhances training efficiency by selectively pruning underutilized experts and reorganizing experts across computing devices according to token distribution statistics. Comprehensive experiments demonstrate that LAEP effectively reduces model size and substantially improves pre-training efficiency. In particular, when pre-training the 1010B Base model from scratch, LAEP achieves a 48.3\% improvement in training efficiency alongside a 33.3% parameter reduction, while still delivering excellent performance across multiple domains.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14327v1</guid></item><item><title>[cs updates on arXiv.org] LURE: Latent Space Unblocking for Multi-Concept Reawakening in Diffusion Models</title><link>https://arxiv.org/abs/2601.14330</link><description>arXiv:2601.14330v1 Announce Type: new 
Abstract: Concept erasure aims to suppress sensitive content in diffusion models, but recent studies show that erased concepts can still be reawakened, revealing vulnerabilities in erasure methods. Existing reawakening methods mainly rely on prompt-level optimization to manipulate sampling trajectories, neglecting other generative factors, which limits a comprehensive understanding of the underlying dynamics. In this paper, we model the generation process as an implicit function to enable a comprehensive theoretical analysis of multiple factors, including text conditions, model parameters, and latent states. We theoretically show that perturbing each factor can reawaken erased concepts. Building on this insight, we propose a novel concept reawakening method: Latent space Unblocking for concept REawakening (LURE), which reawakens erased concepts by reconstructing the latent space and guiding the sampling trajectory. Specifically, our semantic re-binding mechanism reconstructs the latent space by aligning denoising predictions with target distributions to reestablish severed text-visual associations. However, in multi-concept scenarios, naive reconstruction can cause gradient conflicts and feature entanglement. To address this, we introduce Gradient Field Orthogonalization, which enforces feature orthogonality to prevent mutual interference. Additionally, our Latent Semantic Identification-Guided Sampling (LSIS) ensures stability of the reawakening process via posterior density verification. Extensive experiments demonstrate that LURE enables simultaneous, high-fidelity reawakening of multiple erased concepts across diverse erasure tasks and methods.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14330v1</guid></item><item><title>[cs updates on arXiv.org] Predicting Long-Term Self-Rated Health in Small Areas Using Ordinal Regression and Microsimulation</title><link>https://arxiv.org/abs/2601.14335</link><description>arXiv:2601.14335v1 Announce Type: new 
Abstract: This paper presents an approach for predicting the self-rated health of individuals in a future population utilising the individuals' socio-economic characteristics. An open-source microsimulation is used to project Ireland's population into the future where each individual is defined by a number of demographic and socio-economic characteristics. The model is disaggregated spatially at the Electoral Division level, allowing for analysis of results at that, or any broader geographical scales. Ordinal regression is utilised to predict an individual's self-rated health based on their socio-economic characteristics and this method is shown to match well to Ireland's 2022 distribution of health statuses. Due to differences in the health status distributions of the health microdata and the national data, an alignment technique is proposed to bring predictions closer to real values. It is illustrated for one potential future population that the effects of an ageing population may outweigh other improvements in socio-economic outcomes to disimprove Ireland's mean self-rated health slightly. Health modelling at this kind of granular scale could offer local authorities a chance to predict and combat health issues which may arise in their local populations in the future.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14335v1</guid></item><item><title>[cs updates on arXiv.org] Log anomaly detection via Meta Learning and Prototypical Networks for Cross domain generalization</title><link>https://arxiv.org/abs/2601.14336</link><description>arXiv:2601.14336v1 Announce Type: new 
Abstract: Log anomaly detection is essential for system reliability, but it is extremely challenging to do considering it involves class imbalance. Additionally, the models trained in one domain are not applicable to other domains, necessitating the need for cross-domain adaptation (such as HDFS and Linux). Traditional detection models often fail to generalize due to significant data drift and the inherent absence of labeled anomalies in new target domains. To handle the above challenges, we proposed a new end-to-end framework based on a meta-learning approach. Our methodology first gets the data ready by combining a Drain3 log parsing mechanism with a dynamic drift-based labeling technique that uses semantic and fuzzy matching to move existing anomaly knowledge from one source to another. BERT-based semantic embeddings are obtained, and the feature selection is invoked to reduce the dimensionality. Later, Model Agnostic Meta-Learning (MAML) and Prototypical Networks models are trained to adapt quickly and effectively. The SMOTE oversampling method is employed to handle imbalances in the data. All the results are obtained by employing the leave-one-out source method, and the corresponding mean F1 scores are reported. Our empirical findings validate that the proposed meta-learning-driven approach yielded the highest mean F1 score and proved to be effective for cross-domain settings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14336v1</guid></item><item><title>[cs updates on arXiv.org] CityCube: Benchmarking Cross-view Spatial Reasoning on Vision-Language Models in Urban Environments</title><link>https://arxiv.org/abs/2601.14339</link><description>arXiv:2601.14339v1 Announce Type: new 
Abstract: Cross-view spatial reasoning is essential for embodied AI, underpinning spatial understanding, mental simulation and planning in complex environments. Existing benchmarks primarily emphasize indoor or street settings, overlooking the unique challenges of open-ended urban spaces characterized by rich semantics, complex geometries, and view variations. To address this, we introduce CityCube, a systematic benchmark designed to probe cross-view reasoning capabilities of current VLMs in urban settings. CityCube integrates four viewpoint dynamics to mimic camera movements and spans a wide spectrum of perspectives from multiple platforms, e.g., vehicles, drones and satellites. For a comprehensive assessment, it features 5,022 meticulously annotated multi-view QA pairs categorized into five cognitive dimensions and three spatial relation expressions. A comprehensive evaluation of 33 VLMs reveals a significant performance disparity with humans: even large-scale models struggle to exceed 54.1% accuracy, remaining 34.2% below human performance. By contrast, small-scale fine-tuned VLMs achieve over 60.0% accuracy, highlighting the necessity of our benchmark. Further analyses indicate the task correlations and fundamental cognitive disparity between VLMs and human-like reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14339v1</guid></item><item><title>[cs updates on arXiv.org] Turn-Based Structural Triggers: Prompt-Free Backdoors in Multi-Turn LLMs</title><link>https://arxiv.org/abs/2601.14340</link><description>arXiv:2601.14340v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are widely integrated into interactive systems such as dialogue agents and task-oriented assistants. This growing ecosystem also raises supply-chain risks, where adversaries can distribute poisoned models that degrade downstream reliability and user trust. Existing backdoor attacks and defenses are largely prompt-centric, focusing on user-visible triggers while overlooking structural signals in multi-turn conversations. We propose Turn-based Structural Trigger (TST), a backdoor attack that activates from dialogue structure, using the turn index as the trigger and remaining independent of user inputs. Across four widely used open-source LLM models, TST achieves an average attack success rate (ASR) of 99.52% with minimal utility degradation, and remains effective under five representative defenses with an average ASR of 98.04%. The attack also generalizes well across instruction datasets, maintaining an average ASR of 99.19%. Our results suggest that dialogue structure constitutes an important and under-studied attack surface for multi-turn LLM systems, motivating structure-aware auditing and mitigation in practice.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14340v1</guid></item><item><title>[cs updates on arXiv.org] Rethinking On-Device LLM Reasoning: Why Analogical Mapping Outperforms Abstract Thinking for IoT DDoS Detection</title><link>https://arxiv.org/abs/2601.14343</link><description>arXiv:2601.14343v1 Announce Type: new 
Abstract: The rapid expansion of IoT deployments has intensified cybersecurity threats, notably Distributed Denial of Service (DDoS) attacks, characterized by increasingly sophisticated patterns. Leveraging Generative AI through On-Device Large Language Models (ODLLMs) provides a viable solution for real-time threat detection at the network edge, though limited computational resources present challenges for smaller ODLLMs. This paper introduces a novel detection framework that integrates Chain-of-Thought (CoT) reasoning with Retrieval-Augmented Generation (RAG), tailored specifically for IoT edge environments. We systematically evaluate compact ODLLMs, including LLaMA 3.2 (1B, 3B) and Gemma 3 (1B, 4B), using structured prompting and exemplar-driven reasoning strategies. Experimental results demonstrate substantial performance improvements with few-shot prompting, achieving macro-average F1 scores as high as 0.85. Our findings highlight the significant advantages of incorporating exemplar-based reasoning, underscoring that CoT and RAG approaches markedly enhance small ODLLMs' capabilities in accurately classifying complex network attacks under stringent resource constraints.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14343v1</guid></item><item><title>[cs updates on arXiv.org] DiSPA: Differential Substructure-Pathway Attention for Drug Response Prediction</title><link>https://arxiv.org/abs/2601.14346</link><description>arXiv:2601.14346v1 Announce Type: new 
Abstract: Accurate prediction of drug response in precision medicine requires models that capture how specific chemical substructures interact with cellular pathway states. However, most existing deep learning approaches treat chemical and transcriptomic modalities independently or combine them only at late stages, limiting their ability to model fine-grained, context-dependent mechanisms of drug action. In addition, standard attention mechanisms are often sensitive to noise and sparsity in high-dimensional biological networks, hindering both generalization and interpretability. We present DiSPA, a representation learning framework that explicitly disentangles structure-driven and context-driven mechanisms of drug response through bidirectional conditioning between chemical substructures and pathway-level gene expression. DiSPA introduces a differential cross-attention module that suppresses spurious pathway-substructure associations while amplifying contextually relevant interactions. Across multiple evaluation settings on the GDSC benchmark, DiSPA achieves state-of-the-art performance, with particularly strong improvements in the disjoint-set setting, which assesses generalization to unseen drug-cell combinations. Beyond predictive accuracy, DiSPA yields mechanistically informative representations: learned attention patterns recover known pharmacophores, distinguish structure-driven from context-dependent compounds, and exhibit coherent organization across biological pathways. Furthermore, we demonstrate that DiSPA trained solely on bulk RNA-seq data enables zero-shot transfer to spatial transcriptomics, revealing region-specific drug sensitivity patterns without retraining. Together, these results establish DiSPA as a robust and interpretable framework for integrative pharmacogenomic modeling, enabling principled analysis of drug response mechanisms beyond post hoc interpretation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14346v1</guid></item><item><title>[cs updates on arXiv.org] Multi-Partner Project: COIN-3D -- Collaborative Innovation in 3D VLSI Reliability</title><link>https://arxiv.org/abs/2601.14347</link><description>arXiv:2601.14347v1 Announce Type: new 
Abstract: As semiconductor manufacturing advances from the 3-nm process toward the sub-nanometer regime and transitions from FinFETs to gate-all-around field-effect transistors (GAAFETs), the resulting complexity and manufacturing challenges continue to increase. In this context, 3D chiplet-based approaches have emerged as key enablers to address these limitations while exploiting the expanded design space. Specifically, chiplets help address the lower yields typically associated with large monolithic designs. This paradigm enables the modular design of heterogeneous systems consisting of multiple chiplets (e.g., CPUs, GPUs, memory) fabricated using different technology nodes and processes. Consequently, it offers a capable and cost-effective strategy for designing heterogeneous systems. This paper introduces the Horizon Europe Twinning project COIN-3D (Collaborative Innovation in 3D VLSI Reliability), which aims to strengthen research excellence in 2.5D/3D VLSI systems reliability through collaboration between leading European institutions. More specifically, our primary scientific goal is the provision of novel open-source Electronic Design Automation (EDA) tools for reliability assessment of 3D systems, integrating advanced algorithms for physical- and system-level reliability analysis.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14347v1</guid></item><item><title>[cs updates on arXiv.org] Legal Retrieval for Public Defenders</title><link>https://arxiv.org/abs/2601.14348</link><description>arXiv:2601.14348v1 Announce Type: new 
Abstract: AI tools are increasingly suggested as solutions to assist public agencies with heavy workloads. In public defense, where a constitutional right to counsel meets the complexities of law, overwhelming caseloads and constrained resources, practitioners face especially taxing conditions. Yet, there is little evidence of how AI could meaningfully support defenders' day-to-day work. In partnership with the New Jersey Office of the Public Defender, we develop the NJ BriefBank, a retrieval tool which surfaces relevant appellate briefs to streamline legal research and writing. We show that existing legal retrieval benchmarks fail to transfer to public defense search, however adding domain knowledge improves retrieval quality. This includes query expansion with legal reasoning, domain-specific data and curated synthetic examples. To facilitate further research, we provide a taxonomy of realistic defender search queries and release a manually annotated public defense retrieval dataset. Together, our work offers starting points towards building practical, reliable retrieval AI tools for public defense, and towards more realistic legal retrieval benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14348v1</guid></item><item><title>[cs updates on arXiv.org] MARBLE: Multi-Agent Reasoning for Bioinformatics Learning and Evolution</title><link>https://arxiv.org/abs/2601.14349</link><description>arXiv:2601.14349v1 Announce Type: new 
Abstract: Motivation: Developing high-performing bioinformatics models typically requires repeated cycles of hypothesis formulation, architectural redesign, and empirical validation, making progress slow, labor-intensive, and difficult to reproduce. Although recent LLM-based assistants can automate isolated steps, they lack performance-grounded reasoning and stability-aware mechanisms required for reliable, iterative model improvement in bioinformatics workflows. Results: We introduce MARBLE, an execution-stable autonomous model refinement framework for bioinformatics models. MARBLE couples literature-aware reference selection with structured, debate-driven architectural reasoning among role-specialized agents, followed by autonomous execution, evaluation, and memory updates explicitly grounded in empirical performance. Across spatial transcriptomics domain segmentation, drug-target interaction prediction, and drug response prediction, MARBLE consistently achieves sustained performance improvements over strong baselines across multiple refinement cycles, while maintaining high execution robustness and low regression rates. Framework-level analyses demonstrate that structured debate, balanced evidence selection, and performance-grounded memory are critical for stable, repeatable model evolution, rather than single-run or brittle gains. Availability: Source code, data and Supplementary Information are available at https://github.com/PRISM-DGU/MARBLE.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14349v1</guid></item><item><title>[cs updates on arXiv.org] If You Want Coherence, Orchestrate a Team of Rivals: Multi-Agent Models of Organizational Intelligence</title><link>https://arxiv.org/abs/2601.14351</link><description>arXiv:2601.14351v1 Announce Type: new 
Abstract: AI Agents can perform complex operations at great speed, but just like all the humans we have ever hired, their intelligence remains fallible. Miscommunications aren't noticed, systemic biases have no counter-action, and inner monologues are rarely written down.
  We did not come to fire them for their mistakes, but to hire them and provide a safe productive working environment. We posit that we can reuse a common corporate organizational structure: teams of independent AI agents with strict role boundaries can work with common goals, but opposing incentives. Multiple models serving as a team of rivals can catch and minimize errors within the final product at a small cost to the velocity of actions. In this paper we demonstrate that we can achieve reliability without acquiring perfect components, but through careful orchestration of imperfect ones.
  This paper describes the architecture of such a system in practice: specialized agent teams (planners, executors, critics, experts), organized into an organization with clear goals, coordinated through a remote code executor that keeps data transformations and tool invocations separate from reasoning models. Rather than agents directly calling tools and ingesting full responses, they write code that executes remotely; only relevant summaries return to agent context. By preventing raw data and tool outputs from contaminating context windows, the system maintains clean separation between perception (brains that plan and reason) and execution (hands that perform heavy data transformations and API calls). We demonstrate the approach achieves over 90% internal error interception prior to user exposure while maintaining acceptable latency tradeoffs. A survey from our traces shows that we only trade off cost and latency to achieve correctness and incrementally expand capabilities without impacting existing ones.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14351v1</guid></item><item><title>[cs updates on arXiv.org] RoboBrain 2.5: Depth in Sight, Time in Mind</title><link>https://arxiv.org/abs/2601.14352</link><description>arXiv:2601.14352v1 Announce Type: new 
Abstract: We introduce RoboBrain 2.5, a next-generation embodied AI foundation model that advances general perception, spatial reasoning, and temporal modeling through extensive training on high-quality spatiotemporal supervision. Building upon its predecessor, RoboBrain 2.5 introduces two major capability upgrades. Specifically, it unlocks Precise 3D Spatial Reasoning by shifting from 2D pixel-relative grounding to depth-aware coordinate prediction and absolute metric constraint comprehension, generating complete 3D manipulation traces as ordered keypoint sequences under physical constraints. Complementing this spatial precision, the model establishes Dense Temporal Value Estimation that provides dense, step-aware progress prediction and execution state understanding across varying viewpoints, producing stable feedback signals for downstream learning. Together, these upgrades extend the framework toward more physically grounded and execution-aware embodied intelligence for complex, fine-grained manipulation. The code and checkpoints are available at project website: https://superrobobrain.github.io</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14352v1</guid></item><item><title>[cs updates on arXiv.org] VJEPA: Variational Joint Embedding Predictive Architectures as Probabilistic World Models</title><link>https://arxiv.org/abs/2601.14354</link><description>arXiv:2601.14354v1 Announce Type: new 
Abstract: Joint Embedding Predictive Architectures (JEPA) offer a scalable paradigm for self-supervised learning by predicting latent representations rather than reconstructing high-entropy observations. However, existing formulations rely on \textit{deterministic} regression objectives, which mask probabilistic semantics and limit its applicability in stochastic control. In this work, we introduce \emph{Variational JEPA (VJEPA)}, a \textit{probabilistic} generalization that learns a predictive distribution over future latent states via a variational objective. We show that VJEPA unifies representation learning with Predictive State Representations (PSRs) and Bayesian filtering, establishing that sequential modeling does not require autoregressive observation likelihoods. Theoretically, we prove that VJEPA representations can serve as sufficient information states for optimal control without pixel reconstruction, while providing formal guarantees for collapse avoidance. We further propose \emph{Bayesian JEPA (BJEPA)}, an extension that factorizes the predictive belief into a learned dynamics expert and a modular prior expert, enabling zero-shot task transfer and constraint (e.g. goal, physics) satisfaction via a Product of Experts. Empirically, through a noisy environment experiment, we demonstrate that VJEPA and BJEPA successfully filter out high-variance nuisance distractors that cause representation collapse in generative baselines. By enabling principled uncertainty estimation (e.g. constructing credible intervals via sampling) while remaining likelihood-free regarding observations, VJEPA provides a foundational framework for scalable, robust, uncertainty-aware planning in high-dimensional, noisy environments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14354v1</guid></item><item><title>[cs updates on arXiv.org] Single-step Controllable Music Bandwidth Extension With Flow Matching</title><link>https://arxiv.org/abs/2601.14356</link><description>arXiv:2601.14356v1 Announce Type: new 
Abstract: Audio restoration consists in inverting degradations of a digital audio signal to recover what would have been the pristine quality signal before the degradation occurred. This is valuable in contexts such as archives of music recordings, particularly those of precious historical value, for which a clean version may have been lost or simply does not exist. Recent work applied generative models to audio restoration, showing promising improvement over previous methods, and opening the door to the ability to perform restoration operations that were not possible before. However, making these models finely controllable remains a challenge. In this paper, we propose an extension of FLowHigh and introduce the Dynamic Spectral Contour (DSC) as a control signal for bandwidth extension via classifier-free guidance. Our experiments show competitive model performance, and indicate that DSC is a promising feature to support fine-grained conditioning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14356v1</guid></item><item><title>[cs updates on arXiv.org] Recursivism: An Artistic Paradigm for Self-Transforming Art in the Age of AI</title><link>https://arxiv.org/abs/2601.14401</link><description>arXiv:2601.14401v1 Announce Type: new 
Abstract: This article introduces Recursivism as a conceptual framework for analyzing contemporary artistic practices in the age of artificial intelligence. While recursion is precisely defined in mathematics and computer science, it has not previously been formalized as an aesthetic paradigm. Recursivism designates practices in which not only outputs vary over time, but in which the generative process itself becomes capable of reflexive modification through its own effects.
  The paper develops a five-level analytical scale distinguishing simple iteration, cumulative iteration, parametric recursion, reflexive recursion, and meta-recursion. This scale clarifies the threshold at which a system shifts from variation within a fixed rule to genuine self-modification of the rule itself. From this perspective, art history is reinterpreted as a recursive dynamic alternating between internal recursion within movements and meta-recursive transformations of their generative principles.
  Artificial intelligence renders this logic technically explicit through learning loops, parameter updates, and code-level self-modification. To distinguish Recursivism from related notions such as generative art, cybernetics, process art, and evolutionary art, the article proposes three operational criteria: state memory, rule evolvability, and reflexive visibility. These concepts are examined through case studies including Refik Anadol, Sougwen Chung, Karl Sims, and the Darwin-Godel Machine. The article concludes by examining the aesthetic, curatorial, and ethical implications of self-modifying artistic systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14401v1</guid></item><item><title>[cs updates on arXiv.org] A Unified Framework for Scalable and Robust Paper Assignment</title><link>https://arxiv.org/abs/2601.14402</link><description>arXiv:2601.14402v1 Announce Type: new 
Abstract: Assigning papers to reviewers is a central challenge in the peer-review process of large academic conferences. Program chairs must balance competing objectives, including maximizing reviewer expertise, promoting diversity, and enhancing robustness to strategic manipulation, but it is challenging to do so at the modern conference scale.
  Existing algorithmic paper assignment approaches either fail to address all of these goals simultaneously or suffer from poor scalability. To address the limitation, we propose Robust Assignment via Marginal Perturbation (RAMP), a unified framework for large-scale peer review. Our approach formulates a linearized perturbed-maximization objective with soft constraints that flexibly balance assignment quality, diversity, and robustness while maintaining runtime efficiency. We further introduce an attribute-aware sampling procedure that converts fractional solutions into integral assignments and improves the diversity and robustness of the final assignment. On datasets with over 20,000 papers and 20,000 reviewers, RAMP runs in under 20 minutes, demonstrating its suitability for real-world deployment.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14402v1</guid></item><item><title>[cs updates on arXiv.org] A low-order hybrid method for the variable-density incompressible Navier-Stokes equations</title><link>https://arxiv.org/abs/2601.14405</link><description>arXiv:2601.14405v1 Announce Type: new 
Abstract: In this work we introduce and analyse a new low-order method for the variable-density incompressible Navier-Stokes equations. The main novelty of the proposed method lies in the support of general meshes, possibly including polygonal or polyhedral elements as well as non-matching interfaces. We carry out a complete analysis, showing stability, existence and uniqueness of a discrete solution, and convergence of the latter to a suitably defined weak solution of the continuous problem. Numerical tests validate the theoretical results.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14405v1</guid></item><item><title>[cs updates on arXiv.org] Large-Scale Label Quality Assessment for Medical Segmentation via a Vision-Language Judge and Synthetic Data</title><link>https://arxiv.org/abs/2601.14406</link><description>arXiv:2601.14406v1 Announce Type: new 
Abstract: Large-scale medical segmentation datasets often combine manual and pseudo-labels of uneven quality, which can compromise training and evaluation. Low-quality labels may hamper performance and make the model training less robust. To address this issue, we propose SegAE (Segmentation Assessment Engine), a lightweight vision-language model (VLM) that automatically predicts label quality across 142 anatomical structures. Trained on over four million image-label pairs with quality scores, SegAE achieves a high correlation coefficient of 0.902 with ground-truth Dice similarity and evaluates a 3D mask in 0.06s. SegAE shows several practical benefits: (I) Our analysis reveals widespread low-quality labeling across public datasets; (II) SegAE improves data efficiency and training performance in active and semi-supervised learning, reducing dataset annotation cost by one-third and quality-checking time by 70% per label. This tool provides a simple and effective solution for quality control in large-scale medical segmentation datasets. The dataset, model weights, and codes are released at https://github.com/Schuture/SegAE.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14406v1</guid></item><item><title>[cs updates on arXiv.org] A Survey of Security Challenges and Solutions for Advanced Air Mobility and eVTOL Aircraft</title><link>https://arxiv.org/abs/2601.14415</link><description>arXiv:2601.14415v1 Announce Type: new 
Abstract: This survey reviews the existing and envisioned security vulnerabilities and defense mechanisms relevant to Advanced Air Mobility (AAM) systems, with a focus on electric vertical takeoff and landing (eVTOL) aircraft. Drawing from vulnerabilities in the avionics in commercial aviation and the automated unmanned aerial systems (UAS), the paper presents a taxonomy of attacks, analyzes mitigation strategies, and proposes a secure system architecture tailored to the future AAM ecosystem. The paper also highlights key threat vectors, including Global Positioning System (GPS) jamming/spoofing, ATC radio frequency misuse, attacks on TCAS and ADS-B, possible backdoor via Electronic Flight Bag (EFB), new vulnerabilities introduced by aircraft automation and connectivity, and risks from flight management system (FMS) software, database and cloud services. Finally, this paper describes emerging defense techniques against these attacks, and open technical problems to address toward better defense mechanisms.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14415v1</guid></item><item><title>[cs updates on arXiv.org] Quantifying Speaker Embedding Phonological Rule Interactions in Accented Speech Synthesis</title><link>https://arxiv.org/abs/2601.14417</link><description>arXiv:2601.14417v1 Announce Type: new 
Abstract: Many spoken languages, including English, exhibit wide variation in dialects and accents, making accent control an important capability for flexible text-to-speech (TTS) models. Current TTS systems typically generate accented speech by conditioning on speaker embeddings associated with specific accents. While effective, this approach offers limited interpretability and controllability, as embeddings also encode traits such as timbre and emotion. In this study, we analyze the interaction between speaker embeddings and linguistically motivated phonological rules in accented speech synthesis. Using American and British English as a case study, we implement rules for flapping, rhoticity, and vowel correspondences. We propose the phoneme shift rate (PSR), a novel metric quantifying how strongly embeddings preserve or override rule-based transformations. Experiments show that combining rules with embeddings yields more authentic accents, while embeddings can attenuate or overwrite rules, revealing entanglement between accent and speaker identity. Our findings highlight rules as a lever for accent control and a framework for evaluating disentanglement in speech generation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14417v1</guid></item><item><title>[cs updates on arXiv.org] Optimising Cylindrical Algebraic Coverings for use in SMT by Solving a Set Covering Problem with Reasons</title><link>https://arxiv.org/abs/2601.14424</link><description>arXiv:2601.14424v1 Announce Type: new 
Abstract: The Conflict-Driven Cylindrical Algebraic Covering algorithm has proven well suited for performing theory validation checks in the satisfiability modulo theories paradigm for non-linear real arithmetic. CDCAC repurposes the theory underpinning classical cylindrical algebraic decomposition for SMT solving and is implemented in the SMT solvers cvc5 and SMT-RAT, as well as the computer algebra system Maple. It was previously observed that when using cylindrical algebraic decomposition for an SMT theory call, the output can be optimised by solving a single set covering problem instance that minimises the conflict clause. In this paper we consider the corresponding optimisation for CDCAC and observe that CDCAC naturally gives rise to multiple such optimisations within a single call. Each time a covering is generalised in one dimension, the resulting cell in the next dimension is labelled with theory constraints that cannot be satisfied together. We seek the smallest subset of constraints whose union covers all labels from the cells in the current covering. We call this optimisation problem a set covering problem with reasons. To simplify this problem, we introduce a data reduction step that generalises Beasley reduction for the classical set covering problem and show that this step alone solves many of the instances arising from SMT-LIB benchmarks. We then propose an exact solver based on linear programming to efficiently solve the remaining cases. Integrating these techniques into CDCAC has the potential to significantly improve SMT solver performance for non-linear real arithmetic problems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14424v1</guid></item><item><title>[cs updates on arXiv.org] Measuring the State of Open Science in Transportation Using Large Language Models</title><link>https://arxiv.org/abs/2601.14429</link><description>arXiv:2601.14429v1 Announce Type: new 
Abstract: Open science initiatives have strengthened scientific integrity and accelerated research progress across many fields, but the state of their practice within transportation research remains under-investigated. Key features of open science, defined here as data and code availability, are difficult to extract due to the inherent complexity of the field. Previous work has either been limited to small-scale studies due to the labor-intensive nature of manual analysis or has relied on large-scale bibliometric approaches that sacrifice contextual richness. This paper introduces an automatic and scalable feature-extraction pipeline to measure data and code availability in transportation research. We employ Large Language Models (LLMs) for this task and validate their performance against a manually curated dataset and through an inter-rater agreement analysis. We applied this pipeline to examine 10,724 research articles published in the Transportation Research Part series of journals between 2019 and 2024. Our analysis found that only 5% of quantitative papers shared a code repository, 4% of quantitative papers shared a data repository, and about 3% of papers shared both, with trends differing across journals, topics, and geographic regions. We found no significant difference in citation counts or review duration between papers that provided data and code and those that did not, suggesting a misalignment between open science efforts and traditional academic metrics. Consequently, encouraging these practices will likely require structural interventions from journals and funding agencies to supplement the lack of direct author incentives. The pipeline developed in this study can be readily scaled to other journals, representing a critical step toward the automated measurement and monitoring of open science practices in transportation research.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14429v1</guid></item><item><title>[cs updates on arXiv.org] CMind: An AI Agent for Localizing C Memory Bugs</title><link>https://arxiv.org/abs/2601.14434</link><description>arXiv:2601.14434v1 Announce Type: new 
Abstract: This demonstration paper presents CMind, an artificial intelligence agent for localizing C memory bugs. The novel aspect to CMind is that it follows steps that we observed human programmers perform during empirical study of those programmers finding memory bugs in C programs. The input to the tool is a C program's source code and a bug report describing the problem. The output is the tool's hypothesis about the reason for the bug and its location. CMind reads the bug report to find potential entry points to the program, then navigates the program's source code, analyzes that source code, and generates a hypothesis location and rationale that fit a template. The tool combines large language model reasoning with guided decision making we encoded to mimic human behavior. The video demonstration is available at https://youtu.be/_vVd0LRvVHI.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14434v1</guid></item><item><title>[cs updates on arXiv.org] Agentic AI Meets Edge Computing in Autonomous UAV Swarms</title><link>https://arxiv.org/abs/2601.14437</link><description>arXiv:2601.14437v1 Announce Type: new 
Abstract: The integration of agentic AI, powered by large language models (LLMs) with autonomous reasoning, planning, and execution, into unmanned aerial vehicle (UAV) swarms opens new operational possibilities and brings the vision of the Internet of Drones closer to reality. However, infrastructure constraints, dynamic environments, and the computational demands of multi-agent coordination limit real-world deployment in high-risk scenarios such as wildfires and disaster response. This paper investigates the integration of LLM-based agentic AI and edge computing to realize scalable and resilient autonomy in UAV swarms. We first discuss three architectures for supporting UAV swarms - standalone, edge-enabled, and edge-cloud hybrid deployment - each optimized for varying autonomy and connectivity levels. Then, a use case for wildfire search and rescue (SAR) is designed to demonstrate the efficiency of the edge-enabled architecture, enabling high SAR coverage, reduced mission completion times, and a higher level of autonomy compared to traditional approaches. Finally, we highlight open challenges in integrating LLMs and edge computing for mission-critical UAV-swarm applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14437v1</guid></item><item><title>[cs updates on arXiv.org] Vision-Based Natural Language Scene Understanding for Autonomous Driving: An Extended Dataset and a New Model for Traffic Scene Description Generation</title><link>https://arxiv.org/abs/2601.14438</link><description>arXiv:2601.14438v1 Announce Type: new 
Abstract: Traffic scene understanding is essential for enabling autonomous vehicles to accurately perceive and interpret their environment, thereby ensuring safe navigation. This paper presents a novel framework that transforms a single frontal-view camera image into a concise natural language description, effectively capturing spatial layouts, semantic relationships, and driving-relevant cues. The proposed model leverages a hybrid attention mechanism to enhance spatial and semantic feature extraction and integrates these features to generate contextually rich and detailed scene descriptions. To address the limited availability of specialized datasets in this domain, a new dataset derived from the BDD100K dataset has been developed, with comprehensive guidelines provided for its construction. Furthermore, the study offers an in-depth discussion of relevant evaluation metrics, identifying the most appropriate measures for this task. Extensive quantitative evaluations using metrics such as CIDEr and SPICE, complemented by human judgment assessments, demonstrate that the proposed model achieves strong performance and effectively fulfills its intended objectives on the newly developed dataset.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14438v1</guid></item><item><title>[cs updates on arXiv.org] VisTIRA: Closing the Image-Text Modality Gap in Visual Math Reasoning via Structured Tool Integration</title><link>https://arxiv.org/abs/2601.14440</link><description>arXiv:2601.14440v1 Announce Type: new 
Abstract: Vision-language models (VLMs) lag behind text-only language models on mathematical reasoning when the same problems are presented as images rather than text. We empirically characterize this as a modality gap: the same question in text form yields markedly higher accuracy than its visually typeset counterpart, due to compounded failures in reading dense formulas, layout, and mixed symbolic-diagrammatic context. First, we introduce VisTIRA (Vision and Tool-Integrated Reasoning Agent), a tool-integrated reasoning framework that enables structured problem solving by iteratively decomposing a given math problem (as an image) into natural language rationales and executable Python steps to determine the final answer. Second, we build a framework to measure and improve visual math reasoning: a LaTeX-based pipeline that converts chain-of-thought math corpora (e.g., NuminaMath) into challenging image counterparts, and a large set of synthetic tool-use trajectories derived from a real-world, homework-style image dataset (called SnapAsk) for fine-tuning VLMs. Our experiments show that tool-integrated supervision improves image-based reasoning, and OCR grounding can further narrow the gap for smaller models, although its benefit diminishes at scale. These findings highlight that modality gap severity inversely correlates with model size, and that structured reasoning and OCR-based grounding are complementary strategies for advancing visual mathematical reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14440v1</guid></item><item><title>[cs updates on arXiv.org] Diffusion Large Language Models for Black-Box Optimization</title><link>https://arxiv.org/abs/2601.14446</link><description>arXiv:2601.14446v1 Announce Type: new 
Abstract: Offline black-box optimization (BBO) aims to find optimal designs based solely on an offline dataset of designs and their labels. Such scenarios frequently arise in domains like DNA sequence design and robotics, where only a few labeled data points are available. Traditional methods typically rely on task-specific proxy or generative models, overlooking the in-context learning capabilities of pre-trained large language models (LLMs). Recent efforts have adapted autoregressive LLMs to BBO by framing task descriptions and offline datasets as natural language prompts, enabling direct design generation. However, these designs often contain bidirectional dependencies, which left-to-right models struggle to capture. In this paper, we explore diffusion LLMs for BBO, leveraging their bidirectional modeling and iterative refinement capabilities. This motivates our in-context denoising module: we condition the diffusion LLM on the task description and the offline dataset, both formatted in natural language, and prompt it to denoise masked designs into improved candidates. To guide the generation toward high-performing designs, we introduce masked diffusion tree search, which casts the denoising process as a step-wise Monte Carlo Tree Search that dynamically balances exploration and exploitation. Each node represents a partially masked design, each denoising step is an action, and candidates are evaluated via expected improvement under a Gaussian Process trained on the offline dataset. Our method, dLLM, achieves state-of-the-art results in few-shot settings on design-bench.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14446v1</guid></item><item><title>[cs updates on arXiv.org] Gaussian Based Adaptive Multi-Modal 3D Semantic Occupancy Prediction</title><link>https://arxiv.org/abs/2601.14448</link><description>arXiv:2601.14448v1 Announce Type: new 
Abstract: The sparse object detection paradigm shift towards dense 3D semantic occupancy prediction is necessary for dealing with long-tail safety challenges for autonomous vehicles. Nonetheless, the current voxelization methods commonly suffer from excessive computation complexity demands, where the fusion process is brittle, static, and breaks down under dynamic environmental settings. To this end, this research work enhances a novel Gaussian-based adaptive camera-LiDAR multimodal 3D occupancy prediction model that seamlessly bridges the semantic strengths of camera modality with the geometric strengths of LiDAR modality through a memory-efficient 3D Gaussian model. The proposed solution has four key components: (1) LiDAR Depth Feature Aggregation (LDFA), where depth-wise deformable sampling is employed for dealing with geometric sparsity, (2) Entropy-Based Feature Smoothing, where cross-entropy is employed for handling domain-specific noise, (3) Adaptive Camera-LiDAR Fusion, where dynamic recalibration of sensor outputs is performed based on model outputs, and (4) Gauss-Mamba Head that uses Selective State Space Models for global context decoding that enjoys linear computation complexity.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14448v1</guid></item><item><title>[cs updates on arXiv.org] Unpacking Security Scanners for GitHub Actions Workflows</title><link>https://arxiv.org/abs/2601.14455</link><description>arXiv:2601.14455v1 Announce Type: new 
Abstract: GitHub Actions is a widely used platform that allows developers to automate the build and deployment of their projects through configurable workflows. As the platform's popularity continues to grow, it has become a target of choice for recent software supply chain attacks. These attacks exploit excessive permissions, ambiguous versions, or the absence of artifact integrity checks to compromise workflows. In response to these attacks, several security scanners have emerged to help developers harden their workflows.
  In this paper, we perform the first systematic comparison of 9 GitHub Actions workflow security scanners. We compare them in terms of scope (which security weaknesses they target), detection capabilities (how many weaknesses they detect), and usability (how long they take to scan a workflow). To compare scanners on a common ground, we first establish a taxonomy of 10 security weaknesses that can occur in GitHub Actions workflows. Then, we run the scanners against a curated set of 596 workflows.
  Our study reveals that the landscape of GitHub Actions workflow security scanners is diverse, with both broad-scope tools and very focused ones. More importantly, we show that scanners interpret security weaknesses differently, leading to significant differences in the type and number of reported weaknesses. Based on this empirical evidence, we make actionable recommendations for developers to harden their GitHub Actions workflows.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14455v1</guid></item><item><title>[cs updates on arXiv.org] On the Generalization Gap in LLM Planning: Tests and Verifier-Reward RL</title><link>https://arxiv.org/abs/2601.14456</link><description>arXiv:2601.14456v1 Announce Type: new 
Abstract: Recent work shows that fine-tuned Large Language Models (LLMs) can achieve high valid plan rates on PDDL planning tasks. However, it remains unclear whether this reflects transferable planning competence or domain-specific memorization. In this work, we fine-tune a 1.7B-parameter LLM on 40,000 domain-problem-plan tuples from 10 IPC 2023 domains, and evaluate both in-domain and cross-domain generalization. While the model reaches 82.9% valid plan rate in in-domain conditions, it achieves 0% on two unseen domains. To analyze this failure, we introduce three diagnostic interventions, namely (i) instance-wise symbol anonymization, (ii) compact plan serialization, and (iii) verifier-reward fine-tuning using the VAL validator as a success-focused reinforcement signal. Symbol anonymization and compact serialization cause significant performance drops despite preserving plan semantics, thus revealing strong sensitivity to surface representations. Verifier-reward fine-tuning reaches performance saturation in half the supervised training epochs, but does not improve cross-domain generalization. For the explored configurations, in-domain performance plateaus around 80%, while cross-domain performance collapses, suggesting that our fine-tuned model relies heavily on domain-specific patterns rather than transferable planning competence in this setting. Our results highlight a persistent generalization gap in LLM-based planning and provide diagnostic tools for studying its causes.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14456v1</guid></item><item><title>[cs updates on arXiv.org] Trust Me on This: A User Study of Trustworthiness for RAG Responses</title><link>https://arxiv.org/abs/2601.14460</link><description>arXiv:2601.14460v1 Announce Type: new 
Abstract: The integration of generative AI into information access systems often presents users with synthesized answers that lack transparency. This study investigates how different types of explanations can influence user trust in responses from retrieval-augmented generation systems. We conducted a controlled, two-stage user study where participants chose the more trustworthy response from a pair-one objectively higher quality than the other-both with and without one of three explanation types: (1) source attribution, (2) factual grounding, and (3) information coverage. Our results show that while explanations significantly guide users toward selecting higher quality responses, trust is not dictated by objective quality alone: Users' judgments are also heavily influenced by response clarity, actionability, and their own prior knowledge.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14460v1</guid></item><item><title>[cs updates on arXiv.org] Variance Reduction in the Fokker-Planck Particle Method for Rarefied Gases using Quasi-Random Numbers</title><link>https://arxiv.org/abs/2601.14461</link><description>arXiv:2601.14461v1 Announce Type: new 
Abstract: The Fokker-Planck (FP) particle method accelerates rarefied-gas simulations by replacing the binary collisions of the commonly used Direct Simulation Monte Carlo (DSMC) method with a drift=diffusion process. Like all particle methods, the FP method is inherently stochastic, which leads to statistical fluctuations in macroscopic quantities and necessitates large particle numbers for accurate results. In this work, we investigate the use of quasi-random numbers, which sample distributions more evenly and thereby reduce the variance. To preserve the low-discrepancy structure across time steps, we employ the Array Randomized Quasi-Monte Carlo (Array-RQMC) technique. We combine the FP method with Array-RQMC and compare it in homogeneous and inhomogeneous problems with other commonly used variance-reduction techniques. The proposed FP-Array-RQMC approach achieves improved convergence rates compared with pseudo-random sampling and yields smaller estimator errors for sufficiently large particle numbers.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14461v1</guid></item><item><title>[cs updates on arXiv.org] All-Pass Fractional OPF: A Solver-Friendly, Physics-Preserving Approximation of AC OPF</title><link>https://arxiv.org/abs/2601.14468</link><description>arXiv:2601.14468v1 Announce Type: new 
Abstract: This paper presents a fractional approximation of the AC optimal power flow (AC OPF) problem based on an all-pass approximation of the exponential power flow kernel. The classical AC OPF relies on trigonometric coupling between bus voltage phasors, which yields a nonconvex program with oscillatory derivatives that can slow, or in some cases destabilize, interior-point methods. We replace the trigonometric terms with an all-pass fractional (APF) approximation whose real and imaginary components act as smooth surrogates for the cosine and sine functions, and we introduce a pre-rotation to shift the argument of the approximation toward its most accurate region, ensuring that the reformulated power flow model preserves physical loss behavior, maintains the symmetry of the classical kernels, and improves the conditioning of the Jacobian and Hessian matrices. The proposed APF OPF formulation remains nonconvex, as in the classical model, but it eliminates trigonometric evaluations and empirically produces larger and more stable Newton steps under standard interior-point solvers. Numerical results on more than 25 IEEE and PGLib test systems ranging from 9 to 10{,}000 buses demonstrate that the APF OPF model achieves solutions with accuracy comparable to that of the classical formulation while reducing solver times, indicating a more solver-friendly nonconvex representation of AC OPF. All code, functions, verification scripts, and generated results are publicly available on \href{https://github.com/LSU-RAISE-LAB/APF-OPF}{GitHub}, along with a README describing how to run and reproduce the experiments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14468v1</guid></item><item><title>[cs updates on arXiv.org] Tokenomics: Quantifying Where Tokens Are Used in Agentic Software Engineering</title><link>https://arxiv.org/abs/2601.14470</link><description>arXiv:2601.14470v1 Announce Type: new 
Abstract: LLM-based Multi-Agent (LLM-MA) systems are increasingly applied to automate complex software engineering tasks such as requirements engineering, code generation, and testing. However, their operational efficiency and resource consumption remain poorly understood, hindering practical adoption due to unpredictable costs and environmental impact. To address this, we conduct an analysis of token consumption patterns in an LLM-MA system within the Software Development Life Cycle (SDLC), aiming to understand where tokens are consumed across distinct software engineering activities. We analyze execution traces from 30 software development tasks performed by the ChatDev framework using a GPT-5 reasoning model, mapping its internal phases to distinct development stages (Design, Coding, Code Completion, Code Review, Testing, and Documentation) to create a standardized evaluation framework. We then quantify and compare token distribution (input, output, reasoning) across these stages.
  Our preliminary findings show that the iterative Code Review stage accounts for the majority of token consumption for an average of 59.4% of tokens. Furthermore, we observe that input tokens consistently constitute the largest share of consumption for an average of 53.9%, providing empirical evidence for potentially significant inefficiencies in agentic collaboration. Our results suggest that the primary cost of agentic software engineering lies not in initial code generation but in automated refinement and verification. Our novel methodology can help practitioners predict expenses and optimize workflows, and it directs future research toward developing more token-efficient agent collaboration protocols.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14470v1</guid></item><item><title>[cs updates on arXiv.org] Prosody-Guided Harmonic Attention for Phase-Coherent Neural Vocoding in the Complex Spectrum</title><link>https://arxiv.org/abs/2601.14472</link><description>arXiv:2601.14472v1 Announce Type: new 
Abstract: Neural vocoders are central to speech synthesis; despite their success, most still suffer from limited prosody modeling and inaccurate phase reconstruction. We propose a vocoder that introduces prosody-guided harmonic attention to enhance voiced segment encoding and directly predicts complex spectral components for waveform synthesis via inverse STFT. Unlike mel-spectrogram-based approaches, our design jointly models magnitude and phase, ensuring phase coherence and improved pitch fidelity. To further align with perceptual quality, we adopt a multi-objective training strategy that integrates adversarial, spectral, and phase-aware losses. Experiments on benchmark datasets demonstrate consistent gains over HiFi-GAN and AutoVocoder: F0 RMSE reduced by 22 percent, voiced/unvoiced error lowered by 18 percent, and MOS scores improved by 0.15. These results show that prosody-guided attention combined with direct complex spectrum modeling yields more natural, pitch-accurate, and robust synthetic speech, setting a strong foundation for expressive neural vocoding.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14472v1</guid></item><item><title>[cs updates on arXiv.org] Adaptive KDE for Real-Time Thresholding: Prioritized Queues for Financial Crime Investigation</title><link>https://arxiv.org/abs/2601.14473</link><description>arXiv:2601.14473v1 Announce Type: new 
Abstract: We study the problem of converting a stream of risk scores into one or more review queues under explicit intake constraints[cite: 6]. Instead of top-$K$ or manually tuned cutoffs, we fit an online adaptive kernel density to the score stream, transform the density into a tail-mass curve to meet capacity, and ``snap'' the resulting cut to a persistent density valley detected across bandwidths[cite: 7]. The procedure is label-free, supports multi-queue routing, and operates in real time with sliding windows or exponential forgetting[cite: 8]. On synthetic, drifting, multimodal streams, the method achieves competitive capacity adherence while reducing threshold jitter[cite: 9]. Updates cost $O(G)$ per event with constant memory per activity</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14473v1</guid></item><item><title>[cs updates on arXiv.org] Real-Time Wildfire Localization on the NASA Autonomous Modular Sensor using Deep Learning</title><link>https://arxiv.org/abs/2601.14475</link><description>arXiv:2601.14475v1 Announce Type: new 
Abstract: High-altitude, multi-spectral, aerial imagery is scarce and expensive to acquire, yet it is necessary for algorithmic advances and application of machine learning models to high-impact problems such as wildfire detection. We introduce a human-annotated dataset from the NASA Autonomous Modular Sensor (AMS) using 12-channel, medium to high altitude (3 - 50 km) aerial wildfire images similar to those used in current US wildfire missions. Our dataset combines spectral data from 12 different channels, including infrared (IR), short-wave IR (SWIR), and thermal. We take imagery from 20 wildfire missions and randomly sample small patches to generate over 4000 images with high variability, including occlusions by smoke/clouds, easily-confused false positives, and nighttime imagery.
  We demonstrate results from a deep-learning model to automate the human-intensive process of fire perimeter determination. We train two deep neural networks, one for image classification and the other for pixel-level segmentation. The networks are combined into a unique real-time segmentation model to efficiently localize active wildfire on an incoming image feed. Our model achieves 96% classification accuracy, 74% Intersection-over-Union(IoU), and 84% recall surpassing past methods, including models trained on satellite data and classical color-rule algorithms. By leveraging a multi-spectral dataset, our model is able to detect active wildfire at nighttime and behind clouds, while distinguishing between false positives. We find that data from the SWIR, IR, and thermal bands is the most important to distinguish fire perimeters. Our code and dataset can be found here: https://github.com/nasa/Autonomous-Modular-Sensor-Wildfire-Segmentation/tree/main and https://drive.google.com/drive/folders/1-u4vs9rqwkwgdeeeoUhftCxrfe_4QPTn?=usp=drive_link</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14475v1</guid></item><item><title>[cs updates on arXiv.org] GPU-accelerated simulated annealing based on p-bits with real-world device-variability modeling</title><link>https://arxiv.org/abs/2601.14476</link><description>arXiv:2601.14476v1 Announce Type: new 
Abstract: Probabilistic computing using probabilistic bits (p-bits) presents an efficient alternative to traditional CMOS logic for complex problem-solving, including simulated annealing and machine learning. Realizing p-bits with emerging devices such as magnetic tunnel junctions (MTJs) introduces device variability, which was expected to negatively impact computational performance. However, this study reveals an unexpected finding: device variability can not only degrade but also enhance algorithm performance, particularly by leveraging timing variability. This paper introduces a GPU-accelerated, open-source simulated annealing framework based on p-bits that models key device variability factors -- timing, intensity, and offset -- to reflect real-world device behavior. Through CUDA-based simulations, our approach achieves a two-order magnitude speedup over CPU implementations on the MAX-CUT benchmark with problem sizes ranging from 800 to 20,000 nodes. By providing a scalable and accessible tool, this framework aims to advance research in probabilistic computing, enabling optimization applications in diverse fields.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14476v1</guid></item><item><title>[cs updates on arXiv.org] XD-MAP: Cross-Modal Domain Adaptation using Semantic Parametric Mapping</title><link>https://arxiv.org/abs/2601.14477</link><description>arXiv:2601.14477v1 Announce Type: new 
Abstract: Until open-world foundation models match the performance of specialized approaches, the effectiveness of deep learning models remains heavily dependent on dataset availability. Training data must align not only with the target object categories but also with the sensor characteristics and modalities. To bridge the gap between available datasets and deployment domains, domain adaptation strategies are widely used. In this work, we propose a novel approach to transferring sensor-specific knowledge from an image dataset to LiDAR, an entirely different sensing domain. Our method XD-MAP leverages detections from a neural network on camera images to create a semantic parametric map. The map elements are modeled to produce pseudo labels in the target domain without any manual annotation effort. Unlike previous domain transfer approaches, our method does not require direct overlap between sensors and enables extending the angular perception range from a front-view camera to a full 360 view. On our large-scale road feature dataset, XD-MAP outperforms single shot baseline approaches by +19.5 mIoU for 2D semantic segmentation, +19.5 PQth for 2D panoptic segmentation, and +32.3 mIoU in 3D semantic segmentation. The results demonstrate the effectiveness of our approach achieving strong performance on LiDAR data without any manual labeling.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14477v1</guid></item><item><title>[cs updates on arXiv.org] Large Language Models for Large-Scale, Rigorous Qualitative Analysis in Applied Health Services Research</title><link>https://arxiv.org/abs/2601.14478</link><description>arXiv:2601.14478v1 Announce Type: new 
Abstract: Large language models (LLMs) show promise for improving the efficiency of qualitative analysis in large, multi-site health-services research. Yet methodological guidance for LLM integration into qualitative analysis and evidence of their impact on real-world research methods and outcomes remain limited. We developed a model- and task-agnostic framework for designing human-LLM qualitative analysis methods to support diverse analytic aims. Within a multi-site study of diabetes care at Federally Qualified Health Centers (FQHCs), we leveraged the framework to implement human-LLM methods for (1) qualitative synthesis of researcher-generated summaries to produce comparative feedback reports and (2) deductive coding of 167 interview transcripts to refine a practice-transformation intervention. LLM assistance enabled timely feedback to practitioners and the incorporation of large-scale qualitative data to inform theory and practice changes. This work demonstrates how LLMs can be integrated into applied health-services research to enhance efficiency while preserving rigor, offering guidance for continued innovation with LLMs in qualitative research.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14478v1</guid></item><item><title>[cs updates on arXiv.org] Can LLM Reasoning Be Trusted? A Comparative Study: Using Human Benchmarking on Statistical Tasks</title><link>https://arxiv.org/abs/2601.14479</link><description>arXiv:2601.14479v1 Announce Type: new 
Abstract: This paper investigates the ability of large language models (LLMs) to solve statistical tasks, as well as their capacity to assess the quality of reasoning. While state-of-the-art LLMs have demonstrated remarkable performance in a range of NLP tasks, their competence in addressing even moderately complex statistical challenges is not well understood. We have fine-tuned selected open-source LLMs on a specially developed dataset to enhance their statistical reasoning capabilities, and compared their performance with the human scores used as a benchmark. Our results show that the fine-tuned models achieve better performance on advanced statistical tasks on the level comparable to a statistics student. Fine-tuning demonstrates architecture-dependent improvements, with some models showing significant performance gains, indicating clear potential for deployment in educational technology and statistical analysis assistance systems. We also show that LLMs themselves can be far better judges of the answers quality (including explanation and reasoning assessment) in comparison to traditional metrics, such as BLEU or BertScore. This self-evaluation capability enables scalable automated assessment for statistical education platforms and quality assurance in automated analysis tools. Potential applications also include validation tools for research methodology in academic and industry settings, and quality control mechanisms for data analysis workflows.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14479v1</guid></item><item><title>[cs updates on arXiv.org] A benchmarking framework for PON-based fronthaul network design</title><link>https://arxiv.org/abs/2601.14480</link><description>arXiv:2601.14480v1 Announce Type: new 
Abstract: As mobile networks transition toward 5G and 6G RAN architectures, Passive Optical Networks (PONs) offer a critical solution for cost-effective fronthaul transport. However, the lack of standardized evaluation models in current literature makes an objective comparison of diverse optimization strategies difficult. This paper addresses this gap by proposing a unified benchmarking framework that standardizes cost catalogs and deployment scenarios. We formulate the network design problem using Integer Linear Programming (ILP) to establish optimality bounds and evaluate three scalable heuristic strategies: a Genetic Algorithm, K-Means Clustering (KMC+), and a graph-based Randomized Successive Splitter Assignment (RSSA+) algorithm. Simulation results show that a time-limited ILP remains a strong reference point, even when optimality is not reached. Despite being rarely used in prior fronthaul planning studies, it consistently yields solutions superior to those produced by standard heuristic methods. Among scalable approaches, RSSA+ reliably attains near-ILP performance while ensuring feasibility across all evaluated scenarios, which underscores the importance of advanced, constraint-aware algorithmic designs over simpler heuristics. The complete benchmarking framework and datasets are publicly shared in [1].</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14480v1</guid></item><item><title>[cs updates on arXiv.org] Scalable Knee-Point Guided Activity Group Selection in Multi-Tree Genetic Programming for Dynamic Multi-Mode Project Scheduling</title><link>https://arxiv.org/abs/2601.14485</link><description>arXiv:2601.14485v1 Announce Type: new 
Abstract: The dynamic multi-mode resource-constrained project scheduling problem is a challenging scheduling problem that requires making decisions on both the execution order of activities and their corresponding execution modes. Genetic programming has been widely applied as a hyper-heuristic to evolve priority rules that guide the selection of activity-mode pairs from the current eligible set. Recently, an activity group selection strategy has been proposed to select a subset of activities rather than a single activity at each decision point, allowing for more effective scheduling by considering the interdependence between activities. Although effective in small-scale instances, this strategy suffers from scalability issues when applied to larger problems. In this work, we enhance the scalability of the group selection strategy by introducing a knee-point-based selection mechanism to identify a promising subset of activities before evaluating their combinations. An activity ordering rule is first used to rank all eligible activity-mode pairs, followed by a knee point selection to find the promising pairs. Then, a group selection rule selects the best activity combination. We develop a multi-tree GP framework to evolve both types of rules simultaneously. Experimental results demonstrate that our approach scales well to large instances and outperforms GP with sequential decision-making in most scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14485v1</guid></item><item><title>[cs updates on arXiv.org] Stabilizing autoregressive forecasts in chaotic systems via multi-rate latent recurrence</title><link>https://arxiv.org/abs/2601.14487</link><description>arXiv:2601.14487v1 Announce Type: new 
Abstract: Long-horizon autoregressive forecasting of chaotic dynamical systems remains challenging due to rapid error amplification and distribution shift: small one-step inaccuracies compound into physically inconsistent rollouts and collapse of large-scale statistics. We introduce MSR-HINE, a hierarchical implicit forecaster that augments multiscale latent priors with multi-rate recurrent modules operating at distinct temporal scales. At each step, coarse-to-fine recurrent states generate latent priors, an implicit one-step predictor refines the state with multiscale latent injections, and a gated fusion with posterior latents enforces scale-consistent updates; a lightweight hidden-state correction further aligns recurrent memories with fused latents. The resulting architecture maintains long-term context on slow manifolds while preserving fast-scale variability, mitigating error accumulation in chaotic rollouts. Across two canonical benchmarks, MSR-HINE yields substantial gains over a U-Net autoregressive baseline: on Kuramoto-Sivashinsky it reduces end-horizon RMSE by 62.8% at H=400 and improves end-horizon ACC by +0.983 (from -0.155 to 0.828), extending the ACC &gt;= 0.5 predictability horizon from 241 to 400 steps; on Lorenz-96 it reduces RMSE by 27.0% at H=100 and improves end horizon ACC by +0.402 (from 0.144 to 0.545), extending the ACC &gt;= 0.5 horizon from 58 to 100 steps.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14487v1</guid></item><item><title>[cs updates on arXiv.org] High-Order Symmetric Positive Interior Quadrature Rules on Two and Three Dimensional Domains</title><link>https://arxiv.org/abs/2601.14488</link><description>arXiv:2601.14488v1 Announce Type: new 
Abstract: Fully symmetric positive interior (f-SPI) quadrature rules are key building blocks for high-order discretizations of partial differential equations, yet high-degree rules with few nodes remain scarce on reference elements commonly used in mesh generation. We construct new f-SPI rules on the square, cube, prism, and pyramid by coupling a variable parameterization that enforces positivity and interiority with an efficient Levenberg-Marquardt optimization and a symmetry-aware node-reduction strategy that eliminates and collapses orbits, allowing transitions between symmetry types. The resulting rules achieve degrees up to 77 on the square, 45 on the cube, and 30 on the prism and pyramid, and for most degrees use fewer nodes than previously published f-SPI quadrature rules. Verification tests demonstrate comparable accuracy to existing rules. Complete node and weight data are also provided.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14488v1</guid></item><item><title>[cs updates on arXiv.org] GutenOCR: A Grounded Vision-Language Front-End for Documents</title><link>https://arxiv.org/abs/2601.14490</link><description>arXiv:2601.14490v1 Announce Type: new 
Abstract: GutenOCR is a family of grounded OCR front-ends obtained by fine-tuning Qwen2.5-VL-3B and Qwen2.5-VL-7B. The resulting single-checkpoint vision-language models expose reading, detection, and grounding through a unified, prompt-based interface. Trained on business documents, scientific articles, and synthetic grounding data, the models support full-page and localized reading with line- and paragraph-level bounding boxes and conditional ``where is x?'' queries. We introduce a grounded OCR evaluation protocol and show that GutenOCR-7B more than doubles the composite grounded OCR score of its Qwen2.5-VL-7B backbone on 10.5K held-out business and scientific pages (0.40 to 0.82). On Fox and OmniDocBench v1.5, our approach substantially improves region- and line-level OCR as well as text-detection recall, but reveals trade-offs in page-level linearization, color-guided OCR, and formula-heavy layouts.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14490v1</guid></item><item><title>[cs updates on arXiv.org] UNCLE-Grasp: Uncertainty-Aware Grasping of Leaf-Occluded Strawberries</title><link>https://arxiv.org/abs/2601.14492</link><description>arXiv:2601.14492v1 Announce Type: new 
Abstract: Robotic strawberry harvesting is challenging under partial occlusion, where leaves induce significant geometric uncertainty and make grasp decisions based on a single deterministic shape estimate unreliable. From a single partial observation, multiple incompatible 3D completions may be plausible, causing grasps that appear feasible on one completion to fail on another. We propose an uncertainty-aware grasping pipeline for partially occluded strawberries that explicitly models completion uncertainty arising from both occlusion and learned shape reconstruction. Our approach uses point cloud completion with Monte Carlo dropout to sample multiple shape hypotheses, generates candidate grasps for each completion, and evaluates grasp feasibility using physically grounded force-closure-based metrics. Rather than selecting a grasp based on a single estimate, we aggregate feasibility across completions and apply a conservative lower confidence bound (LCB) criterion to decide whether a grasp should be attempted or safely abstained. We evaluate the proposed method in simulation and on a physical robot across increasing levels of synthetic and real leaf occlusion. Results show that uncertainty-aware decision making enables reliable abstention from high-risk grasp attempts under severe occlusion while maintaining robust grasp execution when geometric confidence is sufficient, outperforming deterministic baselines in both simulated and physical robot experiments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14492v1</guid></item><item><title>[cs updates on arXiv.org] Hint-Based SMT Proof Reconstruction</title><link>https://arxiv.org/abs/2601.14495</link><description>arXiv:2601.14495v1 Announce Type: new 
Abstract: There are several paradigms for integrating interactive and automated theorem provers, combining the convenience of powerful automation with strong soundness guarantees. We introduce a new approach for reconstructing proofs found by SMT solvers which we intend to be complementary with existing techniques. Rather than verifying or replaying a full proof produced by the SMT solver, or at the other extreme, rediscovering the solver's proof from just the set of premises it uses, we explore an approach which helps guide an interactive theorem prover's internal automation by leveraging derived facts during solving, which we call hints. This makes it possible to extract more information from the SMT solver's proof without the cost of retaining a dependency on the SMT solver itself. We implement a tactic in the Lean proof assistant, called QuerySMT, which leverages hints from the cvc5 SMT solver to improve existing Lean automation. We evaluate QuerySMT's performance on relevant Lean benchmarks, compare it to other tools available in Lean relating to SMT solving, and show that the hints generated by cvc5 produce a clear improvement in existing automation's performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14495v1</guid></item><item><title>[cs updates on arXiv.org] AQUA: an Agile Process to Develop Quantum Annealing Applications</title><link>https://arxiv.org/abs/2601.14501</link><description>arXiv:2601.14501v1 Announce Type: new 
Abstract: Quadratic unconstrained binary optimization (QUBO) is a field of operations research that is attracting growing interest due to the recent availability of quantum hardware targeted at solving QUBO problems. However, practical adoption is hindered by mathematical intricacy, hardware constraints, and a lack of sound software engineering processes for QUBO development. This work presents AQUA (Agile QUantum Annealing), an agile lifecycle for QUBO/QA development created through an industry-academia partnership between NetService S.p.A and the University of Cagliari. Using the Design Science Research (DSR) approach, AQUA customizes Scrum to the needs of QUBO/QA development, structuring work into four stages: initial assessment with formal modeling, prototype-driven algorithm selection, agile implementation, and deployment with ongoing maintenance, each gated by milestones. Validated on a real credit-scoring case, AQUA shows feasibility and offers an explicit, systematic QA engineering framework. Key contributions of our work are: a dedicated QUBO/QA software process, its creation and design using DSR approach, and its empirical validation on a simple yet real case study.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14501v1</guid></item><item><title>[cs updates on arXiv.org] Uncovering and Understanding FPR Manipulation Attack in Industrial IoT Networks</title><link>https://arxiv.org/abs/2601.14505</link><description>arXiv:2601.14505v1 Announce Type: new 
Abstract: In the network security domain, due to practical issues -- including imbalanced data and heterogeneous legitimate network traffic -- adversarial attacks in machine learning-based NIDSs have been viewed as attack packets misclassified as benign. Due to this prevailing belief, the possibility of (maliciously) perturbed benign packets being misclassified as attack has been largely ignored. In this paper, we demonstrate that this is not only theoretically possible, but also a particular threat to NIDS. In particular, we uncover a practical cyberattack, FPR manipulation attack (FPA), especially targeting industrial IoT networks, where domain-specific knowledge of the widely used MQTT protocol is exploited and a systematic simple packet-level perturbation is performed to alter the labels of benign traffic samples without employing traditional gradient-based or non-gradient-based methods. The experimental evaluations demonstrate that this novel attack results in a success rate of 80.19% to 100%. In addition, while estimating impacts in the Security Operations Center, we observe that even a small fraction of false positive alerts, irrespective of different budget constraints and alert traffic intensities, can increase the delay of genuine alerts investigations up to 2 hr in a single day under normal operating conditions. Furthermore, a series of relevant statistical and XAI analyses is conducted to understand the key factors behind this remarkable success. Finally, we explore the effectiveness of the FPA packets to enhance models' robustness through adversarial training and investigate the changes in decision boundaries accordingly.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14505v1</guid></item><item><title>[cs updates on arXiv.org] Language, Caste, and Context: Demographic Disparities in AI-Generated Explanations Across Indian and American STEM Educational Systems</title><link>https://arxiv.org/abs/2601.14506</link><description>arXiv:2601.14506v1 Announce Type: new 
Abstract: The popularization of AI chatbot usage globally has created opportunities for research into their benefits and drawbacks, especially for students using AI assistants for coursework support. This paper asks: how do LLMs perceive the intellectual capabilities of student profiles from intersecting marginalized identities across different cultural contexts? We conduct one of the first large-scale intersectional analyses on LLM explanation quality for Indian and American undergraduate profiles preparing for engineering entrance examinations. By constructing profiles combining multiple demographic dimensions including caste, medium of instruction, and school boards in India, and race, HBCU attendance, and school type in America, alongside universal factors like income and college tier, we examine how quality varies across these factors. We observe biases providing lower-quality outputs to profiles with marginalized backgrounds in both contexts. LLMs such as Qwen2.5-32B-Instruct and GPT-4o demonstrate granular understandings of context-specific discrimination, systematically providing simpler explanations to Hindi/Regional-medium students in India and HBCU profiles in America, treating these as proxies for lower capability. Even when marginalized profiles attain social mobility by getting accepted into elite institutions, they still receive more simplistic explanations, showing how demographic information is inextricably linked to LLM biases. Different models (Qwen2.5-32B-Instruct, GPT-4o, GPT-4o-mini, GPT-OSS 20B) embed similar biases against historically marginalized populations in both contexts, preventing profiles from switching between AI assistants for better results. Our findings have strong implications for AI incorporation into global engineering education.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14506v1</guid></item><item><title>[cs updates on arXiv.org] Super Time Stepping Methods for Diffusion using Discontinuous-Galerkin Spatial Discretizations</title><link>https://arxiv.org/abs/2601.14508</link><description>arXiv:2601.14508v1 Announce Type: new 
Abstract: Super-time-stepping (STS) methods provide an attractive approach for enabling explicit time integration of parabolic operators, particularly in large-scale, higher-dimensional kinetic simulations where fully implicit schemes are impractical. In this work, we present an explicit STS framework tailored for diffusion operators in gyrokinetic models, motivated by the fact that constructing and storing a Jacobian is often infeasible due to strong nonlocal couplings, high dimensionality, and memory constraints. We investigate the performance of several STS methods, including Runge-Kutta-Chebyshev (RKC) and Runge-Kutta-Legendre (RKL) schemes, applied to a diffusion equation discretized using both discontinuous Galerkin (DG) and finite-difference methods. To support time adaptivity, we introduce a novel error norm designed to more accurately track temporal error arising from DG spatial discretizations, in which degrees of freedom contribute unevenly to the solution error. Finally, we assess the performance of an automatic eigenvalue estimation algorithm for determining the required number of STS stages and compare it against an analytical estimation formula.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14508v1</guid></item><item><title>[cs updates on arXiv.org] Structured Image-based Coding for Efficient Gaussian Splatting Compression</title><link>https://arxiv.org/abs/2601.14510</link><description>arXiv:2601.14510v1 Announce Type: new 
Abstract: Gaussian Splatting (GS) has recently emerged as a state-of-the-art representation for radiance fields, combining real-time rendering with high visual fidelity. However, GS models require storing millions of parameters, leading to large file sizes that impair their use in practical multimedia systems. To address this limitation, this paper introduces GS Image-based Compression (GSICO), a novel GS codec that efficiently compresses pre-trained GS models while preserving perceptual fidelity. The core contribution lies in a mapping procedure that arranges GS parameters into structured images, guided by a novel algorithm that enhances spatial coherence. These GS parameter images are then encoded using a conventional image codec. Experimental evaluations on Tanks and Temples, Deep Blending, and Mip-NeRF360 datasets show that GSICO achieves average compression factors of 20.2x with minimal loss in visual quality, as measured by PSNR, SSIM, and LPIPS. Compared with state-of-the-art GS compression methods, the proposed codec consistently yields superior rate-distortion (RD) trade-offs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14510v1</guid></item><item><title>[cs updates on arXiv.org] Towards Transparent Malware Detection With Granular Explainability: Backtracking Meta-Coarsened Explanations Onto Assembly Flow Graphs With Graph Neural Networks</title><link>https://arxiv.org/abs/2601.14511</link><description>arXiv:2601.14511v1 Announce Type: new 
Abstract: As malware continues to become increasingly sophisticated, threatening, and evasive, malware detection systems must keep pace and become equally intelligent, powerful, and transparent. In this paper, we propose Assembly Flow Graph (AFG) to comprehensively represent the assembly flow of a binary executable as graph data. Importantly, AFG can be used to extract granular explanations needed to increase transparency for malware detection using Graph Neural Networks (GNNs). However, since AFGs may be large in practice, we also propose a Meta-Coarsening approach to improve computational tractability via graph reduction. To evaluate our proposed approach we consider several novel and existing metrics to quantify the granularity and quality of explanations. Lastly, we also consider several hyperparameters in our proposed Meta-Coarsening approach that can be used to control the final explanation size. We evaluate our proposed approach using the CIC-DGG-2025 dataset. Our results indicate that our proposed AFG and Meta-Coarsening approach can provide both increased explainability and inference performance at certain coarsening levels. However, most importantly, to the best of our knowledge, we are the first to consider granular explainability in malware detection using GNNs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14511v1</guid></item><item><title>[cs updates on arXiv.org] Aiming for AI Interoperability: Challenges and Opportunities</title><link>https://arxiv.org/abs/2601.14512</link><description>arXiv:2601.14512v1 Announce Type: new 
Abstract: The Aiming for AI Interoperability report investigates the ongoing challenge of achieving regulatory and technical AI interoperability as national and global AI governance efforts are proliferating. Here, technical interoperability is the ability of AI systems and networks to function together, and regulatory interoperability is the consistency and overlap of rules across jurisdictions and sectors. This report observes an accelerating trend that many governments, standard-setting bodies, and private firms are drafting, implementing, or passing new AI laws, policies, and frameworks at a staggering pace, resulting in fragmentation and confusion for both private and public sector actors.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14512v1</guid></item><item><title>[cs updates on arXiv.org] "Just in Time" World Modeling Supports Human Planning and Reasoning</title><link>https://arxiv.org/abs/2601.14514</link><description>arXiv:2601.14514v1 Announce Type: new 
Abstract: Probabilistic mental simulation is thought to play a key role in human reasoning, planning, and prediction, yet the demands of simulation in complex environments exceed realistic human capacity limits. A theory with growing evidence is that people simulate using simplified representations of the environment that abstract away from irrelevant details, but it is unclear how people determine these simplifications efficiently. Here, we present a "Just-in-Time" framework for simulation-based reasoning that demonstrates how such representations can be constructed online with minimal added computation. The model uses a tight interleaving of simulation, visual search, and representation modification, with the current simulation guiding where to look and visual search flagging objects that should be encoded for subsequent simulation. Despite only ever encoding a small subset of objects, the model makes high-utility predictions. We find strong empirical support for this account over alternative models in a grid-world planning task and a physical reasoning task across a range of behavioral measures. Together, these results offer a concrete algorithmic account of how people construct reduced representations to support efficient mental simulation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14514v1</guid></item><item><title>[cs updates on arXiv.org] Learning PDE Solvers with Physics and Data: A Unifying View of Physics-Informed Neural Networks and Neural Operators</title><link>https://arxiv.org/abs/2601.14517</link><description>arXiv:2601.14517v1 Announce Type: new 
Abstract: Partial differential equations (PDEs) are central to scientific modeling. Modern workflows increasingly rely on learning-based components to support model reuse, inference, and integration across large computational processes. Despite the emergence of various physics-aware data-driven approaches, the field still lacks a unified perspective to uncover their relationships, limitations, and appropriate roles in scientific workflows. To this end, we propose a unifying perspective to place two dominant paradigms: Physics-Informed Neural Networks (PINNs) and Neural Operators (NOs), within a shared design space. We organize existing methods from three fundamental dimensions: what is learned, how physical structures are integrated into the learning process, and how the computational load is amortized across problem instances. In this way, many challenges can be best understood as consequences of these structural properties of learning PDEs. By analyzing advances through this unifying view, our survey aims to facilitate the development of reliable learning-based PDE solvers and catalyze a synthesis of physics and data.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14517v1</guid></item><item><title>[cs updates on arXiv.org] Business Logic-Driven Text-to-SQL Data Synthesis for Business Intelligence</title><link>https://arxiv.org/abs/2601.14518</link><description>arXiv:2601.14518v1 Announce Type: new 
Abstract: Evaluating Text-to-SQL agents in private business intelligence (BI) settings is challenging due to the scarcity of realistic, domain-specific data. While synthetic evaluation data offers a scalable solution, existing generation methods fail to capture business realism--whether questions reflect realistic business logic and workflows. We propose a Business Logic-Driven Data Synthesis framework that generates data grounded in business personas, work scenarios, and workflows. In addition, we improve the data quality by imposing a business reasoning complexity control strategy that diversifies the analytical reasoning steps required to answer the questions. Experiments on a production-scale Salesforce database show that our synthesized data achieves high business realism (98.44%), substantially outperforming OmniSQL (+19.5%) and SQL-Factory (+54.7%), while maintaining strong question-SQL alignment (98.59%). Our synthetic data also reveals that state-of-the-art Text-to-SQL models still have significant performance gaps, achieving only 42.86% execution accuracy on the most complex business queries.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14518v1</guid></item><item><title>[cs updates on arXiv.org] How Worst-Case Are Adversarial Attacks? Linking Adversarial and Statistical Robustness</title><link>https://arxiv.org/abs/2601.14519</link><description>arXiv:2601.14519v1 Announce Type: new 
Abstract: Adversarial attacks are widely used to evaluate model robustness, yet their validity as proxies for robustness to random perturbations remains debated. We ask whether an adversarial perturbation provides a representative estimate of robustness under random noise of the same magnitude, or instead reflects an atypical worst-case event. To this end, we introduce a probabilistic metric that quantifies noisy risk with respect to directionally biased perturbation distributions, parameterized by a concentration factor $\kappa$ that interpolates between isotropic noise and adversarial direction. Using this framework, we study the limits of adversarial perturbations as estimators of noisy risk by proposing an attack strategy designed to operate in regimes statistically closer to uniform noise. Experiments on ImageNet and CIFAR-10 systematically benchmark widely used attacks, highlighting when adversarial success meaningfully reflects noisy risk and when it fails, thereby informing their use in safety-oriented evaluation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14519v1</guid></item><item><title>[cs updates on arXiv.org] On the Runway Cascade of Transformers for Language Modeling</title><link>https://arxiv.org/abs/2601.14522</link><description>arXiv:2601.14522v1 Announce Type: new 
Abstract: In decoder-only (causal) transformers, the computation graph created by causal masking routes information through both direct-path attention and indirect paths formed by intermediate tokens. We denote these indirect paths between token pairs as their runways. We argue that certain failure modes of causal transformers as observed by a growing body of recent works are likely exacerbated by a misalignment between these two information propagation modes. We formalize runway cascade as a phenomenon whereby this misalignment results in redundancies and irrelevant information cascading to token representations despite adequately learned attention patterns. As a solution, we propose runway-aware rewiring as a more explicit way of incorporating runway context directly into each token's direct-path attention. This mechanism re-wires the attention pattern for each token based on a summary of its runway landscape, enabling awareness of accumulating representational influences and allowing for more balanced information propagation. Our proposed methodology introduces no additional parameters and can seamlessly be integrated into standard attention mechanism. Empirically, our rewired transformer results in steady improvements in general language modeling as well as noticeably stronger information retrieval and extrapolation abilities compared to standard transformers.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14522v1</guid></item><item><title>[cs updates on arXiv.org] Large Language Model-Powered Evolutionary Code Optimization on a Phylogenetic Tree</title><link>https://arxiv.org/abs/2601.14523</link><description>arXiv:2601.14523v1 Announce Type: new 
Abstract: Optimizing scientific computing algorithms for modern GPUs is a labor-intensive and iterative process involving repeated code modification, benchmarking, and tuning across complex hardware and software stacks. Recent work has explored large language model (LLM)-assisted evolutionary methods for automated code optimization, but these approaches primarily rely on outcome-based selection and random mutation, underutilizing the rich trajectory information generated during iterative optimization. We propose PhyloEvolve, an LLM-agent system that reframes GPU-oriented algorithm optimization as an In-Context Reinforcement Learning (ICRL) problem. This formulation enables trajectory-conditioned reuse of optimization experience without model retraining. PhyloEvolve integrates Algorithm Distillation and prompt-based Decision Transformers into an iterative workflow, treating sequences of algorithm modifications and performance feedback as first-class learning signals. To organize optimization history, we introduce a phylogenetic tree representation that captures inheritance, divergence, and recombination among algorithm variants, enabling backtracking, cross-lineage transfer, and reproducibility. The system combines elite trajectory pooling, multi-island parallel exploration, and containerized execution to balance exploration and exploitation across heterogeneous hardware. We evaluate PhyloEvolve on scientific computing workloads including PDE solvers, manifold learning, and spectral graph algorithms, demonstrating consistent improvements in runtime, memory efficiency, and correctness over baseline and evolutionary methods. Code is published at: https://github.com/annihi1ation/phylo_evolve</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14523v1</guid></item><item><title>[cs updates on arXiv.org] Towards Execution-Grounded Automated AI Research</title><link>https://arxiv.org/abs/2601.14525</link><description>arXiv:2601.14525v1 Announce Type: new 
Abstract: Automated AI research holds great potential to accelerate scientific discovery. However, current LLMs often generate plausible-looking but ineffective ideas. Execution grounding may help, but it is unclear whether automated execution is feasible and whether LLMs can learn from the execution feedback. To investigate these, we first build an automated executor to implement ideas and launch large-scale parallel GPU experiments to verify their effectiveness. We then convert two realistic research problems - LLM pre-training and post-training - into execution environments and demonstrate that our automated executor can implement a large fraction of the ideas sampled from frontier LLMs. We analyze two methods to learn from the execution feedback: evolutionary search and reinforcement learning. Execution-guided evolutionary search is sample-efficient: it finds a method that significantly outperforms the GRPO baseline (69.4% vs 48.0%) on post-training, and finds a pre-training recipe that outperforms the nanoGPT baseline (19.7 minutes vs 35.9 minutes) on pre-training, all within just ten search epochs. Frontier LLMs often generate meaningful algorithmic ideas during search, but they tend to saturate early and only occasionally exhibit scaling trends. Reinforcement learning from execution reward, on the other hand, suffers from mode collapse. It successfully improves the average reward of the ideator model but not the upper-bound, due to models converging on simple ideas. We thoroughly analyze the executed ideas and training dynamics to facilitate future efforts towards execution-grounded automated AI research.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14525v1</guid></item><item><title>[cs updates on arXiv.org] LLM Security and Safety: Insights from Homotopy-Inspired Prompt Obfuscation</title><link>https://arxiv.org/abs/2601.14528</link><description>arXiv:2601.14528v1 Announce Type: new 
Abstract: In this study, we propose a homotopy-inspired prompt obfuscation framework to enhance understanding of security and safety vulnerabilities in Large Language Models (LLMs). By systematically applying carefully engineered prompts, we demonstrate how latent model behaviors can be influenced in unexpected ways. Our experiments encompassed 15,732 prompts, including 10,000 high-priority cases, across LLama, Deepseek, KIMI for code generation, and Claude to verify. The results reveal critical insights into current LLM safeguards, highlighting the need for more robust defense mechanisms, reliable detection strategies, and improved resilience. Importantly, this work provides a principled framework for analyzing and mitigating potential weaknesses, with the goal of advancing safe, responsible, and trustworthy AI technologies.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14528v1</guid></item><item><title>[cs updates on arXiv.org] PAS-Mamba: Phase-Amplitude-Spatial State Space Model for MRI Reconstruction</title><link>https://arxiv.org/abs/2601.14530</link><description>arXiv:2601.14530v1 Announce Type: new 
Abstract: Joint feature modeling in both the spatial and frequency domains has become a mainstream approach in MRI reconstruction. However, existing methods generally treat the frequency domain as a whole, neglecting the differences in the information carried by its internal components. According to Fourier transform theory, phase and amplitude represent different types of information in the image. Our spectrum swapping experiments show that magnitude mainly reflects pixel-level intensity, while phase predominantly governs image structure. To prevent interference between phase and magnitude feature learning caused by unified frequency-domain modeling, we propose the Phase-Amplitude-Spatial State Space Model (PAS-Mamba) for MRI Reconstruction, a framework that decouples phase and magnitude modeling in the frequency domain and combines it with image-domain features for better reconstruction. In the image domain, LocalMamba preserves spatial locality to sharpen fine anatomical details. In frequency domain, we disentangle amplitude and phase into two specialized branches to avoid representational coupling. To respect the concentric geometry of frequency information, we propose Circular Frequency Domain Scanning (CFDS) to serialize features from low to high frequencies. Finally, a Dual-Domain Complementary Fusion Module (DDCFM) adaptively fuses amplitude phase representations and enables bidirectional exchange between frequency and image domains, delivering superior reconstruction. Extensive experiments on the IXI and fastMRI knee datasets show that PAS-Mamba consistently outperforms state of the art reconstruction methods.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14530v1</guid></item><item><title>[cs updates on arXiv.org] Search over Self-Edit Strategies for LLM Adaptation</title><link>https://arxiv.org/abs/2601.14532</link><description>arXiv:2601.14532v1 Announce Type: new 
Abstract: Many LLM-based open-ended search systems freeze the foundation model that proposes improvements to existing solutions, which may bottleneck long-run progress. Recent work has explored updating the proposal model at test time [arXiv:2511.23473], but the update strategy is still typically hand-specified. Therefore, this study investigated whether an LLM can use task feedback to decide how it should update its weights. For tractability, we focused on the simpler case where there is only one round of self-improvement, and restricted the update operator to self-supervised next token prediction (NTP), leaving the model freedom in choosing its training data and key NTP hyperparameters. Using the Self-Adapting Language Models (SEAL) [arXiv:2506.10943] framework as a testbed, we relaxed its fixed human template constraint and allowed the model to generate its own self-edit templates, thereby giving it more control over its training data and hyperparameters. Two variants were studied, differing in whether template generation was conditioned on a lightweight archive of past templates. In SEAL's Single-Passage Knowledge Incorporation setting with Qwen3-8B on SQuAD [arXiv:1606.05250], the no-archive variant performed comparably to the weaker "Implications" baseline, while the archive variant outperformed "Implications" and approached the strongest human-designed "Rewrite" baseline without surpassing it. Further analysis of collapse in the model's exploration revealed that a naive archive can confer some short-term robustness but can also accelerate homogenization, suggesting that explicit novelty pressure may be required to consistently advance beyond carefully optimized human strategies. Our code is available at https://github.com/cheongalc/search-self-edit-strategies .</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14532v1</guid></item><item><title>[cs updates on arXiv.org] The Algorithmic Barrier: Quantifying Artificial Frictional Unemployment in Automated Recruitment Systems</title><link>https://arxiv.org/abs/2601.14534</link><description>arXiv:2601.14534v1 Announce Type: new 
Abstract: The United States labor market exhibits a persistent coexistence of high job vacancy rates and prolonged unemployment duration, a pattern that standard labor market theory struggles to explain. This paper argues that a non-trivial portion of contemporary frictional unemployment is artificially induced by automated recruitment systems that rely on deterministic keyword-based screening.
  Drawing on labor economics, information asymmetry theory, and prior work on algorithmic hiring, we formalize this phenomenon as artificial frictional unemployment arising from semantic misinterpretation of candidate competencies. We evaluate this claim using controlled simulations that compare legacy keyword-based screening with semantic matching based on high-dimensional vector representations of resumes and job descriptions.
  The results demonstrate substantial improvements in recall and overall matching efficiency without a corresponding loss in precision. Building on these findings, the paper proposes a candidate-side workforce operating architecture that standardizes, verifies, and semantically aligns human capital signals while remaining interoperable with existing recruitment infrastructure. The findings highlight the economic costs of outdated hiring systems and the potential gains from improving semantic alignment in labor market matching.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14534v1</guid></item><item><title>[cs updates on arXiv.org] engGNN: A Dual-Graph Neural Network for Omics-Based Disease Classification and Feature Selection</title><link>https://arxiv.org/abs/2601.14536</link><description>arXiv:2601.14536v1 Announce Type: new 
Abstract: Omics data, such as transcriptomics, proteomics, and metabolomics, provide critical insights into disease mechanisms and clinical outcomes. However, their high dimensionality, small sample sizes, and intricate biological networks pose major challenges for reliable prediction and meaningful interpretation. Graph Neural Networks (GNNs) offer a promising way to integrate prior knowledge by encoding feature relationships as graphs. Yet, existing methods typically rely solely on either an externally curated feature graph or a data-driven generated one, which limits their ability to capture complementary information. To address this, we propose the external and generated Graph Neural Network (engGNN), a dual-graph framework that jointly leverages both external known biological networks and data-driven generated graphs. Specifically, engGNN constructs a biologically informed undirected feature graph from established network databases and complements it with a directed feature graph derived from tree-ensemble models. This dual-graph design produces more comprehensive embeddings, thereby improving predictive performance and interpretability. Through extensive simulations and real-world applications to gene expression data, engGNN consistently outperforms state-of-the-art baselines. Beyond classification, engGNN provides interpretable feature importance scores that facilitate biologically meaningful discoveries, such as pathway enrichment analysis. Taken together, these results highlight engGNN as a robust, flexible, and interpretable framework for disease classification and biomarker discovery in high-dimensional omics contexts.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14536v1</guid></item><item><title>[cs updates on arXiv.org] Report for NSF Workshop on AI for Electronic Design Automation</title><link>https://arxiv.org/abs/2601.14541</link><description>arXiv:2601.14541v1 Announce Type: new 
Abstract: This report distills the discussions and recommendations from the NSF Workshop on AI for Electronic Design Automation (EDA), held on December 10, 2024 in Vancouver alongside NeurIPS 2024. Bringing together experts across machine learning and EDA, the workshop examined how AI-spanning large language models (LLMs), graph neural networks (GNNs), reinforcement learning (RL), neurosymbolic methods, etc.-can facilitate EDA and shorten design turnaround. The workshop includes four themes: (1) AI for physical synthesis and design for manufacturing (DFM), discussing challenges in physical manufacturing process and potential AI applications; (2) AI for high-level and logic-level synthesis (HLS/LLS), covering pragma insertion, program transformation, RTL code generation, etc.; (3) AI toolbox for optimization and design, discussing frontier AI developments that could potentially be applied to EDA tasks; and (4) AI for test and verification, including LLM-assisted verification tools, ML-augmented SAT solving, security/reliability challenges, etc. The report recommends NSF to foster AI/EDA collaboration, invest in foundational AI for EDA, develop robust data infrastructures, promote scalable compute infrastructure, and invest in workforce development to democratize hardware design and enable next-generation hardware systems. The workshop information can be found on the website https://ai4eda-workshop.github.io/.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14541v1</guid></item><item><title>[cs updates on arXiv.org] Shapley Value on Uncertain Data</title><link>https://arxiv.org/abs/2601.14543</link><description>arXiv:2601.14543v1 Announce Type: new 
Abstract: The Shapley value provides a principled framework for fairly distributing rewards among participants according to their individual contributions. While prior work has applied this concept to data valuation in machine learning, existing formulations overwhelmingly assume that each participant contributes a fixed, deterministic dataset. In practice, however, data owners often provide samples drawn from underlying probabilistic distributions, introducing stochasticity into their marginal contributions and rendering the Shapley value itself a random variable. This work addresses this gap by proposing a framework for the Shapley value of probabilistic data distributions that quantifies both the expected contribution and the variance of each participant, thereby capturing uncertainty induced by random sampling. We develop theoretical and empirical methodologies for estimating these quantities: on the theoretical side, we derive unbiased estimators for the expectation and variance of the probabilistic Shapley value and analyze their statistical properties; on the empirical side, we introduce three Monte Carlo-based estimation algorithms - a baseline estimator using independent samples, a pooled estimator that improves efficiency through sample reuse, and a stratified pooled estimator that adaptively allocates sampling budget based on player-specific variability. Experiments on synthetic and real datasets demonstrate that these methods achieve strong accuracy-efficiency trade-offs, with the stratified pooled approach attaining substantial variance reduction at minimal additional cost. By extending Shapley value analysis from deterministic datasets to probabilistic data distributions, this work provides both theoretical rigor and practical tools for fair and reliable data valuation in modern stochastic data-sharing environments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14543v1</guid></item><item><title>[cs updates on arXiv.org] AI Agents vs. Human Investigators: Balancing Automation, Security, and Expertise in Cyber Forensic Analysis</title><link>https://arxiv.org/abs/2601.14544</link><description>arXiv:2601.14544v1 Announce Type: new 
Abstract: In an era where cyber threats are rapidly evolving, the reliability of cyber forensic analysis has become increasingly critical for effective digital investigations and cybersecurity responses. AI agents are being adopted across digital forensic practices due to their ability to automate processes such as anomaly detection, evidence classification, and behavioral pattern recognition, significantly enhancing scalability and reducing investigation timelines. However, the characteristics that make AI indispensable also introduce notable risks. AI systems, often trained on biased or incomplete datasets, can produce misleading results, including false positives and false negatives, thereby jeopardizing the integrity of forensic investigations. This study presents a meticulous comparative analysis of the effectiveness of the most used AI agent, ChatGPT, and human forensic investigators in the realm of cyber forensic analysis. Our research reveals critical limitations within AI-driven approaches, demonstrating scenarios in which sophisticated or novel cyber threats remain undetected due to the rigid pattern-based nature of AI systems. Conversely, our analysis highlights the crucial role that human forensic investigators play in mitigating these risks. Through adaptive decision-making, ethical reasoning, and contextual understanding, human investigators effectively identify subtle anomalies and threats that may evade automated detection systems. To reinforce our findings, we conducted comprehensive reliability testing of forensic techniques using multiple cyber threat scenarios. These tests confirmed that while AI agents significantly improve the efficiency of routine analyses, human oversight remains crucial in ensuring accuracy and comprehensiveness of the results.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14544v1</guid></item><item><title>[cs updates on arXiv.org] Predicting Retrieval Utility and Answer Quality in Retrieval-Augmented Generation</title><link>https://arxiv.org/abs/2601.14546</link><description>arXiv:2601.14546v1 Announce Type: new 
Abstract: The quality of answers generated by large language models (LLMs) in retrieval-augmented generation (RAG) is largely influenced by the contextual information contained in the retrieved documents. A key challenge for improving RAG is to predict both the utility of retrieved documents -- quantified as the performance gain from using context over generation without context -- and the quality of the final answers in terms of correctness and relevance. In this paper, we define two prediction tasks within RAG. The first is retrieval performance prediction (RPP), which estimates the utility of retrieved documents. The second is generation performance prediction (GPP), which estimates the final answer quality. We hypothesise that in RAG, the topical relevance of retrieved documents correlates with their utility, suggesting that query performance prediction (QPP) approaches can be adapted for RPP and GPP. Beyond these retriever-centric signals, we argue that reader-centric features, such as the LLM's perplexity of the retrieved context conditioned on the input query, can further enhance prediction accuracy for both RPP and GPP. Finally, we propose that features reflecting query-agnostic document quality and readability can also provide useful signals to the predictions. We train linear regression models with the above categories of predictors for both RPP and GPP. Experiments on the Natural Questions (NQ) dataset show that combining predictors from multiple feature categories yields the most accurate estimates of RAG performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14546v1</guid></item><item><title>[cs updates on arXiv.org] QMC: Efficient SLM Edge Inference via Outlier-Aware Quantization and Emergent Memories Co-Design</title><link>https://arxiv.org/abs/2601.14549</link><description>arXiv:2601.14549v1 Announce Type: new 
Abstract: Deploying Small Language Models (SLMs) on edge platforms is critical for real-time, privacy-sensitive generative AI, yet constrained by memory, latency, and energy budgets. Quantization reduces model size and cost but suffers from device noise in emerging non-volatile memories, while conventional memory hierarchies further limit efficiency. SRAM provides fast access but has low density, DRAM must simultaneously accommodate static weights and dynamic KV caches, which creates bandwidth contention, and Flash, although dense, is primarily used for initialization and remains inactive during inference. These limitations highlight the need for hybrid memory organizations tailored to LLM inference. We propose Outlier-aware Quantization with Memory Co-design (QMC), a retraining-free quantization with a novel heterogeneous memory architecture. QMC identifies inlier and outlier weights in SLMs, storing inlier weights in compact multi-level Resistive-RAM (ReRAM) while preserving critical outliers in high-precision on-chip Magnetoresistive-RAM (MRAM), mitigating noise-induced degradation. On language modeling and reasoning benchmarks, QMC outperforms and matches state-of-the-art quantization methods using advanced algorithms and hybrid data formats, while achieving greater compression under both algorithm-only evaluation and realistic deployment settings. Specifically, compared against SoTA quantization methods on the latest edge AI platform, QMC reduces memory usage by 6.3x-7.3x, external data transfers by 7.6x, energy by 11.7x, and latency by 12.5x when compared to FP16, establishing QMC as a scalable, deployment-ready co-design for efficient on-device inference.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14549v1</guid></item><item><title>[cs updates on arXiv.org] TacUMI: A Multi-Modal Universal Manipulation Interface for Contact-Rich Tasks</title><link>https://arxiv.org/abs/2601.14550</link><description>arXiv:2601.14550v1 Announce Type: new 
Abstract: Task decomposition is critical for understanding and learning complex long-horizon manipulation tasks. Especially for tasks involving rich physical interactions, relying solely on visual observations and robot proprioceptive information often fails to reveal the underlying event transitions. This raises the requirement for efficient collection of high-quality multi-modal data as well as robust segmentation method to decompose demonstrations into meaningful modules. Building on the idea of the handheld demonstration device Universal Manipulation Interface (UMI), we introduce TacUMI, a multi-modal data collection system that integrates additionally ViTac sensors, force-torque sensor, and pose tracker into a compact, robot-compatible gripper design, which enables synchronized acquisition of all these modalities during human demonstrations. We then propose a multi-modal segmentation framework that leverages temporal models to detect semantically meaningful event boundaries in sequential manipulations. Evaluation on a challenging cable mounting task shows more than 90 percent segmentation accuracy and highlights a remarkable improvement with more modalities, which validates that TacUMI establishes a practical foundation for both scalable collection and segmentation of multi-modal demonstrations in contact-rich tasks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14550v1</guid></item><item><title>[cs updates on arXiv.org] Self-Blinding and Counterfactual Self-Simulation Mitigate Biases and Sycophancy in Large Language Models</title><link>https://arxiv.org/abs/2601.14553</link><description>arXiv:2601.14553v1 Announce Type: new 
Abstract: Fair decisions require ignoring irrelevant, potentially biasing, information. To achieve this, decision-makers need to approximate what decision they would have made had they not known certain facts, such as the gender or race of a job candidate. This counterfactual self-simulation is notoriously hard for humans, leading to biased judgments even by well-meaning actors. Here we show that large language models (LLMs) suffer from similar limitations in their ability to approximate what decisions they would make under counterfactual knowledge in offsetting gender and race biases and overcoming sycophancy. We show that prompting models to ignore or pretend not to know biasing information fails to offset these biases and occasionally backfires. However, unlike humans, LLMs can be given access to a ground-truth model of their own counterfactual cognition -- their own API. We show that this access to the responses of a blinded replica enables fairer decisions, while providing greater transparency to distinguish implicit from intentionally biased behavior.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14553v1</guid></item><item><title>[cs updates on arXiv.org] WebAssembly Based Portable and Secure Sensor Interface for Internet of Things</title><link>https://arxiv.org/abs/2601.14555</link><description>arXiv:2601.14555v1 Announce Type: new 
Abstract: As the expansion of IoT connectivity continues to provide quality-of-life improvements around the world, they simultaneously introduce increasing privacy and security concerns. The lack of a clear definition in managing shared and protected access to IoT sensors offer channels by which devices can be compromised and sensitive data can be leaked. In recent years, WebAssembly has received considerable attention for its efficient application sandboxing suitable for embedded systems, making it a prime candidate for exploring a secure and portable sensor interface. This paper introduces the first WebAssembly System Interface (WASI) extension offering a secure, portable, and low-footprint sandbox enabling multi-tenant access to sensor data across heterogeneous embedded devices. The runtime extensions provide application memory isolation, ensure appropriate resource privileges by intercepting sensor access, and offer an MQTT-SN interface enabling in-network access control. When targeting the WebAssembly byte-code with the associated runtime extensions implemented atop the Zephyr RTOS, our evaluation of sensor access indicates a latency overhead of 6% with an additional memory footprint of 5% when compared to native execution. As MQTT-SN requests are dominated by network delays, the WASI-SN implementation of MQTT-SN introduces less than 1% additional latency with similar memory footprint.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14555v1</guid></item><item><title>[cs updates on arXiv.org] Constructing Multi-label Hierarchical Classification Models for MITRE ATT&amp;CK Text Tagging</title><link>https://arxiv.org/abs/2601.14556</link><description>arXiv:2601.14556v1 Announce Type: new 
Abstract: MITRE ATT&amp;amp;CK is a cybersecurity knowledge base that organizes threat actor and cyber-attack information into a set of tactics describing the reasons and goals threat actors have for carrying out attacks, with each tactic having a set of techniques that describe the potential methods used in these attacks. One major application of ATT&amp;amp;CK is the use of its tactic and technique hierarchy by security specialists as a framework for annotating cyber-threat intelligence reports, vulnerability descriptions, threat scenarios, inter alia, to facilitate downstream analyses. To date, the tagging process is still largely done manually. In this technical note, we provide a stratified "task space" characterization of the MITRE ATT&amp;amp;CK text tagging task for organizing previous efforts toward automation using AIML methods, while also clarifying pathways for constructing new methods. To illustrate one of the pathways, we use the task space strata to stage-wise construct our own multi-label hierarchical classification models for the text tagging task via experimentation over general cyber-threat intelligence text -- using shareable computational tools and publicly releasing the models to the security community (via https://github.com/jpmorganchase/MITRE_models). Our multi-label hierarchical approach yields accuracy scores of roughly 94% at the tactic level, as well as accuracy scores of roughly 82% at the technique level. The models also meet or surpass state-of-the-art performance while relying only on classical machine learning methods -- removing any dependence on LLMs, RAG, agents, or more complex hierarchical approaches. Moreover, we show that GPT-4o model performance at the tactic level is significantly lower (roughly 60% accuracy) than our own approach. We also extend our baseline model to a corpus of threat scenarios for financial applications produced by subject matter experts.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14556v1</guid></item><item><title>[cs updates on arXiv.org] Rewarding How Models Think Pedagogically: Integrating Pedagogical Reasoning and Thinking Rewards for LLMs in Education</title><link>https://arxiv.org/abs/2601.14560</link><description>arXiv:2601.14560v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly deployed as intelligent tutoring systems, yet research on optimizing LLMs specifically for educational contexts remains limited. Recent works have proposed reinforcement learning approaches for training LLM tutors, but these methods focus solely on optimizing visible responses while neglecting the model's internal thinking process. We introduce PedagogicalRL-Thinking, a framework that extends pedagogical alignment to reasoning LLMs in education through two novel approaches: (1) Pedagogical Reasoning Prompting, which guides internal reasoning using domain-specific educational theory rather than generic instructions; and (2) Thinking Reward, which explicitly evaluates and reinforces the pedagogical quality of the model's reasoning traces. Our experiments reveal that domain-specific, theory-grounded prompting outperforms generic prompting, and that Thinking Reward is most effective when combined with pedagogical prompting. Furthermore, models trained only on mathematics tutoring dialogues show improved performance on educational benchmarks not seen during training, while preserving the base model's factual knowledge. Our quantitative and qualitative analyses reveal that pedagogical thinking reward produces systematic reasoning trace changes, with increased pedagogical reasoning and more structured instructional decision-making in the tutor's thinking process.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14560v1</guid></item><item><title>[cs updates on arXiv.org] Scribble-Supervised Medical Image Segmentation with Dynamic Teacher Switching and Hierarchical Consistency</title><link>https://arxiv.org/abs/2601.14563</link><description>arXiv:2601.14563v1 Announce Type: new 
Abstract: Scribble-supervised methods have emerged to mitigate the prohibitive annotation burden in medical image segmentation. However, the inherent sparsity of these annotations introduces significant ambiguity, which results in noisy pseudo-label propagation and hinders the learning of robust anatomical boundaries. To address this challenge, we propose SDT-Net, a novel dual-teacher, single-student framework designed to maximize supervision quality from these weak signals. Our method features a Dynamic Teacher Switching (DTS) module to adaptively select the most reliable teacher. This selected teacher then guides the student via two synergistic mechanisms: high-confidence pseudo-labels, refined by a Pick Reliable Pixels (PRP) mechanism, and multi-level feature alignment, enforced by a Hierarchical Consistency (HiCo) module. Extensive experiments on the ACDC and MSCMRseg datasets demonstrate that SDT-Net achieves state-of-the-art performance, producing more accurate and anatomically plausible segmentation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14563v1</guid></item><item><title>[cs updates on arXiv.org] SCSimulator: An Exploratory Visual Analytics Framework for Partner Selection in Supply Chains through LLM-driven Multi-Agent Simulation</title><link>https://arxiv.org/abs/2601.14566</link><description>arXiv:2601.14566v1 Announce Type: new 
Abstract: Supply chains (SCs), complex networks spanning from raw material acquisition to product delivery, with enterprises as interconnected nodes, play a pivotal role in organizational success. However, optimizing SCs remains challenging, particularly in partner selection, a key bottleneck shaped by competitive and cooperative dynamics. This challenge constitutes a multi-objective dynamic game requiring a synergistic integration of Multi-Criteria Decision-Making and Game Theory. Traditional approaches, grounded in mathematical simplifications and managerial heuristics, fail to capture real-world intricacies and risk introducing subjective biases. Multi-agent simulation offers promise, but prior research has largely relied on fixed, uniform agent logic, limiting practical applicability. Recent advances in LLMs create opportunities to represent complex SC requirements and hybrid game logic. However, challenges persist in modeling dynamic SC relationships, ensuring interpretability, and balancing agent autonomy with expert control. We present SCSimulator, a visual analytics framework that integrates LLM-driven MAS with human-in-the-loop collaboration for SC partner selection. It simulates SC evolution via adaptive network structures and enterprise behaviors, which are visualized via interpretable interfaces. By combining CoT reasoning with XAI techniques, it generates multi-faceted, transparent explanations of decision trade-offs. Users can iteratively adjust simulation settings to explore outcomes aligned with their expectations and strategic priorities. Developed through iterative co-design with SC experts and industry managers, SCSimulator serves as a proof-of-concept, offering methodological contributions and practical insights for future research on SC decision-making and interactive AI-driven analytics. Usage scenarios and a user study demonstrate the system's effectiveness and usability.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14566v1</guid></item><item><title>[cs updates on arXiv.org] Agent Identity URI Scheme: Topology-Independent Naming and Capability-Based Discovery for Multi-Agent Systems</title><link>https://arxiv.org/abs/2601.14567</link><description>arXiv:2601.14567v1 Announce Type: new 
Abstract: Multi-agent systems face a fundamental architectural flaw: agent identity is bound to network location. When agents migrate between providers, scale across instances, or federate across organizations, URI-based identity schemes break references, fragment audit trails, and require centralized coordination. We propose the agent:// URI scheme, which decouples identity from topology through three orthogonal components: a trust root establishing organizational authority, a hierarchical capability path enabling semantic discovery, and a sortable unique identifier providing stable reference. The scheme enables capability-based discovery through DHT key derivation, where queries return agents by what they do rather than where they are. Trust-root scoping prevents cross-organization pollution while permitting federation when desired. Cryptographic attestation via PASETO tokens binds capability claims to agent identity, enabling verification without real-time contact with the issuing authority. We evaluate the scheme across four dimensions: capability expressiveness (100% coverage on 369 production tools with zero collision), discovery precision (F1=1.0 across 10,000 agents), identity stability (formal proofs of migration invariance), and performance (all operations under 5 microseconds). The agent:// URI scheme provides a formally-specified, practically-evaluated foundation for decentralized agent identity and capability-based discovery.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14567v1</guid></item><item><title>[cs updates on arXiv.org] Breaking the accuracy-resource dilemma: a lightweight adaptive video inference enhancement</title><link>https://arxiv.org/abs/2601.14568</link><description>arXiv:2601.14568v1 Announce Type: new 
Abstract: Existing video inference (VI) enhancement methods typically aim to improve performance by scaling up model sizes and employing sophisticated network architectures. While these approaches demonstrated state-of-the-art performance, they often overlooked the trade-off of resource efficiency and inference effectiveness, leading to inefficient resource utilization and suboptimal inference performance. To address this problem, a fuzzy controller (FC-r) is developed based on key system parameters and inference-related metrics. Guided by the FC-r, a VI enhancement framework is proposed, where the spatiotemporal correlation of targets across adjacent video frames is leveraged. Given the real-time resource conditions of the target device, the framework can dynamically switch between models of varying scales during VI. Experimental results demonstrate that the proposed method effectively achieves a balance between resource utilization and inference performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14568v1</guid></item><item><title>[cs updates on arXiv.org] Social Caption: Evaluating Social Understanding in Multimodal Models</title><link>https://arxiv.org/abs/2601.14569</link><description>arXiv:2601.14569v1 Announce Type: new 
Abstract: Social understanding abilities are crucial for multimodal large language models (MLLMs) to interpret human social interactions. We introduce Social Caption, a framework grounded in interaction theory to evaluate social understanding abilities of MLLMs along three dimensions: Social Inference (SI), the ability to make accurate inferences about interactions; Holistic Social Analysis (HSA), the ability to generate comprehensive descriptions of interactions; Directed Social Analysis (DSA), the ability to extract relevant social information from interactions. We analyze factors influencing model performance in social understanding, such as scale, architectural design, and spoken context. Experiments with MLLM judges contribute insights about scaling automated evaluation of multimodal social understanding.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14569v1</guid></item><item><title>[cs updates on arXiv.org] Place with Intention: An Empirical Attendance Predictive Study of Expo 2025 Osaka, Kansai, Japan</title><link>https://arxiv.org/abs/2601.14570</link><description>arXiv:2601.14570v1 Announce Type: new 
Abstract: Accurate forecasting of daily attendance is vital for managing transportation, crowd flows, and services at large-scale international events such as Expo 2025 Osaka, Kansai, Japan. However, existing approaches often rely on multi-source external data (such as weather, traffic, and social media) to improve accuracy, which can lead to unreliable results when historical data are insufficient. To address these challenges, we propose a Transformer-based framework that leverages reservation dynamics, i.e., ticket bookings and subsequent updates within a time window, as a proxy for visitors' attendance intentions, under the assumption that such intentions are eventually reflected in reservation patterns. This design avoids the complexity of multi-source integration while still capturing external influences like weather and promotions implicitly embedded in reservation dynamics. We construct a dataset combining entrance records and reservation dynamics and evaluate the model under both single-channel (total attendance) and two-channel (separated by East and West gates) settings. Results show that separately modeling East and West gates consistently improves accuracy, particularly for short- and medium-term horizons. Ablation studies further confirm the importance of the encoder-decoder structure, inverse-style embedding, and adaptive fusion module. Overall, our findings indicate that reservation dynamics offer a practical and informative foundation for attendance forecasting in large-scale international events.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14570v1</guid></item><item><title>[cs updates on arXiv.org] Automatically Tightening Access Control Policies with Restricter</title><link>https://arxiv.org/abs/2601.14582</link><description>arXiv:2601.14582v1 Announce Type: new 
Abstract: Robust access control is a cornerstone of secure software, systems, and networks. An access control mechanism is as effective as the policy it enforces. However, authoring effective policies that satisfy desired properties such as the principle of least privilege is a challenging task even for experienced administrators, as evidenced by many real instances of policy misconfiguration. In this paper, we set out to address this pain point by proposing Restricter, which automatically tightens each (permit) policy rule of a policy with respect to an access log, which captures some already exercised access requests and their corresponding access decisions (i.e., allow or deny). Restricter achieves policy tightening by reducing the number of access requests permitted by a policy rule without sacrificing the functionality of the underlying system it is regulating. We implement Restricter for Amazon's Cedar policy language and demonstrate its effectiveness through two realistic case studies.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14582v1</guid></item><item><title>[cs updates on arXiv.org] Anatomically Guided Latent Diffusion for Brain MRI Progression Modeling</title><link>https://arxiv.org/abs/2601.14584</link><description>arXiv:2601.14584v1 Announce Type: new 
Abstract: Accurately modeling longitudinal brain MRI progression is crucial for understanding neurodegenerative diseases and predicting individualized structural changes. Existing state-of-the-art approaches, such as Brain Latent Progression (BrLP), often use multi-stage training pipelines with auxiliary conditioning modules but suffer from architectural complexity, suboptimal use of conditional clinical covariates, and limited guarantees of anatomical consistency. We propose Anatomically Guided Latent Diffusion Model (AG-LDM), a segmentation-guided framework that enforces anatomically consistent progression while substantially simplifying the training pipeline. AG-LDM conditions latent diffusion by directly fusing baseline anatomy, noisy follow-up states, and clinical covariates at the input level, a strategy that avoids auxiliary control networks by learning a unified, end-to-end model that represents both anatomy and progression. A lightweight 3D tissue segmentation model (WarpSeg) provides explicit anatomical supervision during both autoencoder fine-tuning and diffusion model training, ensuring consistent brain tissue boundaries and morphometric fidelity. Experiments on 31,713 ADNI longitudinal pairs and zero-shot evaluation on OASIS-3 demonstrate that AG-LDM matches or surpasses more complex diffusion models, achieving state-of-the-art image quality and 15-20\% reduction in volumetric errors in generated images. AG-LDM also exhibits markedly stronger utilization of temporal and clinical covariates (up to 31.5x higher sensitivity than BrLP) and generates biologically plausible counterfactual trajectories, accurately capturing hallmarks of Alzheimer's progression such as limbic atrophy and ventricular expansion. These results highlight AG-LDM as an efficient, anatomically grounded framework for reliable brain MRI progression modeling.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14584v1</guid></item><item><title>[cs updates on arXiv.org] Explainable OOHRI: Communicating Robot Capabilities and Limitations as Augmented Reality Affordances</title><link>https://arxiv.org/abs/2601.14587</link><description>arXiv:2601.14587v1 Announce Type: new 
Abstract: Human interaction is essential for issuing personalized instructions and assisting robots when failure is likely. However, robots remain largely black boxes, offering users little insight into their evolving capabilities and limitations. To address this gap, we present explainable object-oriented HRI (X-OOHRI), an augmented reality (AR) interface that conveys robot action possibilities and constraints through visual signifiers, radial menus, color coding, and explanation tags. Our system encodes object properties and robot limits into object-oriented structures using a vision-language model, allowing explanation generation on the fly and direct manipulation of virtual twins spatially aligned within a simulated environment. We integrate the end-to-end pipeline with a physical robot and showcase diverse use cases ranging from low-level pick-and-place to high-level instructions. Finally, we evaluate X-OOHRI through a user study and find that participants effectively issue object-oriented commands, develop accurate mental models of robot limitations, and engage in mixed-initiative resolution.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14587v1</guid></item><item><title>[cs updates on arXiv.org] Designing KRIYA: An AI Companion for Wellbeing Self-Reflection</title><link>https://arxiv.org/abs/2601.14589</link><description>arXiv:2601.14589v1 Announce Type: new 
Abstract: Most personal wellbeing apps present summative dashboards of health and physical activity metrics, yet many users struggle to translate this information into meaningful understanding. These apps commonly support engagement through goals, reminders, and structured targets, which can reinforce comparison, judgment, and performance anxiety. To explore a complementary approach that prioritizes self-reflection, we design KRIYA, an AI wellbeing companion that supports co-interpretive engagement with personal wellbeing data. KRIYA aims to collaborate with users to explore questions, explanations, and future scenarios through features such as Comfort Zone, Detective Mode, and What-If Planning. We conducted semi-structured interviews with 18 college students interacting with a KRIYA prototype using hypothetical data. Our findings show that through KRIYA interaction, users framed engaging with wellbeing data as interpretation rather than performance, experienced reflection as supportive or pressuring depending on emotional framing, and developed trust through transparency. We discuss design implications for AI companions that support curiosity, self-compassion, and reflective sensemaking of personal health data.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14589v1</guid></item><item><title>[cs updates on arXiv.org] Counterfactual Modeling with Fine-Tuned LLMs for Health Intervention Design and Sensor Data Augmentation</title><link>https://arxiv.org/abs/2601.14590</link><description>arXiv:2601.14590v1 Announce Type: new 
Abstract: Counterfactual explanations (CFEs) provide human-centric interpretability by identifying the minimal, actionable changes required to alter a machine learning model's prediction. Therefore, CFs can be used as (i) interventions for abnormality prevention and (ii) augmented data for training robust models. We conduct a comprehensive evaluation of CF generation using large language models (LLMs), including GPT-4 (zero-shot and few-shot) and two open-source models-BioMistral-7B and LLaMA-3.1-8B, in both pretrained and fine-tuned configurations. Using the multimodal AI-READI clinical dataset, we assess CFs across three dimensions: intervention quality, feature diversity, and augmentation effectiveness. Fine-tuned LLMs, particularly LLaMA-3.1-8B, produce CFs with high plausibility (up to 99%), strong validity (up to 0.99), and realistic, behaviorally modifiable feature adjustments. When used for data augmentation under controlled label-scarcity settings, LLM-generated CFs substantially restore classifier performance, yielding an average 20% F1 recovery across three scarcity scenarios. Compared with optimization-based baselines such as DiCE, CFNOW, and NICE, LLMs offer a flexible, model-agnostic approach that generates more clinically actionable and semantically coherent counterfactuals. Overall, this work demonstrates the promise of LLM-driven counterfactuals for both interpretable intervention design and data-efficient model training in sensor-based digital health.
  Impact: SenseCF fine-tunes an LLM to generate valid, representative counterfactual explanations and supplement minority class in an imbalanced dataset for improving model training and boosting model robustness and predictive performance</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14590v1</guid></item><item><title>[cs updates on arXiv.org] From Volumes to Slices: Computationally Efficient Contrastive Learning for Sequential Abdominal CT Analysis</title><link>https://arxiv.org/abs/2601.14593</link><description>arXiv:2601.14593v1 Announce Type: new 
Abstract: The requirement for expert annotations limits the effectiveness of deep learning for medical image analysis. Although 3D self-supervised methods like volume contrast learning (VoCo) are powerful and partially address the labeling scarcity issue, their high computational cost and memory consumption are barriers. We propose 2D-VoCo, an efficient adaptation of the VoCo framework for slice-level self-supervised pre-training that learns spatial-semantic features from unlabeled 2D CT slices via contrastive learning. The pre-trained CNN backbone is then integrated into a CNN-LSTM architecture to classify multi-organ injuries. In the RSNA 2023 Abdominal Trauma dataset, 2D-VoCo pre-training significantly improves mAP, precision, recall, and RSNA score over training from scratch. Our framework provides a practical method to reduce the dependency on labeled data and enhance model performance in clinical CT analysis. We release the code for reproducibility. https://github.com/tkz05/2D-VoCo-CT-Classifier</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14593v1</guid></item><item><title>[cs updates on arXiv.org] LFS: Learnable Frame Selector for Event-Aware and Temporally Diverse Video Captioning</title><link>https://arxiv.org/abs/2601.14594</link><description>arXiv:2601.14594v1 Announce Type: new 
Abstract: Video captioning models convert frames into visual tokens and generate descriptions with large language models (LLMs). Since encoding all frames is prohibitively expensive, uniform sampling is the default choice, but it enforces equal temporal coverage while ignoring the uneven events distribution. This motivates a Learnable Frame Selector (LFS) that selects temporally diverse and event-relevant frames. LFS explicitly models temporal importance to balance temporal diversity and event relevance, and employs a stratified strategy to ensure temporal coverage while avoiding clustering. Crucially, LFS leverages caption feedback from frozen video-LLMs to learn frame selection that directly optimizes downstream caption quality. Additionally, we identify the gap between existing benchmark and human's cognition. Thus, we introduce ICH-CC built from carefully designed questions by annotators that reflect human-consistent understanding of video. Experiments indicate that LFS consistently improves detailed video captioning across two representative community benchmarks and ICH-CC, achieving up to 2.0% gains on VDC and over 4% gains on ICH-CC. Moreover, we observe that enhanced captions with LFS leads to improved performance on video question answering. Overall, LFS provides an effective and easy-to-integrate solution for detailed video captioning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14594v1</guid></item><item><title>[cs updates on arXiv.org] IntelliSA: An Intelligent Static Analyzer for IaC Security Smell Detection Using Symbolic Rules and Neural Inference</title><link>https://arxiv.org/abs/2601.14595</link><description>arXiv:2601.14595v1 Announce Type: new 
Abstract: Infrastructure as Code (IaC) enables automated provisioning of large-scale cloud and on-premise environments, reducing the need for repetitive manual setup. However, this automation is a double-edged sword: a single misconfiguration in IaC scripts can propagate widely, leading to severe system downtime and security risks. Prior studies have shown that IaC scripts often contain security smells--bad coding patterns that may introduce vulnerabilities--and have proposed static analyzers based on symbolic rules to detect them. Yet, our preliminary analysis reveals that rule-based detection alone tends to over-approximate, producing excessive false positives and increasing the burden of manual inspection. In this paper, we present IntelliSA, an intelligent static analyzer for IaC security smell detection that integrates symbolic rules with neural inference. IntelliSA applies symbolic rules to over-approximate potential smells for broad coverage, then employs neural inference to filter false positives. While an LLM can effectively perform this filtering, reliance on LLM APIs introduces high cost and latency, raises data governance concerns, and limits reproducibility and offline deployment. To address the challenges, we adopt a knowledge distillation approach: an LLM teacher generates pseudo-labels to train a compact student model--over 500x smaller--that learns from the teacher's knowledge and efficiently classifies false positives. We evaluate IntelliSA against two static analyzers and three LLM baselines (Claude-4, Grok-4, and GPT-5) using a human-labeled dataset including 241 security smells across 11,814 lines of real-world IaC code. Experimental results show that IntelliSA achieves the highest F1 score (83%), outperforming baselines by 7-42%. Moreover, IntelliSA demonstrates the best cost-effectiveness, detecting 60% of security smells while inspecting less than 2% of the codebase.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14595v1</guid></item><item><title>[cs updates on arXiv.org] Optimality of Staircase Mechanisms for Vector Queries under Differential Privacy</title><link>https://arxiv.org/abs/2601.14597</link><description>arXiv:2601.14597v1 Announce Type: new 
Abstract: We study the optimal design of additive mechanisms for vector-valued queries under $\epsilon$-differential privacy (DP). Given only the sensitivity of a query and a norm-monotone cost function measuring utility loss, we ask which noise distribution minimizes expected cost among all additive $\epsilon$-DP mechanisms. Using convex rearrangement theory, we show that this infinite-dimensional optimization problem admits a reduction to a one-dimensional compact and convex family of radially symmetric distributions whose extreme points are the staircase distributions. As a consequence, we prove that for any dimension, any norm, and any norm-monotone cost function, there exists an $\epsilon$-DP staircase mechanism that is optimal among all additive mechanisms. This result resolves a conjecture of Geng, Kairouz, Oh, and Viswanath, and provides a geometric explanation for the emergence of staircase mechanisms as extremal solutions in differential privacy.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14597v1</guid></item><item><title>[cs updates on arXiv.org] HELIOS: Hierarchical Graph Abstraction for Structure-Aware LLM Decompilation</title><link>https://arxiv.org/abs/2601.14598</link><description>arXiv:2601.14598v1 Announce Type: new 
Abstract: Large language models (LLMs) have recently been applied to binary decompilation, yet they still treat code as plain text and ignore the graphs that govern program control flow. This limitation often yields syntactically fragile and logically inconsistent output, especially for optimized binaries. This paper presents \textsc{HELIOS}, a framework that reframes LLM-based decompilation as a structured reasoning task. \textsc{HELIOS} summarizes a binary's control flow and function calls into a hierarchical text representation that spells out basic blocks, their successors, and high-level patterns such as loops and conditionals. This representation is supplied to a general-purpose LLM, along with raw decompiler output, optionally combined with a compiler-in-the-loop that returns error messages when the generated code fails to build.
  On HumanEval-Decompile for \texttt{x86\_64}, \textsc{HELIOS} raises average object file compilability from 45.0\% to 85.2\% for Gemini~2.0 and from 71.4\% to 89.6\% for GPT-4.1~Mini. With compiler feedback, compilability exceeds 94\% and functional correctness improves by up to 5.6 percentage points over text-only prompting. Across six architectures drawn from x86, ARM, and MIPS, \textsc{HELIOS} reduces the spread in functional correctness while keeping syntactic correctness consistently high, all without fine-tuning. These properties make \textsc{HELIOS} a practical building block for reverse engineering workflows in security settings where analysts need recompilable, semantically faithful code across diverse hardware targets.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14598v1</guid></item><item><title>[cs updates on arXiv.org] Rethinking Reinforcement fine-tuning of LLMs: A Multi-armed Bandit Learning Perspective</title><link>https://arxiv.org/abs/2601.14599</link><description>arXiv:2601.14599v1 Announce Type: new 
Abstract: A large number of heuristics have been proposed to optimize the reinforcement fine-tuning of LLMs. However, inconsistent claims are made from time to time, making this area elusive. Reflecting on this situation, two fundamental questions still lack a clear understanding: 1) what is the role of each optimizing choice? 2) which ones are the bottlenecks? This paper aims to shed light on them, and it faces the challenge of several entangled confounding factors in the fine-tuning process. To tackle this challenge, we propose a bottom-up experiment pipeline. The bottom layer is composed of a minimalist configuration: one training data, one rollout per round and the reward directly serve as the learning signal without advantage function design. This minimalist configuration connects to multi-armed bandit learning with extremely large discrete action space, which offers theories to corroborate the experiment findings. The up procedure of the experiment pipeline expanding the minimalist configuration layer by layer, examining the role of each design choice. Experimental results on three LLMs and two reasoning datasets not only reveal new understanding of the design choice but also yield essential insights to shape the area.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14599v1</guid></item><item><title>[cs updates on arXiv.org] Holmes: An Evidence-Grounded LLM Agent for Auditable DDoS Investigation in Cloud Networks</title><link>https://arxiv.org/abs/2601.14601</link><description>arXiv:2601.14601v1 Announce Type: new 
Abstract: Cloud environments face frequent DDoS threats due to centralized resources and broad attack surfaces. Modern cloud-native DDoS attacks further evolve rapidly and often blend multi-vector strategies, creating an operational dilemma: defenders need wire-speed monitoring while also requiring explainable, auditable attribution for response. Existing rule-based and supervised-learning approaches typically output black-box scores or labels, provide limited evidence chains, and generalize poorly to unseen attack variants; meanwhile, high-quality labeled data is often difficult to obtain in cloud settings.
  We present Holmes (DDoS Detective), an LLM-based DDoS detection agent that reframes the model as a virtual SRE investigator rather than an end-to-end classifier. Holmes couples a funnel-like hierarchical workflow (counters/sFlow for continuous sensing and triage; PCAP evidence collection triggered only on anomaly windows) with an Evidence Pack abstraction that converts binary packets into compact, reproducible, high-signal structured evidence. On top of this evidence interface, Holmes enforces a structure-first investigation protocol and strict JSON/quotation constraints to produce machine-consumable reports with auditable evidence anchors.
  We evaluate Holmes on CICDDoS2019 reflection/amplification attacks and script-triggered flooding scenarios. Results show that Holmes produces attribution decisions grounded in salient evidence anchors across diverse attack families, and when errors occur, its audit logs make the failure source easy to localize, demonstrating the practicality of an LLM agent for cost-controlled and traceable DDoS investigation in cloud operations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14601v1</guid></item><item><title>[cs updates on arXiv.org] 3D Space as a Scratchpad for Editable Text-to-Image Generation</title><link>https://arxiv.org/abs/2601.14602</link><description>arXiv:2601.14602v1 Announce Type: new 
Abstract: Recent progress in large language models (LLMs) has shown that reasoning improves when intermediate thoughts are externalized into explicit workspaces, such as chain-of-thought traces or tool-augmented reasoning. Yet, visual language models (VLMs) lack an analogous mechanism for spatial reasoning, limiting their ability to generate images that accurately reflect geometric relations, object identities, and compositional intent. We introduce the concept of a spatial scratchpad -- a 3D reasoning substrate that bridges linguistic intent and image synthesis. Given a text prompt, our framework parses subjects and background elements, instantiates them as editable 3D meshes, and employs agentic scene planning for placement, orientation, and viewpoint selection. The resulting 3D arrangement is rendered back into the image domain with identity-preserving cues, enabling the VLM to generate spatially consistent and visually coherent outputs. Unlike prior 2D layout-based methods, our approach supports intuitive 3D edits that propagate reliably into final images. Empirically, it achieves a 32% improvement in text alignment on GenAI-Bench, demonstrating the benefit of explicit 3D reasoning for precise, controllable image generation. Our results highlight a new paradigm for vision-language models that deliberate not only in language, but also in space. Code and visualizations at https://oindrilasaha.github.io/3DScratchpad/</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14602v1</guid></item><item><title>[cs updates on arXiv.org] Variance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum</title><link>https://arxiv.org/abs/2601.14603</link><description>arXiv:2601.14603v1 Announce Type: new 
Abstract: Large Language Models (LLMs) achieve competitive performance across diverse natural language processing (NLP) tasks, yet pretraining is computationally demanding, making optimizer efficiency an important practical consideration. Muon accelerates LLM pretraining via orthogonal momentum updates that serve as a matrix analogue of the element-wise sign operator. Motivated by the recent perspective that Adam is a variance-adaptive sign update algorithm, we propose two variants of Muon, Muon-NSR and Muon-VS, which apply variance-adaptive normalization to momentum before orthogonalization. Muon-NSR applies noise-to-signal ratio (NSR) modulation, while Muon-VS performs variance-based scaling without introducing additional hyperparameters. Experiments on GPT-2 and LLaMA pretraining demonstrate that our proposed methods accelerate convergence and consistently achieve lower validation loss than both competitive, well-tuned AdamW and Muon baselines. For example, on the LLaMA-1.2B model, Muon-NSR and Muon-VS reduce the iterations required to reach the target validation loss by $1.36\times$ relative to the well-tuned Muon following the recent benchmark.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14603v1</guid></item><item><title>[cs updates on arXiv.org] U-Harmony: Enhancing Joint Training for Segmentation Models with Universal Harmonization</title><link>https://arxiv.org/abs/2601.14605</link><description>arXiv:2601.14605v1 Announce Type: new 
Abstract: In clinical practice, medical segmentation datasets are often limited and heterogeneous, with variations in modalities, protocols, and anatomical targets across institutions. Existing deep learning models struggle to jointly learn from such diverse data, often sacrificing either generalization or domain-specific knowledge. To overcome these challenges, we propose a joint training method called Universal Harmonization (U-Harmony), which can be integrated into deep learning-based architectures with a domain-gated head, enabling a single segmentation model to learn from heterogeneous datasets simultaneously. By integrating U-Harmony, our approach sequentially normalizes and then denormalizes feature distributions to mitigate domain-specific variations while preserving original dataset-specific knowledge. More appealingly, our framework also supports universal modality adaptation, allowing the seamless learning of new imaging modalities and anatomical classes. Extensive experiments on cross-institutional brain lesion datasets demonstrate the effectiveness of our approach, establishing a new benchmark for robust and adaptable 3D medical image segmentation models in real-world clinical settings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14605v1</guid></item><item><title>[cs updates on arXiv.org] An LLM Agent-based Framework for Whaling Countermeasures</title><link>https://arxiv.org/abs/2601.14606</link><description>arXiv:2601.14606v1 Announce Type: new 
Abstract: With the spread of generative AI in recent years, attacks known as Whaling have become a serious threat. Whaling is a form of social engineering that targets important high-authority individuals within organizations and uses sophisticated fraudulent emails. In the context of Japanese universities, faculty members frequently hold positions that combine research leadership with authority within institutional workflows. This structural characteristic leads to the wide public disclosure of high-value information such as publications, grants, and detailed researcher profiles. Such extensive information exposure enables the construction of highly precise target profiles using generative AI. This raises concerns that Whaling attacks based on high-precision profiling by generative AI will become prevalent. In this study, we propose a Whaling countermeasure framework for university faculty members that constructs personalized defense profiles and uses large language model (LLM)-based agents. We design agents that (i) build vulnerability profiles for each target from publicly available information on faculty members, (ii) identify potential risk scenarios relevant to Whaling defense based on those profiles, (iii) construct defense profiles corresponding to the vulnerabilities and anticipated risks, and (iv) analyze Whaling emails using the defense profiles. Furthermore, we conduct a preliminary risk-assessment experiment. The results indicate that the proposed method can produce judgments accompanied by explanations of response policies that are consistent with the work context of faculty members who are Whaling targets. The findings also highlight practical challenges and considerations for future operational deployment and systematic evaluation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14606v1</guid></item><item><title>[cs updates on arXiv.org] Exploring Performance-Productivity Trade-offs in AMT Runtimes: A Task Bench Study of Itoyori, ItoyoriFBC, HPX, and MPI</title><link>https://arxiv.org/abs/2601.14608</link><description>arXiv:2601.14608v1 Announce Type: new 
Abstract: Asynchronous Many-Task (AMT) runtimes offer a productive alternative to the Message Passing Interface (MPI). However, the diverse AMT landscape makes fair comparisons challenging. Task Bench, proposed by Slaughter et al., addresses this challenge through a parameterized framework for evaluating parallel programming systems. This work integrates two recent cluster AMTs, Itoyori and ItoyoriFBC, into Task Bench for comprehensive evaluation against MPI and HPX. Itoyori employs a Partitioned Global Address Space (PGAS) model with RDMA-based work stealing, while ItoyoriFBC extends it with futurebased synchronization.
  We evaluate these systems in terms of both performance and programmer productivity. Performance is assessed across various configurations, including compute-bound kernels, weak scaling, and both imbalanced and communication-intensive patterns. Performance is quantified using application efficiency, i.e., the percentage of maximum performance achieved, and the Minimum Effective Task Granularity (METG), i.e., the smallest task duration before runtime overheads dominate. Programmer productivity is quantified using Lines of Code (LOC) and the Number of Library Constructs (NLC).
  Our results reveal distinct trade-offs. MPI achieves the highest efficiency for regular, communication-light workloads but requires verbose, lowlevel code. HPX maintains stable efficiency under load imbalance across varying node counts, yet ranks last in productivity metrics, demonstrating that AMTs do not inherently guarantee improved productivity over MPI. Itoyori achieves the highest efficiency in communication-intensive configurations while leading in programmer productivity. ItoyoriFBC exhibits slightly lower efficiency than Itoyori, though its future-based synchronization offers potential for expressing irregular workloads.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14608v1</guid></item><item><title>[cs updates on arXiv.org] Learning Consistent Taxonomic Classification through Hierarchical Reasoning</title><link>https://arxiv.org/abs/2601.14610</link><description>arXiv:2601.14610v1 Announce Type: new 
Abstract: While Vision-Language Models (VLMs) excel at visual understanding, they often fail to grasp hierarchical knowledge. This leads to common errors where VLMs misclassify coarser taxonomic levels even when correctly identifying the most specific level (leaf level). Existing approaches largely overlook this issue by failing to model hierarchical reasoning. To address this gap, we propose VL-Taxon, a two-stage, hierarchy-based reasoning framework designed to improve both leaf-level accuracy and hierarchical consistency in taxonomic classification. The first stage employs a top-down process to enhance leaf-level classification accuracy. The second stage then leverages this accurate leaf-level output to ensure consistency throughout the entire taxonomic hierarchy. Each stage is initially trained with supervised fine-tuning to instill taxonomy knowledge, followed by reinforcement learning to refine the model's reasoning and generalization capabilities. Extensive experiments reveal a remarkable result: our VL-Taxon framework, implemented on the Qwen2.5-VL-7B model, outperforms its original 72B counterpart by over 10% in both leaf-level and hierarchical consistency accuracy on average on the iNaturalist-2021 dataset. Notably, this significant gain was achieved by fine-tuning on just a small subset of data, without relying on any examples generated by other VLMs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14610v1</guid></item><item><title>[cs updates on arXiv.org] Seeing to Think? How Source Transparency Design Shapes Interactive Information Seeking and Evaluation in Conversational AI</title><link>https://arxiv.org/abs/2601.14611</link><description>arXiv:2601.14611v1 Announce Type: new 
Abstract: Conversational AI systems increasingly function as primary interfaces for information seeking, yet how they present sources to support information evaluation remains under-explored. This paper investigates how source transparency design shapes interactive information seeking, trust, and critical engagement. We conducted a controlled between-subjects experiment (N=372) comparing four source presentation interfaces - Collapsible, Hover Card, Footer, and Aligned Sidebar - varying in visibility and accessibility. Using fine-grained behavioral analysis and automated critical thinking assessment, we found that interface design fundamentally alters exploration strategies and evidence integration. While the Hover Card interface facilitated seamless, on-demand verification during the task, the Aligned Sidebar uniquely mitigated the negative effects of information overload: as citation density increased, Sidebar users demonstrated significantly higher critical thinking and synthesis scores compared to other conditions. Our results highlight a trade-off between designs that support workflow fluency and those that enforce reflective verification, offering practical implications for designing adaptive and responsible conversational AI that fosters critical engagement with AI generated content.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14611v1</guid></item><item><title>[cs updates on arXiv.org] An Ion-Intercalation Memristor for Enabling Full Parallel Writing in Crossbar Networks</title><link>https://arxiv.org/abs/2601.14613</link><description>arXiv:2601.14613v1 Announce Type: new 
Abstract: Crossbar architectures have long been seen as a promising foundation for in-memory computing, using memristor arrays for high-density, energy-efficient analog computation. However, this conventional architecture suffers from a fundamental limitation: the inability to perform parallel write operations due to the sneak path problem. This arises from the structural overlap of read and write paths, forcing sequential or semi-parallel updates and severely limiting scalability. To address this, we introduce a new memristor design that decouples read and write operations at the device level. This design enables orthogonal conductive paths, and employs a reversible ion doping mechanism, inspired by lithium-ion battery principles, to modulate resistance states independently of computation. Fabricated devices exhibit near-ideal memristive characteristics and stable performance under isolated read/write conditions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14613v1</guid></item><item><title>[cs updates on arXiv.org] Towards Cybersecurity Superintelligence: from AI-guided humans to human-guided AI</title><link>https://arxiv.org/abs/2601.14614</link><description>arXiv:2601.14614v1 Announce Type: new 
Abstract: Cybersecurity superintelligence -- artificial intelligence exceeding the best human capability in both speed and strategic reasoning -- represents the next frontier in security. This paper documents the emergence of such capability through three major contributions that have pioneered the field of AI Security. First, PentestGPT (2023) established LLM-guided penetration testing, achieving 228.6% improvement over baseline models through an architecture that externalizes security expertise into natural language guidance. Second, Cybersecurity AI (CAI, 2025) demonstrated automated expert-level performance, operating 3,600x faster than humans while reducing costs 156-fold, validated through #1 rankings at international competitions including the $50,000 Neurogrid CTF prize. Third, Generative Cut-the-Rope (G-CTR, 2026) introduces a neurosymbolic architecture embedding game-theoretic reasoning into LLM-based agents: symbolic equilibrium computation augments neural inference, doubling success rates while reducing behavioral variance 5.2x and achieving 2:1 advantage over non-strategic AI in Attack &amp; Defense scenarios.
  Together, these advances establish a clear progression from AI-guided humans to human-guided game-theoretic cybersecurity superintelligence.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14614v1</guid></item><item><title>[cs updates on arXiv.org] SearchGym: Bootstrapping Real-World Search Agents via Cost-Effective and High-Fidelity Environment Simulation</title><link>https://arxiv.org/abs/2601.14615</link><description>arXiv:2601.14615v1 Announce Type: new 
Abstract: Search agents have emerged as a pivotal paradigm for solving open-ended, knowledge-intensive reasoning tasks. However, training these agents via Reinforcement Learning (RL) faces a critical dilemma: interacting with live commercial Web APIs is prohibitively expensive, while relying on static data snapshots often introduces noise due to data misalignment. This misalignment generates corrupted reward signals that destabilize training by penalizing correct reasoning or rewarding hallucination. To address this, we propose SearchGym, a simulation environment designed to bootstrap robust search agents. SearchGym employs a rigorous generative pipeline to construct a verifiable knowledge graph and an aligned document corpus, ensuring that every reasoning task is factually grounded and strictly solvable. Building on this controllable environment, we introduce SearchGym-RL, a curriculum learning methodology that progressively optimizes agent policies through purified feedback, evolving from basic interactions to complex, long-horizon planning. Extensive experiments across the Llama and Qwen families demonstrate strong Sim-to-Real generalization. Notably, our Qwen2.5-7B-Base model trained within SearchGym surpasses the web-enhanced ASearcher baseline across nine diverse benchmarks by an average relative margin of 10.6%. Our results validate that high-fidelity simulation serves as a scalable and highly cost-effective methodology for developing capable search agents.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14615v1</guid></item><item><title>[cs updates on arXiv.org] Maximum Edge-based Quasi-Clique: Novel Iterative Frameworks</title><link>https://arxiv.org/abs/2601.14619</link><description>arXiv:2601.14619v1 Announce Type: new 
Abstract: Extracting cohesive subgraphs from complex networks is a fundamental task in graph analytics and is essential for understanding biological, social, and web graphs. The edge-based $\gamma$-quasi-clique model offers a flexible alternative by identifying subgraphs whose edge densities exceed a specified threshold $\gamma$. However, finding the exact maximum edge-based quasi-clique is computationally challenging, as the problem is NP-hard and lacks the hereditary property. These characteristics limit the effectiveness of conventional pruning methods and the development of efficient reduction rules. As a result, existing algorithms, such as QClique and FPCE, struggle to scale to large graphs. In this paper, we revisit the problem and propose a novel iterative framework that reformulates the problem as a sequence of hereditary subproblems, enabling more effective pruning and reduction strategies and improving the worst-case time complexity. Furthermore, we redesign the iterative process and introduce a novel heuristic to further improve practical efficiency. Extensive experiments on 253 large-scale real-world graphs demonstrate that our proposed algorithm EQC-Pro outperforms existing methods by up to four orders of magnitude.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14619v1</guid></item><item><title>[cs updates on arXiv.org] Probing Prompt Design for Socially Compliant Robot Navigation with Vision Language Models</title><link>https://arxiv.org/abs/2601.14622</link><description>arXiv:2601.14622v1 Announce Type: new 
Abstract: Language models are increasingly used for social robot navigation, yet existing benchmarks largely overlook principled prompt design for socially compliant behavior. This limitation is particularly relevant in practice, as many systems rely on small vision language models (VLMs) for efficiency. Compared to large language models, small VLMs exhibit weaker decision-making capabilities, making effective prompt design critical for accurate navigation. Inspired by cognitive theories of human learning and motivation, we study prompt design along two dimensions: system guidance (action-focused, reasoning-oriented, and perception-reasoning prompts) and motivational framing, where models compete against humans, other AI systems, or their past selves. Experiments on two socially compliant navigation datasets reveal three key findings. First, for non-finetuned GPT-4o, competition against humans achieves the best performance, while competition against other AI systems performs worst. For finetuned models, competition against the model's past self yields the strongest results, followed by competition against humans, with performance further influenced by coupling effects among prompt design, model choice, and dataset characteristics. Second, inappropriate system prompt design can significantly degrade performance, even compared to direct finetuning. Third, while direct finetuning substantially improves semantic-level metrics such as perception, prediction, and reasoning, it yields limited gains in action accuracy. In contrast, our system prompts produce a disproportionately larger improvement in action accuracy, indicating that the proposed prompt design primarily acts as a decision-level constraint rather than a representational enhancement.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14622v1</guid></item><item><title>[cs updates on arXiv.org] Break-Resilient Codes with Loss Tolerance</title><link>https://arxiv.org/abs/2601.14623</link><description>arXiv:2601.14623v1 Announce Type: new 
Abstract: Emerging applications in manufacturing, wireless communication, and molecular data storage require robust coding schemes that remain effective under physical distortions where codewords may be arbitrarily fragmented and partially missing. To address such challenges, we propose a new family of error-correcting codes, termed $(t,s)$-break-resilient codes ($(t,s)$-BRCs). A $(t,s)$-BRC guarantees correct decoding of the original message even after up to~$t$ arbitrary breaks of the codeword and the complete loss of some fragments whose total length is at most~$s$. This model unifies and generalizes previous approaches, extending break-resilient codes (which handle arbitrary fragmentation without fragment loss) and deletion codes (which correct bit losses in unknown positions without fragmentation) into a single information-theoretic framework. We develop a theoretical foundation for $(t,s)$-BRCs, including a formal adversarial channel model, lower bounds on the necessary redundancy, and explicit code constructions that approach these bounds.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14623v1</guid></item><item><title>[cs updates on arXiv.org] Diffusion Epistemic Uncertainty with Asymmetric Learning for Diffusion-Generated Image Detection</title><link>https://arxiv.org/abs/2601.14625</link><description>arXiv:2601.14625v1 Announce Type: new 
Abstract: The rapid progress of diffusion models highlights the growing need for detecting generated images. Previous research demonstrates that incorporating diffusion-based measurements, such as reconstruction error, can enhance the generalizability of detectors. However, ignoring the differing impacts of aleatoric and epistemic uncertainty on reconstruction error can undermine detection performance. Aleatoric uncertainty, arising from inherent data noise, creates ambiguity that impedes accurate detection of generated images. As it reflects random variations within the data (e.g., noise in natural textures), it does not help distinguish generated images. In contrast, epistemic uncertainty, which represents the model's lack of knowledge about unfamiliar patterns, supports detection. In this paper, we propose a novel framework, Diffusion Epistemic Uncertainty with Asymmetric Learning~(DEUA), for detecting diffusion-generated images. We introduce Diffusion Epistemic Uncertainty~(DEU) estimation via the Laplace approximation to assess the proximity of data to the manifold of diffusion-generated samples. Additionally, an asymmetric loss function is introduced to train a balanced classifier with larger margins, further enhancing generalizability. Extensive experiments on large-scale benchmarks validate the state-of-the-art performance of our method.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14625v1</guid></item><item><title>[cs updates on arXiv.org] A Brain-inspired Embodied Intelligence for Fluid and Fast Reflexive Robotics Control</title><link>https://arxiv.org/abs/2601.14628</link><description>arXiv:2601.14628v1 Announce Type: new 
Abstract: Recent advances in embodied intelligence have leveraged massive scaling of data and model parameters to master natural-language command following and multi-task control. In contrast, biological systems demonstrate an innate ability to acquire skills rapidly from sparse experience. Crucially, current robotic policies struggle to replicate the dynamic stability, reflexive responsiveness, and temporal memory inherent in biological motion. Here we present Neuromorphic Vision-Language-Action (NeuroVLA), a framework that mimics the structural organization of the bio-nervous system between the cortex, cerebellum, and spinal cord. We adopt a system-level bio-inspired design: a high-level model plans goals, an adaptive cerebellum module stabilizes motion using high-frequency sensors feedback, and a bio-inspired spinal layer executes lightning-fast actions generation. NeuroVLA represents the first deployment of a neuromorphic VLA on physical robotics, achieving state-of-the-art performance. We observe the emergence of biological motor characteristics without additional data or special guidance: it stops the shaking in robotic arms, saves significant energy(only 0.4w on Neuromorphic Processor), shows temporal memory ability and triggers safety reflexes in less than 20 milliseconds.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14628v1</guid></item><item><title>[cs updates on arXiv.org] Relational Graph Modeling for Credit Default Prediction: Heterogeneous GNNs and Hybrid Ensemble Learning</title><link>https://arxiv.org/abs/2601.14633</link><description>arXiv:2601.14633v1 Announce Type: new 
Abstract: Credit default risk arises from complex interactions among borrowers, financial institutions, and transaction-level behaviors. While strong tabular models remain highly competitive in credit scoring, they may fail to explicitly capture cross-entity dependencies embedded in multi-table financial histories. In this work, we construct a massive-scale heterogeneous graph containing over 31 million nodes and more than 50 million edges, integrating borrower attributes with granular transaction-level entities such as installment payments, POS cash balances, and credit card histories.
  We evaluate heterogeneous graph neural networks (GNNs), including heterogeneous GraphSAGE and a relation-aware attentive heterogeneous GNN, against strong tabular baselines. We find that standalone GNNs provide limited lift over a competitive gradient-boosted tree baseline, while a hybrid ensemble that augments tabular features with GNN-derived customer embeddings achieves the best overall performance, improving both ROC-AUC and PR-AUC. We further observe that contrastive pretraining can improve optimization stability but yields limited downstream gains under generic graph augmentations. Finally, we conduct structured explainability and fairness analyses to characterize how relational signals affect subgroup behavior and screening-oriented outcomes.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14633v1</guid></item><item><title>[cs updates on arXiv.org] Forest-Chat: Adapting Vision-Language Agents for Interactive Forest Change Analysis</title><link>https://arxiv.org/abs/2601.14637</link><description>arXiv:2601.14637v1 Announce Type: new 
Abstract: The increasing availability of high-resolution satellite imagery, together with advances in deep learning, creates new opportunities for enhancing forest monitoring workflows. Two central challenges in this domain are pixel-level change detection and semantic change interpretation, particularly for complex forest dynamics. While large language models (LLMs) are increasingly adopted for data exploration, their integration with vision-language models (VLMs) for remote sensing image change interpretation (RSICI) remains underexplored, especially beyond urban environments. We introduce Forest-Chat, an LLM-driven agent designed for integrated forest change analysis. The proposed framework enables natural language querying and supports multiple RSICI tasks, including change detection, change captioning, object counting, deforestation percentage estimation, and change reasoning. Forest-Chat builds upon a multi-level change interpretation (MCI) vision-language backbone with LLM-based orchestration, and incorporates zero-shot change detection via a foundation change detection model together with an interactive point-prompt interface to support fine-grained user guidance. To facilitate adaptation and evaluation in forest environments, we introduce the Forest-Change dataset, comprising bi-temporal satellite imagery, pixel-level change masks, and multi-granularity semantic change captions generated through a combination of human annotation and rule-based methods. Experimental results demonstrate that Forest-Chat achieves strong performance on Forest-Change and on LEVIR-MCI-Trees, a tree-focused subset of LEVIR-MCI, for joint change detection and captioning, highlighting the potential of interactive, LLM-driven RSICI systems to improve accessibility, interpretability, and analytical efficiency in forest change analysis.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14637v1</guid></item><item><title>[cs updates on arXiv.org] DesignBridge: Bridging Designer Expertise and User Preferences through AI-Enhanced Co-Design for Fashion</title><link>https://arxiv.org/abs/2601.14639</link><description>arXiv:2601.14639v1 Announce Type: new 
Abstract: Effective collaboration between designers and users is important for fashion design, which can increase the user acceptance of fashion products and thereby create value. However, it remains an enduring challenge, as traditional designer-centric approaches restrict meaningful user participation, while user-driven methods demand design proficiency, often marginalizing professional creative judgment. Current co-design practices, including workshops and AI-assisted frameworks, struggle with low user engagement, inefficient preference collection, and difficulties in balancing user feedback with design considerations. To address these challenges, we conducted a formative study with designers and users experienced in co-design (N=7), identifying critical challenges for current collaboration between designers and users in the co-design process, and their requirements. Informed by these insights, we introduce DesignBridge, a multi-platform AI-enhanced interactive system that bridges designer expertise and user preferences through three stages: (1) Initial Design Framing, where designers define initial concepts. (2) Preference Expression Collection, where users intuitively articulate preferences via interactive tools. (3) Preference-Integrated Design, where designers use AI-assisted analytics to integrate feedback into cohesive designs. A user study demonstrates that DesignBridge significantly enhances user preference collection and analysis, enabling designers to integrate diverse preferences with professional expertise.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14639v1</guid></item><item><title>[cs updates on arXiv.org] MIND: Empowering Mental Health Clinicians with Multimodal Data Insights through a Narrative Dashboard</title><link>https://arxiv.org/abs/2601.14641</link><description>arXiv:2601.14641v1 Announce Type: new 
Abstract: Advances in data collection enable the capture of rich patient-generated data: from passive sensing (e.g., wearables and smartphones) to active self-reports (e.g., cross-sectional surveys and ecological momentary assessments). Although prior research has demonstrated the utility of patient-generated data in mental healthcare, significant challenges remain in effectively presenting these data streams along with clinical data (e.g., clinical notes) for clinical decision-making. Through co-design sessions with five clinicians, we propose MIND, a large language model-powered dashboard designed to present clinically relevant multimodal data insights for mental healthcare. MIND presents multimodal insights through narrative text, complemented by charts communicating underlying data. Our user study (N=16) demonstrates that clinicians perceive MIND as a significant improvement over baseline methods, reporting improved performance to reveal hidden and clinically relevant data insights (p&lt;.001) and support their decision-making (p=.004). Grounded in the study results, we discuss future research opportunities to integrate data narratives in broader clinical practices.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14641v1</guid></item><item><title>[cs updates on arXiv.org] Input-to-State Stabilizing Neural Controllers for Unknown Switched Nonlinear Systems within Compact Sets</title><link>https://arxiv.org/abs/2601.14643</link><description>arXiv:2601.14643v1 Announce Type: new 
Abstract: This paper develops a neural network based control framework that ensures system safety and input-to-state stability (ISS) for general nonlinear switched systems with unknown dynamics. Leveraging the concept of dwell time, we derive Lyapunov based sufficient conditions under which both safety and ISS of the closed-loop switched system are guaranteed. The feedback controllers and the associated Lyapunov functions are parameterized using neural networks and trained from data collected over a compact state space via deterministic sampling. To provide formal stability guarantees under the learned controllers, we introduce a validity condition based on Lipschitz continuity assumptions, which is embedded directly into the training framework. This ensures that the resulting neural network controllers satisfy provable correctness and stability guarantees beyond the sampled data. As a special case, the proposed framework recovers ISS and safety under arbitrary switching when a common Lyapunov function exists. Simulation results on a representative switched nonlinear system demonstrate the effectiveness of the proposed approach.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14643v1</guid></item><item><title>[cs updates on arXiv.org] Spatially Generalizable Mobile Manipulation via Adaptive Experience Selection and Dynamic Imagination</title><link>https://arxiv.org/abs/2601.14649</link><description>arXiv:2601.14649v1 Announce Type: new 
Abstract: Mobile Manipulation (MM) involves long-horizon decision-making over multi-stage compositions of heterogeneous skills, such as navigation and picking up objects. Despite recent progress, existing MM methods still face two key limitations: (i) low sample efficiency, due to ineffective use of redundant data generated during long-term MM interactions; and (ii) poor spatial generalization, as policies trained on specific tasks struggle to transfer to new spatial layouts without additional training. In this paper, we address these challenges through Adaptive Experience Selection (AES) and model-based dynamic imagination. In particular, AES makes MM agents pay more attention to critical experience fragments in long trajectories that affect task success, improving skill chain learning and mitigating skill forgetting. Based on AES, a Recurrent State-Space Model (RSSM) is introduced for Model-Predictive Forward Planning (MPFP) by capturing the coupled dynamics between the mobile base and the manipulator and imagining the dynamics of future manipulations. RSSM-based MPFP can reinforce MM skill learning on the current task while enabling effective generalization to new spatial layouts. Comparative studies across different experimental configurations demonstrate that our method significantly outperforms existing MM policies. Real-world experiments further validate the feasibility and practicality of our method.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14649v1</guid></item><item><title>[cs updates on arXiv.org] READ-Net: Clarifying Emotional Ambiguity via Adaptive Feature Recalibration for Audio-Visual Depression Detection</title><link>https://arxiv.org/abs/2601.14651</link><description>arXiv:2601.14651v1 Announce Type: new 
Abstract: Depression is a severe global mental health issue that impairs daily functioning and overall quality of life. Although recent audio-visual approaches have improved automatic depression detection, methods that ignore emotional cues often fail to capture subtle depressive signals hidden within emotional expressions. Conversely, those incorporating emotions frequently confuse transient emotional expressions with stable depressive symptoms in feature representations, a phenomenon termed \emph{Emotional Ambiguity}, thereby leading to detection errors. To address this critical issue, we propose READ-Net, the first audio-visual depression detection framework explicitly designed to resolve Emotional Ambiguity through Adaptive Feature Recalibration (AFR). The core insight of AFR is to dynamically adjust the weights of emotional features to enhance depression-related signals. Rather than merely overlooking or naively combining emotional information, READ-Net innovatively identifies and preserves depressive-relevant cues within emotional features, while adaptively filtering out irrelevant emotional noise. This recalibration strategy significantly clarifies feature representations, and effectively mitigates the persistent challenge of emotional interference. Additionally, READ-Net can be easily integrated into existing frameworks for improved performance. Extensive evaluations on three publicly available datasets show that READ-Net outperforms state-of-the-art methods, with average gains of 4.55\% in accuracy and 1.26\% in F1-score, demonstrating its robustness to emotional disturbances and improving audio-visual depression detection.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14651v1</guid></item><item><title>[cs updates on arXiv.org] MAS-Orchestra: Understanding and Improving Multi-Agent Reasoning Through Holistic Orchestration and Controlled Benchmarks</title><link>https://arxiv.org/abs/2601.14652</link><description>arXiv:2601.14652v1 Announce Type: new 
Abstract: While multi-agent systems (MAS) promise elevated intelligence through coordination of agents, current approaches to automatic MAS design under-deliver. Such shortcomings stem from two key factors: (1) methodological complexity - agent orchestration is performed using sequential, code-level execution that limits global system-level holistic reasoning and scales poorly with agent complexity - and (2) efficacy uncertainty - MAS are deployed without understanding if there are tangible benefits compared to single-agent systems (SAS). We propose MAS-Orchestra, a training-time framework that formulates MAS orchestration as a function-calling reinforcement learning problem with holistic orchestration, generating an entire MAS at once. In MAS-Orchestra, complex, goal-oriented sub-agents are abstracted as callable functions, enabling global reasoning over system structure while hiding internal execution details. To rigorously study when and why MAS are beneficial, we introduce MASBENCH, a controlled benchmark that characterizes tasks along five axes: Depth, Horizon, Breadth, Parallel, and Robustness. Our analysis reveals that MAS gains depend critically on task structure, verification protocols, and the capabilities of both orchestrator and sub-agents, rather than holding universally. Guided by these insights, MAS-Orchestra achieves consistent improvements on public benchmarks including mathematical reasoning, multi-hop QA, and search-based QA. Together, MAS-Orchestra and MASBENCH enable better training and understanding of MAS in the pursuit of multi-agent intelligence.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14652v1</guid></item><item><title>[cs updates on arXiv.org] Say Anything but This: When Tokenizer Betrays Reasoning in LLMs</title><link>https://arxiv.org/abs/2601.14658</link><description>arXiv:2601.14658v1 Announce Type: new 
Abstract: Large language models (LLMs) reason over discrete token ID sequences, yet modern subword tokenizers routinely produce non-unique encodings: multiple token ID sequences can detokenize to identical surface strings. This representational mismatch creates an unmeasured fragility wherein reasoning processes can fail. LLMs may treat two internal representations as distinct "words" even when they are semantically identical at the text level. In this work, we show that tokenization can betray LLM reasoning through one-to-many token ID mappings. We introduce a tokenization-consistency probe that requires models to replace designated target words in context while leaving all other content unchanged. The task is intentionally simple at the surface level, enabling us to attribute failures to tokenizer-detokenizer artifacts rather than to knowledge gaps or parameter limitations. Through analysis of over 11000 replacement trials across state-of-the-art open-source LLMs, we find a non-trivial rate of outputs exhibit phantom edits: cases where models operate under the illusion of correct reasoning, a phenomenon arising from tokenizer-induced representational defects. We further analyze these cases and provide a taxonomy of eight systematic tokenizer artifacts, including whitespace-boundary shifts and intra-word resegmentation. These findings indicate that part of apparent reasoning deficiency originates in the tokenizer layer, motivating tokenizer-level remedies before incurring the cost of training ever-larger models on ever-larger corpora.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14658v1</guid></item><item><title>[cs updates on arXiv.org] NeuroFilter: Privacy Guardrails for Conversational LLM Agents</title><link>https://arxiv.org/abs/2601.14660</link><description>arXiv:2601.14660v1 Announce Type: new 
Abstract: This work addresses the computational challenge of enforcing privacy for agentic Large Language Models (LLMs), where privacy is governed by the contextual integrity framework. Indeed, existing defenses rely on LLM-mediated checking stages that add substantial latency and cost, and that can be undermined in multi-turn interactions through manipulation or benign-looking conversational scaffolding. Contrasting this background, this paper makes a key observation: internal representations associated with privacy-violating intent can be separated from benign requests using linear structure. Using this insight, the paper proposes NeuroFilter, a guardrail framework that operationalizes contextual integrity by mapping norm violations to simple directions in the model's activation space, enabling detection even when semantic filters are bypassed. The proposed filter is also extended to capture threats arising during long conversations using the concept of activation velocity, which measures cumulative drift in internal representations across turns. A comprehensive evaluation across over 150,000 interactions and covering models from 7B to 70B parameters, illustrates the strong performance of NeuroFilter in detecting privacy attacks while maintaining zero false positives on benign prompts, all while reducing the computational inference cost by several orders of magnitude when compared to LLM-based agentic privacy defenses.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14660v1</guid></item><item><title>[cs updates on arXiv.org] Query-Efficient Agentic Graph Extraction Attacks on GraphRAG Systems</title><link>https://arxiv.org/abs/2601.14662</link><description>arXiv:2601.14662v1 Announce Type: new 
Abstract: Graph-based retrieval-augmented generation (GraphRAG) systems construct knowledge graphs over document collections to support multi-hop reasoning. While prior work shows that GraphRAG responses may leak retrieved subgraphs, the feasibility of query-efficient reconstruction of the hidden graph structure remains unexplored under realistic query budgets. We study a budget-constrained black-box setting where an adversary adaptively queries the system to steal its latent entity-relation graph. We propose AGEA (Agentic Graph Extraction Attack), a framework that leverages a novelty-guided exploration-exploitation strategy, external graph memory modules, and a two-stage graph extraction pipeline combining lightweight discovery with LLM-based filtering. We evaluate AGEA on medical, agriculture, and literary datasets across Microsoft-GraphRAG and LightRAG systems. Under identical query budgets, AGEA significantly outperforms prior attack baselines, recovering up to 90% of entities and relationships while maintaining high precision. These results demonstrate that modern GraphRAG systems are highly vulnerable to structured, agentic extraction attacks, even under strict query limits.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14662v1</guid></item><item><title>[cs updates on arXiv.org] Calibrated uncertainty quantification for prosumer flexibility aggregation in ancillary service markets</title><link>https://arxiv.org/abs/2601.14663</link><description>arXiv:2601.14663v1 Announce Type: new 
Abstract: Reliable forecasting of prosumer flexibility is critical for demand response aggregators participating in frequency controlled ancillary services market, where strict reliability requirements such as the P90 standard are enforced. Limited historical data, dependence on exogeneous factors, and heterogenous prosumer behaviour introduce significant epistemic uncertainty, making deterministic or poorly calibrated probabilistic models unsuitable for market bidding. This paper proposes the use of scalable uncertainty quantification framework that integrates Monte Carlo dropout (MCD) with conformal prediction (CP) to produce calibrated, finite sample prediction intervals for aggregated prosumer flexibility. The proposed framework is applied to a behind-the-meter aggregator participating in the Danish manual frequency restoration reserve capacity market. A large-scale synthetic dataset is generated using a modified industry-grade home energy management system, combined with publicly available load, solar, price, activation and device-level data. The resulting machine learning surrogate model captures aggregate prosumer price responsiveness and provides uncertainty-aware estimates suitable for market bidding. Multiple multivariate CP strategies are evaluated and benchmarked against conventional MCD-based methods. Results show that standalone MCD systematically overestimates available flexibility and violates P90 compliance, whereas the proposed MCD-CP framework achieves reliable coverage with controlled conservatism. When embedded in aggregator bidding model, conformalised methods substantially reduce overbidding risk and achieve upto 70% of perfect-information profit while satisfying regulatory reliability constraints, providing practical, computationally efficient, and market-compliant solution for aggregator flexibility forecasting under uncertainty.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14663v1</guid></item><item><title>[cs updates on arXiv.org] A Two-Stage Risk-Averse DRO-MILP Methodological Framework for Managing AI/Data Center Demand Shocks</title><link>https://arxiv.org/abs/2601.14665</link><description>arXiv:2601.14665v1 Announce Type: new 
Abstract: The rapid growth of artificial intelligence (AI)-driven data centers is reshaping electricity demand patterns. This is achieved by introducing fast, multi-gigawatt load ramps that challenge the stability and resilience of modern power systems. Traditional resilience frameworks focus mainly on physical outages and largely overlook these emerging digital-era disturbances. This paper proposes a unified two-stage, risk-aware distributionally robust optimization (DRO)-MILP framework that coordinates the pre-allocation and post-event dispatch of Flexible Capacity Modules (FCMs), including BESS, fast-ramping generation, demand response, and potential long-duration storage. Stage-I optimally positions FCMs using DRO with CVaR to hedge against uncertain AI load surges. Stage-II models real-time stabilization following stochastic demand-shock scenarios, minimizing imbalance, unserved energy, and restoration penalties. The framework is designed to be applied on IEEE 33-bus system or expanded for scalability to larger IEEE test feeders capable of representing AI-scale loads. This contributes a scalable planning tool for resilient, AI-integrated distribution grids.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14665v1</guid></item><item><title>[cs updates on arXiv.org] INFA-Guard: Mitigating Malicious Propagation via Infection-Aware Safeguarding in LLM-Based Multi-Agent Systems</title><link>https://arxiv.org/abs/2601.14667</link><description>arXiv:2601.14667v1 Announce Type: new 
Abstract: The rapid advancement of Large Language Model (LLM)-based Multi-Agent Systems (MAS) has introduced significant security vulnerabilities, where malicious influence can propagate virally through inter-agent communication. Conventional safeguards often rely on a binary paradigm that strictly distinguishes between benign and attack agents, failing to account for infected agents i.e., benign entities converted by attack agents. In this paper, we propose Infection-Aware Guard, INFA-Guard, a novel defense framework that explicitly identifies and addresses infected agents as a distinct threat category. By leveraging infection-aware detection and topological constraints, INFA-Guard accurately localizes attack sources and infected ranges. During remediation, INFA-Guard replaces attackers and rehabilitates infected ones, avoiding malicious propagation while preserving topological integrity. Extensive experiments demonstrate that INFA-Guard achieves state-of-the-art performance, reducing the Attack Success Rate (ASR) by an average of 33%, while exhibiting cross-model robustness, superior topological generalization, and high cost-effectiveness.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14667v1</guid></item><item><title>[cs updates on arXiv.org] Mirai: Autoregressive Visual Generation Needs Foresight</title><link>https://arxiv.org/abs/2601.14671</link><description>arXiv:2601.14671v1 Announce Type: new 
Abstract: Autoregressive (AR) visual generators model images as sequences of discrete tokens and are trained with next token likelihood. This strict causality supervision optimizes each step only by its immediate next token, which diminishes global coherence and slows convergence. We ask whether foresight, training signals that originate from later tokens, can help AR visual generation. We conduct a series of controlled diagnostics along the injection level, foresight layout, and foresight source axes, unveiling a key insight: aligning foresight to AR models' internal representation on the 2D image grids improves causality modeling. We formulate this insight with Mirai (meaning "future" in Japanese), a general framework that injects future information into AR training with no architecture change and no extra inference overhead: Mirai-E uses explicit foresight from multiple future positions of unidirectional representations, whereas Mirai-I leverages implicit foresight from matched bidirectional representations. Extensive experiments show that Mirai significantly accelerates convergence and improves generation quality. For instance, Mirai can speed up LlamaGen-B's convergence by up to 10$\times$ and reduce the generation FID from 5.34 to 4.34 on the ImageNet class-condition image generation benchmark. Our study highlights that visual autoregressive models need foresight.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14671v1</guid></item><item><title>[cs updates on arXiv.org] GEGO: A Hybrid Golden Eagle and Genetic Optimization Algorithm for Efficient Hyperparameter Tuning in Resource-Constrained Environments</title><link>https://arxiv.org/abs/2601.14672</link><description>arXiv:2601.14672v1 Announce Type: new 
Abstract: Hyperparameter tuning is a critical yet computationally expensive step in training neural networks, particularly when the search space is high dimensional and nonconvex. Metaheuristic optimization algorithms are often used for this purpose due to their derivative free nature and robustness against local optima. In this work, we propose Golden Eagle Genetic Optimization (GEGO), a hybrid metaheuristic that integrates the population movement strategy of Golden Eagle Optimization with the genetic operators of selection, crossover, and mutation.
  The main novelty of GEGO lies in embedding genetic operators directly into the iterative search process of GEO, rather than applying them as a separate evolutionary stage. This design improves population diversity during search and reduces premature convergence while preserving the exploration behavior of GEO.
  GEGO is evaluated on standard unimodal, multimodal, and composite benchmark functions from the CEC2017 suite, where it consistently outperforms its constituent algorithms and several classical metaheuristics in terms of solution quality and robustness. The algorithm is further applied to hyperparameter tuning of artificial neural networks on the MNIST dataset, where GEGO achieves improved classification accuracy and more stable convergence compared to GEO and GA. These results indicate that GEGO provides a balanced exploration-exploitation tradeoff and is well suited for hyperparameter optimization under constrained computational settings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14672v1</guid></item><item><title>[cs updates on arXiv.org] Efficient reformulations of ReLU deep neural networks for surrogate modelling in power system optimisation</title><link>https://arxiv.org/abs/2601.14673</link><description>arXiv:2601.14673v1 Announce Type: new 
Abstract: The ongoing decarbonisation of power systems is driving an increasing reliance on distributed energy resources, which introduces complex and nonlinear interactions that are difficult to capture in conventional optimisation models. As a result, machine learning based surrogate modelling has emerged as a promising approach, but integrating machine learning models such as ReLU deep neural networks (DNNs) directly into optimisation often results in nonconvex and computationally intractable formulations. This paper proposes a linear programming (LP) reformulation for a class of convexified ReLU DNNs with non-negative weight matrices beyond the first layer, enabling a tight and tractable embedding of learned surrogate models in optimisation. We evaluate the method using a case study on learning the prosumer's responsiveness within an aggregator bidding problem in the Danish tertiary capacity market. The proposed reformulation is benchmarked against state-of-the-art alternatives, including piecewise linearisation (PWL), MIP-based embedding, and other LP relaxations. Across multiple neural network architectures and market scenarios, the convexified ReLU DNN achieves solution quality comparable to PWL and MIP-based reformulations while significantly improving computational performance and preserving model fidelity, unlike penalty-based reformulations. The results demonstrate that convexified ReLU DNNs offer a scalable and reliable methodology for integrating learned surrogate models in optimisation, with applicability to a wide range of emerging power system applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14673v1</guid></item><item><title>[cs updates on arXiv.org] LaVR: Scene Latent Conditioned Generative Video Trajectory Re-Rendering using Large 4D Reconstruction Models</title><link>https://arxiv.org/abs/2601.14674</link><description>arXiv:2601.14674v1 Announce Type: new 
Abstract: Given a monocular video, the goal of video re-rendering is to generate views of the scene from a novel camera trajectory. Existing methods face two distinct challenges. Geometrically unconditioned models lack spatial awareness, leading to drift and deformation under viewpoint changes. On the other hand, geometrically-conditioned models depend on estimated depth and explicit reconstruction, making them susceptible to depth inaccuracies and calibration errors.
  We propose to address these challenges by using the implicit geometric knowledge embedded in the latent space of a large 4D reconstruction model to condition the video generation process. These latents capture scene structure in a continuous space without explicit reconstruction. Therefore, they provide a flexible representation that allows the pretrained diffusion prior to regularize errors more effectively. By jointly conditioning on these latents and source camera poses, we demonstrate that our model achieves state-of-the-art results on the video re-rendering task. Project webpage is https://lavr-4d-scene-rerender.github.io/</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14674v1</guid></item><item><title>[cs updates on arXiv.org] A comprehensive overview of deep learning models for object detection from videos/images</title><link>https://arxiv.org/abs/2601.14677</link><description>arXiv:2601.14677v1 Announce Type: new 
Abstract: Object detection in video and image surveillance is a well-established yet rapidly evolving task, strongly influenced by recent deep learning advancements. This review summarises modern techniques by examining architectural innovations, generative model integration, and the use of temporal information to enhance robustness and accuracy. Unlike earlier surveys, it classifies methods based on core architectures, data processing strategies, and surveillance specific challenges such as dynamic environments, occlusions, lighting variations, and real-time requirements. The primary goal is to evaluate the current effectiveness of semantic object detection, while secondary aims include analysing deep learning models and their practical applications. The review covers CNN-based detectors, GAN-assisted approaches, and temporal fusion methods, highlighting how generative models support tasks such as reconstructing missing frames, reducing occlusions, and normalising illumination. It also outlines preprocessing pipelines, feature extraction progress, benchmarking datasets, and comparative evaluations. Finally, emerging trends in low-latency, efficient, and spatiotemporal learning approaches are identified for future research.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14677v1</guid></item><item><title>[cs updates on arXiv.org] Transfer Learning from One Cancer to Another via Deep Learning Domain Adaptation</title><link>https://arxiv.org/abs/2601.14678</link><description>arXiv:2601.14678v1 Announce Type: new 
Abstract: Supervised deep learning models often achieve excellent performance within their training distribution but struggle to generalize beyond it. In cancer histopathology, for example, a convolutional neural network (CNN) may classify cancer severity accurately for cancer types represented in its training data, yet fail on related but unseen types. Although adenocarcinomas from different organs share morphological features that might support limited cross-domain generalization, addressing domain shift directly is necessary for robust performance. Domain adaptation offers a way to transfer knowledge from labeled data in one cancer type to unlabeled data in another, helping mitigate the scarcity of annotated medical images.
  This work evaluates cross-domain classification performance among lung, colon, breast, and kidney adenocarcinomas. A ResNet50 trained on any single adenocarcinoma achieves over 98% accuracy on its own domain but shows minimal generalization to others. Ensembling multiple supervised models does not resolve this limitation. In contrast, converting the ResNet50 into a domain adversarial neural network (DANN) substantially improves performance on unlabeled target domains. A DANN trained on labeled breast and colon data and adapted to unlabeled lung data reaches 95.56% accuracy.
  We also examine the impact of stain normalization on domain adaptation. Its effects vary by target domain: for lung, accuracy drops from 95.56% to 66.60%, while for breast and colon targets, stain normalization boosts accuracy from 49.22% to 81.29% and from 78.48% to 83.36%, respectively. Finally, using Integrated Gradients reveals that DANNs consistently attribute importance to biologically meaningful regions such as densely packed nuclei, indicating that the model learns clinically relevant features and can apply them to unlabeled cancer types.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14678v1</guid></item><item><title>[cs updates on arXiv.org] HCVR Scene Generation: High Compatibility Virtual Reality Environment Generation for Extended Redirected Walking</title><link>https://arxiv.org/abs/2601.14679</link><description>arXiv:2601.14679v1 Announce Type: new 
Abstract: Natural walking enhances immersion in virtual environments (VEs), but physical space limitations and obstacles hinder exploration, especially in large virtual scenes. Redirected Walking (RDW) techniques mitigate this by subtly manipulating the virtual camera to guide users away from physical collisions within pre-defined VEs. However, RDW efficacy diminishes significantly when substantial geometric divergence exists between the physical and virtual environments, leading to unavoidable collisions. Existing scene generation methods primarily focus on object relationships or layout aesthetics, often neglecting the crucial aspect of physical compatibility required for effective RDW. To address this, we introduce HCVR (High Compatibility Virtual Reality Environment Generation), a novel framework that generates virtual scenes inherently optimized for alignment-based RDW controllers. HCVR first employs ENI++, a novel, boundary-sensitive metric to evaluate the incompatibility between physical and virtual spaces by comparing rotation-sensitive visibility polygons. Guided by the ENI++ compatibility map and user prompts, HCVR utilizes a Large Language Model (LLM) for context-aware 3D asset retrieval and initial layout generation. The framework then strategically adjusts object selection, scaling, and placement to maximize coverage of virtually incompatible regions, effectively guiding users towards RDW-feasible paths. User studies evaluating physical collisions and layout quality demonstrate HCVR's effectiveness with HCVR-generated scenes, resulting in 22.78 times fewer physical collisions and received 35.89\% less on ENI++ score compared to LLM-based generation with RDW, while also receiving 12.5\% higher scores on user feedback to layout design.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14679v1</guid></item><item><title>[cs updates on arXiv.org] FARE: Fast-Slow Agentic Robotic Exploration</title><link>https://arxiv.org/abs/2601.14681</link><description>arXiv:2601.14681v1 Announce Type: new 
Abstract: This work advances autonomous robot exploration by integrating agent-level semantic reasoning with fast local control. We introduce FARE, a hierarchical autonomous exploration framework that integrates a large language model (LLM) for global reasoning with a reinforcement learning (RL) policy for local decision making. FARE follows a fast-slow thinking paradigm. The slow-thinking LLM module interprets a concise textual description of the unknown environment and synthesizes an agent-level exploration strategy, which is then grounded into a sequence of global waypoints through a topological graph. To further improve reasoning efficiency, this module employs a modularity-based pruning mechanism that reduces redundant graph structures. The fast-thinking RL module executes exploration by reacting to local observations while being guided by the LLM-generated global waypoints. The RL policy is additionally shaped by a reward term that encourages adherence to the global waypoints, enabling coherent and robust closed-loop behavior. This architecture decouples semantic reasoning from geometric decision, allowing each module to operate in its appropriate temporal and spatial scale. In challenging simulated environments, our results show that FARE achieves substantial improvements in exploration efficiency over state-of-the-art baselines. We further deploy FARE on hardware and validate it in complex, large scale $200m\times130m$ building environment.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14681v1</guid></item><item><title>[cs updates on arXiv.org] Local Language Models for Context-Aware Adaptive Anonymization of Sensitive Text</title><link>https://arxiv.org/abs/2601.14683</link><description>arXiv:2601.14683v1 Announce Type: new 
Abstract: Qualitative research often contains personal, contextual, and organizational details that pose privacy risks if not handled appropriately. Manual anonymization is time-consuming, inconsistent, and frequently omits critical identifiers. Existing automated tools tend to rely on pattern matching or fixed rules, which fail to capture context and may alter the meaning of the data. This study uses local LLMs to build a reliable, repeatable, and context-aware anonymization process for detecting and anonymizing sensitive data in qualitative transcripts. We introduce a Structured Framework for Adaptive Anonymizer (SFAA) that includes three steps: detection, classification, and adaptive anonymization. The SFAA incorporates four anonymization strategies: rule-based substitution, context-aware rewriting, generalization, and suppression. These strategies are applied based on the identifier type and the risk level. The identifiers handled by the SFAA are guided by major international privacy and research ethics standards, including the GDPR, HIPAA, and OECD guidelines. This study followed a dual-method evaluation that combined manual and LLM-assisted processing. Two case studies were used to support the evaluation. The first includes 82 face-to-face interviews on gamification in organizations. The second involves 93 machine-led interviews using an AI-powered interviewer to test LLM awareness and workplace privacy. Two local models, LLaMA and Phi were used to evaluate the performance of the proposed framework. The results indicate that the LLMs found more sensitive data than a human reviewer. Phi outperformed LLaMA in finding sensitive data, but made slightly more errors. Phi was able to find over 91% of the sensitive data and 94.8% kept the same sentiment as the original text, which means it was very accurate, hence, it does not affect the analysis of the qualitative data.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14683v1</guid></item><item><title>[cs updates on arXiv.org] Dissecting Performance Degradation in Audio Source Separation under Sampling Frequency Mismatch</title><link>https://arxiv.org/abs/2601.14684</link><description>arXiv:2601.14684v1 Announce Type: new 
Abstract: Audio processing methods based on deep neural networks are typically trained at a single sampling frequency (SF). To handle untrained SFs, signal resampling is commonly employed, but it can degrade performance, particularly when the input SF is lower than the trained SF. This paper investigates the causes of this degradation through two hypotheses: (i) the lack of high-frequency components introduced by up-sampling, and (ii) the greater importance of their presence than their precise representation. To examine these hypotheses, we compare conventional resampling with three alternatives: post-resampling noise addition, which adds Gaussian noise to the resampled signal; noisy-kernel resampling, which perturbs the kernel with Gaussian noise to enrich high-frequency components; and trainable-kernel resampling, which adapts the interpolation kernel through training. Experiments on music source separation show that noisy-kernel and trainable-kernel resampling alleviate the degradation observed with conventional resampling. We further demonstrate that noisy-kernel resampling is effective across diverse models, highlighting it as a simple yet practical option.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14684v1</guid></item><item><title>[cs updates on arXiv.org] IB-GRPO: Aligning LLM-based Learning Path Recommendation with Educational Objectives via Indicator-Based Group Relative Policy Optimization</title><link>https://arxiv.org/abs/2601.14686</link><description>arXiv:2601.14686v1 Announce Type: new 
Abstract: Learning Path Recommendation (LPR) aims to generate personalized sequences of learning items that maximize long-term learning effect while respecting pedagogical principles and operational constraints. Although large language models (LLMs) offer rich semantic understanding for free-form recommendation, applying them to long-horizon LPR is challenging due to (i) misalignment with pedagogical objectives such as the Zone of Proximal Development (ZPD) under sparse, delayed feedback, (ii) scarce and costly expert demonstrations, and (iii) multi-objective interactions among learning effect, difficulty scheduling, length controllability, and trajectory diversity. To address these issues, we propose IB-GRPO (Indicator-Based Group Relative Policy Optimization), an indicator-guided alignment approach for LLM-based LPR. To mitigate data scarcity, we construct hybrid expert demonstrations via Genetic Algorithm search and teacher RL agents and warm-start the LLM with supervised fine-tuning. Building on this warm-start, we design a within-session ZPD alignment score for difficulty scheduling. IB-GRPO then uses the $I_{\epsilon+}$ dominance indicator to compute group-relative advantages over multiple objectives, avoiding manual scalarization and improving Pareto trade-offs. Experiments on ASSIST09 and Junyi using the KES simulator with a Qwen2.5-7B backbone show consistent improvements over representative RL and LLM baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14686v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Denial-of-Service: The Puppeteer's Attack for Fine-Grained Control in Ranking-Based Federated Learning</title><link>https://arxiv.org/abs/2601.14687</link><description>arXiv:2601.14687v1 Announce Type: new 
Abstract: Federated Rank Learning (FRL) is a promising Federated Learning (FL) paradigm designed to be resilient against model poisoning attacks due to its discrete, ranking-based update mechanism. Unlike traditional FL methods that rely on model updates, FRL leverages discrete rankings as a communication parameter between clients and the server. This approach significantly reduces communication costs and limits an adversary's ability to scale or optimize malicious updates in the continuous space, thereby enhancing its robustness. This makes FRL particularly appealing for applications where system security and data privacy are crucial, such as web-based auction and bidding platforms. While FRL substantially reduces the attack surface, we demonstrate that it remains vulnerable to a new class of local model poisoning attack, i.e., fine-grained control attacks. We introduce the Edge Control Attack (ECA), the first fine-grained control attack tailored to ranking-based FL frameworks. Unlike conventional denial-of-service (DoS) attacks that cause conspicuous disruptions, ECA enables an adversary to precisely degrade a competitor's accuracy to any target level while maintaining a normal-looking convergence trajectory, thereby avoiding detection. ECA operates in two stages: (i) identifying and manipulating Ascending and Descending Edges to align the global model with the target model, and (ii) widening the selection boundary gap to stabilize the global model at the target accuracy. Extensive experiments across seven benchmark datasets and nine Byzantine-robust aggregation rules (AGRs) show that ECA achieves fine-grained accuracy control with an average error of only 0.224%, outperforming the baseline by up to 17x. Our findings highlight the need for stronger defenses against advanced poisoning attacks. Our code is available at: https://github.com/Chenzh0205/ECA</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14687v1</guid></item><item><title>[cs updates on arXiv.org] Ramping-aware Enhanced Flexibility Aggregation of Distributed Generation with Energy Storage in Power Distribution Networks</title><link>https://arxiv.org/abs/2601.14689</link><description>arXiv:2601.14689v1 Announce Type: new 
Abstract: Power distribution networks are increasingly hosting controllable and flexible distributed energy resources (DERs) that, when aggregated, can provide ancillary support to transmission systems. However, existing aggregation schemes often ignore the ramping constraints of these DERs, which can render them impractical in real deployments. This work proposes a ramping-aware flexibility aggregation scheme, computed at the transmission-distribution boundary, that explicitly accounts for DER ramp limits and yields flexibility envelopes that are provably disaggregable. To further enhance the attainable flexibility region, we introduce a novel pre-ramping strategy, which proactively adjusts resource operating points to enlarge the aggregated flexibility envelope while preserving both network feasibility and disaggregation guarantees. The proposed method demonstrates a 5.2% to 19.2% improvement in flexibility relative to the baseline model, depending on system conditions. We validate the scheme on an IEEE-33 bus distribution system and provide formal proofs showing that both aggregation strategies are disaggregable for all feasible trajectories within the aggregate flexibility envelope.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14689v1</guid></item><item><title>[cs updates on arXiv.org] FeedbackSTS-Det: Sparse Frames-Based Spatio-Temporal Semantic Feedback Network for Infrared Small Target Detection</title><link>https://arxiv.org/abs/2601.14690</link><description>arXiv:2601.14690v1 Announce Type: new 
Abstract: Infrared small target detection (ISTD) under complex backgrounds remains a critical yet challenging task, primarily due to the extremely low signal-to-clutter ratio, persistent dynamic interference, and the lack of distinct target features. While multi-frame detection methods leverages temporal cues to improve upon single-frame approaches, existing methods still struggle with inefficient long-range dependency modeling and insufficient robustness. To overcome these issues, we propose a novel scheme for ISTD, realized through a sparse frames-based spatio-temporal semantic feedback network named FeedbackSTS-Det. The core of our approach is a novel spatio-temporal semantic feedback strategy with a closed-loop semantic association mechanism, which consists of paired forward and backward refinement modules that work cooperatively across the encoder and decoder. Moreover, both modules incorporate an embedded sparse semantic module (SSM), which performs structured sparse temporal modeling to capture long-range dependencies with low computational cost. This integrated design facilitates robust implicit inter-frame registration and continuous semantic refinement, effectively suppressing false alarms. Furthermore, our overall procedure maintains a consistent training-inference pipeline, which ensures reliable performance transfer and increases model robustness. Extensive experiments on multiple benchmark datasets confirm the effectiveness of FeedbackSTS-Det. Code and models are available at: https://github.com/IDIP-Lab/FeedbackSTS-Det.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14690v1</guid></item><item><title>[cs updates on arXiv.org] Gaming the Judge: Unfaithful Chain-of-Thought Can Undermine Agent Evaluation</title><link>https://arxiv.org/abs/2601.14691</link><description>arXiv:2601.14691v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly used as judges to evaluate agent performance, particularly in non-verifiable settings where judgments rely on agent trajectories including chain-of-thought (CoT) reasoning. This paradigm implicitly assumes that the agent's CoT faithfully reflects both its internal reasoning and the underlying environment state. We show this assumption is brittle: LLM judges are highly susceptible to manipulation of agent reasoning traces. By systematically rewriting agent CoTs while holding actions and observations fixed, we demonstrate that manipulated reasoning alone can inflate false positive rates of state-of-the-art VLM judges by up to 90% across 800 trajectories spanning diverse web tasks. We study manipulation strategies spanning style-based approaches that alter only the presentation of reasoning and content-based approaches that fabricate signals of task progress, and find that content-based manipulations are consistently more effective. We evaluate prompting-based techniques and scaling judge-time compute, which reduce but do not fully eliminate susceptibility to manipulation. Our findings reveal a fundamental vulnerability in LLM-based evaluation and highlight the need for judging mechanisms that verify reasoning claims against observable evidence.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14691v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Error-Based Optimization: Experience-Driven Symbolic Regression with Goal-Conditioned Reinforcement Learning</title><link>https://arxiv.org/abs/2601.14693</link><description>arXiv:2601.14693v1 Announce Type: new 
Abstract: Symbolic Regression aims to automatically identify compact and interpretable mathematical expressions that model the functional relationship between input and output variables. Most existing search-based symbolic regression methods typically rely on the fitting error to inform the search process. However, in the vast expression space, numerous candidate expressions may exhibit similar error values while differing substantially in structure, leading to ambiguous search directions and hindering convergence to the underlying true function. To address this challenge, we propose a novel framework named EGRL-SR (Experience-driven Goal-conditioned Reinforcement Learning for Symbolic Regression). In contrast to traditional error-driven approaches, EGRL-SR introduces a new perspective: leveraging precise historical trajectories and optimizing the action-value network to proactively guide the search process, thereby achieving a more robust expression search. Specifically, we formulate symbolic regression as a goal-conditioned reinforcement learning problem and incorporate hindsight experience replay, allowing the action-value network to generalize common mapping patterns from diverse input-output pairs. Moreover, we design an all-point satisfaction binary reward function that encourages the action-value network to focus on structural patterns rather than low-error expressions, and concurrently propose a structure-guided heuristic exploration strategy to enhance search diversity and space coverage. Experiments on public benchmarks show that EGRL-SR consistently outperforms state-of-the-art methods in recovery rate and robustness, and can recover more complex expressions under the same search budget. Ablation results validate that the action-value network effectively guides the search, with both the reward function and the exploration strategy playing critical roles.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14693v1</guid></item><item><title>[cs updates on arXiv.org] Re-understanding Graph Unlearning through Memorization</title><link>https://arxiv.org/abs/2601.14694</link><description>arXiv:2601.14694v1 Announce Type: new 
Abstract: Graph unlearning (GU), which removes nodes, edges, or features from trained graph neural networks (GNNs), is crucial in Web applications where graph data may contain sensitive, mislabeled, or malicious information. However, existing GU methods lack a clear understanding of the key factors that determine unlearning effectiveness, leading to three fundamental limitations: (1) impractical and inaccurate GU difficulty assessment due to test-access requirements and invalid assumptions, (2) ineffectiveness on hard-to-unlearn tasks, and (3) misaligned evaluation protocols that overemphasize easy tasks and fail to capture true forgetting capability. To address these issues, we establish GNN memorization as a new perspective for understanding graph unlearning and propose MGU, a Memorization-guided Graph Unlearning framework. MGU achieves three key advances: it provides accurate and practical difficulty assessment across different GU tasks, develops an adaptive strategy that dynamically adjusts unlearning objectives based on difficulty levels, and establishes a comprehensive evaluation protocol that aligns with practical requirements. Extensive experiments on ten real-world graphs demonstrate that MGU consistently outperforms state-of-the-art baselines in forgetting quality, computational efficiency, and utility preservation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14694v1</guid></item><item><title>[cs updates on arXiv.org] CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation</title><link>https://arxiv.org/abs/2601.14695</link><description>arXiv:2601.14695v1 Announce Type: new 
Abstract: Training Large Reasoning Model (LRM) is usually unstable and unpredictable, especially on hard problems or weak foundation models. We found that the current post-training scaling strategy can still improve on these cases. We propose CoScale-RL, a novel scaling strategy with better data and computational efficiency. We first scale up solutions to make problems solvable. The core idea is to collect multiple solutions for each problem, rather than simply enlarging the dataset. Then, we scale up rollout computation to stabilize Reinforcement Learning. We further leverage a model merge technique called Re-distillation to sustain or even improve computational efficiency when scaling up. Our method significantly improves data and computational efficiency, with an average 3.76$\times$ accuracy improvement on four benchmarks. CoScale-RL is able to improve an LRM's ability boundary without an extensive SFT dataset. Our method provides a new scaling direction to further improve LRM's reasoning ability.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14695v1</guid></item><item><title>[cs updates on arXiv.org] AdaTIR: Adaptive Tool-Integrated Reasoning via Difficulty-Aware Policy Optimization</title><link>https://arxiv.org/abs/2601.14696</link><description>arXiv:2601.14696v1 Announce Type: new 
Abstract: Tool-Integrated Reasoning (TIR) has significantly enhanced the capabilities of Large Language Models (LLMs), yet current agents tend to exhibit cognitive offloading, redundantly invoking external tools even for simple tasks. In this paper, we suggest that true agentic intelligence requires not just tool invocation, but the adaptive wisdom to discern when to use them. We propose AdaTIR, a framework that shifts the paradigm from static tool invocation to difficulty-aware reasoning internalization. By introducing a difficulty-aware efficiency reward, AdaTIR dynamically adjusts tool budgets based on task complexity--internalizing reasoning for simple tasks while selectively invoking tools for complex tasks. Furthermore, we identify a sign reversal problem where tool penalties outweigh correctness rewards, mistakenly penalizing correct rollouts with negative advantages. To resolve this, we propose Clipped Advantage Shaping (CAS), which ensures that correctness remains the primary objective while using efficiency as a secondary constraint. Empirical results demonstrate that AdaTIR reduces tool calls by up to 97.6% on simple tasks and 28.2% on complex challenges while maintaining or enhancing accuracy. Notably, AdaTIR successfully internalizes reasoning, outperforming baselines by 4.8% on AIME 2024 even when tool access is strictly disabled.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14696v1</guid></item><item><title>[cs updates on arXiv.org] When Text-as-Vision Meets Semantic IDs in Generative Recommendation: An Empirical Study</title><link>https://arxiv.org/abs/2601.14697</link><description>arXiv:2601.14697v1 Announce Type: new 
Abstract: Semantic ID learning is a key interface in Generative Recommendation (GR) models, mapping items to discrete identifiers grounded in side information, most commonly via a pretrained text encoder. However, these text encoders are primarily optimized for well-formed natural language. In real-world recommendation data, item descriptions are often symbolic and attribute-centric, containing numerals, units, and abbreviations. These text encoders can break these signals into fragmented tokens, weakening semantic coherence and distorting relationships among attributes. Worse still, when moving to multimodal GR, relying on standard text encoders introduces an additional obstacle: text and image embeddings often exhibit mismatched geometric structures, making cross-modal fusion less effective and less stable.
  In this paper, we revisit representation design for Semantic ID learning by treating text as a visual signal. We conduct a systematic empirical study of OCR-based text representations, obtained by rendering item descriptions into images and encoding them with vision-based OCR models. Experiments across four datasets and two generative backbones show that OCR-text consistently matches or surpasses standard text embeddings for Semantic ID learning in both unimodal and multimodal settings. Furthermore, we find that OCR-based Semantic IDs remain robust under extreme spatial-resolution compression, indicating strong robustness and efficiency in practical deployments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14697v1</guid></item><item><title>[cs updates on arXiv.org] ClaimDB: A Fact Verification Benchmark over Large Structured Data</title><link>https://arxiv.org/abs/2601.14698</link><description>arXiv:2601.14698v1 Announce Type: new 
Abstract: Despite substantial progress in fact-verification benchmarks, claims grounded in large-scale structured data remain underexplored. In this work, we introduce ClaimDB, the first fact-verification benchmark where the evidence for claims is derived from compositions of millions of records and multiple tables. ClaimDB consists of 80 unique real-life databases covering a wide range of domains, from governance and healthcare to media, education and the natural sciences. At this scale, verification approaches that rely on "reading" the evidence break down, forcing a timely shift toward reasoning in executable programs. We conduct extensive experiments with 30 state-of-the-art proprietary and open-source (below 70B) LLMs and find that none exceed 83% accuracy, with more than half below 55%. Our analysis also reveals that both closed- and open-source models struggle with abstention -- the ability to admit that there is no evidence to decide -- raising doubts about their reliability in high-stakes data analysis. We release the benchmark, code, and the LLM leaderboard at https://claimdb.github.io .</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14698v1</guid></item><item><title>[cs updates on arXiv.org] DARL: Encouraging Diverse Answers for General Reasoning without Verifiers</title><link>https://arxiv.org/abs/2601.14700</link><description>arXiv:2601.14700v1 Announce Type: new 
Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated promising gains in enhancing the reasoning capabilities of large language models. However, its dependence on domain-specific verifiers significantly restricts its applicability to open and general domains. Recent efforts such as RLPR have extended RLVR to general domains, enabling training on broader datasets and achieving improvements over RLVR. However, a notable limitation of these methods is their tendency to overfit to reference answers, which constrains the model's ability to generate diverse outputs. This limitation is particularly pronounced in open-ended tasks such as writing, where multiple plausible answers exist. To address this, we propose DARL, a simple yet effective reinforcement learning framework that encourages the generation of diverse answers within a controlled deviation range from the reference while preserving alignment with it. Our framework is fully compatible with existing general reinforcement learning methods and can be seamlessly integrated without additional verifiers. Extensive experiments on thirteen benchmarks demonstrate consistent improvements in reasoning performance. Notably, DARL surpasses RLPR, achieving average gains of 1.3 points on six reasoning benchmarks and 9.5 points on seven general benchmarks, highlighting its effectiveness in improving both reasoning accuracy and output diversity.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14700v1</guid></item><item><title>[cs updates on arXiv.org] AutoDriDM: An Explainable Benchmark for Decision-Making of Vision-Language Models in Autonomous Driving</title><link>https://arxiv.org/abs/2601.14702</link><description>arXiv:2601.14702v1 Announce Type: new 
Abstract: Autonomous driving is a highly challenging domain that requires reliable perception and safe decision-making in complex scenarios. Recent vision-language models (VLMs) demonstrate reasoning and generalization abilities, opening new possibilities for autonomous driving; however, existing benchmarks and metrics overemphasize perceptual competence and fail to adequately assess decision-making processes. In this work, we present AutoDriDM, a decision-centric, progressive benchmark with 6,650 questions across three dimensions - Object, Scene, and Decision. We evaluate mainstream VLMs to delineate the perception-to-decision capability boundary in autonomous driving, and our correlation analysis reveals weak alignment between perception and decision-making performance. We further conduct explainability analyses of models' reasoning processes, identifying key failure modes such as logical reasoning errors, and introduce an analyzer model to automate large-scale annotation. AutoDriDM bridges the gap between perception-centered and decision-centered evaluation, providing guidance toward safer and more reliable VLMs for real-world autonomous driving.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14702v1</guid></item><item><title>[cs updates on arXiv.org] RegFreeNet: A Registration-Free Network for CBCT-based 3D Dental Implant Planning</title><link>https://arxiv.org/abs/2601.14703</link><description>arXiv:2601.14703v1 Announce Type: new 
Abstract: As the commercial surgical guide design software usually does not support the export of implant position for pre-implantation data, existing methods have to scan the post-implantation data and map the implant to pre-implantation space to get the label of implant position for training. Such a process is time-consuming and heavily relies on the accuracy of registration algorithm. Moreover, not all hospitals have paired CBCT data, limitting the construction of multi-center dataset. Inspired by the way dentists determine the implant position based on the neighboring tooth texture, we found that even if the implant area is masked, it will not affect the determination of the implant position. Therefore, we propose to mask the implants in the post-implantation data so that any CBCT containing the implants can be used as training data. This paradigm enables us to discard the registration process and makes it possible to construct a large-scale multi-center implant dataset. On this basis, we proposes ImplantFairy, a comprehensive, publicly accessible dental implant dataset with voxel-level 3D annotations of 1622 CBCT data. Furthermore, according to the area variation characteristics of the tooth's spatial structure and the slope information of the implant, we designed a slope-aware implant position prediction network. Specifically, a neighboring distance perception (NDP) module is designed to adaptively extract tooth area variation features, and an implant slope prediction branch assists the network in learning more robust features through additional implant supervision information. Extensive experiments conducted on ImplantFairy and two public dataset demonstrate that the proposed RegFreeNet achieves the state-of-the-art performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14703v1</guid></item><item><title>[cs updates on arXiv.org] Hierarchical Optimization Based Multi-objective Dynamic Regulation Scheme for VANET Topology</title><link>https://arxiv.org/abs/2601.14704</link><description>arXiv:2601.14704v1 Announce Type: new 
Abstract: As a core technology of intelligent transportation systems, vehicular ad-hoc networks support latency-sensitive services such as safety warning and cooperative perception via vehicle-to-everything communications. However, their highly dynamic topology increases average path length, raises latency, and reduces throughput, severely limiting communication performance. Existing topology optimization methods lack capabilities in multi-objective coordination, dynamic adaptation, and global-local synergy. To address this, this paper proposes a two-layer dynamic topology regulation scheme combining local feature aggregation and global adjustment. The scheme constructs a dynamic multi-objective optimization model integrating average path length, end-to-end latency, and network throughput, and achieves multi-index coordination via link adaptability metrics and a dynamic normalization mechanism. it quickly responds to local link changes via feature fusion of local node feature extraction and dynamic neighborhood sensing, and balances optimization accuracy and real-time performance using a dual-mode adaptive solving strategy for global topology adjustment. It reduces network oscillation risks by introducing a performance improvement threshold and a topology validity verification mechanism. Simulation results on real urban road networks via the SUMO platform show that the proposed scheme outperforms traditional methods in average path length (stabilizing at ~4 hops), end-to-end latency (remaining ~0.01 s), and network throughput.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14704v1</guid></item><item><title>[cs updates on arXiv.org] Proximal Policy Optimization with Evolutionary Mutations</title><link>https://arxiv.org/abs/2601.14705</link><description>arXiv:2601.14705v1 Announce Type: new 
Abstract: Proximal Policy Optimization (PPO) is a widely used reinforcement learning algorithm known for its stability and sample efficiency, but it often suffers from premature convergence due to limited exploration. In this paper, we propose POEM (Proximal Policy Optimization with Evolutionary Mutations), a novel modification to PPO that introduces an adaptive exploration mechanism inspired by evolutionary algorithms. POEM enhances policy diversity by monitoring the Kullback-Leibler (KL) divergence between the current policy and a moving average of previous policies. When policy changes become minimal, indicating stagnation, POEM triggers an adaptive mutation of policy parameters to promote exploration. We evaluate POEM on four OpenAI Gym environments: CarRacing, MountainCar, BipedalWalker, and LunarLander. Through extensive fine-tuning using Bayesian optimization techniques and statistical testing using Welch's t-test, we find that POEM significantly outperforms PPO on three of the four tasks (BipedalWalker: t=-2.0642, p=0.0495; CarRacing: t=-6.3987, p=0.0002; MountainCar: t=-6.2431, p&lt;0.0001), while performance on LunarLander is not statistically significant (t=-1.8707, p=0.0778). Our results highlight the potential of integrating evolutionary principles into policy gradient methods to overcome exploration-exploitation tradeoffs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14705v1</guid></item><item><title>[cs updates on arXiv.org] LookBench: A Live and Holistic Open Benchmark for Fashion Image Retrieval</title><link>https://arxiv.org/abs/2601.14706</link><description>arXiv:2601.14706v1 Announce Type: new 
Abstract: In this paper, we present LookBench (We use the term "look" to reflect retrieval that mirrors how people shop -- finding the exact item, a close substitute, or a visually consistent alternative.), a live, holistic and challenging benchmark for fashion image retrieval in real e-commerce settings. LookBench includes both recent product images sourced from live websites and AI-generated fashion images, reflecting contemporary trends and use cases. Each test sample is time-stamped and we intend to update the benchmark periodically, enabling contamination-aware evaluation aligned with declared training cutoffs. Grounded in our fine-grained attribute taxonomy, LookBench covers single-item and outfit-level retrieval across. Our experiments reveal that LookBench poses a significant challenge on strong baselines, with many models achieving below $60\%$ Recall@1. Our proprietary model achieves the best performance on LookBench, and we release an open-source counterpart that ranks second, with both models attaining state-of-the-art results on legacy Fashion200K evaluations. LookBench is designed to be updated semi-annually with new test samples and progressively harder task variants, providing a durable measure of progress. We publicly release our leaderboard, dataset, evaluation code, and trained models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14706v1</guid></item><item><title>[cs updates on arXiv.org] Case-Guided Sequential Assay Planning in Drug Discovery</title><link>https://arxiv.org/abs/2601.14710</link><description>arXiv:2601.14710v1 Announce Type: new 
Abstract: Optimally sequencing experimental assays in drug discovery is a high-stakes planning problem under severe uncertainty and resource constraints. A primary obstacle for standard reinforcement learning (RL) is the absence of an explicit environment simulator or transition data $(s, a, s')$; planning must rely solely on a static database of historical outcomes. We introduce the Implicit Bayesian Markov Decision Process (IBMDP), a model-based RL framework designed for such simulator-free settings. IBMDP constructs a case-guided implicit model of transition dynamics by forming a nonparametric belief distribution using similar historical outcomes. This mechanism enables Bayesian belief updating as evidence accumulates and employs ensemble MCTS planning to generate stable policies that balance information gain toward desired outcomes with resource efficiency. We validate IBMDP through comprehensive experiments. On a real-world central nervous system (CNS) drug discovery task, IBMDP reduced resource consumption by up to 92\% compared to established heuristics while maintaining decision confidence. To rigorously assess decision quality, we also benchmarked IBMDP in a synthetic environment with a computable optimal policy. Our framework achieves significantly higher alignment with this optimal policy than a deterministic value iteration alternative that uses the same similarity-based model, demonstrating the superiority of our ensemble planner. IBMDP offers a practical solution for sequential experimental design in data-rich but simulator-poor domains.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14710v1</guid></item><item><title>[cs updates on arXiv.org] DARA: Few-shot Budget Allocation in Online Advertising via In-Context Decision Making with RL-Finetuned LLMs</title><link>https://arxiv.org/abs/2601.14711</link><description>arXiv:2601.14711v1 Announce Type: new 
Abstract: Optimizing the advertiser's cumulative value of winning impressions under budget constraints poses a complex challenge in online advertising, under the paradigm of AI-Generated Bidding (AIGB). Advertisers often have personalized objectives but limited historical interaction data, resulting in few-shot scenarios where traditional reinforcement learning (RL) methods struggle to perform effectively. Large Language Models (LLMs) offer a promising alternative for AIGB by leveraging their in-context learning capabilities to generalize from limited data. However, they lack the numerical precision required for fine-grained optimization. To address this limitation, we introduce GRPO-Adaptive, an efficient LLM post-training strategy that enhances both reasoning and numerical precision by dynamically updating the reference policy during training. Built upon this foundation, we further propose DARA, a novel dual-phase framework that decomposes the decision-making process into two stages: a few-shot reasoner that generates initial plans via in-context prompting, and a fine-grained optimizer that refines these plans using feedback-driven reasoning. This separation allows DARA to combine LLMs' in-context learning strengths with precise adaptability required by AIGB tasks. Extensive experiments on both real-world and synthetic data environments demonstrate that our approach consistently outperforms existing baselines in terms of cumulative advertiser value under budget constraints.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14711v1</guid></item><item><title>[cs updates on arXiv.org] Unified Multimodal and Multilingual Retrieval via Multi-Task Learning with NLU Integration</title><link>https://arxiv.org/abs/2601.14714</link><description>arXiv:2601.14714v1 Announce Type: new 
Abstract: Multimodal retrieval systems typically employ Vision Language Models (VLMs) that encode images and text independently into vectors within a shared embedding space. Despite incorporating text encoders, VLMs consistently underperform specialized text models on text-only retrieval tasks. Moreover, introducing additional text encoders increases storage, inference overhead, and exacerbates retrieval inefficiencies, especially in multilingual settings. To address these limitations, we propose a multi-task learning framework that unifies the feature representation across images, long and short texts, and intent-rich queries. To our knowledge, this is the first work to jointly optimize multilingual image retrieval, text retrieval, and natural language understanding (NLU) tasks within a single framework. Our approach integrates image and text retrieval with a shared text encoder that is enhanced by NLU features for intent understanding and retrieval accuracy.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14714v1</guid></item><item><title>[cs updates on arXiv.org] PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning</title><link>https://arxiv.org/abs/2601.14716</link><description>arXiv:2601.14716v1 Announce Type: new 
Abstract: We present PCL-Reasoner-V1.5, a 32-billion-parameter large language model (LLM) for mathematical reasoning. The model is built upon Qwen2.5-32B and refined via supervised fine-tuning (SFT) followed by reinforcement learning (RL). A central innovation is our proposed offline RL method, which provides superior training stability and efficiency over standard online RL methods such as GRPO. Our model achieves state-of-the-art performance among models post-trained on Qwen2.5-32B, attaining average accuracies of 90.9% on AIME 2024 and 85.6% on AIME 2025. Our work demonstrates offline RL as a stable and efficient paradigm for advancing reasoning in LLMs. All experiments were conducted on Huawei Ascend 910C NPUs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14716v1</guid></item><item><title>[cs updates on arXiv.org] Context Patch Fusion With Class Token Enhancement for Weakly Supervised Semantic Segmentation</title><link>https://arxiv.org/abs/2601.14718</link><description>arXiv:2601.14718v1 Announce Type: new 
Abstract: Weakly Supervised Semantic Segmentation (WSSS), which relies only on image-level labels, has attracted significant attention for its cost-effectiveness and scalability. Existing methods mainly enhance inter-class distinctions and employ data augmentation to mitigate semantic ambiguity and reduce spurious activations. However, they often neglect the complex contextual dependencies among image patches, resulting in incomplete local representations and limited segmentation accuracy. To address these issues, we propose the Context Patch Fusion with Class Token Enhancement (CPF-CTE) framework, which exploits contextual relations among patches to enrich feature representations and improve segmentation. At its core, the Contextual-Fusion Bidirectional Long Short-Term Memory (CF-BiLSTM) module captures spatial dependencies between patches and enables bidirectional information flow, yielding a more comprehensive understanding of spatial correlations. This strengthens feature learning and segmentation robustness. Moreover, we introduce learnable class tokens that dynamically encode and refine class-specific semantics, enhancing discriminative capability. By effectively integrating spatial and semantic cues, CPF-CTE produces richer and more accurate representations of image content. Extensive experiments on PASCAL VOC 2012 and MS COCO 2014 validate that CPF-CTE consistently surpasses prior WSSS methods.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14718v1</guid></item><item><title>[cs updates on arXiv.org] PULSE: Socially-Aware User Representation Modeling Toward Parameter-Efficient Graph Collaborative Filtering</title><link>https://arxiv.org/abs/2601.14720</link><description>arXiv:2601.14720v1 Announce Type: new 
Abstract: Graph-based social recommendation (SocialRec) has emerged as a powerful extension of graph collaborative filtering (GCF), which leverages graph neural networks (GNNs) to capture multi-hop collaborative signals from user-item interactions. These methods enrich user representations by incorporating social network information into GCF, thereby integrating additional collaborative signals from social relations. However, existing GCF and graph-based SocialRec approaches face significant challenges: they incur high computational costs and suffer from limited scalability due to the large number of parameters required to assign explicit embeddings to all users and items. In this work, we propose PULSE (Parameter-efficient User representation Learning with Social Knowledge), a framework that addresses this limitation by constructing user representations from socially meaningful signals without creating an explicit learnable embedding for each user. PULSE reduces the parameter size by up to 50% compared to the most lightweight GCF baseline. Beyond parameter efficiency, our method achieves state-of-the-art performance, outperforming 13 GCF and graph-based social recommendation baselines across varying levels of interaction sparsity, from cold-start to highly active users, through a time- and memory-efficient modeling process.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14720v1</guid></item><item><title>[cs updates on arXiv.org] Typhoon OCR: Open Vision-Language Model For Thai Document Extraction</title><link>https://arxiv.org/abs/2601.14722</link><description>arXiv:2601.14722v1 Announce Type: new 
Abstract: Document extraction is a core component of digital workflows, yet existing vision-language models (VLMs) predominantly favor high-resource languages. Thai presents additional challenges due to script complexity from non-latin letters, the absence of explicit word boundaries, and the prevalence of highly unstructured real-world documents, limiting the effectiveness of current open-source models. This paper presents Typhoon OCR, an open VLM for document extraction tailored for Thai and English. The model is fine-tuned from vision-language backbones using a Thai-focused training dataset. The dataset is developed using a multi-stage data construction pipeline that combines traditional OCR, VLM-based restructuring, and curated synthetic data. Typhoon OCR is a unified framework capable of text transcription, layout reconstruction, and document-level structural consistency. The latest iteration of our model, Typhoon OCR V1.5, is a compact and inference-efficient model designed to reduce reliance on metadata and simplify deployment. Comprehensive evaluations across diverse Thai document categories, including financial reports, government forms, books, infographics, and handwritten documents, show that Typhoon OCR achieves performance comparable to or exceeding larger frontier proprietary models, despite substantially lower computational cost. The results demonstrate that open vision-language OCR models can achieve accurate text extraction and layout reconstruction for Thai documents, reaching performance comparable to proprietary systems while remaining lightweight and deployable.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14722v1</guid></item><item><title>[cs updates on arXiv.org] HERMES: KV Cache as Hierarchical Memory for Efficient Streaming Video Understanding</title><link>https://arxiv.org/abs/2601.14724</link><description>arXiv:2601.14724v1 Announce Type: new 
Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated significant improvement in offline video understanding. However, extending these capabilities to streaming video inputs, remains challenging, as existing models struggle to simultaneously maintain stable understanding performance, real-time responses, and low GPU memory overhead. To address this challenge, we propose HERMES, a novel training-free architecture for real-time and accurate understanding of video streams. Based on a mechanistic attention investigation, we conceptualize KV cache as a hierarchical memory framework that encapsulates video information across multiple granularities. During inference, HERMES reuses a compact KV cache, enabling efficient streaming understanding under resource constraints. Notably, HERMES requires no auxiliary computations upon the arrival of user queries, thereby guaranteeing real-time responses for continuous video stream interactions, which achieves 10$\times$ faster TTFT compared to prior SOTA. Even when reducing video tokens by up to 68% compared with uniform sampling, HERMES achieves superior or comparable accuracy across all benchmarks, with up to 11.4% gains on streaming datasets.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14724v1</guid></item><item><title>[cs updates on arXiv.org] Differential Privacy on Affine Manifolds: Geometrically Confined Privacy in Linear Dynamical Systems</title><link>https://arxiv.org/abs/2601.14725</link><description>arXiv:2601.14725v1 Announce Type: new 
Abstract: In this paper, we present a comprehensive framework for differential privacy over affine manifolds and validate its usefulness in the contexts of differentially private cloud-based control and average consensus. We consider differential privacy mechanisms for linear queries when the input data are constrained to lie on affine manifolds, a structural property that is assumed to be available as prior knowledge to adversaries. In this setting, the definition of neighborhood adjacency must be formulated with respect to the intrinsic geometry of the manifolds. We demonstrate that such affine-manifold constraints can fundamentally alter the attainable privacy levels relative to the unconstrained case. In particular, we derive necessary and sufficient conditions under which differential privacy can be realized via structured noise injection mechanisms, wherein correlated Gaussian or Laplace noise distributions, rather than i.i.d. perturbations, are calibrated to the dataset. Based on these characterizations, we develop explicit noise calibration procedures that guarantee the tight realization of any prescribed privacy budget with a matching noise magnitude. Finally, we show that the proposed framework admits direct applications to linear dynamical systems ranging from differentially private cloud-based control to privacy-preserving average consensus, all of which naturally involve affine-manifold constraints. The established theoretical results are illustrated through numerical examples.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14725v1</guid></item><item><title>[cs updates on arXiv.org] FSX: Message Flow Sensitivity Enhanced Structural Explainer for Graph Neural Networks</title><link>https://arxiv.org/abs/2601.14730</link><description>arXiv:2601.14730v1 Announce Type: new 
Abstract: Despite the widespread success of Graph Neural Networks (GNNs), understanding the reasons behind their specific predictions remains challenging. Existing explainability methods face a trade-off that gradient-based approaches are computationally efficient but often ignore structural interactions, while game-theoretic techniques capture interactions at the cost of high computational overhead and potential deviation from the model's true reasoning path. To address this gap, we propose FSX (Message Flow Sensitivity Enhanced Structural Explainer), a novel hybrid framework that synergistically combines the internal message flows of the model with a cooperative game approach applied to the external graph data. FSX first identifies critical message flows via a novel flow-sensitivity analysis: during a single forward pass, it simulates localized node perturbations and measures the resulting changes in message flow intensities. These sensitivity-ranked flows are then projected onto the input graph to define compact, semantically meaningful subgraphs. Within each subgraph, a flow-aware cooperative game is conducted, where node contributions are evaluated fairly through a Shapley-like value that incorporates both node-feature importance and their roles in sustaining or destabilizing the identified critical flows. Extensive evaluation across multiple datasets and GNN architectures demonstrates that FSX achieves superior explanation fidelity with significantly reduced runtime, while providing unprecedented insights into the structural logic underlying model predictions--specifically, how important sub-structures exert influence by governing the stability of key internal computational pathways.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14730v1</guid></item><item><title>[cs updates on arXiv.org] ARFT-Transformer: Modeling Metric Dependencies for Cross-Project Aging-Related Bug Prediction</title><link>https://arxiv.org/abs/2601.14731</link><description>arXiv:2601.14731v1 Announce Type: new 
Abstract: Software systems that run for long periods often suffer from software aging, which is typically caused by Aging-Related Bugs (ARBs). To mitigate the risk of ARBs early in the development phase, ARB prediction has been introduced into software aging research. However, due to the difficulty of collecting ARBs, within-project ARB prediction faces the challenge of data scarcity, leading to the proposal of cross-project ARB prediction. This task faces two major challenges: 1) domain adaptation issue caused by distribution difference between source and target projects; and 2) severe class imbalance between ARB-prone and ARB-free samples. Although various methods have been proposed for cross-project ARB prediction, existing approaches treat the input metrics independently and often neglect the rich inter-metric dependencies, which can lead to overlapping information and misjudgment of metric importance, potentially affecting the model's performance. Moreover, they typically use cross-entropy as the loss function during training, which cannot distinguish the difficulty of sample classification. To overcome these limitations, we propose ARFT-Transformer, a transformer-based cross-project ARB prediction framework that introduces a metric-level multi-head attention mechanism to capture metric interactions and incorporates Focal Loss function to effectively handle class imbalance. Experiments conducted on three large-scale open-source projects demonstrate that ARFT-Transformer on average outperforms state-of-the-art cross-project ARB prediction methods in both single-source and multi-source cases, achieving up to a 29.54% and 19.92% improvement in Balance metric.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14731v1</guid></item><item><title>[cs updates on arXiv.org] DeepMoLM: Leveraging Visual and Geometric Structural Information for Molecule-Text Modeling</title><link>https://arxiv.org/abs/2601.14732</link><description>arXiv:2601.14732v1 Announce Type: new 
Abstract: AI models for drug discovery and chemical literature mining must interpret molecular images and generate outputs consistent with 3D geometry and stereochemistry. Most molecular language models rely on strings or graphs, while vision-language models often miss stereochemical details and struggle to map continuous 3D structures into discrete tokens. We propose DeepMoLM: Deep Molecular Language M odeling, a dual-view framework that grounds high-resolution molecular images in geometric invariants derived from molecular conformations. DeepMoLM preserves high-frequency evidence from 1024 $\times$ 1024 inputs, encodes conformer neighborhoods as discrete Extended 3-Dimensional Fingerprints, and fuses visual and geometric streams with cross-attention, enabling physically grounded generation without atom coordinates. DeepMoLM improves PubChem captioning with a 12.3% relative METEOR gain over the strongest generalist baseline while staying competitive with specialist methods. It produces valid numeric outputs for all property queries and attains MAE 13.64 g/mol on Molecular Weight and 37.89 on Complexity in the specialist setting. On ChEBI-20 description generation from images, it exceeds generalist baselines and matches state-of-the-art vision-language models. Code is available at https://github.com/1anj/DeepMoLM.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14732v1</guid></item><item><title>[cs updates on arXiv.org] Optimizing FaaS Platforms for MCP-enabled Agentic Workflows</title><link>https://arxiv.org/abs/2601.14735</link><description>arXiv:2601.14735v1 Announce Type: new 
Abstract: Agentic workflows that use autonomous AI Agents powered by Large Language Models (LLMs) and Model Context Protocol (MCP) servers is rapidly rising. This introduces challenges in scalable cloud deployment and state management. Traditional hosting on Virtual Machines (VMs) is resource-intensive and lacks elasticity. Functions-as-a-Service (FaaS) platforms offer modularity, autoscaling and cost efficiency but are inherently stateless. In this paper, we present the FAME, a FaaS-based architecture for orchestrating MCP-enabled agentic workflows. FAME decomposes agentic patterns such as ReAct into composable agents: Planner, Actor and Evaluator, that are each a FaaS function built using LangGraph and are orchestrated as a FaaS workflow. This enables modular composition as AWS Step Functions and avoids function timeouts seen for monolithic agentic workflows. To address context persistence across user requests in a conversation, FAME automates agent memory persistence and injection using DynamoDB. It also optimizes MCP server deployment through AWS Lambda wrappers, caches tool outputs in S3 and proposes function fusion strategies. We evaluate FAME on two representative applications, on research paper summarization and log analytics, under diverse memory and caching configurations. Results show up to 13x latency reduction, 88% fewer input tokens and 66% in cost savings, along with improved workflow completion rates. This demonstrates the viability of serverless platforms for hosting complex, multi-agent AI workflows at scale.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14735v1</guid></item><item><title>[cs updates on arXiv.org] Trajectory-Driven Multi-Product Influence Maximization in Billboard Advertising</title><link>https://arxiv.org/abs/2601.14737</link><description>arXiv:2601.14737v1 Announce Type: new 
Abstract: Billboard Advertising has emerged as an effective out-of-home advertising technique, where the goal is to select a limited number of slots and play advertisement content there, with the hope that it will be observed by many people and, effectively, a significant number of them will be influenced towards the brand. Given a trajectory and a billboard database and a positive integer $k$, how can we select $k$ highly influential slots to maximize influence? In this paper, we study a variant of this problem where a commercial house wants to make a promotion of multiple products, and there is an influence demand for each product. We have studied two variants of the problem. In the first variant, our goal is to select $k$ slots such that the respective influence demand of each product is satisfied. In the other variant of the problem, we are given with $\ell$ integers $k_1,k_2, \ldots, k_{\ell}$, the goal here is to search for $\ell$ many set of slots $S_1, S_2, \ldots, S_{\ell}$ such that for all $i \in [\ell]$, $|S_{i}| \leq k_i$ and for all $i \neq j$, $S_i \cap S_j=\emptyset$ and the influence demand of each of the products gets satisfied. We model the first variant of the problem as a multi-submodular cover problem and the second variant as its generalization. To solve the common-slot variant, we formulate the problem as a multi-submodular cover problem and design a bi-criteria approximation algorithm based on the continuous greedy framework and randomized rounding. For the disjoint-slot variant, we proposed a sampling-based approximation approach along with an efficient primal-dual greedy algorithm that enforces disjointness naturally. Extensive experiments with real-world trajectory and billboard datasets highlight the effectiveness and efficiency of the proposed solution approaches.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14737v1</guid></item><item><title>[cs updates on arXiv.org] Safeguarding Facial Identity against Diffusion-based Face Swapping via Cascading Pathway Disruption</title><link>https://arxiv.org/abs/2601.14738</link><description>arXiv:2601.14738v1 Announce Type: new 
Abstract: The rapid evolution of diffusion models has democratized face swapping but also raises concerns about privacy and identity security. Existing proactive defenses, often adapted from image editing attacks, prove ineffective in this context. We attribute this failure to an oversight of the structural resilience and the unique static conditional guidance mechanism inherent in face swapping systems. To address this, we propose VoidFace, a systemic defense method that views face swapping as a coupled identity pathway. By injecting perturbations at critical bottlenecks, VoidFace induces cascading disruption throughout the pipeline. Specifically, we first introduce localization disruption and identity erasure to degrade physical regression and semantic embeddings, thereby impairing the accurate modeling of the source face. We then intervene in the generative domain by decoupling attention mechanisms to sever identity injection, and corrupting intermediate diffusion features to prevent the reconstruction of source identity. To ensure visual imperceptibility, we perform adversarial search in the latent manifold, guided by a perceptual adaptive strategy to balance attack potency with image quality. Extensive experiments show that VoidFace outperforms existing defenses across various diffusion-based swapping models, while producing adversarial faces with superior visual quality.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14738v1</guid></item><item><title>[cs updates on arXiv.org] Enhancing Text-to-Image Generation via End-Edge Collaborative Hybrid Super-Resolution</title><link>https://arxiv.org/abs/2601.14741</link><description>arXiv:2601.14741v1 Announce Type: new 
Abstract: Artificial Intelligence-Generated Content (AIGC) has made significant strides, with high-resolution text-to-image (T2I) generation becoming increasingly critical for improving users' Quality of Experience (QoE). Although resource-constrained edge computing adequately supports fast low-resolution T2I generations, achieving high-resolution output still faces the challenge of ensuring image fidelity at the cost of latency. To address this, we first investigate the performance of super-resolution (SR) methods for image enhancement, confirming a fundamental trade-off that lightweight learning-based SR struggles to recover fine details, while diffusion-based SR achieves higher fidelity at a substantial computational cost. Motivated by these observations, we propose an end-edge collaborative generation-enhancement framework. Upon receiving a T2I generation task, the system first generates a low-resolution image based on adaptively selected denoising steps and super-resolution scales at the edge side, which is then partitioned into patches and processed by a region-aware hybrid SR policy. This policy applies a diffusion-based SR model to foreground patches for detail recovery and a lightweight learning-based SR model to background patches for efficient upscaling, ultimately stitching the enhanced ones into the high-resolution image. Experiments show that our system reduces service latency by 33% compared with baselines while maintaining competitive image quality.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14741v1</guid></item><item><title>[cs updates on arXiv.org] SimD3: A Synthetic drone Dataset with Payload and Bird Distractor Modeling for Robust Detection</title><link>https://arxiv.org/abs/2601.14742</link><description>arXiv:2601.14742v1 Announce Type: new 
Abstract: Reliable drone detection is challenging due to limited annotated real-world data, large appearance variability, and the presence of visually similar distractors such as birds. To address these challenges, this paper introduces SimD3, a large-scale high-fidelity synthetic dataset designed for robust drone detection in complex aerial environments. Unlike existing synthetic drone datasets, SimD3 explicitly models drones with heterogeneous payloads, incorporates multiple bird species as realistic distractors, and leverages diverse Unreal Engine 5 environments with controlled weather, lighting, and flight trajectories captured using a 360 six-camera rig. Using SimD3, we conduct an extensive experimental evaluation within the YOLOv5 detection framework, including an attention-enhanced variant termed Yolov5m+C3b, where standard bottleneck-based C3 blocks are replaced with C3b modules. Models are evaluated on synthetic data, combined synthetic and real data, and multiple unseen real-world benchmarks to assess robustness and generalization. Experimental results show that SimD3 provides effective supervision for small-object drone detection and that Yolov5m+C3b consistently outperforms the baseline across in-domain and cross-dataset evaluations. These findings highlight the utility of SimD3 for training and benchmarking robust drone detection models under diverse and challenging conditions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14742v1</guid></item><item><title>[cs updates on arXiv.org] ARISE -- Adaptive Refinement and Iterative Scenario Engineering</title><link>https://arxiv.org/abs/2601.14743</link><description>arXiv:2601.14743v1 Announce Type: new 
Abstract: The effectiveness of collision-free trajectory planners depends on the quality and diversity of training data, especially for rare scenarios. A widely used approach to improve dataset diversity involves generating realistic synthetic traffic scenarios. However, producing such scenarios remains difficult due to the precision required when scripting them manually or generating them in a single pass. Natural language offers a flexible way to describe scenarios, but existing text-to-simulation pipelines often rely on static snippet retrieval, limited grammar, single-pass decoding, or lack robust executability checks. Moreover, they depend heavily on constrained LLM prompting with minimal post-processing. To address these limitations, we introduce ARISE - Adaptive Refinement and Iterative Scenario Engineering, a multi-stage tool that converts natural language prompts into executable Scenic scripts through iterative LLM-guided refinement. After each generation, ARISE tests script executability in simulation software, feeding structured diagnostics back to the LLM until both syntactic and functional requirements are met. This process significantly reduces the need for manual intervention. Through extensive evaluation, ARISE outperforms the baseline in generating semantically accurate and executable traffic scenarios with greater reliability and robustness.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14743v1</guid></item><item><title>[cs updates on arXiv.org] Unlocking Large Audio-Language Models for Interactive Language Learning</title><link>https://arxiv.org/abs/2601.14744</link><description>arXiv:2601.14744v1 Announce Type: new 
Abstract: Achieving pronunciation proficiency in a second language (L2) remains a challenge, despite the development of Computer-Assisted Pronunciation Training (CAPT) systems. Traditional CAPT systems often provide unintuitive feedback that lacks actionable guidance, limiting its effectiveness. Recent advancements in audio-language models (ALMs) offer the potential to enhance these systems by providing more user-friendly feedback. In this work, we investigate ALMs for chat-based pronunciation training by introducing L2-Arctic-plus, an English dataset with detailed error explanations and actionable suggestions for improvement. We benchmark cascaded ASR+LLMs and existing ALMs on this dataset, specifically in detecting mispronunciation and generating actionable feedback. To improve the performance, we further propose to instruction-tune ALMs on L2-Arctic-plus. Experimental results demonstrate that our instruction-tuned models significantly outperform existing baselines on mispronunciation detection and suggestion generation in terms of both objective and human evaluation, highlighting the value of the proposed dataset.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14744v1</guid></item><item><title>[cs updates on arXiv.org] RefProtoFL: Communication-Efficient Federated Learning via External-Referenced Prototype Alignment</title><link>https://arxiv.org/abs/2601.14746</link><description>arXiv:2601.14746v1 Announce Type: new 
Abstract: Federated learning (FL) enables collaborative model training without sharing raw data in edge environments, but is constrained by limited communication bandwidth and heterogeneous client data distributions. Prototype-based FL mitigates this issue by exchanging class-wise feature prototypes instead of full model parameters; however, existing methods still suffer from suboptimal generalization under severe communication constraints. In this paper, we propose RefProtoFL, a communication-efficient FL framework that integrates External-Referenced Prototype Alignment (ERPA) for representation consistency with Adaptive Probabilistic Update Dropping (APUD) for communication efficiency. Specifically, we decompose the model into a private backbone and a lightweight shared adapter, and restrict federated communication to the adapter parameters only. To further reduce uplink cost, APUD performs magnitude-aware Top-K sparsification, transmitting only the most significant adapter updates for server-side aggregation. To address representation inconsistency across heterogeneous clients, ERPA leverages a small server-held public dataset to construct external reference prototypes that serve as shared semantic anchors. For classes covered by public data, clients directly align local representations to public-induced prototypes, whereas for uncovered classes, alignment relies on server-aggregated global reference prototypes via weighted averaging. Extensive experiments on standard benchmarks demonstrate that RefProtoFL attains higher classification accuracy than state-of-the-art prototype-based FL baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14746v1</guid></item><item><title>[cs updates on arXiv.org] Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning</title><link>https://arxiv.org/abs/2601.14750</link><description>arXiv:2601.14750v1 Announce Type: new 
Abstract: Chain-of-Thought (CoT) prompting has achieved remarkable success in unlocking the reasoning capabilities of Large Language Models (LLMs). Although CoT prompting enhances reasoning, its verbosity imposes substantial computational overhead. Recent works often focus exclusively on outcome alignment and lack supervision on the intermediate reasoning process. These deficiencies obscure the analyzability of the latent reasoning chain. To address these challenges, we introduce Render-of-Thought (RoT), the first framework to reify the reasoning chain by rendering textual steps into images, making the latent rationale explicit and traceable. Specifically, we leverage the vision encoders of existing Vision Language Models (VLMs) as semantic anchors to align the vision embeddings with the textual space. This design ensures plug-and-play implementation without incurring additional pre-training overhead. Extensive experiments on mathematical and logical reasoning benchmarks demonstrate that our method achieves 3-4x token compression and substantial inference acceleration compared to explicit CoT. Furthermore, it maintains competitive performance against other methods, validating the feasibility of this paradigm. Our code is available at https://github.com/TencentBAC/RoT</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14750v1</guid></item><item><title>[cs updates on arXiv.org] Secure Communication in MIMOME Movable-Antenna Systems with Statistical Eavesdropper CSI</title><link>https://arxiv.org/abs/2601.14755</link><description>arXiv:2601.14755v1 Announce Type: new 
Abstract: This paper investigates the potential of movable antennas (MAs) to enhance physical layer security within a multiple-input multiple-output multiple-antenna eavesdropper (MIMOME) system. We consider a practical scenario where the transmitter operates with imperfect eavesdropper channel state information (ECSI), knowing only the instantaneous line-of-sight (LoS) component and the statistical properties of non-line-of-sight (NLoS) component. To rigorously quantify secrecy performance under the ECSI uncertainty, we adopt the ergodic secrecy rate (ESR) as the metric. Since deriving an exact analytical expression for the ESR is intractable, we leverage random matrix theory to derive a deterministic equivalent. This avoids heavy Monte Carlo simulations and also provides explicit insights into the effects of channel spatial statistics on secrecy performance. Building upon the deterministic equivalent, we formulate a joint maximization problem for the transmit precoding matrix and the antenna positions at the legitimate transmitter. To tackle the non-convexity of this optimization problem, we develop a comprehensive alternating optimization framework. Specifically, the precoding matrix is optimized via a majorization-minimization (MM) algorithm, where the gradient is computed by solving an implicit fixed-point equation. For the antenna position optimization, the complexity of the objective function prevents the construction of standard MM surrogate. To this end, we further propose a novel AMSGrad-based surrogate function that relies solely on gradient information. We provide a rigorous theoretical proof that guarantees the convergence of this proposed algorithm despite relaxing the strict majorization conditions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14755v1</guid></item><item><title>[cs updates on arXiv.org] ReinPath: A Multimodal Reinforcement Learning Approach for Pathology</title><link>https://arxiv.org/abs/2601.14757</link><description>arXiv:2601.14757v1 Announce Type: new 
Abstract: Interpretability is significant in computational pathology, leading to the development of multimodal information integration from histopathological image and corresponding text data.However, existing multimodal methods have limited interpretability due to the lack of high-quality dataset that support explicit reasoning and inference and simple reasoning process.To address the above problems, we introduce a novel multimodal pathology large language model with strong reasoning capabilities.To improve the generation of accurate and contextually relevant textual descriptions, we design a semantic reward strategy integrated with group relative policy optimization.We construct a high-quality pathology visual question answering (VQA) dataset, specifically designed to support complex reasoning tasks.Comprehensive experiments conducted on this dataset demonstrate that our method outperforms state-of-the-art methods, even when trained with only 20% of the data.Our method also achieves comparable performance on downstream zero-shot image classification task compared with CLIP.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14757v1</guid></item><item><title>[cs updates on arXiv.org] Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models</title><link>https://arxiv.org/abs/2601.14758</link><description>arXiv:2601.14758v1 Announce Type: new 
Abstract: Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repackage autoregressive heuristics. In this work, we address this question by conducting a comparative circuit analysis of ARMs and their MDM counterparts. Our analysis reveals a systematic "mechanism shift" dependent on the structural nature of the task. Structurally, we observe a distinct divergence: while MDMs largely retain autoregressive circuitry for tasks dominated by local causal dependencies, they abandon initialized pathways for global planning tasks, exhibiting distinct rewiring characterized by increased early-layer processing. Semantically, we identify a transition from sharp, localized specialization in ARMs to distributed integration in MDMs. Through these findings, we conclude that diffusion post-training does not merely adapt model parameters but fundamentally reorganizes internal computation to support non-sequential global planning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14758v1</guid></item><item><title>[cs updates on arXiv.org] An XAI View on Explainable ASP: Methods, Systems, and Perspectives</title><link>https://arxiv.org/abs/2601.14764</link><description>arXiv:2601.14764v1 Announce Type: new 
Abstract: Answer Set Programming (ASP) is a popular declarative reasoning and problem solving approach in symbolic AI. Its rule-based formalism makes it inherently attractive for explainable and interpretive reasoning, which is gaining importance with the surge of Explainable AI (XAI). A number of explanation approaches and tools for ASP have been developed, which often tackle specific explanatory settings and may not cover all scenarios that ASP users encounter. In this survey, we provide, guided by an XAI perspective, an overview of types of ASP explanations in connection with user questions for explanation, and describe how their coverage by current theory and tools. Furthermore, we pinpoint gaps in existing ASP explanations approaches and identify research directions for future work.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14764v1</guid></item><item><title>[cs updates on arXiv.org] Anytime Optimal Decision Tree Learning with Continuous Features</title><link>https://arxiv.org/abs/2601.14765</link><description>arXiv:2601.14765v1 Announce Type: new 
Abstract: In recent years, significant progress has been made on algorithms for learning optimal decision trees, primarily in the context of binary features. Extending these methods to continuous features remains substantially more challenging due to the large number of potential splits for each feature. Recently, an elegant exact algorithm was proposed for learning optimal decision trees with continuous features; however, the rapidly increasing computational time limits its practical applicability to shallow depths (typically 3 or 4). It relies on a depth-first search optimization strategy that fully optimizes the left subtree of each split before exploring the corresponding right subtree. While effective in finding optimal solutions given sufficient time, this strategy can lead to poor anytime behavior: when interrupted early, the best-found tree is often highly unbalanced and suboptimal. In such cases, purely greedy methods such as C4.5 may, paradoxically, yield better solutions. To address this limitation, we propose an anytime, yet complete approach leveraging limited discrepancy search, distributing the computational effort more evenly across the entire tree structure, and thus ensuring that a high-quality decision tree is available at any interruption point. Experimental results show that our approach outperforms the existing one in terms of anytime performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14765v1</guid></item><item><title>[cs updates on arXiv.org] PAColorHolo: A Perceptually-Aware Color Management Framework for Holographic Displays</title><link>https://arxiv.org/abs/2601.14766</link><description>arXiv:2601.14766v1 Announce Type: new 
Abstract: Holographic displays offer significant potential for augmented and virtual reality applications by reconstructing wavefronts that enable continuous depth cues and natural parallax without vergence-accommodation conflict. However, despite advances in pixel-level image quality, current systems struggle to achieve perceptually accurate color reproduction--an essential component of visual realism. These challenges arise from complex system-level distortions caused by coherent laser illumination, spatial light modulator imperfections, chromatic aberrations, and camera-induced color biases. In this work, we propose a perceptually-aware color management framework for holographic displays that jointly addresses input-output color inconsistencies through color space transformation, adaptive illumination control, and neural network-based perceptual modeling of the camera's color response. We validate the effectiveness of our approach through numerical simulations, optical experiments, and a controlled user study. The results demonstrate substantial improvements in perceptual color fidelity, laying the groundwork for perceptually driven holographic rendering in future systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14766v1</guid></item><item><title>[cs updates on arXiv.org] Using Multi-Instance Learning to Identify Unique Polyps in Colon Capsule Endoscopy Images</title><link>https://arxiv.org/abs/2601.14771</link><description>arXiv:2601.14771v1 Announce Type: new 
Abstract: Identifying unique polyps in colon capsule endoscopy (CCE) images is a critical yet challenging task for medical personnel due to the large volume of images, the cognitive load it creates for clinicians, and the ambiguity in labeling specific frames. This paper formulates this problem as a multi-instance learning (MIL) task, where a query polyp image is compared with a target bag of images to determine uniqueness. We employ a multi-instance verification (MIV) framework that incorporates attention mechanisms, such as variance-excited multi-head attention (VEMA) and distance-based attention (DBA), to enhance the model's ability to extract meaningful representations. Additionally, we investigate the impact of self-supervised learning using SimCLR to generate robust embeddings. Experimental results on a dataset of 1912 polyps from 754 patients demonstrate that attention mechanisms significantly improve performance, with DBA L1 achieving the highest test accuracy of 86.26\% and a test AUC of 0.928 using a ConvNeXt backbone with SimCLR pretraining. This study underscores the potential of MIL and self-supervised learning in advancing automated analysis of Colon Capsule Endoscopy images, with implications for broader medical imaging applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14771v1</guid></item><item><title>[cs updates on arXiv.org] Semantic-Guided Unsupervised Video Summarization</title><link>https://arxiv.org/abs/2601.14773</link><description>arXiv:2601.14773v1 Announce Type: new 
Abstract: Video summarization is a crucial technique for social understanding, enabling efficient browsing of massive multimedia content and extraction of key information from social platforms. Most existing unsupervised summarization methods rely on Generative Adversarial Networks (GANs) to enhance keyframe selection and generate coherent, video summaries through adversarial training. However, such approaches primarily exploit unimodal features, overlooking the guiding role of semantic information in keyframe selection, and often suffer from unstable training. To address these limitations, we propose a novel Semantic-Guided Unsupervised Video Summarization method. Specifically, we design a novel frame-level semantic alignment attention mechanism and integrate it into a keyframe selector, which guides the Transformer-based generator within the adversarial framework to better reconstruct videos. In addition, we adopt an incremental training strategy to progressively update the model components, effectively mitigating the instability of GAN training. Experimental results demonstrate that our approach achieves superior performance on multiple benchmark datasets.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14773v1</guid></item><item><title>[cs updates on arXiv.org] Does medical specialization of VLMs enhance discriminative power?: A comprehensive investigation through feature distribution analysis</title><link>https://arxiv.org/abs/2601.14774</link><description>arXiv:2601.14774v1 Announce Type: new 
Abstract: This study investigates the feature representations produced by publicly available open source medical vision-language models (VLMs). While medical VLMs are expected to capture diagnostically relevant features, their learned representations remain underexplored, and standard evaluations like classification accuracy do not fully reveal if they acquire truly discriminative, lesion-specific features. Understanding these representations is crucial for revealing medical image structures and improving downstream tasks in medical image analysis. This study aims to investigate the feature distributions learned by medical VLMs and evaluate the impact of medical specialization. We analyze the feature distribution of multiple image modalities extracted by some representative medical VLMs across lesion classification datasets on multiple modalities. These distributions were compared them with non-medical VLMs to assess the domain-specific medical training. Our experiments showed that medical VLMs can extract discriminative features that are effective for medical classification tasks. Moreover, it was found that non-medical VLMs with recent improvement with contextual enrichment such as LLM2CLIP produce more refined feature representations. Our results imply that enhancing text encoder is more crucial than training intensively on medical images when developing medical VLMs. Notably, non-medical models are particularly vulnerable to biases introduced by overlaied text strings on images. These findings underscore the need for careful consideration on model selection according to downstream tasks besides potential risks in inference due to background biases such as textual information in images.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14774v1</guid></item><item><title>[cs updates on arXiv.org] M2I2HA: A Multi-modal Object Detection Method Based on Intra- and Inter-Modal Hypergraph Attention</title><link>https://arxiv.org/abs/2601.14776</link><description>arXiv:2601.14776v1 Announce Type: new 
Abstract: Recent advances in multi-modal detection have significantly improved detection accuracy in challenging environments (e.g., low light, overexposure). By integrating RGB with modalities such as thermal and depth, multi-modal fusion increases data redundancy and system robustness. However, significant challenges remain in effectively extracting task-relevant information both within and across modalities, as well as in achieving precise cross-modal alignment. While CNNs excel at feature extraction, they are limited by constrained receptive fields, strong inductive biases, and difficulty in capturing long-range dependencies. Transformer-based models offer global context but suffer from quadratic computational complexity and are confined to pairwise correlation modeling. Mamba and other State Space Models (SSMs), on the other hand, are hindered by their sequential scanning mechanism, which flattens 2D spatial structures into 1D sequences, disrupting topological relationships and limiting the modeling of complex higher-order dependencies. To address these issues, we propose a multi-modal perception network based on hypergraph theory called M2I2HA. Our architecture includes an Intra-Hypergraph Enhancement module to capture global many-to-many high-order relationships within each modality, and an Inter-Hypergraph Fusion module to align, enhance, and fuse cross-modal features by bridging configuration and spatial gaps between data sources. We further introduce a M2-FullPAD module to enable adaptive multi-level fusion of multi-modal enhanced features within the network, meanwhile enhancing data distribution and flow across the architecture. Extensive object detection experiments on multiple public datasets against baselines demonstrate that M2I2HA achieves state-of-the-art performance in multi-modal object detection tasks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14776v1</guid></item><item><title>[cs updates on arXiv.org] FunCineForge: A Unified Dataset Toolkit and Model for Zero-Shot Movie Dubbing in Diverse Cinematic Scenes</title><link>https://arxiv.org/abs/2601.14777</link><description>arXiv:2601.14777v1 Announce Type: new 
Abstract: Movie dubbing is the task of synthesizing speech from scripts conditioned on video scenes, requiring accurate lip sync, faithful timbre transfer, and proper modeling of character identity and emotion. However, existing methods face two major limitations: (1) high-quality multimodal dubbing datasets are limited in scale, suffer from high word error rates, contain sparse annotations, rely on costly manual labeling, and are restricted to monologue scenes, all of which hinder effective model training; (2) existing dubbing models rely solely on the lip region to learn audio-visual alignment, which limits their applicability to complex live-action cinematic scenes, and exhibit suboptimal performance in lip sync, speech quality, and emotional expressiveness. To address these issues, we propose FunCineForge, which comprises an end-to-end production pipeline for large-scale dubbing datasets and an MLLM-based dubbing model designed for diverse cinematic scenes. Using the pipeline, we construct the first Chinese television dubbing dataset with rich annotations, and demonstrate the high quality of these data. Experiments across monologue, narration, dialogue, and multi-speaker scenes show that our dubbing model consistently outperforms SOTA methods in audio quality, lip sync, timbre transfer, and instruction following. Code and demos are available at https://anonymous.4open.science/w/FunCineForge.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14777v1</guid></item><item><title>[cs updates on arXiv.org] STEAD: Robust Provably Secure Linguistic Steganography with Diffusion Language Model</title><link>https://arxiv.org/abs/2601.14778</link><description>arXiv:2601.14778v1 Announce Type: new 
Abstract: Recent provably secure linguistic steganography (PSLS) methods rely on mainstream autoregressive language models (ARMs) to address historically challenging tasks, that is, to disguise covert communication as ``innocuous'' natural language communication. However, due to the characteristic of sequential generation of ARMs, the stegotext generated by ARM-based PSLS methods will produce serious error propagation once it changes, making existing methods unavailable under an active tampering attack. To address this, we propose a robust, provably secure linguistic steganography with diffusion language models (DLMs). Unlike ARMs, DLMs can generate text in a partially parallel manner, allowing us to find robust positions for steganographic embedding that can be combined with error-correcting codes. Furthermore, we introduce error correction strategies, including pseudo-random error correction and neighborhood search correction, during steganographic extraction. Theoretical proof and experimental results demonstrate that our method is secure and robust. It can resist token ambiguity in stegotext segmentation and, to some extent, withstand token-level attacks of insertion, deletion, and substitution.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14778v1</guid></item><item><title>[cs updates on arXiv.org] RECAP: Resistance Capture in Text-based Mental Health Counseling with Large Language Models</title><link>https://arxiv.org/abs/2601.14780</link><description>arXiv:2601.14780v1 Announce Type: new 
Abstract: Recognizing and navigating client resistance is critical for effective mental health counseling, yet detecting such behaviors is particularly challenging in text-based interactions. Existing NLP approaches oversimplify resistance categories, ignore the sequential dynamics of therapeutic interventions, and offer limited interpretability.
  To address these limitations, we propose PsyFIRE, a theoretically grounded framework capturing 13 fine-grained resistance behaviors alongside collaborative interactions. Based on PsyFIRE, we construct the ClientResistance corpus with 23,930 annotated utterances from real-world Chinese text-based counseling, each supported by context-specific rationales. Leveraging this dataset, we develop RECAP, a two-stage framework that detects resistance and fine-grained resistance types with explanations.
  RECAP achieves 91.25% F1 for distinguishing collaboration and resistance and 66.58% macro-F1 for fine-grained resistance categories classification, outperforming leading prompt-based LLM baselines by over 20 points. Applied to a separate counseling dataset and a pilot study with 62 counselors, RECAP reveals the prevalence of resistance, its negative impact on therapeutic relationships and demonstrates its potential to improve counselors' understanding and intervention strategies.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14780v1</guid></item><item><title>[cs updates on arXiv.org] Towards Bound Consistency for the No-Overlap Constraint Using MDDs</title><link>https://arxiv.org/abs/2601.14784</link><description>arXiv:2601.14784v1 Announce Type: new 
Abstract: Achieving bound consistency for the no-overlap constraint is known to be NP-complete. Therefore, several polynomial-time tightening techniques, such as edge finding, not-first-not-last reasoning, and energetic reasoning, have been introduced for this constraint. In this work, we derive the first bound-consistent algorithm for the no-overlap constraint. By building on the no-overlap MDD defined by Cir\'e and van Hoeve, we extract bounds of the time window of the jobs, allowing us to tighten start and end times in time polynomial in the number of nodes of the MDD. Similarly, to bound the size and time-complexity, we limit the width of the MDD to a threshold, creating a relaxed MDD that can also be used to relax the bound-consistent filtering. Through experiments on a sequencing problem with time windows and a just-in-time objective ($1 \mid r_j, d_j, \bar{d}_j \mid \sum E_j + \sum T_j$), we observe that the proposed filtering, even with a threshold on the width, achieves a stronger reduction in the number of nodes visited in the search tree compared to the previously proposed precedence-detection algorithm of Cir\'e and van Hoeve. The new filtering also appears to be complementary to classical propagation methods for the no-overlap constraint, allowing a substantial reduction in both the number of nodes and the solving time on several instances.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14784v1</guid></item><item><title>[cs updates on arXiv.org] Training-Efficient Text-to-Music Generation with State-Space Modeling</title><link>https://arxiv.org/abs/2601.14786</link><description>arXiv:2601.14786v1 Announce Type: new 
Abstract: Recent advances in text-to-music generation (TTM) have yielded high-quality results, but often at the cost of extensive compute and the use of large proprietary internal data. To improve the affordability and openness of TTM training, an open-source generative model backbone that is more training- and data-efficient is needed. In this paper, we constrain the number of trainable parameters in the generative model to match that of the MusicGen-small benchmark (with about 300M parameters), and replace its Transformer backbone with the emerging class of state-space models (SSMs). Specifically, we explore different SSM variants for sequence modeling, and compare a single-stage SSM-based design with a decomposable two-stage SSM/diffusion hybrid design. All proposed models are trained from scratch on a purely public dataset comprising 457 hours of CC-licensed music, ensuring full openness. Our experimental findings are three-fold. First, we show that SSMs exhibit superior training efficiency compared to the Transformer counterpart. Second, despite using only 9% of the FLOPs and 2% of the training data size compared to the MusicGen-small benchmark, our model achieves competitive performance in both objective metrics and subjective listening tests based on MusicCaps captions. Finally, our scaling-down experiment demonstrates that SSMs can maintain competitive performance relative to the Transformer baseline even at the same training budget (measured in iterations), when the model size is reduced to four times smaller. To facilitate the democratization of TTM research, the processed captions, model checkpoints, and source code are available on GitHub via the project page: https://lonian6.github.io/ssmttm/.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14786v1</guid></item><item><title>[cs updates on arXiv.org] Reconstruction-Anchored Diffusion Model for Text-to-Motion Generation</title><link>https://arxiv.org/abs/2601.14788</link><description>arXiv:2601.14788v1 Announce Type: new 
Abstract: Diffusion models have seen widespread adoption for text-driven human motion generation and related tasks due to their impressive generative capabilities and flexibility. However, current motion diffusion models face two major limitations: a representational gap caused by pre-trained text encoders that lack motion-specific information, and error propagation during the iterative denoising process. This paper introduces Reconstruction-Anchored Diffusion Model (RAM) to address these challenges. First, RAM leverages a motion latent space as intermediate supervision for text-to-motion generation. To this end, RAM co-trains a motion reconstruction branch with two key objective functions: self-regularization to enhance the discrimination of the motion space and motion-centric latent alignment to enable accurate mapping from text to the motion latent space. Second, we propose Reconstructive Error Guidance (REG), a testing-stage guidance mechanism that exploits the diffusion model's inherent self-correction ability to mitigate error propagation. At each denoising step, REG uses the motion reconstruction branch to reconstruct the previous estimate, reproducing the prior error patterns. By amplifying the residual between the current prediction and the reconstructed estimate, REG highlights the improvements in the current prediction. Extensive experiments demonstrate that RAM achieves significant improvements and state-of-the-art performance. Our code will be released.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14788v1</guid></item><item><title>[cs updates on arXiv.org] CI4A: Semantic Component Interfaces for Agents Empowering Web Automation</title><link>https://arxiv.org/abs/2601.14790</link><description>arXiv:2601.14790v1 Announce Type: new 
Abstract: While Large Language Models demonstrate remarkable proficiency in high-level semantic planning, they remain limited in handling fine-grained, low-level web component manipulations. To address this limitation, extensive research has focused on enhancing model grounding capabilities through techniques such as Reinforcement Learning. However, rather than compelling agents to adapt to human-centric interfaces, we propose constructing interaction interfaces specifically optimized for agents. This paper introduces Component Interface for Agent (CI4A), a semantic encapsulation mechanism that abstracts the complex interaction logic of UI components into a set of unified tool primitives accessible to agents. We implemented CI4A within Ant Design, an industrial-grade front-end framework, covering 23 categories of commonly used UI components. Furthermore, we developed a hybrid agent featuring an action space that dynamically updates according to the page state, enabling flexible invocation of available CI4A tools. Leveraging the CI4A-integrated Ant Design, we refactored and upgraded the WebArena benchmark to evaluate existing SoTA methods. Experimental results demonstrate that the CI4A-based agent significantly outperforms existing approaches, achieving a new SoTA task success rate of 86.3%, alongside substantial improvements in execution efficiency.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14790v1</guid></item><item><title>[cs updates on arXiv.org] Synthetic Data Augmentation for Multi-Task Chinese Porcelain Classification: A Stable Diffusion Approach</title><link>https://arxiv.org/abs/2601.14791</link><description>arXiv:2601.14791v1 Announce Type: new 
Abstract: The scarcity of training data presents a fundamental challenge in applying deep learning to archaeological artifact classification, particularly for the rare types of Chinese porcelain. This study investigates whether synthetic images generated through Stable Diffusion with Low-Rank Adaptation (LoRA) can effectively augment limited real datasets for multi-task CNN-based porcelain classification. Using MobileNetV3 with transfer learning, we conducted controlled experiments comparing models trained on pure real data against those trained on mixed real-synthetic datasets (95:5 and 90:10 ratios) across four classification tasks: dynasty, glaze, kiln and type identification. Results demonstrate task-specific benefits: type classification showed the most substantial improvement (5.5\% F1-macro increase with 90:10 ratio), while dynasty and kiln tasks exhibited modest gains (3-4\%), suggesting that synthetic augmentation effectiveness depends on the alignment between generated features and task-relevant visual signatures. Our work contributes practical guidelines for deploying generative AI in archaeological research, demonstrating both the potential and limitations of synthetic data when archaeological authenticity must be balanced with data diversity.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14791v1</guid></item><item><title>[cs updates on arXiv.org] Robustness of Mixtures of Experts to Feature Noise</title><link>https://arxiv.org/abs/2601.14792</link><description>arXiv:2601.14792v1 Announce Type: new 
Abstract: Despite their practical success, it remains unclear why Mixture of Experts (MoE) models can outperform dense networks beyond sheer parameter scaling. We study an iso-parameter regime where inputs exhibit latent modular structure but are corrupted by feature noise, a proxy for noisy internal activations. We show that sparse expert activation acts as a noise filter: compared to a dense estimator, MoEs achieve lower generalization error under feature noise, improved robustness to perturbations, and faster convergence speed. Empirical results on synthetic data and real-world language tasks corroborate the theoretical insights, demonstrating consistent robustness and efficiency gains from sparse modular computation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14792v1</guid></item><item><title>[cs updates on arXiv.org] RANDSMAPs: Random-Feature/multi-Scale Neural Decoders with Mass Preservation</title><link>https://arxiv.org/abs/2601.14794</link><description>arXiv:2601.14794v1 Announce Type: new 
Abstract: We introduce RANDSMAPs (Random-feature/multi-scale neural decoders with Mass Preservation), numerical analysis-informed, explainable neural decoders designed to explicitly respect conservation laws when solving the challenging ill-posed pre-image problem in manifold learning. We start by proving the equivalence of vanilla random Fourier feature neural networks to Radial Basis Function interpolation and the double Diffusion Maps (based on Geometric Harmonics) decoders in the deterministic limit. We then establish the theoretical foundations for RANDSMAP and introduce its multiscale variant to capture structures across multiple scales. We formulate and derive the closed-form solution of the corresponding constrained optimization problem and prove the mass preservation property. Numerically, we assess the performance of RANDSMAP on three benchmark problems/datasets with mass preservation obtained by the Lighthill-Whitham-Richards traffic flow PDE with shock waves, 2D rotated MRI brain images, and the Hughes crowd dynamics PDEs. We demonstrate that RANDSMAPs yield high reconstruction accuracy at low computational cost and maintain mass conservation at single-machine precision. In its vanilla formulation, the scheme remains applicable to the classical pre-image problem, i.e., when mass-preservation constraints are not imposed.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14794v1</guid></item><item><title>[cs updates on arXiv.org] Reflecting in the Reflection: Integrating a Socratic Questioning Framework into Automated AI-Based Question Generation</title><link>https://arxiv.org/abs/2601.14798</link><description>arXiv:2601.14798v1 Announce Type: new 
Abstract: Designing good reflection questions is pedagogically important but time-consuming and unevenly supported across teachers. This paper introduces a reflection-in-reflection framework for automated generation of reflection questions with large language models (LLMs). Our approach coordinates two role-specialized agents, a Student-Teacher and a Teacher-Educator, that engage in a Socratic multi-turn dialogue to iteratively refine a single question given a teacher-specified topic, key concepts, student level, and optional instructional materials. The Student-Teacher proposes candidate questions with brief rationales, while the Teacher-Educator evaluates them along clarity, depth, relevance, engagement, and conceptual interconnections, responding only with targeted coaching questions or a fixed signal to stop the dialogue. We evaluate the framework in an authentic lower-secondary ICT setting on the topic, using GPT-4o-mini as the backbone model and a stronger GPT- 4-class LLM as an external evaluator in pairwise comparisons of clarity, relevance, depth, and overall quality. First, we study how interaction design and context (dynamic vs.fixed iteration counts; presence or absence of student level and materials) affect question quality. Dynamic stopping combined with contextual information consistently outperforms fixed 5- or 10-step refinement, with very long dialogues prone to drift or over-complication. Second, we show that our two-agent protocol produces questions that are judged substantially more relevant and deeper, and better overall, than a one-shot baseline using the same backbone model.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14798v1</guid></item><item><title>[cs updates on arXiv.org] UBATrack: Spatio-Temporal State Space Model for General Multi-Modal Tracking</title><link>https://arxiv.org/abs/2601.14799</link><description>arXiv:2601.14799v1 Announce Type: new 
Abstract: Multi-modal object tracking has attracted considerable attention by integrating multiple complementary inputs (e.g., thermal, depth, and event data) to achieve outstanding performance. Although current general-purpose multi-modal trackers primarily unify various modal tracking tasks (i.e., RGB-Thermal infrared, RGB-Depth or RGB-Event tracking) through prompt learning, they still overlook the effective capture of spatio-temporal cues. In this work, we introduce a novel multi-modal tracking framework based on a mamba-style state space model, termed UBATrack. Our UBATrack comprises two simple yet effective modules: a Spatio-temporal Mamba Adapter (STMA) and a Dynamic Multi-modal Feature Mixer. The former leverages Mamba's long-sequence modeling capability to jointly model cross-modal dependencies and spatio-temporal visual cues in an adapter-tuning manner. The latter further enhances multi-modal representation capacity across multiple feature dimensions to improve tracking robustness. In this way, UBATrack eliminates the need for costly full-parameter fine-tuning, thereby improving the training efficiency of multi-modal tracking algorithms. Experiments show that UBATrack outperforms state-of-the-art methods on RGB-T, RGB-D, and RGB-E tracking benchmarks, achieving outstanding results on the LasHeR, RGBT234, RGBT210, DepthTrack, VOT-RGBD22, and VisEvent datasets.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14799v1</guid></item><item><title>[cs updates on arXiv.org] FastFI: Enhancing API Call-Site Robustness in Microservice-Based Systems with Fault Injection</title><link>https://arxiv.org/abs/2601.14800</link><description>arXiv:2601.14800v1 Announce Type: new 
Abstract: Fault injection is a key technique for assessing software reliability, enabling proactive detection of system defects before they manifest in production. However, the increasing complexity of microservice architectures leads to exponential growth in the fault-injection space, rendering traditional random injection inefficient. Recent lineage-driven approaches mitigate this problem through heuristic pruning, but they face two limitations. First, combinatorial-fault discovery remains bottlenecked by general-purpose SAT solvers, which fail to exploit the monotone and low-overlap structure of derived CNF formulas and typically rely on a static upper bound on fault size. Second, existing techniques provide limited post-injection guidance beyond reporting detected faults. To address these challenges, we propose FastFI, a fault-injection-guided framework to enhance the robustness of API call sites in microservice-based systems. FastFI features a DFS-based solver with dynamic fault injection to discover all valid combinatorial faults, and it leverages fault-injection results to identify critical APIs whose call sites should be hardened for robustness. Experiments on four representative microservice benchmarks show that FastFI reduces end-to-end fault-injection time by an average of 76.12\% compared to state-of-the-art baselines while maintaining acceptable resource overhead. Moreover, FastFI accurately identifies high-impact APIs and provides actionable guidance for call-site hardening.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14800v1</guid></item><item><title>[cs updates on arXiv.org] LocBAM: Advancing 3D Patch-Based Image Segmentation by Integrating Location Contex</title><link>https://arxiv.org/abs/2601.14802</link><description>arXiv:2601.14802v1 Announce Type: new 
Abstract: Patch-based methods are widely used in 3D medical image segmentation to address memory constraints in processing high-resolution volumetric data. However, these approaches often neglect the patch's location within the global volume, which can limit segmentation performance when anatomical context is important. In this paper, we investigate the role of location context in patch-based 3D segmentation and propose a novel attention mechanism, LocBAM, that explicitly processes spatial information. Experiments on BTCV, AMOS22, and KiTS23 demonstrate that incorporating location context stabilizes training and improves segmentation performance, particularly under low patch-to-volume coverage where global context is missing. Furthermore, LocBAM consistently outperforms classical coordinate encoding via CoordConv. Code is publicly available at https://github.com/compai-lab/2026-ISBI-hooft</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14802v1</guid></item><item><title>[cs updates on arXiv.org] Efficient Beamforming for Discrete SIM-Aided Multiuser Systems Under Statistical CSI</title><link>https://arxiv.org/abs/2601.14803</link><description>arXiv:2601.14803v1 Announce Type: new 
Abstract: Stacked Intelligent Metasurfaces (SIM) have emerged as a revolutionary architecture for next-generation wireless communications, offering wave-domain signal processing capabilities with significantly reduced hardware complexity compared to conventional systems. However, most existing SIM research assumes continuous phase shifts and perfect instantaneous channel state information (CSI), which are impractical due to hardware discrete phase shift constraints and prohibitive pilot overhead. This paper presents a joint power allocation and discrete phase shift optimization framework for SIM-aided multiuser multiple-input single-output(MISO) downlink systems under statistical CSI. We formulate the achievable sum rate maximization problem considering practical discrete phase constraints and derive a closed-form expression for the average achievable rate under statistical CSI. To tackle the resulting non-convex optimization problem, we decouple the problem by using the weighted minimum mean square error (WMMSE) algorithm and alternating optimization (AO). Subsequently, we utilize the Lagrangian multiplier method and alternating direction method of multipliers (ADMM) to obtain closed-form iterative solutions. Our simulations demonstrate that the proposed algorithm reduces computational complexity by a factor of 50 compared to semi-definite relaxation (SDR) methods, , while maintaining over 85% of the continuous phase shift performance with only 1-bit quantization, highlighting its feasibility for low-cost hardware systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14803v1</guid></item><item><title>[cs updates on arXiv.org] Symmetry Informative and Agnostic Feature Disentanglement for 3D Shapes</title><link>https://arxiv.org/abs/2601.14804</link><description>arXiv:2601.14804v1 Announce Type: new 
Abstract: Shape descriptors, i.e., per-vertex features of 3D meshes or point clouds, are fundamental to shape analysis. Historically, various handcrafted geometry-aware descriptors and feature refinement techniques have been proposed. Recently, several studies have initiated a new research direction by leveraging features from image foundation models to create semantics-aware descriptors, demonstrating advantages across tasks like shape matching, editing, and segmentation. Symmetry, another key concept in shape analysis, has also attracted increasing attention. Consequently, constructing symmetry-aware shape descriptors is a natural progression. Although the recent method $\chi$ (Wang et al., 2025) successfully extracted symmetry-informative features from semantic-aware descriptors, its features are only one-dimensional, neglecting other valuable semantic information. Furthermore, the extracted symmetry-informative feature is usually noisy and yields small misclassified patches. To address these gaps, we propose a feature disentanglement approach which is simultaneously symmetry informative and symmetry agnostic. Further, we propose a feature refinement technique to improve the robustness of predicted symmetry informative features. Extensive experiments, including intrinsic symmetry detection, left/right classification, and shape matching, demonstrate the effectiveness of our proposed framework compared to various state-of-the-art methods, both qualitatively and quantitatively.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14804v1</guid></item><item><title>[cs updates on arXiv.org] Stochastic Decision-Making Framework for Human-Robot Collaboration in Industrial Applications</title><link>https://arxiv.org/abs/2601.14809</link><description>arXiv:2601.14809v1 Announce Type: new 
Abstract: Collaborative robots, or cobots, are increasingly integrated into various industrial and service settings to work efficiently and safely alongside humans. However, for effective human-robot collaboration, robots must reason based on human factors such as motivation level and aggression level. This paper proposes an approach for decision-making in human-robot collaborative (HRC) environments utilizing stochastic modeling. By leveraging probabilistic models and control strategies, the proposed method aims to anticipate human actions and emotions, enabling cobots to adapt their behavior accordingly. So far, most of the research has been done to detect the intentions of human co-workers. This paper discusses the theoretical framework, implementation strategies, simulation results, and potential applications of the bilateral collaboration approach for safety and efficiency in collaborative robotics.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14809v1</guid></item><item><title>[cs updates on arXiv.org] ICLF: An Immersive Code Learning Framework based on Git for Teaching and Evaluating Student Programming Projects</title><link>https://arxiv.org/abs/2601.14814</link><description>arXiv:2601.14814v1 Announce Type: new 
Abstract: Programming projects are essential in computer science education for bridging theory with practice and introducing students to tools like Git, IDEs, and debuggers. However, designing and evaluating these projects (especially in MOOCs)can be challenging. We propose the Immersive Code Learning Framework (ICLF), a scalable Git-based organizational pipeline for managing and evaluating student programming project. Students begin with an existing code base, a practice that is crucial for mirroring real-world software development. Students then iteratively complete tasks that pass predefined tests. The instructor only manages a hidden parent repository containing solutions, which is used to generate an intermediate public repository with these solutions removed via a templating system. Students are invited collaborators on private forks of this intermediate repository, possibly updated throughout the semester whenever the teacher changes the parent repository. This approach reduces grading platform dependency, supports automated feedback, and allows the project to evolve without disrupting student work. Successfully tested over several years, including in an edX MOOC, this organizational pipeline provides transparent evaluation, plagiarism detection, and continuous progress tracking for each student.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14814v1</guid></item><item><title>[cs updates on arXiv.org] Statistical Learning Theory for Distributional Classification</title><link>https://arxiv.org/abs/2601.14818</link><description>arXiv:2601.14818v1 Announce Type: new 
Abstract: In supervised learning with distributional inputs in the two-stage sampling setup, relevant to applications like learning-based medical screening or causal learning, the inputs (which are probability distributions) are not accessible in the learning phase, but only samples thereof. This problem is particularly amenable to kernel-based learning methods, where the distributions or samples are first embedded into a Hilbert space, often using kernel mean embeddings (KMEs), and then a standard kernel method like Support Vector Machines (SVMs) is applied, using a kernel defined on the embedding Hilbert space. In this work, we contribute to the theoretical analysis of this latter approach, with a particular focus on classification with distributional inputs using SVMs. We establish a new oracle inequality and derive consistency and learning rate results. Furthermore, for SVMs using the hinge loss and Gaussian kernels, we formulate a novel variant of an established noise assumption from the binary classification literature, under which we can establish learning rates. Finally, some of our technical tools like a new feature space for Gaussian kernels on Hilbert spaces are of independent interest.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14818v1</guid></item><item><title>[cs updates on arXiv.org] POTR: Post-Training 3DGS Compression</title><link>https://arxiv.org/abs/2601.14821</link><description>arXiv:2601.14821v1 Announce Type: new 
Abstract: 3D Gaussian Splatting (3DGS) has recently emerged as a promising contender to Neural Radiance Fields (NeRF) in 3D scene reconstruction and real-time novel view synthesis. 3DGS outperforms NeRF in training and inference speed but has substantially higher storage requirements. To remedy this downside, we propose POTR, a post-training 3DGS codec built on two novel techniques. First, POTR introduces a novel pruning approach that uses a modified 3DGS rasterizer to efficiently calculate every splat's individual removal effect simultaneously. This technique results in 2-4x fewer splats than other post-training pruning techniques and as a result also significantly accelerates inference with experiments demonstrating 1.5-2x faster inference than other compressed models. Second, we propose a novel method to recompute lighting coefficients, significantly reducing their entropy without using any form of training. Our fast and highly parallel approach especially increases AC lighting coefficient sparsity, with experiments demonstrating increases from 70% to 97%, with minimal loss in quality. Finally, we extend POTR with a simple fine-tuning scheme to further enhance pruning, inference, and rate-distortion performance. Experiments demonstrate that POTR, even without fine-tuning, consistently outperforms all other post-training compression techniques in both rate-distortion performance and inference speed.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14821v1</guid></item><item><title>[cs updates on arXiv.org] Multimodal system for skin cancer detection</title><link>https://arxiv.org/abs/2601.14822</link><description>arXiv:2601.14822v1 Announce Type: new 
Abstract: Melanoma detection is vital for early diagnosis and effective treatment. While deep learning models on dermoscopic images have shown promise, they require specialized equipment, limiting their use in broader clinical settings. This study introduces a multi-modal melanoma detection system using conventional photo images, making it more accessible and versatile. Our system integrates image data with tabular metadata, such as patient demographics and lesion characteristics, to improve detection accuracy. It employs a multi-modal neural network combining image and metadata processing and supports a two-step model for cases with or without metadata. A three-stage pipeline further refines predictions by boosting algorithms and enhancing performance. To address the challenges of a highly imbalanced dataset, specific techniques were implemented to ensure robust training. An ablation study evaluated recent vision architectures, boosting algorithms, and loss functions, achieving a peak Partial ROC AUC of 0.18068 (0.2 maximum) and top-15 retrieval sensitivity of 0.78371. Results demonstrate that integrating photo images with metadata in a structured, multi-stage pipeline yields significant performance improvements. This system advances melanoma detection by providing a scalable, equipment-independent solution suitable for diverse healthcare environments, bridging the gap between specialized and general clinical practices.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14822v1</guid></item><item><title>[cs updates on arXiv.org] Archives, archival bond, and digital representation: A case study with the International Image Interoperability Framework</title><link>https://arxiv.org/abs/2601.14823</link><description>arXiv:2601.14823v1 Announce Type: new 
Abstract: Within the archival sector, digitization has long been a strategic initiative to ensure greater availability of historical documents. In recent years, the promotion of guidelines and standards, combined with technological advancements, has established methodologies and best practices and developed tools to facilitate massive digitization projects. However, despite the availability of technological solutions and guidelines, digitization is intended mostly to scan documents and make the outcome images available online. This practice can be problematic in representing the complex fonds structure made of relations, the archival bond that establishes the natural ordering of documents into archival units. This is particularly relevant when the fonds also has a multimedia component, such as an audiovisual component, that is often reproduced on different platforms disconnected from textual documents. This article addresses the challenges linked to digitization in the archival sector and proposes a methodological framework for representing fonds with respect to their native organization. For this purpose, the International Image Interoperability Framework (IIIF) is employed to configure a specific model that respects the archive's hierarchical structure. In particular, this model is configured to maintain the archival bond and enhance the resource's semantic aspect to make the IIIF model semantically interoperable. To demonstrate the adaptability of the framework to the archival domain, in this work, the ''PCI-Unitelefilm'' fonds of the Fondazione Archivio Audiovisivo del Movimento Operaio e Democratico (AAMOD) served as the case study.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14823v1</guid></item><item><title>[cs updates on arXiv.org] Comparative Study of Large Language Models on Chinese Film Script Continuation: An Empirical Analysis Based on GPT-5.2 and Qwen-Max</title><link>https://arxiv.org/abs/2601.14826</link><description>arXiv:2601.14826v1 Announce Type: new 
Abstract: As large language models (LLMs) are increasingly applied to creative writing, their performance on culturally specific narrative tasks warrants systematic investigation. This study constructs the first Chinese film script continuation benchmark comprising 53 classic films, and designs a multi-dimensional evaluation framework comparing GPT-5.2 and Qwen-Max-Latest. Using a "first half to second half" continuation paradigm with 3 samples per film, we obtained 303 valid samples (GPT-5.2: 157, 98.7% validity; Qwen-Max: 146, 91.8% validity). Evaluation integrates ROUGE-L, Structural Similarity, and LLM-as-Judge scoring (DeepSeek-Reasoner).
  Statistical analysis of 144 paired samples reveals: Qwen-Max achieves marginally higher ROUGE-L (0.2230 vs 0.2114, d=-0.43); however, GPT-5.2 significantly outperforms in structural preservation (0.93 vs 0.75, d=0.46), overall quality (44.79 vs 25.72, d=1.04), and composite scores (0.50 vs 0.39, d=0.84). The overall quality effect size reaches large effect level (d&gt;0.8).
  GPT-5.2 excels in character consistency, tone-style matching, and format preservation, while Qwen-Max shows deficiencies in generation stability. This study provides a reproducible framework for LLM evaluation in Chinese creative writing.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14826v1</guid></item><item><title>[cs updates on arXiv.org] Measuring and Aligning Abstraction in Vision-Language Models with Medical Taxonomies</title><link>https://arxiv.org/abs/2601.14827</link><description>arXiv:2601.14827v1 Announce Type: new 
Abstract: Vision-Language Models show strong zero-shot performance for chest X-ray classification, but standard flat metrics fail to distinguish between clinically minor and severe errors. This work investigates how to quantify and mitigate abstraction errors by leveraging medical taxonomies. We benchmark several state-of-the-art VLMs using hierarchical metrics and introduce Catastrophic Abstraction Errors to capture cross-branch mistakes. Our results reveal substantial misalignment of VLMs with clinical taxonomies despite high flat performance. To address this, we propose risk-constrained thresholding and taxonomy-aware fine-tuning with radial embeddings, which reduce severe abstraction errors to below 2 per cent while maintaining competitive performance. These findings highlight the importance of hierarchical evaluation and representation-level alignment for safer and more clinically meaningful deployment of VLMs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14827v1</guid></item><item><title>[cs updates on arXiv.org] Moving Beyond Compliance in Soft-Robotic Catheters Through Modularity for Precision Therapies</title><link>https://arxiv.org/abs/2601.14837</link><description>arXiv:2601.14837v1 Announce Type: new 
Abstract: Soft robotic instruments could navigate delicate, tortuous anatomy more safely than rigid tools, but clinical adoption is limited by insufficient tip functionalization and real-time feedback at the tissue interface. Few sensing and therapeutic modules are compact, robust, and adaptable enough to measure, and respond to, subtle physiological cues during intraluminal procedures. We present a 1.47 mm diameter modular soft robotic catheter that integrates sensing, actuation, and therapy while retaining the compliance needed for safe endoluminal navigation. Validated across multiple in vivo settings, we emphasize its utility in endoscopic retrograde cholangiopancreatography (ERCP), a highly technical procedure and a key access route to the pancreas, an organ that is fragile, difficult to instrument, and central to diseases such as pancreatic cancer. Our architecture supports up to four independently controlled functional units, allowing customizable combinations of anchoring, manipulation, sensing, and targeted drug delivery. In a live porcine model, we demonstrate semi-autonomous deployment into the pancreatic duct and 7.5 cm of endoscopic navigation within it, a region currently inaccessible with standard catheters. A closed-loop autonomous/shared-control system that combines a learned model, magnetic actuation, onboard shape sensing, and visual marker tracking further improves cannulation accuracy. Together, these results establish a scalable platform for multifunctional soft robotic catheters and a new paradigm for complex endoluminal interventions, with potential to reduce radiation exposure, shorten training, and accelerate clinical translation of soft robotic technologies.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14837v1</guid></item><item><title>[cs updates on arXiv.org] Implementing Knowledge Representation and Reasoning with Object Oriented Design</title><link>https://arxiv.org/abs/2601.14840</link><description>arXiv:2601.14840v1 Announce Type: new 
Abstract: This paper introduces KRROOD, a framework designed to bridge the integration gap between modern software engineering and Knowledge Representation &amp; Reasoning (KR&amp;amp;R) systems. While Object-Oriented Programming (OOP) is the standard for developing complex applications, existing KR&amp;amp;R frameworks often rely on external ontologies and specialized languages that are difficult to integrate with imperative code. KRROOD addresses this by treating knowledge as a first-class programming abstraction using native class structures, bridging the gap between the logic programming and OOP paradigms. We evaluate the system on the OWL2Bench benchmark and a human-robot task learning scenario. Experimental results show that KRROOD achieves strong performance while supporting the expressive reasoning required for real-world autonomous systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14840v1</guid></item><item><title>[cs updates on arXiv.org] MTFlow: Time-Conditioned Flow Matching for Microtubule Segmentation in Noisy Microscopy Images</title><link>https://arxiv.org/abs/2601.14841</link><description>arXiv:2601.14841v1 Announce Type: new 
Abstract: Microtubules are cytoskeletal filaments that play essential roles in many cellular processes and are key therapeutic targets in several diseases. Accurate segmentation of microtubule networks is critical for studying their organization and dynamics but remains challenging due to filament curvature, dense crossings, and image noise. We present MTFlow, a novel time-conditioned flow-matching model for microtubule segmentation. Unlike conventional U-Net variants that predict masks in a single pass, MTFlow learns vector fields that iteratively transport noisy masks toward the ground truth, enabling interpretable, trajectory-based refinement. Our architecture combines a U-Net backbone with temporal embeddings, allowing the model to capture the dynamics of uncertainty resolution along filament boundaries. We trained and evaluated MTFlow on synthetic and real microtubule datasets and assessed its generalization capability on public biomedical datasets of curvilinear structures such as retinal blood vessels and nerves. MTFlow achieves competitive segmentation accuracy comparable to state-of-the-art models, offering a powerful and time-efficient tool for filamentous structure analysis with more precise annotations than manual or semi-automatic approaches.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14841v1</guid></item><item><title>[cs updates on arXiv.org] A Category-Theoretic Framework for Dependent Effect Systems</title><link>https://arxiv.org/abs/2601.14846</link><description>arXiv:2601.14846v1 Announce Type: new 
Abstract: Graded monads refine traditional monads using effect annotations in order to describe quantitatively the computational effects that a program can generate. They have been successfully applied to a variety of formal systems for reasoning about effectful computations. However, existing categorical frameworks for graded monads do not support effects that may depend on program values, which we call dependent effects, thereby limiting their expressiveness. We address this limitation by introducing indexed graded monads, a categorical generalization of graded monads inspired by the fibrational "indexed" view and by classical categorical semantics of dependent type theories. We show how indexed graded monads provide semantics for a refinement type system with dependent effects. We also show how this type system can be instantiated with specific choices of parameters to obtain several formal systems for reasoning about specific program properties. These instances include, in particular, cost analysis, probability-bound reasoning, expectation-bound reasoning, and temporal safety verification.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14846v1</guid></item><item><title>[cs updates on arXiv.org] From Observation to Prediction: LSTM for Vehicle Lane Change Forecasting on Highway On/Off-Ramps</title><link>https://arxiv.org/abs/2601.14848</link><description>arXiv:2601.14848v1 Announce Type: new 
Abstract: On and off-ramps are understudied road sections even though they introduce a higher level of variation in highway interactions. Predicting vehicles' behavior in these areas can decrease the impact of uncertainty and increase road safety. In this paper, the difference between this Area of Interest (AoI) and a straight highway section is studied. Multi-layered LSTM architecture to train the AoI model with ExiD drone dataset is utilized. In the process, different prediction horizons and different models' workflow are tested. The results show great promise on horizons up to 4 seconds with prediction accuracy starting from about 76% for the AoI and 94% for the general highway scenarios on the maximum horizon.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14848v1</guid></item><item><title>[cs updates on arXiv.org] Multi-Tast Transformer for Explainable Speech Deepfake Detection via Formant Modeling</title><link>https://arxiv.org/abs/2601.14850</link><description>arXiv:2601.14850v1 Announce Type: new 
Abstract: In this work, we introduce a multi-task transformer for speech deepfake detection, capable of predicting formant trajectories and voicing patterns over time, ultimately classifying speech as real or fake, and highlighting whether its decisions rely more on voiced or unvoiced regions. Building on a prior speaker-formant transformer architecture, we streamline the model with an improved input segmentation strategy, redesign the decoding process, and integrate built-in explainability. Compared to the baseline, our model requires fewer parameters, trains faster, and provides better interpretability, without sacrificing prediction performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14850v1</guid></item><item><title>[cs updates on arXiv.org] Adaptive Exponential Integration for Stable Gaussian Mixture Black-Box Variational Inference</title><link>https://arxiv.org/abs/2601.14855</link><description>arXiv:2601.14855v1 Announce Type: new 
Abstract: Black-box variational inference (BBVI) with Gaussian mixture families offers a flexible approach for approximating complex posterior distributions without requiring gradients of the target density. However, standard numerical optimization methods often suffer from instability and inefficiency. We develop a stable and efficient framework that combines three key components: (1) affine-invariant preconditioning via natural gradient formulations, (2) an exponential integrator that unconditionally preserves the positive definiteness of covariance matrices, and (3) adaptive time stepping to ensure stability and to accommodate distinct warm-up and convergence phases. The proposed approach has natural connections to manifold optimization and mirror descent. For Gaussian posteriors, we prove exponential convergence in the noise-free setting and almost-sure convergence under Monte Carlo estimation, rigorously justifying the necessity of adaptive time stepping. Numerical experiments on multimodal distributions, Neal's multiscale funnel, and a PDE-based Bayesian inverse problem for Darcy flow demonstrate the effectiveness of the proposed method.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14855v1</guid></item><item><title>[cs updates on arXiv.org] HiNS: Hierarchical Negative Sampling for More Comprehensive Memory Retrieval Embedding Model</title><link>https://arxiv.org/abs/2601.14857</link><description>arXiv:2601.14857v1 Announce Type: new 
Abstract: Memory-augmented language agents rely on embedding models for effective memory retrieval. However, existing training data construction overlooks a critical limitation: the hierarchical difficulty of negative samples and their natural distribution in human-agent interactions. In practice, some negatives are semantically close distractors while others are trivially irrelevant, and natural dialogue exhibits structured proportions of these types. Current approaches using synthetic or uniformly sampled negatives fail to reflect this diversity, limiting embedding models' ability to learn nuanced discrimination essential for robust memory retrieval. In this work, we propose a principled data construction framework HiNS that explicitly models negative sample difficulty tiers and incorporates empirically grounded negative ratios derived from conversational data, enabling the training of embedding models with substantially improved retrieval fidelity and generalization in memory-intensive tasks. Experiments show significant improvements: on LoCoMo, F1/BLEU-1 gains of 3.27%/3.30%(MemoryOS) and 1.95%/1.78% (Mem0); on PERSONAMEM, total score improvements of 1.19% (MemoryOS) and 2.55% (Mem0).</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14857v1</guid></item><item><title>[cs updates on arXiv.org] Modal-Centric Field Inversion via Differentiable Proper Orthogonal Decomposition</title><link>https://arxiv.org/abs/2601.14858</link><description>arXiv:2601.14858v1 Announce Type: new 
Abstract: Inverse problems in computational physics often require matching high-dimensional spatio-temporal fields, leading to prohibitive computational costs and ill-conditioned optimizations. We introduce modal-centric field inversion (MCFI), a paradigm that reformulates inverse problems in the reduced space of proper orthogonal decomposition (POD) modes rather than the full physical state space. By targeting dominant flow structures instead of point-wise field values, MCFI provides a compact, physically meaningful objective that naturally regularizes the inversion and dramatically reduces computational burden. Central to this framework is the differentiable POD: an adjoint-based method that efficiently computes sensitivities of POD modes with respect to model parameters, enabling gradient-based optimization in the modal space. We demonstrate MCFI on a one and two-dimensional modified viscous Burger's equation, optimizing spatially varying coefficients to match target dynamics through mode-matching. The adjoint formulation achieves computational cost independent of parameter dimension, in contrast to finite-difference approaches that scale linearly. MCFI establishes a foundation for scalable inverse design and model calibration in unsteady, high-dimensional systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14858v1</guid></item><item><title>[cs updates on arXiv.org] Strategic Doctrine Language Models (sdLM): A Learning-System Framework for Doctrinal Consistency and Geopolitical Forecasting</title><link>https://arxiv.org/abs/2601.14862</link><description>arXiv:2601.14862v1 Announce Type: new 
Abstract: We introduce Strategic Doctrine Language Models (sdLM), a learning-system framework for multi-document strategic reasoning with doctrinal consistency constraints and calibrated uncertainty. The approach combines multi-document attention, temporal encoding, and a doctrine-consistency layer to improve long-horizon forecasting and plan plausibility while reducing severe doctrinal violations. We evaluate sdLM using (i) expert-panel scoring of strategic scenarios (N=47), (ii) doctrine consistency on 336 doctrine publications (12,847 statements), and (iii) geopolitical forecasting on 127 historical counterfactuals (1945-2020) across 12-60 month horizons. Across these benchmarks, sdLM achieves higher strategic quality and better calibration than strong general-purpose LLM baselines, and remains competitive with human experts on long-horizon judgments. We further report ablations, scaling trends, and deployment-oriented performance/latency characteristics to clarify which components drive improvements and how they translate to operational settings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14862v1</guid></item><item><title>[cs updates on arXiv.org] Understanding Usefulness in Developer Explanations on Stack Overflow</title><link>https://arxiv.org/abs/2601.14865</link><description>arXiv:2601.14865v1 Announce Type: new 
Abstract: Explanations are essential in software engineering (SE) and requirements communication, helping stakeholders clarify ambiguities, justify design choices, and build shared understanding. Online Q&amp;amp;A forums such as Stack Overflow provide large-scale settings where such explanations are produced and evaluated, offering valuable insights into what makes them effective. While prior work has explored answer acceptance and voting behavior, little is known about which specific features make explanations genuinely useful. The relative influence of structural, contextual, and linguistic factors, such as content richness, timing, and sentiment, remains unclear. We analyzed 3,323 questions and 59,398 answers from Stack Overflow, combining text analysis and statistical modeling to examine how explanation attributes relate to perceived usefulness (normalized upvotes). Structural and contextual factors, especially explanation length, code inclusion, timing, and author reputation, show small to moderate positive effects. Sentiment polarity has negligible influence, suggesting that clarity and substance outweigh tone in technical communication. This study provides an empirical account of what drives perceived usefulness in developer explanations. It contributes methodological transparency through open data and replication materials, and conceptual insight by relating observed communication patterns to principles of requirements communication. The findings offer evidence-based implications for how developers and RE practitioners can craft clearer and more effective explanations, potentially supporting fairer communication in both open and organizational contexts. From an RE perspective, these determinants can be interpreted as practical signals for ambiguity reduction and rationale articulation in day-to-day requirements communication.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14865v1</guid></item><item><title>[cs updates on arXiv.org] On-the-fly hand-eye calibration for the da Vinci surgical robot</title><link>https://arxiv.org/abs/2601.14871</link><description>arXiv:2601.14871v1 Announce Type: new 
Abstract: In Robot-Assisted Minimally Invasive Surgery (RMIS), accurate tool localization is crucial to ensure patient safety and successful task execution. However, this remains challenging for cable-driven robots, such as the da Vinci robot, because erroneous encoder readings lead to pose estimation errors. In this study, we propose a calibration framework to produce accurate tool localization results through computing the hand-eye transformation matrix on-the-fly. The framework consists of two interrelated algorithms: the feature association block and the hand-eye calibration block, which provide robust correspondences for key points detected on monocular images without pre-training, and offer the versatility to accommodate various surgical scenarios by adopting an array of filter approaches, respectively. To validate its efficacy, we test the framework extensively on publicly available video datasets that feature multiple surgical instruments conducting tasks in both in vitro and ex vivo scenarios, under varying illumination conditions and with different levels of key point measurement accuracy. The results show a significant reduction in tool localization errors under the proposed calibration framework, with accuracies comparable to other state-of-the-art methods while being more time-efficient.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14871v1</guid></item><item><title>[cs updates on arXiv.org] HumanoidVLM: Vision-Language-Guided Impedance Control for Contact-Rich Humanoid Manipulation</title><link>https://arxiv.org/abs/2601.14874</link><description>arXiv:2601.14874v1 Announce Type: new 
Abstract: Humanoid robots must adapt their contact behavior to diverse objects and tasks, yet most controllers rely on fixed, hand-tuned impedance gains and gripper settings. This paper introduces HumanoidVLM, a vision-language driven retrieval framework that enables the Unitree G1 humanoid to select task-appropriate Cartesian impedance parameters and gripper configurations directly from an egocentric RGB image. The system couples a vision-language model for semantic task inference with a FAISS-based Retrieval-Augmented Generation (RAG) module that retrieves experimentally validated stiffness-damping pairs and object-specific grasp angles from two custom databases, and executes them through a task-space impedance controller for compliant manipulation. We evaluate HumanoidVLM on 14 visual scenarios and achieve a retrieval accuracy of 93%. Real-world experiments show stable interaction dynamics, with z-axis tracking errors typically within 1-3.5 cm and virtual forces consistent with task-dependent impedance settings. These results demonstrate the feasibility of linking semantic perception with retrieval-based control as an interpretable path toward adaptive humanoid manipulation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14874v1</guid></item><item><title>[cs updates on arXiv.org] GAT-NeRF: Geometry-Aware-Transformer Enhanced Neural Radiance Fields for High-Fidelity 4D Facial Avatars</title><link>https://arxiv.org/abs/2601.14875</link><description>arXiv:2601.14875v1 Announce Type: new 
Abstract: High-fidelity 4D dynamic facial avatar reconstruction from monocular video is a critical yet challenging task, driven by increasing demands for immersive virtual human applications. While Neural Radiance Fields (NeRF) have advanced scene representation, their capacity to capture high-frequency facial details, such as dynamic wrinkles and subtle textures from information-constrained monocular streams, requires significant enhancement. To tackle this challenge, we propose a novel hybrid neural radiance field framework, called Geometry-Aware-Transformer Enhanced NeRF (GAT-NeRF) for high-fidelity and controllable 4D facial avatar reconstruction, which integrates the Transformer mechanism into the NeRF pipeline. GAT-NeRF synergistically combines a coordinate-aligned Multilayer Perceptron (MLP) with a lightweight Transformer module, termed as Geometry-Aware-Transformer (GAT) due to its processing of multi-modal inputs containing explicit geometric priors. The GAT module is enabled by fusing multi-modal input features, including 3D spatial coordinates, 3D Morphable Model (3DMM) expression parameters, and learnable latent codes to effectively learn and enhance feature representations pertinent to fine-grained geometry. The Transformer's effective feature learning capabilities are leveraged to significantly augment the modeling of complex local facial patterns like dynamic wrinkles and acne scars. Comprehensive experiments unequivocally demonstrate GAT-NeRF's state-of-the-art performance in visual fidelity and high-frequency detail recovery, forging new pathways for creating realistic dynamic digital humans for multimedia applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14875v1</guid></item><item><title>[cs updates on arXiv.org] Contingency Planning for Safety-Critical Autonomous Vehicles: A Review and Perspectives</title><link>https://arxiv.org/abs/2601.14880</link><description>arXiv:2601.14880v1 Announce Type: new 
Abstract: Contingency planning is the architectural capability that enables autonomous vehicles (AVs) to anticipate and mitigate discrete, high-impact hazards, such as sensor outages and adversarial interactions. This paper presents a comprehensive survey of the field, synthesizing fragmented literature into a unified logic-conditioned hybrid control framework. Within this formalism, we categorize approaches into two distinct paradigms: Reactive Safety, which responds to realized hazards by enforcing safety constraints or executing fail-safe maneuvers; and Proactive Safety, which optimizes for future recourse by branching over potential modal transitions. In addition, we propose a fine-grained taxonomy that partitions the landscape into external contingencies (environmental and interactive hazards) and internal contingencies (system faults). Through a critical comparative analysis, we reveal a fundamental structural divergence: internal faults are predominantly addressed via reactive fail-safe mechanisms, whereas external interaction uncertainties increasingly require proactive branching strategies. Furthermore, we identify a critical methodological divergence: whereas physical hazards are typically managed with formal guarantees, semantic and out-of-distribution anomalies currently rely heavily on empirical validation. We conclude by identifying the open challenges in bridging the gap between theoretical guarantees and practical validation, advocating for hybrid architectures and standardized benchmarking to transition contingency planning from formulation to certifiable real-world deployment.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14880v1</guid></item><item><title>[cs updates on arXiv.org] 5G NR Non-Terrestrial Networks: Open Challenges for Full-Stack Protocol Design</title><link>https://arxiv.org/abs/2601.14883</link><description>arXiv:2601.14883v1 Announce Type: new 
Abstract: As 5th generation (5G) networks continue to evolve, there is a growing interest toward the integration of Terrestrial Networks (TNs) and Non-Terrestrial Networks (NTNs). Specifically, NTNs leverage space/air base stations such as satellites, High Altitude Platforms (HAPs), and Unmanned Aerial Vehicles (UAVs) for expanding wireless coverage to underserved rural/remote areas, supporting emergency communications, and offloading traffic in highly congested urban environments. In this paper we focus on the 3GPP 5G NR-NTN standard in the context of satellite communication networks, and highlight critical challenges that must be addressed for proper full-stack protocol design, with considerations related to the PHY, MAC, and higher layers. We also present simulation results in ns-3 to demonstrate the impact of some of these challenges on the network, as an initial step toward more advanced standardization activities on 3GPP 5G NR-NTN.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14883v1</guid></item><item><title>[cs updates on arXiv.org] What Makes Low-Bit Quantization-Aware Training Work for Reasoning LLMs? A Systematic Study</title><link>https://arxiv.org/abs/2601.14888</link><description>arXiv:2601.14888v1 Announce Type: new 
Abstract: Reasoning models excel at complex tasks such as coding and mathematics, yet their inference is often slow and token-inefficient. To improve the inference efficiency, post-training quantization (PTQ) usually comes with the cost of large accuracy drops, especially for reasoning tasks under low-bit settings. In this study, we present a systematic empirical study of quantization-aware training (QAT) for reasoning models. Our key findings include: (1) Knowledge distillation is a robust objective for reasoning models trained via either supervised fine-tuning or reinforcement learning; (2) PTQ provides a strong initialization for QAT, improving accuracy while reducing training cost; (3) Reinforcement learning remains feasible for quantized models given a viable cold start and yields additional gains; and (4) Aligning the PTQ calibration domain with the QAT training domain accelerates convergence and often improves the final accuracy. Finally, we consolidate these findings into an optimized workflow (Reasoning-QAT), and show that it consistently outperforms state-of-the-art PTQ methods across multiple LLM backbones and reasoning datasets. For instance, on Qwen3-0.6B, it surpasses GPTQ by 44.53% on MATH-500 and consistently recovers performance in the 2-bit regime.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14888v1</guid></item><item><title>[cs updates on arXiv.org] The CHI26 Workshop on the Future of Cognitive Personal Informatics</title><link>https://arxiv.org/abs/2601.14891</link><description>arXiv:2601.14891v1 Announce Type: new 
Abstract: Research on Cognitive Personal Informatics (CPI) is steadily growing as new wearable cognitive tracking technologies emerge on the consumer market, claiming to measure stress, focus, and other cognitive factors. At the same time, with generative AI offering new ways to analyse, visualize, and interpret cognitive data, we hypothesize that cognitive tracking will soon become as simple as measuring your heart rate during a run. Yet, cognitive data remains inherently more complex, context-dependent, and less well understood than physical activity data. This workshop brings together HCI experts to discuss critical questions, including: How can complex cognitive data be translated into meaningful metrics? How can AI support users' data sensemaking without over-simplifying cognitive insights? How can we design inclusive CPI technologies that consider inter-personal variance and neurodiversity? We will map</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14891v1</guid></item><item><title>[cs updates on arXiv.org] To Neuro-Symbolic Classification and Beyond by Compiling Description Logic Ontologies to Probabilistic Circuits</title><link>https://arxiv.org/abs/2601.14894</link><description>arXiv:2601.14894v1 Announce Type: new 
Abstract: Background: Neuro-symbolic methods enhance the reliability of neural network classifiers through logical constraints, but they lack native support for ontologies.
  Objectives: We aim to develop a neuro-symbolic method that reliably outputs predictions consistent with a Description Logic ontology that formalizes domain-specific knowledge.
  Methods: We encode a Description Logic ontology as a circuit, a feed-forward differentiable computational graph that supports tractable execution of queries and transformations. We show that the circuit can be used to (i) generate synthetic datasets that capture the semantics of the ontology; (ii) efficiently perform deductive reasoning on a GPU; (iii) implement neuro-symbolic models whose predictions are approximately or provably consistent with the knowledge defined in the ontology.
  Results We show that the synthetic dataset generated using the circuit qualitatively captures the semantics of the ontology while being challenging for Machine Learning classifiers, including neural networks. Moreover, we show that compiling the ontology into a circuit is a promising approach for scalable deductive reasoning, with runtimes up to three orders of magnitude faster than available reasoners. Finally, we show that our neuro-symbolic classifiers reliably produce consistent predictions when compared to neural network baselines, maintaining competitive performances or even outperforming them.
  Conclusions By compiling Description Logic ontologies into circuits, we obtain a tighter integration between the Deep Learning and Knowledge Representation fields. We show that a single circuit representation can be used to tackle different challenging tasks closely related to real-world applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14894v1</guid></item><item><title>[cs updates on arXiv.org] SpatialMem: Unified 3D Memory with Metric Anchoring and Fast Retrieval</title><link>https://arxiv.org/abs/2601.14895</link><description>arXiv:2601.14895v1 Announce Type: new 
Abstract: We present SpatialMem, a memory-centric system that unifies 3D geometry, semantics, and language into a single, queryable representation. Starting from casually captured egocentric RGB video, SpatialMem reconstructs metrically scaled indoor environments, detects structural 3D anchors (walls, doors, windows) as the first-layer scaffold, and populates a hierarchical memory with open-vocabulary object nodes -- linking evidence patches, visual embeddings, and two-layer textual descriptions to 3D coordinates -- for compact storage and fast retrieval. This design enables interpretable reasoning over spatial relations (e.g., distance, direction, visibility) and supports downstream tasks such as language-guided navigation and object retrieval without specialized sensors. Experiments across three real-life indoor scenes demonstrate that SpatialMem maintains strong anchor-description-level navigation completion and hierarchical retrieval accuracy under increasing clutter and occlusion, offering an efficient and extensible framework for embodied spatial intelligence.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14895v1</guid></item><item><title>[cs updates on arXiv.org] Language-Coupled Reinforcement Learning for Multilingual Retrieval-Augmented Generation</title><link>https://arxiv.org/abs/2601.14896</link><description>arXiv:2601.14896v1 Announce Type: new 
Abstract: Multilingual retrieval-augmented generation (MRAG) requires models to effectively acquire and integrate beneficial external knowledge from multilingual collections. However, most existing studies employ a unitive process where queries of equivalent semantics across different languages are processed through a single-turn retrieval and subsequent optimization. Such a ``one-size-fits-all'' strategy is often suboptimal in multilingual settings, as the models occur to knowledge bias and conflict during the interaction with the search engine. To alleviate the issues, we propose LcRL, a multilingual search-augmented reinforcement learning framework that integrates a language-coupled Group Relative Policy Optimization into the policy and reward models. We adopt the language-coupled group sampling in the rollout module to reduce knowledge bias, and regularize an auxiliary anti-consistency penalty in the reward models to mitigate the knowledge conflict. Experimental results demonstrate that LcRL not only achieves competitive performance but is also appropriate for various practical scenarios such as constrained training data and retrieval over collections encompassing a large number of languages. Our code is available at https://github.com/Cherry-qwq/LcRL-Open.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14896v1</guid></item><item><title>[cs updates on arXiv.org] Just aware enough: Evaluating awareness across artificial systems</title><link>https://arxiv.org/abs/2601.14901</link><description>arXiv:2601.14901v1 Announce Type: new 
Abstract: Recent debates on artificial intelligence increasingly emphasise questions of AI consciousness and moral status, yet there remains little agreement on how such properties should be evaluated. In this paper, we argue that awareness offers a more productive and methodologically tractable alternative. We introduce a practical method for evaluating awareness across diverse systems, where awareness is understood as encompassing a system's abilities to process, store and use information in the service of goal-directed action. Central to this approach is the claim that any evaluation aiming to capture the diversity of artificial systems must be domain-sensitive, deployable at any scale, multidimensional, and enable the prediction of task performance, while generalising to the level of abilities for the sake of comparison. Given these four desiderata, we outline a structured approach to evaluating and comparing awareness profiles across artificial systems with differing architectures, scales, and operational domains. By shifting the focus from artificial consciousness to being just aware enough, this approach aims to facilitate principled assessment, support design and oversight, and enable more constructive scientific and public discourse.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14901v1</guid></item><item><title>[cs updates on arXiv.org] PodBench: A Comprehensive Benchmark for Instruction-Aware Audio-Oriented Podcast Script Generation</title><link>https://arxiv.org/abs/2601.14903</link><description>arXiv:2601.14903v1 Announce Type: new 
Abstract: Podcast script generation requires LLMs to synthesize structured, context-grounded dialogue from diverse inputs, yet systematic evaluation resources for this task remain limited. To bridge this gap, we introduce PodBench, a benchmark comprising 800 samples with inputs up to 21K tokens and complex multi-speaker instructions. We propose a multifaceted evaluation framework that integrates quantitative constraints with LLM-based quality assessment. Extensive experiments reveal that while proprietary models generally excel, open-source models equipped with explicit reasoning demonstrate superior robustness in handling long contexts and multi-speaker coordination compared to standard baselines. However, our analysis uncovers a persistent divergence where high instruction following does not guarantee high content substance. PodBench offers a reproducible testbed to address these challenges in long-form, audio-centric generation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14903v1</guid></item><item><title>[cs updates on arXiv.org] SynPerf: A Hybrid Analytical-ML Framework for GPU Performance Prediction</title><link>https://arxiv.org/abs/2601.14910</link><description>arXiv:2601.14910v1 Announce Type: new 
Abstract: The rapid expansion of Transformer-based large language models has dramatically increased the need for high-performance GPUs. As a result, there is growing demand for fast, accurate, and widely generalizable GPU performance models to support next-generation hardware selection and system-level exploration. However, current data-driven methods are limited, exhibiting poor generalization across hardware and inadequate modeling of complex production-level kernels common in modern inference stacks. To address these issues, we present SyncPerf, a unified GPU modeling framework. This approach first employs an analytical model to quantify a given kernel's demands on the GPU's heterogeneous instruction pipelines. These analytical features are then fed into a machine learning (ML) model to capture complex cross-pipeline interactions and resource dependencies, enabling high-fidelity performance prediction. Our evaluation across 11 GPU types from four generations of major architectures on two widely-used serving systems demonstrates that SyncPerf delivers high fidelity and strong generalizability. It achieves accurate predictions, with only 6.1% average error at the kernel level and 8.5% for end-to-end inference -- reducing the error of state-of-the-art methods by 6.7x and 4.4x, respectively. We also demonstrate SynPerf's value "beyond simulation" by utilizing its performance ceiling to diagnose implementation shortcomings and guide the optimization of a production fused MoE Triton kernel, achieving up to 1.7x speedup.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14910v1</guid></item><item><title>[cs updates on arXiv.org] Generalized preconditioned conjugate gradients for adaptive FEM with optimal complexity</title><link>https://arxiv.org/abs/2601.14911</link><description>arXiv:2601.14911v1 Announce Type: new 
Abstract: We consider adaptive finite element methods (AFEMs) with inexact algebraic solver for second-order symmetric linear elliptic diffusion problems. We formulate and analyze a non-linear and non-symmetric geometric multigrid preconditioner for the generalized preconditioned conjugate gradient method (GPCG) used to solve the arising finite element systems. Moreover, a linear and symmetric variant of the geometric multigrid preconditioner that is suitable for the (standard) preconditioned conjugate gradient method (PCG) is provided and analyzed. We show that both preconditioners are optimal in the sense that, first, the resulting algebraic solvers admit a contraction factor that is independent of the local mesh size h and the polynomial degree p, and, second, that they can be applied with linear computational complexity. Related to this, quasi-optimal computational cost of the overall adaptive finite element method is addressed. Numerical experiments underline the theoretical findings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14911v1</guid></item><item><title>[cs updates on arXiv.org] AlertGuardian: Intelligent Alert Life-Cycle Management for Large-scale Cloud Systems</title><link>https://arxiv.org/abs/2601.14912</link><description>arXiv:2601.14912v1 Announce Type: new 
Abstract: Alerts are critical for detecting anomalies in large-scale cloud systems, ensuring reliability and user experience. However, current systems generate overwhelming volumes of alerts, degrading operational efficiency due to ineffective alert life-cycle management. This paper details the efforts of Company-X to optimize alert life-cycle management, addressing alert fatigue in cloud systems. We propose AlertGuardian, a framework collaborating large language models (LLMs) and lightweight graph models to optimize the alert life-cycle through three phases: Alert Denoise uses graph learning model with virtual noise to filter noise, Alert Summary employs Retrieval Augmented Generation (RAG) with LLMs to create actionable summary, and Alert Rule Refinement leverages multi-agent iterative feedbacks to improve alert rule quality. Evaluated on four real-world datasets from Company-X's services, AlertGuardian significantly mitigates alert fatigue (94.8\% alert reduction ratios) and accelerates fault diagnosis (90.5\% diagnosis accuracy). Moreover, AlertGuardian improves 1,174 alert rules, with 375 accepted by SREs (32% acceptance rate). Finally, we share success stories and lessons learned about alert life-cycle management after the deployment of AlertGuardian in Company-X.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14912v1</guid></item><item><title>[cs updates on arXiv.org] CodeDelegator: Mitigating Context Pollution via Role Separation in Code-as-Action Agents</title><link>https://arxiv.org/abs/2601.14914</link><description>arXiv:2601.14914v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) allow agents to represent actions as executable code, offering greater expressivity than traditional tool-calling. However, real-world tasks often demand both strategic planning and detailed implementation. Using a single agent for both leads to context pollution from debugging traces and intermediate failures, impairing long-horizon performance. We propose CodeDelegator, a multi-agent framework that separates planning from implementation via role specialization. A persistent Delegator maintains strategic oversight by decomposing tasks, writing specifications, and monitoring progress without executing code. For each sub-task, a new Coder agent is instantiated with a clean context containing only its specification, shielding it from prior failures. To coordinate between agents, we introduce Ephemeral-Persistent State Separation (EPSS), which isolates each Coder's execution state while preserving global coherence, preventing debugging traces from polluting the Delegator's context. Experiments on various benchmarks demonstrate the effectiveness of CodeDelegator across diverse scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14914v1</guid></item><item><title>[cs updates on arXiv.org] Tailoring Adverse Event Prediction in Type 1 Diabetes with Patient-Specific Deep Learning Models</title><link>https://arxiv.org/abs/2601.14917</link><description>arXiv:2601.14917v1 Announce Type: new 
Abstract: Effective management of Type 1 Diabetes requires continuous glucose monitoring and precise insulin adjustments to prevent hyperglycemia and hypoglycemia. With the growing adoption of wearable glucose monitors and mobile health applications, accurate blood glucose prediction is essential for enhancing automated insulin delivery and decision-support systems. This paper presents a deep learning-based approach for personalized blood glucose prediction, leveraging patient-specific data to improve prediction accuracy and responsiveness in real-world scenarios. Unlike traditional generalized models, our method accounts for individual variability, enabling more effective subject-specific predictions. We compare Leave-One-Subject-Out Cross-Validation with a fine-tuning strategy to evaluate their ability to model patient-specific dynamics. Results show that personalized models significantly improve the prediction of adverse events, enabling more precise and timely interventions in real-world scenarios. To assess the impact of patient-specific data, we conduct experiments comparing a multimodal, patient-specific approach against traditional CGM-only methods. Additionally, we perform an ablation study to investigate model performance with progressively smaller training sets, identifying the minimum data required for effective personalization-an essential consideration for real-world applications where extensive data collection is often challenging. Our findings underscore the potential of adaptive, personalized glucose prediction models for advancing next-generation diabetes management, particularly in wearable and mobile health platforms, enhancing consumer-oriented diabetes care solutions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14917v1</guid></item><item><title>[cs updates on arXiv.org] Diagonals and algebraicity modulo $p$: a sharper degree bound</title><link>https://arxiv.org/abs/2601.14920</link><description>arXiv:2601.14920v1 Announce Type: new 
Abstract: In 1984, Deligne proved that for any prime number $p$, the reduction modulo $p$ of the diagonal of a multivariate algebraic power series with integer coefficients is algebraic over the field of rational functions with coefficients in $\mathbb F_p$. Moreover, he conjectured that the algebraic degrees $d_p$ of these functions should grow at most polynomially in $p$. In this article, we provide a new and elementary proof of Deligne's theorem, which yields the first general polynomial bound on $d_p$ with an explicit and reasonable degree.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14920v1</guid></item><item><title>[cs updates on arXiv.org] Vision-Language Models on the Edge for Real-Time Robotic Perception</title><link>https://arxiv.org/abs/2601.14921</link><description>arXiv:2601.14921v1 Announce Type: new 
Abstract: Vision-Language Models (VLMs) enable multimodal reasoning for robotic perception and interaction, but their deployment in real-world systems remains constrained by latency, limited onboard resources, and privacy risks of cloud offloading. Edge intelligence within 6G, particularly Open RAN and Multi-access Edge Computing (MEC), offers a pathway to address these challenges by bringing computation closer to the data source. This work investigates the deployment of VLMs on ORAN/MEC infrastructure using the Unitree G1 humanoid robot as an embodied testbed. We design a WebRTC-based pipeline that streams multimodal data to an edge node and evaluate LLaMA-3.2-11B-Vision-Instruct deployed at the edge versus in the cloud under real-time conditions. Our results show that edge deployment preserves near-cloud accuracy while reducing end-to-end latency by 5\%. We further evaluate Qwen2-VL-2B-Instruct, a compact model optimized for resource-constrained environments, which achieves sub-second responsiveness, cutting latency by more than half but at the cost of accuracy.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14921v1</guid></item><item><title>[cs updates on arXiv.org] Operationalising DAO Sustainability KPIs: A Multi-Chain Dashboard for Governance Analytics</title><link>https://arxiv.org/abs/2601.14927</link><description>arXiv:2601.14927v1 Announce Type: new 
Abstract: We present DAO Portal, a production-grade analytics pipeline and interactive dashboard for assessing the sustainability of Decentralised Autonomous Organisations (DAOs) through Key Performance Indicators (KPIs) derived from on-chain governance and token events. Building on our previous work, which defined and validated a multidimensional KPI framework for DAO sustainability, this paper moves from theory to practice by operationalising that framework in software infrastructure designed for finance and FinTech contexts. The system ingests governance and treasury data from major EVM networks, harmonises the outputs, and computes sustainability scores across four dimensions: participation, accumulated funds, voting efficiency, and decentralisation. A composite 0 to 12 score is then derived using transparent thresholds that are applied client-side in the browser.
  Using a curated snapshot of more than 50 active DAOs covering 6,930 proposals and 317,317 unique voting addresses, we show how the platform surfaces recurring patterns such as persistently low participation and concentration of proposal activity. These results demonstrate how DAO Portal supports the diagnosis of governance risks and the comparison of design choices across DAOs. To promote reproducibility and adoption, we release source code, data schema, and dashboard implementation. By turning governance traces into measurable and explainable KPIs, DAO Portal provides auditable evidence of DAO sustainability and contributes software engineering infrastructure for financial applications where treasuries and decision-making rights involve significant assets.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14927v1</guid></item><item><title>[cs updates on arXiv.org] Generative Artificial Intelligence, Musical Heritage and the Construction of Peace Narratives: A Case Study in Mali</title><link>https://arxiv.org/abs/2601.14931</link><description>arXiv:2601.14931v1 Announce Type: new 
Abstract: This study explores the capacity of generative artificial intelligence (Gen AI) to contribute to the construction of peace narratives and the revitalization of musical heritage in Mali. The study has been made in a political and social context where inter-community tensions and social fractures motivate a search for new symbolic frameworks for reconciliation. The study empirically explores three questions: (1) how Gen AI can be used as a tool for musical creation rooted in national languages and traditions; (2) to what extent Gen AI systems enable a balanced hybridization between technological innovation and cultural authenticity; and (3) how AI-assisted musical co-creation can strengthen social cohesion and cultural sovereignty. The experimental results suggest that Gen AI, embedded in a culturally conscious participatory framework, can act as a catalyst for symbolic diplomacy, amplifying local voices instead of standardizing them. However, challenges persist regarding the availability of linguistic corpora, algorithmic censorship, and the ethics of generating compositions derived from copyrighted sources.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14931v1</guid></item><item><title>[cs updates on arXiv.org] LLM-Based Repair of C++ Implicit Data Loss Compiler Warnings: An Industrial Case Study</title><link>https://arxiv.org/abs/2601.14936</link><description>arXiv:2601.14936v1 Announce Type: new 
Abstract: This paper presents a method to automatically fix implicit data loss warnings in large C++ projects using Large Language Models (LLMs). Our approach uses the Language Server Protocol (LSP) to gather context, Tree-sitter to extract relevant code, and LLMs to make decisions and generate fixes. The method evaluates the necessity of range checks concerning performance implications and generates appropriate fixes. We tested this method in a large C++ project, resulting in a 92.73% acceptance rate of the fixes by human developers during the code review. Our LLM-generated fixes reduced the number of warning fix changes that introduced additional instructions due to range checks and exception handling by 39.09% compared to a baseline fix strategy. This result was 13.56% behind the optimal solutions created by human developers. These findings demonstrate that our LLM-based approach can reduce the manual effort to address compiler warnings while maintaining code quality and performance in a real-world scenario. Our automated approach shows promise for integration into existing development workflows, potentially improving code maintenance practices in complex C++ software projects.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14936v1</guid></item><item><title>[cs updates on arXiv.org] Communication-Efficient Multi-Modal Edge Inference via Uncertainty-Aware Distributed Learning</title><link>https://arxiv.org/abs/2601.14942</link><description>arXiv:2601.14942v1 Announce Type: new 
Abstract: Semantic communication is emerging as a key enabler for distributed edge intelligence due to its capability to convey task-relevant meaning. However, achieving communication-efficient training and robust inference over wireless links remains challenging. This challenge is further exacerbated for multi-modal edge inference (MMEI) by two factors: 1) prohibitive communication overhead for distributed learning over bandwidth-limited wireless links, due to the \emph{multi-modal} nature of the system; and 2) limited robustness under varying channels and noisy multi-modal inputs. In this paper, we propose a three-stage communication-aware distributed learning framework to improve training and inference efficiency while maintaining robustness over wireless channels. In Stage~I, devices perform local multi-modal self-supervised learning to obtain shared and modality-specific encoders without device--server exchange, thereby reducing the communication cost. In Stage~II, distributed fine-tuning with centralized evidential fusion calibrates per-modality uncertainty and reliably aggregates features distorted by noise or channel fading. In Stage~III, an uncertainty-guided feedback mechanism selectively requests additional features for uncertain samples, optimizing the communication--accuracy tradeoff in the distributed setting. Experiments on RGB--depth indoor scene classification show that the proposed framework attains higher accuracy with far fewer training communication rounds and remains robust to modality degradation or channel variation, outperforming existing self-supervised and fully supervised baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14942v1</guid></item><item><title>[cs updates on arXiv.org] State of the Art of LLM-Enabled Interaction with Visualization</title><link>https://arxiv.org/abs/2601.14943</link><description>arXiv:2601.14943v1 Announce Type: new 
Abstract: We report on a systematic, PRISMA-guided survey of research at the intersection of LLMs and visualization, with a particular focus on visio-verbal interaction -- where verbal and visual modalities converge to support data sense-making. The emergence of Large Language Models (LLMs) has introduced new paradigms for interacting with data visualizations through natural language, leading to intuitive, multimodal, and accessible interfaces. We analyze 48 papers across six dimensions: application domain, visualization task, visualization representation, interaction modality, LLM integration, and system evaluation. Our classification framework maps LLM roles across the visualization pipeline, from data querying and transformation to visualization generation, explanation, and navigation. We highlight emerging design patterns, identify gaps in accessibility and visualization reading, and discuss the limitations of current LLMs in spatial reasoning and contextual grounding. We further reflect on evaluations of combined LLM-visualization systems, highlighting how current research projects tackle this challenge and discuss current gaps in conducting meaningful evaluations of such systems. With our survey we aim to guide future research and system design in LLM-enhanced visualization, supporting broad audiences and intelligent, conversational interfaces.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14943v1</guid></item><item><title>[cs updates on arXiv.org] The GDN-CC Dataset: Automatic Corpus Clarification for AI-enhanced Democratic Citizen Consultations</title><link>https://arxiv.org/abs/2601.14944</link><description>arXiv:2601.14944v1 Announce Type: new 
Abstract: LLMs are ubiquitous in modern NLP, and while their applicability extends to texts produced for democratic activities such as online deliberations or large-scale citizen consultations, ethical questions have been raised for their usage as analysis tools. We continue this line of research with two main goals: (a) to develop resources that can help standardize citizen contributions in public forums at the pragmatic level, and make them easier to use in topic modeling and political analysis; (b) to study how well this standardization can reliably be performed by small, open-weights LLMs, i.e. models that can be run locally and transparently with limited resources. Accordingly, we introduce Corpus Clarification as a preprocessing framework for large-scale consultation data that transforms noisy, multi-topic contributions into structured, self-contained argumentative units ready for downstream analysis. We present GDN-CC, a manually-curated dataset of 1,231 contributions to the French Grand D\'ebat National, comprising 2,285 argumentative units annotated for argumentative structure and manually clarified. We then show that finetuned Small Language Models match or outperform LLMs on reproducing these annotations, and measure their usability for an opinion clustering task. We finally release GDN-CC-large, an automatically annotated corpus of 240k contributions, the largest annotated democratic consultation dataset to date.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14944v1</guid></item><item><title>[cs updates on arXiv.org] TIDAL: Temporally Interleaved Diffusion and Action Loop for High-Frequency VLA Control</title><link>https://arxiv.org/abs/2601.14945</link><description>arXiv:2601.14945v1 Announce Type: new 
Abstract: Large-scale Vision-Language-Action (VLA) models offer semantic generalization but suffer from high inference latency, limiting them to low-frequency batch-and-execute paradigm. This frequency mismatch creates an execution blind spot, causing failures in dynamic environments where targets move during the open-loop execution window. We propose TIDAL (Temporally Interleaved Diffusion and Action Loop), a hierarchical framework that decouples semantic reasoning from high-frequency actuation. TIDAL operates as a backbone-agnostic module for diffusion-based VLAs, using a dual-frequency architecture to redistribute the computational budget. Specifically, a low-frequency macro-intent loop caches semantic embeddings, while a high-frequency micro-control loop interleaves single-step flow integration with execution. This design enables approximately 9 Hz control updates on edge hardware (vs. approximately 2.4 Hz baselines) without increasing marginal overhead. To handle the resulting latency shift, we introduce a temporally misaligned training strategy where the policy learns predictive compensation using stale semantic intent alongside real-time proprioception. Additionally, we address the insensitivity of static vision encoders to velocity by incorporating a differential motion predictor. TIDAL is architectural, making it orthogonal to system-level optimizations. Experiments show a 2x performance gain over open-loop baselines in dynamic interception tasks. Despite a marginal regression in static success rates, our approach yields a 4x increase in feedback frequency and extends the effective horizon of semantic embeddings beyond the native action chunk size. Under non-paused inference protocols, TIDAL remains robust where standard baselines fail due to latency.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14945v1</guid></item><item><title>[cs updates on arXiv.org] What Should I Cite? A RAG Benchmark for Academic Citation Prediction</title><link>https://arxiv.org/abs/2601.14949</link><description>arXiv:2601.14949v1 Announce Type: new 
Abstract: With the rapid growth of Web-based academic publications, more and more papers are being published annually, making it increasingly difficult to find relevant prior work. Citation prediction aims to automatically suggest appropriate references, helping scholars navigate the expanding scientific literature. Here we present \textbf{CiteRAG}, the first comprehensive retrieval-augmented generation (RAG)-integrated benchmark for evaluating large language models on academic citation prediction, featuring a multi-level retrieval strategy, specialized retrievers, and generators. Our benchmark makes four core contributions: (1) We establish two instances of the citation prediction task with different granularity. Task 1 focuses on coarse-grained list-specific citation prediction, while Task 2 targets fine-grained position-specific citation prediction. To enhance these two tasks, we build a dataset containing 7,267 instances for Task 1 and 8,541 instances for Task 2, enabling comprehensive evaluation of both retrieval and generation. (2) We construct a three-level large-scale corpus with 554k papers spanning many major subfields, using an incremental pipeline. (3) We propose a multi-level hybrid RAG approach for citation prediction, fine-tuning embedding models with contrastive learning to capture complex citation relationships, paired with specialized generation models. (4) We conduct extensive experiments across state-of-the-art language models, including closed-source APIs, open-source models, and our fine-tuned generators, demonstrating the effectiveness of our framework. Our open-source toolkit enables reproducible evaluation and focuses on academic literature, providing the first comprehensive evaluation framework for citation prediction and serving as a methodological template for other scientific domains. Our source code and data are released at https://github.com/LQgdwind/CiteRAG.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14949v1</guid></item><item><title>[cs updates on arXiv.org] Erosion Attack for Adversarial Training to Enhance Semantic Segmentation Robustness</title><link>https://arxiv.org/abs/2601.14950</link><description>arXiv:2601.14950v1 Announce Type: new 
Abstract: Existing segmentation models exhibit significant vulnerability to adversarial attacks.To improve robustness, adversarial training incorporates adversarial examples into model training. However, existing attack methods consider only global semantic information and ignore contextual semantic relationships within the samples, limiting the effectiveness of adversarial training. To address this issue, we propose EroSeg-AT, a vulnerability-aware adversarial training framework that leverages EroSeg to generate adversarial examples. EroSeg first selects sensitive pixels based on pixel-level confidence and then progressively propagates perturbations to higher-confidence pixels, effectively disrupting the semantic consistency of the samples. Experimental results show that, compared to existing methods, our approach significantly improves attack effectiveness and enhances model robustness under adversarial training.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14950v1</guid></item><item><title>[cs updates on arXiv.org] TempViz: On the Evaluation of Temporal Knowledge in Text-to-Image Models</title><link>https://arxiv.org/abs/2601.14951</link><description>arXiv:2601.14951v1 Announce Type: new 
Abstract: Time alters the visual appearance of entities in our world, like objects, places, and animals. Thus, for accurately generating contextually-relevant images, knowledge and reasoning about time can be crucial (e.g., for generating a landscape in spring vs. in winter). Yet, although substantial work exists on understanding and improving temporal knowledge in natural language processing, research on how temporal phenomena appear and are handled in text-to-image (T2I) models remains scarce. We address this gap with TempViz, the first data set to holistically evaluate temporal knowledge in image generation, consisting of 7.9k prompts and more than 600 reference images. Using TempViz, we study the capabilities of five T2I models across five temporal knowledge categories. Human evaluation shows that temporal competence is generally weak, with no model exceeding 75% accuracy across categories. Towards larger-scale studies, we also examine automated evaluation methods, comparing several established approaches against human judgments. However, none of these approaches provides a reliable assessment of temporal cues - further indicating the pressing need for future research on temporal knowledge in T2I.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14951v1</guid></item><item><title>[cs updates on arXiv.org] CorpusQA: A 10 Million Token Benchmark for Corpus-Level Analysis and Reasoning</title><link>https://arxiv.org/abs/2601.14952</link><description>arXiv:2601.14952v1 Announce Type: new 
Abstract: While large language models now handle million-token contexts, their capacity for reasoning across entire document repositories remains largely untested. Existing benchmarks are inadequate, as they are mostly limited to single long texts or rely on a "sparse retrieval" assumption-that answers can be derived from a few relevant chunks. This assumption fails for true corpus-level analysis, where evidence is highly dispersed across hundreds of documents and answers require global integration, comparison, and statistical aggregation. To address this critical gap, we introduce CorpusQA, a new benchmark scaling up to 10 million tokens, generated via a novel data synthesis framework. By decoupling reasoning from textual representation, this framework creates complex, computation-intensive queries with programmatically guaranteed ground-truth answers, challenging systems to perform holistic reasoning over vast, unstructured text without relying on fallible human annotation. We further demonstrate the utility of our framework beyond evaluation, showing that fine-tuning on our synthesized data effectively enhances an LLM's general long-context reasoning capabilities. Extensive experiments reveal that even state-of-the-art long-context LLMs struggle as input length increases, and standard retrieval-augmented generation systems collapse entirely. Our findings indicate that memory-augmented agentic architectures offer a more robust alternative, suggesting a critical shift is needed from simply extending context windows to developing advanced architectures for global information synthesis.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14952v1</guid></item><item><title>[cs updates on arXiv.org] Multimodal Rumor Detection Enhanced by External Evidence and Forgery Features</title><link>https://arxiv.org/abs/2601.14954</link><description>arXiv:2601.14954v1 Announce Type: new 
Abstract: Social media increasingly disseminates information through mixed image text posts, but rumors often exploit subtle inconsistencies and forged content, making detection based solely on post content difficult. Deep semantic mismatch rumors, which superficially align images and texts, pose particular challenges and threaten online public opinion. Existing multimodal rumor detection methods improve cross modal modeling but suffer from limited feature extraction, noisy alignment, and inflexible fusion strategies, while ignoring external factual evidence necessary for verifying complex rumors. To address these limitations, we propose a multimodal rumor detection model enhanced with external evidence and forgery features. The model uses a ResNet34 visual encoder, a BERT text encoder, and a forgery feature module extracting frequency-domain traces and compression artifacts via Fourier transformation. BLIP-generated image descriptions bridge image and text semantic spaces. A dual contrastive learning module computes contrastive losses between text image and text description pairs, improving detection of semantic inconsistencies. A gated adaptive feature-scaling fusion mechanism dynamically adjusts multimodal fusion and reduces redundancy. Experiments on Weibo and Twitter datasets demonstrate that our model outperforms mainstream baselines in macro accuracy, recall, and F1 score.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14954v1</guid></item><item><title>[cs updates on arXiv.org] Multi-Behavior Sequential Modeling with Transition-Aware Graph Attention Network for E-Commerce Recommendation</title><link>https://arxiv.org/abs/2601.14955</link><description>arXiv:2601.14955v1 Announce Type: new 
Abstract: User interactions on e-commerce platforms are inherently diverse, involving behaviors such as clicking, favoriting, adding to cart, and purchasing. The transitions between these behaviors offer valuable insights into user-item interactions, serving as a key signal for understanding evolving preferences. Consequently, there is growing interest in leveraging multi-behavior data to better capture user intent. Recent studies have explored sequential modeling of multi-behavior data, many relying on transformer-based architectures with polynomial time complexity. While effective, these approaches often incur high computational costs, limiting their applicability in large-scale industrial systems with long user sequences. To address this challenge, we propose the Transition-Aware Graph Attention Network (TGA), a linear-complexity approach for modeling multi-behavior transitions. Unlike traditional transformers that treat all behavior pairs equally, TGA constructs a structured sparse graph by identifying informative transitions from three perspectives: (a) item-level transitions, (b) category-level transitions, and (c) neighbor-level transitions. Built upon the structured graph, TGA employs a transition-aware graph Attention mechanism that jointly models user-item interactions and behavior transition types, enabling more accurate capture of sequential patterns while maintaining computational efficiency. Experiments show that TGA outperforms all state-of-the-art models while significantly reducing computational cost. Notably, TGA has been deployed in a large-scale industrial production environment, where it leads to impressive improvements in key business metrics.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14955v1</guid></item><item><title>[cs updates on arXiv.org] Improving Regret Approximation for Unsupervised Dynamic Environment Generation</title><link>https://arxiv.org/abs/2601.14957</link><description>arXiv:2601.14957v1 Announce Type: new 
Abstract: Unsupervised Environment Design (UED) seeks to automatically generate training curricula for reinforcement learning (RL) agents, with the goal of improving generalisation and zero-shot performance. However, designing effective curricula remains a difficult problem, particularly in settings where small subsets of environment parameterisations result in significant increases in the complexity of the required policy. Current methods struggle with a difficult credit assignment problem and rely on regret approximations that fail to identify challenging levels, both of which are compounded as the size of the environment grows. We propose Dynamic Environment Generation for UED (DEGen) to enable a denser level generator reward signal, reducing the difficulty of credit assignment and allowing for UED to scale to larger environment sizes. We also introduce a new regret approximation, Maximised Negative Advantage (MNA), as a significantly improved metric to optimise for, that better identifies more challenging levels. We show empirically that MNA outperforms current regret approximations and when combined with DEGen, consistently outperforms existing methods, especially as the size of the environment grows. We have made all our code available here: https://github.com/HarryMJMead/Dynamic-Environment-Generation-for-UED.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14957v1</guid></item><item><title>[cs updates on arXiv.org] A Comprehensive Benchmark of Language Models on Unicode and Romanized Sinhala</title><link>https://arxiv.org/abs/2601.14958</link><description>arXiv:2601.14958v1 Announce Type: new 
Abstract: The performance of Language Models (LMs) on lower-resource, morphologically rich languages like Sinhala remains under-explored, particularly for Romanized Sinhala, which is prevalent in digital communication. This paper presents a comprehensive benchmark of modern LMs on a diverse corpus of Unicode and Romanized Sinhala. We evaluate open-source models using perplexity, a measure of how well a model predicts a text, and leading closed-source models via a qualitative analysis of sentence completion. Our findings reveal that the Mistral-Nemo-Base-2407 model achieves the strongest predictive performance on Unicode text and the Mistral-7B-v0.3 model for Romanized text. The results also highlight the strong all-around performance of the Llama-3.1-8B model for both scripts. Furthermore, a significant performance disparity exists among closed-source models: Gemini-1.5-pro and DeepSeek excel at Unicode generation, whereas Claude-3.5-Sonnet is superior at handling Romanized text. These results provide an essential guide for practitioners selecting models for Sinhala-specific applications and highlight the critical role of training data in handling script variations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14958v1</guid></item><item><title>[cs updates on arXiv.org] Towards Holistic Modeling for Video Frame Interpolation with Auto-regressive Diffusion Transformers</title><link>https://arxiv.org/abs/2601.14959</link><description>arXiv:2601.14959v1 Announce Type: new 
Abstract: Existing video frame interpolation (VFI) methods often adopt a frame-centric approach, processing videos as independent short segments (e.g., triplets), which leads to temporal inconsistencies and motion artifacts. To overcome this, we propose a holistic, video-centric paradigm named \textbf{L}ocal \textbf{D}iffusion \textbf{F}orcing for \textbf{V}ideo \textbf{F}rame \textbf{I}nterpolation (LDF-VFI). Our framework is built upon an auto-regressive diffusion transformer that models the entire video sequence to ensure long-range temporal coherence. To mitigate error accumulation inherent in auto-regressive generation, we introduce a novel skip-concatenate sampling strategy that effectively maintains temporal stability. Furthermore, LDF-VFI incorporates sparse, local attention and tiled VAE encoding, a combination that not only enables efficient processing of long sequences but also allows generalization to arbitrary spatial resolutions (e.g., 4K) at inference without retraining. An enhanced conditional VAE decoder, which leverages multi-scale features from the input video, further improves reconstruction fidelity. Empirically, LDF-VFI achieves state-of-the-art performance on challenging long-sequence benchmarks, demonstrating superior per-frame quality and temporal consistency, especially in scenes with large motion. The source code is available at https://github.com/xypeng9903/LDF-VFI.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14959v1</guid></item><item><title>[cs updates on arXiv.org] VCNAC: A Variable-Channel Neural Audio Codec for Mono, Stereo, and Surround Sound</title><link>https://arxiv.org/abs/2601.14960</link><description>arXiv:2601.14960v1 Announce Type: new 
Abstract: We present VCNAC, a variable channel neural audio codec. Our approach features a single encoder and decoder parametrization that enables native inference for different channel setups, from mono speech to cinematic 5.1 channel surround audio. Channel compatibility objectives ensure that multi-channel content maintains perceptual quality when decoded to fewer channels. The shared representation enables training of generative language models on a single set of codebooks while supporting inference-time scalability across modalities and channel configurations. Evaluation using objective spatial audio metrics and subjective listening tests demonstrates that our unified approach maintains high reconstruction quality across mono, stereo, and surround audio configurations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14960v1</guid></item><item><title>[cs updates on arXiv.org] Unsupervised Material Fingerprinting: Ultra-fast hyperelastic model discovery from full-field experimental measurements</title><link>https://arxiv.org/abs/2601.14965</link><description>arXiv:2601.14965v1 Announce Type: new 
Abstract: Material Fingerprinting is a lookup table-based strategy to discover material models from experimental measurements, which completely avoids the need to solve an optimization problem. In an offline phase, a comprehensive database of simulated material responses, so-called material fingerprints, is generated for a predefined experimental setup. This database can then be used repeatedly in the online phase to discover material models corresponding to experimentally measured observations. To this end, the experimentally measured fingerprint is compared with all fingerprints in the database to identify the closest match. The primary advantage of this strategy is that it does not require solving a continuous optimization problem. This avoids the associated computational costs as well as issues of ill-posedness caused by local minima in non-convex optimization landscapes. Material Fingerprinting has been successfully demonstrated for supervised datasets consisting of stress-strain pairs, as well as for unsupervised datasets involving full-field displacements and net reaction forces. However, to date, there is no experimental validation for the latter approach which is the objective of this work.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14965v1</guid></item><item><title>[cs updates on arXiv.org] InstructTime++: Time Series Classification with Multimodal Language Modeling via Implicit Feature Enhancement</title><link>https://arxiv.org/abs/2601.14968</link><description>arXiv:2601.14968v1 Announce Type: new 
Abstract: Most existing time series classification methods adopt a discriminative paradigm that maps input sequences directly to one-hot encoded class labels. While effective, this paradigm struggles to incorporate contextual features and fails to capture semantic relationships among classes. To address these limitations, we propose InstructTime, a novel framework that reformulates time series classification as a multimodal generative task. Specifically, continuous numerical sequences, contextual textual features, and task instructions are treated as multimodal inputs, while class labels are generated as textual outputs by tuned language models. To bridge the modality gap, InstructTime introduces a time series discretization module that converts continuous sequences into discrete temporal tokens, together with an alignment projection layer and a generative self-supervised pre-training strategy to enhance cross-modal representation alignment. Building upon this framework, we further propose InstructTime++, which extends InstructTime by incorporating implicit feature modeling to compensate for the limited inductive bias of language models. InstructTime++ leverages specialized toolkits to mine informative implicit patterns from raw time series and contextual inputs, including statistical feature extraction and vision-language-based image captioning, and translates them into textual descriptions for seamless integration. Extensive experiments on multiple benchmark datasets demonstrate the superior performance of InstructTime++.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14968v1</guid></item><item><title>[cs updates on arXiv.org] Fine-Grained Traceability for Transparent ML Pipelines</title><link>https://arxiv.org/abs/2601.14971</link><description>arXiv:2601.14971v1 Announce Type: new 
Abstract: Modern machine learning systems are increasingly realised as multistage pipelines, yet existing transparency mechanisms typically operate at a model level: they describe what a system is and why it behaves as it does, but not how individual data samples are operationally recorded, tracked, and verified as they traverse the pipeline. This absence of verifiable, sample-level traceability leaves practitioners and users unable to determine whether a specific sample was used, when it was processed, or whether the corresponding records remain intact over time. We introduce FG-Trac, a model-agnostic framework that establishes verifiable, fine-grained sample-level traceability throughout machine learning pipelines. FG-Trac defines an explicit mechanism for capturing and verifying sample lifecycle events across preprocessing and training, computes contribution scores explicitly grounded in training checkpoints, and anchors these traces to tamper-evident cryptographic commitments. The framework integrates without modifying model architectures or training objectives, reconstructing complete and auditable data-usage histories with practical computational overhead. Experiments on a canonical convolutional neural network and a multimodal graph learning pipeline demonstrate that FG-Trac preserves predictive performance while enabling machine learning systems to furnish verifiable evidence of how individual samples were used and propagated during model execution.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14971v1</guid></item><item><title>[cs updates on arXiv.org] HumanDiffusion: A Vision-Based Diffusion Trajectory Planner with Human-Conditioned Goals for Search and Rescue UAV</title><link>https://arxiv.org/abs/2601.14973</link><description>arXiv:2601.14973v1 Announce Type: new 
Abstract: Reliable human--robot collaboration in emergency scenarios requires autonomous systems that can detect humans, infer navigation goals, and operate safely in dynamic environments. This paper presents HumanDiffusion, a lightweight image-conditioned diffusion planner that generates human-aware navigation trajectories directly from RGB imagery. The system combines YOLO-11--based human detection with diffusion-driven trajectory generation, enabling a quadrotor to approach a target person and deliver medical assistance without relying on prior maps or computationally intensive planning pipelines. Trajectories are predicted in pixel space, ensuring smooth motion and a consistent safety margin around humans. We evaluate HumanDiffusion in simulation and real-world indoor mock-disaster scenarios. On a 300-sample test set, the model achieves a mean squared error of 0.02 in pixel-space trajectory reconstruction. Real-world experiments demonstrate an overall mission success rate of 80% across accident-response and search-and-locate tasks with partial occlusions. These results indicate that human-conditioned diffusion planning offers a practical and robust solution for human-aware UAV navigation in time-critical assistance settings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14973v1</guid></item><item><title>[cs updates on arXiv.org] Fractional Diffusion on Graphs: Superposition of Laplacian Semigroups and Memory</title><link>https://arxiv.org/abs/2601.14977</link><description>arXiv:2601.14977v1 Announce Type: new 
Abstract: Subdiffusion on graphs is often modeled by time-fractional diffusion equations, yet its structural and dynamical consequences remain unclear. We show that subdiffusive transport on graphs is a memory-driven process generated by a random time change that compresses operational time, produces long-tailed waiting times, and breaks Markovianity while preserving linearity and mass conservation. We prove that Mittag-Leffler graph dynamics admit an exact convex, mass-preserving representation as a superposition of classical heat semigroups evaluated at rescaled times, revealing fractional diffusion as ordinary diffusion acting across multiple intrinsic time scales. This framework uncovers heterogeneous, vertex-dependent memory effects and induces transport biases absent in classical diffusion, including algebraic relaxation, degree-dependent waiting times, and early-time asymmetries between sources and neighbors. These features define a subdiffusive geometry on graphs enabling particles to locally discover global shortest paths while favoring high-degree regions. Finally, we show that time-fractional diffusion arises as a singular limit of multi-rate diffusion.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14977v1</guid></item><item><title>[cs updates on arXiv.org] Unified Multi-Dataset Training for TBPS</title><link>https://arxiv.org/abs/2601.14978</link><description>arXiv:2601.14978v1 Announce Type: new 
Abstract: Text-Based Person Search (TBPS) has seen significant progress with vision-language models (VLMs), yet it remains constrained by limited training data and the fact that VLMs are not inherently pre-trained for pedestrian-centric recognition. Existing TBPS methods therefore rely on dataset-centric fine-tuning to handle distribution shift, resulting in multiple independently trained models for different datasets. While synthetic data can increase the scale needed to fine-tune VLMs, it does not eliminate dataset-specific adaptation. This motivates a fundamental question: can we train a single unified TBPS model across multiple datasets? We show that naive joint training over all datasets remains sub-optimal because current training paradigms do not scale to a large number of unique person identities and are vulnerable to noisy image-text pairs. To address these challenges, we propose Scale-TBPS with two contributions: (i) a noise-aware unified dataset curation strategy that cohesively merges diverse TBPS datasets; and (ii) a scalable discriminative identity learning framework that remains effective under a large number of unique identities. Extensive experiments on CUHK-PEDES, ICFG-PEDES, RSTPReid, IIITD-20K, and UFine6926 demonstrate that a single Scale-TBPS model outperforms dataset-centric optimized models and naive joint training.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14978v1</guid></item><item><title>[cs updates on arXiv.org] Parallel Collaborative ADMM Privacy Computing and Adaptive GPU Acceleration for Distributed Edge Networks</title><link>https://arxiv.org/abs/2601.14980</link><description>arXiv:2601.14980v1 Announce Type: new 
Abstract: Distributed computing has been widely applied in distributed edge networks for reducing the processing burden of high-dimensional data centralization, where a high-dimensional computational task is decomposed into multiple low-dimensional collaborative processing tasks or multiple edge nodes use distributed data to train a global model. However, the computing power of a single-edge node is limited, and collaborative computing will cause information leakage and excessive communication overhead. In this paper, we design a parallel collaborative distributed alternating direction method of multipliers (ADMM) and propose a three-phase parallel collaborative ADMM privacy computing (3P-ADMM-PC2) algorithm for distributed computing in edge networks, where the Paillier homomorphic encryption is utilized to protect data privacy during interactions. Especially, a quantization method is introduced, which maps the real numbers to a positive integer interval without affecting the homomorphic operations. To address the architectural mismatch between large-integer and Graphics Processing Unit (GPU) computing, we transform high-bitwidth computations into low-bitwidth matrix and vector operations. Thus the GPU can be utilized to implement parallel encryption and decryption computations with long keys. Finally, a GPU-accelerated 3P-ADMM-PC2 is proposed to optimize the collaborative computing tasks. Meanwhile, large-scale computational tasks are conducted in network topologies with varying numbers of edge nodes. Experimental results demonstrate that the proposed 3P-ADMM-PC2 has excellent mean square error performance, which is close to that of distributed ADMM without privacy-preserving. Compared to centralized ADMM and distributed ADMM implemented with Central Processing Unit (CPU) computation, the proposed scheme demonstrates a significant speedup ratio.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14980v1</guid></item><item><title>[cs updates on arXiv.org] Interoperable Architecture for Digital Identity Delegation for AI Agents with Blockchain Integration</title><link>https://arxiv.org/abs/2601.14982</link><description>arXiv:2601.14982v1 Announce Type: new 
Abstract: Verifiable delegation in digital identity systems remains unresolved across centralized, federated, and self-sovereign identity (SSI) environments, particularly where both human users and autonomous AI agents must exercise and transfer authority without exposing primary credentials or private keys. We introduce a unified framework that enables bounded, auditable, and least-privilege delegation across heterogeneous identity ecosystems. The framework includes four key elements: Delegation Grants (DGs), first-class authorization artefacts that encode revocable transfers of authority with enforced scope reduction; a Canonical Verification Context (CVC) that normalizes verification requests into a single structured representation independent of protocols or credential formats; a layered reference architecture that separates trust anchoring, credential and proof validation, policy evaluation, and protocol mediation via a Trust Gateway; and an explicit treatment of blockchain anchoring as an optional integrity layer rather than a structural dependency. Together, these elements advance interoperable delegation and auditability and provide a foundation for future standardization, implementation, and integration of autonomous agents into trusted digital identity infrastructures.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14982v1</guid></item><item><title>[cs updates on arXiv.org] Stealthy bias injection attack detection based on Kullback-Leibler divergence in stochastic linear systems</title><link>https://arxiv.org/abs/2601.14984</link><description>arXiv:2601.14984v1 Announce Type: new 
Abstract: This paper studies the design of detection observers against stealthy bias injection attacks in stochastic linear systems under Gaussian noise, considering adversaries that exploit noise and inject crafted bias signals into a subset of sensors in a slow and coordinated manner, thereby achieving malicious objectives while remaining stealthy. To address such attacks, we formulate the observer design as a max-min optimization problem to enhance the detectability of worst-case BIAs, which attain a prescribed attack impact with the least detectability evaluated via Kullback-Leibler divergence. To reduce the computational complexity of the derived non-convex design problem, we consider the detectability of worst-case BIAs at three specific time instants: attack onset, one step after attack occurrence, and the steady state. We prove that the Kalman filter is optimal for maximizing the BIA detectability at the attack onset, regardless of the subset of attacked sensors. For the one-step and steady-state cases, the observer design problems are approximated by bi-convex optimization problems, which can be efficiently solved using alternating optimization and alternating direction method of multipliers. Moreover, more tractable linear matrix inequality relaxations are developed. Finally, the effectiveness of the proposed stealth-aware detection framework is demonstrated through an application to a thermal system.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14984v1</guid></item><item><title>[cs updates on arXiv.org] Random Gilbert-Varshamov Codes for Joint Source-Channel Coding</title><link>https://arxiv.org/abs/2601.14987</link><description>arXiv:2601.14987v1 Announce Type: new 
Abstract: We propose a random coding technique for joint source-channel coding of discrete memoryless sources and channels. The approach builds on the random Gilbert-Varshamov code construction of Somekh-Baruch et al. and extends it to the joint source-channel setting. We show that the resulting ensemble attains the maximum of the random-coding and expurgated error exponents.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14987v1</guid></item><item><title>[cs updates on arXiv.org] Obscuring Data Contamination Through Translation: Evidence from Arabic Corpora</title><link>https://arxiv.org/abs/2601.14994</link><description>arXiv:2601.14994v1 Announce Type: new 
Abstract: Data contamination undermines the validity of Large Language Model evaluation by enabling models to rely on memorized benchmark content rather than true generalization. While prior work has proposed contamination detection methods, these approaches are largely limited to English benchmarks, leaving multilingual contamination poorly understood. In this work, we investigate contamination dynamics in multilingual settings by fine-tuning several open-weight LLMs on varying proportions of Arabic datasets and evaluating them on original English benchmarks. To detect memorization, we extend the Tested Slot Guessing method with a choice-reordering strategy and incorporate Min-K% probability analysis, capturing both behavioral and distributional contamination signals.
  Our results show that translation into Arabic suppresses conventional contamination indicators, yet models still benefit from exposure to contaminated data, particularly those with stronger Arabic capabilities. This effect is consistently reflected in rising Mink% scores and increased cross-lingual answer consistency as contamination levels grow. To address this blind spot, we propose Translation-Aware Contamination Detection, which identifies contamination by comparing signals across multiple translated benchmark variants rather than English alone. The Translation-Aware Contamination Detection reliably exposes contamination even when English-only methods fail. Together, our findings highlight the need for multilingual, translation-aware evaluation pipelines to ensure fair, transparent, and reproducible assessment of LLMs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14994v1</guid></item><item><title>[cs updates on arXiv.org] On the Effectiveness of Mempool-based Transaction Auditing</title><link>https://arxiv.org/abs/2601.14996</link><description>arXiv:2601.14996v1 Announce Type: new 
Abstract: While the literature features a number of proposals to defend against transaction manipulation attacks, existing proposals are still not integrated within large blockchains, such as Bitcoin, Ethereum, and Cardano. Instead, the user community opted to rely on more practical but ad-hoc solutions (such as Mempool.space) that aim at detecting censorship and transaction displacement attacks by auditing discrepancies in the mempools of so-called observers.
  In this paper, we precisely analyze, for the first time, the interplay between mempool auditing and the ability to detect censorship and transaction displacement attacks by malicious miners in Bitcoin and Ethereum. Our analysis shows that mempool auditing can result in mis-accusations against miners with a probability larger than 25% in some settings. On a positive note, however, we show that mempool auditing schemes can successfully audit the execution of any two transactions (with an overwhelming probability of 99.9%) if they are consistently received by all observers and sent at least 30 seconds apart from each other. As a direct consequence, our findings show, for the first time, that batch-order fair-ordering schemes can offer only strong fairness guarantees for a limited subset of transactions in real-world deployments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14996v1</guid></item><item><title>[cs updates on arXiv.org] Graph-Based Adaptive Planning for Coordinated Dual-Arm Robotic Disassembly of Electronic Devices (eGRAP)</title><link>https://arxiv.org/abs/2601.14998</link><description>arXiv:2601.14998v1 Announce Type: new 
Abstract: E-waste is growing rapidly while recycling rates remain low. We propose an electronic-device Graph-based Adaptive Planning (eGRAP) that integrates vision, dynamic planning, and dual-arm execution for autonomous disassembly. A camera-equipped arm identifies parts and estimates their poses, and a directed graph encodes which parts must be removed first. A scheduler uses topological ordering of this graph to select valid next steps and assign them to two robot arms, allowing independent tasks to run in parallel. One arm carries a screwdriver (with an eye-in-hand depth camera) and the other holds or handles components. We demonstrate eGRAP on 3.5in hard drives: as parts are unscrewed and removed, the system updates its graph and plan online. Experiments show consistent full disassembly of each HDD, with high success rates and efficient cycle times, illustrating the method's ability to adaptively coordinate dual-arm tasks in real time.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14998v1</guid></item><item><title>[cs updates on arXiv.org] Lineup Regularized Adjusted Plus-Minus (L-RAPM): Basketball Lineup Ratings with Informed Priors</title><link>https://arxiv.org/abs/2601.15000</link><description>arXiv:2601.15000v1 Announce Type: new 
Abstract: Identifying combinations of players (that is, lineups) in basketball - and other sports - that perform well when they play together is one of the most important tasks in sports analytics. One of the main challenges associated with this task is the frequent substitutions that occur during a game, which results in highly sparse data. In particular, a National Basketball Association (NBA) team will use more than 600 lineups during a season, which translates to an average lineup having seen the court in approximately 25-30 possessions. Inevitably, any statistics that one collects for these lineups are going to be noisy, with low predictive value. Yet, there is no existing work (in the public at least) that addresses this problem. In this work, we propose a regression-based approach that controls for the opposition faced by each lineup, while it also utilizes information about the players making up the lineups. Our experiments show that L-RAPM provides improved predictive power than the currently used baseline, and this improvement increases as the sample size for the lineups gets smaller.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15000v1</guid></item><item><title>[cs updates on arXiv.org] RadixMLP -- Intra-batch Deduplication for Causal Transformers</title><link>https://arxiv.org/abs/2601.15013</link><description>arXiv:2601.15013v1 Announce Type: new 
Abstract: Batch inference workloads for causal transformer models frequently process sequences that share common prefixes, such as system prompts, few-shot examples, or shared queries. Standard inference engines treat each sequence independently, redundantly recomputing identical MLP activations for every copy of the shared prefix. We introduce RadixMLP, a technique that exploits the position-wise nature of MLPs, LayerNorms, linear projections, and embeddings to eliminate this redundancy. RadixMLP dynamically maps batches to a prefix trie, gathering shared segments into a compressed representation for position-wise computation and scattering results back only at attention boundaries. RadixMLP is stateless and operates within a single forward pass. In end-to-end serving benchmarks on MS~MARCO v1.1 with Qwen3 models (0.6B to 8B parameters), RadixMLP achieves 1.44-1.59$\times$ speedups in realistic reranking workloads, with up to $5\times$ speedups on synthetic benchmarks with longer shared prefixes. Our code is available at https://github.com/michaelfeil/radix-mlp.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15013v1</guid></item><item><title>[cs updates on arXiv.org] Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control</title><link>https://arxiv.org/abs/2601.15015</link><description>arXiv:2601.15015v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has shown promising results in active flow control (AFC), yet progress in the field remains difficult to assess as existing studies rely on heterogeneous observation and actuation schemes, numerical setups, and evaluation protocols. Current AFC benchmarks attempt to address these issues but heavily rely on external computational fluid dynamics (CFD) solvers, are not fully differentiable, and provide limited 3D and multi-agent support. To overcome these limitations, we introduce FluidGym, the first standalone, fully differentiable benchmark suite for RL in AFC. Built entirely in PyTorch on top of the GPU-accelerated PICT solver, FluidGym runs in a single Python stack, requires no external CFD software, and provides standardized evaluation protocols. We present baseline results with PPO and SAC and release all environments, datasets, and trained models as public resources. FluidGym enables systematic comparison of control methods, establishes a scalable foundation for future research in learning-based flow control, and is available at https://github.com/safe-autonomous-systems/fluidgym.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15015v1</guid></item><item><title>[cs updates on arXiv.org] LiViBench: An Omnimodal Benchmark for Interactive Livestream Video Understanding</title><link>https://arxiv.org/abs/2601.15016</link><description>arXiv:2601.15016v1 Announce Type: new 
Abstract: The development of multimodal large language models (MLLMs) has advanced general video understanding. However, existing video evaluation benchmarks primarily focus on non-interactive videos, such as movies and recordings. To fill this gap, this paper proposes the first omnimodal benchmark for interactive livestream videos, LiViBench. It features a diverse set of 24 tasks, highlighting the perceptual, reasoning, and livestream-specific challenges. To efficiently construct the dataset, we design a standardized semi-automatic annotation workflow that incorporates the human-in-the-loop at multiple stages. The workflow leverages multiple MLLMs to form a multi-agent system for comprehensive video description and uses a seed-question-driven method to construct high-quality annotations. All interactive videos in the benchmark include audio, speech, and real-time comments modalities. To enhance models' understanding of interactive videos, we design tailored two-stage instruction-tuning and propose a Video-to-Comment Retrieval (VCR) module to improve the model's ability to utilize real-time comments. Based on these advancements, we develop LiVi-LLM-7B, an MLLM with enhanced knowledge of interactive livestreams. Experiments show that our model outperforms larger open-source models with up to 72B parameters, narrows the gap with leading proprietary models on LiViBench, and achieves enhanced performance on general video benchmarks, including VideoMME, LongVideoBench, MLVU, and VideoEval-Pro.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15016v1</guid></item><item><title>[cs updates on arXiv.org] SpatialV2A: Visual-Guided High-fidelity Spatial Audio Generation</title><link>https://arxiv.org/abs/2601.15017</link><description>arXiv:2601.15017v1 Announce Type: new 
Abstract: While video-to-audio generation has achieved remarkable progress in semantic and temporal alignment, most existing studies focus solely on these aspects, paying limited attention to the spatial perception and immersive quality of the synthesized audio. This limitation stems largely from current models' reliance on mono audio datasets, which lack the binaural spatial information needed to learn visual-to-spatial audio mappings. To address this gap, we introduce two key contributions: we construct BinauralVGGSound, the first large-scale video-binaural audio dataset designed to support spatially aware video-to-audio generation; and we propose a end-to-end spatial audio generation framework guided by visual cues, which explicitly models spatial features. Our framework incorporates a visual-guided audio spatialization module that ensures the generated audio exhibits realistic spatial attributes and layered spatial depth while maintaining semantic and temporal alignment. Experiments show that our approach substantially outperforms state-of-the-art models in spatial fidelity and delivers a more immersive auditory experience, without sacrificing temporal or semantic consistency. All datasets, code, and model checkpoints will be publicly released to facilitate future research.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15017v1</guid></item><item><title>[cs updates on arXiv.org] Risk Estimation for Automated Driving</title><link>https://arxiv.org/abs/2601.15018</link><description>arXiv:2601.15018v1 Announce Type: new 
Abstract: Safety is a central requirement for automated vehicles. As such, the assessment of risk in automated driving is key in supporting both motion planning technologies and safety evaluation. In automated driving, risk is characterized by two aspects. The first aspect is the uncertainty on the state estimates of other road participants by an automated vehicle. The second aspect is the severity of a collision event with said traffic participants. Here, the uncertainty aspect typically causes the risk to be non-zero for near-collision events. This makes risk particularly useful for automated vehicle motion planning. Namely, constraining or minimizing risk naturally navigates the automated vehicle around traffic participants while keeping a safety distance based on the level of uncertainty and the potential severity of the impending collision. Existing approaches to calculate the risk either resort to empirical modeling or severe approximations, and, hence, lack generalizability and accuracy. In this paper, we combine recent advances in collision probability estimation with the concept of collision severity to develop a general method for accurate risk estimation. The proposed method allows us to assign individual severity functions for different collision constellations, such as, e.g., frontal or side collisions. Furthermore, we show that the proposed approach is computationally efficient, which is beneficial, e.g., in real-time motion planning applications. The programming code for an exemplary implementation of Gaussian uncertainties is also provided.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15018v1</guid></item><item><title>[cs updates on arXiv.org] Mixture-of-Experts Models in Vision: Routing, Optimization, and Generalization</title><link>https://arxiv.org/abs/2601.15021</link><description>arXiv:2601.15021v1 Announce Type: new 
Abstract: Mixture-of-Experts (MoE) architectures enable conditional computation by routing inputs to multiple expert subnetworks and are often motivated as a mechanism for scaling large language models. In this project, we instead study MoE behavior in an image classification setting, focusing on predictive performance, expert utilization, and generalization. We compare dense, SoftMoE, and SparseMoE classifier heads on the CIFAR10 dataset under comparable model capacity. Both MoE variants achieve slightly higher validation accuracy than the dense baseline while maintaining balanced expert utilization through regularization, avoiding expert collapse. To analyze generalization, we compute Hessian-based sharpness metrics at convergence, including the largest eigenvalue and trace of the loss Hessian, evaluated on both training and test data. We find that SoftMoE exhibits higher sharpness by these metrics, while Dense and SparseMoE lie in a similar curvature regime, despite all models achieving comparable generalization performance. Complementary loss surface perturbation analyses reveal qualitative differences in non-local behavior under finite parameter perturbations between dense and MoE models, which help contextualize curvature-based measurements without directly explaining validation accuracy. We further evaluate empirical inference efficiency and show that naively implemented conditional routing does not yield inference speedups on modern hardware at this scale, highlighting the gap between theoretical and realized efficiency in sparse MoE models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15021v1</guid></item><item><title>[cs updates on arXiv.org] ExPrIS: Knowledge-Level Expectations as Priors for Object Interpretation from Sensor Data</title><link>https://arxiv.org/abs/2601.15025</link><description>arXiv:2601.15025v1 Announce Type: new 
Abstract: While deep learning has significantly advanced robotic object recognition, purely data-driven approaches often lack semantic consistency and fail to leverage valuable, pre-existing knowledge about the environment. This report presents the ExPrIS project, which addresses this challenge by investigating how knowledge-level expectations can serve as to improve object interpretation from sensor data. Our approach is based on the incremental construction of a 3D Semantic Scene Graph (3DSSG). We integrate expectations from two sources: contextual priors from past observations and semantic knowledge from external graphs like ConceptNet. These are embedded into a heterogeneous Graph Neural Network (GNN) to create an expectation-biased inference process. This method moves beyond static, frame-by-frame analysis to enhance the robustness and consistency of scene understanding over time. The report details this architecture, its evaluation, and outlines its planned integration on a mobile robotic platform.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15025v1</guid></item><item><title>[cs updates on arXiv.org] Information mechanics: conservation and exchange</title><link>https://arxiv.org/abs/2601.15028</link><description>arXiv:2601.15028v1 Announce Type: new 
Abstract: Inference and learning are commonly cast in terms of optimisation, yet the fundamental constraints governing uncertainty reduction remain unclear. This work presents a first-principles framework inherent to Bayesian updating, termed information mechanics (infomechanics). Any pointwise reduction in posterior surprisal is exactly balanced by information gained from data, independently of algorithms, dynamics, or implementation. Imposing additivity, symmetry, and robustness collapses the freedom of this identity to only two independent conservation relations. One governs the global redistribution of uncertainty and recovers Shannon entropy. The other captures a complementary local geometric component, formalised as Fisher information. Together, these conserved quantities motivate a non-additive state function, the information potential $\Phi$, which isolates structural degrees of freedom beyond entropy while remaining invariant under reparametrisation. $\Phi$ quantifies local sharpness and ruggedness in posterior beliefs and vanishes uniquely for isotropic Gaussian distributions. In a low-temperature regime, $\Phi$ scales logarithmically with the effective number of local optima, linking information geometry to computational complexity. This formalises an information-computation exchange, whereby information acquisition reshapes the inference landscape and reduces computational demands. By separating invariant informational constraints from inference mechanisms, this framework provides a unified, algorithm-independent foundation for inference, learning, and computation across biological and artificial systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15028v1</guid></item><item><title>[cs updates on arXiv.org] Emergent, not Immanent: A Baradian Reading of Explainable AI</title><link>https://arxiv.org/abs/2601.15029</link><description>arXiv:2601.15029v1 Announce Type: new 
Abstract: Explainable AI (XAI) is frequently positioned as a technical problem of revealing the inner workings of an AI model. This position is affected by unexamined onto-epistemological assumptions: meaning is treated as immanent to the model, the explainer is positioned outside the system, and a causal structure is presumed recoverable through computational techniques. In this paper, we draw on Barad's agential realism to develop an alternative onto-epistemology of XAI. We propose that interpretations are material-discursive performances that emerge from situated entanglements of the AI model with humans, context, and the interpretative apparatus. To develop this position, we read a comprehensive set of XAI methods through agential realism and reveal the assumptions and limitations that underpin several of these methods. We then articulate the framework's ethical dimension and propose design directions for XAI interfaces that support emergent interpretation, using a speculative text-to-music interface as a case study.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15029v1</guid></item><item><title>[cs updates on arXiv.org] Visual and Cognitive Demands of a Large Language Model-Powered In-vehicle Conversational Agent</title><link>https://arxiv.org/abs/2601.15034</link><description>arXiv:2601.15034v1 Announce Type: new 
Abstract: Driver distraction remains a leading contributor to motor vehicle crashes, necessitating rigorous evaluation of new in-vehicle technologies. This study assessed the visual and cognitive demands associated with an advanced Large Language Model (LLM) conversational agent (Gemini Live) during on-road driving, comparing it against handsfree phone calls, visual turn-by-turn guidance (low load baseline), and the Operation Span (OSPAN) task (high load anchor). Thirty-two licensed drivers completed five secondary tasks while visual and cognitive demands were measured using the Detection Response Task (DRT) for cognitive load, eye-tracking for visual attention, and subjective workload ratings. Results indicated that Gemini Live interactions (both single-turn and multi-turn) and hands-free phone calls shared similar levels of cognitive load, between that of visual turn-by-turn guidance and OSPAN. Exploratory analysis showed that cognitive load remained stable across extended multi-turn conversations. All tasks maintained mean glance durations well below the well-established 2-second safety threshold, confirming low visual demand. Furthermore, drivers consistently dedicated longer glances to the roadway between brief off-road glances toward the device during task completion, particularly during voice-based interactions, rendering longer total-eyes-off-road time findings less consequential. Subjective ratings mirrored objective data, with participants reporting low effort, demands, and perceived distraction for Gemini Live. These findings demonstrate that advanced LLM conversational agents, when implemented via voice interfaces, impose cognitive and visual demands comparable to established, low-risk hands-free benchmarks, supporting their safe deployment in the driving environment.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15034v1</guid></item><item><title>[cs updates on arXiv.org] Factorizable joint shift revisited</title><link>https://arxiv.org/abs/2601.15036</link><description>arXiv:2601.15036v1 Announce Type: new 
Abstract: Factorizable joint shift (FJS) was proposed as a type of distribution shift (or dataset shift) that comprises both covariate and label shift. Recently, it has been observed that FJS actually arises from consecutive label and covariate (or vice versa) shifts. Research into FJS so far has been confined to the case of categorical label spaces. We propose a framework for analysing distribution shift in the case of general label spaces, thus covering both classification and regression models. Based on the framework, we generalise existing results on FJS to general label spaces and propose a related extension of the expectation maximisation (EM) algorithm for class prior probabilities. We also take a fresh look at generalized label shift (GLS) in the case of general label spaces.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15036v1</guid></item><item><title>[cs updates on arXiv.org] Knowledge Restoration-driven Prompt Optimization: Unlocking LLM Potential for Open-Domain Relational Triplet Extraction</title><link>https://arxiv.org/abs/2601.15037</link><description>arXiv:2601.15037v1 Announce Type: new 
Abstract: Open-domain Relational Triplet Extraction (ORTE) is the foundation for mining structured knowledge without predefined schemas. Despite the impressive in-context learning capabilities of Large Language Models (LLMs), existing methods are hindered by their reliance on static, heuristic-driven prompting strategies. Due to the lack of reflection mechanisms required to internalize erroneous signals, these methods exhibit vulnerability in semantic ambiguity, often making erroneous extraction patterns permanent. To address this bottleneck, we propose a Knowledge Reconstruction-driven Prompt Optimization (KRPO) framework to assist LLMs in continuously improving their extraction capabilities for complex ORTE task flows. Specifically, we design a self-evaluation mechanism based on knowledge restoration, which provides intrinsic feedback signals by projecting structured triplets into semantic consistency scores. Subsequently, we propose a prompt optimizer based on a textual gradient that can internalize historical experiences to iteratively optimize prompts, which can better guide LLMs to handle subsequent extraction tasks. Furthermore, to alleviate relation redundancy, we design a relation canonicalization memory that collects representative relations and provides semantically distinct schemas for the triplets. Extensive experiments across three datasets show that KRPO significantly outperforms strong baselines in the extraction F1 score.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15037v1</guid></item><item><title>[cs updates on arXiv.org] A Curriculum-Based Deep Reinforcement Learning Framework for the Electric Vehicle Routing Problem</title><link>https://arxiv.org/abs/2601.15038</link><description>arXiv:2601.15038v1 Announce Type: new 
Abstract: The electric vehicle routing problem with time windows (EVRPTW) is a complex optimization problem in sustainable logistics, where routing decisions must minimize total travel distance, fleet size, and battery usage while satisfying strict customer time constraints. Although deep reinforcement learning (DRL) has shown great potential as an alternative to classical heuristics and exact solvers, existing DRL models often struggle to maintain training stability-failing to converge or generalize when constraints are dense. In this study, we propose a curriculum-based deep reinforcement learning (CB-DRL) framework designed to resolve this instability. The framework utilizes a structured three-phase curriculum that gradually increases problem complexity: the agent first learns distance and fleet optimization (Phase A), then battery management (Phase B), and finally the full EVRPTW (Phase C). To ensure stable learning across phases, the framework employs a modified proximal policy optimization algorithm with phase-specific hyperparameters, value and advantage clipping, and adaptive learning-rate scheduling. The policy network is built upon a heterogeneous graph attention encoder enhanced by global-local attention and feature-wise linear modulation. This specialized architecture explicitly captures the distinct properties of depots, customers, and charging stations. Trained exclusively on small instances with N=10 customers, the model demonstrates robust generalization to unseen instances ranging from N=5 to N=100, significantly outperforming standard baselines on medium-scale problems. Experimental results confirm that this curriculum-guided approach achieves high feasibility rates and competitive solution quality on out-of-distribution instances where standard DRL baselines fail, effectively bridging the gap between neural speed and operational reliability.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15038v1</guid></item><item><title>[cs updates on arXiv.org] CADGrasp: Learning Contact and Collision Aware General Dexterous Grasping in Cluttered Scenes</title><link>https://arxiv.org/abs/2601.15039</link><description>arXiv:2601.15039v1 Announce Type: new 
Abstract: Dexterous grasping in cluttered environments presents substantial challenges due to the high degrees of freedom of dexterous hands, occlusion, and potential collisions arising from diverse object geometries and complex layouts. To address these challenges, we propose CADGrasp, a two-stage algorithm for general dexterous grasping using single-view point cloud inputs. In the first stage, we predict sparse IBS, a scene-decoupled, contact- and collision-aware representation, as the optimization target. Sparse IBS compactly encodes the geometric and contact relationships between the dexterous hand and the scene, enabling stable and collision-free dexterous grasp pose optimization. To enhance the prediction of this high-dimensional representation, we introduce an occupancy-diffusion model with voxel-level conditional guidance and force closure score filtering. In the second stage, we develop several energy functions and ranking strategies for optimization based on sparse IBS to generate high-quality dexterous grasp poses. Extensive experiments in both simulated and real-world settings validate the effectiveness of our approach, demonstrating its capability to mitigate collisions while maintaining a high grasp success rate across diverse objects and complex scenes.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15039v1</guid></item><item><title>[cs updates on arXiv.org] Electrical Design of a Clean Offshore Heat and Power (CleanOFF) Hub</title><link>https://arxiv.org/abs/2601.15040</link><description>arXiv:2601.15040v1 Announce Type: new 
Abstract: This paper presents an innovative offshore solution where oil &amp; gas platform clusters are powered by a wind farm and a hydrogen hub. The results show a feasible off-grid design as an alternative to conventional electrification solutions. To address the challenges of design and operation of such a system, a power system model of the equipment and control was developed in a power system simulator called Process Power Simulator (PPSim). Power fluctuations in the wind farm are modelled using a state-of-the-art method encompassing turbulence and wakes. Various operation scenarios were used to evaluate the system design and find the right equipment size. An expensive component to over dimension is the battery energy storage system (BESS). The BESS power rating and energy capacity were found by running a combination of scenarios with extreme and natural wind variations, and contingencies. The control strategy and ramp rates of electrolyzers have significant impact on both system performance and design. A ramp rate in the order of seconds as opposed to minutes will decrease the required BESS size by 60-70%. Choosing synchronized control of the electrolyzers can further reduce the BESS size by 15-20%. The simulations also revealed challenges to achieve self-sufficiency of hydrogen and potential design improvements are suggested.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15040v1</guid></item><item><title>[cs updates on arXiv.org] HyperNet-Adaptation for Diffusion-Based Test Case Generation</title><link>https://arxiv.org/abs/2601.15041</link><description>arXiv:2601.15041v1 Announce Type: new 
Abstract: The increasing deployment of deep learning systems requires systematic evaluation of their reliability in real-world scenarios. Traditional gradient-based adversarial attacks introduce small perturbations that rarely correspond to realistic failures and mainly assess robustness rather than functional behavior. Generative test generation methods offer an alternative but are often limited to simple datasets or constrained input domains. Although diffusion models enable high-fidelity image synthesis, their computational cost and limited controllability restrict their applicability to large-scale testing. We present HyNeA, a generative testing method that enables direct and efficient control over diffusion-based generation. HyNeA provides dataset-free controllability through hypernetworks, allowing targeted manipulation of the generative process without relying on architecture-specific conditioning mechanisms or dataset-driven adaptations such as fine-tuning. HyNeA employs a distinct training strategy that supports instance-level tuning to identify failure-inducing test cases without requiring datasets that explicitly contain examples of similar failures. This approach enables the targeted generation of realistic failure cases at substantially lower computational cost than search-based methods. Experimental results show that HyNeA improves controllability and test diversity compared to existing generative test generators and generalizes to domains where failure-labeled training data is unavailable.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15041v1</guid></item><item><title>[cs updates on arXiv.org] Federated Transformer-GNN for Privacy-Preserving Brain Tumor Localization with Modality-Level Explainability</title><link>https://arxiv.org/abs/2601.15042</link><description>arXiv:2601.15042v1 Announce Type: new 
Abstract: Deep learning models for brain tumor analysis require large and diverse datasets that are often siloed across healthcare institutions due to privacy regulations. We present a federated learning framework for brain tumor localization that enables multi-institutional collaboration without sharing sensitive patient data. Our method extends a hybrid Transformer-Graph Neural Network architecture derived from prior decoder-free supervoxel GNNs and is deployed within CAFEIN\textsuperscript{\textregistered}, CERN's federated learning platform designed for healthcare environments. We provide an explainability analysis through Transformer attention mechanisms that reveals which MRI modalities drive the model predictions. Experiments on the BraTS dataset demonstrate a key finding: while isolated training on individual client data triggers early stopping well before reaching full training capacity, federated learning enables continued model improvement by leveraging distributed data, ultimately matching centralized performance. This result provides strong justification for federated learning when dealing with complex tasks and high-dimensional input data, as aggregating knowledge from multiple institutions significantly benefits the learning process. Our explainability analysis, validated through rigorous statistical testing on the full test set (paired t-tests with Bonferroni correction), reveals that deeper network layers significantly increase attention to T2 and FLAIR modalities ($p&lt;0.001$, Cohen's $d$=1.50), aligning with clinical practice.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15042v1</guid></item><item><title>[cs updates on arXiv.org] Game-Theoretic Lens on LLM-based Multi-Agent Systems</title><link>https://arxiv.org/abs/2601.15047</link><description>arXiv:2601.15047v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated strong reasoning, planning, and communication abilities, enabling them to operate as autonomous agents in open environments. While single-agent systems remain limited in adaptability and coordination, recent progress has shifted attention toward multi-agent systems (MAS) composed of interacting LLMs that pursue cooperative, competitive, or mixed objectives. This emerging paradigm provides a powerful testbed for studying social dynamics and strategic behaviors among intelligent agents. However, current research remains fragmented and lacks a unifying theoretical foundation. To address this gap, we present a comprehensive survey of LLM-based multi-agent systems through a game-theoretic lens. By organizing existing studies around the four key elements of game theory: players, strategies, payoffs, and information, we establish a systematic framework for understanding, comparing, and guiding future research on the design and analysis of LLM-based MAS.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15047v1</guid></item><item><title>[cs updates on arXiv.org] Towards Standardizing OTFS: A Candidate Waveform for Next-Generation Wireless Networks</title><link>https://arxiv.org/abs/2601.15048</link><description>arXiv:2601.15048v1 Announce Type: new 
Abstract: The standardization of the sixth-generation (6G) has recently commenced to address the rapidly growing demands for enhanced wireless network services. Nevertheless, existing wireless systems, particularly at the physical layer waveform level, remain inadequate for achieving the ambitious key performance indicators (KPIs) envisioned for 6G. Specifically, orthogonal frequency division multiplexing (OFDM), the widely adopted waveform in fifth-generation new radio (5G-NR) networks, suffers from inherent limitations in satisfying these stringent requirements. In practice, OFDM can experience severe inter-carrier interference (ICI), resulting in a pronounced data rate error floor caused by high Doppler shifts. Additionally, the repetitive usage of cyclic prefixes (CPs), intended to combat multipath delays, results in significant spectral inefficiency. These fundamental drawbacks pose critical obstacles to fulfilling 6G performance objectives. Orthogonal time frequency space (OTFS) modulation has recently emerged as a promising waveform candidate, addressing the aforementioned challenges by exploiting the unique characteristics of the delay-Doppler (DD) domain channel. Unlike OFDM, OTFS is inherently resilient to channel distortions induced by delay and Doppler effects, while remaining sensitive to time and frequency shifts. Such intrinsic properties are instrumental in enabling OTFS, with joint communication and sensing capabilities, to embrace, rather than combat, dynamic channel conditions. Motivated by these compelling advantages, this article investigates the feasibility and practical implementation of OTFS modulation leveraging the current OFDM-based wireless systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15048v1</guid></item><item><title>[cs updates on arXiv.org] Deep Leakage with Generative Flow Matching Denoiser</title><link>https://arxiv.org/abs/2601.15049</link><description>arXiv:2601.15049v1 Announce Type: new 
Abstract: Federated Learning (FL) has emerged as a powerful paradigm for decentralized model training, yet it remains vulnerable to deep leakage (DL) attacks that reconstruct private client data from shared model updates. While prior DL methods have demonstrated varying levels of success, they often suffer from instability, limited fidelity, or poor robustness under realistic FL settings. We introduce a new DL attack that integrates a generative Flow Matching (FM) prior into the reconstruction process. By guiding optimization toward the distribution of realistic images (represented by a flow matching foundation model), our method enhances reconstruction fidelity without requiring knowledge of the private data. Extensive experiments on multiple datasets and target models demonstrate that our approach consistently outperforms state-of-the-art attacks across pixel-level, perceptual, and feature-based similarity metrics. Crucially, the method remains effective across different training epochs, larger client batch sizes, and under common defenses such as noise injection, clipping, and sparsification. Our findings call for the development of new defense strategies that explicitly account for adversaries equipped with powerful generative priors.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15049v1</guid></item><item><title>[cs updates on arXiv.org] \textsc{LogicScore}: Fine-grained Logic Evaluation of Conciseness, Completeness, and Determinateness in Attributed Question Answering</title><link>https://arxiv.org/abs/2601.15050</link><description>arXiv:2601.15050v1 Announce Type: new 
Abstract: Current evaluation methods for Attributed Question Answering (AQA) suffer from \textit{attribution myopia}: they emphasize verification of isolated statements and their attributions but overlook the global logical integrity of long-form answers. Consequently, Large Language Models (LLMs) often produce factually grounded yet logically incoherent responses with elusive deductive gaps. To mitigate this limitation, we present \textsc{LogicScore}, a unified evaluation framework that shifts the paradigm from local assessment to global reasoning scrutiny. Grounded in Horn Rules, our approach integrates a backward verification mechanism to systematically evaluate three key reasoning dimensions: \textit{Completeness} (logically sound deduction), \textit{Conciseness} (non-redundancy), and \textit{Determinateness} (consistent answer entailment). Extensive experiments across three multi-hop QA datasets (HotpotQA, MusiQue, and 2WikiMultiHopQA) and over 20 LLMs (including GPT-5, Gemini-3-Pro, LLaMA3, and task-specific tuned models) reveal a critical capability gap: leading models often achieve high attribution scores (e.g., 92.85\% precision for Gemini-3 Pro) but struggle with global reasoning quality (e.g., 35.11\% Conciseness for Gemini-3 Pro). Our work establishes a robust standard for logical evaluation, highlighting the need to prioritize reasoning coherence alongside factual grounding in LLM development. Codes are available at: https://github.com/zhichaoyan11/LogicScore.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15050v1</guid></item><item><title>[cs updates on arXiv.org] SpooFL: Spoofing Federated Learning</title><link>https://arxiv.org/abs/2601.15055</link><description>arXiv:2601.15055v1 Announce Type: new 
Abstract: Traditional defenses against Deep Leakage (DL) attacks in Federated Learning (FL) primarily focus on obfuscation, introducing noise, transformations or encryption to degrade an attacker's ability to reconstruct private data. While effective to some extent, these methods often still leak high-level information such as class distributions or feature representations, and are frequently broken by increasingly powerful denoising attacks. We propose a fundamentally different perspective on FL defense: framing it as a spoofing problem.We introduce SpooFL (Figure 1), a spoofing-based defense that deceives attackers into believing they have recovered the true training data, while actually providing convincing but entirely synthetic samples from an unrelated task. Unlike prior synthetic-data defenses that share classes or distributions with the private data and thus still leak semantic information, SpooFL uses a state-of-the-art generative model trained on an external dataset with no class overlap. As a result, attackers are misled into recovering plausible yet completely irrelevant samples, preventing meaningful data leakage while preserving FL training integrity. We implement the first example of such a spoofing defense, and evaluate our method against state-of-the-art DL defenses and demonstrate that it successfully misdirects attackers without compromising model performance significantly.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15055v1</guid></item><item><title>[cs updates on arXiv.org] Systematic Evaluation of Hip Exoskeleton Assistance Parameters for Enhancing Gait Stability During Ground Slip Perturbations</title><link>https://arxiv.org/abs/2601.15056</link><description>arXiv:2601.15056v1 Announce Type: new 
Abstract: Falls are the leading cause of injury related hospitalization and mortality among older adults. Consequently, mitigating age-related declines in gait stability and reducing fall risk during walking is a critical goal for assistive devices. Lower-limb exoskeletons have the potential to support users in maintaining stability during walking. However, most exoskeleton controllers are optimized to reduce the energetic cost of walking rather than to improve stability. While some studies report stability benefits with assistance, the effects of specific parameters, such as assistance magnitude and duration, remain unexplored. To address this gap, we systematically modulated the magnitude and duration of torque provided by a bilateral hip exoskeleton during slip perturbations in eight healthy adults, quantifying stability using whole-body angular momentum (WBAM). WBAM responses were governed by a significant interaction between assistance magnitude and duration, with duration determining whether exoskeleton assistance was stabilizing or destabilizing relative to not wearing the exoskeleton device. Compared to an existing energy-optimized controller, experimentally identified stability-optimal parameters reduced WBAM range by 25.7% on average. Notably, substantial inter-subject variability was observed in the parameter combinations that minimized WBAM during perturbations. We found that optimizing exoskeleton assistance for energetic outcomes alone is insufficient for improving reactive stability during gait perturbations. Stability-focused exoskeleton control should prioritize temporal assistance parameters and include user-specific personalization. This study represents an important step toward personalized, stability-focused exoskeleton control, with direct implications for improving stability and reducing fall risk in older adults.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15056v1</guid></item><item><title>[cs updates on arXiv.org] The Responsibility Vacuum: Organizational Failure in Scaled Agent Systems</title><link>https://arxiv.org/abs/2601.15059</link><description>arXiv:2601.15059v1 Announce Type: new 
Abstract: Modern CI/CD pipelines integrating agent-generated code exhibit a structural failure in responsibility attribution. Decisions are executed through formally correct approval processes, yet no entity possesses both the authority to approve those decisions and the epistemic capacity to meaningfully understand their basis.
  We define this condition as responsibility vacuum: a state in which decisions occur, but responsibility cannot be attributed because authority and verification capacity do not coincide. We show that this is not a process deviation or technical defect, but a structural property of deployments where decision generation throughput exceeds bounded human verification capacity.
  We identify a scaling limit under standard deployment assumptions, including parallel agent generation, CI-based validation, and individualized human approval gates. Beyond a throughput threshold, verification ceases to function as a decision criterion and is replaced by ritualized approval based on proxy signals. Personalized responsibility becomes structurally unattainable in this regime.
  We further characterize a CI amplification dynamic, whereby increasing automated validation coverage raises proxy signal density without restoring human capacity. Under fixed time and attention constraints, this accelerates cognitive offloading in the broad sense and widens the gap between formal approval and epistemic understanding. Additional automation therefore amplifies, rather than mitigates, the responsibility vacuum.
  We conclude that unless organizations explicitly redesign decision boundaries or reassign responsibility away from individual decisions toward batch- or system-level ownership, responsibility vacuum remains an invisible but persistent failure mode in scaled agent deployments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15059v1</guid></item><item><title>[cs updates on arXiv.org] Differential Privacy Image Generation with Reconstruction Loss and Noise Injection Using an Error Feedback SGD</title><link>https://arxiv.org/abs/2601.15061</link><description>arXiv:2601.15061v1 Announce Type: new 
Abstract: Traditional data masking techniques such as anonymization cannot achieve the expected privacy protection while ensuring data utility for privacy-preserving machine learning. Synthetic data plays an increasingly important role as it generates a large number of training samples and prevents information leakage in real data. The existing methods suffer from the repeating trade-off processes between privacy and utility. We propose a novel framework for differential privacy generation, which employs an Error Feedback Stochastic Gradient Descent(EFSGD) method and introduces a reconstruction loss and noise injection mechanism into the training process. We generate images with higher quality and usability under the same privacy budget as the related work. Extensive experiments demonstrate the effectiveness and generalization of our proposed framework for both grayscale and RGB images. We achieve state-of-the-art results over almost all metrics on three benchmarks: MNIST, Fashion-MNIST, and CelebA.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 22 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15061v1</guid></item></channel></rss>