<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>My Customized Papers</title><link>https://github.com/your_username/your_repo</link><description>Aggregated research papers</description><language>en-US</language><lastBuildDate>Thu, 29 Jan 2026 06:40:20 GMT</lastBuildDate><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>[cs updates on arXiv.org] Flexible Bit-Truncation Memory for Approximate Applications on the Edge</title><link>https://arxiv.org/abs/2601.19900</link><description>arXiv:2601.19900v1 Announce Type: new 
Abstract: Bit truncation has demonstrated great potential to enable run-time quality-power adaptive data storage, thereby optimizing the power/energy efficiency of approximate applications and supporting their deployment in edge environments. However, existing bit-truncation memories require custom designs for a specific application. In this paper, we present a novel bit-truncation memory with full adaptation flexibility, which can truncate any number of data bits at run time to meet different quality and power trade-off requirements for various approximate applications. The developed bit-truncation memory has been applied to two representative data-intensive approximate applications: video processing and deep learning. Our experiments show that the proposed memory can support three different video applications (including luminance-aware, content-aware, and region-of-interest-aware) with enhanced power efficiency (up to 47.02% power savings) as compared to state-of-the-art. In addition, the proposed memory achieves significant (up to 51.69%) power savings for both baseline and pruned lightweight deep learning models, respectively, with a low implementation cost (2.89% silicon area overhead).</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19900v1</guid></item><item><title>[cs updates on arXiv.org] Light Field Display Point Rendering</title><link>https://arxiv.org/abs/2601.19901</link><description>arXiv:2601.19901v1 Announce Type: new 
Abstract: Rendering for light field displays (LFDs) requires rendering of dozens or hundreds of views, which must then be combined into a single image on the display, making real-time LFD rendering extremely difficult. We introduce light field display point rendering (LFDPR), which meets these challenges by improving eye-based point rendering [Gavane and Watson 2023] with texture-based splatting, which avoids oversampling of triangles mapped to only a few texels; and with LFD-biased sampling, which adjusts horizontal and vertical triangle sampling to match the sampling of the LFD itself. To improve image quality, we introduce multiview mipmapping, which reduces texture aliasing even though compute shaders do not support hardware mipmapping. We also introduce angular supersampling and reconstruction to combat LFD view aliasing and crosstalk. The resulting LFDPR is 2-8x times faster than multiview rendering, with similar comparable quality.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19901v1</guid></item><item><title>[cs updates on arXiv.org] STELLAR: Structure-guided LLM Assertion Retrieval and Generation for Formal Verification</title><link>https://arxiv.org/abs/2601.19903</link><description>arXiv:2601.19903v1 Announce Type: new 
Abstract: Formal Verification (FV) relies on high-quality SystemVerilog Assertions (SVAs), but the manual writing process is slow and error-prone. Existing LLM-based approaches either generate assertions from scratch or ignore structural patterns in hardware designs and expert-crafted assertions. This paper presents STELLAR, the first framework that guides LLM-based SVA generation with structural similarity. STELLAR represents RTL blocks as AST structural fingerprints, retrieves structurally relevant (RTL, SVA) pairs from a knowledge base, and integrates them into structure-guided prompts. Experiments show that STELLAR achieves superior syntax correctness, stylistic alignment, and functional correctness, highlighting structure-aware retrieval as a promising direction for industrial FV.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19903v1</guid></item><item><title>[cs updates on arXiv.org] DABench-LLM: Standardized and In-Depth Benchmarking of Post-Moore Dataflow AI Accelerators for LLMs</title><link>https://arxiv.org/abs/2601.19904</link><description>arXiv:2601.19904v1 Announce Type: new 
Abstract: The exponential growth of large language models has outpaced the capabilities of traditional CPU and GPU architectures due to the slowdown of Moore's Law. Dataflow AI accelerators present a promising alternative; however, there remains a lack of in-depth performance analysis and standardized benchmarking methodologies for LLM training. We introduce DABench-LLM, the first benchmarking framework designed for evaluating LLM workloads on dataflow-based accelerators. By combining intra-chip performance profiling and inter-chip scalability analysis, DABench-LLM enables comprehensive evaluation across key metrics such as resource allocation, load balance, and resource efficiency. The framework helps researchers rapidly gain insights into underlying hardware and system behaviors, and provides guidance for performance optimizations. We validate DABench-LLM on three commodity dataflow accelerators, Cerebras WSE-2, SambaNova RDU, and Graphcore IPU. Our framework reveals performance bottlenecks and provides specific optimization strategies, demonstrating its generality and effectiveness across a diverse range of dataflow-based AI hardware platforms.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19904v1</guid></item><item><title>[cs updates on arXiv.org] Hardware-Aware Model Design and Training of Silicon-based Analog Neural Networks</title><link>https://arxiv.org/abs/2601.19905</link><description>arXiv:2601.19905v1 Announce Type: new 
Abstract: Silicon-based analog neural networks physically embody the ideal neural network model in an approximate way. We show that by retraining the neural network using a physics-informed hardware-aware model one can fully recover the inference accuracy of the ideal network model even in the presence of significant non-idealities. This is way more promising for scalability and integration density than the default option of improving the fidelity of the analog neural network at the cost of significant energy, area, and design overhead, through extensive calibration and conservative analog design.
  We first present a physics-informed hardware-aware model for a time-domain vector-matrix multiplier implemented with single-transistor floating-gate memory cells that explicitly accounts for two dominant non-idealities of the physical implementation - capacitive crosstalk and bit-line voltage drop - and integrates seamlessly with modern deep-learning workflows. The model discretizes each operation into adaptive time slots, processes activation patterns in parallel, and accumulates their contributions to predict effective multiplier outputs. Using measurements from a 16x16 silicon array, we calibrate the model, show that crosstalk is layout-dependent and often dominant, and introduce an improved weight-extraction procedure that doubles signal-to-error ratio versus an ideal vector-matrix multiplier model. Finally, we show that by training silicon-based analog neural networks using an hardware-aware model in the forward pass we can recover the accuracy of the ideal software networks across three architectures -- custom MLP on low-resolution MNIST, LeNet-5 on MNIST, and a VGG-style CNN on CIFAR-10 - establishing a complete design-to-deployment workflow for time-domain analog neuromorphic chips.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19905v1</guid></item><item><title>[cs updates on arXiv.org] GTAC: A Generative Transformer for Approximate Circuits</title><link>https://arxiv.org/abs/2601.19906</link><description>arXiv:2601.19906v1 Announce Type: new 
Abstract: Targeting error-tolerant applications, approximate circuits introduce controlled errors to significantly improve performance, power, and area (PPA) of circuits. In this work, we introduce GTAC, a novel generative Transformer-based model for producing approximate circuits. By leveraging principles of approximate computing and AI-driven EDA, our model innovatively integrates error thresholds into the design process. Experimental results show that compared with a state-of-the-art method, GTAC further reduces 6.4% area under the error rate constraint, while being 4.3x faster.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19906v1</guid></item><item><title>[cs updates on arXiv.org] RAPID-Graph: Recursive All-Pairs Shortest Paths Using Processing-in-Memory for Dynamic Programming on Graphs</title><link>https://arxiv.org/abs/2601.19907</link><description>arXiv:2601.19907v1 Announce Type: new 
Abstract: All-pairs shortest paths (APSP) remains a major bottleneck for large-scale graph analytics, as data movement with cubic complexity overwhelms the bandwidth of conventional memory hierarchies. In this work, we propose RAPID-Graph to address this challenge through a co-designed processing-in-memory (PIM) system that integrates algorithm, architecture, and device-level optimizations. At the algorithm level, we introduce a recursion-aware partitioner that enables an exact APSP computation by decomposing graphs into vertex tiles to reduce data dependency, such that both Floyd-Warshall and Min-Plus kernels execute fully in-place within digital PIM arrays. At the architecture and device levels, we design a 2.5D PIM stack integrating two phase-change memory compute dies, a logic die, and high-bandwidth scratchpad memory within a unified advanced package. An external non-volatile storage stack stores large APSP results persistently. The design achieves both tile-level and unit-level parallel processing to sustain high throughput. On the 2.45M-node OGBN-Products dataset, RAPID-Graph is 5.8x faster and 1,186x more energy efficient than state-of-the-art GPU clusters, while exceeding prior PIM accelerators by 8.3x in speed and 104x in efficiency. It further delivers up to 42.8x speedup and 392x energy savings over an NVIDIA H100 GPU.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19907v1</guid></item><item><title>[cs updates on arXiv.org] CHIME: Chiplet-based Heterogeneous Near-Memory Acceleration for Edge Multimodal LLM Inference</title><link>https://arxiv.org/abs/2601.19908</link><description>arXiv:2601.19908v1 Announce Type: new 
Abstract: The proliferation of large language models (LLMs) is accelerating the integration of multimodal assistants into edge devices, where inference is executed under stringent latency and energy constraints, often exacerbated by intermittent connectivity. These challenges become particularly acute in the context of multimodal LLMs (MLLMs), as high-dimensional visual inputs are transformed into extensive token sequences, thereby inflating the key-value (KV) cache and imposing substantial data movement overheads to the LLM backbone. To address these issues, we present CHIME, a chiplet-based heterogeneous near-memory acceleration for edge MLLMs inference. CHIME leverages the complementary strengths of integrated monolithic 3D (M3D) DRAM and RRAM chiplets: DRAM supplies low-latency bandwidth for attention, while RRAM offers dense, non-volatile storage for weights. This heterogeneous hardware is orchestrated by a co-designed mapping framework that executes fused kernels near data, minimizing cross-chiplet traffic to maximize effective bandwidth. On FastVLM (0.6B/1.7B) and MobileVLM (1.7B/3B), CHIME achieves up to 54x speedup and up to 246x better energy efficiency per inference as compared to the edge GPU NVIDIA Jetson Orin NX. It sustains 116.5-266.5 token/J compared to Jetson's 0.7-1.1 token/J. Furthermore, it delivers up to 69.2x higher throughput than the state-of-the-art PIM accelerator FACIL. Compared to the M3D DRAM-only design, CHIME's heterogeneous memory further improves energy efficiency by 7% and performance by 2.4x.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19908v1</guid></item><item><title>[cs updates on arXiv.org] A Cache-Aware Hybrid Sieve Combining Segmentation and Bit-Packing for Fast Prime Generation</title><link>https://arxiv.org/abs/2601.19909</link><description>arXiv:2601.19909v1 Announce Type: new 
Abstract: Prime generation is a fundamental task in cryptography, number theory, and randomized algorithms. While the classical Sieve of Eratosthenes is simple and efficient in theory, its practical performance on modern central processing units is often limited by memory access inefficiencies. This paper introduces a cache-aware hybrid sieve that integrates segmentation, bit-packing, and cache-line-aligned block processing to optimize memory bandwidth and level one and level two cache locality.
  The proposed approach reduces memory usage by storing only odd numbers and using one bit per value. The sieve range is divided into cache-sized blocks to minimize cache misses, while primes up to the square root of the limit are reused across blocks. Experimental results demonstrate up to an eight times reduction in memory usage and runtime improvements of up to two point four times compared to the classical sieve and one point seven times compared to the segmented sieve. Benchmarks up to ten to the power of nine illustrate that architecture-aware algorithm design can yield substantial practical performance gains.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19909v1</guid></item><item><title>[cs updates on arXiv.org] Understanding Bottlenecks for Efficiently Serving LLM Inference With KV Offloading</title><link>https://arxiv.org/abs/2601.19910</link><description>arXiv:2601.19910v1 Announce Type: new 
Abstract: KV cache offloading enables long-context LLM inference by storing caches in CPU DRAM, but PCIe bandwidth limitations create severe bottlenecks. In this paper, we develops an analytical framework that derives $\kappa_{\text{crit}}$, the critical cached-to-prefill token ratio where execution becomes memory-bound and show typical workloads exceed this threshold by orders of magnitude. Empirical characterization reveals 99\% of latency spent on transfers and serving offloaded requests results in GPU's consuming only 28\% of their rated TDP, motivating our proposed optimizations for hardware interconnects, model architectures, and scheduling algorithms.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19910v1</guid></item><item><title>[cs updates on arXiv.org] GPU-Augmented OLAP Execution Engine: GPU Offloading</title><link>https://arxiv.org/abs/2601.19911</link><description>arXiv:2601.19911v1 Announce Type: new 
Abstract: Modern OLAP systems have mitigated I/O bottlenecks via storage-compute separation and columnar layouts, but CPU costs in the execution layer (especially Top-K selection and join probe) are emerging as new bottlenecks at scale. This paper proposes a hybrid architecture that augments existing vectorized execution by selectively offloading only high-impact primitives to the GPU. To reduce data movement, we use key-only transfer (keys and pointers) with late materialization. We further introduce a Risky Gate (risk-aware gating) that triggers offloading only in gain/risk intervals based on input size, transfer, kernel and post-processing costs, and candidate-set complexity (K, M). Using PostgreSQL microbenchmarks and GPU proxy measurements, we observe improved tail latency (P95/P99) under gated offloading compared to always-on GPU offloading. This work extends the risk-aware gating principle used for optimizer-stage GPU-assisted measurement (arXiv:2512.19750) to execution-layer OLAP primitives.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19911v1</guid></item><item><title>[cs updates on arXiv.org] Analysis of LLM Vulnerability to GPU Soft Errors: An Instruction-Level Fault Injection Study</title><link>https://arxiv.org/abs/2601.19912</link><description>arXiv:2601.19912v1 Announce Type: new 
Abstract: Large language models (LLMs) are highly compute- and memory-intensive, posing significant demands on high-performance GPUs. At the same time, advances in GPU technology driven by shrinking transistor sizes and lower operating voltages have made these devices increasingly susceptible to soft errors. While prior work has examined GPU reliability, most studies have focused on general-purpose applications or conventional neural networks mostly used for vision tasks such as classification and detection. In contrast, systematic analysis of modern large-scale LLMs remains limited, despite their rapid adoption in diverse application scenarios. Given the unique characteristics of LLMs, their resilience to soft errors may differ substantially from earlier models. To bridge this gap, we conduct the first instruction-level fault injection study of LLM inference. Our approach reveals reliability characteristics from multiple perspectives, highlighting the effects of model architecture, parameter scale, and task complexity. These findings provide new insights into LLM reliability and inform the design of more effective fault tolerance mechanisms.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19912v1</guid></item><item><title>[cs updates on arXiv.org] From Intuition to Expertise: Rubric-Based Cognitive Calibration for Human Detection of LLM-Generated Korean Text</title><link>https://arxiv.org/abs/2601.19913</link><description>arXiv:2601.19913v1 Announce Type: new 
Abstract: Distinguishing human-written Korean text from fluent LLM outputs remains difficult even for linguistically trained readers, who can over-trust surface well-formedness. We study whether expert detection can be treated as a learnable skill and improved through structured calibration. We introduce LREAD, a rubric derived from national Korean writing standards and adapted to target micro-level artifacts (e.g., punctuation optionality, spacing behavior, and register shifts). In a three-phase longitudinal blind protocol with Korean linguistics majors, Phase 1 measures intuition-only detection, Phase 2 enforces criterion-level scoring with explicit justifications, and Phase 3 evaluates domain-focused mastery on held-out elementary essays. Across phases, majority-vote accuracy increases from 60% to 100%, accompanied by stronger inter-annotator agreement (Fleiss' kappa: -0.09 --&gt; 0.82). Compared to state-of-the-art LLM detectors, calibrated humans rely more on language-specific micro-diagnostics that are not well captured by coarse discourse priors. Our findings suggest that rubric-scaffolded expert judgment can serve as an interpretable complement to automated detectors for non-English settings, and we release the full rubric and a taxonomy of calibrated detection signatures.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19913v1</guid></item><item><title>[cs updates on arXiv.org] Simulating Complex Multi-Turn Tool Calling Interactions in Stateless Execution Environments</title><link>https://arxiv.org/abs/2601.19914</link><description>arXiv:2601.19914v1 Announce Type: new 
Abstract: Synthetic data has proven itself to be a valuable resource for tuning smaller, cost-effective language models to handle the complexities of multi-turn tool calling conversations. While many frameworks and systems for producing synthetic multi-turn tool calling data have been proposed, prior works have frequently assumed that any tool calling interactions will take place in an execution environment that maintains state. When such an environment is available, this is advantageous as it allows for the validity of an interaction to be determined by whether or not the state of the execution environment matches to some prespecified objective. Unfortunately, this does not hold in many real-world tool use settings, e.g., in enterprise settings where data security is of the utmost importance or in cases where tool specifications are synthesized from multiple sources. In this work, we address this gap by introducing a data generation method, DiGiT-TC, that is designed to produce tool calling conversations that have the characteristics of conversations generated through search in a stateful environment. The key to our technique lies in a novel generation pattern that allows our approach to implicitly represent certain tool calls in the user request. We validate our approach on standard tool calling benchmarks and demonstrate that, even in stateful problem settings, our approach results in strong performance gains.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19914v1</guid></item><item><title>[cs updates on arXiv.org] Modeling Next-Token Prediction as Left-Nested Intuitionistic Implication</title><link>https://arxiv.org/abs/2601.19915</link><description>arXiv:2601.19915v1 Announce Type: new 
Abstract: We introduce the \emph{Arrow Language Model}, a neural architecture derived from an intuitionistic-logic interpretation of next-token prediction. Instead of representing tokens as additive embeddings mixed by attention, we encode a prefix as a \emph{left-nested implication chain} whose structure preserves order through non-commutative composition. Next-token prediction corresponds to \emph{modus ponens}, and sequence processing becomes constructive proof extension under the Curry--Howard correspondence. Our Prolog-based specialized theorem provers validate fundamental properties of the neural models, among which relations between commutative vs. non-commutative sequencing and single-token vs. multi-token prediction choices. We show that a neural architecture equivalent to multiplicative RNNs arises naturally from a proof-theoretic interpretation of next-token prediction as nested intuitionistic implication, we present a practical low-rank neural realization and position the model relative to Transformers and state-space models.
  Keywords: logic-based derivation of neural architectures, intuitionistic implicational logic, token-as-operator neural models, state-space models, alternatives to transformer-based foundational models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19915v1</guid></item><item><title>[cs updates on arXiv.org] PaperAudit-Bench: Benchmarking Error Detection in Research Papers for Critical Automated Peer Review</title><link>https://arxiv.org/abs/2601.19916</link><description>arXiv:2601.19916v1 Announce Type: new 
Abstract: Large language models can generate fluent peer reviews, yet their assessments often lack sufficient critical rigor when substantive issues are subtle and distributed across a paper. In this paper, we introduce PaperAudit-Bench, which consists of two components: (1) PaperAudit-Dataset, an error dataset covering both errors identifiable within individual sections and those requiring cross-section reasoning, designed for controlled evaluation under long-context settings; and (2) PaperAudit-Review, an automated review framework that integrates structured error detection with evidence-aware review generation to support critical assessment. Experiments on PaperAudit-Bench reveal large variability in error detectability across models and detection depths, highlighting the difficulty of identifying such errors under long-context settings. Relative to representative automated reviewing baselines, incorporating explicit error detection into the review workflow produces systematically stricter and more discriminative evaluations, demonstrating its suitability for peer review. Finally, we show that the dataset supports training lightweight LLM detectors via SFT and RL, enabling effective error detection at reduced computational cost.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19916v1</guid></item><item><title>[cs updates on arXiv.org] PILOT: Planning via Internalized Latent Optimization Trajectories for Large Language Models</title><link>https://arxiv.org/abs/2601.19917</link><description>arXiv:2601.19917v1 Announce Type: new 
Abstract: Strategic planning is critical for multi-step reasoning, yet compact Large Language Models (LLMs) often lack the capacity to formulate global strategies, leading to error propagation in long-horizon tasks. Our analysis reveals that LLMs possess latent reasoning capabilities that can be unlocked when conditioned on explicit plans from a teacher model; however, runtime reliance on external guidance is often impractical due to latency and availability constraints. To bridge this gap, we propose PILOT (Planning via Internalized Latent Optimization Trajectories), a non-invasive framework designed to internalize the strategic oversight of large models into intrinsic Latent Guidance. Instead of altering backbone weights, PILOT employs a lightweight Hyper-Network to synthesize a query-conditioned Latent Guidance vector. This vector acts as an internal steering mechanism, guiding the model's representations toward optimal reasoning paths. Extensive experiments on mathematical and coding benchmarks demonstrate that PILOT effectively stabilizes reasoning trajectories, consistently outperforming strong baselines (e.g., +8.9% on MATH500) with negligible inference latency.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19917v1</guid></item><item><title>[cs updates on arXiv.org] Lowest Span Confidence: A Zero-Shot Metric for Efficient and Black-Box Hallucination Detection in LLMs</title><link>https://arxiv.org/abs/2601.19918</link><description>arXiv:2601.19918v1 Announce Type: new 
Abstract: Hallucinations in Large Language Models (LLMs), i.e., the tendency to generate plausible but non-factual content, pose a significant challenge for their reliable deployment in high-stakes environments. However, existing hallucination detection methods generally operate under unrealistic assumptions, i.e., either requiring expensive intensive sampling strategies for consistency checks or white-box LLM states, which are unavailable or inefficient in common API-based scenarios. To this end, we propose a novel efficient zero-shot metric called Lowest Span Confidence (LSC) for hallucination detection under minimal resource assumptions, only requiring a single forward with output probabilities. Concretely, LSC evaluates the joint likelihood of semantically coherent spans via a sliding window mechanism. By identifying regions of lowest marginal confidence across variable-length n-grams, LSC could well capture local uncertainty patterns strongly correlated with factual inconsistency. Importantly, LSC can mitigate the dilution effect of perplexity and the noise sensitivity of minimum token probability, offering a more robust estimate of factual uncertainty. Extensive experiments across multiple state-of-the-art (SOTA) LLMs and diverse benchmarks show that LSC consistently outperforms existing zero-shot baselines, delivering strong detection performance even under resource-constrained conditions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19918v1</guid></item><item><title>[cs updates on arXiv.org] FastWhisper: Adaptive Self-knowledge Distillation for Real-time Automatic Speech Recognition</title><link>https://arxiv.org/abs/2601.19919</link><description>arXiv:2601.19919v1 Announce Type: new 
Abstract: Knowledge distillation is one of the most effective methods for model compression. Previous studies have focused on the student model effectively training the predictive distribution of the teacher model. However, during training, the student model may inherit the shortcomings of the teacher model, which can lead to a decline in generalization capacity. To mitigate this issue, we propose adaptive self-knowledge distillation (ASKD), which dynamically reduces the dependence of the teacher model to improve the self-training capacity, and performs the self-knowledge distillation method to improve the generalization capacity of the student model. We further distill the Whisper model into a smaller variant, called FastWhisper. In our post-training setting, FastWhisper achieved a word error rate of 1.07% lower than the teacher model Whisper, and its relative inference time was 5 times faster.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19919v1</guid></item><item><title>[cs updates on arXiv.org] PiC-BNN: A 128-kbit 65 nm Processing-in-CAM-Based End-to-End Binary Neural Network Accelerator</title><link>https://arxiv.org/abs/2601.19920</link><description>arXiv:2601.19920v1 Announce Type: new 
Abstract: Binary Neural Networks (BNNs), where weights and activations are constrained to binary values (+1, -1), are a highly efficient alternative to traditional neural networks. Unfortunately, typical BNNs, while binarizing linear layers (matrix-vector multiplication), still implement other network layers (batch normalization, softmax, output layer, and sometimes the input layer of a convolutional neural network) in full precision. This limits the area and energy benefits and requires architectural support for full precision operations. We propose PiC-BNN, a true end-to-end binary in-approximate search (Hamming distance tolerant) Content Addressable Memory based BNN accelerator. PiC-BNN is designed and manufactured in a commercial 65nm process. PiC-BNN uses Hamming distance tolerance to apply the law of large numbers to enable accurate classification without implementing full precision operations. PiC-BNN achieves baseline software accuracy (95.2%) on the MNIST dataset and 93.5% on the Hand Gesture (HG) dataset, a throughput of 560K inferences/s, and presents a power efficiency of 703M inferences/s/W when implementing a binary MLP model for MNIST/HG dataset classification.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19920v1</guid></item><item><title>[cs updates on arXiv.org] Demystifying Multi-Agent Debate: The Role of Confidence and Diversity</title><link>https://arxiv.org/abs/2601.19921</link><description>arXiv:2601.19921v1 Announce Type: new 
Abstract: Multi-agent debate (MAD) is widely used to improve large language model (LLM) performance through test-time scaling, yet recent work shows that vanilla MAD often underperforms simple majority vote despite higher computational cost. Studies show that, under homogeneous agents and uniform belief updates, debate preserves expected correctness and therefore cannot reliably improve outcomes. Drawing on findings from human deliberation and collective decision-making, we identify two key mechanisms missing from vanilla MAD: (i) diversity of initial viewpoints and (ii) explicit, calibrated confidence communication. We propose two lightweight interventions. First, a diversity-aware initialisation that selects a more diverse pool of candidate answers, increasing the likelihood that a correct hypothesis is present at the start of debate. Second, a confidence-modulated debate protocol in which agents express calibrated confidence and condition their updates on others' confidence. We show theoretically that diversity-aware initialisation improves the prior probability of MAD success without changing the underlying update dynamics, while confidence-modulated updates enable debate to systematically drift to the correct hypothesis. Empirically, across six reasoning-oriented QA benchmarks, our methods consistently outperform vanilla MAD and majority vote. Our results connect human deliberation with LLM-based debate and demonstrate that simple, principled modifications can substantially enhance debate effectiveness.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19921v1</guid></item><item><title>[cs updates on arXiv.org] HEART: A Unified Benchmark for Assessing Humans and LLMs in Emotional Support Dialogue</title><link>https://arxiv.org/abs/2601.19922</link><description>arXiv:2601.19922v1 Announce Type: new 
Abstract: Supportive conversation depends on skills that go beyond language fluency, including reading emotions, adjusting tone, and navigating moments of resistance, frustration, or distress. Despite rapid progress in language models, we still lack a clear way to understand how their abilities in these interpersonal domains compare to those of humans. We introduce HEART, the first-ever framework that directly compares humans and LLMs on the same multi-turn emotional-support conversations. For each dialogue history, we pair human and model responses and evaluate them through blinded human raters and an ensemble of LLM-as-judge evaluators. All assessments follow a rubric grounded in interpersonal communication science across five dimensions: Human Alignment, Empathic Responsiveness, Attunement, Resonance, and Task-Following. HEART uncovers striking behavioral patterns. Several frontier models approach or surpass the average human responses in perceived empathy and consistency. At the same time, humans maintain advantages in adaptive reframing, tension-naming, and nuanced tone shifts, particularly in adversarial turns. Human and LLM-as-judge preferences align on about 80 percent of pairwise comparisons, matching inter-human agreement, and their written rationales emphasize similar HEART dimensions. This pattern suggests an emerging convergence in the criteria used to assess supportive quality. By placing humans and models on equal footing, HEART reframes supportive dialogue as a distinct capability axis, separable from general reasoning or linguistic fluency. It provides a unified empirical foundation for understanding where model-generated support aligns with human social judgment, where it diverges, and how affective conversational competence scales with model size.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19922v1</guid></item><item><title>[cs updates on arXiv.org] Table-BiEval: A Self-Supervised, Dual-Track Framework for Decoupling Structure and Content in LLM Evaluation</title><link>https://arxiv.org/abs/2601.19923</link><description>arXiv:2601.19923v1 Announce Type: new 
Abstract: As Large Language Models (LLMs) evolve into autonomous agents, the capability to faithfully translate natural language into rigorous structured formats-essential for tool invocation-and to convert complex tabular information into machine-readable specifications has become paramount. However, current evaluations lack effective methodologies to measure this structural fidelity without costly human intervention, as traditional text metrics fail to detect semantic drift in code-like outputs. This paper proposes Table-BiEval, a novel approach based on a human-free, self-supervised evaluation framework, to assess LLMs performance quantitatively. By leveraging deterministic Intermediate Representations, our framework calculates Content Semantic Accuracy and Normalized Tree Edit Distance to decouple structure from content. Also, it empirically evaluates 15 state-of-the-art LLMs across dual topological dimensions-hierarchical structures and flat tables. The results reveal substantial variability, highlighting that mid-sized models can surprisingly outperform larger counterparts in structural efficiency and confirming that deep recursive nesting remains a universal bottleneck for current architectures.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19923v1</guid></item><item><title>[cs updates on arXiv.org] OPT-Engine: Benchmarking the Limits of LLMs in Optimization Modeling via Complexity Scaling</title><link>https://arxiv.org/abs/2601.19924</link><description>arXiv:2601.19924v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated impressive progress in optimization modeling, fostering a rapid expansion of new methodologies and evaluation benchmarks. However, the boundaries of their capabilities in automated formulation and problem solving remain poorly understood, particularly when extending to complex, real-world tasks. To bridge this gap, we propose OPT-ENGINE, an extensible benchmark framework designed to evaluate LLMs on optimization modeling with controllable and scalable difficulty levels. OPT-ENGINE spans 10 canonical tasks across operations research, with five Linear Programming and five Mixed-Integer Programming. Utilizing OPT-ENGINE, we conduct an extensive study of LLMs' reasoning capabilities, addressing two critical questions: 1.) Do LLMs' performance remain robust when generalizing to out-of-distribution optimization tasks that scale in complexity beyond current benchmark levels? and 2.) At what stage, from problem interpretation to solution generation, do current LLMs encounter the most significant bottlenecks? Our empirical results yield two key insights: first, tool-integrated reasoning with external solvers exhibits significantly higher robustness as task complexity escalates, while pure-text reasoning reaches a ceiling; second, the automated formulation of constraints constitutes the primary performance bottleneck. These findings provide actionable guidance for developing next-generation LLMs for advanced optimization. Our code is publicly available at \textcolor{blue}{https://github.com/Cardinal-Operations/OPTEngine}.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19924v1</guid></item><item><title>[cs updates on arXiv.org] Evaluating Large Language Models for Abstract Evaluation Tasks: An Empirical Study</title><link>https://arxiv.org/abs/2601.19925</link><description>arXiv:2601.19925v1 Announce Type: new 
Abstract: Introduction: Large language models (LLMs) can process requests and generate texts, but their feasibility for assessing complex academic content needs further investigation. To explore LLM's potential in assisting scientific review, this study examined ChatGPT-5, Gemini-3-Pro, and Claude-Sonnet-4.5's consistency and reliability in evaluating abstracts compared to one another and to human reviewers. Methods: 160 abstracts from a local conference were graded by human reviewers and three LLMs using one rubric. Composite score distributions across three LLMs and fourteen reviewers were examined. Inter-rater reliability was calculated using intraclass correlation coefficients (ICCs) for within-AI reliability and AI-human concordance. Bland-Altman plots were examined for visual agreement patterns and systematic bias. Results: LLMs achieved good-to-excellent agreement with each other (ICCs: 0.59-0.87). ChatGPT and Claude reached moderate agreement with human reviewers on overall quality and content-specific criteria, with ICCs ~.45-.60 for composite, impression, clarity, objective, and results. They exhibited fair agreement on subjective dimensions, with ICC ranging from 0.23-0.38 for impact, engagement, and applicability. Gemini showed fair agreement on half criteria and no reliability on impact and applicability. Three LLMs showed acceptable or negligible mean difference (ChatGPT=0.24, Gemini=0.42, Claude=-0.02) from the human mean composite scores. Discussion: LLMs could process abstracts in batches with moderate agreement with human experts on overall quality and objective criteria. With appropriate process architecture, they can apply a rubric consistently across volumes of abstracts exceeding feasibility for a human rater. The weaker performance on subjective dimensions indicates that AI should serve a complementary role in evaluation, while human expertise remains essential.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19925v1</guid></item><item><title>[cs updates on arXiv.org] The Grammar of Transformers: A Systematic Review of Interpretability Research on Syntactic Knowledge in Language Models</title><link>https://arxiv.org/abs/2601.19926</link><description>arXiv:2601.19926v1 Announce Type: new 
Abstract: We present a systematic review of 337 articles evaluating the syntactic abilities of Transformer-based language models, reporting on 1,015 model results from a range of syntactic phenomena and interpretability methods. Our analysis shows that the state of the art presents a healthy variety of methods and data, but an over-focus on a single language (English), a single model (BERT), and phenomena that are easy to get at (like part of speech and agreement). Results also suggest that TLMs capture these form-oriented phenomena well, but show more variable and weaker performance on phenomena at the syntax-semantics interface, like binding or filler-gap dependencies. We provide recommendations for future work, in particular reporting complete data, better aligning theoretical constructs and methods across studies, increasing the use of mechanistic methods, and broadening the empirical scope regarding languages and linguistic phenomena.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19926v1</guid></item><item><title>[cs updates on arXiv.org] Attribution Techniques for Mitigating Hallucinated Information in RAG Systems: A Survey</title><link>https://arxiv.org/abs/2601.19927</link><description>arXiv:2601.19927v1 Announce Type: new 
Abstract: Large Language Models (LLMs)-based question answering (QA) systems play a critical role in modern AI, demonstrating strong performance across various tasks. However, LLM-generated responses often suffer from hallucinations, unfaithful statements lacking reliable references. Retrieval-Augmented Generation (RAG) frameworks enhance LLM responses by incorporating external references but also introduce new forms of hallucination due to complex interactions between the retriever and generator. To address these challenges, researchers have explored attribution-based techniques that ensure responses are verifiably supported by retrieved content. Despite progress, a unified pipeline for these techniques, along with a clear taxonomy and systematic comparison of their strengths and weaknesses, remains lacking. A well-defined taxonomy is essential for identifying specific failure modes within RAG systems, while comparative analysis helps practitioners choose appropriate solutions based on hallucination types and application context. This survey investigates how attribution-based techniques are used within RAG systems to mitigate hallucinations and addresses the gap by: (i) outlining a taxonomy of hallucination types in RAG systems, (ii) presenting a unified pipeline for attribution techniques, (iii) reviewing techniques based on the hallucinations they target, and (iv) discussing strengths and weaknesses with practical guidelines. This work offers insights for future research and practical use of attribution techniques in RAG systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19927v1</guid></item><item><title>[cs updates on arXiv.org] Towards a Mechanistic Understanding of Large Reasoning Models: A Survey of Training, Inference, and Failures</title><link>https://arxiv.org/abs/2601.19928</link><description>arXiv:2601.19928v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has catalyzed the emergence of Large Reasoning Models (LRMs) that have pushed reasoning capabilities to new heights. While their performance has garnered significant excitement, exploring the internal mechanisms driving these behaviors has become an equally critical research frontier. This paper provides a comprehensive survey of the mechanistic understanding of LRMs, organizing recent findings into three core dimensions: 1) training dynamics, 2) reasoning mechanisms, and 3) unintended behaviors. By synthesizing these insights, we aim to bridge the gap between black-box performance and mechanistic transparency. Finally, we discuss under-explored challenges to outline a roadmap for future mechanistic studies, including the need for applied interpretability, improved methodologies, and a unified theoretical framework.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19928v1</guid></item><item><title>[cs updates on arXiv.org] Stingy Context: 18:1 Hierarchical Code Compression for LLM Auto-Coding</title><link>https://arxiv.org/abs/2601.19929</link><description>arXiv:2601.19929v1 Announce Type: new 
Abstract: We introduce Stingy Context, a hierarchical tree-based compression scheme achieving 18:1 reduction in LLM context for auto-coding tasks. Using our TREEFRAG exploit decomposition, we reduce a real source code base of 239k tokens to 11k tokens while preserving task fidelity. Empirical results across 12 Frontier models show 94 to 97% success on 40 real-world issues at low cost, outperforming flat methods and mitigating lost-in-the-middle effects.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19929v1</guid></item><item><title>[cs updates on arXiv.org] SDUs DAISY: A Benchmark for Danish Culture</title><link>https://arxiv.org/abs/2601.19930</link><description>arXiv:2601.19930v1 Announce Type: new 
Abstract: We introduce a new benchmark for Danish culture via cultural heritage, Daisy, based on the curated topics from the Danish Culture Canon 2006. For each artifact in the culture canon, we query the corresponding Wikipedia page and have a language model generate random questions. This yields a sampling strategy within each work, with a mix of central of peripheral questions for each work, not only knowledge of mainstream information, but also in-depth cornerstones defining the heritage of Danish Culture, defined by the Canon committee. Each question-answer pair is humanly approved or corrected in the final dataset consisting of 741 close-ended question answer pairs covering topics, from 1300 BC. archaeological findings, 1700 century poems and musicals pieces to contemporary pop music and Danish design and architecture.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19930v1</guid></item><item><title>[cs updates on arXiv.org] CascadeMind at SemEval-2026 Task 4: A Hybrid Neuro-Symbolic Cascade for Narrative Similarity</title><link>https://arxiv.org/abs/2601.19931</link><description>arXiv:2601.19931v1 Announce Type: new 
Abstract: We present a hybrid neuro-symbolic system for the SemEval-2026 Task 4 on Narrative Story Similarity. Our approach combines neural self-consistency voting with a novel Multi-Scale Narrative Analysis Ensemble that operates as a symbolic tiebreaker. The neural network component uses a large language model with multiple parallel votes, applying a supermajority threshold for confident decisions and escalating uncertain cases to additional voting rounds. When votes result in a perfect tie, a symbolic ensemble combining five narrative similarity signals (lexical overlap, semantic embeddings, story grammar structure, event chain alignment, and narrative tension curves) provides the final decision. Our cascade architecture achieves 81% accuracy on the development set, demonstrating that selective deferral to symbolic methods can enhance neural predictions on genuinely ambiguous narrative comparisons.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19931v1</guid></item><item><title>[cs updates on arXiv.org] "Newspaper Eat" Means "Not Tasty": A Taxonomy and Benchmark for Coded Languages in Real-World Chinese Online Reviews</title><link>https://arxiv.org/abs/2601.19932</link><description>arXiv:2601.19932v1 Announce Type: new 
Abstract: Coded language is an important part of human communication. It refers to cases where users intentionally encode meaning so that the surface text differs from the intended meaning and must be decoded to be understood. Current language models handle coded language poorly. Progress has been limited by the lack of real-world datasets and clear taxonomies. This paper introduces CodedLang, a dataset of 7,744 Chinese Google Maps reviews, including 900 reviews with span-level annotations of coded language. We developed a seven-class taxonomy that captures common encoding strategies, including phonetic, orthographic, and cross-lingual substitutions. We benchmarked language models on coded language detection, classification, and review rating prediction. Results show that even strong models can fail to identify or understand coded language. Because many coded expressions rely on pronunciation-based strategies, we further conducted a phonetic analysis of coded and decoded forms. Together, our results highlight coded language as an important and underexplored challenge for real-world NLP systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19932v1</guid></item><item><title>[cs updates on arXiv.org] Text-to-State Mapping for Non-Resolution Reasoning: The Contradiction-Preservation Principle</title><link>https://arxiv.org/abs/2601.19933</link><description>arXiv:2601.19933v1 Announce Type: new 
Abstract: Non-Resolution Reasoning (NRR) provides a formal framework for maintaining semantic ambiguity rather than forcing premature interpretation collapse. While the foundational architecture establishes state spaces and operators for ambiguity-preserving computation, the critical question of how natural language maps to these mathematical structures remains open. This paper introduces the text-to-state mapping function {\phi} that transforms linguistic input into superposition states within the NRR framework. We formalize the Contradiction-Preservation Principle, which requires that genuinely ambiguous expressions maintain non-zero entropy in their state representations, and develop extraction protocols using existing Large Language Models as interpretation generators. Empirical validation across 68 test sentences spanning lexical, structural, and pragmatic ambiguity demonstrates that our mapping achieves mean Shannon entropy H(S) = 1.087 bits for ambiguous inputs while baseline single-interpretation approaches yield H(S) = 0.000. The framework provides the missing algorithmic bridge between raw text and the formal state spaces on which NRR operators act, enabling architectural collapse deferment in language model inference.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19933v1</guid></item><item><title>[cs updates on arXiv.org] Quantifying non deterministic drift in large language models</title><link>https://arxiv.org/abs/2601.19934</link><description>arXiv:2601.19934v1 Announce Type: new 
Abstract: Large language models (LLMs) are widely used for tasks ranging from summarisation to decision support. In practice, identical prompts do not always produce identical outputs, even when temperature and other decoding parameters are fixed. In this work, we conduct repeated-run experiments to empirically quantify baseline behavioural drift, defined as output variability observed when the same prompt is issued multiple times under operator-free conditions. We evaluate two publicly accessible models, gpt-4o-mini and llama3.1-8b, across five prompt categories using exact repeats, perturbed inputs, and reuse modes at temperatures of 0.0 and 0.7. Drift is measured using unique output fractions, lexical similarity, and word count statistics, enabling direct comparison across models, prompting modes, and deployment types. The results show that nondeterminism persists even at temperature 0.0, with distinct variability patterns by model size, deployment, and prompt type. We situate these findings within existing work on concept drift, behavioural drift, and infrastructure-induced nondeterminism, discuss the limitations of lexical metrics, and highlight emerging semantic approaches. By establishing a systematic empirical baseline in the absence of stabilisation techniques, this study provides a reference point for evaluating future drift mitigation and control methods.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19934v1</guid></item><item><title>[cs updates on arXiv.org] Mem2ActBench: A Benchmark for Evaluating Long-Term Memory Utilization in Task-Oriented Autonomous Agents</title><link>https://arxiv.org/abs/2601.19935</link><description>arXiv:2601.19935v1 Announce Type: new 
Abstract: Large Language Model (LLM)-based agents are increasingly deployed for complex, tool-based tasks where long-term memory is critical to driving actions. Existing benchmarks, however, primarily test a angent's ability to passively retrieve isolated facts in response to explicit questions. They fail to evaluate the more crucial capability of actively applying memory to execute tasks. To address this gap, we introduce \textsc{Mem2ActBench}, a benchmark for evaluating whether agents can proactively leverage long-term memory to execute tool-based actions by selecting appropriate tools and grounding their parameters. The benchmark simulates persistent assistant usage, where users mention the same topic across long, interrupted interactions and expect previously established preferences and task states to be implicitly applied. We build the dataset with an automated pipeline that merges heterogeneous sources (ToolACE, BFCL, Oasst1), resolves conflicts via consistency modeling, and synthesizes 2,029 sessions with 12 user--assistant--tool turns on average. From these memory chains, a reverse-generation method produces 400 tool-use tasks, with human evaluation confirming 91.3\% are strongly memory-dependent. Experiments on seven memory frameworks show that current systems remain inadequate at actively utilizing memory for parameter grounding, highlighting the need for more effective approaches to evaluate and improve memory application in task execution.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19935v1</guid></item><item><title>[cs updates on arXiv.org] Gap-K%: Measuring Top-1 Prediction Gap for Detecting Pretraining Data</title><link>https://arxiv.org/abs/2601.19936</link><description>arXiv:2601.19936v1 Announce Type: new 
Abstract: The opacity of massive pretraining corpora in Large Language Models (LLMs) raises significant privacy and copyright concerns, making pretraining data detection a critical challenge. Existing state-of-the-art methods typically rely on token likelihoods, yet they often overlook the divergence from the model's top-1 prediction and local correlation between adjacent tokens. In this work, we propose Gap-K%, a novel pretraining data detection method grounded in the optimization dynamics of LLM pretraining. By analyzing the next-token prediction objective, we observe that discrepancies between the model's top-1 prediction and the target token induce strong gradient signals, which are explicitly penalized during training. Motivated by this, Gap-K% leverages the log probability gap between the top-1 predicted token and the target token, incorporating a sliding window strategy to capture local correlations and mitigate token-level fluctuations. Extensive experiments on the WikiMIA and MIMIR benchmarks demonstrate that Gap-K% achieves state-of-the-art performance, consistently outperforming prior baselines across various model sizes and input lengths.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19936v1</guid></item><item><title>[cs updates on arXiv.org] DecHW: Heterogeneous Decentralized Federated Learning Exploiting Second-Order Information</title><link>https://arxiv.org/abs/2601.19938</link><description>arXiv:2601.19938v1 Announce Type: new 
Abstract: Decentralized Federated Learning (DFL) is a serverless collaborative machine learning paradigm where devices collaborate directly with neighbouring devices to exchange model information for learning a generalized model. However, variations in individual experiences and different levels of device interactions lead to data and model initialization heterogeneities across devices. Such heterogeneities leave variations in local model parameters across devices that leads to slower convergence. This paper tackles the data and model heterogeneity by explicitly addressing the parameter level varying evidential credence across local models. A novel aggregation approach is introduced that captures these parameter variations in local models and performs robust aggregation of neighbourhood local updates. Specifically, consensus weights are generated via approximation of second-order information of local models on their local datasets. These weights are utilized to scale neighbourhood updates before aggregating them into global neighbourhood representation. In extensive experiments with computer vision tasks, the proposed approach shows strong generalizability of local models at reduced communication costs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19938v1</guid></item><item><title>[cs updates on arXiv.org] oculomix: Hierarchical Sampling for Retinal-Based Systemic Disease Prediction</title><link>https://arxiv.org/abs/2601.19939</link><description>arXiv:2601.19939v1 Announce Type: new 
Abstract: Oculomics - the concept of predicting systemic diseases, such as cardiovascular disease and dementia, through retinal imaging - has advanced rapidly due to the data efficiency of transformer-based foundation models like RETFound. Image-level mixed sample data augmentations, such as CutMix and MixUp, are frequently used for training transformers, yet these techniques perturb patient-specific attributes, such as medical comorbidity and clinical factors, since they only account for images and labels. To address this limitation, we propose a hierarchical sampling strategy, Oculomix, for mixed sample augmentations. Our method is based on two clinical priors. First (exam level), images acquired from the same patient at the same time point share the same attributes. Second (patient level), images acquired from the same patient at different time points have a soft temporal trend, as morbidity generally increases over time. Guided by these priors, our method constrains the mixing space to the patient and exam levels to better preserve patient-specific characteristics and leverages their hierarchical relationships. The proposed method is validated using ViT models on a five-year prediction of major adverse cardiovascular events (MACE) in a large ethnically diverse population (Alzeye). We show that Oculomix consistently outperforms image-level CutMix and MixUp by up to 3% in AUROC, demonstrating the necessity and value of the proposed method in oculomics.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19939v1</guid></item><item><title>[cs updates on arXiv.org] Continuous-Flow Data-Rate-Aware CNN Inference on FPGA</title><link>https://arxiv.org/abs/2601.19940</link><description>arXiv:2601.19940v1 Announce Type: new 
Abstract: Among hardware accelerators for deep-learning inference, data flow implementations offer low latency and high throughput capabilities. In these architectures, each neuron is mapped to a dedicated hardware unit, making them well-suited for field-programmable gate array (FPGA) implementation. Previous unrolled implementations mostly focus on fully connected networks because of their simplicity, although it is well known that convolutional neural networks (CNNs) require fewer computations for the same accuracy. When observing the data flow in CNNs, pooling layers and convolutional layers with a stride larger than one, the number of data at their output is reduced with respect to their input. This data reduction strongly affects the data rate in a fully parallel implementation, making hardware units heavily underutilized unless it is handled properly. This work addresses this issue by analyzing the data flow of CNNs and presents a novel approach to designing data-rate-aware, continuous-flow CNN architectures. The proposed approach ensures a high hardware utilization close to 100% by interleaving low data rate signals and sharing hardware units, as well as using the right parallelization to achieve the throughput of a fully parallel implementation. The results show that a significant amount of the arithmetic logic can be saved, which allows implementing complex CNNs like MobileNet on a single FPGA with high throughput.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19940v1</guid></item><item><title>[cs updates on arXiv.org] Bench4HLS: End-to-End Evaluation of LLMs in High-Level Synthesis Code Generation</title><link>https://arxiv.org/abs/2601.19941</link><description>arXiv:2601.19941v1 Announce Type: new 
Abstract: In last two years, large language models (LLMs) have shown strong capabilities in code generation, including hardware design at register-transfer level (RTL). While their use in high-level synthesis (HLS) remains comparatively less mature, the ratio of HLS- to RTL-focused studies has shifted from 1:10 to 2:10 in the past six months, indicating growing interest in leveraging LLMs for high-level design entry while relying on downstream synthesis for optimization. This growing trend highlights the need for a comprehensive benchmarking and evaluation framework dedicated to LLM-based HLS. To address this, We present Bench4HLS for evaluating LLM-generated HLS designs. Bench4HLS comprises 170 manually drafted and validated case studies, spanning small kernels to complex accelerators, curated from widely used public repositories. The framework supports fully automated assessment of compilation success, functional correctness via simulation, and synthesis feasibility/optimization. Crucially, Bench4HLS integrates a pluggable API for power, performance, and area (PPA) analysis across various HLS toolchains and architectures, demonstrated here with Xilinx Vitis HLS and validated on Catapult HLS. By providing a structured, extensible, and plug-and-play testbed, Bench4HLS establishes a foundational methodology for benchmarking LLMs in HLS workflows.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19941v1</guid></item><item><title>[cs updates on arXiv.org] Latent Object Permanence: Topological Phase Transitions, Free-Energy Principles, and Renormalization Group Flows in Deep Transformer Manifolds</title><link>https://arxiv.org/abs/2601.19942</link><description>arXiv:2601.19942v1 Announce Type: new 
Abstract: We study the emergence of multi-step reasoning in deep Transformer language models through a geometric and statistical-physics lens. Treating the hidden-state trajectory as a flow on an implicit Riemannian manifold, we analyze the layerwise covariance spectrum of activations, where $C^{(\ell)}=\mathbb{E}[h^{(\ell)}h^{(\ell)\top}]$, and track deviations from a random-matrix bulk. Across model scales (1.5B--30B), we observe a sharp reduction in effective dimensionality consistent with a phase transition: an order parameter based on sparsity/localization, $\Omega(h)=1-\|h\|_1/(\sqrt{d}\|h\|_2)$, exhibits a discontinuity near a critical normalized depth $\gamma_c\approx 0.42$ in sufficiently large models. We formalize the forward pass as a discrete coarse-graining map and relate the appearance of stable "concept basins" to fixed points of this renormalization-like dynamics. The resulting low-entropy regime is characterized by a spectral tail collapse and by the formation of transient, reusable object-like structures in representation space, which we call Transient Class Objects (TCOs). We provide theoretical conditions connecting logical separability to spectral decay and validate the predicted signatures with layerwise probes on multiple open-weight model families.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19942v1</guid></item><item><title>[cs updates on arXiv.org] Emergent Specialization in Learner Populations: Competition as the Source of Diversity</title><link>https://arxiv.org/abs/2601.19943</link><description>arXiv:2601.19943v1 Announce Type: new 
Abstract: How can populations of learners develop coordinated, diverse behaviors without explicit communication or diversity incentives? We demonstrate that competition alone is sufficient to induce emergent specialization -- learners spontaneously partition into specialists for different environmental regimes through competitive dynamics, consistent with ecological niche theory. We introduce the NichePopulation algorithm, a simple mechanism combining competitive exclusion with niche affinity tracking. Validated across six real-world domains (cryptocurrency trading, commodity prices, weather forecasting, solar irradiance, urban traffic, and air quality), our approach achieves a mean Specialization Index of 0.75 with effect sizes of Cohen's d &gt; 20. Key findings: (1) At lambda=0 (no niche bonus), learners still achieve SI &gt; 0.30, proving specialization is genuinely emergent; (2) Diverse populations outperform homogeneous baselines by +26.5% through method-level division of labor; (3) Our approach outperforms MARL baselines (QMIX, MAPPO, IQL) by 4.3x while being 4x faster.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19943v1</guid></item><item><title>[cs updates on arXiv.org] Classifier Calibration at Scale: An Empirical Study of Model-Agnostic Post-Hoc Methods</title><link>https://arxiv.org/abs/2601.19944</link><description>arXiv:2601.19944v1 Announce Type: new 
Abstract: We study model-agnostic post-hoc calibration methods intended to improve probabilistic predictions in supervised binary classification on real i.i.d. tabular data, with particular emphasis on conformal and Venn-based approaches that provide distribution-free validity guarantees under exchangeability. We benchmark 21 widely used classifiers, including linear models, SVMs, tree ensembles (CatBoost, XGBoost, LightGBM), and modern tabular neural and foundation models, on binary tasks from the TabArena-v0.1 suite using randomized, stratified five-fold cross-validation with a held-out test fold. Five calibrators; Isotonic regression, Platt scaling, Beta calibration, Venn-Abers predictors, and Pearsonify are trained on a separate calibration split and applied to test predictions. Calibration is evaluated using proper scoring rules (log-loss and Brier score) and diagnostic measures (Spiegelhalter's Z, ECE, and ECI), alongside discrimination (AUC-ROC) and standard classification metrics. Across tasks and architectures, Venn-Abers predictors achieve the largest average reductions in log-loss, followed closely by Beta calibration, while Platt scaling exhibits weaker and less consistent effects. Beta calibration improves log-loss most frequently across tasks, whereas Venn-Abers displays fewer instances of extreme degradation and slightly more instances of extreme improvement. Importantly, we find that commonly used calibration procedures, most notably Platt scaling and isotonic regression, can systematically degrade proper scoring performance for strong modern tabular models. Overall classification performance is often preserved, but calibration effects vary substantially across datasets and architectures, and no method dominates uniformly. In expectation, all methods except Pearsonify slightly increase accuracy, but the effect is marginal, with the largest expected gain about 0.008%.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19944v1</guid></item><item><title>[cs updates on arXiv.org] NCSAM Noise-Compensated Sharpness-Aware Minimization for Noisy Label Learning</title><link>https://arxiv.org/abs/2601.19947</link><description>arXiv:2601.19947v1 Announce Type: new 
Abstract: Learning from Noisy Labels (LNL) presents a fundamental challenge in deep learning, as real-world datasets often contain erroneous or corrupted annotations, \textit{e.g.}, data crawled from Web. Current research focuses on sophisticated label correction mechanisms. In contrast, this paper adopts a novel perspective by establishing a theoretical analysis the relationship between flatness of the loss landscape and the presence of label noise. In this paper, we theoretically demonstrate that carefully simulated label noise synergistically enhances both the generalization performance and robustness of label noises. Consequently, we propose Noise-Compensated Sharpness-aware Minimization (NCSAM) to leverage the perturbation of Sharpness-Aware Minimization (SAM) to remedy the damage of label noises. Our analysis reveals that the testing accuracy exhibits a similar behavior that has been observed on the noise-clear dataset. Extensive experimental results on multiple benchmark datasets demonstrate the consistent superiority of the proposed method over existing state-of-the-art approaches on diverse tasks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19947v1</guid></item><item><title>[cs updates on arXiv.org] Defensive Rebalancing for Automated Market Makers</title><link>https://arxiv.org/abs/2601.19950</link><description>arXiv:2601.19950v1 Announce Type: new 
Abstract: This paper introduces and analyzes \emph{defensive rebalancing}, a novel mechanism for protecting constant-function market makers (CFMMs) from value leakage due to arbitrage. A \emph{rebalancing} transfers assets directly from one CFMM's pool to another's, bypassing the CFMMs' standard trading protocols. In any \emph{arbitrage-prone} configuration, we prove there exists a rebalancing to an \textit{arbitrage-free} configuration that strictly increases some CFMMs' liquidities without reducing the liquidities of the others. Moreover, we prove that a configuration is arbitrage-free if and only if it is \emph{Pareto efficient} under rebalancing, meaning that any further direct asset transfers must decrease some CFMM's liquidity. We prove that for any log-concave trading function, including the ubiquitous constant product market maker, the search for an optimal, arbitrage-free rebalancing that maximizes global liquidity while ensuring no participant is worse off can be cast as a convex optimization problem with a unique, computationally tractable solution. We extend this framework to \emph{mixed rebalancing}, where a subset of participating CFMMs use a combination of direct transfers and standard trades to transition to an arbitrage-free configuration while harvesting arbitrage profits from non-participating CFMMs, and from price oracle market makers such as centralized exchanges. Our results provide a rigorous foundation for future AMM protocols that proactively defend liquidity providers against arbitrage.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19950v1</guid></item><item><title>[cs updates on arXiv.org] LTS-VoiceAgent: A Listen-Think-Speak Framework for Efficient Streaming Voice Interaction via Semantic Triggering and Incremental Reasoning</title><link>https://arxiv.org/abs/2601.19952</link><description>arXiv:2601.19952v1 Announce Type: new 
Abstract: Real-time voice agents face a dilemma: end-to-end models often lack deep reasoning, while cascaded pipelines incur high latency by executing ASR, LLM reasoning, and TTS strictly in sequence, unlike human conversation where listeners often start thinking before the speaker finishes. Since cascaded architectures remain the dominant choice for complex tasks, existing cascaded streaming strategies attempt to reduce this latency via mechanical segmentation (e.g., fixed chunks, VAD-based splitting) or speculative generation, but they frequently either break semantic units or waste computation on predictions that must be rolled back. To address these challenges, we propose LTS-VoiceAgent, a Listen-Think-Speak framework that explicitly separates when to think from how to reason incrementally. It features a Dynamic Semantic Trigger to detect meaningful prefixes, and a Dual-Role Stream Orchestrator that coordinates a background Thinker (for state maintenance) and a foreground Speaker (for speculative solving). This parallel design enables "thinking while speaking" without blocking responses. We also introduce a Pause-and-Repair benchmark containing natural disfluencies to stress-test streaming robustness. Experiments across VERA, Spoken-MQA, BigBenchAudio, and our benchmark show that LTS-VoiceAgent achieves a stronger accuracy-latency-efficiency trade-off than serial cascaded baselines and existing streaming strategies.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19952v1</guid></item><item><title>[cs updates on arXiv.org] Probabilistic Sensing: Intelligence in Data Sampling</title><link>https://arxiv.org/abs/2601.19953</link><description>arXiv:2601.19953v1 Announce Type: new 
Abstract: Extending the intelligence of sensors to the data-acquisition process - deciding whether to sample or not - can result in transformative energy-efficiency gains. However, making such a decision in a deterministic manner involves risk of losing information. Here we present a sensing paradigm that enables making such a decision in a probabilistic manner. The paradigm takes inspiration from the autonomous nervous system and employs a probabilistic neuron (p-neuron) driven by an analog feature extraction circuit. The response time of the system is on the order of microseconds, over-coming the sub-sampling-rate response time limit and enabling real-time intelligent autonomous activation of data-sampling. Validation experiments on active seismic survey data demonstrate lossless probabilistic data acquisition, with a normalized mean squared error of 0.41%, and 93% saving in the active operation time of the system and the number of generated samples.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19953v1</guid></item><item><title>[cs updates on arXiv.org] NeuroAI and Beyond</title><link>https://arxiv.org/abs/2601.19955</link><description>arXiv:2601.19955v1 Announce Type: new 
Abstract: Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possible promising new future avenues. Overall, we advocate for the development of NeuroAI, a type of Neuroscience-informed Artificial Intelligence that, we argue, has the potential for significantly improving the scope and efficiency of AI algorithms while simultaneously changing the way we understand biological neural computations. We include personal statements from several leading researchers on their diverse views of NeuroAI. Two Strength-Weakness-Opportunities-Threat (SWOT) analyses by researchers and trainees are appended that describe the benefits and risks offered by NeuroAI.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19955v1</guid></item><item><title>[cs updates on arXiv.org] MeanCache: From Instantaneous to Average Velocity for Accelerating Flow Matching Inference</title><link>https://arxiv.org/abs/2601.19961</link><description>arXiv:2601.19961v1 Announce Type: new 
Abstract: We present MeanCache, a training-free caching framework for efficient Flow Matching inference. Existing caching methods reduce redundant computation but typically rely on instantaneous velocity information (e.g., feature caching), which often leads to severe trajectory deviations and error accumulation under high acceleration ratios. MeanCache introduces an average-velocity perspective: by leveraging cached Jacobian--vector products (JVP) to construct interval average velocities from instantaneous velocities, it effectively mitigates local error accumulation. To further improve cache timing and JVP reuse stability, we develop a trajectory-stability scheduling strategy as a practical tool, employing a Peak-Suppressed Shortest Path under budget constraints to determine the schedule. Experiments on FLUX.1, Qwen-Image, and HunyuanVideo demonstrate that MeanCache achieves 4.12X and 4.56X and 3.59X acceleration, respectively, while consistently outperforming state-of-the-art caching baselines in generation quality. We believe this simple yet effective approach provides a new perspective for Flow Matching inference and will inspire further exploration of stability-driven acceleration in commercial-scale generative models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19961v1</guid></item><item><title>[cs updates on arXiv.org] Cross-Session Decoding of Neural Spiking Data via Task-Conditioned Latent Alignment</title><link>https://arxiv.org/abs/2601.19963</link><description>arXiv:2601.19963v1 Announce Type: new 
Abstract: Cross-session nonstationarity in neural activity recorded by implanted electrodes is a major challenge for invasive Brain-computer interfaces (BCIs), as decoders trained on data from one session often fail to generalize to subsequent sessions. This issue is further exacerbated in practice, as retraining or adapting decoders becomes particularly challenging when only limited data are available from a new session. To address this challenge, we propose a Task-Conditioned Latent Alignment framework (TCLA) for cross-session neural decoding. Building upon an autoencoder architecture, TCLA first learns a low-dimensional representation of neural dynamics from a source session with sufficient data. For target sessions with limited data, TCLA then aligns target latent representations to the source in a task-conditioned manner, enabling effective transfer of learned neural dynamics. We evaluate TCLA on the macaque motor and oculomotor center-out dataset. Compared to baseline methods trained solely on target-session data, TCLA consistently improves decoding performance across datasets and decoding settings, with gains in the coefficient of determination of up to 0.386 for y coordinate velocity decoding in a motor dataset. These results suggest that TCLA provides an effective strategy for transferring knowledge from source to target sessions, enabling more robust neural decoding under conditions with limited data.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19963v1</guid></item><item><title>[cs updates on arXiv.org] Achieving Productivity Gains with AI-based IDE features: A Journey at Google</title><link>https://arxiv.org/abs/2601.19964</link><description>arXiv:2601.19964v1 Announce Type: new 
Abstract: We discuss Google's journey in developing and refining two internal AI-based IDE features: code completion and natural-language-driven code transformation (Transform Code). We address challenges in latency, user experience and suggestion quality, all backed by rigorous experimentation. The article serves as an example of how to refine AI developer tools across the user interface, backend, and model layers, to deliver tangible productivity improvements in an enterprise setting.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19964v1</guid></item><item><title>[cs updates on arXiv.org] Perturbation-Induced Linearization: Constructing Unlearnable Data with Solely Linear Classifiers</title><link>https://arxiv.org/abs/2601.19967</link><description>arXiv:2601.19967v1 Announce Type: new 
Abstract: Collecting web data to train deep models has become increasingly common, raising concerns about unauthorized data usage. To mitigate this issue, unlearnable examples introduce imperceptible perturbations into data, preventing models from learning effectively. However, existing methods typically rely on deep neural networks as surrogate models for perturbation generation, resulting in significant computational costs. In this work, we propose Perturbation-Induced Linearization (PIL), a computationally efficient yet effective method that generates perturbations using only linear surrogate models. PIL achieves comparable or better performance than existing surrogate-based methods while reducing computational time dramatically. We further reveal a key mechanism underlying unlearnable examples: inducing linearization to deep models, which explains why PIL can achieve competitive results in a very short time. Beyond this, we provide an analysis about the property of unlearnable examples under percentage-based partial perturbation. Our work not only provides a practical approach for data protection but also offers insights into what makes unlearnable examples effective.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19967v1</guid></item><item><title>[cs updates on arXiv.org] What is the AGI in Offensive Security ?</title><link>https://arxiv.org/abs/2601.19968</link><description>arXiv:2601.19968v1 Announce Type: new 
Abstract: What is the AGI in Offensive Security? One can break it down into two questions : (1) any offensive security tasks could be reduced into symbolic language manipulation (language representation + reasoning), (2) powerful language model (LLM) are enough to "deal with" any symbolic language manipulation. This paper can formally model a target system as a state machine and a hacker as an interactive symbolic agent. And it shows that every interaction in an offensive engagement can be encoded as a finite string. This paper provides definitions, short lemmas, and open discussion.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19968v1</guid></item><item><title>[cs updates on arXiv.org] E2HiL: Entropy-Guided Sample Selection for Efficient Real-World Human-in-the-Loop Reinforcement Learning</title><link>https://arxiv.org/abs/2601.19969</link><description>arXiv:2601.19969v1 Announce Type: new 
Abstract: Human-in-the-loop guidance has emerged as an effective approach for enabling faster convergence in online reinforcement learning (RL) of complex real-world manipulation tasks. However, existing human-in-the-loop RL (HiL-RL) frameworks often suffer from low sample efficiency, requiring substantial human interventions to achieve convergence and thereby leading to high labor costs. To address this, we propose a sample-efficient real-world human-in-the-loop RL framework named \method, which requires fewer human intervention by actively selecting informative samples. Specifically, stable reduction of policy entropy enables improved trade-off between exploration and exploitation with higher sample efficiency. We first build influence functions of different samples on the policy entropy, which is efficiently estimated by the covariance of action probabilities and soft advantages of policies. Then we select samples with moderate values of influence functions, where shortcut samples that induce sharp entropy drops and noisy samples with negligible effect are pruned. Extensive experiments on four real-world manipulation tasks demonstrate that \method achieves a 42.1\% higher success rate while requiring 10.1\% fewer human interventions compared to the state-of-the-art HiL-RL method, validating its effectiveness. The project page providing code, videos, and mathematical formulations can be found at https://e2hil.github.io/.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19969v1</guid></item><item><title>[cs updates on arXiv.org] Benchmarking LLAMA Model Security Against OWASP Top 10 For LLM Applications</title><link>https://arxiv.org/abs/2601.19970</link><description>arXiv:2601.19970v1 Announce Type: new 
Abstract: As large language models (LLMs) move from research prototypes to enterprise systems, their security vulnerabilities pose serious risks to data privacy and system integrity. This study benchmarks various Llama model variants against the OWASP Top 10 for LLM Applications framework, evaluating threat detection accuracy, response safety, and computational overhead. Using the FABRIC testbed with NVIDIA A30 GPUs, we tested five standard Llama models and five Llama Guard variants on 100 adversarial prompts covering ten vulnerability categories. Our results reveal significant differences in security performance: the compact Llama-Guard-3-1B model achieved the highest detection rate of 76% with minimal latency (0.165s per test), whereas base models such as Llama-3.1-8B failed to detect threats (0% accuracy) despite longer inference times (0.754s). We observe an inverse relationship between model size and security effectiveness, suggesting that smaller, specialized models often outperform larger general-purpose ones in security tasks. Additionally, we provide an open-source benchmark dataset including adversarial prompts, threat labels, and attack metadata to support reproducible research in AI security, [1].</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19970v1</guid></item><item><title>[cs updates on arXiv.org] Just in time Informed Trees: Manipulability-Aware Asymptotically Optimized Motion Planning</title><link>https://arxiv.org/abs/2601.19972</link><description>arXiv:2601.19972v1 Announce Type: new 
Abstract: In high-dimensional robotic path planning, traditional sampling-based methods often struggle to efficiently identify both feasible and optimal paths in complex, multi-obstacle environments. This challenge is intensified in robotic manipulators, where the risk of kinematic singularities and self-collisions further complicates motion efficiency and safety. To address these issues, we introduce the Just-in-Time Informed Trees (JIT*) algorithm, an enhancement over Effort Informed Trees (EIT*), designed to improve path planning through two core modules: the Just-in-Time module and the Motion Performance module. The Just-in-Time module includes "Just-in-Time Edge," which dynamically refines edge connectivity, and "Just-in-Time Sample," which adjusts sampling density in bottleneck areas to enable faster initial path discovery. The Motion Performance module balances manipulability and trajectory cost through dynamic switching, optimizing motion control while reducing the risk of singularities. Comparative analysis shows that JIT* consistently outperforms traditional sampling-based planners across $\mathbb{R}^4$ to $\mathbb{R}^{16}$ dimensions. Its effectiveness is further demonstrated in single-arm and dual-arm manipulation tasks, with experimental results available in a video at https://youtu.be/nL1BMHpMR7c.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19972v1</guid></item><item><title>[cs updates on arXiv.org] BayPrAnoMeta: Bayesian Proto-MAML for Few-Shot Industrial Image Anomaly Detection</title><link>https://arxiv.org/abs/2601.19992</link><description>arXiv:2601.19992v1 Announce Type: new 
Abstract: Industrial image anomaly detection is a challenging problem owing to extreme class imbalance and the scarcity of labeled defective samples, particularly in few-shot settings. We propose BayPrAnoMeta, a Bayesian generalization of Proto-MAML for few-shot industrial image anomaly detection. Unlike existing Proto-MAML approaches that rely on deterministic class prototypes and distance-based adaptation, BayPrAnoMeta replaces prototypes with task-specific probabilistic normality models and performs inner-loop adaptation via a Bayesian posterior predictive likelihood. We model normal support embeddings with a Normal-Inverse-Wishart (NIW) prior, producing a Student-$t$ predictive distribution that enables uncertainty-aware, heavy-tailed anomaly scoring and is essential for robustness in extreme few-shot settings. We further extend BayPrAnoMeta to a federated meta-learning framework with supervised contrastive regularization for heterogeneous industrial clients and prove convergence to stationary points of the resulting nonconvex objective. Experiments on the MVTec AD benchmark demonstrate consistent and significant AUROC improvements over MAML, Proto-MAML, and PatchCore-based methods in few-shot anomaly detection settings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19992v1</guid></item><item><title>[cs updates on arXiv.org] New Adaptive Numerical Methods Based on Dual Formulation of Hyperbolic Conservation Laws</title><link>https://arxiv.org/abs/2601.20000</link><description>arXiv:2601.20000v1 Announce Type: new 
Abstract: In this paper, we propose an adaptive high-order method for hyperbolic systems of conservation laws. The proposed method is based on a dual formulation approach: Two numerical solutions, corresponding to conservative and nonconservative formulations of the same system, are evolved simultaneously. Since nonconservative schemes are known to produce nonphysical weak solutions near discontinuities, we exploit the difference between these two solutions to construct a smoothness indicator (SI). In smooth regions, the difference between the conservative and nonconservative solutions is of the same order as the truncation error of the underlying discretization, whereas in nonsmooth regions, it is ${\cal O}(1)$. We apply this idea to the Euler equations of gas dynamics and define the SI using differences in the momentum and pressure variables. This choice allows us to further distinguish neighborhoods of contact discontinuities from other nonsmooth parts of the computed solution. The resulting classification is used to adaptively select numerical discretizations. In the vicinities of contact discontinuities, we employ the low-dissipation central-upwind numerical flux and a second-order piecewise linear reconstruction with the slopes computed using an overcompressive SBM limiter. Elsewhere, we use an alternative weighted essentially non-oscillatory (A-WENO) framework with the central-upwind finite-volume numerical fluxes and either unlimited (in smooth regions) or Ai-WENO-Z (in the nonsmooth regions away from contact discontinuities) fifth-order interpolation. Numerical results for the one- and two-dimensional compressible Euler equations show that the proposed adaptive method improves both the computational efficiency and resolution of complex flow features compared with the non-adaptive fifth-order A-WENO scheme.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20000v1</guid></item><item><title>[cs updates on arXiv.org] OptAgent: an Agentic AI framework for Intelligent Building Operations</title><link>https://arxiv.org/abs/2601.20005</link><description>arXiv:2601.20005v1 Announce Type: new 
Abstract: The urgent need for building decarbonization calls for a paradigm shift in future autonomous building energy operation, from human-intensive engineering workflows toward intelligent agents that interact with physics-grounded digital environments. This study proposes an end-to-end agentic AI-enabled Physics-Informed Machine Learning (PIML) environment for scalable building energy modeling, simulation, control, and automation. The framework consists of (1) a modular and physics-consistent PIML digital environment spanning building thermal dynamics, Heating, Ventilation, and Air Conditioning (HVAC), and distributed energy resources (DER) for grid-interactive energy management; and (2) an agentic AI layer with 11 specialist agents and 72 Model Context Protocol (MCP) tools that enable end-to-end execution of multi-step energy analytics. A representative case study demonstrates multi-domain, multi-agent coordination for assessing how system and control upgrades affect energy use, operating cost, thermal comfort, and flexibility. In addition, a large-scale benchmark (about 4000 runs) systematically evaluates workflow performance in terms of accuracy, token consumption, execution time, and inference cost. The results quantify the impacts of intelligence mode design, model size, task complexity, and orchestrator-specialist coordination, and provide key lessons for building future agentic AI systems in real-world building energy applications. This work establishes a scalable, physics-grounded foundation for deploying agentic AI in decarbonized and grid-interactive building operations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20005v1</guid></item><item><title>[cs updates on arXiv.org] On the Effectiveness of LLM-Specific Fine-Tuning for Detecting AI-Generated Text</title><link>https://arxiv.org/abs/2601.20006</link><description>arXiv:2601.20006v1 Announce Type: new 
Abstract: The rapid progress of large language models has enabled the generation of text that closely resembles human writing, creating challenges for authenticity verification in education, publishing, and digital security. Detecting AI-generated text has therefore become a crucial technical and ethical issue. This paper presents a comprehensive study of AI-generated text detection based on large-scale corpora and novel training strategies. We introduce a 1-billion-token corpus of human-authored texts spanning multiple genres and a 1.9-billion-token corpus of AI-generated texts produced by prompting a variety of LLMs across diverse domains. Using these resources, we develop and evaluate numerous detection models and propose two novel training paradigms: Per LLM and Per LLM family fine-tuning. Across a 100-million-token benchmark covering 21 large language models, our best fine-tuned detector achieves up to $99.6\%$ token-level accuracy, substantially outperforming existing open-source baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20006v1</guid></item><item><title>[cs updates on arXiv.org] LinguaMap: Which Layers of LLMs Speak Your Language and How to Tune Them?</title><link>https://arxiv.org/abs/2601.20009</link><description>arXiv:2601.20009v1 Announce Type: new 
Abstract: Despite multilingual pretraining, large language models often struggle with non-English tasks, particularly in language control, the ability to respond in the intended language. We identify and characterize two key failure modes: the multilingual transfer bottleneck (correct language, incorrect task response) and the language consistency bottleneck (correct task response, wrong language). To systematically surface these issues, we design a four-scenario evaluation protocol spanning MMLU, MGSM, and XQuAD benchmarks. To probe these issues with interpretability, we extend logit lens analysis to track language probabilities layer by layer and compute cross-lingual semantic similarity of hidden states. The results reveal a three-phase internal structure: early layers align inputs into a shared semantic space, middle layers perform task reasoning, and late layers drive language-specific generation. Guided by these insights, we introduce selective fine-tuning of only the final layers responsible for language control. On Qwen-3-32B and Bloom-7.1B, this method achieves over 98 percent language consistency across six languages while fine-tuning only 3-5 percent of parameters, without sacrificing task accuracy. Importantly, this result is nearly identical to that of full-scope fine-tuning (for example, above 98 percent language consistency for both methods across all prompt scenarios) but uses a fraction of the computational resources. To the best of our knowledge, this is the first approach to leverage layer-localization of language control for efficient multilingual adaptation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20009v1</guid></item><item><title>[cs updates on arXiv.org] Treating symptoms or root causes: How does information about causal mechanisms affect interventions?</title><link>https://arxiv.org/abs/2601.20010</link><description>arXiv:2601.20010v1 Announce Type: new 
Abstract: When deciding how to solve complex problems, it seems important not only to know whether an intervention is helpful but also to understand why. Therefore, the present study investigated whether explicit information about causal mechanisms enables people to distinguish between multiple interventions. It was hypothesised that mechanism information helps them appreciate indirect interventions that treat the root causes of a problem instead of just fixing its symptoms. This was investigated in an experimental hoof trimming scenario in which participants evaluated various interventions. To do so, they received causal diagrams with different types of causal information and levels of mechanistic detail. While detailed mechanism information and its embedding in the context of other influences made participants less sceptical towards indirect interventions, the effects were quite small. Moreover, it did not mitigate participants' robust preference for interventions that only fix a problem's symptoms. Taken together, the findings suggest that in order to help people choose sustainable interventions, it is not sufficient to make information about causal mechanisms available.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20010v1</guid></item><item><title>[cs updates on arXiv.org] Least-Squares Neural Network (LSNN) Method for Scalar Hyperbolic Partial Differential Equations</title><link>https://arxiv.org/abs/2601.20013</link><description>arXiv:2601.20013v1 Announce Type: new 
Abstract: This chapter offers a comprehensive introduction to the least-squares neural network (LSNN) method introduced in [14,16], for solving scalar first-order hyperbolic partial differential equations, specifically linear advection-reaction equations and nonlinear hyperbolic conservation laws. The LSNN method is built on an equivalent least-squares formulation of the underlying problem on an admissible solution set that accommodates discontinuous solutions. It employs ReLU neural networks (in place of finite elements) as the approximating functions, uses a carefully designed physics-preserved numerical differentiation, and avoids penalization techniques such as artificial viscosity, entropy condition, and/or total variation. This approach captures shock features in the solution without oscillations or overshooting. Efficiently and reliably solving the resulting non-convex optimization problem posed by the LSNN method remains an open challenge. This chapter concludes with a brief discussion on application of the structure-guided Gauss-Newton (SgGN) method developed recently in [21] for solving shallow NN approximation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20013v1</guid></item><item><title>[cs updates on arXiv.org] Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning</title><link>https://arxiv.org/abs/2601.20014</link><description>arXiv:2601.20014v1 Announce Type: new 
Abstract: Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\texttt{Sat}/\texttt{Viol}/\texttt{Unk}) and resolves unknowns via (i) targeted self-queries to an oracle/user or (ii) \emph{bridging} hypotheses that establish the missing condition through an additional action. SQ-BCP performs bidirectional search and invokes a pullback-based verifier as a categorical certificate of goal compatibility, while using distance-based scores only for ranking and pruning. We prove that when the verifier succeeds and hard constraints pass deterministic checks, accepted plans are compatible with goal requirements; under bounded branching and finite resolution depth, SQ-BCP finds an accepting plan when one exists. Across WikiHow and RecipeNLG tasks with withheld preconditions, SQ-BCP reduces resource-violation rates to \textbf{14.9\%} and \textbf{5.8\%} (vs.\ \textbf{26.0\%} and \textbf{15.7\%} for the best baseline), while maintaining competitive reference quality.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20014v1</guid></item><item><title>[cs updates on arXiv.org] DBTuneSuite: An Extendible Experimental Suite to Test the Time Performance of Multi-layer Tuning Options on Database Management Systems</title><link>https://arxiv.org/abs/2601.20015</link><description>arXiv:2601.20015v1 Announce Type: new 
Abstract: DBTuneSuite is a suite of experiments on four widely deployed free database systems to test their performance under various query/upsert loads and under various tuning options. The suite provides: (i) scripts to generate data and to install and run tests, making it expandable to other tests and systems; (ii) suggestions of which systems work best for which query types; and (iii) quantitative evidence that tuning options widely used in practice can behave very differently across systems. This paper is most useful for database system engineers, advanced database users and troubleshooters, and students.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20015v1</guid></item><item><title>[cs updates on arXiv.org] Fueling Volunteer Growth: the case of Wikipedia Administrators</title><link>https://arxiv.org/abs/2601.20016</link><description>arXiv:2601.20016v1 Announce Type: new 
Abstract: Wikipedia administrators are vital to the platform's success, performing over a million administrative actions annually. This multi-method study systematically analyzes adminship across 284 Wikipedia languages since 2018, revealing a critical two-sided trend: while over half of all Wikipedias show a net increase in administrators, almost two-thirds of highly active Wikipedias face decline. Our analysis, drawing from large-scale adminship log analysis, over 3000 surveys, and 12 interviews, reveals this decline is primarily driven by insufficient recruitment, not unusual attrition. We identify key barriers for potential administrators, including limited awareness, ambiguous requirements, a demanding selection process, and low initial interest. Recognizing that current administrators remain highly motivated and engaged, we propose actionable recommendations to strengthen recruitment pipelines and fuel Wikipedia administrator growth, crucial for Wikipedia's long-term sustainability.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20016v1</guid></item><item><title>[cs updates on arXiv.org] Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic Constraints</title><link>https://arxiv.org/abs/2601.20021</link><description>arXiv:2601.20021v1 Announce Type: new 
Abstract: Natural-language planning often involves vague predicates (e.g., suitable substitute, stable enough) whose satisfaction is inherently graded. Existing category-theoretic planners provide compositional structure and pullback-based hard-constraint verification, but treat applicability as crisp, forcing thresholding that collapses meaningful distinctions and cannot track quality degradation across multi-step plans. We propose Fuzzy Category-theoretic Planning (FCP), which annotates each action (morphism) with a degree in [0,1], composes plan quality via a t-norm Lukasiewicz, and retains crisp executability checks via pullback verification. FCP grounds graded applicability from language using an LLM with k-sample median aggregation and supports meeting-in-the-middle search using residuum-based backward requirements. We evaluate on (i) public PDDL3 preference/oversubscription benchmarks and (ii) RecipeNLG-Subs, a missing-substitute recipe-planning benchmark built from RecipeNLG with substitution candidates from Recipe1MSubs and FoodKG. FCP improves success and reduces hard-constraint violations on RecipeNLG-Subs compared to LLM-only and ReAct-style baselines, while remaining competitive with classical PDDL3 planners.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20021v1</guid></item><item><title>[cs updates on arXiv.org] Quick Change Detection in Discrete-Time in Presence of a Covert Adversary</title><link>https://arxiv.org/abs/2601.20022</link><description>arXiv:2601.20022v1 Announce Type: new 
Abstract: We study the problem of covert quickest change detection in a discrete-time setting, where a sequence of observations undergoes a distributional change at an unknown time. Unlike classical formulations, we consider a covert adversary who has knowledge of the detector's false alarm constraint parameter $\gamma$ and selects a stationary post-change distribution that depends on it, seeking to remain undetected for as long as possible. Building on the theoretical foundations of the CuSum procedure, we rigorously characterize the asymptotic behavior of the average detection delay (ADD) and the average time to false alarm (AT2FA) when the post-change distribution converges to the pre-change distribution as $\gamma \to \infty$. Our analysis establishes exact asymptotic expressions for these quantities, extending and refining classical results that no longer hold in this regime. We identify the critical scaling laws governing covert behavior and derive explicit conditions under which an adversary can maintain covertness, defined by ADD = $\Theta(\gamma)$, whereas in the classical setting, ADD grows only as $\mathcal{O}(\log \gamma)$. In particular, for Gaussian and Exponential models under adversarial perturbations of their respective parameters, we asymptotically characterize ADD as a function of the Kullback--Leibler divergence between the pre- and post-change distributions and $\gamma$.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20022v1</guid></item><item><title>[cs updates on arXiv.org] Semantic Uncertainty Quantification of Hallucinations in LLMs: A Quantum Tensor Network Based Method</title><link>https://arxiv.org/abs/2601.20026</link><description>arXiv:2601.20026v1 Announce Type: new 
Abstract: Large language models (LLMs) exhibit strong generative capabilities but remain vulnerable to confabulations, fluent yet unreliable outputs that vary arbitrarily even under identical prompts. Leveraging a quantum tensor network based pipeline, we propose a quantum physics inspired uncertainty quantification framework that accounts for aleatoric uncertainty in token sequence probability for semantic equivalence based clustering of LLM generations. This offers a principled and interpretable scheme for hallucination detection. We further introduce an entropy maximization strategy that prioritizes high certainty, semantically coherent outputs and highlights entropy regions where LLM decisions are likely to be unreliable, offering practical guidelines for when human oversight is warranted. We evaluate the robustness of our scheme under different generation lengths and quantization levels, dimensions overlooked in prior studies, demonstrating that our approach remains reliable even in resource constrained deployments. A total of 116 experiments on TriviaQA, NQ, SVAMP, and SQuAD across multiple architectures including Mistral-7B, Mistral-7B-instruct, Falcon-rw-1b, LLaMA-3.2-1b, LLaMA-2-13b-chat, LLaMA-2-7b-chat, LLaMA-2-13b, and LLaMA-2-7b show consistent improvements in AUROC and AURAC over state of the art baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20026v1</guid></item><item><title>[cs updates on arXiv.org] Decomposing multimodal embedding spaces with group-sparse autoencoders</title><link>https://arxiv.org/abs/2601.20028</link><description>arXiv:2601.20028v1 Announce Type: new 
Abstract: The Linear Representation Hypothesis asserts that the embeddings learned by neural networks can be understood as linear combinations of features corresponding to high-level concepts. Based on this ansatz, sparse autoencoders (SAEs) have recently become a popular method for decomposing embeddings into a sparse combination of linear directions, which have been shown empirically to often correspond to human-interpretable semantics. However, recent attempts to apply SAEs to multimodal embedding spaces (such as the popular CLIP embeddings for image/text data) have found that SAEs often learn "split dictionaries", where most of the learned sparse features are essentially unimodal, active only for data of a single modality. In this work, we study how to effectively adapt SAEs for the setting of multimodal embeddings while ensuring multimodal alignment. We first argue that the existence of a split dictionary decomposition on an aligned embedding space implies the existence of a non-split dictionary with improved modality alignment. Then, we propose a new SAE-based approach to multimodal embedding decomposition using cross-modal random masking and group-sparse regularization. We apply our method to popular embeddings for image/text (CLIP) and audio/text (CLAP) data and show that, compared to standard SAEs, our approach learns a more multimodal dictionary while reducing the number of dead neurons and improving feature semanticity. We finally demonstrate how this improvement in alignment of concepts between modalities can enable improvements in the interpretability and control of cross-modal tasks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20028v1</guid></item><item><title>[cs updates on arXiv.org] Delta Fair Sharing: Performance Isolation for Multi-Tenant Storage Systems</title><link>https://arxiv.org/abs/2601.20030</link><description>arXiv:2601.20030v1 Announce Type: new 
Abstract: Modern storage systems, often deployed to support multiple tenants in the cloud, must provide performance isolation. Unfortunately, traditional approaches such as fair sharing do not provide performance isolation for storage systems, because their resources (e.g., write buffers and read caches) exhibit high preemption delays. These delays lead to unacceptable spikes in client tail latencies, as clients may be forced to wait arbitrarily long to receive their fair share of resources.
  We introduce Delta Fair Sharing, a family of algorithms for sharing resources with high preemption delays. These algorithms satisfy two key properties: $\delta$-fairness, which bounds a client's delay in receiving its fair share of resources to $\delta$ time units, and $\delta$-Pareto-efficiency, which allocates unused resources to clients with unmet demand. Together, these properties capture resource-acquisition delays end-to-end, bound well-behaved clients' tail-latency spikes to $\delta$ time units, and ensure high utilization. We implement such algorithms in FAIRDB, an extension of RocksDB. Our evaluation shows that FAIRDB isolates well-behaved clients from high-demand workloads better than state-of-the-art alternatives.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20030v1</guid></item><item><title>[cs updates on arXiv.org] TAIGR: Towards Modeling Influencer Content on Social Media via Structured, Pragmatic Inference</title><link>https://arxiv.org/abs/2601.20032</link><description>arXiv:2601.20032v1 Announce Type: new 
Abstract: Health influencers play a growing role in shaping public beliefs, yet their content is often conveyed through conversational narratives and rhetorical strategies rather than explicit factual claims. As a result, claim-centric verification methods struggle to capture the pragmatic meaning of influencer discourse. In this paper, we propose TAIGR (Takeaway Argumentation Inference with Grounded References), a structured framework designed to analyze influencer discourse, which operates in three stages: (1) identifying the core influencer recommendation--takeaway; (2) constructing an argumentation graph that captures influencer justification for the takeaway; (3) performing factor graph-based probabilistic inference to validate the takeaway. We evaluate TAIGR on a content validation task over influencer video transcripts on health, showing that accurate validation requires modeling the discourse's pragmatic and argumentative structure rather than treating transcripts as flat collections of claims.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20032v1</guid></item><item><title>[cs updates on arXiv.org] Computational aspects of disks enclosing many points</title><link>https://arxiv.org/abs/2601.20036</link><description>arXiv:2601.20036v1 Announce Type: new 
Abstract: Let $S$ be a set of $n$ points in the plane. We present several different algorithms for finding a pair of points in $S$ such that any disk that contains that pair must contain at least $cn$ points of $S$, for some constant $c&gt;0$. The first is a randomized algorithm that finds a pair in $O(n\log n)$ expected time for points in general position, and $c = 1/2-\sqrt{(1+2\alpha)/12}$, for any $0&lt;\alpha&lt;1$. The second algorithm, also for points in general position, takes quadratic time, but the constant $c$ is improved to $1/2-1/{\sqrt{12}} \approx 1/4.7$. The second algorithm can also be used as a subroutine to find the pair that maximizes the number of points inside any disk that contains the pair, in $O(n^2\log n)$ time. We also consider variants of the problem. When the set $S$ is in convex position, we present an algorithm that finds in linear time a pair of points such that any disk through them contains at least $n/3$ points of $ S $. For the variant where we are only interested in finding a pair such that the diametral disk of that pair contains many points, we also have a linear-time algorithm that finds a disk with at least $n/3$ points of $S$. Finally, we present a generalization of the first two algorithms to the case where the set $S$ of points is coloured using two colours. We also consider adapting these algorithms to solve the same problems when $S$ is a set of points inside of a simple polygon $P$, with the notion of a disk replaced by that of a geodesic disk.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20036v1</guid></item><item><title>[cs updates on arXiv.org] Structural Compositional Function Networks: Interpretable Functional Compositions for Tabular Discovery</title><link>https://arxiv.org/abs/2601.20037</link><description>arXiv:2601.20037v1 Announce Type: new 
Abstract: Despite the ubiquity of tabular data in high-stakes domains, traditional deep learning architectures often struggle to match the performance of gradient-boosted decision trees while maintaining scientific interpretability. Standard neural networks typically treat features as independent entities, failing to exploit the inherent manifold structural dependencies that define tabular distributions. We propose Structural Compositional Function Networks (StructuralCFN), a novel architecture that imposes a Relation-Aware Inductive Bias via a differentiable structural prior. StructuralCFN explicitly models each feature as a mathematical composition of its counterparts through Differentiable Adaptive Gating, which automatically discovers the optimal activation physics (e.g., attention-style filtering vs. inhibitory polarity) for each relationship. Our framework enables Structured Knowledge Integration, allowing domain-specific relational priors to be injected directly into the architecture to guide discovery. We evaluate StructuralCFN across a rigorous 10-fold cross-validation suite on 18 benchmarks, demonstrating statistically significant improvements (p &lt; 0.05) on scientific and clinical datasets (e.g., Blood Transfusion, Ozone, WDBC). Furthermore, StructuralCFN provides Intrinsic Symbolic Interpretability: it recovers the governing "laws" of the data manifold as human-readable mathematical expressions while maintaining a compact parameter footprint (300--2,500 parameters) that is over an order of magnitude (10x--20x) smaller than standard deep baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20037v1</guid></item><item><title>[cs updates on arXiv.org] Node-Weighted Multicut in Planar Digraphs</title><link>https://arxiv.org/abs/2601.20038</link><description>arXiv:2601.20038v1 Announce Type: new 
Abstract: Kawarabayashi and Sidiropoulos [KS22] obtained an $O(\log^2 n)$-approximation algorithm for Multicut in planar digraphs via a natural LP relaxation, which also establishes a corresponding upper bound on the multicommodity flow-cut gap. Their result is in contrast to a lower bound of $\tilde{\Omega}(n^{1/7})$ on the flow-cut gap for general digraphs due to Chuzhoy and Khanna [CK09]. We extend the algorithm and analysis in [KS22] to the node-weighted Multicut problem. Unlike in general digraphs, node-weighted problems cannot be reduced to edge-weighted problems in a black box fashion due to the planarity restriction. We use the node-weighted problem as a vehicle to accomplish two additional goals: (i) to obtain a deterministic algorithm (the algorithm in [KS22] is randomized), and (ii) to simplify and clarify some aspects of the algorithm and analysis from [KS22]. The Multicut result, via a standard technique, implies an approximation for the Nonuniform Sparsest Cut problem with an additional logarithmic factor loss.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20038v1</guid></item><item><title>[cs updates on arXiv.org] Hypergraph Samplers: Typical and Worst Case Behavior</title><link>https://arxiv.org/abs/2601.20039</link><description>arXiv:2601.20039v1 Announce Type: new 
Abstract: We study the utility and limitations of using $k$-uniform hypergraphs $H = ([n], E)$ ($n \ge \mathrm{poly}(k)$) in the context of error reduction for randomized algorithms for decision problems with one- or two-sided error. Our error reduction idea is sampling a uniformly random hyperedge of $H$, and repeating the algorithm $k$ times using the hyperedge vertices as seeds. This is a general paradigm, which captures every pseudorandom method generating $k$ seeds without repetition. We show two results which imply a gap between the typical and the worst-case behavior of using $H$ for error-reduction.
  First, in the context of one-sided error reduction, if using a random hyperedge of $H$ decreases the error probability from $p$ to $p^k + \epsilon$, then $H$ cannot have too few edges, i.e., $|E| = \Omega(n k^{-1} \epsilon^{-1})$. Thus, the number of random bits needed for reducing the error from $p$ to $p^k + \epsilon$ cannot be reduced below $\lg n+\lg(\epsilon^{-1})-\lg k+O(1)$. This is also true for hypergraphs of average uniformity $k$. Our result implies new lower bounds for dispersers and vertex-expanders.
  Second, if the vertex degrees are reasonably distributed, we show that in a $(1-o(1))$-fraction of the cases, choosing $k$ pseudorandom seeds using $H$ will reduce the error probability to at most $o(1)$ above the error probability of using $k$ IID seeds, for both algorithms with one- or two-sided error. Thus, despite our lower bound, for a $(1-o(1))$-fraction of randomized algorithms (and inputs) for decision problems, the advantage of using IID samples over samples obtained from a uniformly random edge of a reasonable hypergraph is negligible. A similar statement holds true for randomized algorithms with two-sided error.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20039v1</guid></item><item><title>[cs updates on arXiv.org] CiMRAG: Cim-Aware Domain-Adaptive and Noise-Resilient Retrieval-Augmented Generation for Edge-Based LLMs</title><link>https://arxiv.org/abs/2601.20041</link><description>arXiv:2601.20041v1 Announce Type: new 
Abstract: Personalized virtual assistants powered by large language models (LLMs) on edge devices are attracting growing attention, with Retrieval-Augmented Generation (RAG) emerging as a key method for personalization by retrieving relevant profile data and generating tailored responses. However, deploying RAG on edge devices faces efficiency hurdles due to the rapid growth of profile data, such as user-LLM interactions and recent updates. While Computing-in-Memory (CiM) architectures mitigate this bottleneck by eliminating data movement between memory and processing units via in-situ operations, they are susceptible to environmental noise that can degrade retrieval precision. This poses a critical issue in dynamic, multi-domain edge-based scenarios (e.g., travel, medicine, and law) where both accuracy and adaptability are paramount. To address these challenges, we propose Task-Oriented Noise-resilient Embedding Learning (TONEL), a framework that improves noise robustness and domain adaptability for RAG in noisy edge environments. TONEL employs a noise-aware projection model to learn task-specific embeddings compatible with CiM hardware constraints, enabling accurate retrieval under noisy conditions. Extensive experiments conducted on personalization benchmarks demonstrate the effectiveness and practicality of our methods relative to strong baselines, especially in task-specific noisy scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20041v1</guid></item><item><title>[cs updates on arXiv.org] Regime-Adaptive Bayesian Optimization via Dirichlet Process Mixtures of Gaussian Processes</title><link>https://arxiv.org/abs/2601.20043</link><description>arXiv:2601.20043v1 Announce Type: new 
Abstract: Standard Bayesian Optimization (BO) assumes uniform smoothness across the search space an assumption violated in multi-regime problems such as molecular conformation search through distinct energy basins or drug discovery across heterogeneous molecular scaffolds. A single GP either oversmooths sharp transitions or hallucinates noise in smooth regions, yielding miscalibrated uncertainty. We propose RAMBO, a Dirichlet Process Mixture of Gaussian Processes that automatically discovers latent regimes during optimization, each modeled by an independent GP with locally-optimized hyperparameters. We derive collapsed Gibbs sampling that analytically marginalizes latent functions for efficient inference, and introduce adaptive concentration parameter scheduling for coarse-to-fine regime discovery. Our acquisition functions decompose uncertainty into intra-regime and inter-regime components. Experiments on synthetic benchmarks and real-world applications, including molecular conformer optimization, virtual screening for drug discovery, and fusion reactor design, demonstrate consistent improvements over state-of-the-art baselines on multi-regime objectives.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20043v1</guid></item><item><title>[cs updates on arXiv.org] Externally Validated Longitudinal GRU Model for Visit-Level 180-Day Mortality Risk in Metastatic Castration-Resistant Prostate Cancer</title><link>https://arxiv.org/abs/2601.20046</link><description>arXiv:2601.20046v1 Announce Type: new 
Abstract: Metastatic castration-resistant prostate cancer (mCRPC) is a highly aggressive disease with poor prognosis and heterogeneous treatment response. In this work, we developed and externally validated a visit-level 180-day mortality risk model using longitudinal data from two Phase III cohorts (n=526 and n=640). Only visits with observable 180-day outcomes were labeled; right-censored cases were excluded from analysis. We compared five candidate architectures: Long Short-Term Memory, Gated Recurrent Unit (GRU), Cox Proportional Hazards, Random Survival Forest (RSF), and Logistic Regression. For each dataset, we selected the smallest risk-threshold that achieved an 85% sensitivity floor. The GRU and RSF models showed high discrimination capabilities initially (C-index: 87% for both). In external validation, the GRU obtained a higher calibration (slope: 0.93; intercept: 0.07) and achieved an PR-AUC of 0.87. Clinical impact analysis showed a median time-in-warning of 151.0 days for true positives (59.0 days for false positives) and 18.3 alerts per 100 patient-visits. Given late-stage frailty or cachexia and hemodynamic instability, permutation importance ranked BMI and systolic blood pressure as the strongest associations. These results suggest that longitudinal routine clinical markers can estimate short-horizon mortality risk in mCRPC and support proactive care planning over a multi-month window.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20046v1</guid></item><item><title>[cs updates on arXiv.org] Insight Agents: An LLM-Based Multi-Agent System for Data Insights</title><link>https://arxiv.org/abs/2601.20048</link><description>arXiv:2601.20048v1 Announce Type: new 
Abstract: Today, E-commerce sellers face several key challenges, including difficulties in discovering and effectively utilizing available programs and tools, and struggling to understand and utilize rich data from various tools. We therefore aim to develop Insight Agents (IA), a conversational multi-agent Data Insight system, to provide E-commerce sellers with personalized data and business insights through automated information retrieval. Our hypothesis is that IA will serve as a force multiplier for sellers, thereby driving incremental seller adoption by reducing the effort required and increase speed at which sellers make good business decisions. In this paper, we introduce this novel LLM-backed end-to-end agentic system built on a plan-and-execute paradigm and designed for comprehensive coverage, high accuracy, and low latency. It features a hierarchical multi-agent structure, consisting of manager agent and two worker agents: data presentation and insight generation, for efficient information retrieval and problem-solving. We design a simple yet effective ML solution for manager agent that combines Out-of-Domain (OOD) detection using a lightweight encoder-decoder model and agent routing through a BERT-based classifier, optimizing both accuracy and latency. Within the two worker agents, a strategic planning is designed for API-based data model that breaks down queries into granular components to generate more accurate responses, and domain knowledge is dynamically injected to to enhance the insight generator. IA has been launched for Amazon sellers in US, which has achieved high accuracy of 90% based on human evaluation, with latency of P90 below 15s.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20048v1</guid></item><item><title>[cs updates on arXiv.org] A mixed virtual element discretization for the generalized Oseen problem</title><link>https://arxiv.org/abs/2601.20050</link><description>arXiv:2601.20050v1 Announce Type: new 
Abstract: In this paper we introduce a mixed virtual element method to approximate the solution for the two dimensional generalized Oseen problem. We introduce the pseudostress as an additional unknown, which allows to eliminate the pressure from the system; the pressure can be recovered via a post-process of the pseudostress tensor. We prove existence and uniqueness of the continuous solution via a fixed point argument. Under standard mesh assumptions, we develop a virtual element method to approximate both the tensor and the velocity field, and we show that it is stable. Furthermore, we provide a priori error estimates for the method and validate them through a series of numerical tests using different polygonal meshes.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20050v1</guid></item><item><title>[cs updates on arXiv.org] Size Matters: Reconstructing Real-Scale 3D Models from Monocular Images for Food Portion Estimation</title><link>https://arxiv.org/abs/2601.20051</link><description>arXiv:2601.20051v1 Announce Type: new 
Abstract: The rise of chronic diseases related to diet, such as obesity and diabetes, emphasizes the need for accurate monitoring of food intake. While AI-driven dietary assessment has made strides in recent years, the ill-posed nature of recovering size (portion) information from monocular images for accurate estimation of ``how much did you eat?'' is a pressing challenge. Some 3D reconstruction methods have achieved impressive geometric reconstruction but fail to recover the crucial real-world scale of the reconstructed object, limiting its usage in precision nutrition. In this paper, we bridge the gap between 3D computer vision and digital health by proposing a method that recovers a true-to-scale 3D reconstructed object from a monocular image. Our approach leverages rich visual features extracted from models trained on large-scale datasets to estimate the scale of the reconstructed object. This learned scale enables us to convert single-view 3D reconstructions into true-to-life, physically meaningful models. Extensive experiments and ablation studies on two publicly available datasets show that our method consistently outperforms existing techniques, achieving nearly a 30% reduction in mean absolute volume-estimation error, showcasing its potential to enhance the domain of precision nutrition. Code: https://gitlab.com/viper-purdue/size-matters</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20051v1</guid></item><item><title>[cs updates on arXiv.org] Game-Theoretic Autonomous Driving: A Graphs of Convex Sets Approach</title><link>https://arxiv.org/abs/2601.20054</link><description>arXiv:2601.20054v1 Announce Type: new 
Abstract: Multi-vehicle autonomous driving couples strategic interaction with hybrid (discrete-continuous) maneuver planning under shared safety constraints. We introduce IBR-GCS, an Iterative Best Response (IBR) planning approach based on the Graphs of Convex Sets (GCS) framework that models highway driving as a generalized noncooperative game. IBR-GCS integrates combinatorial maneuver reasoning, trajectory planning, and game-theoretic interaction within a unified framework. The key novelty is a vehicle-specific, strategy-dependent GCS construction. Specifically, at each best-response update, each vehicle builds its own graph conditioned on the current strategies of the other vehicles, with vertices representing lane-specific, time-varying, convex, collision-free regions and edges encoding dynamically feasible transitions. This yields a shortest-path problem in GCS for each best-response step, which admits an efficient convex relaxation that can be solved using convex optimization tools without exhaustive discrete tree search. We then apply an iterative best-response scheme in which vehicles update their trajectories sequentially and provide conditions under which the resulting inexact updates converge to an approximate generalized Nash equilibrium. Simulation results across multi-lane, multi-vehicle scenarios demonstrate that IBR-GCS produces safe trajectories and strategically consistent interactive behaviors.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20054v1</guid></item><item><title>[cs updates on arXiv.org] VERGE: Formal Refinement and Guidance Engine for Verifiable LLM Reasoning</title><link>https://arxiv.org/abs/2601.20055</link><description>arXiv:2601.20055v1 Announce Type: new 
Abstract: Despite the syntactic fluency of Large Language Models (LLMs), ensuring their logical correctness in high-stakes domains remains a fundamental challenge. We present a neurosymbolic framework that combines LLMs with SMT solvers to produce verification-guided answers through iterative refinement. Our approach decomposes LLM outputs into atomic claims, autoformalizes them into first-order logic, and verifies their logical consistency using automated theorem proving. We introduce three key innovations: (1) multi-model consensus via formal semantic equivalence checking to ensure logic-level alignment between candidates, eliminating the syntactic bias of surface-form metrics, (2) semantic routing that directs different claim types to appropriate verification strategies: symbolic solvers for logical claims and LLM ensembles for commonsense reasoning, and (3) precise logical error localization via Minimal Correction Subsets (MCS), which pinpoint the exact subset of claims to revise, transforming binary failure signals into actionable feedback. Our framework classifies claims by their logical status and aggregates multiple verification signals into a unified score with variance-based penalty. The system iteratively refines answers using structured feedback until acceptance criteria are met or convergence is achieved. This hybrid approach delivers formal guarantees where possible and consensus verification elsewhere, advancing trustworthy AI. With the GPT-OSS-120B model, VERGE demonstrates an average performance uplift of 18.7% at convergence across a set of reasoning benchmarks compared to single-pass approaches.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20055v1</guid></item><item><title>[cs updates on arXiv.org] How many times can two minimum spanning trees cross?</title><link>https://arxiv.org/abs/2601.20060</link><description>arXiv:2601.20060v1 Announce Type: new 
Abstract: Let $P$ be a generic set of $n$ points in the plane, and let $P=R\cup B$ be a coloring of $P$ in two colors. We are interested in the number of crossings between the minimum spanning trees (MSTs) of $R$ and $B$, denoted by $\crossAB(R,B)$. We define the \emph{bicolored MST crossing number} of $P$, denoted by $\cross(P)$, as $\cross(P) = \max_{P= R\cup B}(\crossAB(R,B))$. We prove a linear upper bound for $\cross(P)$ when $P$ is generic. If $P$ is dense or in convex position, we provide linear lower bounds. Lastly, if $P$ is chosen uniformly at random from the unit square and is colored uniformly at random, we prove that the expected value of $\crossAB(R,B)$ is linear.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20060v1</guid></item><item><title>[cs updates on arXiv.org] Primitive-Driven Acceleration of Hyperdimensional Computing for Real-Time Image Classification</title><link>https://arxiv.org/abs/2601.20061</link><description>arXiv:2601.20061v1 Announce Type: new 
Abstract: Hyperdimensional Computing (HDC) represents data using extremely high-dimensional, low-precision vectors, termed hypervectors (HVs), and performs learning and inference through lightweight, noise-tolerant operations. However, the high dimensionality, sparsity, and repeated data movement involved in HDC make these computations difficult to accelerate efficiently on conventional processors. As a result, executing core HDC operations: binding, permutation, bundling, and similarity search: on CPUs or GPUs often leads to suboptimal utilization, memory bottlenecks, and limits on real-time performance. In this paper, our contributions are two-fold. First, we develop an image-encoding algorithm that, similar in spirit to convolutional neural networks, maps local image patches to hypervectors enriched with spatial information. These patch-level hypervectors are then merged into a global representation using the fundamental HDC operations, enabling spatially sensitive and robust image encoding. This encoder achieves 95.67% accuracy on MNIST and 85.14% on Fashion-MNIST, outperforming prior HDC-based image encoders. Second, we design an end-to-end accelerator that implements these compute operations on an FPGA through a pipelined architecture that exploits parallelism both across the hypervector dimensionality and across the set of image patches. Our Alveo U280 implementation delivers 0.09ms inference latency, achieving up to 1300x and 60x speedup over state-of-the-art CPU and GPU baselines, respectively.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20061v1</guid></item><item><title>[cs updates on arXiv.org] DiSa: Saliency-Aware Foreground-Background Disentangled Framework for Open-Vocabulary Semantic Segmentation</title><link>https://arxiv.org/abs/2601.20064</link><description>arXiv:2601.20064v1 Announce Type: new 
Abstract: Open-vocabulary semantic segmentation aims to assign labels to every pixel in an image based on text labels. Existing approaches typically utilize vision-language models (VLMs), such as CLIP, for dense prediction. However, VLMs, pre-trained on image-text pairs, are biased toward salient, object-centric regions and exhibit two critical limitations when adapted to segmentation: (i) Foreground Bias, which tends to ignore background regions, and (ii) Limited Spatial Localization, resulting in blurred object boundaries. To address these limitations, we introduce DiSa, a novel saliency-aware foreground-background disentangled framework. By explicitly incorporating saliency cues in our designed Saliency-aware Disentanglement Module (SDM), DiSa separately models foreground and background ensemble features in a divide-and-conquer manner. Additionally, we propose a Hierarchical Refinement Module (HRM) that leverages pixel-wise spatial contexts and enables channel-wise feature refinement through multi-level updates. Extensive experiments on six benchmarks demonstrate that DiSa consistently outperforms state-of-the-art methods.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20064v1</guid></item><item><title>[cs updates on arXiv.org] A Paradigm for Generalized Multi-Level Priority Encoders</title><link>https://arxiv.org/abs/2601.20067</link><description>arXiv:2601.20067v1 Announce Type: new 
Abstract: Priority encoders are typically considered expensive hardware components in terms of complexity, especially at high bit precisions or input lengths (e.g., above 512 bits). However, if the complexity can be reduced, priority encoders can feasibly accelerate a variety of key applications, such as high-precision integer arithmetic and content-addressable memory. We propose a new paradigm for constructing priority encoders by generalizing the previously proposed two-level priority encoder structure. We extend this concept to three and four levels using two techniques -- cascading and composition -- and discuss further generalization. We then analyze the complexity and delay of new and existing priority encoder designs as a function of input length, for both FPGA and ASIC implementation technologies. In particular, we compare the multi-level structure to the traditional single-level priority encoder structure, a tree-based design, a recursive design, and the two-level structure. We find that the two-level architecture provides balanced performance -- reducing complexity by around half, but at the cost of a corresponding increase in delay. Additional levels have diminishing returns, highlighting a tradeoff between complexity and delay. Meanwhile, the tree and recursive designs are generally faster, but are more complex than the two-level and multi-level structures. We explore several characteristics and patterns of the designs across a wide range of input lengths. We then provide recommendations on which architecture to use for a given input length and implementation technology, based on which design factors -- such as complexity or delay -- are most important to the hardware designer. With this overview and analysis of various priority encoder architectures, we provide a priority encoder toolkit to assist hardware designers in creating the most optimal design.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20067v1</guid></item><item><title>[cs updates on arXiv.org] Distributional value gradients for stochastic environments</title><link>https://arxiv.org/abs/2601.20071</link><description>arXiv:2601.20071v1 Announce Type: new 
Abstract: Gradient-regularized value learning methods improve sample efficiency by leveraging learned models of transition dynamics and rewards to estimate return gradients. However, existing approaches, such as MAGE, struggle in stochastic or noisy environments, limiting their applicability. In this work, we address these limitations by extending distributional reinforcement learning on continuous state-action spaces to model not only the distribution over scalar state-action value functions but also over their gradients. We refer to this approach as Distributional Sobolev Training. Inspired by Stochastic Value Gradients (SVG), our method utilizes a one-step world model of reward and transition distributions implemented via a conditional Variational Autoencoder (cVAE). The proposed framework is sample-based and employs Max-sliced Maximum Mean Discrepancy (MSMMD) to instantiate the distributional Bellman operator. We prove that the Sobolev-augmented Bellman operator is a contraction with a unique fixed point, and highlight a fundamental smoothness trade-off underlying contraction in gradient-aware RL. To validate our method, we first showcase its effectiveness on a simple stochastic reinforcement learning toy problem, then benchmark its performance on several MuJoCo environments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20071v1</guid></item><item><title>[cs updates on arXiv.org] Semi-Supervised Masked Autoencoders: Unlocking Vision Transformer Potential with Limited Data</title><link>https://arxiv.org/abs/2601.20072</link><description>arXiv:2601.20072v1 Announce Type: new 
Abstract: We address the challenge of training Vision Transformers (ViTs) when labeled data is scarce but unlabeled data is abundant. We propose Semi-Supervised Masked Autoencoder (SSMAE), a framework that jointly optimizes masked image reconstruction and classification using both unlabeled and labeled samples with dynamically selected pseudo-labels. SSMAE introduces a validation-driven gating mechanism that activates pseudo-labeling only after the model achieves reliable, high-confidence predictions that are consistent across both weakly and strongly augmented views of the same image, reducing confirmation bias. On CIFAR-10 and CIFAR-100, SSMAE consistently outperforms supervised ViT and fine-tuned MAE, with the largest gains in low-label regimes (+9.24% over ViT on CIFAR-10 with 10% labels). Our results demonstrate that when pseudo-labels are introduced is as important as how they are generated for data-efficient transformer training. Codes are available at https://github.com/atik666/ssmae.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20072v1</guid></item><item><title>[cs updates on arXiv.org] Sparse CLIP: Co-Optimizing Interpretability and Performance in Contrastive Learning</title><link>https://arxiv.org/abs/2601.20075</link><description>arXiv:2601.20075v1 Announce Type: new 
Abstract: Contrastive Language-Image Pre-training (CLIP) has become a cornerstone in vision-language representation learning, powering diverse downstream tasks and serving as the default vision backbone in multimodal large language models (MLLMs). Despite its success, CLIP's dense and opaque latent representations pose significant interpretability challenges. A common assumption is that interpretability and performance are in tension: enforcing sparsity during training degrades accuracy, motivating recent post-hoc approaches such as Sparse Autoencoders (SAEs). However, these post-hoc approaches often suffer from degraded downstream performance and loss of CLIP's inherent multimodal capabilities, with most learned features remaining unimodal.
  We propose a simple yet effective approach that integrates sparsity directly into CLIP training, yielding representations that are both interpretable and performant. Compared to SAEs, our Sparse CLIP representations preserve strong downstream task performance, achieve superior interpretability, and retain multimodal capabilities. We show that multimodal sparse features enable straightforward semantic concept alignment and reveal training dynamics of how cross-modal knowledge emerges. Finally, as a proof of concept, we train a vision-language model on sparse CLIP representations that enables interpretable, vision-based steering capabilities. Our findings challenge conventional wisdom that interpretability requires sacrificing accuracy and demonstrate that interpretability and performance can be co-optimized, offering a promising design principle for future models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20075v1</guid></item><item><title>[cs updates on arXiv.org] Techno-economic optimization of a heat-pipe microreactor, part II: multi-objective optimization analysis</title><link>https://arxiv.org/abs/2601.20079</link><description>arXiv:2601.20079v1 Announce Type: new 
Abstract: Heat-pipe microreactors (HPMRs) are compact and transportable nuclear power systems exhibiting inherent safety, well-suited for deployment in remote regions where access is limited and reliance on costly fossil fuels is prevalent. In prior work, we developed a design optimization framework that incorporates techno-economic considerations through surrogate modeling and reinforcement learning (RL)-based optimization, focusing solely on minimizing the levelized cost of electricity (LCOE) by using a bottom-up cost estimation approach. In this study, we extend that framework to a multi-objective optimization that uses the Pareto Envelope Augmented with Reinforcement Learning (PEARL) algorithm. The objectives include minimizing both the rod-integrated peaking factor ($F_{\Delta h}$) and LCOE -- subject to safety and operational constraints. We evaluate three cost scenarios: (1) a high-cost axial and drum reflectors, (2) a low-cost axial reflector, and (3) low-cost axial and drum reflectors. Our findings indicate that reducing the solid moderator radius, pin pitch, and drum coating angle -- all while increasing the fuel height -- effectively lowers $F_{\Delta h}$. Across all three scenarios, four key strategies consistently emerged for optimizing LCOE: (1) minimizing the axial reflector contribution when costly, (2) reducing control drum reliance, (3) substituting expensive tri-structural isotropic (TRISO) fuel with axial reflector material priced at the level of graphite, and (4) maximizing fuel burnup. While PEARL demonstrates promise in navigating trade-offs across diverse design scenarios, discrepancies between surrogate model predictions and full-order simulations remain. Further improvements are anticipated through constraint relaxation and surrogate development, constituting an ongoing area of investigation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20079v1</guid></item><item><title>[cs updates on arXiv.org] Locatability and Locatability Robustness of Visual Variables in Single Target Localization</title><link>https://arxiv.org/abs/2601.20080</link><description>arXiv:2601.20080v1 Announce Type: new 
Abstract: Finding a particular object in a display is important for viewers in many visualizations, for example, when reacting to brushing or to a highlighted object. This can be enabled by making the target object different in one of the visual variables that determine the object's appearance; for example, by changing its color or size. Certain interpretations of the visual search literature have promoted the view that using visual variables such as hue-often labeled as preattentive-would make the target object automatically "popout," implying that an object can be located almost instantly, regardless of the number of objects in the display. In this paper we present a study that serves as a bridge between the extensive visual search literature and visualization, establishing empirical base measurements for the localization task. By testing displays with up to hundreds of objects, we are able to show that none of the common visual variables is immune to the increase in the number of objects. We also provide the first empirically informed comparisons between visual variables for this task in the context of visualization, and show how different visual variables have varying robustness with respect to two additional dimensions: the location of the target and the overall visual arrangement (layout). A free copy of this paper and all supplemental materials are available on our online repository: https://osf.io/z68ak/overview.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20080v1</guid></item><item><title>[cs updates on arXiv.org] LLaTTE: Scaling Laws for Multi-Stage Sequence Modeling in Large-Scale Ads Recommendation</title><link>https://arxiv.org/abs/2601.20083</link><description>arXiv:2601.20083v1 Announce Type: new 
Abstract: We present LLaTTE (LLM-Style Latent Transformers for Temporal Events), a scalable transformer architecture for production ads recommendation. Through systematic experiments, we demonstrate that sequence modeling in recommendation systems follows predictable power-law scaling similar to LLMs. Crucially, we find that semantic features bend the scaling curve: they are a prerequisite for scaling, enabling the model to effectively utilize the capacity of deeper and longer architectures. To realize the benefits of continued scaling under strict latency constraints, we introduce a two-stage architecture that offloads the heavy computation of large, long-context models to an asynchronous upstream user model. We demonstrate that upstream improvements transfer predictably to downstream ranking tasks. Deployed as the largest user model at Meta, this multi-stage framework drives a 4.3\% conversion uplift on Facebook Feed and Reels with minimal serving overhead, establishing a practical blueprint for harnessing scaling laws in industrial recommender systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20083v1</guid></item><item><title>[cs updates on arXiv.org] IMRNNs: An Efficient Method for Interpretable Dense Retrieval via Embedding Modulation</title><link>https://arxiv.org/abs/2601.20084</link><description>arXiv:2601.20084v1 Announce Type: new 
Abstract: Interpretability in black-box dense retrievers remains a central challenge in Retrieval-Augmented Generation (RAG). Understanding how queries and documents semantically interact is critical for diagnosing retrieval behavior and improving model design. However, existing dense retrievers rely on static embeddings for both queries and documents, which obscures this bidirectional relationship. Post-hoc approaches such as re-rankers are computationally expensive, add inference latency, and still fail to reveal the underlying semantic alignment. To address these limitations, we propose Interpretable Modular Retrieval Neural Networks (IMRNNs), a lightweight framework that augments any dense retriever with dynamic, bidirectional modulation at inference time. IMRNNs employ two independent adapters: one conditions document embeddings on the current query, while the other refines the query embedding using corpus-level feedback from initially retrieved documents. This iterative modulation process enables the model to adapt representations dynamically and expose interpretable semantic dependencies between queries and documents. Empirically, IMRNNs not only enhance interpretability but also improve retrieval effectiveness. Across seven benchmark datasets, applying our method to standard dense retrievers yields average gains of +6.35% nDCG, +7.14% recall, and +7.04% MRR over state-of-the-art baselines. These results demonstrate that incorporating interpretability-driven modulation can both explain and enhance retrieval in RAG systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20084v1</guid></item><item><title>[cs updates on arXiv.org] Editrail: Understanding AI Usage by Visualizing Student-AI Interaction in Code</title><link>https://arxiv.org/abs/2601.20085</link><description>arXiv:2601.20085v1 Announce Type: new 
Abstract: Programming instructors have diverse philosophies about integrating generative AI into their classes. Some encourage students to use AI, while others restrict or forbid it. Regardless of their approach, all instructors benefit from understanding how their students actually use AI while writing code. Such insight helps instructors assess whether AI use aligns with their pedagogical goals, enables timely intervention when they find unproductive usage patterns, and establishes effective policies for AI use. However, our survey with programming instructors found that many instructors lack visibility into how students use AI in their code-writing processes. To address this challenge, we introduce Editrail, an interactive system that enables instructors to track students' AI usage, create personalized assessments, and provide timely interventions, all within the workflow of monitoring coding histories. We found that Editrail enables instructors to detect AI use that conflicts with pedagogical goals accurately and to determine when and which students require intervention.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20085v1</guid></item><item><title>[cs updates on arXiv.org] Quantization-Aware Distillation for NVFP4 Inference Accuracy Recovery</title><link>https://arxiv.org/abs/2601.20088</link><description>arXiv:2601.20088v1 Announce Type: new 
Abstract: This technical report presents quantization-aware distillation (QAD) and our best practices for recovering accuracy of NVFP4-quantized large language models (LLMs) and vision-language models (VLMs). QAD distills a full-precision teacher model into a quantized student model using a KL divergence loss. While applying distillation to quantized models is not a new idea, we observe key advantages of QAD for today's LLMs: 1. It shows remarkable effectiveness and stability for models trained through multi-stage post-training pipelines, including supervised fine-tuning (SFT), reinforcement learning (RL), and model merging, where traditional quantization-aware training (QAT) suffers from engineering complexity and training instability; 2. It is robust to data quality and coverage, enabling accuracy recovery without full training data. We evaluate QAD across multiple post-trained models including AceReason Nemotron, Nemotron 3 Nano, Nemotron Nano V2, Nemotron Nano V2 VL (VLM), and Llama Nemotron Super v1, showing consistent recovery to near-BF16 accuracy.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20088v1</guid></item><item><title>[cs updates on arXiv.org] Should I Have Expressed a Different Intent? Counterfactual Generation for LLM-Based Autonomous Control</title><link>https://arxiv.org/abs/2601.20090</link><description>arXiv:2601.20090v1 Announce Type: new 
Abstract: Large language model (LLM)-powered agents can translate high-level user intents into plans and actions in an environment. Yet after observing an outcome, users may wonder: What if I had phrased my intent differently? We introduce a framework that enables such counterfactual reasoning in agentic LLM-driven control scenarios, while providing formal reliability guarantees. Our approach models the closed-loop interaction between a user, an LLM-based agent, and an environment as a structural causal model (SCM), and leverages test-time scaling to generate multiple candidate counterfactual outcomes via probabilistic abduction. Through an offline calibration phase, the proposed conformal counterfactual generation (CCG) yields sets of counterfactual outcomes that are guaranteed to contain the true counterfactual outcome with high probability. We showcase the performance of CCG on a wireless network control use case, demonstrating significant advantages compared to naive re-execution baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20090v1</guid></item><item><title>[cs updates on arXiv.org] Dynamics of Human-AI Collective Knowledge on the Web: A Scalable Model and Insights for Sustainable Growth</title><link>https://arxiv.org/abs/2601.20099</link><description>arXiv:2601.20099v1 Announce Type: new 
Abstract: Humans and large language models (LLMs) now co-produce and co-consume the web's shared knowledge archives. Such human-AI collective knowledge ecosystems contain feedback loops with both benefits (e.g., faster growth, easier learning) and systemic risks (e.g., quality dilution, skill reduction, model collapse). To understand such phenomena, we propose a minimal, interpretable dynamical model of the co-evolution of archive size, archive quality, model (LLM) skill, aggregate human skill, and query volume. The model captures two content inflows (human, LLM) controlled by a gate on LLM-content admissions, two learning pathways for humans (archive study vs. LLM assistance), and two LLM-training modalities (corpus-driven scaling vs. learning from human feedback). Through numerical experiments, we identify different growth regimes (e.g., healthy growth, inverted flow, inverted learning, oscillations), and show how platform and policy levers (gate strictness, LLM training, human learning pathways) shift the system across regime boundaries. Two domain configurations (PubMed, GitHub and Copilot) illustrate contrasting steady states under different growth rates and moderation norms. We also fit the model to Wikipedia's knowledge flow during pre-ChatGPT and post-ChatGPT eras separately. We find a rise in LLM additions with a concurrent decline in human inflow, consistent with a regime identified by the model. Our model and analysis yield actionable insights for sustainable growth of human-AI collective knowledge on the Web.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20099v1</guid></item><item><title>[cs updates on arXiv.org] Taming Toxic Talk: Using chatbots to intervene with users posting toxic comments</title><link>https://arxiv.org/abs/2601.20100</link><description>arXiv:2601.20100v1 Announce Type: new 
Abstract: Generative AI chatbots have proven surprisingly effective at persuading people to change their beliefs and attitudes in lab settings. However, the practical implications of these findings are not yet clear. In this work, we explore the impact of rehabilitative conversations with generative AI chatbots on users who share toxic content online. Toxic behaviors -- like insults or threats of violence, are widespread in online communities. Strategies to deal with toxic behavior are typically punitive, such as removing content or banning users. Rehabilitative approaches are rarely attempted, in part due to the emotional and psychological cost of engaging with aggressive users. In collaboration with seven large Reddit communities, we conducted a large-scale field experiment (N=893) to invite people who had recently posted toxic content to participate in conversations with AI chatbots. A qualitative analysis of the conversations shows that many participants engaged in good faith and even expressed remorse or a desire to change. However, we did not observe a significant change in toxic behavior in the following month compared to a control group. We discuss possible explanations for our findings, as well as theoretical and practical implications based on our results.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20100v1</guid></item><item><title>[cs updates on arXiv.org] Counterfactual Cultural Cues Reduce Medical QA Accuracy in LLMs: Identifier vs Context Effects</title><link>https://arxiv.org/abs/2601.20102</link><description>arXiv:2601.20102v1 Announce Type: new 
Abstract: Engineering sustainable and equitable healthcare requires medical language models that do not change clinically correct diagnoses when presented with non-decisive cultural information. We introduce a counterfactual benchmark that expands 150 MedQA test items into 1650 variants by inserting culture-related (i) identifier tokens, (ii) contextual cues, or (iii) their combination for three groups (Indigenous Canadian, Middle-Eastern Muslim, Southeast Asian), plus a length-matched neutral control, where a clinician verified that the gold answer remains invariant in all variants. We evaluate GPT-5.2, Llama-3.1-8B, DeepSeek-R1, and MedGemma (4B/27B) under option-only and brief-explanation prompting. Across models, cultural cues significantly affect accuracy (Cochran's Q, $p&lt;10^-14$), with the largest degradation when identifier and context co-occur (up to 3-7 percentage points under option-only prompting), while neutral edits produce smaller, non-systematic changes. A human-validated rubric ($\kappa=0.76$) applied via an LLM-as-judge shows that more than half of culturally grounded explanations end in an incorrect answer, linking culture-referential reasoning to diagnostic failure. We release prompts and augmentations to support evaluation and mitigation of culturally induced diagnostic errors.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20102v1</guid></item><item><title>[cs updates on arXiv.org] Benchmarking Reward Hack Detection in Code Environments via Contrastive Analysis</title><link>https://arxiv.org/abs/2601.20103</link><description>arXiv:2601.20103v1 Announce Type: new 
Abstract: Recent advances in reinforcement learning for code generation have made robust environments essential to prevent reward hacking. As LLMs increasingly serve as evaluators in code-based RL, their ability to detect reward hacking remains understudied. In this paper, we propose a novel taxonomy of reward exploits spanning across 54 categories and introduce TRACE (Testing Reward Anomalies in Code Environments), a synthetically curated and human-verified benchmark containing 517 testing trajectories. Unlike prior work that evaluates reward hack detection in isolated classification scenarios, we contrast these evaluations with a more realistic, contrastive anomaly detection setup on TRACE. Our experiments reveal that models capture reward hacks more effectively in contrastive settings than in isolated classification settings, with GPT-5.2 with highest reasoning mode achieving the best detection rate at 63%, up from 45% in isolated settings on TRACE. Building on this insight, we demonstrate that state-of-the-art models struggle significantly more with semantically contextualized reward hacks compared to syntactically contextualized ones. We further conduct qualitative analyses of model behaviors, as well as ablation studies showing that the ratio of benign to hacked trajectories and analysis cluster sizes substantially impact detection performance. We release the benchmark and evaluation harness to enable the community to expand TRACE and evaluate their models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20103v1</guid></item><item><title>[cs updates on arXiv.org] NucFuseRank: Dataset Fusion and Performance Ranking for Nuclei Instance Segmentation</title><link>https://arxiv.org/abs/2601.20104</link><description>arXiv:2601.20104v1 Announce Type: new 
Abstract: Nuclei instance segmentation in hematoxylin and eosin (H&amp;amp;E)-stained images plays an important role in automated histological image analysis, with various applications in downstream tasks. While several machine learning and deep learning approaches have been proposed for nuclei instance segmentation, most research in this field focuses on developing new segmentation algorithms and benchmarking them on a limited number of arbitrarily selected public datasets.
  In this work, rather than focusing on model development, we focused on the datasets used for this task. Based on an extensive literature review, we identified manually annotated, publicly available datasets of H&amp;amp;E-stained images for nuclei instance segmentation and standardized them into a unified input and annotation format. Using two state-of-the-art segmentation models, one based on convolutional neural networks (CNNs) and one based on a hybrid CNN and vision transformer architecture, we systematically evaluated and ranked these datasets based on their nuclei instance segmentation performance. Furthermore, we proposed a unified test set (NucFuse-test) for fair cross-dataset evaluation and a unified training set (NucFuse-train) for improved segmentation performance by merging images from multiple datasets.
  By evaluating and ranking the datasets, performing comprehensive analyses, generating fused datasets, conducting external validation, and making our implementation publicly available, we provided a new benchmark for training, testing, and evaluating nuclei instance segmentation models on H&amp;amp;E-stained histological images.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20104v1</guid></item><item><title>[cs updates on arXiv.org] FFE-Hallu:Hallucinations in Fixed Figurative Expressions:Benchmark of Idioms and Proverbs in the Persian Language</title><link>https://arxiv.org/abs/2601.20105</link><description>arXiv:2601.20105v1 Announce Type: new 
Abstract: Figurative language, particularly fixed figurative expressions (FFEs) such as idioms and proverbs, poses persistent challenges for large language models (LLMs). Unlike literal phrases, FFEs are culturally grounded, largely non-compositional, and conventionally fixed, making them especially vulnerable to figurative hallucination. We define figurative hallucination as the generation or endorsement of expressions that sound idiomatic and plausible but do not exist as authentic figurative expressions in the target language. We introduce FFEHallu, the first comprehensive benchmark for evaluating figurative hallucination in LLMs, with a focus on Persian, a linguistically rich yet underrepresented language. FFEHallu consists of 600 carefully curated instances spanning three complementary tasks: (i) FFE generation from meaning, (ii) detection of fabricated FFEs across four controlled construction categories, and (iii) FFE to FFE translation from English to Persian. Evaluating six state of the art multilingual LLMs, we find systematic weaknesses in figurative competence and cultural grounding. While models such as GPT4.1 demonstrate relatively strong performance in rejecting fabricated FFEs and retrieving authentic ones, most models struggle to reliably distinguish real expressions from high quality fabrications and frequently hallucinate during cross lingual translation. These findings reveal substantial gaps in current LLMs handling of figurative language and underscore the need for targeted benchmarks to assess and mitigate figurative hallucination.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20105v1</guid></item><item><title>[cs updates on arXiv.org] Are We All Using Agents the Same Way? An Empirical Study of Core and Peripheral Developers Use of Coding Agents</title><link>https://arxiv.org/abs/2601.20106</link><description>arXiv:2601.20106v1 Announce Type: new 
Abstract: Autonomous AI agents are transforming software development and redefining how developers collaborate with AI. Prior research shows that the adoption and use of AI-powered tools differ between core and peripheral developers. However, it remains unclear how this dynamic unfolds in the emerging era of autonomous coding agents. In this paper, we present the first empirical study of 9,427 agentic PRs, examining how core and peripheral developers use, review, modify, and verify agent-generated contributions prior to acceptance. Through a mix of qualitative and quantitative analysis, we make four key contributions. First, a subset of peripheral developers use agents more often, delegating tasks evenly across bug fixing, feature addition, documentation, and testing. In contrast, core developers focus more on documentation and testing, yet their agentic PRs are frequently merged into the main/master branch. Second, core developers engage slightly more in review discussions than peripheral developers, and both groups focus on evolvability issues. Third, agentic PRs are less likely to be modified, but when they are, both groups commonly perform refactoring. Finally, peripheral developers are more likely to merge without running CI checks, whereas core developers more consistently require passing verification before acceptance. Our analysis offers a comprehensive view of how developer experience shapes integration offer insights for both peripheral and core developers on how to effectively collaborate with coding agents.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20106v1</guid></item><item><title>[cs updates on arXiv.org] Look in the Middle: Structural Anchor Pruning for Scalable Visual RAG Indexing</title><link>https://arxiv.org/abs/2601.20107</link><description>arXiv:2601.20107v1 Announce Type: new 
Abstract: Recent Vision-Language Models (e.g., ColPali) enable fine-grained Visual Document Retrieval (VDR) but incur prohibitive index vector size overheads. Training-free pruning solutions (e.g., EOS-attention based methods) can reduce index vector size by approximately 60% without model adaptation, but often underperform random selection in high-compression scenarios (&gt; 80%). Prior research (e.g., Light-ColPali) attributes this to the conclusion that visual token importance is inherently query-dependent, thereby questioning the feasibility of training-free pruning. In this work, we propose Structural Anchor Pruning (SAP), a training-free pruning method that identifies key visual patches from middle layers to achieve high performance compression. We also introduce Oracle Score Retention (OSR) protocol to evaluate how layer-wise information affects compression efficiency. Evaluations on the ViDoRe benchmark demonstrate that SAP reduces index vectors by over 90% while maintaining robust retrieval fidelity, providing a highly scalable solution for Visual RAG. Furthermore, our OSR-based analysis reveals that semantic structural anchor patches persist in the middle layers, unlike traditional pruning solutions that focus on the final layer where structural signals dissipate.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20107v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Bug Fixes: An Empirical Investigation of Post-Merge Code Quality Issues in Agent-Generated Pull Requests</title><link>https://arxiv.org/abs/2601.20109</link><description>arXiv:2601.20109v1 Announce Type: new 
Abstract: The increasing adoption of AI coding agents has increased the number of agent-generated pull requests (PRs) merged with little or no human intervention. Although such PRs promise productivity gains, their post-merge code quality remains underexplored, as prior work has largely relied on benchmarks and controlled tasks rather than large-scale post-merge analyses. To address this gap, we analyze 1,210 merged agent-generated bug-fix PRs from Python repositories in the AIDev dataset. Using SonarQube, we perform a differential analysis between base and merged commits to identify code quality issues newly introduced by PR changes. We examine issue frequency, density, severity, and rule-level prevalence across five agents. Our results show that apparent differences in raw issue counts across agents largely disappear after normalizing by code churn, indicating that higher issue counts are primarily driven by larger PRs. Across all agents, code smells dominate, particularly at critical and major severities, while bugs are less frequent but often severe. Overall, our findings show that merge success does not reliably reflect post-merge code quality, highlighting the need for systematic quality checks for agent-generated bug-fix PRs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20109v1</guid></item><item><title>[cs updates on arXiv.org] Usage, Effects and Requirements for AI Coding Assistants in the Enterprise: An Empirical Study</title><link>https://arxiv.org/abs/2601.20112</link><description>arXiv:2601.20112v1 Announce Type: new 
Abstract: The rise of large language models (LLMs) has accelerated the development of automated techniques and tools for supporting various software engineering tasks, e.g., program understanding, code generation, software testing, and program repair. As CodeLLMs are being employed toward automating these tasks, one question that arises, especially in enterprise settings, is whether these coding assistants and the code LLMs that power them are ready for real-world projects and enterprise use cases, and how do they impact the existing software engineering process and user experience. In this paper we survey 57 developers from different domains and with varying software engineering skill about their experience with AI coding assistants and CodeLLMs. We also reviewed 35 user surveys on the usage, experience and expectations of professionals and students using AI coding assistants and CodeLLMs. Based on our study findings and analysis of existing surveys, we discuss the requirements for AI-powered coding assistants.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20112v1</guid></item><item><title>[cs updates on arXiv.org] A Data-Informed Local Subspaces Method for Error-Bounded Lossy Compression of Large-Scale Scientific Datasets</title><link>https://arxiv.org/abs/2601.20113</link><description>arXiv:2601.20113v1 Announce Type: new 
Abstract: The growing volume of scientific simulation data presents a significant challenge for storage and transfer. Error-bounded lossy compression has emerged as a critical solution for mitigating these challenges, providing a means to reduce data size while ensuring that reconstructed data remains valid for scientific analysis. In this paper, we present a data-driven scientific data compressor, called Discontinuous Data-informed Local Subspaces (Discontinuous DLS), to improve compression-to-error ratios over data-agnostic compressors. This error-bounded compressor leverages localized spatial and temporal subspaces, informed by the underlying data structure, to enhance compression efficiency and preserve key features. The presented technique is flexible and applicable to a wide range of scientific data, including fluid dynamics, environmental simulations, and other high-dimensional, time-dependent datasets. We describe the core principles of the method and demonstrate its ability to significantly reduce storage requirements without compromising critical data fidelity. The technique is implemented in a distributed computing environment using MPI, and its performance is evaluated against state-of-the-art error-bounded compression methods in terms of compression ratio and reconstruction accuracy. This study highlights discontinuous DLS as a promising approach for large-scale scientific data compression in high-performance computing environments, providing a robust solution for managing the growing data demands of modern scientific simulations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20113v1</guid></item><item><title>[cs updates on arXiv.org] In-Context Reinforcement Learning From Suboptimal Historical Data</title><link>https://arxiv.org/abs/2601.20116</link><description>arXiv:2601.20116v1 Announce Type: new 
Abstract: Transformer models have achieved remarkable empirical successes, largely due to their in-context learning capabilities. Inspired by this, we explore training an autoregressive transformer for in-context reinforcement learning (ICRL). In this setting, we initially train a transformer on an offline dataset consisting of trajectories collected from various RL tasks, and then fix and use this transformer to create an action policy for new RL tasks. Notably, we consider the setting where the offline dataset contains trajectories sampled from suboptimal behavioral policies. In this case, standard autoregressive training corresponds to imitation learning and results in suboptimal performance. To address this, we propose the Decision Importance Transformer(DIT) framework, which emulates the actor-critic algorithm in an in-context manner. In particular, we first train a transformer-based value function that estimates the advantage functions of the behavior policies that collected the suboptimal trajectories. Then we train a transformer-based policy via a weighted maximum likelihood estimation loss, where the weights are constructed based on the trained value function to steer the suboptimal policies to the optimal ones. We conduct extensive experiments to test the performance of DIT on both bandit and Markov Decision Process problems. Our results show that DIT achieves superior performance, particularly when the offline dataset contains suboptimal historical data.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20116v1</guid></item><item><title>[cs updates on arXiv.org] Improving Smoothed Aggregation AMG Robustness on Stretched Mesh Applications</title><link>https://arxiv.org/abs/2601.20119</link><description>arXiv:2601.20119v1 Announce Type: new 
Abstract: Strength-of-connection algorithms play a key role in algebraic multigrid (AMG). Specifically, they determine which matrix nonzeros are classified as weak and so ignored when coarsening matrix graphs and defining interpolation sparsity patterns. The general goal is to encourage coarsening only in directions where error can be smoothed and to avoid coarsening across sharp problem variations. Unfortunately, developing robust and inexpensive strength-of-connection schemes is challenging.
  The classification of matrix nonzeros involves four aspects: (a) choosing a strength-of-connection matrix, (b) scaling its values, (c) choosing a criterion to classify scaled values as strong or weak, and (d) dropping weak entries which includes adjusting matrix values to account for dropped terms. Typically, smoothed aggregation AMG uses the linear system being solved as a strength-of-connection matrix. It scales values symmetrically using square-roots of the matrix diagonal. It classifies based on whether scaled values are above or below a threshold. Finally, it adjusts matrix values by modifying the diagonal so that the sum of entries within each row of the dropped matrix matches that of the original. While these procedures can work well, we illustrate failure cases that motivate alternatives. The first alternative uses a distance Laplacian strength-of-connection matrix. The second centers on non-symmetric scaling. We then investigate alternative classification criteria based on identifying gaps in the values of the scaled entries. Finally, an alternative lumping procedure is proposed where row sums are preserved by modifying all retained matrix entries (as opposed to just diagonal entries). A series of numerical results illustrates trade-offs demonstrating in some cases notably more robust convergence on matrices coming from linear finite elements on stretched meshes.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20119v1</guid></item><item><title>[cs updates on arXiv.org] Going NUTS with ADVI: Exploring various Bayesian Inference techniques with Facebook Prophet</title><link>https://arxiv.org/abs/2601.20120</link><description>arXiv:2601.20120v1 Announce Type: new 
Abstract: Since its introduction, Facebook Prophet has attracted positive attention from both classical statisticians and the Bayesian statistics community. The model provides two built-in inference methods: maximum a posteriori estimation using the L-BFGS-B algorithm, and Markov Chain Monte Carlo (MCMC) sampling via the No-U-Turn Sampler (NUTS). While exploring various time-series forecasting problems using Bayesian inference with Prophet, we encountered limitations stemming from the inability to apply alternative inference techniques beyond those provided by default. Additionally, the fluent API design of Facebook Prophet proved insufficiently flexible for implementing our custom modeling ideas. To address these shortcomings, we developed a complete reimplementation of the Prophet model in PyMC, which enables us to extend the base model and evaluate and compare multiple Bayesian inference methods. In this paper, we present our PyMC-based implementation and analyze in detail the implementation of different Bayesian inference techniques. We consider full MCMC techniques, MAP estimation and Variational inference techniques on a time-series forecasting problem. We discuss in details the sampling approach, convergence diagnostics, forecasting metrics as well as their computational efficiency and detect possible issues which will be addressed in our future work.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20120v1</guid></item><item><title>[cs updates on arXiv.org] Membership Inference Attacks Against Fine-tuned Diffusion Language Models</title><link>https://arxiv.org/abs/2601.20125</link><description>arXiv:2601.20125v1 Announce Type: new 
Abstract: Diffusion Language Models (DLMs) represent a promising alternative to autoregressive language models, using bidirectional masked token prediction. Yet their susceptibility to privacy leakage via Membership Inference Attacks (MIA) remains critically underexplored. This paper presents the first systematic investigation of MIA vulnerabilities in DLMs. Unlike the autoregressive models' single fixed prediction pattern, DLMs' multiple maskable configurations exponentially increase attack opportunities. This ability to probe many independent masks dramatically improves detection chances. To exploit this, we introduce SAMA (Subset-Aggregated Membership Attack), which addresses the sparse signal challenge through robust aggregation. SAMA samples masked subsets across progressive densities and applies sign-based statistics that remain effective despite heavy-tailed noise. Through inverse-weighted aggregation prioritizing sparse masks' cleaner signals, SAMA transforms sparse memorization detection into a robust voting mechanism. Experiments on nine datasets show SAMA achieves 30% relative AUC improvement over the best baseline, with up to 8 times improvement at low false positive rates. These findings reveal significant, previously unknown vulnerabilities in DLMs, necessitating the development of tailored privacy defenses.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20125v1</guid></item><item><title>[cs updates on arXiv.org] Rewarding Intellectual Humility Learning When Not To Answer In Large Language Models</title><link>https://arxiv.org/abs/2601.20126</link><description>arXiv:2601.20126v1 Announce Type: new 
Abstract: Large Language Models (LLMs) often produce hallucinated or unverifiable content, undermining their reliability in factual domains. This work investigates Reinforcement Learning with Verifiable Rewards (RLVR) as a training paradigm that explicitly rewards abstention ("I don't know") alongside correctness to promote intellectual humility. We fine-tune and evaluate Granite-3.3-2B-Instruct and Qwen-3-4B-Instruct on the MedMCQA and Hendrycks Math benchmarks using a ternary reward structure ($-1$, r_abs, 1) under varying abstention reward structures. We further study the effect of combining RLVR with supervised fine-tuning strategies that teach abstention prior to reinforcement learning. Our results show that moderate abstention rewards (r_abs $\approx -0.25$ to 0.3) consistently reduce incorrect responses without severe accuracy degradation on multiple-choice tasks, with larger models exhibiting greater robustness to abstention incentives. On open-ended question answering, we observe limitations due to insufficient exploration, which can be partially mitigated through supervised abstention training. Overall, these findings demonstrate the feasibility and flexibility of verifiable reward design as a practical approach for hallucination mitigation in language models. Reproducible code for our abstention training framework is available here https://github.com/Mystic-Slice/rl-abstention.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20126v1</guid></item><item><title>[cs updates on arXiv.org] BengaliSent140: A Large-Scale Bengali Binary Sentiment Dataset for Hate and Non-Hate Speech Classification</title><link>https://arxiv.org/abs/2601.20129</link><description>arXiv:2601.20129v1 Announce Type: new 
Abstract: Sentiment analysis for the Bengali language has attracted increasing research interest in recent years. However, progress remains constrained by the scarcity of large-scale and diverse annotated datasets. Although several Bengali sentiment and hate speech datasets are publicly available, most are limited in size or confined to a single domain, such as social media comments. Consequently, these resources are often insufficient for training modern deep learning based models, which require large volumes of heterogeneous data to learn robust and generalizable representations. In this work, we introduce BengaliSent140, a large-scale Bengali binary sentiment dataset constructed by consolidating seven existing Bengali text datasets into a unified corpus. To ensure consistency across sources, heterogeneous annotation schemes are systematically harmonized into a binary sentiment formulation with two classes: Not Hate (0) and Hate (1). The resulting dataset comprises 139,792 unique text samples, including 68,548 hate and 71,244 not-hate instances, yielding a relatively balanced class distribution. By integrating data from multiple sources and domains, BengaliSent140 offers broader linguistic and contextual coverage than existing Bengali sentiment datasets and provides a strong foundation for training and benchmarking deep learning models. Baseline experimental results are also reported to demonstrate the practical usability of the dataset. The dataset is publicly available at https://www.kaggle.com/datasets/akifislam/bengalisent140/</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20129v1</guid></item><item><title>[cs updates on arXiv.org] Real-Time Robot Execution with Masked Action Chunking</title><link>https://arxiv.org/abs/2601.20130</link><description>arXiv:2601.20130v1 Announce Type: new 
Abstract: Real-time execution is essential for cyber-physical systems such as robots. These systems operate in dynamic real-world environments where even small delays can undermine responsiveness and compromise performance. Asynchronous inference has recently emerged as a system-level paradigm for real-time robot manipulation, enabling the next action chunk to be predicted while the current one is being executed. While this approach achieves real-time responsiveness, naive integration often results in execution failure. Previous methods attributed this failure to inter-chunk discontinuity and developed test-time algorithms to smooth chunk boundaries. In contrast, we identify another critical yet overlooked factor: intra-chunk inconsistency, where the robot's executed action chunk partially misaligns with its current perception. To address this, we propose REMAC, which learns corrective adjustments on the pretrained policy through masked action chunking, enabling the policy to remain resilient under mismatches between intended actions and actual execution during asynchronous inference. In addition, we introduce a prefix-preserved sampling procedure to reinforce inter-chunk continuity. Overall, our method delivers more reliable policies without incurring additional latency. Extensive experiments in both simulation and real-world settings demonstrate that our method enables faster task execution, maintains robustness across varying delays, and consistently achieves higher completion rates.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20130v1</guid></item><item><title>[cs updates on arXiv.org] Taxonomy of the Retrieval System Framework: Pitfalls and Paradigms</title><link>https://arxiv.org/abs/2601.20131</link><description>arXiv:2601.20131v1 Announce Type: new 
Abstract: Designing an embedding retrieval system requires navigating a complex design space of conflicting trade-offs between efficiency and effectiveness. This work structures these decisions as a vertical traversal of the system design stack. We begin with the Representation Layer by examining how loss functions and architectures, specifically Bi-encoders and Cross-encoders, define semantic relevance and geometric projection. Next, we analyze the Granularity Layer and evaluate how segmentation strategies like Atomic and Hierarchical chunking mitigate information bottlenecks in long-context documents. Moving to the Orchestration Layer, we discuss methods that transcend the single-vector paradigm, including hierarchical retrieval, agentic decomposition, and multi-stage reranking pipelines to resolve capacity limitations. Finally, we address the Robustness Layer by identifying architectural mitigations for domain generalization failures, lexical blind spots, and the silent degradation of retrieval quality due to temporal drift. By categorizing these limitations and design choices, we provide a comprehensive framework for practitioners to optimize the efficiency-effectiveness frontier in modern neural search systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20131v1</guid></item><item><title>[cs updates on arXiv.org] Control systems for synthetic biology and a case-study in cell fate reprogramming</title><link>https://arxiv.org/abs/2601.20135</link><description>arXiv:2601.20135v1 Announce Type: new 
Abstract: This paper gives an overview of the use of control systems engineering in synthetic biology, motivated by applications such as cell therapy and cell fate reprogramming for regenerative medicine. A ubiquitous problem in these and other applications is the ability to control the concentration of specific regulatory factors in the cell accurately despite environmental uncertainty and perturbations. The paper describes the origin of these perturbations and how they affect the dynamics of the biomolecular ``plant'' to be controlled. A variety of biomolecular control implementations are then introduced to achieve robustness of the plant's output to perturbations and are grouped into feedback and feedforward control architectures. Although sophisticated control laws can be implemented in a computer today, they cannot be necessarily implemented inside the cell via biomolecular processes. This fact constraints the set of feasible control laws to those realizable through biomolecular processes that can be engineered with synthetic biology. After reviewing biomolecular feedback and feedforward control implementations, mostly focusing on the author's own work, the paper illustrates the application of such control strategies to cell fate reprogramming. Within this context, a master regulatory factor needs to be controlled at a specific level inside the cell in order to reprogram skin cells to pluripotent stem cells. The article closes by highlighting on-going challenges and directions of future research for biomolecular control design.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20135v1</guid></item><item><title>[cs updates on arXiv.org] Dynamic framework for edge-connectivity maintenance of simple graphs</title><link>https://arxiv.org/abs/2601.20137</link><description>arXiv:2601.20137v1 Announce Type: new 
Abstract: We present a dynamic framework for maintaining $k$-edge-connectivity of undirected, simple graphs subject to structural updates, specifically single edge additions and removals. The required edge-connectivity $k$ is a chosen, constant parameter. Unlike standard dynamic graph problems, such as dynamic minimum-cut, which focus solely on reporting the value of the minimum cut, our approach actively modifies the graph $G$ to maintain the edge-connectivity invariant $\lambda(G) \ge k$. We address two fundamental maintenance tasks: redundancy elimination, which identifies and removes an existing edge rendered redundant for $k$-edge-connectivity by new edge insertion, and connectivity restoration, which computes and inserts a minimal set of augmenting edges to restore graph's $k$-edge-connectivity following an old edge deletion. To preclude trivial reversals, we strictly enforce that the eliminated edge is distinct from the inserted edge and that restoration excludes the already deleted edge. Our solution of the first problem integrates Nagamochi-Ibaraki sparse certificates [Nagamochi and Ibaraki 1992] with Link-Cut Trees [Sleator and Tarjan 1983] to remove redundant edges in $O(k \log n)$ amortized time. For restoration, we propose a localized augmentation strategy that exploits the residual graph structure to bridge the minimum cut. By executing Dinic's [Dinic 1970] algorithm on the sparsified input graph, we identify the minimal edge set required to reconnect the graph in $O(k \cdot n^{5/3})$ time.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20137v1</guid></item><item><title>[cs updates on arXiv.org] Scaling Next-Brain-Token Prediction for MEG</title><link>https://arxiv.org/abs/2601.20138</link><description>arXiv:2601.20138v1 Announce Type: new 
Abstract: We present a large autoregressive model for source-space MEG that scales next-token prediction to long context across datasets and scanners: handling a corpus of over 500 hours and thousands of sessions across the three largest MEG datasets. A modified SEANet-style vector-quantizer reduces multichannel MEG into a flattened token stream on which we train a Qwen2.5-VL backbone from scratch to predict the next brain token and to recursively generate minutes of MEG from up to a minute of context. To evaluate long-horizon generation, we introduce three task-matched tests: (i) on-manifold stability via generated-only drift compared to the time-resolved distribution of real sliding windows, and (ii) conditional specificity via correct context versus prompt-swap controls using a neurophysiologically grounded metric set. We train on CamCAN and Omega and run all analyses on held-out MOUS, establishing cross-dataset generalization. Across metrics, generations remain relatively stable over long rollouts and are closer to the correct continuation than swapped controls. Code available at: https://github.com/ricsinaruto/brain-gen.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20138v1</guid></item><item><title>[cs updates on arXiv.org] Large language models accurately predict public perceptions of support for climate action worldwide</title><link>https://arxiv.org/abs/2601.20141</link><description>arXiv:2601.20141v1 Announce Type: new 
Abstract: Although most people support climate action, widespread underestimation of others' support stalls individual and systemic changes. In this preregistered experiment, we test whether large language models (LLMs) can reliably predict these perception gaps worldwide. Using country-level indicators and public opinion data from 125 countries, we benchmark four state-of-the-art LLMs against Gallup World Poll 2021/22 data and statistical regressions. LLMs, particularly Claude, accurately capture public perceptions of others' willingness to contribute financially to climate action (MAE approximately 5 p.p.; r = .77), comparable to statistical models, though performance declines in less digitally connected, lower-GDP countries. Controlled tests show that LLMs capture the key psychological process - social projection with a systematic downward bias - and rely on structured reasoning rather than memorized values. Overall, LLMs provide a rapid tool for assessing perception gaps in climate action, serving as an alternative to costly surveys in resource-rich countries and as a complement in underrepresented populations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20141v1</guid></item><item><title>[cs updates on arXiv.org] Mind the Shift: Using Delta SSL Embeddings to Enhance Child ASR</title><link>https://arxiv.org/abs/2601.20142</link><description>arXiv:2601.20142v1 Announce Type: new 
Abstract: Self-supervised learning (SSL) models have achieved impressive results across many speech tasks, yet child automatic speech recognition (ASR) remains challenging due to limited data and pretraining domain mismatch. Fine-tuning SSL models on child speech induces shifts in the representation space. We hypothesize that delta SSL embeddings, defined as the differences between embeddings from a finetuned model and those from its pretrained counterpart, encode task-specific information that complements finetuned features from another SSL model. We evaluate multiple fusion strategies on the MyST childrens corpus using different models. Results show that delta embedding fusion with WavLM yields up to a 10 percent relative WER reduction for HuBERT and a 4.4 percent reduction for W2V2, compared to finetuned embedding fusion. Notably, fusing WavLM with delta W2V2 embeddings achieves a WER of 9.64, setting a new state of the art among SSL models on the MyST corpus. These findings demonstrate the effectiveness of delta embeddings and highlight feature fusion as a promising direction for advancing child ASR.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20142v1</guid></item><item><title>[cs updates on arXiv.org] Trajectory2Task: Training Robust Tool-Calling Agents with Synthesized Yet Verifiable Data for Complex User Intents</title><link>https://arxiv.org/abs/2601.20144</link><description>arXiv:2601.20144v1 Announce Type: new 
Abstract: Tool-calling agents are increasingly deployed in real-world customer-facing workflows. Yet most studies on tool-calling agents focus on idealized settings with general, fixed, and well-specified tasks. In real-world applications, user requests are often (1) ambiguous, (2) changing over time, or (3) infeasible due to policy constraints, and training and evaluation data that cover these diverse, complex interaction patterns remain under-represented. To bridge the gap, we present Trajectory2Task, a verifiable data generation pipeline for studying tool use at scale under three realistic user scenarios: ambiguous intent, changing intent, and infeasible intents. The pipeline first conducts multi-turn exploration to produce valid tool-call trajectories. It then converts these trajectories into user-facing tasks with controlled intent adaptations. This process yields verifiable task that support closed-loop evaluation and training. We benchmark seven state-of-the-art LLMs on the generated complex user scenario tasks and observe frequent failures. Finally, using successful trajectories obtained from task rollouts, we fine-tune lightweight LLMs and find consistent improvements across all three conditions, along with better generalization to unseen tool-use domains, indicating stronger general tool-calling ability.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20144v1</guid></item><item><title>[cs updates on arXiv.org] Not All Tokens Matter: Data-Centric Optimization for Efficient Code Summarization</title><link>https://arxiv.org/abs/2601.20147</link><description>arXiv:2601.20147v1 Announce Type: new 
Abstract: Instruction-tuned Language Models ILMs have become essential components of modern AI systems, demonstrating exceptional versatility across a wide range of natural language and reasoning tasks. Among their most impactful applications is code generation, where ILMs--commonly referred to as Code Language Models CLMs--have demonstrated remarkable capability. This strength stems from their defining feature: the use of explicit task instructions during fine-tuning, which enables them to bridge natural language and code by translating human intent into executable code. While much of their progress has been driven by advances in scaling laws and training methodologies, one critical aspect remains underexplored--the impact of system prompts on the performance of both general-purpose ILMs and specialized CLMs when instantiated to assist users with code generation activities. In this study, we take a first step toward bridging this gap by systematically evaluating how system prompts of varying instructional detail, along with model scale, prompting strategy, and programming language, affect ILMs and CLMs in code generation tasks. Our evaluation framework, spanning 120 model configurations, reveals that (1) the influence of system prompts increases with model scale; (2) few-shot prompting reduces this effect compared to zero-shot; and (3) programming language matters, with Java showing greater sensitivity to system prompt variations than Python.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20147v1</guid></item><item><title>[cs updates on arXiv.org] LogSieve: Task-Aware CI Log Reduction for Sustainable LLM-Based Analysis</title><link>https://arxiv.org/abs/2601.20148</link><description>arXiv:2601.20148v1 Announce Type: new 
Abstract: Logs are essential for understanding Continuous Integration (CI) behavior, particularly for diagnosing build failures and performance regressions. Yet their growing volume and verbosity make both manual inspection and automated analysis increasingly costly, time-consuming, and environmentally costly. While prior work has explored log compression, anomaly detection, and LLM-based log analysis, most efforts target structured system logs rather than the unstructured, noisy, and verbose logs typical of CI workflows.
  We present LogSieve, a lightweight, RCA-aware and semantics-preserving log reduction technique that filters low-information lines while retaining content relevant to downstream reasoning. Evaluated on CI logs from 20 open-source Android projects using GitHub Actions, LogSieve achieves an average 42% reduction in lines and 40% reduction in tokens with minimal semantic loss. This pre-inference reduction lowers computational cost and can proportionally reduce energy use (and associated emissions) by decreasing the volume of data processed during LLM inference.
  Compared with structure-first baselines (LogZip and random-line removal), LogSieve preserves much higher semantic and categorical fidelity (Cosine = 0.93, GPTScore = 0.93, 80% exact-match accuracy). Embedding-based classifiers automate relevance detection with near-human accuracy (97%), enabling scalable and sustainable integration of semantics-aware filtering into CI workflows. LogSieve thus bridges log management and LLM reasoning, offering a practical path toward greener and more interpretable CI automation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20148v1</guid></item><item><title>[cs updates on arXiv.org] A Taylor Series Approach to Correct Localization Errors in Robotic Field Mapping using Gaussian Processes</title><link>https://arxiv.org/abs/2601.20149</link><description>arXiv:2601.20149v1 Announce Type: new 
Abstract: Gaussian Processes (GPs) are powerful non-parametric Bayesian models for regression of scalar fields, formulated under the assumption that measurement locations are perfectly known and the corresponding field measurements have Gaussian noise. However, many real-world scalar field mapping applications rely on sensor-equipped mobile robots to collect field measurements, where imperfect localization introduces state uncertainty. Such discrepancies between the estimated and true measurement locations degrade GP mean and covariance estimates. To address this challenge, we propose a method for updating the GP models when improved estimates become available. Leveraging the differentiability of the kernel function, a second-order correction algorithm is developed using the precomputed Jacobians and Hessians of the GP mean and covariance functions for real-time refinement based on measurement location discrepancy data. Simulation results demonstrate improved prediction accuracy and computational efficiency compared to full model retraining.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20149v1</guid></item><item><title>[cs updates on arXiv.org] Spectral Ghost in Representation Learning: from Component Analysis to Self-Supervised Learning</title><link>https://arxiv.org/abs/2601.20154</link><description>arXiv:2601.20154v1 Announce Type: new 
Abstract: Self-supervised learning (SSL) have improved empirical performance by unleashing the power of unlabeled data for practical applications. Specifically, SSL extracts the representation from massive unlabeled data, which will be transferred to a plenty of down streaming tasks with limited data. The significant improvement on diverse applications of representation learning has attracted increasing attention, resulting in a variety of dramatically different self-supervised learning objectives for representation extraction, with an assortment of learning procedures, but the lack of a clear and unified understanding. Such an absence hampers the ongoing development of representation learning, leaving a theoretical understanding missing, principles for efficient algorithm design unclear, and the use of representation learning methods in practice unjustified. The urgency for a unified framework is further motivated by the rapid growth in representation learning methods. In this paper, we are therefore compelled to develop a principled foundation of representation learning. We first theoretically investigate the sufficiency of the representation from a spectral representation view, which reveals the spectral essence of the existing successful SSL algorithms and paves the path to a unified framework for understanding and analysis. Such a framework work also inspires the development of more efficient and easy-to-use representation learning algorithms with principled way in real-world applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20154v1</guid></item><item><title>[cs updates on arXiv.org] PASS: Ambiguity Guided Subsets for Scalable Classical and Quantum Constrained Clustering</title><link>https://arxiv.org/abs/2601.20157</link><description>arXiv:2601.20157v1 Announce Type: new 
Abstract: Pairwise-constrained clustering augments unsupervised partitioning with side information by enforcing must-link (ML) and cannot-link (CL) constraints between specific samples, yielding labelings that respect known affinities and separations. However, ML and CL constraints add an extra layer of complexity to the clustering problem, with current methods struggling in data scalability, especially in niche applications like quantum or quantum-hybrid clustering. We propose PASS, a pairwise-constraints and ambiguity-driven subset selection framework that preserves ML and CL constraints satisfaction while allowing scalable, high-quality clustering solution. PASS collapses ML constraints into pseudo-points and offers two selectors: a constraint-aware margin rule that collects near-boundary points and all detected CL violations, and an information-geometric rule that scores points via a Fisher-Rao distance derived from soft assignment posteriors, then selects the highest-information subset under a simple budget. Across diverse benchmarks, PASS attains competitive SSE at substantially lower cost than exact or penalty-based methods, and remains effective in regimes where prior approaches fail.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20157v1</guid></item><item><title>[cs updates on arXiv.org] Cascaded Vulnerability Attacks in Software Supply Chains</title><link>https://arxiv.org/abs/2601.20158</link><description>arXiv:2601.20158v1 Announce Type: new 
Abstract: Most of the current software security analysis tools assess vulnerabilities in isolation. However, sophisticated software supply chain security threats often stem from cascaded vulnerability and security weakness chains that span dependent components. Moreover, although the adoption of Software Bills of Materials (SBOMs) has been accelerating, downstream vulnerability findings vary substantially across SBOM generators and analysis tools. We propose a novel approach to SBOM-driven security analysis methods and tools. We model vulnerability relationships over dependency structure rather than treating scanner outputs as independent records. We represent enriched SBOMs as heterogeneous graphs with nodes being the SBOM components and dependencies, the known software vulnerabilities, and the known software security weaknesses. We then train a Heterogeneous Graph Attention Network (HGAT) to predict whether a component is associated with at least one known vulnerability. Since documented multi-vulnerability chains are scarce, we model cascade discovery as a link prediction problem over CVE pairs using a multi-layer perceptron neural network. This way, we produce ranked candidate links that can be composed into multi-step paths. The HGAT component classifier achieves an Accuracy of 91.03% and an F1-score of 74.02%.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20158v1</guid></item><item><title>[cs updates on arXiv.org] How do Agents Refactor: An Empirical Study</title><link>https://arxiv.org/abs/2601.20160</link><description>arXiv:2601.20160v1 Announce Type: new 
Abstract: Software development agents such as Claude Code, GitHub Copilot, Cursor Agent, Devin, and OpenAI Codex are being increasingly integrated into developer workflows. While prior work has evaluated agent capabilities for code completion and task automation, there is little work investigating how these agents perform Java refactoring in practice, the types of changes they make, and their impact on code quality. In this study, we present the first analysis of agentic refactoring pull requests in Java, comparing them to developer refactorings across 86 projects per group. Using RefactoringMiner and DesigniteJava 3.0, we identify refactoring types and detect code smells before and after refactoring commits. Our results show that agent refactorings are dominated by annotation changes (the 5 most common refactoring types done by agents are annotation related), in contrast to the diverse structural improvements typical of developers. Despite these differences in refactoring types, we find Cursor to be the only model to show a statistically significant increase in refactoring smells.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20160v1</guid></item><item><title>[cs updates on arXiv.org] Supporting Informed Self-Disclosure: Design Recommendations for Presenting AI-Estimates of Privacy Risks to Users</title><link>https://arxiv.org/abs/2601.20161</link><description>arXiv:2601.20161v1 Announce Type: new 
Abstract: People candidly discuss sensitive topics online under the perceived safety of anonymity; yet, for many, this perceived safety is tenuous, as miscalibrated risk perceptions can lead to over-disclosure. Recent advances in Natural Language Processing (NLP) afford an unprecedented opportunity to present users with quantified disclosure-based re-identification risk (i.e., "population risk estimates", PREs). How can PREs be presented to users in a way that promotes informed decision-making, mitigating risk without encouraging unnecessary self-censorship? Using design fictions and comic-boarding, we story-boarded five design concepts for presenting PREs to users and evaluated them through an online survey with N = 44 Reddit users. We found participants had detailed conceptions of how PREs may impact risk awareness and motivation, but envisioned needing additional context and support to effectively interpret and act on risks. We distill our findings into four key design recommendations for how best to present users with quantified privacy risks to support informed disclosure decision-making.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20161v1</guid></item><item><title>[cs updates on arXiv.org] Me-Agent: A Personalized Mobile Agent with Two-Level User Habit Learning for Enhanced Interaction</title><link>https://arxiv.org/abs/2601.20162</link><description>arXiv:2601.20162v1 Announce Type: new 
Abstract: Large Language Model (LLM)-based mobile agents have made significant performance advancements. However, these agents often follow explicit user instructions while overlooking personalized needs, leading to significant limitations for real users, particularly without personalized context: (1) inability to interpret ambiguous instructions, (2) lack of learning from user interaction history, and (3) failure to handle personalized instructions. To alleviate the above challenges, we propose Me-Agent, a learnable and memorable personalized mobile agent. Specifically, Me-Agent incorporates a two-level user habit learning approach. At the prompt level, we design a user preference learning strategy enhanced with a Personal Reward Model to improve personalization performance. At the memory level, we design a Hierarchical Preference Memory, which stores users' long-term memory and app-specific memory in different level memory. To validate the personalization capabilities of mobile agents, we introduce User FingerTip, a new benchmark featuring numerous ambiguous instructions for daily life. Extensive experiments on User FingerTip and general benchmarks demonstrate that Me-Agent achieves state-of-the-art performance in personalization while maintaining competitive instruction execution performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20162v1</guid></item><item><title>[cs updates on arXiv.org] What's the plan? Metrics for implicit planning in LLMs and their application to rhyme generation and question answering</title><link>https://arxiv.org/abs/2601.20164</link><description>arXiv:2601.20164v1 Announce Type: new 
Abstract: Prior work suggests that language models, while trained on next token prediction, show implicit planning behavior: they may select the next token in preparation to a predicted future token, such as a likely rhyming word, as supported by a prior qualitative study of Claude 3.5 Haiku using a cross-layer transcoder. We propose much simpler techniques for assessing implicit planning in language models. With case studies on rhyme poetry generation and question answering, we demonstrate that our methodology easily scales to many models. Across models, we find that the generated rhyme (e.g. "-ight") or answer to a question ("whale") can be manipulated by steering at the end of the preceding line with a vector, affecting the generation of intermediate tokens leading up to the rhyme or answer word. We show that implicit planning is a universal mechanism, present in smaller models than previously thought, starting from 1B parameters. Our methodology offers a widely applicable direct way to study implicit planning abilities of LLMs. More broadly, understanding planning abilities of language models can inform decisions in AI safety and control.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20164v1</guid></item><item><title>[cs updates on arXiv.org] Efficient Token Pruning for LLaDA-V</title><link>https://arxiv.org/abs/2601.20168</link><description>arXiv:2601.20168v1 Announce Type: new 
Abstract: Diffusion-based large multimodal models, such as LLaDA-V, have demonstrated impressive capabilities in vision-language understanding and generation. However, their bidirectional attention mechanism and diffusion-style iterative denoising paradigm introduce significant computational overhead, as visual tokens are repeatedly processed across all layers and denoising steps. In this work, we conduct an in-depth attention analysis and reveal that, unlike autoregressive decoders, LLaDA-V aggregates cross-modal information predominantly in middle-to-late layers, leading to delayed semantic alignment. Motivated by this observation, we propose a structured token pruning strategy inspired by FastV, selectively removing a proportion of visual tokens at designated layers to reduce FLOPs while preserving critical semantic information. To the best of our knowledge, this is the first work to investigate structured token pruning in diffusion-based large multimodal models. Unlike FastV, which focuses on shallow-layer pruning, our method targets the middle-to-late layers of the first denoising step to align with LLaDA-V's delayed attention aggregation to maintain output quality, and the first-step pruning strategy reduces the computation across all subsequent steps. Our framework provides an empirical basis for efficient LLaDA-V inference and highlights the potential of vision-aware pruning in diffusion-based multimodal models. Across multiple benchmarks, our best configuration reduces computational cost by up to 65% while preserving an average of 95% task performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20168v1</guid></item><item><title>[cs updates on arXiv.org] Who Writes the Docs in SE 3.0? Agent vs. Human Documentation Pull Requests</title><link>https://arxiv.org/abs/2601.20171</link><description>arXiv:2601.20171v1 Announce Type: new 
Abstract: As software engineering moves toward SE3.0, AI agents are increasingly used to carry out development tasks and contribute changes to software projects. It is therefore important to understand the extent of these contributions and how human developers review and intervene, since these factors shape the risks of delegating work to AI agents. While recent studies have examined how AI agents support software development tasks (e.g., code generation, issue resolution, and PR automation), their role in documentation tasks remains underexplored-even though documentation is widely consumed and shapes how developers understand and use software.
  Using the AIDev, we analyze 1,997 documentation-related pull requests (PRs) authored by AI agents and human developers, where documentation PRs are those that create or modify project documentation artifacts. We find that AI agents submit substantially more documentation-related PRs than humans in the studied repositories. We further observe that agent-authored documentation edits are typically integrated with little follow-up modification from humans, raising concerns about review practices and the reliability of agent-generated documentation. Overall, while AI agents already contribute substantially to documentation workflows, our results suggest concerns for emerging challenges for documentation quality assurance and human-AI collaboration in SE3.0.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20171v1</guid></item><item><title>[cs updates on arXiv.org] Loss Landscape Geometry and the Learning of Symmetries: Or, What Influence Functions Reveal About Robust Generalization</title><link>https://arxiv.org/abs/2601.20172</link><description>arXiv:2601.20172v1 Announce Type: new 
Abstract: We study how neural emulators of partial differential equation solution operators internalize physical symmetries by introducing an influence-based diagnostic that measures the propagation of parameter updates between symmetry-related states, defined as the metric-weighted overlap of loss gradients evaluated along group orbits. This quantity probes the local geometry of the learned loss landscape and goes beyond forward-pass equivariance tests by directly assessing whether learning dynamics couple physically equivalent configurations. Applying our diagnostic to autoregressive fluid flow emulators, we show that orbit-wise gradient coherence provides the mechanism for learning to generalize over symmetry transformations and indicates when training selects a symmetry compatible basin. The result is a novel technique for evaluating if surrogate models have internalized symmetry properties of the known solution operator.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20172v1</guid></item><item><title>[cs updates on arXiv.org] MAPLE: Self-supervised Learning-Enhanced Nonlinear Dimensionality Reduction for Visual Analysis</title><link>https://arxiv.org/abs/2601.20173</link><description>arXiv:2601.20173v1 Announce Type: new 
Abstract: We present a new nonlinear dimensionality reduction method, MAPLE, that enhances UMAP by improving manifold modeling. MAPLE employs a self-supervised learning approach to more efficiently encode low-dimensional manifold geometry. Central to this approach are maximum manifold capacity representations (MMCRs), which help untangle complex manifolds by compressing variances among locally similar data points while amplifying variance among dissimilar data points. This design is particularly effective for high-dimensional data with substantial intra-cluster variance and curved manifold structures, such as biological or image data. Our qualitative and quantitative evaluations demonstrate that MAPLE can produce clearer visual cluster separations and finer subcluster resolution than UMAP while maintaining comparable computational cost.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20173v1</guid></item><item><title>[cs updates on arXiv.org] NeuraLSP: An Efficient and Rigorous Neural Left Singular Subspace Preconditioner for Conjugate Gradient Methods</title><link>https://arxiv.org/abs/2601.20174</link><description>arXiv:2601.20174v1 Announce Type: new 
Abstract: Numerical techniques for solving partial differential equations (PDEs) are integral for many fields across science and engineering. Such techniques usually involve solving large, sparse linear systems, where preconditioning methods are critical. In recent years, neural methods, particularly graph neural networks (GNNs), have demonstrated their potential through accelerated convergence. Nonetheless, to extract connective structures, existing techniques aggregate discretized system matrices into graphs, and suffer from rank inflation and a suboptimal convergence rate. In this paper, we articulate NeuraLSP, a novel neural preconditioner combined with a novel loss metric that leverages the left singular subspace of the system matrix's near-nullspace vectors. By compressing spectral information into a fixed low-rank operator, our method exhibits both theoretical guarantees and empirical robustness to rank inflation, affording up to a 53% speedup. Besides the theoretical guarantees for our newly-formulated loss function, our comprehensive experimental results across diverse families of PDEs also substantiate the aforementioned theoretical advances.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20174v1</guid></item><item><title>[cs updates on arXiv.org] TeleStyle: Content-Preserving Style Transfer in Images and Videos</title><link>https://arxiv.org/abs/2601.20175</link><description>arXiv:2601.20175v1 Announce Type: new 
Abstract: Content-preserving style transfer, generating stylized outputs based on content and style references, remains a significant challenge for Diffusion Transformers (DiTs) due to the inherent entanglement of content and style features in their internal representations. In this technical report, we present TeleStyle, a lightweight yet effective model for both image and video stylization. Built upon Qwen-Image-Edit, TeleStyle leverages the base model's robust capabilities in content preservation and style customization. To facilitate effective training, we curated a high-quality dataset of distinct specific styles and further synthesized triplets using thousands of diverse, in-the-wild style categories. We introduce a Curriculum Continual Learning framework to train TeleStyle on this hybrid dataset of clean (curated) and noisy (synthetic) triplets. This approach enables the model to generalize to unseen styles without compromising precise content fidelity. Additionally, we introduce a video-to-video stylization module to enhance temporal consistency and visual quality. TeleStyle achieves state-of-the-art performance across three core evaluation metrics: style similarity, content consistency, and aesthetic quality. Code and pre-trained models are available at https://github.com/Tele-AI/TeleStyle</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20175v1</guid></item><item><title>[cs updates on arXiv.org] Causal-Driven Feature Evaluation for Cross-Domain Image Classification</title><link>https://arxiv.org/abs/2601.20176</link><description>arXiv:2601.20176v1 Announce Type: new 
Abstract: Out-of-distribution (OOD) generalization remains a fundamental challenge in real-world classification, where test distributions often differ substantially from training data. Most existing approaches pursue domain-invariant representations, implicitly assuming that invariance implies reliability. However, features that are invariant across domains are not necessarily causally effective for prediction.
  In this work, we revisit OOD classification from a causal perspective and propose to evaluate learned representations based on their necessity and sufficiency under distribution shift. We introduce an explicit segment-level framework that directly measures causal effectiveness across domains, providing a more faithful criterion than invariance alone.
  Experiments on multi-domain benchmarks demonstrate consistent improvements in OOD performance, particularly under challenging domain shifts, highlighting the value of causal evaluation for robust generalization.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20176v1</guid></item><item><title>[cs updates on arXiv.org] On the Computational Complexity of Performative Prediction</title><link>https://arxiv.org/abs/2601.20180</link><description>arXiv:2601.20180v1 Announce Type: new 
Abstract: Performative prediction captures the phenomenon where deploying a predictive model shifts the underlying data distribution. While simple retraining dynamics are known to converge linearly when the performative effects are weak ($\rho &lt; 1$), the complexity in the regime $\rho &gt; 1$ was hitherto open. In this paper, we establish a sharp phase transition: computing an $\epsilon$-performatively stable point is PPAD-complete -- and thus polynomial-time equivalent to Nash equilibria in general-sum games -- even when $\rho = 1 + O(\epsilon)$. This intractability persists even in the ostensibly simple setting with a quadratic loss function and linear distribution shifts. One of our key technical contributions is to extend this PPAD-hardness result to general convex domains, which is of broader interest in the complexity of variational inequalities. Finally, we address the special case of strategic classification, showing that computing a strategic local optimum is PLS-hard.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20180v1</guid></item><item><title>[cs updates on arXiv.org] C-AoEI-Aware Cross-Layer Optimization in Satellite IoT Systems: Balancing Data Freshness and Transmission Efficiency</title><link>https://arxiv.org/abs/2601.20183</link><description>arXiv:2601.20183v1 Announce Type: new 
Abstract: Satellite-based Internet of Things (S-IoT) faces a fundamental trilemma: propagation delay, dynamic fading, and bandwidth scarcity. While Layer-coded Hybrid ARQ (L-HARQ) enhances reliability, its backtracking decoding introduces age ambiguity, undermining the standard Age of Information (AoI) metric and obscuring the critical trade-off between data freshness and transmission efficiency. To bridge this gap, we propose a novel cross-layer optimization framework centered on a new metric, the Cross-layer Age of Error Information (C-AoEI). We derive a closed-form expression for C-AoEI, explicitly linking freshness to system parameters, establishing an explicit analytical connection between freshness degradation and channel dynamics. Building on this, we develop a packet-level encoded L-HARQ scheme for multi-GBS scenarios and an adaptive algorithm that jointly optimizes coding and decision thresholds. Extensive simulations demonstrate the effectiveness of our proposed framework: it achieves 31.8% higher transmission efficiency and 17.2% lower C-AoEI than conventional schemes. The framework also proves robust against inter-cell interference and varying channel conditions, providing a foundation for designing efficient, latency-aware next-generation S-IoT protocols.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20183v1</guid></item><item><title>[cs updates on arXiv.org] Securing AI Agents in Cyber-Physical Systems: A Survey of Environmental Interactions, Deepfake Threats, and Defenses</title><link>https://arxiv.org/abs/2601.20184</link><description>arXiv:2601.20184v1 Announce Type: new 
Abstract: The increasing integration of AI agents into cyber-physical systems (CPS) introduces new security risks that extend beyond traditional cyber or physical threat models. Recent advances in generative AI enable deepfake and semantic manipulation attacks that can compromise agent perception, reasoning, and interaction with the physical environment, while emerging protocols such as the Model Context Protocol (MCP) further expand the attack surface through dynamic tool use and cross-domain context sharing. This survey provides a comprehensive review of security threats targeting AI agents in CPS, with a particular focus on environmental interactions, deepfake-driven attacks, and MCP-mediated vulnerabilities. We organize the literature using the SENTINEL framework, a lifecycle-aware methodology that integrates threat characterization, feasibility analysis under CPS constraints, defense selection, and continuous validation. Through an end-to-end case study grounded in a real-world smart grid deployment, we quantitatively illustrate how timing, noise, and false-positive costs constrain deployable defenses, and why detection mechanisms alone are insufficient as decision authorities in safety-critical CPS. The survey highlights the role of provenance- and physics-grounded trust mechanisms and defense-in-depth architectures, and outlines open challenges toward trustworthy AI-enabled CPS.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20184v1</guid></item><item><title>[cs updates on arXiv.org] Improving X-Codec-2.0 for Multi-Lingual Speech: 25 Hz Latent Rate and 24 kHz Sampling</title><link>https://arxiv.org/abs/2601.20185</link><description>arXiv:2601.20185v1 Announce Type: new 
Abstract: X-Codec-2.0 has shown strong performance in neural audio compression and multilingual speech modeling, operating at a 50 Hz latent rate and a 16 kHz sampling rate using frozen HuBERT features. While effective, this configuration limits temporal efficiency and audio fidelity. In this work, we explore a simple and effective modification by introducing additional pooling and increasing the decoder hop size. This reduces the latent rate from 50 Hz to 25 Hz and simultaneously raises the output sampling rate from 16 kHz to 24 kHz, improving efficiency and perceptual quality without altering the core architecture. Evaluated on the multilingual Common Voice 17 test set, the proposed configuration achieves a 0.29 MOS improvement over the original X-Codec-2.0 baseline based on UTMOSv2, and attains the best reported performance among all codecs operating at 25 Hz. The source code, checkpoints, and generation comparisons are released at \href{https://huggingface.co/Scicom-intl/xcodec2-25TPS-24k}{https://huggingface.co/Scicom-intl/xcodec2-25TPS-24k}.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20185v1</guid></item><item><title>[cs updates on arXiv.org] A direct sampling method for magnetic induction tomography</title><link>https://arxiv.org/abs/2601.20191</link><description>arXiv:2601.20191v1 Announce Type: new 
Abstract: This paper proposes a direct sampling method for the inverse problem of magnetic induction tomography (MIT). Our approach defines a class of point spread functions with explicit expressions, which are computed via inner products, leading to a simple and fast imaging process. We then prove that these point spread functions decay with distance, establishing the theoretical basis of the algorithm. Specific expressions for special cases are also derived to visually demonstrate their attenuation pattern. Numerical experimental results further confirm the efficiency and accuracy of the proposed algorithm.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20191v1</guid></item><item><title>[cs updates on arXiv.org] Meta-Cognitive Reinforcement Learning with Self-Doubt and Recovery</title><link>https://arxiv.org/abs/2601.20193</link><description>arXiv:2601.20193v1 Announce Type: new 
Abstract: Robust reinforcement learning methods typically focus on suppressing unreliable experiences or corrupted rewards, but they lack the ability to reason about the reliability of their own learning process. As a result, such methods often either overreact to noise by becoming overly conservative or fail catastrophically when uncertainty accumulates.
  In this work, we propose a meta-cognitive reinforcement learning framework that enables an agent to assess, regulate, and recover its learning behavior based on internally estimated reliability signals. The proposed method introduces a meta-trust variable driven by Value Prediction Error Stability (VPES), which modulates learning dynamics via fail-safe regulation and gradual trust recovery.
  Experiments on continuous-control benchmarks with reward corruption demonstrate that recovery-enabled meta-cognitive control achieves higher average returns and significantly reduces late-stage training failures compared to strong robustness baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20193v1</guid></item><item><title>[cs updates on arXiv.org] An Autonomous Agent Framework for Feature-Label Extraction from Device Dialogues and Automatic Multi-Dimensional Device Hosting Planning Based on Large Language Models</title><link>https://arxiv.org/abs/2601.20194</link><description>arXiv:2601.20194v1 Announce Type: new 
Abstract: With the deep integration of artificial intelligence and smart home technologies, the intelligent transformation of traditional household appliances has become an inevitable trend. This paper presents AirAgent--an LLM-driven autonomous agent framework designed for home air systems. Leveraging a voice-based dialogue interface, AirAgent autonomously and personally manages indoor air quality through comprehensive perception, reasoning, and control. The framework innovatively adopts a two-layer cooperative architecture: Memory-Based Tag Extraction and Reasoning-Driven Planning. First, a dynamic memory tag extraction module continuously updates personalized user profiles. Second, a reasoning-planning model integrates real-time environmental sensor data, user states, and domain-specific prior knowledge (e.g., public health guidelines) to generate context-aware decisions. To support both interpretability and execution, we design a semi-streaming output mechanism that uses special tokens to segment the model's output stream in real time, simultaneously producing human-readable Chain-of-Thought explanations and structured, device-executable control commands. The system handles planning across 25 distinct complex dimensions while satisfying more than 20 customized constraints. As a result, AirAgent endows home air systems with proactive perception, service, and orchestration capabilities, enabling seamless, precise, and personalized air management responsive to dynamic indoor and outdoor conditions. Experimental results demonstrate up to 94.9 percent accuracy and more than 20 percent improvement in user experience metrics compared to competing commercial solutions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20194v1</guid></item><item><title>[cs updates on arXiv.org] Automated Marine Biofouling Assessment: Benchmarking Computer Vision and Multimodal LLMs on the Level of Fouling Scale</title><link>https://arxiv.org/abs/2601.20196</link><description>arXiv:2601.20196v1 Announce Type: new 
Abstract: Marine biofouling on vessel hulls poses major ecological, economic, and biosecurity risks. Traditional survey methods rely on diver inspections, which are hazardous and limited in scalability. This work investigates automated classification of biofouling severity on the Level of Fouling (LoF) scale using both custom computer vision models and large multimodal language models (LLMs). Convolutional neural networks, transformer-based segmentation, and zero-shot LLMs were evaluated on an expert-labelled dataset from the New Zealand Ministry for Primary Industries. Computer vision models showed high accuracy at extreme LoF categories but struggled with intermediate levels due to dataset imbalance and image framing. LLMs, guided by structured prompts and retrieval, achieved competitive performance without training and provided interpretable outputs. The results demonstrate complementary strengths across approaches and suggest that hybrid methods integrating segmentation coverage with LLM reasoning offer a promising pathway toward scalable and interpretable biofouling assessment.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20196v1</guid></item><item><title>[cs updates on arXiv.org] DeRaDiff: Denoising Time Realignment of Diffusion Models</title><link>https://arxiv.org/abs/2601.20198</link><description>arXiv:2601.20198v1 Announce Type: new 
Abstract: Recent advances align diffusion models with human preferences to increase aesthetic appeal and mitigate artifacts and biases. Such methods aim to maximize a conditional output distribution aligned with higher rewards whilst not drifting far from a pretrained prior. This is commonly enforced by KL (Kullback Leibler) regularization. As such, a central issue still remains: how does one choose the right regularization strength? Too high of a strength leads to limited alignment and too low of a strength leads to "reward hacking". This renders the task of choosing the correct regularization strength highly non-trivial. Existing approaches sweep over this hyperparameter by aligning a pretrained model at multiple regularization strengths and then choose the best strength. Unfortunately, this is prohibitively expensive. We introduce DeRaDiff, a denoising time realignment procedure that, after aligning a pretrained model once, modulates the regularization strength during sampling to emulate models trained at other regularization strengths without any additional training or finetuning. Extending decoding-time realignment from language to diffusion models, DeRaDiff operates over iterative predictions of continuous latents by replacing the reverse step reference distribution by a geometric mixture of an aligned and reference posterior, thus giving rise to a closed form update under common schedulers and a single tunable parameter, lambda, for on the fly control. Our experiments show that across multiple text image alignment and image-quality metrics, our method consistently provides a strong approximation for models aligned entirely from scratch at different regularization strengths. Thus, our method yields an efficient way to search for the optimal strength, eliminating the need for expensive alignment sweeps and thereby substantially reducing computational costs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20198v1</guid></item><item><title>[cs updates on arXiv.org] MERGE: Next-Generation Item Indexing Paradigm for Large-Scale Streaming Recommendation</title><link>https://arxiv.org/abs/2601.20199</link><description>arXiv:2601.20199v1 Announce Type: new 
Abstract: Item indexing, which maps a large corpus of items into compact discrete representations, is critical for both discriminative and generative recommender systems, yet existing Vector Quantization (VQ)-based approaches struggle with the highly skewed and non-stationary item distributions common in streaming industry recommenders, leading to poor assignment accuracy, imbalanced cluster occupancy, and insufficient cluster separation. To address these challenges, we propose MERGE, a next-generation item indexing paradigm that adaptively constructs clusters from scratch, dynamically monitors cluster occupancy, and forms hierarchical index structures via fine-to-coarse merging. Extensive experiments demonstrate that MERGE significantly improves assignment accuracy, cluster uniformity, and cluster separation compared with existing indexing methods, while online A/B tests show substantial gains in key business metrics, highlighting its potential as a foundational indexing approach for large-scale recommendation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20199v1</guid></item><item><title>[cs updates on arXiv.org] Minimum-Cost Network Flow with Dual Predictions</title><link>https://arxiv.org/abs/2601.20203</link><description>arXiv:2601.20203v1 Announce Type: new 
Abstract: Recent work has shown that machine-learned predictions can provably improve the performance of classic algorithms. In this work, we propose the first minimum-cost network flow algorithm augmented with a dual prediction. Our method is based on a classic minimum-cost flow algorithm, namely $\varepsilon$-relaxation. We provide time complexity bounds in terms of the infinity norm prediction error, which is both consistent and robust. We also prove sample complexity bounds for PAC-learning the prediction. We empirically validate our theoretical results on two applications of minimum-cost flow, i.e., traffic networks and chip escape routing, in which we learn a fixed prediction, and a feature-based neural network model to infer the prediction, respectively. Experimental results illustrate $12.74\times$ and $1.64\times$ average speedup on two applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20203v1</guid></item><item><title>[cs updates on arXiv.org] Hyperparameter Transfer with Mixture-of-Expert Layers</title><link>https://arxiv.org/abs/2601.20205</link><description>arXiv:2601.20205v1 Announce Type: new 
Abstract: Mixture-of-Experts (MoE) layers have emerged as an important tool in scaling up modern neural networks by decoupling total trainable parameters from activated parameters in the forward pass for each token. However, sparse MoEs add complexity to training due to (i) new trainable parameters (router weights) that, like all other parameter groups, require hyperparameter (HP) tuning; (ii) new architecture scale dimensions (number of and size of experts) that must be chosen and potentially taken large. To make HP selection cheap and reliable, we propose a new parameterization for transformer models with MoE layers when scaling model width, depth, number of experts, and expert (hidden) size. Our parameterization is justified by a novel dynamical mean-field theory (DMFT) analysis. When varying different model dimensions trained at a fixed token budget, we find empirically that our parameterization enables reliable HP transfer across models from 51M to over 2B total parameters. We further take HPs identified from sweeping small models on a short token horizon to train larger models on longer horizons and report performant model behaviors.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20205v1</guid></item><item><title>[cs updates on arXiv.org] Towards Intelligent Urban Park Development Monitoring: LLM Agents for Multi-Modal Information Fusion and Analysis</title><link>https://arxiv.org/abs/2601.20206</link><description>arXiv:2601.20206v1 Announce Type: new 
Abstract: As an important part of urbanization, the development monitoring of newly constructed parks is of great significance for evaluating the effect of urban planning and optimizing resource allocation. However, traditional change detection methods based on remote sensing imagery have obvious limitations in high-level and intelligent analysis, and thus are difficult to meet the requirements of current urban planning and management. In face of the growing demand for complex multi-modal data analysis in urban park development monitoring, these methods often fail to provide flexible analysis capabilities for diverse application scenarios. This study proposes a multi-modal LLM agent framework, which aims to make full use of the semantic understanding and reasoning capabilities of LLM to meet the challenges in urban park development monitoring. In this framework, a general horizontal and vertical data alignment mechanism is designed to ensure the consistency and effective tracking of multi-modal data. At the same time, a specific toolkit is constructed to alleviate the hallucination issues of LLM due to the lack of domain-specific knowledge. Compared to vanilla GPT-4o and other agents, our approach enables robust multi-modal information fusion and analysis, offering reliable and scalable solutions tailored to the diverse and evolving demands of urban park development monitoring.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20206v1</guid></item><item><title>[cs updates on arXiv.org] Local Regularity Estimation through Sobolev-Scale Norm Profile</title><link>https://arxiv.org/abs/2601.20207</link><description>arXiv:2601.20207v1 Announce Type: new 
Abstract: We develop a kernel-based approach for estimating the spatially varying Sobolev regularity~$s$ of an unknown $d$-variate function~$f$ from scattered sampling data, which quantifies the degree of local differentiability supported by the data. Relying only on neighborhood data near the point of interest $z\in \Omega_z$, our method constructs a sequence of Sobolev-space reproducing kernel interpolants whose kernel smoothness order is specified by an index~$m &gt; d/2$. The native-space norms of these interpolants are evaluated over a bounded range of~$m$, producing a \emph{Sobolev-scale norm profile}. The elbow of this profile serves as a quantitative probe of the underlying local regularity~$s(\Omega_z)$. In particular, when $m &gt; s(\Omega_z)$, the profile exhibits rapid, near-worst-case growth governed by the classical upper bound associated with the conditioning of the kernel matrix. A band-limited surrogate analysis explains this transition and establishes a lower-bound relation linking native-norm growth to the Sobolev regularity of~$f$. Two complementary strategies are incorporated for further enhancement: (i)~a \emph{stencil-shift} subroutine, which repositions local neighborhoods to avoid crossing discontinuities whenever possible, thereby suppressing artifacts in the norm estimates; and (ii)~a local--global \emph{norm-sweep comparison} strategy that combines short two-point local tails with an optional one-point global screen to detect outlier $\Omega_z$ of low Sobolev regularity and accelerate evaluation on large datasets. Numerical experiments on synthetic test functions and turbulent-flow data demonstrate accurate recovery of spatially varying regularity and confirm the robustness of the proposed characterization for kernel-based approximation and differentiation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20207v1</guid></item><item><title>[cs updates on arXiv.org] TRACER: Texture-Robust Affordance Chain-of-Thought for Deformable-Object Refinement</title><link>https://arxiv.org/abs/2601.20208</link><description>arXiv:2601.20208v1 Announce Type: new 
Abstract: The central challenge in robotic manipulation of deformable objects lies in aligning high-level semantic instructions with physical interaction points under complex appearance and texture variations. Due to near-infinite degrees of freedom, complex dynamics, and heterogeneous patterns, existing vision-based affordance prediction methods often suffer from boundary overflow and fragmented functional regions. To address these issues, we propose TRACER, a Texture-Robust Affordance Chain-of-thought with dEformable-object Refinement framework, which establishes a cross-hierarchical mapping from hierarchical semantic reasoning to appearance-robust and physically consistent functional region refinement. Specifically, a Tree-structured Affordance Chain-of-Thought (TA-CoT) is formulated to decompose high-level task intentions into hierarchical sub-task semantics, providing consistent guidance across various execution stages. To ensure spatial integrity, a Spatial-Constrained Boundary Refinement (SCBR) mechanism is introduced to suppress prediction spillover, guiding the perceptual response to converge toward authentic interaction manifolds. Furthermore, an Interactive Convergence Refinement Flow (ICRF) is developed to aggregate discrete pixels corrupted by appearance noise, significantly enhancing the spatial continuity and physical plausibility of the identified functional regions. Extensive experiments conducted on the Fine-AGDDO15 dataset and a real-world robotic platform demonstrate that TRACER significantly improves affordance grounding precision across diverse textures and patterns inherent to deformable objects. More importantly, it enhances the success rate of long-horizon tasks, effectively bridging the gap between high-level semantic reasoning and low-level physical execution. The source code and dataset will be made publicly available at https://github.com/Dikay1/TRACER.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20208v1</guid></item><item><title>[cs updates on arXiv.org] Spark: Strategic Policy-Aware Exploration via Dynamic Branching for Long-Horizon Agentic Learning</title><link>https://arxiv.org/abs/2601.20209</link><description>arXiv:2601.20209v1 Announce Type: new 
Abstract: Reinforcement learning has empowered large language models to act as intelligent agents, yet training them for long-horizon tasks remains challenging due to the scarcity of high-quality trajectories, especially under limited resources. Existing methods typically scale up rollout sizes and indiscriminately allocate computational resources among intermediate steps. Such attempts inherently waste substantial computation budget on trivial steps while failing to guarantee sample quality. To address this, we propose \textbf{Spark} (\textbf{S}trategic \textbf{P}olicy-\textbf{A}ware explo\textbf{R}ation via \textbf{K}ey-state dynamic branching), a novel framework that selectively branches at critical decision states for resource-efficient exploration. Our key insight is to activate adaptive branching exploration at critical decision points to probe promising trajectories, thereby achieving precise resource allocation that prioritizes sampling quality over blind coverage. This design leverages the agent's intrinsic decision-making signals to reduce dependence on human priors, enabling the agent to autonomously expand exploration and achieve stronger generalization. Experiments across diverse tasks (e.g., embodied planning), demonstrate that \textsc{Spark} achieves superior success rates with significantly fewer training samples, exhibiting robust generalization even in unseen scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20209v1</guid></item><item><title>[cs updates on arXiv.org] High-Resolution Mapping of Port Dynamics from Open-Access AIS Data in Tokyo Bay</title><link>https://arxiv.org/abs/2601.20211</link><description>arXiv:2601.20211v1 Announce Type: new 
Abstract: Knowledge about vessel activity in port areas and around major industrial zones provides insights into economic trends, supports decision-making for shipping and port operators, and contributes to maritime safety. Vessel data from terrestrial receivers of the Automatic Identification System (AIS) have become increasingly openly available, and we demonstrate that such data can be used to infer port activities at high resolution and with precision comparable to official statistics. We analyze open-access AIS data from a three-month period in 2024 for Tokyo Bay, located in Japan's most densely populated urban region. Accounting for uneven data coverage, we reconstruct vessel activity in Tokyo Bay at $\sim\,$30~m resolution and identify 161 active berths across seven major port areas in the bay. During the analysis period, we find an average of $35\pm17_{\text{stat}}$ vessels moving within the bay at any given time, and $293\pm22_{\text{stat}}+65_{\text{syst}}-10_{\text{syst}}$ vessels entering or leaving the bay daily, with an average gross tonnage of $11{,}860^{+280}_{-\;\,50}$. These figures indicate an accelerating long-term trend toward fewer but larger vessels in Tokyo Bay's commercial traffic. Furthermore, we find that in dense urban environments, radio shadows in vessel AIS data can reveal the precise locations of inherently passive receiver stations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20211v1</guid></item><item><title>[cs updates on arXiv.org] Towards End-to-End Alignment of User Satisfaction via Questionnaire in Video Recommendation</title><link>https://arxiv.org/abs/2601.20215</link><description>arXiv:2601.20215v1 Announce Type: new 
Abstract: Short-video recommender systems typically optimize ranking models using dense user behavioral signals, such as clicks and watch time. However, these signals are only indirect proxies of user satisfaction and often suffer from noise and bias. Recently, explicit satisfaction feedback collected through questionnaires has emerged as a high-quality direct alignment supervision, but is extremely sparse and easily overwhelmed by abundant behavioral data, making it difficult to incorporate into online recommendation models. To address these challenges, we propose a novel framework which is towards End-to-End Alignment of user Satisfaction via Questionaire, named EASQ, to enable real-time alignment of ranking models with true user satisfaction. Specifically, we first construct an independent parameter pathway for sparse questionnaire signals by combining a multi-task architecture and a lightweight LoRA module. The multi-task design separates sparse satisfaction supervision from dense behavioral signals, preventing the former from being overwhelmed. The LoRA module pre-inject these preferences in a parameter-isolated manner, ensuring stability in the backbone while optimizing user satisfaction. Furthermore, we employ a DPO-based optimization objective tailored for online learning, which aligns the main model outputs with sparse satisfaction signals in real time. This design enables end-to-end online learning, allowing the model to continuously adapt to new questionnaire feedback while maintaining the stability and effectiveness of the backbone. Extensive offline experiments and large-scale online A/B tests demonstrate that EASQ consistently improves user satisfaction metrics across multiple scenarios. EASQ has been successfully deployed in a production short-video recommendation system, delivering significant and stable business gains.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20215v1</guid></item><item><title>[cs updates on arXiv.org] DenseGRPO: From Sparse to Dense Reward for Flow Matching Model Alignment</title><link>https://arxiv.org/abs/2601.20218</link><description>arXiv:2601.20218v1 Announce Type: new 
Abstract: Recent GRPO-based approaches built on flow matching models have shown remarkable improvements in human preference alignment for text-to-image generation. Nevertheless, they still suffer from the sparse reward problem: the terminal reward of the entire denoising trajectory is applied to all intermediate steps, resulting in a mismatch between the global feedback signals and the exact fine-grained contributions at intermediate denoising steps. To address this issue, we introduce \textbf{DenseGRPO}, a novel framework that aligns human preference with dense rewards, which evaluates the fine-grained contribution of each denoising step. Specifically, our approach includes two key components: (1) we propose to predict the step-wise reward gain as dense reward of each denoising step, which applies a reward model on the intermediate clean images via an ODE-based approach. This manner ensures an alignment between feedback signals and the contributions of individual steps, facilitating effective training; and (2) based on the estimated dense rewards, a mismatch drawback between the uniform exploration setting and the time-varying noise intensity in existing GRPO-based methods is revealed, leading to an inappropriate exploration space. Thus, we propose a reward-aware scheme to calibrate the exploration space by adaptively adjusting a timestep-specific stochasticity injection in the SDE sampler, ensuring a suitable exploration space at all timesteps. Extensive experiments on multiple standard benchmarks demonstrate the effectiveness of the proposed DenseGRPO and highlight the critical role of the valid dense rewards in flow matching model alignment.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20218v1</guid></item><item><title>[cs updates on arXiv.org] Scaling Medical Reasoning Verification via Tool-Integrated Reinforcement Learning</title><link>https://arxiv.org/abs/2601.20221</link><description>arXiv:2601.20221v1 Announce Type: new 
Abstract: Large language models have achieved strong performance on medical reasoning benchmarks, yet their deployment in clinical settings demands rigorous verification to ensure factual accuracy. While reward models offer a scalable approach for reasoning trace verification, existing methods face two limitations: they produce only scalar reward values without explicit justification, and they rely on single-pass retrieval that precludes adaptive knowledge access as verification unfolds. We introduce $\method$, an agentic framework that addresses these limitations by training medical reasoning verifiers to iteratively query external medical corpora during evaluation. Our approach combines tool-augmented verification with an iterative reinforcement learning paradigm that requires only trace-level supervision, alongside an adaptive curriculum mechanism that dynamically adjusts training data distribution. Across four medical reasoning benchmarks, $\method$ achieves substantial gains over existing methods, improving MedQA accuracy by 23.5% and MedXpertQA by 32.0% relative to the base generator in particular. Crucially, $\method$ demonstrates an $\mathbf{8\times}$ reduction in sampling budget requirement compared to prior reward model baselines. These findings establish that grounding verification in dynamically retrieved evidence offers a principled path toward more reliable medical reasoning systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20221v1</guid></item><item><title>[cs updates on arXiv.org] Control Models for In-IDE Code Completion</title><link>https://arxiv.org/abs/2601.20223</link><description>arXiv:2601.20223v1 Announce Type: new 
Abstract: We introduce control models for LLM-powered code completion in JetBrains IDEs: ML classifiers which trigger inference and filter the generated suggestions to better align them with users and reduce unnecessary requests. To this end, we evaluate boosting- and transformer-based architectures on an offline dataset of real code completions with n=98 users. We further evaluate the offline classification performance of our boosting-based approach on a range of syntactically diverse languages; and perform an A/B study in a production environment where they improve completion efficiency and quality metrics. With this study, we hope to demonstrate the potential in using auxiliary models for smarter in-IDE integration of LLM-driven features, highlight fruitful future directions, and open problems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20223v1</guid></item><item><title>[cs updates on arXiv.org] Feature Projection Learning for Better Vision-Language Reasoning</title><link>https://arxiv.org/abs/2601.20224</link><description>arXiv:2601.20224v1 Announce Type: new 
Abstract: Vision-Language Pre-Trained models, notably CLIP, that utilize contrastive learning have proven highly adept at extracting generalizable visual features. To inherit the well-learned knowledge of VLP models for downstream tasks, several approaches aim to adapt them efficiently with limited supervision. However, these methods either suffer from limited performance, excessive learnable parameters, or extended training times, all of which hinder their effectiveness in adapting the CLIP model to downstream tasks. In this work, we propose a simple yet efficient and effective method called \textit{\textbf{F}eature \textbf{P}rojection \textbf{L}earning(FPL)} to address these problems. Specifically, we develop a projection model that projects class prototype features into the query image feature space and reconstructs the query image feature map. The negative average squared reconstruction error is used as the class score. In this way, we transform the classification problem into a feature projection problem. The final output of this method is a combination of the prediction from the projection model and the original pre-trained CLIP. Comprehensive empirical evaluations confirm that FPL delivers superior accuracy, surpassing the current state-of-the-art methods by a substantial margin.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20224v1</guid></item><item><title>[cs updates on arXiv.org] Parametric and Generative Forecasts of Day-Ahead Market Curves for Storage Optimization</title><link>https://arxiv.org/abs/2601.20226</link><description>arXiv:2601.20226v1 Announce Type: new 
Abstract: We present two machine learning frameworks for forecasting aggregated curves and optimizing storage in the EPEX SPOT day-ahead market. First, a fast parametric model forecasts hourly demand and supply curves in a low-dimensional and grid-robust representation, with minimum and maximum volumes combined with a Chebyshev polynomial for the elastic segment. The model enables daily use with low error and clear interpretability. Second, for a more comprehensive analysis, though less suited to daily operation, we employ generative models that learn the joint distribution of 24-hour order-level submissions given weather and fuel variables. These models generate synthetic daily scenarios of individual buy and sell orders, which, once aggregated, yield hourly supply and demand curves. Based on these forecasts, we optimize a price-making storage strategy, quantify revenue distributions, and highlight the price-compression effect with lower peaks, higher off-peak levels, and diminishing returns as capacity expands.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20226v1</guid></item><item><title>[cs updates on arXiv.org] ProFlow: Zero-Shot Physics-Consistent Sampling via Proximal Flow Guidance</title><link>https://arxiv.org/abs/2601.20227</link><description>arXiv:2601.20227v1 Announce Type: new 
Abstract: Inferring physical fields from sparse observations while strictly satisfying partial differential equations (PDEs) is a fundamental challenge in computational physics. Recently, deep generative models offer powerful data-driven priors for such inverse problems, yet existing methods struggle to enforce hard physical constraints without costly retraining or disrupting the learned generative prior. Consequently, there is a critical need for a sampling mechanism that can reconcile strict physical consistency and observational fidelity with the statistical structure of the pre-trained prior. To this end, we present ProFlow, a proximal guidance framework for zero-shot physics-consistent sampling, defined as inferring solutions from sparse observations using a fixed generative prior without task-specific retraining. The algorithm employs a rigorous two-step scheme that alternates between: (\romannumeral1) a terminal optimization step, which projects the flow prediction onto the intersection of the physically and observationally consistent sets via proximal minimization; and (\romannumeral2) an interpolation step, which maps the refined state back to the generative trajectory to maintain consistency with the learned flow probability path. This procedure admits a Bayesian interpretation as a sequence of local maximum a posteriori (MAP) updates. Comprehensive benchmarks on Poisson, Helmholtz, Darcy, and viscous Burgers' equations demonstrate that ProFlow achieves superior physical and observational consistency, as well as more accurate distributional statistics, compared to state-of-the-art diffusion- and flow-based baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20227v1</guid></item><item><title>[cs updates on arXiv.org] Proactive SFC Provisioning with Forecast-Driven DRL in Data Centers</title><link>https://arxiv.org/abs/2601.20229</link><description>arXiv:2601.20229v1 Announce Type: new 
Abstract: Service Function Chaining (SFC) requires efficient placement of Virtual Network Functions (VNFs) to satisfy diverse service requirements while maintaining high resource utilization in Data Centers (DCs). Conventional static resource allocation often leads to overprovisioning or underprovisioning due to the dynamic nature of traffic loads and application demands. To address this challenge, we propose a hybrid forecast-driven Deep reinforcement learning (DRL) framework that combines predictive intelligence with SFC provisioning. Specifically, we leverage DRL to generate datasets capturing DC resource utilization and service demands, which are then used to train deep learning forecasting models. Using Optuna-based hyperparameter optimization, the best-performing models, Spatio-Temporal Graph Neural Network, Temporal Graph Neural Network, and Long Short-Term Memory, are combined into an ensemble to enhance stability and accuracy. The ensemble predictions are integrated into the DC selection process, enabling proactive placement decisions that consider both current and future resource availability. Experimental results demonstrate that the proposed method not only sustains high acceptance ratios for resource-intensive services such as Cloud Gaming and VoIP but also significantly improves acceptance ratios for latency-critical categories such as Augmented Reality increases from 30% to 50%, while Industry 4.0 improves from 30% to 45%. Consequently, the prediction-based model achieves significantly lower E2E latencies of 20.5%, 23.8%, and 34.8% reductions for VoIP, Video Streaming, and Cloud Gaming, respectively. This strategy ensures more balanced resource allocation, and reduces contention.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20229v1</guid></item><item><title>[cs updates on arXiv.org] Unit-Based Agent for Semi-Cascaded Full-Duplex Dialogue Systems</title><link>https://arxiv.org/abs/2601.20230</link><description>arXiv:2601.20230v1 Announce Type: new 
Abstract: Full-duplex voice interaction is crucial for natural human computer interaction. We present a framework that decomposes complex dialogue into minimal conversational units, enabling the system to process each unit independently and predict when to transit to the next. This framework is instantiated as a semi-cascaded full-duplex dialogue system built around a multimodal large language model, supported by auxiliary modules such as voice activity detection (VAD) and text-to-speech (TTS) synthesis. The resulting system operates in a train-free, plug-and-play manner. Experiments on the HumDial dataset demonstrate the effectiveness of our framework, which ranks second among all teams on the test set of the Human-like Spoken Dialogue Systems Challenge (Track 2: Full-Duplex Interaction). Code is available at the GitHub repository https://github.com/yu-haoyuan/fd-badcat.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20230v1</guid></item><item><title>[cs updates on arXiv.org] Certificate-Guided Pruning for Stochastic Lipschitz Optimization</title><link>https://arxiv.org/abs/2601.20231</link><description>arXiv:2601.20231v1 Announce Type: new 
Abstract: We study black-box optimization of Lipschitz functions under noisy evaluations. Existing adaptive discretization methods implicitly avoid suboptimal regions but do not provide explicit certificates of optimality or measurable progress guarantees. We introduce \textbf{Certificate-Guided Pruning (CGP)}, which maintains an explicit \emph{active set} $A_t$ of potentially optimal points via confidence-adjusted Lipschitz envelopes. Any point outside $A_t$ is certifiably suboptimal with high probability, and under a margin condition with near-optimality dimension $\alpha$, we prove $\Vol(A_t)$ shrinks at a controlled rate yielding sample complexity $\tildeO(\varepsilon^{-(2+\alpha)})$. We develop three extensions: CGP-Adaptive learns $L$ online with $O(\log T)$ overhead; CGP-TR scales to $d &gt; 50$ via trust regions with local certificates; and CGP-Hybrid switches to GP refinement when local smoothness is detected. Experiments on 12 benchmarks ($d \in [2, 100]$) show CGP variants match or exceed strong baselines while providing principled stopping criteria via certificate volume.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20231v1</guid></item><item><title>[cs updates on arXiv.org] Visual Prompt-Agnostic Evolution</title><link>https://arxiv.org/abs/2601.20232</link><description>arXiv:2601.20232v1 Announce Type: new 
Abstract: Visual Prompt Tuning (VPT) adapts a frozen Vision Transformer (ViT) to downstream tasks by inserting a small number of learnable prompt tokens into the token sequence at each layer. However, we observe that existing VPT variants often suffer from unstable training dynamics, characterized by gradient oscillations. A layer-wise analysis reveals that shallow-layer prompts tend to stagnate early, while deeper-layer prompts exhibit high-variance oscillations, leading to cross-layer mismatch. These issues slow convergence and degrade final performance. To address these challenges, we propose Prompt-Agnostic Evolution ($\mathtt{PAE}$), which strengthens vision prompt tuning by explicitly modeling prompt dynamics. From a frequency-domain perspective, we initialize prompts in a task-aware direction by uncovering and propagating frequency shortcut patterns that the backbone inherently exploits for recognition. To ensure coherent evolution across layers, we employ a shared Koopman operator that imposes a global linear transformation instead of uncoordinated, layer-specific updates. Finally, inspired by Lyapunov stability theory, we introduce a regularizer that constrains error amplification during evolution. Extensive experiments show that $\mathtt{PAE}$ accelerates convergence with an average $1.41\times$ speedup and improves accuracy by 1--3% on 25 datasets across multiple downstream tasks. Beyond performance, $\mathtt{PAE}$ is prompt-agnostic and lightweight, and it integrates seamlessly with diverse VPT variants without backbone modification or inference-time changes.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20232v1</guid></item><item><title>[cs updates on arXiv.org] MALLOC: Benchmarking the Memory-aware Long Sequence Compression for Large Sequential Recommendation</title><link>https://arxiv.org/abs/2601.20234</link><description>arXiv:2601.20234v1 Announce Type: new 
Abstract: The scaling law, which indicates that model performance improves with increasing dataset and model capacity, has fueled a growing trend in expanding recommendation models in both industry and academia. However, the advent of large-scale recommenders also brings significantly higher computational costs, particularly under the long-sequence dependencies inherent in the user intent of recommendation systems. Current approaches often rely on pre-storing the intermediate states of the past behavior for each user, thereby reducing the quadratic re-computation cost for the following requests. Despite their effectiveness, these methods often treat memory merely as a medium for acceleration, without adequately considering the space overhead it introduces. This presents a critical challenge in real-world recommendation systems with billions of users, each of whom might initiate thousands of interactions and require massive memory for state storage. Fortunately, there have been several memory management strategies examined for compression in LLM, while most have not been evaluated on the recommendation task. To mitigate this gap, we introduce MALLOC, a comprehensive benchmark for memory-aware long sequence compression. MALLOC presents a comprehensive investigation and systematic classification of memory management techniques applicable to large sequential recommendations. These techniques are integrated into state-of-the-art recommenders, enabling a reproducible and accessible evaluation platform. Through extensive experiments across accuracy, efficiency, and complexity, we demonstrate the holistic reliability of MALLOC in advancing large-scale recommendation. Code is available at https://anonymous.4open.science/r/MALLOC.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20234v1</guid></item><item><title>[cs updates on arXiv.org] A Unified Variational Functional for Equidistribution and Alignment in Moving Mesh Adaptation</title><link>https://arxiv.org/abs/2601.20235</link><description>arXiv:2601.20235v1 Announce Type: new 
Abstract: Existing variational mesh functionals often suffer from strong nonlinearity or dependence on empirical parameters.We propose a new variational functional for adaptive moving mesh generation that enforces equidistribution and alignment through an $\boldsymbol A$-pullback formulation, where $\boldsymbol A=\boldsymbol J^{-1}\boldsymbol M^{-1}\boldsymbol J^{-T}$. The functional combines a trace-based term with a logarithmic determinant term, achieving balanced control of mesh size and anisotropy without empirical parameters. We establish coercivity, polyconvexity, existence of minimizers, and geodesic convexity with respect to the inverse Jacobian, and derive a simplified geometric discretization leading to an efficient moving mesh algorithm. Numerical experiments confirm the theoretical properties and demonstrate robust adaptive behavior for function-induced meshes and Rayleigh-Taylor instability simulations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20235v1</guid></item><item><title>[cs updates on arXiv.org] TouchGuide: Inference-Time Steering of Visuomotor Policies via Touch Guidance</title><link>https://arxiv.org/abs/2601.20239</link><description>arXiv:2601.20239v1 Announce Type: new 
Abstract: Fine-grained and contact-rich manipulation remain challenging for robots, largely due to the underutilization of tactile feedback. To address this, we introduce TouchGuide, a novel cross-policy visuo-tactile fusion paradigm that fuses modalities within a low-dimensional action space. Specifically, TouchGuide operates in two stages to guide a pre-trained diffusion or flow-matching visuomotor policy at inference time. First, the policy produces a coarse, visually-plausible action using only visual inputs during early sampling. Second, a task-specific Contact Physical Model (CPM) provides tactile guidance to steer and refine the action, ensuring it aligns with realistic physical contact conditions. Trained through contrastive learning on limited expert demonstrations, the CPM provides a tactile-informed feasibility score to steer the sampling process toward refined actions that satisfy physical contact constraints. Furthermore, to facilitate TouchGuide training with high-quality and cost-effective data, we introduce TacUMI, a data collection system. TacUMI achieves a favorable trade-off between precision and affordability; by leveraging rigid fingertips, it obtains direct tactile feedback, thereby enabling the collection of reliable tactile data. Extensive experiments on five challenging contact-rich tasks, such as shoe lacing and chip handover, show that TouchGuide consistently and significantly outperforms state-of-the-art visuo-tactile policies.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20239v1</guid></item><item><title>[cs updates on arXiv.org] Understanding npm Developers' Practices, Challenges, and Recommendations for Secure Package Development</title><link>https://arxiv.org/abs/2601.20240</link><description>arXiv:2601.20240v1 Announce Type: new 
Abstract: Background: The Node Package Manager (npm) ecosystem plays a vital role in modern software development by providing a vast repository of packages and tools that developers can use to implement their software systems. However, recent vulnerabilities in third-party packages have led to serious security breaches, compromising the integrity of applications that depend on them. Objective: This study investigates how npm package developers perceive and handle security in their work. We examined developers' understanding of security risks, the practices and tools they use, the barriers to stronger security measures, and their suggestions for improving the npm ecosystem's security. Method: We conducted an online survey with 75 npm package developers and undertook a mixed-methods approach to analyzing their responses. Results: While developers prioritize security, they perceive their packages as only moderately secure, with concerns about supply chain attacks, dependency vulnerabilities, and malicious code. Only 40% are satisfied with the current npm security tools due to issues such as alert fatigue. Automated methods such as two-factor authentication and npm audit are favored over code reviews. Many drop dependencies due to abandonment or vulnerabilities, and typically respond to vulnerabilities in their packages by quickly releasing patches. Key barriers include time constraints and high false-positive rates. To improve npm security, developers seek better detection tools, clearer documentation, stronger account protections, and more education initiatives. Conclusion: Our findings will benefit npm package contributors and maintainers by highlighting prevalent security challenges and promoting discussions on best practices to strengthen security and trustworthiness within the npm landscape.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20240v1</guid></item><item><title>[cs updates on arXiv.org] Adequately Tailoring Age Verification Regulations</title><link>https://arxiv.org/abs/2601.20241</link><description>arXiv:2601.20241v1 Announce Type: new 
Abstract: The Supreme Court decision in Free Speech Coalition v. Paxton upheld the constitutionality of Texas H.B. 1181, one of the most constitutionally vulnerable of these age verification laws, holding that it was subject to and satisfied intermediate scrutiny and the requirement that age verification regulations be "adequately tailored". However, the decision leaves unresolved practical challenges. What is the current state of age verification legislation in the United States? How can "adequate tailoring" be interpreted in a way that is accessible to non-legal experts, particularly those in technical and engineering domains? What age verification approaches are used today, what infrastructures and standards support them, and what tradeoffs do they introduce? This paper addresses those questions by proposing an analytical model to interpret "adequate tailoring" from multiple perspectives with associated governmental goals and interests, and by applying that model to evaluate both current state laws and widely used verification methods. This paper's major contributions include: (1) we mapped the current U.S. age-verification legislative landscape; (2) we introduce an analytical model to analyze "adequate tailoring" for age verification and potential application to other online regulatory policies; and (3) we analyze the main technical approaches to age verification, highlighting the practical challenges and tradeoffs from a technical perspective. Further, while we focus on U.S. State laws, the principles underlying our framework are applicable to age-verification debates and methods worldwide.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20241v1</guid></item><item><title>[cs updates on arXiv.org] Element-based B-spline basis function spaces: construction and application in isogeometric analysis</title><link>https://arxiv.org/abs/2601.20243</link><description>arXiv:2601.20243v1 Announce Type: new 
Abstract: This paper develops a unified theoretical framework for constructing B-spline basis function spaces with structural equivalence to finite element spaces. The theory rigorously establishes that these bases emerge as explicit linear combinations of B-spline element bases. For any prescribed smoothness requirements, this element-wise formulation enables the Hermite interpolation at nodes, which directly utilizes function values and derivatives without solving global linear systems. By focusing on explicit interpolation properties, element-wise analysis establishes optimal approximation errors, even when the space smoothness attains its theoretical maximum for the space degree. In isogeometric analysis (IgA), the construction naturally decomposes geometric mappings into element-level representations, allowing efficient computations across elements regardless of node distribution. Notably, the same Hermite interpolation framework simultaneously handles domain parameterization and IgA solutions, allowing direct imposition of boundary conditions through function and derivative matching. Numerical tests demonstrate optimal convergence rates and superconvergence properties in 2D IgA under uniform knot configurations, and improved computational efficiency in 3D IgA with non-uniform knot distributions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20243v1</guid></item><item><title>[cs updates on arXiv.org] How AI Impacts Skill Formation</title><link>https://arxiv.org/abs/2601.20245</link><description>arXiv:2601.20245v1 Announce Type: new 
Abstract: AI assistance produces significant productivity gains across professional domains, particularly for novice workers. Yet how this assistance affects the development of skills required to effectively supervise AI remains unclear. Novice workers who rely heavily on AI to complete unfamiliar tasks may compromise their own skill acquisition in the process. We conduct randomized experiments to study how developers gained mastery of a new asynchronous programming library with and without the assistance of AI. We find that AI use impairs conceptual understanding, code reading, and debugging abilities, without delivering significant efficiency gains on average. Participants who fully delegated coding tasks showed some productivity improvements, but at the cost of learning the library. We identify six distinct AI interaction patterns, three of which involve cognitive engagement and preserve learning outcomes even when participants receive AI assistance. Our findings suggest that AI-enhanced productivity is not a shortcut to competence and AI assistance should be carefully adopted into workflows to preserve skill formation -- particularly in safety-critical domains.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20245v1</guid></item><item><title>[cs updates on arXiv.org] BLENDER: Blended Text Embeddings and Diffusion Residuals for Intra-Class Image Synthesis in Deep Metric Learning</title><link>https://arxiv.org/abs/2601.20246</link><description>arXiv:2601.20246v1 Announce Type: new 
Abstract: The rise of Deep Generative Models (DGM) has enabled the generation of high-quality synthetic data. When used to augment authentic data in Deep Metric Learning (DML), these synthetic samples enhance intra-class diversity and improve the performance of downstream DML tasks. We introduce BLenDeR, a diffusion sampling method designed to increase intra-class diversity for DML in a controllable way by leveraging set-theory inspired union and intersection operations on denoising residuals. The union operation encourages any attribute present across multiple prompts, while the intersection extracts the common direction through a principal component surrogate. These operations enable controlled synthesis of diverse attribute combinations within each class, addressing key limitations of existing generative approaches. Experiments on standard DML benchmarks demonstrate that BLenDeR consistently outperforms state-of-the-art baselines across multiple datasets and backbones. Specifically, BLenDeR achieves 3.7% increase in Recall@1 on CUB-200 and a 1.8% increase on Cars-196, compared to state-of-the-art baselines under standard experimental settings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20246v1</guid></item><item><title>[cs updates on arXiv.org] Order-Optimal Sample Complexity of Rectified Flows</title><link>https://arxiv.org/abs/2601.20250</link><description>arXiv:2601.20250v1 Announce Type: new 
Abstract: Recently, flow-based generative models have shown superior efficiency compared to diffusion models. In this paper, we study rectified flow models, which constrain transport trajectories to be linear from the base distribution to the data distribution. This structural restriction greatly accelerates sampling, often enabling high-quality generation with a single Euler step. Under standard assumptions on the neural network classes used to parameterize the velocity field and data distribution, we prove that rectified flows achieve sample complexity $\tilde{O}(\varepsilon^{-2})$. This improves on the best known $O(\varepsilon^{-4})$ bounds for flow matching model and matches the optimal rate for mean estimation. Our analysis exploits the particular structure of rectified flows: because the model is trained with a squared loss along linear paths, the associated hypothesis class admits a sharply controlled localized Rademacher complexity. This yields the improved, order-optimal sample complexity and provides a theoretical explanation for the strong empirical performance of rectified flow models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20250v1</guid></item><item><title>[cs updates on arXiv.org] Automated Benchmark Generation from Domain Guidelines Informed by Bloom's Taxonomy</title><link>https://arxiv.org/abs/2601.20253</link><description>arXiv:2601.20253v1 Announce Type: new 
Abstract: Open-ended question answering (QA) evaluates a model's ability to perform contextualized reasoning beyond factual recall. This challenge is especially acute in practice-based domains, where knowledge is procedural and grounded in professional judgment, while most existing LLM benchmarks depend on pre-existing human exam datasets that are often unavailable in such settings. We introduce a framework for automated benchmark generation from expert-authored guidelines informed by Bloom's Taxonomy. It converts expert practices into implicit violation-based scenarios and expands them into auto-graded multiple-choice questions (MCQs) and multi-turn dialogues across four cognitive levels, enabling deterministic, reproducible, and scalable evaluation. Applied to three applied domains: teaching, dietetics, and caregiving, we find differences between model and human-like reasoning: LLMs sometimes perform relatively better on higher-order reasoning (Analyze) but fail more frequently on lower-level items (Remember). We produce large-scale, psychometrically informed benchmarks that surface these non-intuitive model behaviors and enable evaluation of contextualized reasoning in real-world settings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20253v1</guid></item><item><title>[cs updates on arXiv.org] HE-SNR: Uncovering Latent Logic via Entropy for Guiding Mid-Training on SWE-BENCH</title><link>https://arxiv.org/abs/2601.20255</link><description>arXiv:2601.20255v1 Announce Type: new 
Abstract: SWE-bench has emerged as the premier benchmark for evaluating Large Language Models on complex software engineering tasks. While these capabilities are fundamentally acquired during the mid-training phase and subsequently elicited during Supervised Fine-Tuning (SFT), there remains a critical deficit in metrics capable of guiding mid-training effectively. Standard metrics such as Perplexity (PPL) are compromised by the "Long-Context Tax" and exhibit weak correlation with downstream SWE performance. In this paper, we bridge this gap by first introducing a rigorous data filtering strategy. Crucially, we propose the Entropy Compression Hypothesis, redefining intelligence not by scalar Top-1 compression, but by the capacity to structure uncertainty into Entropy-Compressed States of low orders ("reasonable hesitation"). Grounded in this fine-grained entropy analysis, we formulate a novel metric, HE-SNR (High-Entropy Signal-to-Noise Ratio). Validated on industrial-scale Mixture-of-Experts (MoE) models across varying context windows (32K/128K), our approach demonstrates superior robustness and predictive power. This work provides both the theoretical foundation and practical tools for optimizing the latent potential of LLMs in complex engineering domains.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20255v1</guid></item><item><title>[cs updates on arXiv.org] SoftHateBench: Evaluating Moderation Models Against Reasoning-Driven, Policy-Compliant Hostility</title><link>https://arxiv.org/abs/2601.20256</link><description>arXiv:2601.20256v1 Announce Type: new 
Abstract: Online hate on social media ranges from overt slurs and threats (\emph{hard hate speech}) to \emph{soft hate speech}: discourse that appears reasonable on the surface but uses framing and value-based arguments to steer audiences toward blaming or excluding a target group. We hypothesize that current moderation systems, largely optimized for surface toxicity cues, are not robust to this reasoning-driven hostility, yet existing benchmarks do not measure this gap systematically. We introduce \textbf{\textsc{SoftHateBench}}, a generative benchmark that produces soft-hate variants while preserving the underlying hostile standpoint. To generate soft hate, we integrate the \emph{Argumentum Model of Topics} (AMT) and \emph{Relevance Theory} (RT) in a unified framework: AMT provides the backbone argument structure for rewriting an explicit hateful standpoint into a seemingly neutral discussion while preserving the stance, and RT guides generation to keep the AMT chain logically coherent. The benchmark spans \textbf{7} sociocultural domains and \textbf{28} target groups, comprising \textbf{4,745} soft-hate instances. Evaluations across encoder-based detectors, general-purpose LLMs, and safety models show a consistent drop from hard to soft tiers: systems that detect explicit hostility often fail when the same stance is conveyed through subtle, reasoning-based language. \textcolor{red}{\textbf{Disclaimer.} Contains offensive examples used solely for research.}</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20256v1</guid></item><item><title>[cs updates on arXiv.org] C2:Cross learning module enhanced decision transformer with Constraint-aware loss for auto-bidding</title><link>https://arxiv.org/abs/2601.20257</link><description>arXiv:2601.20257v1 Announce Type: new 
Abstract: Decision Transformer (DT) shows promise for generative auto-bidding by capturing temporal dependencies, but suffers from two critical limitations: insufficient cross-correlation modeling among state, action, and return-to-go (RTG) sequences, and indiscriminate learning of optimal/suboptimal behaviors. To address these, we propose C2, a novel framework enhancing DT with two core innovations: (1) a Cross Learning Block (CLB) via cross-attention to strengthen inter-sequence correlation modeling; (2) a Constraint-aware Loss (CL) incorporating budget and Cost-Per-Acquisition (CPA) constraints for selective learning of optimal trajectories. Extensive offline evaluations on the AuctionNet dataset demonstrate consistent performance gains (up to 3.23\% over state-of-the-art GAVE) across diverse budget settings; ablation studies verify the complementary synergy of CLB and CL, confirming C2's superiority in auto-bidding. The code for reproducing our results is available at: https://github.com/Dingjinren/C2.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20257v1</guid></item><item><title>[cs updates on arXiv.org] Reversible Efficient Diffusion for Image Fusion</title><link>https://arxiv.org/abs/2601.20260</link><description>arXiv:2601.20260v1 Announce Type: new 
Abstract: Multi-modal image fusion aims to consolidate complementary information from diverse source images into a unified representation. The fused image is expected to preserve fine details and maintain high visual fidelity. While diffusion models have demonstrated impressive generative capabilities in image generation, they often suffer from detail loss when applied to image fusion tasks. This issue arises from the accumulation of noise errors inherent in the Markov process, leading to inconsistency and degradation in the fused results. However, incorporating explicit supervision into end-to-end training of diffusion-based image fusion introduces challenges related to computational efficiency. To address these limitations, we propose the Reversible Efficient Diffusion (RED) model - an explicitly supervised training framework that inherits the powerful generative capability of diffusion models while avoiding the distribution estimation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20260v1</guid></item><item><title>[cs updates on arXiv.org] Shallow-{\pi}: Knowledge Distillation for Flow-based VLAs</title><link>https://arxiv.org/abs/2601.20262</link><description>arXiv:2601.20262v1 Announce Type: new 
Abstract: The growing demand for real-time robotic deployment necessitates fast and on-device inference for vision-language-action (VLA) models. Within the VLA literature, efficiency has been extensively studied at the token level, such as visual token pruning. In contrast, systematic transformer layer reduction has received limited attention and, to the best of our knowledge, has not been explored for flow-based VLA models under knowledge distillation. In this work, we propose Shallow-pi, a principled knowledge distillation framework that aggressively reduces the transformer depth of both the VLM backbone and the flow-based action head, compressing the model from 18 to 6 layers. Shallow-pi achieves over two times faster inference with less than one percent absolute drop in success rate on standard manipulation benchmarks, establishing state-of-the-art performance among reduced VLA models. Crucially, we validate our approach through industrial-scale real-world experiments on Jetson Orin and Jetson Thor across multiple robot platforms, including humanoid systems, in complex and dynamic manipulation scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20262v1</guid></item><item><title>[cs updates on arXiv.org] SATA: Sparsity-Aware Scheduling for Selective Token Attention</title><link>https://arxiv.org/abs/2601.20267</link><description>arXiv:2601.20267v1 Announce Type: new 
Abstract: Transformers have become the foundation of numerous state-of-the-art AI models across diverse domains, thanks to their powerful attention mechanism for modeling long-range dependencies. However, the quadratic scaling complexity of attention poses significant challenges for efficient hardware implementation. While techniques such as quantization and pruning help mitigate this issue, selective token attention offers a promising alternative by narrowing the attention scope to only the most relevant tokens, reducing computation and filtering out noise.
  In this work, we propose SATA, a locality-centric dynamic scheduling scheme that proactively manages sparsely distributed access patterns from selective Query-Key operations. By reordering operand flow and exploiting data locality, our approach enables early fetch and retirement of intermediate Query/Key vectors, improving system utilization. We implement and evaluate our token management strategy in a control and compute system, using runtime traces from selective-attention-based models. Experimental results show that our method improves system throughput by up to 1.76x and boosts energy efficiency by 2.94x, while incurring minimal scheduling overhead.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20267v1</guid></item><item><title>[cs updates on arXiv.org] Eliciting Least-to-Most Reasoning for Phishing URL Detection</title><link>https://arxiv.org/abs/2601.20270</link><description>arXiv:2601.20270v1 Announce Type: new 
Abstract: Phishing continues to be one of the most prevalent attack vectors, making accurate classification of phishing URLs essential. Recently, large language models (LLMs) have demonstrated promising results in phishing URL detection. However, their reasoning capabilities that enabled such performance remain underexplored. To this end, in this paper, we propose a Least-to-Most prompting framework for phishing URL detection. In particular, we introduce an "answer sensitivity" mechanism that guides Least-to-Most's iterative approach to enhance reasoning and yield higher prediction accuracy. We evaluate our framework using three URL datasets and four state-of-the-art LLMs, comparing against a one-shot approach and a supervised model. We demonstrate that our framework outperforms the one-shot baseline while achieving performance comparable to that of the supervised model, despite requiring significantly less training data. Furthermore, our in-depth analysis highlights how the iterative reasoning enabled by Least-to-Most, and reinforced by our answer sensitivity mechanism, drives these performance gains. Overall, we show that this simple yet powerful prompting strategy consistently outperforms both one-shot and supervised approaches, despite requiring minimal training or few-shot guidance. Our experimental setup can be found in our Github repository github.sydney.edu.au/htri0928/least-to-most-phishing-detection.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20270v1</guid></item><item><title>[cs updates on arXiv.org] StreamFusion: Scalable Sequence Parallelism for Distributed Inference of Diffusion Transformers on GPUs</title><link>https://arxiv.org/abs/2601.20273</link><description>arXiv:2601.20273v1 Announce Type: new 
Abstract: Diffusion Transformers (DiTs) have gained increasing adoption in high-quality image and video generation. As demand for higher-resolution images and longer videos increases, single-GPU inference becomes inefficient due to increased latency and large activation sizes. Current frameworks employ sequence parallelism (SP) techniques such as Ulysses Attention and Ring Attention to scale inference. However, these implementations have three primary limitations: (1) suboptimal communication patterns for network topologies on modern GPU machines, (2) latency bottlenecks from all-to-all operations in inter-machine communication, and (3) GPU sender-receiver synchronization and computation overheads from using two-sided communication libraries. To address these issues, we present StreamFusion, a topology-aware efficient DiT serving engine. StreamFusion incorporates three key innovations: (1) a topology-aware sequence parallelism technique that accounts for inter- and intra-machine bandwidth differences, (2) Torus Attention, a novel SP technique enabling overlapping of inter-machine all-to-all operations with computation, and (3) a one-sided communication implementation that minimizes GPU sender-receiver synchronization and computation overheads. Our experiments demonstrate that StreamFusion outperforms the state-of-the-art approach by an average of $1.35\times$ (up to $1.77\times$).</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20273v1</guid></item><item><title>[cs updates on arXiv.org] RusLICA: A Russian-Language Platform for Automated Linguistic Inquiry and Category Analysis</title><link>https://arxiv.org/abs/2601.20275</link><description>arXiv:2601.20275v1 Announce Type: new 
Abstract: Defining psycholinguistic characteristics in written texts is a task gaining increasing attention from researchers. One of the most widely used tools in the current field is Linguistic Inquiry and Word Count (LIWC) that originally was developed to analyze English texts and translated into multiple languages. Our approach offers the adaptation of LIWC methodology for the Russian language, considering its grammatical and cultural specificities. The suggested approach comprises 96 categories, integrating syntactic, morphological, lexical, general statistical features, and results of predictions obtained using pre-trained language models (LMs) for text analysis. Rather than applying direct translation to existing thesauri, we built the dictionary specifically for the Russian language based on the content from several lexicographic resources, semantic dictionaries and corpora. The paper describes the process of mapping lemmas to 42 psycholinguistic categories and the implementation of the analyzer as part of RusLICA web service.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20275v1</guid></item><item><title>[cs updates on arXiv.org] Beyond the Needle's Illusion: Decoupled Evaluation of Evidence Access and Use under Semantic Interference at 326M-Token Scale</title><link>https://arxiv.org/abs/2601.20276</link><description>arXiv:2601.20276v1 Announce Type: new 
Abstract: Long-context LLM agents must access the right evidence from large environments and use it faithfully. However, the popular Needle-in-a-Haystack (NIAH) evaluation mostly measures benign span localization. The needle is near-unique, and the haystack is largely irrelevant. We introduce EverMemBench-S (EMB-S), an adversarial NIAH-style benchmark built on a 326M-token MemoryBank. While the full MemoryBank spans 326M tokens for retrieval-based (RAG) evaluation, we evaluate native long-context models only at scales that fit within each model's context window (up to 1M tokens in this work) to ensure a fair comparison. EMB-S pairs queries with collision-tested near-miss hard negatives and gold evidence sets spanning one or more documents, validated via human screening and LLM verification. We also propose a decoupled diagnostic protocol that reports evidence access (document-ID localization) separately from end-to-end QA quality under full-context prompting. This enables consistent diagnosis for both native long-context prompting and retrieval pipelines. Across a reference-corpus ladder from domain-isolated 64K contexts to a globally shared 326M-token environment, we observe a clear reality gap. Systems that saturate benign NIAH degrade sharply in evidence access under semantic interference. These results indicate that semantic discrimination, not context length alone, is the dominant bottleneck for long-context memory at scale.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20276v1</guid></item><item><title>[cs updates on arXiv.org] Hallucination Begins Where Saliency Drops</title><link>https://arxiv.org/abs/2601.20279</link><description>arXiv:2601.20279v1 Announce Type: new 
Abstract: Recent studies have examined attention dynamics in large vision-language models (LVLMs) to detect hallucinations. However, existing approaches remain limited in reliably distinguishing hallucinated from factually grounded outputs, as they rely solely on forward-pass attention patterns and neglect gradient-based signals that reveal how token influence propagates through the network. To bridge this gap, we introduce LVLMs-Saliency, a gradient-aware diagnostic framework that quantifies the visual grounding strength of each output token by fusing attention weights with their input gradients. Our analysis uncovers a decisive pattern: hallucinations frequently arise when preceding output tokens exhibit low saliency toward the prediction of the next token, signaling a breakdown in contextual memory retention. Leveraging this insight, we propose a dual-mechanism inference-time framework to mitigate hallucinations: (1) Saliency-Guided Rejection Sampling (SGRS), which dynamically filters candidate tokens during autoregressive decoding by rejecting those whose saliency falls below a context-adaptive threshold, thereby preventing coherence-breaking tokens from entering the output sequence; and (2) Local Coherence Reinforcement (LocoRE), a lightweight, plug-and-play module that strengthens attention from the current token to its most recent predecessors, actively counteracting the contextual forgetting behavior identified by LVLMs-Saliency. Extensive experiments across multiple LVLMs demonstrate that our method significantly reduces hallucination rates while preserving fluency and task performance, offering a robust and interpretable solution for enhancing model reliability. Code is available at: https://github.com/zhangbaijin/LVLMs-Saliency</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20279v1</guid></item><item><title>[cs updates on arXiv.org] The Forecast After the Forecast: A Post-Processing Shift in Time Series</title><link>https://arxiv.org/abs/2601.20280</link><description>arXiv:2601.20280v1 Announce Type: new 
Abstract: Time series forecasting has long been dominated by advances in model architecture, with recent progress driven by deep learning and hybrid statistical techniques. However, as forecasting models approach diminishing returns in accuracy, a critical yet underexplored opportunity emerges: the strategic use of post-processing. In this paper, we address the last-mile gap in time-series forecasting, which is to improve accuracy and uncertainty without retraining or modifying a deployed backbone. We propose $\delta$-Adapter, a lightweight, architecture-agnostic way to boost deployed time series forecasters without retraining. $\delta$-Adapter learns tiny, bounded modules at two interfaces: input nudging (soft edits to covariates) and output residual correction. We provide local descent guarantees, $O(\delta)$ drift bounds, and compositional stability for combined adapters. Meanwhile, it can act as a feature selector by learning a sparse, horizon-aware mask over inputs to select important features, thereby improving interpretability. In addition, it can also be used as a distribution calibrator to measure uncertainty. Thus, we introduce a Quantile Calibrator and a Conformal Corrector that together deliver calibrated, personalized intervals with finite-sample coverage. Our experiments across diverse backbones and datasets show that $\delta$-Adapter improves accuracy and calibration with negligible compute and no interface changes.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20280v1</guid></item><item><title>[cs updates on arXiv.org] Memory Retrieval in Transformers: Insights from The Encoding Specificity Principle</title><link>https://arxiv.org/abs/2601.20282</link><description>arXiv:2601.20282v1 Announce Type: new 
Abstract: While explainable artificial intelligence (XAI) for large language models (LLMs) remains an evolving field with many unresolved questions, increasing regulatory pressures have spurred interest in its role in ensuring transparency, accountability, and privacy-preserving machine unlearning. Despite recent advances in XAI have provided some insights, the specific role of attention layers in transformer based LLMs remains underexplored. This study investigates the memory mechanisms instantiated by attention layers, drawing on prior research in psychology and computational psycholinguistics that links Transformer attention to cue based retrieval in human memory. In this view, queries encode the retrieval context, keys index candidate memory traces, attention weights quantify cue trace similarity, and values carry the encoded content, jointly enabling the construction of a context representation that precedes and facilitates memory retrieval. Guided by the Encoding Specificity Principle, we hypothesize that the cues used in the initial stage of retrieval are instantiated as keywords. We provide converging evidence for this keywords-as-cues hypothesis. In addition, we isolate neurons within attention layers whose activations selectively encode and facilitate the retrieval of context-defining keywords. Consequently, these keywords can be extracted from identified neurons and further contribute to downstream applications such as unlearning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20282v1</guid></item><item><title>[cs updates on arXiv.org] One Word is Enough: Minimal Adversarial Perturbations for Neural Text Ranking</title><link>https://arxiv.org/abs/2601.20283</link><description>arXiv:2601.20283v1 Announce Type: new 
Abstract: Neural ranking models (NRMs) achieve strong retrieval effectiveness, yet prior work has shown they are vulnerable to adversarial perturbations. We revisit this robustness question with a minimal, query-aware attack that promotes a target document by inserting or substituting a single, semantically aligned word - the query center. We study heuristic and gradient-guided variants, including a white-box method that identifies influential insertion points. On TREC-DL 2019/2020 with BERT and monoT5 re-rankers, our single-word attacks achieve up to 91% success while modifying fewer than two tokens per document on average, achieving competitive rank and score boosts with far fewer edits under a comparable white-box setup to ensure fair evaluation against PRADA. We also introduce new diagnostic metrics to analyze attack sensitivity beyond aggregate success rates. Our analysis reveals a Goldilocks zone in which mid-ranked documents are most vulnerable. These findings demonstrate practical risks and motivate future defenses for robust neural ranking.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20283v1</guid></item><item><title>[cs updates on arXiv.org] A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency</title><link>https://arxiv.org/abs/2601.20284</link><description>arXiv:2601.20284v1 Announce Type: new 
Abstract: Domain adaptation (DA) addresses the challenge of transferring knowledge from a source domain to a target domain where image data distributions may differ. Existing DA methods often require access to source domain data, adversarial training, or complex pseudo-labeling techniques, which are computationally expensive. To address these challenges, this paper introduces a novel source-free domain adaptation method. It is the first approach to use multiview augmentation and latent space consistency techniques to learn domain-invariant features directly from the target domain. Our method eliminates the need for source-target alignment or pseudo-label refinement by learning transferable representations solely from the target domain by enforcing consistency between multiple augmented views in the latent space. Additionally, the method ensures consistency in the learned features by generating multiple augmented views of target domain data and minimizing the distance between their feature representations in the latent space. We also introduce a ConvNeXt-based encoder and design a loss function that combines classification and consistency objectives to drive effective adaptation directly from the target domain. The proposed model achieves an average classification accuracy of 90. 72\%, 84\%, and 97. 12\% in Office-31, Office-Home and Office-Caltech datasets, respectively. Further evaluations confirm that our study improves existing methods by an average classification accuracy increment of +1.23\%, +7.26\%, and +1.77\% on the respective datasets.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20284v1</guid></item><item><title>[cs updates on arXiv.org] A note on approximation in weighted Korobov spaces via multiple rank-1 lattices</title><link>https://arxiv.org/abs/2601.20290</link><description>arXiv:2601.20290v1 Announce Type: new 
Abstract: This paper studies the multivariate approximation of functions in weighted Korobov spaces using multiple rank-1 lattice rules. It has been shown by K\"{a}mmerer and Volkmer (2019) that algorithms based on multiple rank-1 lattices achieve the optimal convergence rate for the $L_{\infty}$ error in Wiener-type spaces, up to logarithmic factors. While this result was translated to weighted Korobov spaces in the recent monograph by Dick, Kritzer, and Pillichshammer (2022), the analysis requires the smoothness parameter $\alpha$ to be greater than $1$ and is restricted to product weights. In this paper, we extend this result for multiple rank-1 lattice-based algorithms to the case where $1/2&lt;\alpha\le 1$ and for general weights, covering a broader range of periodic functions with low smoothness and general relative importance of variables. We also provide a summability condition on the weights to ensure strong polynomial tractability for any $\alpha&gt;1/2$. Furthermore, by incorporating random shifts into multiple rank-1 lattice-based algorithms, we prove that the resulting randomized algorithm achieves a nearly optimal convergence rate in terms of the worst-case root mean squared $L_2$ error, while retaining the same tractability property.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20290v1</guid></item><item><title>[cs updates on arXiv.org] A Learning-based Framework for Spatial Impulse Response Compensation in 3D Photoacoustic Computed Tomography</title><link>https://arxiv.org/abs/2601.20291</link><description>arXiv:2601.20291v1 Announce Type: new 
Abstract: Photoacoustic computed tomography (PACT) is a promising imaging modality that combines the advantages of optical contrast with ultrasound detection. Utilizing ultrasound transducers with larger surface areas can improve detection sensitivity. However, when computationally efficient analytic reconstruction methods that neglect the spatial impulse responses (SIRs) of the transducer are employed, the spatial resolution of the reconstructed images will be compromised. Although optimization-based reconstruction methods can explicitly account for SIR effects, their computational cost is generally high, particularly in three-dimensional (3D) applications. To address the need for accurate but rapid 3D PACT image reconstruction, this study presents a framework for establishing a learned SIR compensation method that operates in the data domain. The learned compensation method maps SIR-corrupted PACT measurement data to compensated data that would have been recorded by idealized point-like transducers. Subsequently, the compensated data can be used with a computationally efficient reconstruction method that neglects SIR effects. Two variants of the learned compensation model are investigated that employ a U-Net model and a specifically designed, physics-inspired model, referred to as Deconv-Net. A fast and analytical training data generation procedure is also a component of the presented framework. The framework is rigorously validated in virtual imaging studies, demonstrating resolution improvement and robustness to noise variations, object complexity, and sound speed heterogeneity. When applied to in-vivo breast imaging data, the learned compensation models revealed fine structures that had been obscured by SIR-induced artifacts. To our knowledge, this is the first demonstration of learned SIR compensation in 3D PACT imaging.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20291v1</guid></item><item><title>[cs updates on arXiv.org] Cheap2Rich: A Multi-Fidelity Framework for Data Assimilation and System Identification of Multiscale Physics -- Rotating Detonation Engines</title><link>https://arxiv.org/abs/2601.20295</link><description>arXiv:2601.20295v1 Announce Type: new 
Abstract: Bridging the sim2real gap between computationally inexpensive models and complex physical systems remains a central challenge in machine learning applications to engineering problems, particularly in multi-scale settings where reduced-order models typically capture only dominant dynamics. In this work, we present Cheap2Rich, a multi-scale data assimilation framework that reconstructs high-fidelity state spaces from sparse sensor histories by combining a fast low-fidelity prior with learned, interpretable discrepancy corrections. We demonstrate the performance on rotating detonation engines (RDEs), a challenging class of systems that couple detonation-front propagation with injector-driven unsteadiness, mixing, and stiff chemistry across disparate scales. Our approach successfully reconstructs high-fidelity RDE states from sparse measurements while isolating physically meaningful discrepancy dynamics associated with injector-driven effects. The results highlight a general multi-fidelity framework for data assimilation and system identification in complex multi-scale systems, enabling rapid design exploration and real-time monitoring and control while providing interpretable discrepancy dynamics. Code for this project is is available at: github.com/kro0l1k/Cheap2Rich.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20295v1</guid></item><item><title>[cs updates on arXiv.org] Artifact-Aware Evaluation for High-Quality Video Generation</title><link>https://arxiv.org/abs/2601.20297</link><description>arXiv:2601.20297v1 Announce Type: new 
Abstract: With the rapid advancement of video generation techniques, evaluating and auditing generated videos has become increasingly crucial. Existing approaches typically offer coarse video quality scores, lacking detailed localization and categorization of specific artifacts. In this work, we introduce a comprehensive evaluation protocol focusing on three key aspects affecting human perception: Appearance, Motion, and Camera. We define these axes through a taxonomy of 10 prevalent artifact categories reflecting common generative failures observed in video generation. To enable robust artifact detection and categorization, we introduce GenVID, a large-scale dataset of 80k videos generated by various state-of-the-art video generation models, each carefully annotated for the defined artifact categories. Leveraging GenVID, we develop DVAR, a Dense Video Artifact Recognition framework for fine-grained identification and classification of generative artifacts. Extensive experiments show that our approach significantly improves artifact detection accuracy and enables effective filtering of low-quality content.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20297v1</guid></item><item><title>[cs updates on arXiv.org] Truthfulness Despite Weak Supervision: Evaluating and Training LLMs Using Peer Prediction</title><link>https://arxiv.org/abs/2601.20299</link><description>arXiv:2601.20299v1 Announce Type: new 
Abstract: The evaluation and post-training of large language models (LLMs) rely on supervision, but strong supervision for difficult tasks is often unavailable, especially when evaluating frontier models. In such cases, models are demonstrated to exploit evaluations built on such imperfect supervision, leading to deceptive results. However, underutilized in LLM research, a wealth of mechanism design research focuses on game-theoretic incentive compatibility, i.e., eliciting honest and informative answers with weak supervision. Drawing from this literature, we introduce the peer prediction method for model evaluation and post-training. It rewards honest and informative answers over deceptive and uninformative ones, using a metric based on mutual predictability and without requiring ground truth labels. We demonstrate the method's effectiveness and resistance to deception, with both theoretical guarantees and empirical validation on models with up to 405B parameters. We show that training an 8B model with peer prediction-based reward recovers most of the drop in truthfulness due to prior malicious finetuning, even when the reward is produced by a 0.135B language model with no finetuning. On the evaluation front, in contrast to LLM-as-a-Judge which requires strong and trusted judges, we discover an inverse scaling property in peer prediction, where, surprisingly, resistance to deception is strengthened as the capability gap between the experts and participants widens, enabling reliable evaluation of strong models with weak supervision. In particular, LLM-as-a-Judge become worse than random guess when facing deceptive models 5-20x the judge's size, while peer prediction thrives when such gaps are large, including in cases with over 100x size difference.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20299v1</guid></item><item><title>[cs updates on arXiv.org] MiLorE-SSL: Scaling Multilingual Capabilities in Self-Supervised Models without Forgetting</title><link>https://arxiv.org/abs/2601.20300</link><description>arXiv:2601.20300v1 Announce Type: new 
Abstract: Self-supervised learning (SSL) has greatly advanced speech representation learning, but multilingual SSL models remain constrained to languages encountered during pretraining. Retraining from scratch to incorporate new languages is computationally expensive, while sequential training without migitation strategies often leads to catastrophic forgetting. To address this, we propose MiLorE-SSL, a lightweight framework that combines LoRA modules with a soft mixture-of-experts (MoE) mechanism for efficient continual multilingual training. LoRA provides efficient low-rank adaptation, while soft MoE promotes flexible expert sharing across languages, reducing cross-lingual interference. To further mitigate forgetting, we introduce limited replay data from existing languages, avoiding reliance on large historical corpora. Experiments on ML-SUPERB demonstrate that MiLorE-SSL achieves strong performance in new languages and improves the ability in existing ones with only 2.14% trainable parameters.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20300v1</guid></item><item><title>[cs updates on arXiv.org] Towards Compact and Robust DNNs via Compression-aware Sharpness Minimization</title><link>https://arxiv.org/abs/2601.20301</link><description>arXiv:2601.20301v1 Announce Type: new 
Abstract: Sharpness-Aware Minimization (SAM) has recently emerged as an effective technique for improving DNN robustness to input variations. However, its interplay with the compactness requirements of on-device DNN deployments remains less explored. Simply pruning a SAM-trained model can undermine robustness, since flatness in the continuous parameter space does not necessarily translate to robustness under the discrete structural changes induced by pruning. Conversely, applying SAM after pruning may be fundamentally constrained by architectural limitations imposed by an early, robustness-agnostic pruning pattern. To address this gap, we propose Compression-aware ShArpness Minimization (C-SAM), a framework that shifts sharpness-aware learning from parameter perturbations to mask perturbations. By explicitly perturbing pruning masks during training, C-SAM promotes a flatter loss landscape with respect to model structure, enabling the discovery of pruning patterns that simultaneously optimize model compactness and robustness to input variations. Extensive experiments on CelebA-HQ, Flowers-102, and CIFAR-10-C across ResNet-18, GoogLeNet, and MobileNet-V2 show that C-SAM consistently achieves higher certified robustness than strong baselines, with improvements of up to 42%, while maintaining task accuracy comparable to the corresponding unpruned models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20301v1</guid></item><item><title>[cs updates on arXiv.org] Bridging the Applicator Gap with Data-Doping:Dual-Domain Learning for Precise Bladder Segmentation in CT-Guided Brachytherapy</title><link>https://arxiv.org/abs/2601.20302</link><description>arXiv:2601.20302v1 Announce Type: new 
Abstract: Performance degradation due to covariate shift remains a major challenge for deep learning models in medical image segmentation. An open question is whether samples from a shifted distribution can effectively support learning when combined with limited target domain data. We investigate this problem in the context of bladder segmentation in CT guided gynecological brachytherapy, a critical task for accurate dose optimization and organ at risk sparing. While CT scans without brachytherapy applicators (no applicator: NA) are widely available, scans with applicators inserted (with applicator: WA) are scarce and exhibit substantial anatomical deformation and imaging artifacts, making automated segmentation particularly difficult.
  We propose a dual domain learning strategy that integrates NA and WA CT data to improve robustness and generalizability under covariate shift. Using a curated assorted dataset, we show that NA data alone fail to capture the anatomical and artifact related characteristics of WA images. However, introducing a modest proportion of WA data into a predominantly NA training set leads to significant performance improvements. Through systematic experiments across axial, coronal, and sagittal planes using multiple deep learning architectures, we demonstrate that doping only 10 to 30 percent WA data achieves segmentation performance comparable to models trained exclusively on WA data.
  The proposed approach attains Dice similarity coefficients of up to 0.94 and Intersection over Union scores of up to 0.92, indicating effective domain adaptation and improved clinical reliability. This study highlights the value of integrating anatomically similar but distribution shifted datasets to overcome data scarcity and enhance deep learning based segmentation for brachytherapy treatment planning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20302v1</guid></item><item><title>[cs updates on arXiv.org] Physically Guided Visual Mass Estimation from a Single RGB Image</title><link>https://arxiv.org/abs/2601.20303</link><description>arXiv:2601.20303v1 Announce Type: new 
Abstract: Estimating object mass from visual input is challenging because mass depends jointly on geometric volume and material-dependent density, neither of which is directly observable from RGB appearance. Consequently, mass prediction from pixels is ill-posed and therefore benefits from physically meaningful representations to constrain the space of plausible solutions. We propose a physically structured framework for single-image mass estimation that addresses this ambiguity by aligning visual cues with the physical factors governing mass. From a single RGB image, we recover object-centric three-dimensional geometry via monocular depth estimation to inform volume and extract coarse material semantics using a vision-language model to guide density-related reasoning. These geometry, semantic, and appearance representations are fused through an instance-adaptive gating mechanism, and two physically guided latent factors (volume- and density-related) are predicted through separate regression heads under mass-only supervision. Experiments on image2mass and ABO-500 show that the proposed method consistently outperforms state-of-the-art methods.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20303v1</guid></item><item><title>[cs updates on arXiv.org] Structure-constrained Language-informed Diffusion Model for Unpaired Low-dose Computed Tomography Angiography Reconstruction</title><link>https://arxiv.org/abs/2601.20304</link><description>arXiv:2601.20304v1 Announce Type: new 
Abstract: The application of iodinated contrast media (ICM) improves the sensitivity and specificity of computed tomography (CT) for a wide range of clinical indications. However, overdose of ICM can cause problems such as kidney damage and life-threatening allergic reactions. Deep learning methods can generate CT images of normal-dose ICM from low-dose ICM, reducing the required dose while maintaining diagnostic power. However, existing methods are difficult to realize accurate enhancement with incompletely paired images, mainly because of the limited ability of the model to recognize specific structures. To overcome this limitation, we propose a Structure-constrained Language-informed Diffusion Model (SLDM), a unified medical generation model that integrates structural synergy and spatial intelligence. First, the structural prior information of the image is effectively extracted to constrain the model inference process, thus ensuring structural consistency in the enhancement process. Subsequently, semantic supervision strategy with spatial intelligence is introduced, which integrates the functions of visual perception and spatial reasoning, thus prompting the model to achieve accurate enhancement. Finally, the subtraction angiography enhancement module is applied, which serves to improve the contrast of the ICM agent region to suitable interval for observation. Qualitative analysis of visual comparison and quantitative results of several metrics demonstrate the effectiveness of our method in angiographic reconstruction for low-dose contrast medium CT angiography.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20304v1</guid></item><item><title>[cs updates on arXiv.org] Endogenous Reprompting: Self-Evolving Cognitive Alignment for Unified Multimodal Models</title><link>https://arxiv.org/abs/2601.20305</link><description>arXiv:2601.20305v1 Announce Type: new 
Abstract: Unified Multimodal Models (UMMs) exhibit strong understanding, yet this capability often fails to effectively guide generation. We identify this as a Cognitive Gap: the model lacks the understanding of how to enhance its own generation process. To bridge this gap, we propose Endogenous Reprompting, a mechanism that transforms the model's understanding from a passive encoding process into an explicit generative reasoning step by generating self-aligned descriptors during generation. To achieve this, we introduce SEER (Self-Evolving Evaluator and Reprompter), a training framework that establishes a two-stage endogenous loop using only 300 samples from a compact proxy task, Visual Instruction Elaboration. First, Reinforcement Learning with Verifiable Rewards (RLVR) activates the model's latent evaluation ability via curriculum learning, producing a high-fidelity endogenous reward signal. Second, Reinforcement Learning with Model-rewarded Thinking (RLMT) leverages this signal to optimize the generative reasoning policy. Experiments show that SEER consistently outperforms state-of-the-art baselines in evaluation accuracy, reprompting efficiency, and generation quality, without sacrificing general multimodal capabilities.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20305v1</guid></item><item><title>[cs updates on arXiv.org] TPGDiff: Hierarchical Triple-Prior Guided Diffusion for Image Restoration</title><link>https://arxiv.org/abs/2601.20306</link><description>arXiv:2601.20306v1 Announce Type: new 
Abstract: All-in-one image restoration aims to address diverse degradation types using a single unified model. Existing methods typically rely on degradation priors to guide restoration, yet often struggle to reconstruct content in severely degraded regions. Although recent works leverage semantic information to facilitate content generation, integrating it into the shallow layers of diffusion models often disrupts spatial structures (\emph{e.g.}, blurring artifacts). To address this issue, we propose a Triple-Prior Guided Diffusion (TPGDiff) network for unified image restoration. TPGDiff incorporates degradation priors throughout the diffusion trajectory, while introducing structural priors into shallow layers and semantic priors into deep layers, enabling hierarchical and complementary prior guidance for image reconstruction. Specifically, we leverage multi-source structural cues as structural priors to capture fine-grained details and guide shallow layers representations. To complement this design, we further develop a distillation-driven semantic extractor that yields robust semantic priors, ensuring reliable high-level guidance at deep layers even under severe degradations. Furthermore, a degradation extractor is employed to learn degradation-aware priors, enabling stage-adaptive control of the diffusion process across all timesteps. Extensive experiments on both single- and multi-degradation benchmarks demonstrate that TPGDiff achieves superior performance and generalization across diverse restoration scenarios. Our project page is: https://leoyjtu.github.io/tpgdiff-project.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20306v1</guid></item><item><title>[cs updates on arXiv.org] Delayed Feedback Modeling for Post-Click Gross Merchandise Volume Prediction: Benchmark, Insights and Approaches</title><link>https://arxiv.org/abs/2601.20307</link><description>arXiv:2601.20307v1 Announce Type: new 
Abstract: The prediction objectives of online advertisement ranking models are evolving from probabilistic metrics like conversion rate (CVR) to numerical business metrics like post-click gross merchandise volume (GMV). Unlike the well-studied delayed feedback problem in CVR prediction, delayed feedback modeling for GMV prediction remains unexplored and poses greater challenges, as GMV is a continuous target, and a single click can lead to multiple purchases that cumulatively form the label. To bridge the research gap, we establish TRACE, a GMV prediction benchmark containing complete transaction sequences rising from each user click, which supports delayed feedback modeling in an online streaming manner. Our analysis and exploratory experiments on TRACE reveal two key insights: (1) the rapid evolution of the GMV label distribution necessitates modeling delayed feedback under online streaming training; (2) the label distribution of repurchase samples substantially differs from that of single-purchase samples, highlighting the need for separate modeling. Motivated by these findings, we propose RepurchasE-Aware Dual-branch prEdictoR (READER), a novel GMV modeling paradigm that selectively activates expert parameters according to repurchase predictions produced by a router. Moreover, READER dynamically calibrates the regression target to mitigate under-estimation caused by incomplete labels. Experimental results show that READER yields superior performance on TRACE over baselines, achieving a 2.19% improvement in terms of accuracy. We believe that our study will open up a new avenue for studying online delayed feedback modeling for GMV prediction, and our TRACE benchmark with the gathered insights will facilitate future research and application in this promising direction. Our code and dataset are available at https://github.com/alimama-tech/OnlineGMV .</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20307v1</guid></item><item><title>[cs updates on arXiv.org] OSDEnhancer: Taming Real-World Space-Time Video Super-Resolution with One-Step Diffusion</title><link>https://arxiv.org/abs/2601.20308</link><description>arXiv:2601.20308v1 Announce Type: new 
Abstract: Diffusion models (DMs) have demonstrated exceptional success in video super-resolution (VSR), showcasing a powerful capacity for generating fine-grained details. However, their potential for space-time video super-resolution (STVSR), which necessitates not only recovering realistic visual content from low-resolution to high-resolution but also improving the frame rate with coherent temporal dynamics, remains largely underexplored. Moreover, existing STVSR methods predominantly address spatiotemporal upsampling under simplified degradation assumptions, which often struggle in real-world scenarios with complex unknown degradations. Such a high demand for reconstruction fidelity and temporal consistency makes the development of a robust STVSR framework particularly non-trivial. To address these challenges, we propose OSDEnhancer, a novel framework that, to the best of our knowledge, represents the first method to achieve real-world STVSR through an efficient one-step diffusion process. OSDEnhancer initializes essential spatiotemporal structures through a linear pre-interpolation strategy and pivots on training temporal refinement and spatial enhancement mixture of experts (TR-SE MoE), which allows distinct expert pathways to progressively learn robust, specialized representations for temporal coherence and spatial detail, further collaboratively reinforcing each other during inference. A bidirectional deformable variational autoencoder (VAE) decoder is further introduced to perform recurrent spatiotemporal aggregation and propagation, enhancing cross-frame reconstruction fidelity. Experiments demonstrate that the proposed method achieves state-of-the-art performance while maintaining superior generalization capability in real-world scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20308v1</guid></item><item><title>[cs updates on arXiv.org] SuperInfer: SLO-Aware Rotary Scheduling and Memory Management for LLM Inference on Superchips</title><link>https://arxiv.org/abs/2601.20309</link><description>arXiv:2601.20309v1 Announce Type: new 
Abstract: Large Language Model (LLM) serving faces a fundamental tension between stringent latency Service Level Objectives (SLOs) and limited GPU memory capacity. When high request rates exhaust the KV cache budget, existing LLM inference systems often suffer severe head-of-line (HOL) blocking. While prior work explored PCIe-based offloading, these approaches cannot sustain responsiveness under high request rates, often failing to meet tight Time-To-First-Token (TTFT) and Time-Between-Tokens (TBT) SLOs. We present SuperInfer, a high-performance LLM inference system designed for emerging Superchips (e.g., NVIDIA GH200) with tightly coupled GPU-CPU architecture via NVLink-C2C. SuperInfer introduces RotaSched, the first proactive, SLO-aware rotary scheduler that rotates requests to maintain responsiveness on Superchips, and DuplexKV, an optimized rotation engine that enables full-duplex transfer over NVLink-C2C. Evaluations on GH200 using various models and datasets show that SuperInfer improves TTFT SLO attainment rates by up to 74.7% while maintaining comparable TBT and throughput compared to state-of-the-art systems, demonstrating that SLO-aware scheduling and memory co-design unlocks the full potential of Superchips for responsive LLM serving.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20309v1</guid></item><item><title>[cs updates on arXiv.org] SemBind: Binding Diffusion Watermarks to Semantics Against Black-Box Forgery Attacks</title><link>https://arxiv.org/abs/2601.20310</link><description>arXiv:2601.20310v1 Announce Type: new 
Abstract: Latent-based watermarks, integrated into the generation process of latent diffusion models (LDMs), simplify detection and attribution of generated images. However, recent black-box forgery attacks, where an attacker needs at least one watermarked image and black-box access to the provider's model, can embed the provider's watermark into images not produced by the provider, posing outsized risk to provenance and trust. We propose SemBind, the first defense framework for latent-based watermarks that resists black-box forgery by binding latent signals to image semantics via a learned semantic masker. Trained with contrastive learning, the masker yields near-invariant codes for the same prompt and near-orthogonal codes across prompts; these codes are reshaped and permuted to modulate the target latent before any standard latent-based watermark. SemBind is generally compatible with existing latent-based watermarking schemes and keeps image quality essentially unchanged, while a simple mask-ratio parameter offers a tunable trade-off between anti-forgery strength and robustness. Across four mainstream latent-based watermark methods, our SemBind-enabled anti-forgery variants markedly reduce false acceptance under black-box forgery while providing a controllable robustness-security balance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20310v1</guid></item><item><title>[cs updates on arXiv.org] DiagLink: A Dual-User Diagnostic Assistance System by Synergizing Experts with LLMs and Knowledge Graphs</title><link>https://arxiv.org/abs/2601.20311</link><description>arXiv:2601.20311v1 Announce Type: new 
Abstract: The global shortage and uneven distribution of medical expertise continue to hinder equitable access to accurate diagnostic care. While existing intelligent diagnostic system have shown promise, most struggle with dual-user interaction, and dynamic knowledge integration -- limiting their real-world applicability. In this study, we present DiagLink, a dual-user diagnostic assistance system that synergizes large language models (LLMs), knowledge graphs (KGs), and medical experts to support both patients and physicians. DiagLink uses guided dialogues to elicit patient histories, leverages LLMs and KGs for collaborative reasoning, and incorporates physician oversight for continuous knowledge validation and evolution. The system provides a role-adaptive interface, dynamically visualized history, and unified multi-source evidence to improve both trust and usability. We evaluate DiagLink through user study, use cases and expert interviews, demonstrating its effectiveness in improving user satisfaction and diagnostic efficiency, while offering insights for the design of future AI-assisted diagnostic systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20311v1</guid></item><item><title>[cs updates on arXiv.org] SAPO: Self-Adaptive Process Optimization Makes Small Reasoners Stronger</title><link>https://arxiv.org/abs/2601.20312</link><description>arXiv:2601.20312v1 Announce Type: new 
Abstract: Existing self-evolution methods overlook the influence of fine-grained reasoning steps, which leads to the reasoner-verifier gap. The computational inefficiency of Monte Carlo (MC) process supervision further exacerbates the difficulty in mitigating the gap. Motivated by the Error-Related Negativity (ERN), which the reasoner can localize error following incorrect decisions, guiding rapid adjustments, we propose a Self-Adaptive Process Optimization (SAPO) method for self-improvement in Small Language Models (SLMs). SAPO adaptively and efficiently introduces process supervision signals by actively minimizing the reasoner-verifier gap rather than relying on inefficient MC estimations. Extensive experiments demonstrate that the proposed method outperforms most existing self-evolution methods on two challenging task types: mathematics and code. Additionally, to further investigate SAPO's impact on verifier performance, this work introduces two new benchmarks for process reward models in both mathematical and coding tasks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20312v1</guid></item><item><title>[cs updates on arXiv.org] Efficient Trajectory Design and Communication Scheduling for Dual-UAV Jamming-Aided Secure Communication Networks</title><link>https://arxiv.org/abs/2601.20314</link><description>arXiv:2601.20314v1 Announce Type: new 
Abstract: We study dual-unmanned aerial vehicle (UAV) jamming-aided secure communication networks, in which one UAV delivers confidential data to multiple ground users (GUs), while a cooperative UAV provides protective interference against a ground eavesdropper. To enforce fairness, we maximize the minimum secrecy throughput across GUs by jointly designing trajectories and communication scheduling. The key difficulty lies in the continuous-time nature of UAV trajectories and the tight space-time coupling between the transmitter and the jammer, which jointly render the problem infinite-dimensional and nonconvex. To address these challenges, we characterize, for the first time, the structure of the optimal trajectories and rigorously prove that they follow a collaborative successive hover-and-fly (co-SHF) structure, where the two UAVs visit a limited number of synchronized co-hovering point pairs, and during each flight segment at least one UAV moves at maximum speed. Leveraging this structure, we reformulate the problem into a finite-dimensional form, without loss of optimality, over hovering and turning points, hovering durations, and scheduling. For tractability, we adopt a minimum-distance approximation of continuous anti-collision constraints and employ concave lower bounds on secrecy throughput within a successive convex approximation (SCA) method, which converges and, thanks to the co-SHF reduction in optimization variables and constraints, achieves low computational complexity. Numerical results show that, compared with time-discretization and no-jamming benchmarks, the proposed co-SHF design improves the min-secrecy and user fairness while requiring significantly less runtime.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20314v1</guid></item><item><title>[cs updates on arXiv.org] Less is More: Benchmarking LLM Based Recommendation Agents</title><link>https://arxiv.org/abs/2601.20316</link><description>arXiv:2601.20316v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly deployed for personalized product recommendations, with practitioners commonly assuming that longer user purchase histories lead to better predictions. We challenge this assumption through a systematic benchmark of four state of the art LLMs GPT-4o-mini, DeepSeek-V3, Qwen2.5-72B, and Gemini 2.5 Flash across context lengths ranging from 5 to 50 items using the REGEN dataset.
  Surprisingly, our experiments with 50 users in a within subject design reveal no significant quality improvement with increased context length. Quality scores remain flat across all conditions (0.17--0.23). Our findings have significant practical implications: practitioners can reduce inference costs by approximately 88\% by using context (5--10 items) instead of longer histories (50 items), without sacrificing recommendation quality. We also analyze latency patterns across providers and find model specific behaviors that inform deployment decisions. This work challenges the existing ``more context is better'' paradigm and provides actionable guidelines for cost effective LLM based recommendation systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20316v1</guid></item><item><title>[cs updates on arXiv.org] VersaQ-3D: A Reconfigurable Accelerator Enabling Feed-Forward and Generalizable 3D Reconstruction via Versatile Quantization</title><link>https://arxiv.org/abs/2601.20317</link><description>arXiv:2601.20317v1 Announce Type: new 
Abstract: The Visual Geometry Grounded Transformer (VGGT) enables strong feed-forward 3D reconstruction without per-scene optimization. However, its billion-parameter scale creates high memory and compute demands, hindering on-device deployment. Existing LLM quantization methods fail on VGGT due to saturated activation channels and diverse 3D semantics, which cause unreliable calibration. Furthermore, VGGT presents hardware challenges regarding precision-sensitive nonlinear operators and memory-intensive global attention. To address this, we propose VersaQ-3D, an algorithm-architecture co-design framework. Algorithmically, we introduce the first calibration-free, scene-agnostic quantization for VGGT down to 4-bit, leveraging orthogonal transforms to decorrelate features and suppress outliers. Architecturally, we design a reconfigurable accelerator supporting BF16, INT8, and INT4. A unified systolic datapath handles both linear and nonlinear operators, reducing latency by 60%, while two-stage recomputation-based tiling alleviates memory pressure for long-sequence attention. Evaluations show VersaQ-3D preserves 98-99% accuracy at W4A8. At W4A4, it outperforms prior methods by 1.61x-2.39x across diverse scenes. The accelerator delivers 5.2x-10.8x speedup over edge GPUs with low power, enabling efficient instant 3D reconstruction.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20317v1</guid></item><item><title>[cs updates on arXiv.org] CPiRi: Channel Permutation-Invariant Relational Interaction for Multivariate Time Series Forecasting</title><link>https://arxiv.org/abs/2601.20318</link><description>arXiv:2601.20318v1 Announce Type: new 
Abstract: Current methods for multivariate time series forecasting can be classified into channel-dependent and channel-independent models. Channel-dependent models learn cross-channel features but often overfit the channel ordering, which hampers adaptation when channels are added or reordered. Channel-independent models treat each channel in isolation to increase flexibility, yet this neglects inter-channel dependencies and limits performance. To address these limitations, we propose \textbf{CPiRi}, a \textbf{channel permutation invariant (CPI)} framework that infers cross-channel structure from data rather than memorizing a fixed ordering, enabling deployment in settings with structural and distributional co-drift without retraining. CPiRi couples \textbf{spatio-temporal decoupling architecture} with \textbf{permutation-invariant regularization training strategy}: a frozen pretrained temporal encoder extracts high-quality temporal features, a lightweight spatial module learns content-driven inter-channel relations, while a channel shuffling strategy enforces CPI during training. We further \textbf{ground CPiRi in theory} by analyzing permutation equivariance in multivariate time series forecasting. Experiments on multiple benchmarks show state-of-the-art results. CPiRi remains stable when channel orders are shuffled and exhibits strong \textbf{inductive generalization} to unseen channels even when trained on \textbf{only half} of the channels, while maintaining \textbf{practical efficiency} on large-scale datasets. The source code is released at https://github.com/JasonStraka/CPiRi.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20318v1</guid></item><item><title>[cs updates on arXiv.org] Tactile-Force Alignment in Vision-Language-Action Models for Force-aware Manipulation</title><link>https://arxiv.org/abs/2601.20321</link><description>arXiv:2601.20321v1 Announce Type: new 
Abstract: Vision-Language-Action (VLA) models have recently emerged as powerful generalists for robotic manipulation. However, due to their predominant reliance on visual modalities, they fundamentally lack the physical intuition required for contact-rich tasks that require precise force regulation and physical reasoning. Existing attempts to incorporate vision-based tactile sensing into VLA models typically treat tactile inputs as auxiliary visual textures, thereby overlooking the underlying correlation between surface deformation and interaction dynamics. To bridge this gap, we propose a paradigm shift from tactile-vision alignment to tactile-force alignment. Here, we introduce TaF-VLA, a framework that explicitly grounds high-dimensional tactile observations in physical interaction forces. To facilitate this, we develop an automated tactile-force data acquisition device and curate the TaF-Dataset, comprising over 10 million synchronized tactile observations, 6-axis force/torque, and matrix force map. To align sequential tactile observations with interaction forces, the central component of our approach is the Tactile-Force Adapter (TaF-Adapter), a tactile sensor encoder that extracts discretized latent information for encoding tactile observations. This mechanism ensures that the learned representations capture history-dependent, noise-insensitive physical dynamics rather than static visual textures. Finally, we integrate this force-aligned encoder into a VLA backbone. Extensive real-world experiments demonstrate that TaF-VLA policy significantly outperforms state-of-the-art tactile-vision-aligned and vision-only baselines on contact-rich tasks, verifying its ability to achieve robust, force-aware manipulation through cross-modal physical reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20321v1</guid></item><item><title>[cs updates on arXiv.org] ECG-Agent: On-Device Tool-Calling Agent for ECG Multi-Turn Dialogue</title><link>https://arxiv.org/abs/2601.20323</link><description>arXiv:2601.20323v1 Announce Type: new 
Abstract: Recent advances in Multimodal Large Language Models have rapidly expanded to electrocardiograms, focusing on classification, report generation, and single-turn QA tasks. However, these models fall short in real-world scenarios, lacking multi-turn conversational ability, on-device efficiency, and precise understanding of ECG measurements such as the PQRST intervals. To address these limitations, we introduce ECG-Agent, the first LLM-based tool-calling agent for multi-turn ECG dialogue. To facilitate its development and evaluation, we also present ECG-Multi-Turn-Dialogue (ECG-MTD) dataset, a collection of realistic user-assistant multi-turn dialogues for diverse ECG lead configurations. We develop ECG-Agents in various sizes, from on-device capable to larger agents. Experimental results show that ECG-Agents outperform baseline ECG-LLMs in response accuracy. Furthermore, on-device agents achieve comparable performance to larger agents in various evaluations that assess response accuracy, tool-calling ability, and hallucinations, demonstrating their viability for real-world applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20323v1</guid></item><item><title>[cs updates on arXiv.org] Neural Cooperative Reach-While-Avoid Certificates for Interconnected Systems</title><link>https://arxiv.org/abs/2601.20324</link><description>arXiv:2601.20324v1 Announce Type: new 
Abstract: Providing formal guarantees for neural network-based controllers in large-scale interconnected systems remains a fundamental challenge. In particular, using neural certificates to capture cooperative interactions and verifying these certificates at scale is crucial for the safe deployment of such controllers. However, existing approaches fall short on both fronts. To address these limitations, we propose neural cooperative reach-while-avoid certificates with Dynamic-Localized Vector Control Lyapunov and Barrier Functions, which capture cooperative dynamics through state-dependent neighborhood structures and provide decentralized certificates for global exponential stability and safety. Based on the certificates, we further develop a scalable training and verification framework that jointly synthesizes controllers and neural certificates via a constrained optimization objective, and leverages a sufficient condition to ensure formal guarantees considering modeling error. To improve scalability, we introduce a structural reuse mechanism to transfer controllers and certificates between substructure-isomorphic systems. The proposed methodology is validated with extensive experiments on multi-robot coordination and vehicle platoons. Results demonstrate that our framework ensures certified cooperative reach-while-avoid while maintaining strong control performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20324v1</guid></item><item><title>[cs updates on arXiv.org] UnlearnShield: Shielding Forgotten Privacy against Unlearning Inversion</title><link>https://arxiv.org/abs/2601.20325</link><description>arXiv:2601.20325v1 Announce Type: new 
Abstract: Machine unlearning is an emerging technique that aims to remove the influence of specific data from trained models, thereby enhancing privacy protection. However, recent research has uncovered critical privacy vulnerabilities, showing that adversaries can exploit unlearning inversion to reconstruct data that was intended to be erased. Despite the severity of this threat, dedicated defenses remain lacking. To address this gap, we propose UnlearnShield, the first defense specifically tailored to counter unlearning inversion. UnlearnShield introduces directional perturbations in the cosine representation space and regulates them through a constraint module to jointly preserve model accuracy and forgetting efficacy, thereby reducing inversion risk while maintaining utility. Experiments demonstrate that it achieves a good trade-off among privacy protection, accuracy, and forgetting.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20325v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Speedup -- Utilizing KV Cache for Sampling and Reasoning</title><link>https://arxiv.org/abs/2601.20326</link><description>arXiv:2601.20326v1 Announce Type: new 
Abstract: KV caches, typically used only to speed up autoregressive decoding, encode contextual information that can be reused for downstream tasks at no extra cost. We propose treating the KV cache as a lightweight representation, eliminating the need to recompute or store full hidden states. Despite being weaker than dedicated embeddings, KV-derived representations are shown to be sufficient for two key applications: \textbf{(i) Chain-of-Embedding}, where they achieve competitive or superior performance on Llama-3.1-8B-Instruct and Qwen2-7B-Instruct; and \textbf{(ii) Fast/Slow Thinking Switching}, where they enable adaptive reasoning on Qwen3-8B and DeepSeek-R1-Distil-Qwen-14B, reducing token generation by up to $5.7\times$ with minimal accuracy loss. Our findings establish KV caches as a free, effective substrate for sampling and reasoning, opening new directions for representation reuse in LLM inference. Code: https://github.com/cmd2001/ICLR2026_KV-Embedding.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20326v1</guid></item><item><title>[cs updates on arXiv.org] CE-RM: A Pointwise Generative Reward Model Optimized via Two-Stage Rollout and Unified Criteria</title><link>https://arxiv.org/abs/2601.20327</link><description>arXiv:2601.20327v1 Announce Type: new 
Abstract: Automatic evaluation is crucial yet challenging for open-ended natural language generation, especially when rule-based metrics are infeasible. Compared with traditional methods, the recent LLM-as-a-Judge paradigms enable better and more flexible evaluation, and show promise as generative reward models for reinforcement learning. However, prior work has revealed a notable gap between their seemingly impressive benchmark performance and actual effectiveness in RL practice. We attribute this issue to some limitations in existing studies, including the dominance of pairwise evaluation and inadequate optimization of evaluation criteria. Therefore, we propose CE-RM-4B, a pointwise generative reward model trained with a dedicated two-stage rollout method, and adopting unified query-based criteria. Using only about 5.7K high-quality data curated from the open-source preference dataset, our CE-RM-4B achieves superior performance on diverse reward model benchmarks, especially in Best-of-N scenarios, and delivers more effective improvements in downstream RL practice.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20327v1</guid></item><item><title>[cs updates on arXiv.org] PsychePass: Calibrating LLM Therapeutic Competence via Trajectory-Anchored Tournaments</title><link>https://arxiv.org/abs/2601.20330</link><description>arXiv:2601.20330v1 Announce Type: new 
Abstract: While large language models show promise in mental healthcare, evaluating their therapeutic competence remains challenging due to the unstructured and longitudinal nature of counseling. We argue that current evaluation paradigms suffer from an unanchored defect, leading to two forms of instability: process drift, where unsteered client simulation wanders away from specific counseling goals, and standard drift, where static pointwise scoring lacks the stability for reliable judgment. To address this, we introduce Ps, a unified framework that calibrates the therapeutic competence of LLMs via trajectory-anchored tournaments. We first anchor the interaction trajectory in simulation, where clients precisely control the fluid consultation process to probe multifaceted capabilities. We then anchor the battle trajectory in judgments through an efficient Swiss-system tournament, utilizing dynamic pairwise battles to yield robust Elo ratings. Beyond ranking, we demonstrate that tournament trajectories can be transformed into credible reward signals, enabling on-policy reinforcement learning to enhance LLMs' performance. Extensive experiments validate the effectiveness of PsychePass and its strong consistency with human expert judgments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20330v1</guid></item><item><title>[cs updates on arXiv.org] Window-Diffusion: Accelerating Diffusion Language Model Inference with Windowed Token Pruning and Caching</title><link>https://arxiv.org/abs/2601.20332</link><description>arXiv:2601.20332v1 Announce Type: new 
Abstract: Diffusion language models (DLMs) generate text through iterative denoising, but inference requires full-sequence attention at every iteration, resulting in substantial redundant computation on masked tokens. Block-wise diffusion can reduce this cost, yet it typically relies on retraining and constrained update orders, limiting its direct applicability to pretrained DLMs. Our token-level analysis reveals pronounced structural locality in DLM inference. Decoding is driven by a small set of prefix-localized active tokens; the influence of distant undecoded context diminishes rapidly, and decoded tokens exhibit stage-wise temporal stability, enabling reuse of intermediate representations except for a brief post-decode transient. Motivated by these observations, we propose \textbf{\placeholder}\footnote{The source code is available at https://github.com/vhicrgit/Window-Diffusion.}, a window-based token pruning and caching method for inference. We maintain a local computation window that slides rightward as denoising progresses, and partition undecoded tokens into: (i) \textit{active tokens} that are computed online, (ii) \textit{buffer tokens} whose KV states are cached and periodically refreshed, and (iii) \textit{far-field tokens} that are pruned outside the window. Computation is restricted to active and buffer tokens within the window, while far-field tokens are omitted at each stage. Experiments on LLaDA and Dream show that, under matched compute budgets, our method achieves up to $99\times$ inference speedup while largely preserving generation performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20332v1</guid></item><item><title>[cs updates on arXiv.org] Test-Time Adaptation for Anomaly Segmentation via Topology-Aware Optimal Transport Chaining</title><link>https://arxiv.org/abs/2601.20333</link><description>arXiv:2601.20333v1 Announce Type: new 
Abstract: Deep topological data analysis (TDA) offers a principled framework for capturing structural invariants such as connectivity and cycles that persist across scales, making it a natural fit for anomaly segmentation (AS). Unlike thresholdbased binarisation, which produces brittle masks under distribution shift, TDA allows anomalies to be characterised as disruptions to global structure rather than local fluctuations. We introduce TopoOT, a topology-aware optimal transport (OT) framework that integrates multi-filtration persistence diagrams (PDs) with test-time adaptation (TTA). Our key innovation is Optimal Transport Chaining, which sequentially aligns PDs across thresholds and filtrations, yielding geodesic stability scores that identify features consistently preserved across scales. These stabilityaware pseudo-labels supervise a lightweight head trained online with OT-consistency and contrastive objectives, ensuring robust adaptation under domain shift. Across standard 2D and 3D anomaly detection benchmarks, TopoOT achieves state-of-the-art performance, outperforming the most competitive methods by up to +24.1% mean F1 on 2D datasets and +10.2% on 3D AS benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20333v1</guid></item><item><title>[cs updates on arXiv.org] Demonstration-Free Robotic Control via LLM Agents</title><link>https://arxiv.org/abs/2601.20334</link><description>arXiv:2601.20334v1 Announce Type: new 
Abstract: Robotic manipulation has increasingly adopted vision-language-action (VLA) models, which achieve strong performance but typically require task-specific demonstrations and fine-tuning, and often generalize poorly under domain shift. We investigate whether general-purpose large language model (LLM) agent frameworks, originally developed for software engineering, can serve as an alternative control paradigm for embodied manipulation. We introduce FAEA (Frontier Agent as Embodied Agent), which applies an LLM agent framework directly to embodied manipulation without modification. Using the same iterative reasoning that enables software agents to debug code, FAEA enables embodied agents to reason through manipulation strategies. We evaluate an unmodified frontier agent, Claude Agent SDK, across the LIBERO, ManiSkill3, and MetaWorld benchmarks. With privileged environment state access, FAEA achieves success rates of 84.9%, 85.7%, and 96%, respectively. This level of task success approaches that of VLA models trained with less than 100 demonstrations per task, without requiring demonstrations or fine-tuning. With one round of human feedback as an optional optimization, performance increases to 88.2% on LIBERO. This demonstration-free capability has immediate practical value: FAEA can autonomously explore novel scenarios in simulation and generate successful trajectories for training data augmentation in embodied learning. Our results indicate that general-purpose agents are sufficient for a class of manipulation tasks dominated by deliberative, task-level planning. This opens a path for robotics systems to leverage actively maintained agent infrastructure and benefit directly from ongoing advances in frontier models. Code is available at https://github.com/robiemusketeer/faea-sim</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20334v1</guid></item><item><title>[cs updates on arXiv.org] MobileBench-OL: A Comprehensive Chinese Benchmark for Evaluating Mobile GUI Agents in Real-World Environment</title><link>https://arxiv.org/abs/2601.20335</link><description>arXiv:2601.20335v1 Announce Type: new 
Abstract: Recent advances in mobile Graphical User Interface (GUI) agents highlight the growing need for comprehensive evaluation benchmarks. While new online benchmarks offer more realistic testing than offline ones, they tend to focus on the agents' task instruction-following ability while neglecting their reasoning and exploration ability. Moreover, these benchmarks do not consider the random noise in real-world mobile environments. This leads to a gap between benchmarks and real-world environments. To addressing these limitations, we propose MobileBench-OL, an online benchmark with 1080 tasks from 80 Chinese apps. It measures task execution, complex reasoning, and noise robustness of agents by including 5 subsets, which set multiple evaluation dimensions. We also provide an auto-eval framework with a reset mechanism, enabling stable and repeatable real-world benchmarking. Evaluating 12 leading GUI agents on MobileBench-OL shows significant room for improvement to meet real-world requirements. Human evaluation further confirms that MobileBench-OL can reliably measure the performance of leading GUI agents in real environments. Our data and code will be released upon acceptance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20335v1</guid></item><item><title>[cs updates on arXiv.org] Improving Diffusion Language Model Decoding through Joint Search in Generation Order and Token Space</title><link>https://arxiv.org/abs/2601.20339</link><description>arXiv:2601.20339v1 Announce Type: new 
Abstract: Diffusion Language Models (DLMs) offer order-agnostic generation that can explore many possible decoding trajectories. However, current decoding methods commit to a single trajectory, limiting exploration in trajectory space. We introduce Order-Token Search to explore this space through jointly searching over generation order and token values. Its core is a likelihood estimator that scores denoising actions, enabling stable pruning and efficient exploration of diverse trajectories. Across mathematical reasoning and coding benchmarks, Order-Token Search consistently outperforms baselines on GSM8K, MATH500, Countdown, and HumanEval (3.1%, 3.8%, 7.9%, and 6.8% absolute over backbone), matching or surpassing diffu-GRPO post-trained d1-LLaDA. Our work establishes joint search as a key component for advancing decoding in DLMs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20339v1</guid></item><item><title>[cs updates on arXiv.org] Multimodal Multi-Agent Ransomware Analysis Using AutoGen</title><link>https://arxiv.org/abs/2601.20346</link><description>arXiv:2601.20346v1 Announce Type: new 
Abstract: Ransomware has become one of the most serious cybersecurity threats causing major financial losses and operational disruptions worldwide.Traditional detection methods such as static analysis, heuristic scanning and behavioral analysis often fall short when used alone. To address these limitations, this paper presents multimodal multi agent ransomware analysis framework designed for ransomware classification. Proposed multimodal multiagent architecture combines information from static, dynamic and network sources. Each data type is handled by specialized agent that uses auto encoder based feature extraction. These representations are then integrated through a fusion agent. After that fused representation are used by transformer based classifier. It identifies the specific ransomware family. The agents interact through an interagent feedback mechanism that iteratively refines feature representations by suppressing low confidence information. The framework was evaluated on large scale datasets containing thousands of ransomware and benign samples. Multiple experiments were conducted on ransomware dataset. It outperforms single modality and nonadaptive fusion baseline achieving improvement of up to 0.936 in Macro-F1 for family classification and reducing calibration error. Over 100 epochs, the agentic feedback loop displays a stable monotonic convergence leading to over +0.75 absolute improvement in terms of agent quality and a final composite score of around 0.88 without fine tuning of the language models. Zeroday ransomware detection remains family dependent on polymorphism and modality disruptions. Confidence aware abstention enables reliable real world deployment by favoring conservativeand trustworthy decisions over forced classification. The findings indicate that proposed approach provides a practical andeffective path toward improving real world ransomware defense systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20346v1</guid></item><item><title>[cs updates on arXiv.org] MMSF: Multitask and Multimodal Supervised Framework for WSI Classification and Survival Analysis</title><link>https://arxiv.org/abs/2601.20347</link><description>arXiv:2601.20347v1 Announce Type: new 
Abstract: Multimodal evidence is critical in computational pathology: gigapixel whole slide images capture tumor morphology, while patient-level clinical descriptors preserve complementary context for prognosis. Integrating such heterogeneous signals remains challenging because feature spaces exhibit distinct statistics and scales. We introduce MMSF, a multitask and multimodal supervised framework built on a linear-complexity MIL backbone that explicitly decomposes and fuses cross-modal information. MMSF comprises a graph feature extraction module embedding tissue topology at the patch level, a clinical data embedding module standardizing patient attributes, a feature fusion module aligning modality-shared and modality-specific representations, and a Mamba-based MIL encoder with multitask prediction heads. Experiments on CAMELYON16 and TCGA-NSCLC demonstrate 2.1--6.6\% accuracy and 2.2--6.9\% AUC improvements over competitive baselines, while evaluations on five TCGA survival cohorts yield 7.1--9.8\% C-index improvements compared with unimodal methods and 5.6--7.1\% over multimodal alternatives.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20347v1</guid></item><item><title>[cs updates on arXiv.org] PalmBridge: A Plug-and-Play Feature Alignment Framework for Open-Set Palmprint Verification</title><link>https://arxiv.org/abs/2601.20351</link><description>arXiv:2601.20351v1 Announce Type: new 
Abstract: Palmprint recognition is widely used in biometric systems, yet real-world performance often degrades due to feature distribution shifts caused by heterogeneous deployment conditions. Most deep palmprint models assume a closed and stationary distribution, leading to overfitting to dataset-specific textures rather than learning domain-invariant representations. Although data augmentation is commonly used to mitigate this issue, it assumes augmented samples can approximate the target deployment distribution, an assumption that often fails under significant domain mismatch. To address this limitation, we propose PalmBridge, a plug-and-play feature-space alignment framework for open-set palmprint verification based on vector quantization. Rather than relying solely on data-level augmentation, PalmBridge learns a compact set of representative vectors directly from training features. During enrollment and verification, each feature vector is mapped to its nearest representative vector under a minimum-distance criterion, and the mapped vector is then blended with the original vector. This design suppresses nuisance variation induced by domain shifts while retaining discriminative identity cues. The representative vectors are jointly optimized with the backbone network using task supervision, a feature-consistency objective, and an orthogonality regularization term to form a stable and well-structured shared embedding space. Furthermore, we analyze feature-to-representative mappings via assignment consistency and collision rate to assess model's sensitivity to blending weights. Experiments on multiple palmprint datasets and backbone architectures show that PalmBridge consistently reduces EER in intra-dataset open-set evaluation and improves cross-dataset generalization with negligible to modest runtime overhead.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20351v1</guid></item><item><title>[cs updates on arXiv.org] AMA: Adaptive Memory via Multi-Agent Collaboration</title><link>https://arxiv.org/abs/2601.20352</link><description>arXiv:2601.20352v1 Announce Type: new 
Abstract: The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from simple context extension to the development of dedicated agentic memory systems. However, existing approaches typically rely on rigid retrieval granularity, accumulation-heavy maintenance strategies, and coarse-grained update mechanisms. These design choices create a persistent mismatch between stored information and task-specific reasoning demands, while leading to the unchecked accumulation of logical inconsistencies over time. To address these challenges, we propose Adaptive Memory via Multi-Agent Collaboration (AMA), a novel framework that leverages coordinated agents to manage memory across multiple granularities. AMA employs a hierarchical memory design that dynamically aligns retrieval granularity with task complexity. Specifically, the Constructor and Retriever jointly enable multi-granularity memory construction and adaptive query routing. The Judge verifies the relevance and consistency of retrieved content, triggering iterative retrieval when evidence is insufficient or invoking the Refresher upon detecting logical conflicts. The Refresher then enforces memory consistency by performing targeted updates or removing outdated entries. Extensive experiments on challenging long-context benchmarks show that AMA significantly outperforms state-of-the-art baselines while reducing token consumption by approximately 80% compared to full-context methods, demonstrating its effectiveness in maintaining retrieval precision and long-term memory consistency.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20352v1</guid></item><item><title>[cs updates on arXiv.org] Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models</title><link>https://arxiv.org/abs/2601.20354</link><description>arXiv:2601.20354v1 Announce Type: new 
Abstract: Text-to-image (T2I) models have achieved remarkable success in generating high-fidelity images, but they often fail in handling complex spatial relationships, e.g., spatial perception, reasoning, or interaction. These critical aspects are largely overlooked by current benchmarks due to their short or information-sparse prompt design. In this paper, we introduce SpatialGenEval, a new benchmark designed to systematically evaluate the spatial intelligence of T2I models, covering two key aspects: (1) SpatialGenEval involves 1,230 long, information-dense prompts across 25 real-world scenes. Each prompt integrates 10 spatial sub-domains and corresponding 10 multi-choice question-answer pairs, ranging from object position and layout to occlusion and causality. Our extensive evaluation of 21 state-of-the-art models reveals that higher-order spatial reasoning remains a primary bottleneck. (2) To demonstrate that the utility of our information-dense design goes beyond simple evaluation, we also construct the SpatialT2I dataset. It contains 15,400 text-image pairs with rewritten prompts to ensure image consistency while preserving information density. Fine-tuned results on current foundation models (i.e., Stable Diffusion-XL, Uniworld-V1, OmniGen2) yield consistent performance gains (+4.2%, +5.7%, +4.4%) and more realistic effects in spatial relations, highlighting a data-centric paradigm to achieve spatial intelligence in T2I models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20354v1</guid></item><item><title>[cs updates on arXiv.org] CURVE: Learning Causality-Inspired Invariant Representations for Robust Scene Understanding via Uncertainty-Guided Regularization</title><link>https://arxiv.org/abs/2601.20355</link><description>arXiv:2601.20355v1 Announce Type: new 
Abstract: Scene graphs provide structured abstractions for scene understanding, yet they often overfit to spurious correlations, severely hindering out-of-distribution generalization. To address this limitation, we propose CURVE, a causality-inspired framework that integrates variational uncertainty modeling with uncertainty-guided structural regularization to suppress high-variance, environment-specific relations. Specifically, we apply prototype-conditioned debiasing to disentangle invariant interaction dynamics from environment-dependent variations, promoting a sparse and domain-stable topology. Empirically, we evaluate CURVE in zero-shot transfer and low-data sim-to-real adaptation, verifying its ability to learn domain-stable sparse topologies and provide reliable uncertainty estimates to support risk prediction under distribution shifts.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20355v1</guid></item><item><title>[cs updates on arXiv.org] TABED: Test-Time Adaptive Ensemble Drafting for Robust Speculative Decoding in LVLMs</title><link>https://arxiv.org/abs/2601.20357</link><description>arXiv:2601.20357v1 Announce Type: new 
Abstract: Speculative decoding (SD) has proven effective for accelerating LLM inference by quickly generating draft tokens and verifying them in parallel. However, SD remains largely unexplored for Large Vision-Language Models (LVLMs), which extend LLMs to process both image and text prompts. To address this gap, we benchmark existing inference methods with small draft models on 11 datasets across diverse input scenarios and observe scenario-specific performance fluctuations. Motivated by these findings, we propose Test-time Adaptive Batched Ensemble Drafting (TABED), which dynamically ensembles multiple drafts obtained via batch inference by leveraging deviations from past ground truths available in the SD setting. The dynamic ensemble method achieves an average robust walltime speedup of 1.74x over autoregressive decoding and a 5% improvement over single drafting methods, while remaining training-free and keeping ensembling costs negligible through parameter sharing. With its plug-and-play compatibility, we further enhance TABED by integrating advanced verification and alternative drafting methods. Code and custom-trained models are available at https://github.com/furiosa-ai/TABED.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20357v1</guid></item><item><title>[cs updates on arXiv.org] TINNs: Time-Induced Neural Networks for Solving Time-Dependent PDEs</title><link>https://arxiv.org/abs/2601.20361</link><description>arXiv:2601.20361v1 Announce Type: new 
Abstract: Physics-informed neural networks (PINNs) solve time-dependent partial differential equations (PDEs) by learning a mesh-free, differentiable solution that can be evaluated anywhere in space and time. However, standard space--time PINNs take time as an input but reuse a single network with shared weights across all times, forcing the same features to represent markedly different dynamics. This coupling degrades accuracy and can destabilize training when enforcing PDE, boundary, and initial constraints jointly. We propose Time-Induced Neural Networks (TINNs), a novel architecture that parameterizes the network weights as a learned function of time, allowing the effective spatial representation to evolve over time while maintaining shared structure. The resulting formulation naturally yields a nonlinear least-squares problem, which we optimize efficiently using a Levenberg--Marquardt method. Experiments on various time-dependent PDEs show up to $4\times$ improved accuracy and $10\times$ faster convergence compared to PINNs and strong baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20361v1</guid></item><item><title>[cs updates on arXiv.org] Switchcodec: Adaptive residual-expert sparse quantization for high-fidelity neural audio coding</title><link>https://arxiv.org/abs/2601.20362</link><description>arXiv:2601.20362v1 Announce Type: new 
Abstract: Recent neural audio compression models often rely on residual vector quantization for high-fidelity coding, but using a fixed number of per-frame codebooks is suboptimal for the wide variability of audio content-especially for signals that are either very simple or highly complex. To address this limitation, we propose SwitchCodec, a neural audio codec based on Residual Experts Vector Quantization (REVQ). REVQ combines a shared quantizer with dynamically routed expert quantizers that are activated according to the input audio, decoupling bitrate from codebook capacity and improving compression efficiency. This design ensures full training and utilization of each quantizer. In addition, a variable-bitrate mechanism adjusts the number of active expert quantizers at inference, enabling multi-bitrate operation without retraining. Experiments demonstrate that SwitchCodec surpasses existing baselines on both objective metrics and subjective listening tests.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20362v1</guid></item><item><title>[cs updates on arXiv.org] Can Continuous-Time Diffusion Models Generate and Solve Globally Constrained Discrete Problems? A Study on Sudoku</title><link>https://arxiv.org/abs/2601.20363</link><description>arXiv:2601.20363v1 Announce Type: new 
Abstract: Can standard continuous-time generative models represent distributions whose support is an extremely sparse, globally constrained discrete set? We study this question using completed Sudoku grids as a controlled testbed, treating them as a subset of a continuous relaxation space. We train flow-matching and score-based models along a Gaussian probability path and compare deterministic (ODE) sampling, stochastic (SDE) sampling, and DDPM-style discretizations derived from the same continuous-time training. Unconditionally, stochastic sampling substantially outperforms deterministic flows; score-based samplers are the most reliable among continuous-time methods, and DDPM-style ancestral sampling achieves the highest validity overall. We further show that the same models can be repurposed for guided generation: by repeatedly sampling completions under clamped clues and stopping when constraints are satisfied, the model acts as a probabilistic Sudoku solver. Although far less sample-efficient than classical solvers and discrete-geometry-aware diffusion methods, these experiments demonstrate that classic diffusion/flow formulations can assign non-zero probability mass to globally constrained combinatorial structures and can be used for constraint satisfaction via stochastic search.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20363v1</guid></item><item><title>[cs updates on arXiv.org] RAW-Flow: Advancing RGB-to-RAW Image Reconstruction with Deterministic Latent Flow Matching</title><link>https://arxiv.org/abs/2601.20364</link><description>arXiv:2601.20364v1 Announce Type: new 
Abstract: RGB-to-RAW reconstruction, or the reverse modeling of a camera Image Signal Processing (ISP) pipeline, aims to recover high-fidelity RAW data from RGB images. Despite notable progress, existing learning-based methods typically treat this task as a direct regression objective and struggle with detail inconsistency and color deviation, due to the ill-posed nature of inverse ISP and the inherent information loss in quantized RGB images. To address these limitations, we pioneer a generative perspective by reformulating RGB-to-RAW reconstruction as a deterministic latent transport problem and introduce a novel framework named RAW-Flow, which leverages flow matching to learn a deterministic vector field in latent space, to effectively bridge the gap between RGB and RAW representations and enable accurate reconstruction of structural details and color information. To further enhance latent transport, we introduce a cross-scale context guidance module that injects hierarchical RGB features into the flow estimation process. Moreover, we design a dual-domain latent autoencoder with a feature alignment constraint to support the proposed latent transport framework, which jointly encodes RGB and RAW inputs while promoting stable training and high-fidelity reconstruction. Extensive experiments demonstrate that RAW-Flow outperforms state-of-the-art approaches both quantitatively and visually.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20364v1</guid></item><item><title>[cs updates on arXiv.org] Dual-Modality IoT Framework for Integrated Access Control and Environmental Safety Monitoring with Real-Time Cloud Analytics</title><link>https://arxiv.org/abs/2601.20366</link><description>arXiv:2601.20366v1 Announce Type: new 
Abstract: The integration of physical security systems with environmental safety monitoring represents a critical advancement in smart infrastructure management. Traditional approaches maintain these systems as independent silos, creating operational inefficiencies, delayed emergency responses, and increased management complexity. This paper presents a comprehensive dual-modality Internet of Things framework that seamlessly integrates RFID-based access control with multi-sensor environmental safety monitoring through a unified cloud architecture. The system comprises two coordinated subsystems: Subsystem 1 implements RFID authentication with servo-actuated gate control and real-time Google Sheets logging, while Subsystem 2 provides comprehensive safety monitoring incorporating flame detection, water flow measurement, LCD status display, and personnel identification. Both subsystems utilize ESP32 microcontrollers for edge processing and wireless connectivity. Experimental evaluation over 45 days demonstrates exceptional performance metrics: 99.2\% RFID authentication accuracy with 0.82-second average response time, 98.5\% flame detection reliability within 5-meter range, and 99.8\% cloud data logging success rate. The system maintains operational integrity during network disruptions through intelligent local caching mechanisms and achieves total implementation cost of 5,400 BDT (approximately \$48), representing an 82\% reduction compared to commercial integrated solutions. This research establishes a practical framework for synergistic security-safety integration, demonstrating that professional-grade performance can be achieved through careful architectural design and component optimization while maintaining exceptional cost-effectiveness and accessibility for diverse application scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20366v1</guid></item><item><title>[cs updates on arXiv.org] Unsupervised Anomaly Detection in Multi-Agent Trajectory Prediction via Transformer-Based Models</title><link>https://arxiv.org/abs/2601.20367</link><description>arXiv:2601.20367v1 Announce Type: new 
Abstract: Identifying safety-critical scenarios is essential for autonomous driving, but the rarity of such events makes supervised labeling impractical. Traditional rule-based metrics like Time-to-Collision are too simplistic to capture complex interaction risks, and existing methods lack a systematic way to verify whether statistical anomalies truly reflect physical danger. To address this gap, we propose an unsupervised anomaly detection framework based on a multi-agent Transformer that models normal driving and measures deviations through prediction residuals. A dual evaluation scheme has been proposed to assess both detection stability and physical alignment: Stability is measured using standard ranking metrics in which Kendall Rank Correlation Coefficient captures rank agreement and Jaccard index captures the consistency of the top-K selected items; Physical alignment is assessed through correlations with established Surrogate Safety Measures (SSM). Experiments on the NGSIM dataset demonstrate our framework's effectiveness: We show that the maximum residual aggregator achieves the highest physical alignment while maintaining stability. Furthermore, our framework identifies 388 unique anomalies missed by Time-to-Collision and statistical baselines, capturing subtle multi-agent risks like reactive braking under lateral drift. The detected anomalies are further clustered into four interpretable risk types, offering actionable insights for simulation and testing.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20367v1</guid></item><item><title>[cs updates on arXiv.org] LIFT: Byzantine Resilient Hub-Sampling</title><link>https://arxiv.org/abs/2601.20368</link><description>arXiv:2601.20368v1 Announce Type: new 
Abstract: Recently, a novel peer sampling protocol, Elevator, was introduced to construct network topologies tailored for emerging decentralized applications such as federated learning and blockchain. Elevator builds hub-based topologies in a fully decentralized manner, randomly selecting hubs among participating nodes. These hubs, acting as central nodes connected to the entire network, can be leveraged to accelerate message dissemination. Simulation results have shown that Elevator converges rapidly (within 3--4 cycles) and exhibits robustness against crash failures and churn. However, its resilience to Byzantine adversaries has not been investigated. In this work, we provide the first evaluation of Elevator under Byzantine adversaries and show that even a small fraction (2%) of Byzantine nodes is sufficient to subvert the network. As a result, we introduce LIFT, a new protocol that extends Elevator by employing a cryptographically secure pseudo-random number generator (PRNG) for hub selection, thereby mitigating Byzantine manipulation. In contrast, LIFT withstands adversarial infiltration and remains robust with up to 10% Byzantine nodes. These results highlight the necessity of secure randomness in decentralized hub formation and position LIFT as a more reliable building block for Byzantine-resilient decentralized systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20368v1</guid></item><item><title>[cs updates on arXiv.org] RepSFNet : A Single Fusion Network with Structural Reparameterization for Crowd Counting</title><link>https://arxiv.org/abs/2601.20369</link><description>arXiv:2601.20369v1 Announce Type: new 
Abstract: Crowd counting remains challenging in variable-density scenes due to scale variations, occlusions, and the high computational cost of existing models. To address these issues, we propose RepSFNet (Reparameterized Single Fusion Network), a lightweight architecture designed for accurate and real-time crowd estimation. RepSFNet leverages a RepLK-ViT backbone with large reparameterized kernels for efficient multi-scale feature extraction. It further integrates a Feature Fusion module combining Atrous Spatial Pyramid Pooling (ASPP) and Context-Aware Network (CAN) to achieve robust, density-adaptive context modeling. A Concatenate Fusion module is employed to preserve spatial resolution and generate high-quality density maps. By avoiding attention mechanisms and multi-branch designs, RepSFNet significantly reduces parameters and computational complexity. The training objective combines Mean Squared Error and Optimal Transport loss to improve both count accuracy and spatial distribution alignment. Experiments conducted on ShanghaiTech, NWPU, and UCF-QNRF datasets demonstrate that RepSFNet achieves competitive accuracy while reducing inference latency by up to 34 percent compared to recent state-of-the-art methods, making it suitable for real-time and low-power edge computing applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20369v1</guid></item><item><title>[cs updates on arXiv.org] A Program Logic for Abstract (Hyper)Properties</title><link>https://arxiv.org/abs/2601.20370</link><description>arXiv:2601.20370v1 Announce Type: new 
Abstract: We introduce APPL (Abstract Program Property Logic), a unifying Hoare-style logic that subsumes standard Hoare logic, incorrectness logic, and several variants of Hyper Hoare logic. APPL provides a principled foundation for abstract program logics parameterised by an abstract domain, encompassing both existing and novel abstractions of properties and hyperproperties. The logic is grounded in a semantic framework where the meaning of commands is first defined on a lattice basis and then extended to the full lattice via additivity. Crucially, nondeterministic choice is interpreted by a monoidal operator that need not be idempotent nor coincide with the lattice join. This flexibility allows the framework to capture collecting semantics, various classes of abstract semantics, and hypersemantics. The APPL proof system is sound, and it is relatively complete whenever the property language is sufficiently expressive. When the property language is restricted to an abstract domain, the result is a sound abstract deduction system based on best correct approximations. Relative completeness with respect to a corresponding abstract semantics is recovered provided the abstract domain is complete, in the sense of abstract interpretation, for the monoidal operator.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20370v1</guid></item><item><title>[cs updates on arXiv.org] A High-Performance Fractal Encryption Framework and Modern Innovations for Secure Image Transmission</title><link>https://arxiv.org/abs/2601.20374</link><description>arXiv:2601.20374v1 Announce Type: new 
Abstract: The current digital era, driven by growing threats to data security, requires a robust image encryption technique. Classical encryption algorithms suffer from a trade-off among security, image fidelity, and computational efficiency. This paper aims to enhance the performance and efficiency of image encryption. This is done by proposing Fractal encryption based on Fourier transforms as a new method of image encryption, leveraging state-of-the-art technology. The new approach considered here intends to enhance both security and efficiency in image encryption by comparing Fractal Encryption with basic methods. The suggested system also aims to optimise encryption/ decryption times and preserve image quality. This paper provides an introduction to Image Encryption using the fractal-based method, its mathematical formulation, and its comparative efficiency against publicly known traditional encryption methods. As a result, after filling the gaps identified in previous research, it has significantly improved both its encryption/decryption time and image fidelity compared to other techniques. In this paper, directions for future research and possible improvements are outlined for attention.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20374v1</guid></item><item><title>[cs updates on arXiv.org] LLM-AutoDP: Automatic Data Processing via LLM Agents for Model Fine-tuning</title><link>https://arxiv.org/abs/2601.20375</link><description>arXiv:2601.20375v1 Announce Type: new 
Abstract: Large Language Models (LLMs) can be fine-tuned on domain-specific data to enhance their performance in specialized fields. However, such data often contains numerous low-quality samples, necessitating effective data processing (DP). In practice, DP strategies are typically developed through iterative manual analysis and trial-and-error adjustment. These processes inevitably incur high labor costs and may lead to privacy issues in high-privacy domains like healthcare due to direct human access to sensitive data. Thus, achieving automated data processing without exposing the raw data has become a critical challenge. To address this challenge, we propose LLM-AutoDP, a novel framework that leverages LLMs as agents to automatically generate and optimize data processing strategies. Our method generates multiple candidate strategies and iteratively refines them using feedback signals and comparative evaluations. This iterative in-context learning mechanism enables the agent to converge toward high-quality processing pipelines without requiring direct human intervention or access to the underlying data. To further accelerate strategy search, we introduce three key techniques: Distribution Preserving Sampling, which reduces data volume while maintaining distributional integrity; Processing Target Selection, which uses a binary classifier to identify low-quality samples for focused processing; Cache-and-Reuse Mechanism}, which minimizes redundant computations by reusing prior processing results. Results show that models trained on data processed by our framework achieve over 80% win rates against models trained on unprocessed data. Compared to AutoML baselines based on LLM agents, LLM-AutoDP achieves approximately a 65% win rate. Moreover, our acceleration techniques reduce the total searching time by up to 10 times, demonstrating both effectiveness and efficiency.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20375v1</guid></item><item><title>[cs updates on arXiv.org] RF-MatID: Dataset and Benchmark for Radio Frequency Material Identification</title><link>https://arxiv.org/abs/2601.20377</link><description>arXiv:2601.20377v1 Announce Type: new 
Abstract: Accurate material identification plays a crucial role in embodied AI systems, enabling a wide range of applications. However, current vision-based solutions are limited by the inherent constraints of optical sensors, while radio-frequency (RF) approaches, which can reveal intrinsic material properties, have received growing attention. Despite this progress, RF-based material identification remains hindered by the lack of large-scale public datasets and the limited benchmarking of learning-based approaches. In this work, we present RF-MatID, the first open-source, large-scale, wide-band, and geometry-diverse RF dataset for fine-grained material identification. RF-MatID includes 16 fine-grained categories grouped into 5 superclasses, spanning a broad frequency range from 4 to 43.5 GHz, and comprises 142k samples in both frequency- and time-domain representations. The dataset systematically incorporates controlled geometry perturbations, including variations in incidence angle and stand-off distance. We further establish a multi-setting, multi-protocol benchmark by evaluating state-of-the-art deep learning models, assessing both in-distribution performance and out-of-distribution robustness under cross-angle and cross-distance shifts. The 5 frequency-allocation protocols enable systematic frequency- and region-level analysis, thereby facilitating real-world deployment. RF-MatID aims to enable reproducible research, accelerate algorithmic advancement, foster cross-domain robustness, and support the development of real-world application in RF-based material identification.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20377v1</guid></item><item><title>[cs updates on arXiv.org] Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution</title><link>https://arxiv.org/abs/2601.20379</link><description>arXiv:2601.20379v1 Announce Type: new 
Abstract: Large language models (LLMs) struggle with complex, long-horizon reasoning due to instability caused by their frozen policy assumption. Current test-time scaling methods treat execution feedback merely as an external signal for filtering or rewriting trajectories, without internalizing it to improve the underlying reasoning strategy. Inspired by Popper's epistemology of "conjectures and refutations," we argue that intelligence requires real-time evolution of the model's policy through learning from failed attempts. We introduce Policy of Thoughts (PoT), a framework that recasts reasoning as a within-instance online optimization process. PoT first generates diverse candidate solutions via an efficient exploration mechanism, then uses Group Relative Policy Optimization (GRPO) to update a transient LoRA adapter based on execution feedback. This closed-loop design enables dynamic, instance-specific refinement of the model's reasoning priors. Experiments show that PoT dramatically boosts performance: a 4B model achieves 49.71% accuracy on LiveCodeBench, outperforming GPT-4o and DeepSeek-V3 despite being over 50 smaller.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20379v1</guid></item><item><title>[cs updates on arXiv.org] OmegaUse: Building a General-Purpose GUI Agent for Autonomous Task Execution</title><link>https://arxiv.org/abs/2601.20380</link><description>arXiv:2601.20380v1 Announce Type: new 
Abstract: Graphical User Interface (GUI) agents show great potential for enabling foundation models to complete real-world tasks, revolutionizing human-computer interaction and improving human productivity. In this report, we present OmegaUse, a general-purpose GUI agent model for autonomous task execution on both mobile and desktop platforms, supporting computer-use and phone-use scenarios. Building an effective GUI agent model relies on two factors: (1) high-quality data and (2) effective training methods. To address these, we introduce a carefully engineered data-construction pipeline and a decoupled training paradigm. For data construction, we leverage rigorously curated open-source datasets and introduce a novel automated synthesis framework that integrates bottom-up autonomous exploration with top-down taxonomy-guided generation to create high-fidelity synthetic data. For training, to better leverage these data, we adopt a two-stage strategy: Supervised Fine-Tuning (SFT) to establish fundamental interaction syntax, followed by Group Relative Policy Optimization (GRPO) to improve spatial grounding and sequential planning. To balance computational efficiency with agentic reasoning capacity, OmegaUse is built on a Mixture-of-Experts (MoE) backbone. To evaluate cross-terminal capabilities in an offline setting, we introduce OS-Nav, a benchmark suite spanning multiple operating systems: ChiM-Nav, targeting Chinese Android mobile environments, and Ubu-Nav, focusing on routine desktop interactions on Ubuntu. Extensive experiments show that OmegaUse is highly competitive across established GUI benchmarks, achieving a state-of-the-art (SOTA) score of 96.3% on ScreenSpot-V2 and a leading 79.1% step success rate on AndroidControl. OmegaUse also performs strongly on OS-Nav, reaching 74.24% step success on ChiM-Nav and 55.9% average success on Ubu-Nav.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20380v1</guid></item><item><title>[cs updates on arXiv.org] STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation</title><link>https://arxiv.org/abs/2601.20381</link><description>arXiv:2601.20381v1 Announce Type: new 
Abstract: Visual foundation models provide strong perceptual features for robotics, but their dense representations lack explicit object-level structure, limiting robustness and contractility in manipulation tasks. We propose STORM (Slot-based Task-aware Object-centric Representation for robotic Manipulation), a lightweight object-centric adaptation module that augments frozen visual foundation models with a small set of semantic-aware slots for robotic manipulation. Rather than retraining large backbones, STORM employs a multi-phase training strategy: object-centric slots are first stabilized through visual--semantic pretraining using language embeddings, then jointly adapted with a downstream manipulation policy. This staged learning prevents degenerate slot formation and preserves semantic consistency while aligning perception with task objectives. Experiments on object discovery benchmarks and simulated manipulation tasks show that STORM improves generalization to visual distractors, and control performance compared to directly using frozen foundation model features or training object-centric representations end-to-end. Our results highlight multi-phase adaptation as an efficient mechanism for transforming generic foundation model features into task-aware object-centric representations for robotic control.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20381v1</guid></item><item><title>[cs updates on arXiv.org] HINT: Hierarchical Interaction Modeling for Autoregressive Multi-Human Motion Generation</title><link>https://arxiv.org/abs/2601.20383</link><description>arXiv:2601.20383v1 Announce Type: new 
Abstract: Text-driven multi-human motion generation with complex interactions remains a challenging problem. Despite progress in performance, existing offline methods that generate fixed-length motions with a fixed number of agents, are inherently limited in handling long or variable text, and varying agent counts. These limitations naturally encourage autoregressive formulations, which predict future motions step by step conditioned on all past trajectories and current text guidance. In this work, we introduce HINT, the first autoregressive framework for multi-human motion generation with Hierarchical INTeraction modeling in diffusion. First, HINT leverages a disentangled motion representation within a canonicalized latent space, decoupling local motion semantics from inter-person interactions. This design facilitates direct adaptation to varying numbers of human participants without requiring additional refinement. Second, HINT adopts a sliding-window strategy for efficient online generation, and aggregates local within-window and global cross-window conditions to capture past human history, inter-person dependencies, and align with text guidance. This strategy not only enables fine-grained interaction modeling within each window but also preserves long-horizon coherence across all the long sequence. Extensive experiments on public benchmarks demonstrate that HINT matches the performance of strong offline models and surpasses autoregressive baselines. Notably, on InterHuman, HINT achieves an FID of 3.100, significantly improving over the previous state-of-the-art score of 5.154.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20383v1</guid></item><item><title>[cs updates on arXiv.org] SFQA: A Comprehensive Perceptual Quality Assessment Dataset for Singing Face Generation</title><link>https://arxiv.org/abs/2601.20385</link><description>arXiv:2601.20385v1 Announce Type: new 
Abstract: The Talking Face Generation task has enormous potential for various applications in digital humans and agents, etc. Singing, as a common facial movement second only to talking, can be regarded as a universal language across ethnicities and cultures. However, it is often underestimated in the field due to lack of singing face datasets and the domain gap between singing and talking in rhythm and amplitude. More significantly, the quality of Singing Face Generation (SFG) often falls short and is uneven or limited by different applicable scenarios, which prompts us to propose timely and effective quality assessment methods to ensure user experience. To address existing gaps in this domain, this paper introduces a new SFG content quality assessment dataset SFQA, built using 12 representative generation methods. During the construction of the dataset, 100 photographs or portraits, as well as 36 music clips from 7 different styles, are utilized to generate 5,184 singing face videos that constitute the SFQA dataset. To further explore the quality of SFG methods, subjective quality assessment is conducted by evaluators, whose ratings reveal a significant variation in quality among different generation methods. Based on our proposed SFQA dataset, we comprehensively benchmark the current objective quality assessment algorithms.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20385v1</guid></item><item><title>[cs updates on arXiv.org] Graph-Structured Deep Learning Framework for Multi-task Contention Identification with High-dimensional Metrics</title><link>https://arxiv.org/abs/2601.20389</link><description>arXiv:2601.20389v1 Announce Type: new 
Abstract: This study addresses the challenge of accurately identifying multi-task contention types in high-dimensional system environments and proposes a unified contention classification framework that integrates representation transformation, structural modeling, and a task decoupling mechanism. The method first constructs system state representations from high-dimensional metric sequences, applies nonlinear transformations to extract cross-dimensional dynamic features, and integrates multiple source information such as resource utilization, scheduling behavior, and task load variations within a shared representation space. It then introduces a graph-based modeling mechanism to capture latent dependencies among metrics, allowing the model to learn competitive propagation patterns and structural interference across resource links. On this basis, task-specific mapping structures are designed to model the differences among contention types and enhance the classifier's ability to distinguish multiple contention patterns. To achieve stable performance, the method employs an adaptive multi-task loss weighting strategy that balances shared feature learning with task-specific feature extraction and generates final contention predictions through a standardized inference process. Experiments conducted on a public system trace dataset demonstrate advantages in accuracy, recall, precision, and F1, and sensitivity analyses on batch size, training sample scale, and metric dimensionality further confirm the model's stability and applicability. The study shows that structured representations and multi-task classification based on high-dimensional metrics can significantly improve contention pattern recognition and offer a reliable technical approach for performance management in complex computing environments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20389v1</guid></item><item><title>[cs updates on arXiv.org] Eliminating Hallucination in Diffusion-Augmented Interactive Text-to-Image Retrieval</title><link>https://arxiv.org/abs/2601.20391</link><description>arXiv:2601.20391v1 Announce Type: new 
Abstract: Diffusion-Augmented Interactive Text-to-Image Retrieval (DAI-TIR) is a promising paradigm that improves retrieval performance by generating query images via diffusion models and using them as additional ``views'' of the user's intent. However, these generative views can be incorrect because diffusion generation may introduce hallucinated visual cues that conflict with the original query text. Indeed, we empirically demonstrate that these hallucinated cues can substantially degrade DAI-TIR performance. To address this, we propose Diffusion-aware Multi-view Contrastive Learning (DMCL), a hallucination-robust training framework that casts DAI-TIR as joint optimization over representations of query intent and the target image. DMCL introduces semantic-consistency and diffusion-aware contrastive objectives to align textual and diffusion-generated query views while suppressing hallucinated query signals. This yields an encoder that acts as a semantic filter, effectively mapping hallucinated cues into a null space, improving robustness to spurious cues and better representing the user's intent. Attention visualization and geometric embedding-space analyses corroborate this filtering behavior. Across five standard benchmarks, DMCL delivers consistent improvements in multi-round Hits@10, reaching as high as 7.37\% over prior fine-tuned and zero-shot baselines, which indicates it is a general and robust training framework for DAI-TIR.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20391v1</guid></item><item><title>[cs updates on arXiv.org] Comprehension vs. Adoption: Evaluating a Language Workbench Through a Family of Experiments</title><link>https://arxiv.org/abs/2601.20394</link><description>arXiv:2601.20394v1 Announce Type: new 
Abstract: Language workbenches are tools that enable the definition, reuse, and composition of programming languages and their ecosystems, aiming to streamline language development. To facilitate their adoption by language designers, the comprehensibility of the language used to define other languages is an important aspect to evaluate. Moreover, considering that language workbenches are relatively new tools, user acceptance emerges as a crucial factor to be accounted for during their assessment. Current literature often neglects user-centred aspects like comprehensibility and acceptance in the assessment of this breed of tools. This paper addresses this gap through a family of experiments assessing Neverlang, a modular language workbench. The study adopts a tailored version of the Method Evaluation Model (MEM) to evaluate the comprehensibility of Neverlang's meta-language and programs, as well as user acceptance in terms of perceived ease of use, perceived usefulness, and intention to use. It also investigates the relationships among these dimensions. The experiments were conducted in three iterations involving participants from academia. The results reveal that users demonstrate sufficient comprehension of Neverlang's meta-language, particularly concerning its syntax, express a favourable perception of its usefulness, and indicate their intention to use it. However, the results also indicate that Neverlang's ease of use remains a challenge. Additionally, variations in the perceived ease of use and perceived usefulness, whether low or high, influence the users' intention to use the tool. Surprisingly, no significant correlation is found between comprehensibility and user acceptance. Notably, higher comprehensibility of the meta-language does not necessarily translate into greater acceptance, underscoring the complex interplay between comprehension and adoption.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20394v1</guid></item><item><title>[cs updates on arXiv.org] FedRD: Reducing Divergences for Generalized Federated Learning via Heterogeneity-aware Parameter Guidance</title><link>https://arxiv.org/abs/2601.20397</link><description>arXiv:2601.20397v1 Announce Type: new 
Abstract: Heterogeneous federated learning (HFL) aims to ensure effective and privacy-preserving collaboration among different entities. As newly joined clients require significant adjustments and additional training to align with the existing system, the problem of generalizing federated learning models to unseen clients under heterogeneous data has become progressively crucial. Consequently, we highlight two unsolved challenging issues in federated domain generalization: Optimization Divergence and Performance Divergence. To tackle the above challenges, we propose FedRD, a novel heterogeneity-aware federated learning algorithm that collaboratively utilizes parameter-guided global generalization aggregation and local debiased classification to reduce divergences, aiming to obtain an optimal global model for participating and unseen clients. Extensive experiments on public multi-domain datasets demonstrate that our approach exhibits a substantial performance advantage over competing baselines in addressing this specific problem.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20397v1</guid></item><item><title>[cs updates on arXiv.org] ScatterFusion: A Hierarchical Scattering Transform Framework for Enhanced Time Series Forecasting</title><link>https://arxiv.org/abs/2601.20401</link><description>arXiv:2601.20401v1 Announce Type: new 
Abstract: Time series forecasting presents significant challenges due to the complex temporal dependencies at multiple time scales. This paper introduces ScatterFusion, a novel framework that synergistically integrates scattering transforms with hierarchical attention mechanisms for robust time series forecasting. Our approach comprises four key components: (1) a Hierarchical Scattering Transform Module (HSTM) that extracts multi-scale invariant features capturing both local and global patterns; (2) a Scale-Adaptive Feature Enhancement (SAFE) module that dynamically adjusts feature importance across different scales; (3) a Multi-Resolution Temporal Attention (MRTA) mechanism that learns dependencies at varying time horizons; and (4) a Trend-Seasonal-Residual (TSR) decomposition-guided structure-aware loss function. Extensive experiments on seven benchmark datasets demonstrate that ScatterFusion outperforms other common methods, achieving significant reductions in error metrics across various prediction horizons.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20401v1</guid></item><item><title>[cs updates on arXiv.org] GuideAI: A Real-time Personalized Learning Solution with Adaptive Interventions</title><link>https://arxiv.org/abs/2601.20402</link><description>arXiv:2601.20402v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have emerged as powerful learning tools, but they lack awareness of learners' cognitive and physiological states, limiting their adaptability to the user's learning style. Contemporary learning techniques primarily focus on structured learning paths, knowledge tracing, and generic adaptive testing but fail to address real-time learning challenges driven by cognitive load, attention fluctuations, and engagement levels. Building on findings from a formative user study (N=66), we introduce GuideAI, a multi-modal framework that enhances LLM-driven learning by integrating real-time biosensory feedback including eye gaze tracking, heart rate variability, posture detection, and digital note-taking behavior. GuideAI dynamically adapts learning content and pacing through cognitive optimizations (adjusting complexity based on learning progress markers), physiological interventions (breathing guidance and posture correction), and attention-aware strategies (redirecting focus using gaze analysis). Additionally, GuideAI supports diverse learning modalities, including text-based, image-based, audio-based, and video-based instruction, across varied knowledge domains. A preliminary study (N = 25) assessed GuideAI's impact on knowledge retention and cognitive load through standardized assessments. The results show statistically significant improvements in both problem-solving capability and recall-based knowledge assessments. Participants also experienced notable reductions in key NASA-TLX measures including mental demand, frustration levels, and effort, while simultaneously reporting enhanced perceived performance. These findings demonstrate GuideAI's potential to bridge the gap between current LLM-based learning systems and individualized learner needs, paving the way for adaptive, cognition-aware education at scale.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20402v1</guid></item><item><title>[cs updates on arXiv.org] Refined rates of convergence for target-data dependent greedy generalized interpolation with Sobolev kernels</title><link>https://arxiv.org/abs/2601.20407</link><description>arXiv:2601.20407v1 Announce Type: new 
Abstract: Greedy methods have recently been successfully applied to generalized kernel interpolation, or the recovery of a function from data stemming from the evaluation of linear functionals, including the approximation of solutions of linear PDEs by symmetric collocation. When applied to kernels generating Sobolev spaces as their native Hilbert spaces, some of these greedy methods can provide the same error guarantee of generalized interpolation on quasi-uniform points. More importantly, certain target-data-adaptive methods even give a dimension- and smoothness-independent improvement in the speed of convergence over quasi-uniform points, thus offering advantages for high-dimensional problems. These convergence rates however contain a spurious logarithmic term that limits this beneficial effect. The goal of this note is to remove this factor, and this is possible by using estimates on metric entropy numbers.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20407v1</guid></item><item><title>[cs updates on arXiv.org] Meeting SLOs, Slashing Hours: Automated Enterprise LLM Optimization with OptiKIT</title><link>https://arxiv.org/abs/2601.20408</link><description>arXiv:2601.20408v1 Announce Type: new 
Abstract: Enterprise LLM deployment faces a critical scalability challenge: organizations must optimize models systematically to scale AI initiatives within constrained compute budgets, yet the specialized expertise required for manual optimization remains a niche and scarce skillset. This challenge is particularly evident in managing GPU utilization across heterogeneous infrastructure while enabling teams with diverse workloads and limited LLM optimization experience to deploy models efficiently.
  We present OptiKIT, a distributed LLM optimization framework that democratizes model compression and tuning by automating complex optimization workflows for non-expert teams. OptiKIT provides dynamic resource allocation, staged pipeline execution with automatic cleanup, and seamless enterprise integration.
  In production, it delivers more than 2x GPU throughput improvement while empowering application teams to achieve consistent performance improvements without deep LLM optimization expertise. We share both the platform design and key engineering insights into resource allocation algorithms, pipeline orchestration, and integration patterns that enable large-scale, production-grade democratization of model optimization. Finally, we open-source the system to enable external contributions and broader reproducibility.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20408v1</guid></item><item><title>[cs updates on arXiv.org] AWGformer: Adaptive Wavelet-Guided Transformer for Multi-Resolution Time Series Forecasting</title><link>https://arxiv.org/abs/2601.20409</link><description>arXiv:2601.20409v1 Announce Type: new 
Abstract: Time series forecasting requires capturing patterns across multiple temporal scales while maintaining computational efficiency. This paper introduces AWGformer, a novel architecture that integrates adaptive wavelet decomposition with cross-scale attention mechanisms for enhanced multi-variate time series prediction. Our approach comprises: (1) an Adaptive Wavelet Decomposition Module (AWDM) that dynamically selects optimal wavelet bases and decomposition levels based on signal characteristics; (2) a Cross-Scale Feature Fusion (CSFF) mechanism that captures interactions between different frequency bands through learnable coupling matrices; (3) a Frequency-Aware Multi-Head Attention (FAMA) module that weights attention heads according to their frequency selectivity; (4) a Hierarchical Prediction Network (HPN) that generates forecasts at multiple resolutions before reconstruction. Extensive experiments on benchmark datasets demonstrate that AWGformer achieves significant average improvements over state-of-the-art methods, with particular effectiveness on multi-scale and non-stationary time series. Theoretical analysis provides convergence guarantees and establishes the connection between our wavelet-guided attention and classical signal processing principles.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20409v1</guid></item><item><title>[cs updates on arXiv.org] On Efficient Polyphase Network Implementation Using Successive Vector Approximation</title><link>https://arxiv.org/abs/2601.20411</link><description>arXiv:2601.20411v1 Announce Type: new 
Abstract: In this work, we explore an energy-efficient implementation of the polyphase network for a filter bank multicarrier (FBMC) system. The network is approximated using a greedy algorithm based on matching pursuits (MP) that converts the numerical representation directly from floating point to sum of signed powers of two (SOPOT), which is key for a multiplierless implementation. We compare this technique with other state-of-the-art methods for designing multiplierless hardware, and show that our technique achieves superior performance with similar computational complexity.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20411v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Accuracy: A Cognitive Load Framework for Mapping the Capability Boundaries of Tool-use Agents</title><link>https://arxiv.org/abs/2601.20412</link><description>arXiv:2601.20412v1 Announce Type: new 
Abstract: The ability of Large Language Models (LLMs) to use external tools unlocks powerful real-world interactions, making rigorous evaluation essential. However, current benchmarks primarily report final accuracy, revealing what models can do but obscuring the cognitive bottlenecks that define their true capability boundaries. To move from simple performance scoring to a diagnostic tool, we introduce a framework grounded in Cognitive Load Theory. Our framework deconstructs task complexity into two quantifiable components: Intrinsic Load, the inherent structural complexity of the solution path, formalized with a novel Tool Interaction Graph; and Extraneous Load, the difficulty arising from ambiguous task presentation. To enable controlled experiments, we construct ToolLoad-Bench, the first benchmark with parametrically adjustable cognitive load. Our evaluation reveals distinct performance cliffs as cognitive load increases, allowing us to precisely map each model's capability boundary. We validate that our framework's predictions are highly calibrated with empirical results, establishing a principled methodology for understanding an agent's limits and a practical foundation for building more efficient systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20412v1</guid></item><item><title>[cs updates on arXiv.org] Schadenfreude in the Digital Public Sphere: A cross-national and decade-long analysis of Facebook news engagement</title><link>https://arxiv.org/abs/2601.20413</link><description>arXiv:2601.20413v1 Announce Type: new 
Abstract: Schadenfreude, or the pleasure derived from others' misfortunes, has become a visible and performative feature of online news engagement, yet little is known about its prevalence, dynamics, or social patterning. We examine schadenfreude on Facebook over a ten-year period across nine major news publishers in the United States, the United Kingdom, and India (one left-leaning, one right-leaning, and one centrist per country). Using a combination of human annotation and machine-learning classification, we identify posts describing misfortune and detect schadenfreude in nearly one million associated comments. We find that while sadness and anger dominate reactions to misfortune posts, laughter and amusement form a substantial and patterned minority. Schadenfreude is most frequent in moralized and political contexts, higher among right-leaning audiences, and more pronounced in India than in the United States or United Kingdom. Temporal and regression analyses further reveal that schadenfreude generally increases when groups are politically out of power, but these patterns differ across party lines. Together, our findings move beyond anecdotal accounts to map schadenfreude as a dynamic, context-dependent feature of digital discourse, revealing how it evolves over time and across ideological and cultural divides.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20413v1</guid></item><item><title>[cs updates on arXiv.org] An Empirical Evaluation of Modern MLOps Frameworks</title><link>https://arxiv.org/abs/2601.20415</link><description>arXiv:2601.20415v1 Announce Type: new 
Abstract: Given the increasing adoption of AI solutions in professional environments, it is necessary for developers to be able to make informed decisions about the current tool landscape. This work empirically evaluates various MLOps (Machine Learning Operations) tools to facilitate the management of the ML model lifecycle: MLflow, Metaflow, Apache Airflow, and Kubeflow Pipelines. The tools are evaluated by assessing the criteria of Ease of installation, Configuration flexibility, Interoperability, Code instrumentation complexity, result interpretability, and Documentation when implementing two common ML scenarios: Digit classifier with MNIST and Sentiment classifier with IMDB and BERT. The evaluation is completed by providing weighted results that lead to practical conclusions on which tools are best suited for different scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20415v1</guid></item><item><title>[cs updates on arXiv.org] SpeechMapper: Speech-to-text Embedding Projector for LLMs</title><link>https://arxiv.org/abs/2601.20417</link><description>arXiv:2601.20417v1 Announce Type: new 
Abstract: Current speech LLMs bridge speech foundation models to LLMs using projection layers, training all of these components on speech instruction data. This strategy is computationally intensive and susceptible to task and prompt overfitting. We present SpeechMapper, a cost-efficient speech-to-LLM-embedding training approach that mitigates overfitting, enabling more robust and generalizable models. Our model is first pretrained without the LLM on inexpensive hardware, and then efficiently attached to the target LLM via a brief 1K-step instruction tuning (IT) stage. Through experiments on speech translation and spoken question answering, we demonstrate the versatility of SpeechMapper's pretrained block, presenting results for both task-agnostic IT, an ASR-based adaptation strategy that does not train in the target task, and task-specific IT. In task-agnostic settings, Speechmapper rivals the best instruction-following speech LLM from IWSLT25, despite never being trained on these tasks, while in task-specific settings, it outperforms this model across many datasets, despite requiring less data and compute. Overall, SpeechMapper offers a practical and scalable approach for efficient, generalizable speech-LLM integration without large-scale IT.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20417v1</guid></item><item><title>[cs updates on arXiv.org] Let's Roll a BiFTA: Bi-refinement for Fine-grained Text-visual Alignment in Vision-Language Models</title><link>https://arxiv.org/abs/2601.20419</link><description>arXiv:2601.20419v1 Announce Type: new 
Abstract: Recent research has shown that aligning fine-grained text descriptions with localized image patches can significantly improve the zero-shot performance of pre-trained vision-language models (e.g., CLIP). However, we find that both fine-grained text descriptions and localized image patches often contain redundant information, making text-visual alignment less effective. In this paper, we tackle this issue from two perspectives: \emph{View Refinement} and \emph{Description refinement}, termed as \textit{\textbf{Bi}-refinement for \textbf{F}ine-grained \textbf{T}ext-visual \textbf{A}lignment} (BiFTA). \emph{View refinement} removes redundant image patches with high \emph{Intersection over Union} (IoU) ratios, resulting in more distinctive visual samples. \emph{Description refinement} removes redundant text descriptions with high pairwise cosine similarity, ensuring greater diversity in the remaining descriptions. BiFTA achieves superior zero-shot performance on 6 benchmark datasets for both ViT-based and ResNet-based CLIP, justifying the necessity to remove redundant information in visual-text alignment.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20419v1</guid></item><item><title>[cs updates on arXiv.org] Concept Component Analysis: A Principled Approach for Concept Extraction in LLMs</title><link>https://arxiv.org/abs/2601.20420</link><description>arXiv:2601.20420v1 Announce Type: new 
Abstract: Developing human understandable interpretation of large language models (LLMs) becomes increasingly critical for their deployment in essential domains. Mechanistic interpretability seeks to mitigate the issues through extracts human-interpretable process and concepts from LLMs' activations. Sparse autoencoders (SAEs) have emerged as a popular approach for extracting interpretable and monosemantic concepts by decomposing the LLM internal representations into a dictionary. Despite their empirical progress, SAEs suffer from a fundamental theoretical ambiguity: the well-defined correspondence between LLM representations and human-interpretable concepts remains unclear. This lack of theoretical grounding gives rise to several methodological challenges, including difficulties in principled method design and evaluation criteria. In this work, we show that, under mild assumptions, LLM representations can be approximated as a {linear mixture} of the log-posteriors over concepts given the input context, through the lens of a latent variable model where concepts are treated as latent variables. This motivates a principled framework for concept extraction, namely Concept Component Analysis (ConCA), which aims to recover the log-posterior of each concept from LLM representations through a {unsupervised} linear unmixing process. We explore a specific variant, termed sparse ConCA, which leverages a sparsity prior to address the inherent ill-posedness of the unmixing problem. We implement 12 sparse ConCA variants and demonstrate their ability to extract meaningful concepts across multiple LLMs, offering theory-backed advantages over SAEs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20420v1</guid></item><item><title>[cs updates on arXiv.org] Guiding the Recommender: Information-Aware Auto-Bidding for Content Promotion</title><link>https://arxiv.org/abs/2601.20422</link><description>arXiv:2601.20422v1 Announce Type: new 
Abstract: Modern content platforms offer paid promotion to mitigate cold start by allocating exposure via auctions. Our empirical analysis reveals a counterintuitive flaw in this paradigm: while promotion rescues low-to-medium quality content, it can harm high-quality content by forcing exposure to suboptimal audiences, polluting engagement signals and downgrading future recommendation. We recast content promotion as a dual-objective optimization that balances short-term value acquisition with long-term model improvement. To make this tractable at bid time in content promotion, we introduce a decomposable surrogate objective, gradient coverage, and establish its formal connection to Fisher Information and optimal experimental design. We design a two-stage auto-bidding algorithm based on Lagrange duality that dynamically paces budget through a shadow price and optimizes impression-level bids using per-impression marginal utilities. To address missing labels at bid time, we propose a confidence-gated gradient heuristic, paired with a zeroth-order variant for black-box models that reliably estimates learning signals in real time. We provide theoretical guarantees, proving monotone submodularity of the composite objective, sublinear regret in online auction, and budget feasibility. Extensive offline experiments on synthetic and real-world datasets validate the framework: it outperforms baselines, achieves superior final AUC/LogLoss, adheres closely to budget targets, and remains effective when gradients are approximated zeroth-order. These results show that strategic, information-aware promotion can improve long-term model performance and organic outcomes beyond naive impression-maximization strategies.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20422v1</guid></item><item><title>[cs updates on arXiv.org] Hopes and Fears -- Emotion Distribution in the Topic Landscape of Finnish Parliamentary Speech 2000-2020</title><link>https://arxiv.org/abs/2601.20424</link><description>arXiv:2601.20424v1 Announce Type: new 
Abstract: Existing research often treats parliamentary discourse as a homogeneous whole, overlooking topic-specific patterns. Parliamentary speeches address a wide range of topics, some of which evoke stronger emotions than others. While everyone has intuitive assumptions about what the most emotive topics in a parliament may be, there has been little research into the emotions typically linked to different topics. This paper strives to fill this gap by examining emotion expression among the topics of parliamentary speeches delivered in Eduskunta, the Finnish Parliament, between 2000 and 2020. An emotion analysis model is used to investigate emotion expression in topics, from both synchronic and diachronic perspectives. The results strengthen evidence of increasing positivity in parliamentary speech and provide further insights into topic-specific emotion expression within parliamentary debate.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20424v1</guid></item><item><title>[cs updates on arXiv.org] Quartet of Diffusions: Structure-Aware Point Cloud Generation through Part and Symmetry Guidance</title><link>https://arxiv.org/abs/2601.20425</link><description>arXiv:2601.20425v1 Announce Type: new 
Abstract: We introduce the Quartet of Diffusions, a structure-aware point cloud generation framework that explicitly models part composition and symmetry. Unlike prior methods that treat shape generation as a holistic process or only support part composition, our approach leverages four coordinated diffusion models to learn distributions of global shape latents, symmetries, semantic parts, and their spatial assembly. This structured pipeline ensures guaranteed symmetry, coherent part placement, and diverse, high-quality outputs. By disentangling the generative process into interpretable components, our method supports fine-grained control over shape attributes, enabling targeted manipulation of individual parts while preserving global consistency. A central global latent further reinforces structural coherence across assembled parts. Our experiments show that the Quartet achieves state-of-the-art performance. To our best knowledge, this is the first 3D point cloud generation framework that fully integrates and enforces both symmetry and part priors throughout the generative process.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20425v1</guid></item><item><title>[cs updates on arXiv.org] Mix2Morph: Learning Sound Morphing from Noisy Mixes</title><link>https://arxiv.org/abs/2601.20426</link><description>arXiv:2601.20426v1 Announce Type: new 
Abstract: We introduce Mix2Morph, a text-to-audio diffusion model fine-tuned to perform sound morphing without a dedicated dataset of morphs. By finetuning on noisy surrogate mixes at higher diffusion timesteps, Mix2Morph yields stable, perceptually coherent morphs that convincingly integrate qualities of both sources. We specifically target sound infusions, a practically and perceptually motivated subclass of morphing in which one sound acts as the dominant primary source, providing overall temporal and structural behavior, while a secondary sound is infused throughout, enriching its timbral and textural qualities. Objective evaluations and listening tests show that Mix2Morph outperforms prior baselines and produces high-quality sound infusions across diverse categories, representing a step toward more controllable and concept-driven tools for sound design. Sound examples are available at https://anniejchu.github.io/mix2morph .</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20426v1</guid></item><item><title>[cs updates on arXiv.org] Reducing End-to-End Latency of Cause-Effect Chains with Shared Cache Analysis</title><link>https://arxiv.org/abs/2601.20427</link><description>arXiv:2601.20427v1 Announce Type: new 
Abstract: Cause-effect chains, as a widely used modeling method in real-time embedded systems, are extensively applied in various safety-critical domains. End-to-end latency, as a key real-time attribute of cause-effect chains, is crucial in many applications. But the analysis of end-to-end latency for cause-effect chains on multicore platforms with shared caches still presents an unresolved issue. Traditional methods typically assume that the worst-case execution time (WCET) of each task in the cause-effect chain is known. However, in the absence of scheduling information, these methods often assume that all shared cache accesses result in misses, leading to an overestimation of WCET and, consequently, affecting the accuracy of end-to-end latency. However, effectively integrating scheduling information into the WCET analysis process of the chains may introduce two challenges: first, how to leverage the structural characteristics of the chains to optimize shared cache analysis, and second, how to improve analysis accuracy while avoiding state space explosion.
  To address these issues, this paper proposes a novel end-to-end latency analysis framework designed for multi-chain systems on multicore platforms with shared caches. This framework extracts scheduling information and structural characteristics of cause-effect chains, constructing fine-grained and scalable inter-core memory access contexts at the basic block level for time-sensitive shared cache analysis. This results in more accurate WCET (TSC-WCET) estimates, which are then used to derive the end-to-end latency. Finally, we conduct experiments on dual-core and quad-core systems with various cache configurations, which show that under certain settings, the average maximum end-to-end latency of cause-effect chains is reduced by up to 34% and 26%.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20427v1</guid></item><item><title>[cs updates on arXiv.org] Youtu-Parsing: Perception, Structuring and Recognition via High-Parallelism Decoding</title><link>https://arxiv.org/abs/2601.20430</link><description>arXiv:2601.20430v1 Announce Type: new 
Abstract: This paper presents Youtu-Parsing, an efficient and versatile document parsing model designed for high-performance content extraction. The architecture employs a native Vision Transformer (ViT) featuring a dynamic-resolution visual encoder to extract shared document features, coupled with a prompt-guided Youtu-LLM-2B language model for layout analysis and region-prompted decoding. Leveraging this decoupled and feature-reusable framework, we introduce a high-parallelism decoding strategy comprising two core components: token parallelism and query parallelism. The token parallelism strategy concurrently generates up to 64 candidate tokens per inference step, which are subsequently validated through a verification mechanism. This approach yields a 5--11x speedup over traditional autoregressive decoding and is particularly well-suited for highly structured scenarios, such as table recognition. To further exploit the advantages of region-prompted decoding, the query parallelism strategy enables simultaneous content prediction for multiple bounding boxes (up to five), providing an additional 2x acceleration while maintaining output quality equivalent to standard decoding. Youtu-Parsing encompasses a diverse range of document elements, including text, formulas, tables, charts, seals, and hierarchical structures. Furthermore, the model exhibits strong robustness when handling rare characters, multilingual text, and handwritten content. Extensive evaluations demonstrate that Youtu-Parsing achieves state-of-the-art (SOTA) performance on both the OmniDocBench and olmOCR-bench benchmarks. Overall, Youtu-Parsing demonstrates significant experimental value and practical utility for large-scale document intelligence applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20430v1</guid></item><item><title>[cs updates on arXiv.org] Self Voice Conversion as an Attack against Neural Audio Watermarking</title><link>https://arxiv.org/abs/2601.20432</link><description>arXiv:2601.20432v1 Announce Type: new 
Abstract: Audio watermarking embeds auxiliary information into speech while maintaining speaker identity, linguistic content, and perceptual quality. Although recent advances in neural and digital signal processing-based watermarking methods have improved imperceptibility and embedding capacity, robustness is still primarily assessed against conventional distortions such as compression, additive noise, and resampling. However, the rise of deep learning-based attacks introduces novel and significant threats to watermark security. In this work, we investigate self voice conversion as a universal, content-preserving attack against audio watermarking systems. Self voice conversion remaps a speaker's voice to the same identity while altering acoustic characteristics through a voice conversion model. We demonstrate that this attack severely degrades the reliability of state-of-the-art watermarking approaches and highlight its implications for the security of modern audio watermarking techniques.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20432v1</guid></item><item><title>[cs updates on arXiv.org] MARE: Multimodal Alignment and Reinforcement for Explainable Deepfake Detection via Vision-Language Models</title><link>https://arxiv.org/abs/2601.20433</link><description>arXiv:2601.20433v1 Announce Type: new 
Abstract: Deepfake detection is a widely researched topic that is crucial for combating the spread of malicious content, with existing methods mainly modeling the problem as classification or spatial localization. The rapid advancements in generative models impose new demands on Deepfake detection. In this paper, we propose multimodal alignment and reinforcement for explainable Deepfake detection via vision-language models, termed MARE, which aims to enhance the accuracy and reliability of Vision-Language Models (VLMs) in Deepfake detection and reasoning. Specifically, MARE designs comprehensive reward functions, incorporating reinforcement learning from human feedback (RLHF), to incentivize the generation of text-spatially aligned reasoning content that adheres to human preferences. Besides, MARE introduces a forgery disentanglement module to capture intrinsic forgery traces from high-level facial semantics, thereby improving its authenticity detection capability. We conduct thorough evaluations on the reasoning content generated by MARE. Both quantitative and qualitative experimental results demonstrate that MARE achieves state-of-the-art performance in terms of accuracy and reliability.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20433v1</guid></item><item><title>[cs updates on arXiv.org] Rethinking Thread Scheduling under Oversubscription: A User-Space Framework for Coordinating Multi-runtime and Multi-process Workloads</title><link>https://arxiv.org/abs/2601.20435</link><description>arXiv:2601.20435v1 Announce Type: new 
Abstract: The convergence of high-performance computing (HPC) and artificial intelligence (AI) is driving the emergence of increasingly complex parallel applications and workloads. These workloads often combine multiple parallel runtimes within the same application or across co-located jobs, creating scheduling demands that place significant stress on traditional OS schedulers. When oversubscribed (there are more ready threads than cores), OS schedulers rely on periodic preemptions to multiplex cores, often introducing interference that may degrade performance. In this paper, we present: (1) The User-space Scheduling Framework (USF), a novel seamless process scheduling framework completely implemented in user-space. USF enables users to implement their own process scheduling algorithms without requiring special permissions. We evaluate USF with its default cooperative policy, (2) SCHED_COOP, designed to reduce interference by switching threads only upon blocking. This approach mitigates well-known issues such as Lock-Holder Preemption (LHP), Lock-Waiter Preemption (LWP), and scalability collapse. We implement USF and SCHED_COOP by extending the GNU C library with the nOS-V runtime, enabling seamless coordination across multiple runtimes (e.g., OpenMP) without requiring invasive application changes. Evaluations show gains up to 2.4x in oversubscribed multi-process scenarios, including nested BLAS workloads, multi-process PyTorch inference with LLaMA-3, and Molecular Dynamics (MD) simulations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20435v1</guid></item><item><title>[cs updates on arXiv.org] PEARL: Plan Exploration and Adaptive Reinforcement Learning for Multihop Tool Use</title><link>https://arxiv.org/abs/2601.20439</link><description>arXiv:2601.20439v1 Announce Type: new 
Abstract: Large Language Models show great potential with external tools, but face significant challenges in complex, multi-turn tool invocation. They often exhibit weak planning, tool hallucination, erroneous parameter generation, and struggle with robust interaction. To tackle these issues, we present PEARL, a novel framework to enhance LLM planning and execution for sophisticated tool use. PEARL adopts a two-stage approach: an offline phase where the agent explores tools to learn valid usage patterns and failure conditions, and an online reinforcement learning phase. In the online phase, a dedicated Planner is trained via group Relative Policy Optimization (GRPO) with a carefully designed reward function that provides distinct signals for planning quality. Experiments on the ToolHop and T-Eval benchmarks show PEARL significantly outperforms existing methods, achieving a new state-of-the-art success rate of \textbf{56.5\%} on ToolHop while maintaining a low invocation error rate. Our work marks a key advance in addressing the complex planning challenges of tool use, contributing to the development of more robust and reliable LLM-based agents.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20439v1</guid></item><item><title>[cs updates on arXiv.org] A Timing-Anomaly Free Dynamic Scheduling on Heterogeneous Systems</title><link>https://arxiv.org/abs/2601.20445</link><description>arXiv:2601.20445v1 Announce Type: new 
Abstract: Heterogeneous systems commonly adopt dynamic scheduling algorithms to improve resource utilization and enhance scheduling flexibility. However, such flexibility may introduce timing anomalies, wherein locally reduced execution times can lead to an increase in the overall system execution time. This phenomenon significantly complicates the analysis of Worst-Case Response Time (WCRT), rendering conventional analysis either overly pessimistic or unsafe, and often necessitating exhaustive state-space exploration to ensure correctness.
  To address this challenge, this paper presents the first timing-anomaly-free dynamic scheduling algorithm for heterogeneous systems, referred to as Deterministic Dynamic Execution. It achieves a safe and tight WCRT estimate through a single offline simulation execution. The core idea is to apply deterministic execution constraints, which partially restrict the resource allocation and execution order of tasks at runtime. Based on a formally defined execution progress model for heterogeneous system scheduling, we prove the correctness of the proposed execution constraints and their ability to eliminate timing anomalies. Furthermore, we propose two methods to generate execution constraints. The first method derives execution constraints directly from the execution traces produced by existing scheduling algorithms. The second method is a heuristic-based approach that constructs execution constraints, enabling further reduction of the WCRT. Experimental results on synthetically generated DAG task sets under various system configurations demonstrate that, compared to traditional dynamic scheduling algorithms, our approach not only eliminates timing anomalies but also effectively reduces both the WCRT and response time jitter.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20445v1</guid></item><item><title>[cs updates on arXiv.org] TimeCatcher: A Variational Framework for Volatility-Aware Forecasting of Non-Stationary Time Series</title><link>https://arxiv.org/abs/2601.20448</link><description>arXiv:2601.20448v1 Announce Type: new 
Abstract: Recent lightweight MLP-based models have achieved strong performance in time series forecasting by capturing stable trends and seasonal patterns. However, their effectiveness hinges on an implicit assumption of local stationarity assumption, making them prone to errors in long-term forecasting of highly non-stationary series, especially when abrupt fluctuations occur, a common challenge in domains like web traffic monitoring. To overcome this limitation, we propose TimeCatcher, a novel Volatility-Aware Variational Forecasting framework. TimeCatcher extends linear architectures with a variational encoder to capture latent dynamic patterns hidden in historical data and a volatility-aware enhancement mechanism to detect and amplify significant local variations. Experiments on nine real-world datasets from traffic, financial, energy, and weather domains show that TimeCatcher consistently outperforms state-of-the-art baselines, with particularly large improvements in long-term forecasting scenarios characterized by high volatility and sudden fluctuations. Our code is available at https://github.com/ColaPrinceCHEN/TimeCatcher.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20448v1</guid></item><item><title>[cs updates on arXiv.org] Fair Recourse for All: Ensuring Individual and Group Fairness in Counterfactual Explanations</title><link>https://arxiv.org/abs/2601.20449</link><description>arXiv:2601.20449v1 Announce Type: new 
Abstract: Explainable Artificial Intelligence (XAI) is becoming increasingly essential for enhancing the transparency of machine learning (ML) models. Among the various XAI techniques, counterfactual explanations (CFs) hold a pivotal role due to their ability to illustrate how changes in input features can alter an ML model's decision, thereby offering actionable recourse to users. Ensuring that individuals with comparable attributes and those belonging to different protected groups (e.g., demographic) receive similar and actionable recourse options is essential for trustworthy and fair decision-making. In this work, we address this challenge directly by focusing on the generation of fair CFs. Specifically, we start by defining and formulating fairness at: 1) individual fairness, ensuring that similar individuals receive similar CFs, 2) group fairness, ensuring equitable CFs across different protected groups and 3) hybrid fairness, which accounts for both individual and broader group-level fairness. We formulate the problem as an optimization task and propose a novel model-agnostic, reinforcement learning based approach to generate CFs that satisfy fairness constraints at both the individual and group levels, two objectives that are usually treated as orthogonal. As fairness metrics, we extend existing metrics commonly used for auditing ML models, such as equal choice of recourse and equal effectiveness across individuals and groups. We evaluate our approach on three benchmark datasets, showing that it effectively ensures individual and group fairness while preserving the quality of the generated CFs in terms of proximity and plausibility, and quantify the cost of fairness in the different levels separately. Our work opens a broader discussion on hybrid fairness and its role and implications for XAI and beyond CFs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20449v1</guid></item><item><title>[cs updates on arXiv.org] MuVaC: AVariational Causal Framework for Multimodal Sarcasm Understanding in Dialogues</title><link>https://arxiv.org/abs/2601.20451</link><description>arXiv:2601.20451v1 Announce Type: new 
Abstract: The prevalence of sarcasm in multimodal dialogues on the social platforms presents a crucial yet challenging task for understanding the true intent behind online content. Comprehensive sarcasm analysis requires two key aspects: Multimodal Sarcasm Detection (MSD) and Multimodal Sarcasm Explanation (MuSE). Intuitively, the act of detection is the result of the reasoning process that explains the sarcasm. Current research predominantly focuses on addressing either MSD or MuSE as a single task. Even though some recent work has attempted to integrate these tasks, their inherent causal dependency is often overlooked. To bridge this gap, we propose MuVaC, a variational causal inference framework that mimics human cognitive mechanisms for understanding sarcasm, enabling robust multimodal feature learning to jointly optimize MSD and MuSE. Specifically, we first model MSD and MuSE from the perspective of structural causal models, establishing variational causal pathways to define the objectives for joint optimization. Next, we design an alignment-then-fusion approach to integrate multimodal features, providing robust fusion representations for sarcasm detection and explanation generation. Finally, we enhance the reasoning trustworthiness by ensuring consistency between detection results and explanations. Experimental results demonstrate the superiority of MuVaC in public datasets, offering a new perspective for understanding multimodal sarcasm.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20451v1</guid></item><item><title>[cs updates on arXiv.org] Challenges in Android Data Disclosure: An Empirical Study</title><link>https://arxiv.org/abs/2601.20459</link><description>arXiv:2601.20459v1 Announce Type: new 
Abstract: Current legal frameworks enforce that Android developers accurately report the data their apps collect. However, large codebases can make this reporting challenging. This paper employs an empirical approach to understand developers' experience with Google Play Store's Data Safety Section (DSS) form.
  We first survey 41 Android developers to understand how they categorize privacy-related data into DSS categories and how confident they feel when completing the DSS form. To gain a broader and more detailed view of the challenges developers encounter during the process, we complement the survey with an analysis of 172 online developer discussions, capturing the perspectives of 642 additional developers. Together, these two data sources represent insights from 683 developers.
  Our findings reveal that developers often manually classify the privacy-related data their apps collect into the data categories defined by Google-or, in some cases, omit classification entirely-and rely heavily on existing online resources when completing the form. Moreover, developers are generally confident in recognizing the data their apps collect, yet they lack confidence in translating this knowledge into DSS-compliant disclosures. Key challenges include issues in identifying privacy-relevant data to complete the form, limited understanding of the form, and concerns about app rejection due to discrepancies with Google's privacy requirements.
  These results underscore the need for clearer guidance and more accessible tooling to support developers in meeting privacy-aware reporting obligations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20459v1</guid></item><item><title>[cs updates on arXiv.org] Exploiting the Final Component of Generator Architectures for AI-Generated Image Detection</title><link>https://arxiv.org/abs/2601.20461</link><description>arXiv:2601.20461v1 Announce Type: new 
Abstract: With the rapid proliferation of powerful image generators, accurate detection of AI-generated images has become essential for maintaining a trustworthy online environment. However, existing deepfake detectors often generalize poorly to images produced by unseen generators. Notably, despite being trained under vastly different paradigms, such as diffusion or autoregressive modeling, many modern image generators share common final architectural components that serve as the last stage for converting intermediate representations into images. Motivated by this insight, we propose to "contaminate" real images using the generator's final component and train a detector to distinguish them from the original real images. We further introduce a taxonomy based on generators' final components and categorize 21 widely used generators accordingly, enabling a comprehensive investigation of our method's generalization capability. Using only 100 samples from each of three representative categories, our detector-fine-tuned on the DINOv3 backbone-achieves an average accuracy of 98.83% across 22 testing sets from unseen generators.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20461v1</guid></item><item><title>[cs updates on arXiv.org] CM-GAI: Continuum Mechanistic Generative Artificial Intelligence Theory for Data Dynamics</title><link>https://arxiv.org/abs/2601.20462</link><description>arXiv:2601.20462v1 Announce Type: new 
Abstract: Generative artificial intelligence (GAI) plays a fundamental role in high-impact AI-based systems such as SORA and AlphaFold. Currently, GAI shows limited capability in the specialized domains due to data scarcity. In this paper, we develop a continuum mechanics-based theoretical framework to generalize the optimal transport theory from pure mathematics, which can be used to describe the dynamics of data, realizing the generative tasks with a small amount of data. The developed theory is used to solve three typical problem involved in many mechanical designs and engineering applications: at material level, how to generate the stress-strain response outside the range of experimental conditions based on experimentally measured stress-strain data; at structure level, how to generate the temperature-dependent stress fields under the thermal loading; at system level, how to generate the plastic strain fields under transient dynamic loading. Our results show the proposed theory can complete the generation successfully, showing its potential to solve many difficult problems involved in engineering applications, not limited to mechanics problems, such as image generation. The present work shows that mechanics can provide new tools for computer science. The limitation of the proposed theory is also discussed.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20462v1</guid></item><item><title>[cs updates on arXiv.org] BMAM: Brain-inspired Multi-Agent Memory Framework</title><link>https://arxiv.org/abs/2601.20465</link><description>arXiv:2601.20465v1 Announce Type: new 
Abstract: Language-model-based agents operating over extended interaction horizons face persistent challenges in preserving temporally grounded information and maintaining behavioral consistency across sessions, a failure mode we term soul erosion. We present BMAM (Brain-inspired Multi-Agent Memory), a general-purpose memory architecture that models agent memory as a set of functionally specialized subsystems rather than a single unstructured store. Inspired by cognitive memory systems, BMAM decomposes memory into episodic, semantic, salience-aware, and control-oriented components that operate at complementary time scales. To support long-horizon reasoning, BMAM organizes episodic memories along explicit timelines and retrieves evidence by fusing multiple complementary signals. Experiments on the LoCoMo benchmark show that BMAM achieves 78.45 percent accuracy under the standard long-horizon evaluation setting, and ablation analyses confirm that the hippocampus-inspired episodic memory subsystem plays a critical role in temporal reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20465v1</guid></item><item><title>[cs updates on arXiv.org] Piloting Planetarium Visualizations with LLMs during Live Events in Science Centers</title><link>https://arxiv.org/abs/2601.20466</link><description>arXiv:2601.20466v1 Announce Type: new 
Abstract: We designed and evaluated an AI pilot in a planetarium visualization software, OpenSpace, for public shows in science centers. The piloting role is usually given to a human working in close collaboration with the guide on stage. We recruited 7 professional guides with extensive experience in giving shows to the public to study the impact of the AI-piloting on the overall experience. The AI-pilot is a conversational AI-agent listening to the guide and interpreting the verbal statements as commands to execute camera motions, change simulation time, or toggle visual assets. Our results show that, while AI pilots lack several critical skills for live shows, they could become useful as co-pilots to reduce workload of human pilots and allow multitasking. We propose research directions toward implementing visualization pilots and co-pilots in live settings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20466v1</guid></item><item><title>[cs updates on arXiv.org] CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning</title><link>https://arxiv.org/abs/2601.20467</link><description>arXiv:2601.20467v1 Announce Type: new 
Abstract: Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which can miss task-critical cues and degrade accuracy. Moreover, combining the two is non-trivial due to sequential dependency, task-agnostic pruning, and distribution mismatch. We propose \textbf{CtrlCoT}, a dual-granularity CoT compression framework that harmonizes semantic abstraction and token-level pruning through three components: Hierarchical Reasoning Abstraction produces CoTs at multiple semantic granularities; Logic-Preserving Distillation trains a logic-aware pruner to retain indispensable reasoning cues (e.g., numbers and operators) across pruning ratios; and Distribution-Alignment Generation aligns compressed traces with fluent inference-time reasoning styles to avoid fragmentation. On MATH-500 with Qwen2.5-7B-Instruct, CtrlCoT uses 30.7\% fewer tokens while achieving 7.6 percentage points higher than the strongest baseline, demonstrating more efficient and reliable reasoning. Our code will be publicly available at https://github.com/fanzhenxuan/Ctrl-CoT.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20467v1</guid></item><item><title>[cs updates on arXiv.org] Opportunities of Touch-Enabled Spherical Displays to support Climate Conversations</title><link>https://arxiv.org/abs/2601.20468</link><description>arXiv:2601.20468v1 Announce Type: new 
Abstract: We explore how touch-sensitive spherical displays can support climate conversations in museums and science centers. These displays enable intuitive and embodied interaction with complex climate data, and support collective exploration. However, current interaction capabilities of spherical displays are limited. Therefore, this exploratory study aims to identify potential opportunities to develop meaningful interactions and technical solutions. Through two workshops, key opportunities were identified to improve visitors' understanding and navigation of climate data, along with recommendations for technical implementation. Our results provide guidelines and aspects to consider for future research and development in this area.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20468v1</guid></item><item><title>[cs updates on arXiv.org] Can We Improve Educational Diagram Generation with In-Context Examples? Not if a Hallucination Spoils the Bunch</title><link>https://arxiv.org/abs/2601.20476</link><description>arXiv:2601.20476v1 Announce Type: new 
Abstract: Generative artificial intelligence (AI) has found a widespread use in computing education; at the same time, quality of generated materials raises concerns among educators and students. This study addresses this issue by introducing a novel method for diagram code generation with in-context examples based on the Rhetorical Structure Theory (RST), which aims to improve diagram generation by aligning models' output with user expectations. Our approach is evaluated by computer science educators, who assessed 150 diagrams generated with large language models (LLMs) for logical organization, connectivity, layout aesthetic, and AI hallucination. The assessment dataset is additionally investigated for its utility in automated diagram evaluation. The preliminary results suggest that our method decreases the rate of factual hallucination and improves diagram faithfulness to provided context; however, due to LLMs' stochasticity, the quality of the generated diagrams varies. Additionally, we present an in-depth analysis and discussion on the connection between AI hallucination and the quality of generated diagrams, which reveals that text contexts of higher complexity lead to higher rates of hallucination and LLMs often fail to detect mistakes in their output.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20476v1</guid></item><item><title>[cs updates on arXiv.org] Implicit Hypothesis Testing and Divergence Preservation in Neural Network Representations</title><link>https://arxiv.org/abs/2601.20477</link><description>arXiv:2601.20477v1 Announce Type: new 
Abstract: We study the supervised training dynamics of neural classifiers through the lens of binary hypothesis testing. We model classification as a set of binary tests between class-conditional distributions of representations and empirically show that, along training trajectories, well-generalizing networks increasingly align with Neyman-Pearson optimal decision rules via monotonic improvements in KL divergence that relate to error rate exponents. We finally discuss how this yields an explanation and possible training or regularization strategies for different classes of neural networks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20477v1</guid></item><item><title>[cs updates on arXiv.org] On Every Note a Griff: Looking for a Useful Representation of Basso Continuo Performance Style</title><link>https://arxiv.org/abs/2601.20478</link><description>arXiv:2601.20478v1 Announce Type: new 
Abstract: Basso continuo is a baroque improvisatory accompaniment style which involves improvising multiple parts above a given bass line in a musical score on a harpsichord or organ. Basso continuo is not merely a matter of history; moreover, it is a historically inspired living practice, and The Aligned Continuo Dataset (ACoRD) records the first sample of modern-day basso continuo playing in the symbolic domain. This dataset, containing 175 MIDI recordings of 5 basso continuo scores performed by 7 players, allows us to start observing and analyzing the variety that basso continuo improvisation brings. A recently proposed basso continuo performance-to-score alignment system provides a way of mapping improvised performance notes to score notes. In order to study aligned basso continuo performances, we need an appropriate feature representation. We propose griff, a representation inspired by historical basso continuo treatises. It enables us to encode both pitch content and structure of a basso continuo realization in a transposition-invariant way. Griffs are directly extracted from aligned basso continuo performances by grouping together performance notes aligned to the same score note in a onset-time ordered way, and they provide meaningful tokens that form a feature space in which we can analyze basso continuo performance styles. We statistically describe griffs extracted from the ACoRD dataset recordings, and show in two experiments how griffs can be used for statistical analysis of individuality of different players' basso continuo performance styles. We finally present an argument why it is desirable to preserve the structure of a basso continuo improvisation in order to conduct a refined analysis of personal performance styles of individual basso continuo practitioners, and why griffs can provide a meaningful historically informed feature space worthy of a more robust empirical validation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20478v1</guid></item><item><title>[cs updates on arXiv.org] An explainable framework for the relationship between dementia and glucose metabolism patterns</title><link>https://arxiv.org/abs/2601.20480</link><description>arXiv:2601.20480v1 Announce Type: new 
Abstract: High-dimensional neuroimaging data presents challenges for assessing neurodegenerative diseases due to complex non-linear relationships. Variational Autoencoders (VAEs) can encode scans into lower-dimensional latent spaces capturing disease-relevant features. We propose a semi-supervised VAE framework with a flexible similarity regularization term that aligns selected latent variables with clinical or biomarker measures of dementia progression. This allows adapting the similarity metric and supervised variables to specific goals or available data. We demonstrate the approach using PET scans from the Alzheimer's Disease Neuroimaging Initiative (ADNI), guiding the first latent dimension to align with a cognitive score. Using this supervised latent variable, we generate average reconstructions across levels of cognitive impairment. Voxel-wise GLM analysis reveals reduced metabolism in key regions, mainly the hippocampus, and within major Resting State Networks, particularly the Default Mode and Central Executive Networks. The remaining latent variables encode affine transformations and intensity variations, capturing confounds such as inter-subject variability and site effects. Our framework effectively extracts disease-related patterns aligned with established Alzheimer's biomarkers, offering an interpretable and adaptable tool for studying neurodegenerative progression.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20480v1</guid></item><item><title>[cs updates on arXiv.org] ConStruM: A Structure-Guided LLM Framework for Context-Aware Schema Matching</title><link>https://arxiv.org/abs/2601.20482</link><description>arXiv:2601.20482v1 Announce Type: new 
Abstract: Column matching is a central task in reconciling schemas for data integration. Column names and descriptions are valuable for this task. LLMs can leverage such natural-language schema metadata. However, in many datasets, correct matching requires additional evidence beyond the column itself. Because it is impractical to provide an LLM with the entire schema metadata needed to capture this evidence, the core challenge becomes to select and organize the most useful contextual information.
  We present ConStruM, a structure-guided framework for budgeted evidence packing in schema matching. ConStruM constructs a lightweight, reusable structure in which, at query time, it assembles a small context pack emphasizing the most discriminative evidence. ConStruM is designed as an add-on: given a shortlist of candidate targets produced by an upstream matcher, it augments the matcher's final LLM prompt with structured, query-specific evidence so that the final selection is better grounded. For this purpose, we develop a context tree for budgeted multi-level context retrieval and a global similarity hypergraph that surfaces groups of highly similar columns (on both the source and target sides), summarized via group-aware differentiation cues computed online or precomputed offline. Experiments on real datasets show that ConStruM improves matching by providing and organizing the right contextual evidence.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20482v1</guid></item><item><title>[cs updates on arXiv.org] Normative Equivalence in human-AI Cooperation: Behaviour, Not Identity, Drives Cooperation in Mixed-Agent Groups</title><link>https://arxiv.org/abs/2601.20487</link><description>arXiv:2601.20487v1 Announce Type: new 
Abstract: The introduction of artificial intelligence (AI) agents into human group settings raises essential questions about how these novel participants influence cooperative social norms. While previous studies on human-AI cooperation have primarily focused on dyadic interactions, little is known about how integrating AI agents affects the emergence and maintenance of cooperative norms in small groups. This study addresses this gap through an online experiment using a repeated four-player Public Goods Game (PGG). Each group consisted of three human participants and one bot, which was framed either as human or AI and followed one of three predefined decision strategies: unconditional cooperation, conditional cooperation, or free-riding. In our sample of 236 participants, we found that reciprocal group dynamics and behavioural inertia primarily drove cooperation. These normative mechanisms operated identically across conditions, resulting in cooperation levels that did not differ significantly between human and AI labels. Furthermore, we found no evidence of differences in norm persistence in a follow-up Prisoner's Dilemma, or in participants' normative perceptions. Participants' behaviour followed the same normative logic across human and AI conditions, indicating that cooperation depended on group behaviour rather than partner identity. This supports a pattern of normative equivalence, in which the mechanisms that sustain cooperation function similarly in mixed human-AI and all human groups. These findings suggest that cooperative norms are flexible enough to extend to artificial agents, blurring the boundary between humans and AI in collective decision-making.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20487v1</guid></item><item><title>[cs updates on arXiv.org] Monotone-based Numerical Schemes for Two-Dimensional Systems of Nonlocal Conservation Laws</title><link>https://arxiv.org/abs/2601.20494</link><description>arXiv:2601.20494v1 Announce Type: new 
Abstract: We present a class of numerical schemes for two-dimensional systems of nonlocal conservation laws, which are based on utilizing well-known monotone numerical flux functions after suitably approximating the nonlocal terms. The considered systems are weakly coupled by the nonlocal terms and the underlying flux function is rather general to guarantee that our results are applicable to a wide range of common nonlocal models. We state sufficient conditions to ensure the convergence of the monotone-based numerical schemes to the unique weak entropy solution. Moreover, we provide an error estimate that yields the convergence rate of $\mathcal{O}(\sqrt{\Delta t})$ for the numerical approximations of the solution. Our results include an existence and uniqueness proof of the nonlocal system, too. Numerical results illustrate our theoretical findings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20494v1</guid></item><item><title>[cs updates on arXiv.org] Efficient Autoregressive Video Diffusion with Dummy Head</title><link>https://arxiv.org/abs/2601.20499</link><description>arXiv:2601.20499v1 Announce Type: new 
Abstract: The autoregressive video diffusion model has recently gained considerable research interest due to its causal modeling and iterative denoising. In this work, we identify that the multi-head self-attention in these models under-utilizes historical frames: approximately 25% heads attend almost exclusively to the current frame, and discarding their KV caches incurs only minor performance degradation. Building upon this, we propose Dummy Forcing, a simple yet effective method to control context accessibility across different heads. Specifically, the proposed heterogeneous memory allocation reduces head-wise context redundancy, accompanied by dynamic head programming to adaptively classify head types. Moreover, we develop a context packing technique to achieve more aggressive cache compression. Without additional training, our Dummy Forcing delivers up to 2.0x speedup over the baseline, supporting video generation at 24.3 FPS with less than 0.5% quality drop. Project page is available at https://csguoh.github.io/project/DummyForcing/.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20499v1</guid></item><item><title>[cs updates on arXiv.org] Comparative evaluation of training strategies using partially labelled datasets for segmentation of white matter hyperintensities and stroke lesions in FLAIR MRI</title><link>https://arxiv.org/abs/2601.20503</link><description>arXiv:2601.20503v1 Announce Type: new 
Abstract: White matter hyperintensities (WMH) and ischaemic stroke lesions (ISL) are imaging features associated with cerebral small vessel disease (SVD) that are visible on brain magnetic resonance imaging (MRI) scans. The development and validation of deep learning models to segment and differentiate these features is difficult because they visually confound each other in the fluid-attenuated inversion recovery (FLAIR) sequence and often appear in the same subject. We investigated six strategies for training a combined WMH and ISL segmentation model using partially labelled data. We combined privately held fully and partially labelled datasets with publicly available partially labelled datasets to yield a total of 2052 MRI volumes, with 1341 and 1152 containing ground truth annotations for WMH and ISL respectively. We found that several methods were able to effectively leverage the partially labelled data to improve model performance, with the use of pseudolabels yielding the best result.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20503v1</guid></item><item><title>[cs updates on arXiv.org] Latent Temporal Discrepancy as Motion Prior: A Loss-Weighting Strategy for Dynamic Fidelity in T2V</title><link>https://arxiv.org/abs/2601.20504</link><description>arXiv:2601.20504v1 Announce Type: new 
Abstract: Video generation models have achieved notable progress in static scenarios, yet their performance in motion video generation remains limited, with quality degrading under drastic dynamic changes. This is due to noise disrupting temporal coherence and increasing the difficulty of learning dynamic regions. {Unfortunately, existing diffusion models rely on static loss for all scenarios, constraining their ability to capture complex dynamics.} To address this issue, we introduce Latent Temporal Discrepancy (LTD) as a motion prior to guide loss weighting. LTD measures frame-to-frame variation in the latent space, assigning larger penalties to regions with higher discrepancy while maintaining regular optimization for stable regions. This motion-aware strategy stabilizes training and enables the model to better reconstruct high-frequency dynamics. Extensive experiments on the general benchmark VBench and the motion-focused VMBench show consistent gains, with our method outperforming strong baselines by 3.31% on VBench and 3.58% on VMBench, achieving significant improvements in motion quality.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20504v1</guid></item><item><title>[cs updates on arXiv.org] T\"AMU: Emulating Trusted Applications at the (GlobalPlatform)-API Layer</title><link>https://arxiv.org/abs/2601.20507</link><description>arXiv:2601.20507v1 Announce Type: new 
Abstract: Mobile devices rely on Trusted Execution Environments (TEEs) to execute security-critical code and protect sensitive assets. This security-critical code is modularized in components known as Trusted Applications (TAs). Vulnerabilities in TAs can compromise the TEE and, thus, the entire system. However, the closed-source nature and fragmentation of mobile TEEs severely hinder dynamic analysis of TAs, limiting testing efforts to mostly static analyses. This paper presents T\"AMU, a rehosting platform enabling dynamic analysis of TAs, specifically fuzzing and debugging, by interposing their execution at the API layer. To scale to many TAs across different TEEs, T\"AMU leverages the standardization of TEE APIs, driven by the GlobalPlatform specifications. For the remaining TEE-specific APIs not shared across different TEEs, T\"AMU introduces the notion of greedy high-level emulation, a technique that allows prioritizing manual rehosting efforts based on the potential coverage gain during fuzzing. We implement T\"AMU and use it to emulate 67 TAs across four TEEs. Our fuzzing campaigns yielded 17 zero-day vulnerabilities across 11 TAs. These results indicate a deficit of dynamic analysis capabilities across the TEE ecosystem, where not even vendors with source code unlocked these capabilities for themselves. T\"AMU promises to close this gap by bringing effective and practical dynamic analysis to the mobile TEE domain.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20507v1</guid></item><item><title>[cs updates on arXiv.org] Audio Deepfake Detection in the Age of Advanced Text-to-Speech models</title><link>https://arxiv.org/abs/2601.20510</link><description>arXiv:2601.20510v1 Announce Type: new 
Abstract: Recent advances in Text-to-Speech (TTS) systems have substantially increased the realism of synthetic speech, raising new challenges for audio deepfake detection. This work presents a comparative evaluation of three state-of-the-art TTS models--Dia2, Maya1, and MeloTTS--representing streaming, LLM-based, and non-autoregressive architectures. A corpus of 12,000 synthetic audio samples was generated using the Daily-Dialog dataset and evaluated against four detection frameworks, including semantic, structural, and signal-level approaches. The results reveal significant variability in detector performance across generative mechanisms: models effective against one TTS architecture may fail against others, particularly LLM-based synthesis. In contrast, a multi-view detection approach combining complementary analysis levels demonstrates robust performance across all evaluated models. These findings highlight the limitations of single-paradigm detectors and emphasize the necessity of integrated detection strategies to address the evolving landscape of audio deepfake threats.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20510v1</guid></item><item><title>[cs updates on arXiv.org] Say Cheese! Detail-Preserving Portrait Collection Generation via Natural Language Edits</title><link>https://arxiv.org/abs/2601.20511</link><description>arXiv:2601.20511v1 Announce Type: new 
Abstract: As social media platforms proliferate, users increasingly demand intuitive ways to create diverse, high-quality portrait collections. In this work, we introduce Portrait Collection Generation (PCG), a novel task that generates coherent portrait collections by editing a reference portrait image through natural language instructions. This task poses two unique challenges to existing methods: (1) complex multi-attribute modifications such as pose, spatial layout, and camera viewpoint; and (2) high-fidelity detail preservation including identity, clothing, and accessories. To address these challenges, we propose CHEESE, the first large-scale PCG dataset containing 24K portrait collections and 573K samples with high-quality modification text annotations, constructed through an Large Vison-Language Model-based pipeline with inversion-based verification. We further propose SCheese, a framework that combines text-guided generation with hierarchical identity and detail preservation. SCheese employs adaptive feature fusion mechanism to maintain identity consistency, and ConsistencyNet to inject fine-grained features for detail consistency. Comprehensive experiments validate the effectiveness of CHEESE in advancing PCG, with SCheese achieving state-of-the-art performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20511v1</guid></item><item><title>[cs updates on arXiv.org] CCMamba: Selective State-Space Models for Higher-Order Graph Learning on Combinatorial Complexes</title><link>https://arxiv.org/abs/2601.20518</link><description>arXiv:2601.20518v1 Announce Type: new 
Abstract: Topological deep learning has emerged for modeling higher-order relational structures beyond pairwise interactions that standard graph neural networks fail to capture. Although combinatorial complexes offer a unified topological framework, most existing topological deep learning methods rely on local message passing via attention mechanisms, which incur quadratic complexity and remain low-dimensional, limiting scalability and rank-aware information aggregation in higher-order complexes.We propose Combinatorial Complex Mamba (CCMamba), the first unified mamba-based neural framework for learning on combinatorial complexes. CCMamba reformulates message passing as a selective state-space modeling problem by organizing multi-rank incidence relations into structured sequences processed by rank-aware state-space models. This enables adaptive, directional, and long range information propagation in linear time without self attention. We further establish the theoretical analysis that the expressive power upper-bound of CCMamba message passing is the 1-Weisfeiler-Lehman test. Experiments on graph, hypergraph, and simplicial benchmarks demonstrate that CCMamba consistently outperforms existing methods while exhibiting improved scalability and robustness to depth.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20518v1</guid></item><item><title>[cs updates on arXiv.org] Context Tokens are Anchors: Understanding the Repetition Curse in dMLLMs from an Information Flow Perspective</title><link>https://arxiv.org/abs/2601.20520</link><description>arXiv:2601.20520v1 Announce Type: new 
Abstract: Recent diffusion-based Multimodal Large Language Models (dMLLMs) suffer from high inference latency and therefore rely on caching techniques to accelerate decoding. However, the application of cache mechanisms often introduces undesirable repetitive text generation, a phenomenon we term the \textbf{Repeat Curse}. To better investigate underlying mechanism behind this issue, we analyze repetition generation through the lens of information flow. Our work reveals three key findings: (1) context tokens aggregate semantic information as anchors and guide the final predictions; (2) as information propagates across layers, the entropy of context tokens converges in deeper layers, reflecting the model's growing prediction certainty; (3) Repetition is typically linked to disruptions in the information flow of context tokens and to the inability of their entropy to converge in deeper layers. Based on these insights, we present \textbf{CoTA}, a plug-and-play method for mitigating repetition. CoTA enhances the attention of context tokens to preserve intrinsic information flow patterns, while introducing a penalty term to the confidence score during decoding to avoid outputs driven by uncertain context tokens. With extensive experiments, CoTA demonstrates significant effectiveness in alleviating repetition and achieves consistent performance improvements on general tasks. Code is available at https://github.com/ErikZ719/CoTA</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20520v1</guid></item><item><title>[cs updates on arXiv.org] AnomalyVFM -- Transforming Vision Foundation Models into Zero-Shot Anomaly Detectors</title><link>https://arxiv.org/abs/2601.20524</link><description>arXiv:2601.20524v1 Announce Type: new 
Abstract: Zero-shot anomaly detection aims to detect and localise abnormal regions in the image without access to any in-domain training images. While recent approaches leverage vision-language models (VLMs), such as CLIP, to transfer high-level concept knowledge, methods based on purely vision foundation models (VFMs), like DINOv2, have lagged behind in performance. We argue that this gap stems from two practical issues: (i) limited diversity in existing auxiliary anomaly detection datasets and (ii) overly shallow VFM adaptation strategies. To address both challenges, we propose AnomalyVFM, a general and effective framework that turns any pretrained VFM into a strong zero-shot anomaly detector. Our approach combines a robust three-stage synthetic dataset generation scheme with a parameter-efficient adaptation mechanism, utilising low-rank feature adapters and a confidence-weighted pixel loss. Together, these components enable modern VFMs to substantially outperform current state-of-the-art methods. More specifically, with RADIO as a backbone, AnomalyVFM achieves an average image-level AUROC of 94.1% across 9 diverse datasets, surpassing previous methods by significant 3.3 percentage points. Project Page: https://maticfuc.github.io/anomaly_vfm/</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20524v1</guid></item><item><title>[cs updates on arXiv.org] IOTA: Corrective Knowledge-Guided Prompt Learning via Black-White Box Framework</title><link>https://arxiv.org/abs/2601.20526</link><description>arXiv:2601.20526v1 Announce Type: new 
Abstract: Recently, adapting pre-trained models to downstream tasks has attracted increasing interest. Previous Parameter-Efficient-Tuning (PET) methods regard the pre-trained model as an opaque Black Box model, relying purely on data-driven optimization and underutilizing their inherent prior knowledge. This oversight limits the models' potential for effective downstream task adaptation. To address these issues, we propose a novel black-whIte bOx prompT leArning framework (IOTA), which integrates a data-driven Black Box module with a knowledge-driven White Box module for downstream task adaptation. Specifically, the White Box module derives corrective knowledge by contrasting the wrong predictions with the right cognition. This knowledge is verbalized into interpretable human prompts and leveraged through a corrective knowledge-guided prompt selection strategy to guide the Black Box module toward more accurate predictions. By jointly leveraging knowledge- and data-driven learning signals, IOTA achieves effective downstream task adaptation. Experimental results on 12 image classification benchmarks under few-shot and easy-to-hard adaptation settings demonstrate the effectiveness of corrective knowledge and the superiority of our method over state-of-the-art methods.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20526v1</guid></item><item><title>[cs updates on arXiv.org] A Practical Framework of Key Performance Indicators for Multi-Robot Lunar and Planetary Field Tests</title><link>https://arxiv.org/abs/2601.20529</link><description>arXiv:2601.20529v1 Announce Type: new 
Abstract: Robotic prospecting for critical resources on the Moon, such as ilmenite, rare earth elements, and water ice, requires robust exploration methods given the diverse terrain and harsh environmental conditions. Although numerous analog field trials address these goals, comparing their results remains challenging because of differences in robot platforms and experimental setups. These missions typically assess performance using selected, scenario-specific engineering metrics that fail to establish a clear link between field performance and science-driven objectives. In this paper, we address this gap by deriving a structured framework of KPI from three realistic multi-robot lunar scenarios reflecting scientific objectives and operational constraints. Our framework emphasizes scenario-dependent priorities in efficiency, robustness, and precision, and is explicitly designed for practical applicability in field deployments. We validated the framework in a multi-robot field test and found it practical and easy to apply for efficiency- and robustness-related KPI, whereas precision-oriented KPI require reliable ground-truth data that is not always feasible to obtain in outdoor analog environments. Overall, we propose this framework as a common evaluation standard enabling consistent, goal-oriented comparison of multi-robot field trials and supporting systematic development of robotic systems for future planetary exploration.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20529v1</guid></item><item><title>[cs updates on arXiv.org] Colored Markov Modulated Fluid Queues</title><link>https://arxiv.org/abs/2601.20537</link><description>arXiv:2601.20537v1 Announce Type: new 
Abstract: Markov-modulated fluid queues (MMFQs) are a powerful modeling framework for analyzing the performance of computer and communication systems. Their distinguishing feature is that the underlying Markov process evolves on a continuous state space, making them well suited to capture the dynamics of workloads, energy levels, and other performance-related quantities. Although classical MMFQs do not permit jumps in the fluid level, they can still be applied to analyze a wide range of jump processes.
  In this paper, we generalize the MMFQ framework in a new direction by introducing {\bf colored MMFQs} and {\bf colored MMFQs with fluid jumps}. This enriched framework provides an additional form of memory: the color of incoming fluid can be used to keep track of the fluid level when certain events took place. This capability greatly enhances modeling flexibility and enables the analysis of queueing systems that would otherwise be intractable due to the curse of dimensionality or state-space explosion.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20537v1</guid></item><item><title>[cs updates on arXiv.org] Interpreting Emergent Extreme Events in Multi-Agent Systems</title><link>https://arxiv.org/abs/2601.20538</link><description>arXiv:2601.20538v1 Announce Type: new 
Abstract: Large language model-powered multi-agent systems have emerged as powerful tools for simulating complex human-like systems. The interactions within these systems often lead to extreme events whose origins remain obscured by the black box of emergence. Interpreting these events is critical for system safety. This paper proposes the first framework for explaining emergent extreme events in multi-agent systems, aiming to answer three fundamental questions: When does the event originate? Who drives it? And what behaviors contribute to it? Specifically, we adapt the Shapley value to faithfully attribute the occurrence of extreme events to each action taken by agents at different time steps, i.e., assigning an attribution score to the action to measure its influence on the event. We then aggregate the attribution scores along the dimensions of time, agent, and behavior to quantify the risk contribution of each dimension. Finally, we design a set of metrics based on these contribution scores to characterize the features of extreme events. Experiments across diverse multi-agent system scenarios (economic, financial, and social) demonstrate the effectiveness of our framework and provide general insights into the emergence of extreme phenomena.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20538v1</guid></item><item><title>[cs updates on arXiv.org] PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs</title><link>https://arxiv.org/abs/2601.20539</link><description>arXiv:2601.20539v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have enabled automated heuristic design (AHD) for combinatorial optimization problems (COPs), but existing frameworks' reliance on fixed evolutionary rules and static prompt templates often leads to myopic heuristic generation, redundant evaluations, and limited reasoning about how new heuristics should be derived. We propose a novel multi-agent reasoning framework, referred to as Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs (PathWise), which formulates heuristic generation as a sequential decision process over an entailment graph serving as a compact, stateful memory of the search trajectory. This approach allows the system to carry forward past decisions and reuse or avoid derivation information across generations. A policy agent plans evolutionary actions, a world model agent generates heuristic rollouts conditioned on those actions, and critic agents provide routed reflections summarizing lessons from prior steps, shifting LLM-based AHD from trial-and-error evolution toward state-aware planning through reasoning. Experiments across diverse COPs show that PathWise converges faster to better heuristics, generalizes across different LLM backbones, and scales to larger problem sizes.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20539v1</guid></item><item><title>[cs updates on arXiv.org] Advancing Open-source World Models</title><link>https://arxiv.org/abs/2601.20540</link><description>arXiv:2601.20540v1 Announce Type: new 
Abstract: We present LingBot-World, an open-sourced world simulator stemming from video generation. Positioned as a top-tier world model, LingBot-World offers the following features. (1) It maintains high fidelity and robust dynamics in a broad spectrum of environments, including realism, scientific contexts, cartoon styles, and beyond. (2) It enables a minute-level horizon while preserving contextual consistency over time, which is also known as "long-term memory". (3) It supports real-time interactivity, achieving a latency of under 1 second when producing 16 frames per second. We provide public access to the code and model in an effort to narrow the divide between open-source and closed-source technologies. We believe our release will empower the community with practical applications across areas like content creation, gaming, and robot learning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20540v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Literacy: Predicting Interpretation Correctness of Visualizations with User Traits, Item Difficulty, and Rasch Scores</title><link>https://arxiv.org/abs/2601.20544</link><description>arXiv:2601.20544v1 Announce Type: new 
Abstract: Data Visualization Literacy assessments are typically administered via fixed sets of Data Visualization items, despite substantial heterogeneity in how different people interpret the same visualization. This paper presents and evaluates an approach for predicting Human Interpretation Correctness (P-HIC) of data visualizations; i.e., anticipating whether a specific person will interpret a data visualization correctly or not, before exposure to that DV, enabling more personalized assessment and training. We operationalize P-HIC as a binary classification problem using 22 features spanning Human Profile, Human Performance, and Item difficulty (including ExpertDifficulty and RaschDifficulty). We evaluate three machine-learning models (Logistic Regression model, Random Forest, Multi Layer Perceptron) with and without feature selection, using a survey with 1,083 participants who answered 32 Data Visualization items (eight data visualizations per four items), yielding 34,656 item responses. Performance is assessed via a ten-time ten-fold cross-validation in each 32 (item-specific) datasets, using AUC and Cohen's kappa. Logistic Regression model with feature selection is the best-performing approach, reaching a median AUC of 0.72 and a median kappa of 0.32. Feature analyses show RaschDifficulty as the dominant predictor, followed by experts' ratings and prior correctness (PercCorrect), whose relevance increases across sessions. Profile information did not particularly support P-HIC. Our results support the feasibility of anticipating misinterpretations of data visualizations, and motivate the runtime selection of data visualizations items tailored to an audience, thereby improving the efficiency of Data Visualization Literacy assessment and targeted training.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20544v1</guid></item><item><title>[cs updates on arXiv.org] Beyond Divergent Creativity: A Human-Based Evaluation of Creativity in Large Language Models</title><link>https://arxiv.org/abs/2601.20546</link><description>arXiv:2601.20546v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly used in verbal creative tasks. However, previous assessments of the creative capabilities of LLMs remain weakly grounded in human creativity theory and are thus hard to interpret. The widely used Divergent Association Task (DAT) focuses on novelty, ignoring appropriateness, a core component of creativity. We evaluate a range of state-of-the-art LLMs on DAT and show that their scores on the task are lower than those of two baselines that do not possess any creative abilities, undermining its validity for model evaluation. Grounded in human creativity theory, which defines creativity as the combination of novelty and appropriateness, we introduce Conditional Divergent Association Task (CDAT). CDAT evaluates novelty conditional on contextual appropriateness, separating noise from creativity better than DAT, while remaining simple and objective. Under CDAT, smaller model families often show the most creativity, whereas advanced families favor appropriateness at lower novelty. We hypothesize that training and alignment likely shift models along this frontier, making outputs more appropriate but less creative. We release the dataset and code.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20546v1</guid></item><item><title>[cs updates on arXiv.org] IoT Device Identification with Machine Learning: Common Pitfalls and Best Practices</title><link>https://arxiv.org/abs/2601.20548</link><description>arXiv:2601.20548v1 Announce Type: new 
Abstract: This paper critically examines the device identification process using machine learning, addressing common pitfalls in existing literature. We analyze the trade-offs between identification methods (unique vs. class based), data heterogeneity, feature extraction challenges, and evaluation metrics. By highlighting specific errors, such as improper data augmentation and misleading session identifiers, we provide a robust guideline for researchers to enhance the reproducibility and generalizability of IoT security models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20548v1</guid></item><item><title>[cs updates on arXiv.org] DeepSeek-OCR 2: Visual Causal Flow</title><link>https://arxiv.org/abs/2601.20552</link><description>arXiv:2601.20552v1 Announce Type: new 
Abstract: We present DeepSeek-OCR 2 to investigate the feasibility of a novel encoder-DeepEncoder V2-capable of dynamically reordering visual tokens upon image semantics. Conventional vision-language models (VLMs) invariably process visual tokens in a rigid raster-scan order (top-left to bottom-right) with fixed positional encoding when fed into LLMs. However, this contradicts human visual perception, which follows flexible yet semantically coherent scanning patterns driven by inherent logical structures. Particularly for images with complex layouts, human vision exhibits causally-informed sequential processing. Inspired by this cognitive mechanism, DeepEncoder V2 is designed to endow the encoder with causal reasoning capabilities, enabling it to intelligently reorder visual tokens prior to LLM-based content interpretation. This work explores a novel paradigm: whether 2D image understanding can be effectively achieved through two-cascaded 1D causal reasoning structures, thereby offering a new architectural approach with the potential to achieve genuine 2D reasoning. Codes and model weights are publicly accessible at http://github.com/deepseek-ai/DeepSeek-OCR-2.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20552v1</guid></item><item><title>[cs updates on arXiv.org] Online Risk-Averse Planning in POMDPs Using Iterated CVaR Value Function</title><link>https://arxiv.org/abs/2601.20554</link><description>arXiv:2601.20554v1 Announce Type: new 
Abstract: We study risk-sensitive planning under partial observability using the dynamic risk measure Iterated Conditional Value-at-Risk (ICVaR). A policy evaluation algorithm for ICVaR is developed with finite-time performance guarantees that do not depend on the cardinality of the action space. Building on this foundation, three widely used online planning algorithms--Sparse Sampling, Particle Filter Trees with Double Progressive Widening (PFT-DPW), and Partially Observable Monte Carlo Planning with Observation Widening (POMCPOW)--are extended to optimize the ICVaR value function rather than the expectation of the return. Our formulations introduce a risk parameter $\alpha$, where $\alpha = 1$ recovers standard expectation-based planning and $\alpha &lt; 1$ induces increasing risk aversion. For ICVaR Sparse Sampling, we establish finite-time performance guarantees under the risk-sensitive objective, which further enable a novel exploration strategy tailored to ICVaR. Experiments on benchmark POMDP domains demonstrate that the proposed ICVaR planners achieve lower tail risk compared to their risk-neutral counterparts.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20554v1</guid></item><item><title>[cs updates on arXiv.org] Vibro-Sense: Robust Vibration-based Impulse Response Localization and Trajectory Tracking for Robotic Hands</title><link>https://arxiv.org/abs/2601.20555</link><description>arXiv:2601.20555v1 Announce Type: new 
Abstract: Rich contact perception is crucial for robotic manipulation, yet traditional tactile skins remain expensive and complex to integrate. This paper presents a scalable alternative: high-accuracy whole-body touch localization via vibro-acoustic sensing. By equipping a robotic hand with seven low-cost piezoelectric microphones and leveraging an Audio Spectrogram Transformer, we decode the vibrational signatures generated during physical interaction. Extensive evaluation across stationary and dynamic tasks reveals a localization error of under 5 mm in static conditions. Furthermore, our analysis highlights the distinct influence of material properties: stiff materials (e.g., metal) excel in impulse response localization due to sharp, high-bandwidth responses, whereas textured materials (e.g., wood) provide superior friction-based features for trajectory tracking. The system demonstrates robustness to the robot's own motion, maintaining effective tracking even during active operation. Our primary contribution is demonstrating that complex physical contact dynamics can be effectively decoded from simple vibrational signals, offering a viable pathway to widespread, affordable contact perception in robotics. To accelerate research, we provide our full datasets, models, and experimental setups as open-source resources.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20555v1</guid></item><item><title>[cs updates on arXiv.org] Unsupervised Ensemble Learning Through Deep Energy-based Models</title><link>https://arxiv.org/abs/2601.20556</link><description>arXiv:2601.20556v1 Announce Type: new 
Abstract: Unsupervised ensemble learning emerged to address the challenge of combining multiple learners' predictions without access to ground truth labels or additional data. This paradigm is crucial in scenarios where evaluating individual classifier performance or understanding their strengths is challenging due to limited information. We propose a novel deep energy-based method for constructing an accurate meta-learner using only the predictions of individual learners, potentially capable of capturing complex dependence structures between them. Our approach requires no labeled data, learner features, or problem-specific information, and has theoretical guarantees for when learners are conditionally independent. We demonstrate superior performance across diverse ensemble scenarios, including challenging mixture of experts settings. Our experiments span standard ensemble datasets and curated datasets designed to test how the model fuses expertise from multiple sources. These results highlight the potential of unsupervised ensemble learning to harness collective intelligence, especially in data-scarce or privacy-sensitive environments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20556v1</guid></item><item><title>[cs updates on arXiv.org] Tilt-based Aberration Estimation in Transmission Electron Microscopy</title><link>https://arxiv.org/abs/2601.20561</link><description>arXiv:2601.20561v1 Announce Type: new 
Abstract: Transmission electron microscopes (TEMs) enable atomic-scale imaging but suffer from aberrations caused by lens imperfections and environmental conditions, reducing image quality. These aberrations can be compensated by adjusting electromagnetic lenses, but this requires accurate estimates of the aberration coefficients, which can drift over time. This paper introduces a method for the estimation of aberrations in TEM by leveraging the relationship between an induced electron beam tilt and the resulting image shift. The method uses a Kalman filter (KF) to estimate the aberration coefficients from a sequence of image shifts, while accounting for the drift of the aberrations over time. The applied tilt sequence is optimized by minimizing the trace of the predicted error covariance in the KF, which corresponds to the A-optimality criterion in experimental design. We show that this optimization can be performed offline, as the cost criterion is independent of the actual measurements. The resulting non-convex optimization problem is solved using a gradient-based, receding-horizon approach with multi-starts. Additionally, we develop an approach to estimate specimen-dependent noise properties using expectation maximization (EM), which are then used to tailor the tilt pattern optimization to the specific specimen being imaged. The proposed method is validated on a real TEM set-up with several optimized tilt patterns. The results show that optimized patterns significantly outperform naive approaches and that the aberration and drift model accurately captures the underlying physical phenomena. In total, the alignment time is reduced from typically several minutes to less than a minute compared to the state-of-the-art.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20561v1</guid></item><item><title>[cs updates on arXiv.org] DiffVC-RT: Towards Practical Real-Time Diffusion-based Perceptual Neural Video Compression</title><link>https://arxiv.org/abs/2601.20564</link><description>arXiv:2601.20564v1 Announce Type: new 
Abstract: The practical deployment of diffusion-based Neural Video Compression (NVC) faces critical challenges, including severe information loss, prohibitive inference latency, and poor temporal consistency. To bridge this gap, we propose DiffVC-RT, the first framework designed to achieve real-time diffusion-based perceptual NVC. First, we introduce an Efficient and Informative Model Architecture. Through strategic module replacements and pruning, this architecture significantly reduces computational complexity while mitigating structural information loss. Second, to address generative flickering artifacts, we propose Explicit and Implicit Consistency Modeling. We enhance temporal consistency by explicitly incorporating a zero-cost Online Temporal Shift Module within the U-Net, complemented by hybrid implicit consistency constraints. Finally, we present an Asynchronous and Parallel Decoding Pipeline incorporating Mixed Half Precision, which enables asynchronous latent decoding and parallel frame reconstruction via a Batch-dimension Temporal Shift design. Experiments show that DiffVC-RT achieves 80.1% bitrate savings in terms of LPIPS over VTM-17.0 on HEVC dataset with real-time encoding and decoding speeds of 206 / 30 fps for 720p videos on an NVIDIA H800 GPU, marking a significant milestone in diffusion-based video compression.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20564v1</guid></item><item><title>[cs updates on arXiv.org] Local convergence analysis of a linearized Alikhanov scheme for the time fractional sine-Gordon equation</title><link>https://arxiv.org/abs/2601.20566</link><description>arXiv:2601.20566v1 Announce Type: new 
Abstract: This paper investigates the time fractional sine-Gordon equation whose solution exhibits a weak singularity of type t^{\alpha}. By means of the Alikhanov formula we derive a fully discrete, linearized scheme. Using the more general regularity assumption, we derive a sharp truncation-error bound for the fractional derivative. Furthermore, we prove a key inequality and a less restrictive stability result that is valid on general graded temporal meshes. Consequently, the temporal local convergence order is shown to be min{2, r} in H^1-seminorm, where r is the degree of grading; numerical experiments confirm that the optimal rate is already attained as soon as r = 2.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20566v1</guid></item><item><title>[cs updates on arXiv.org] Reinforcement Unlearning via Group Relative Policy Optimization</title><link>https://arxiv.org/abs/2601.20568</link><description>arXiv:2601.20568v1 Announce Type: new 
Abstract: During pretraining, LLMs inadvertently memorize sensitive or copyrighted data, posing significant compliance challenges under legal frameworks like the GDPR and the EU AI Act. Fulfilling these mandates demands techniques that can remove information from a deployed model without retraining from scratch. Existing unlearning approaches attempt to address this need, but often leak the very data they aim to erase, sacrifice fluency and robustness, or depend on costly external reward models. We introduce PURGE (Policy Unlearning through Relative Group Erasure), a novel method grounded in the Group Relative Policy Optimization framework that formulates unlearning as a verifiable problem. PURGE uses an intrinsic reward signal that penalizes any mention of forbidden concepts, allowing safe and consistent unlearning. Our approach reduces token usage per target by up to a factor of 46 compared with SotA methods, while improving fluency by 5.48 percent and adversarial robustness by 12.02 percent over the base model. On the Real World Knowledge Unlearning (RWKU) benchmark, PURGE achieves 11 percent unlearning effectiveness while preserving 98 percent of original utility. PURGE shows that framing LLM unlearning as a verifiable task, enables more reliable, efficient, and scalable forgetting, suggesting a promising new direction for unlearning research that combines theoretical guarantees, improved safety, and practical deployment efficiency.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20568v1</guid></item><item><title>[cs updates on arXiv.org] Gen-SER: When the generative model meets speech emotion recognition</title><link>https://arxiv.org/abs/2601.20573</link><description>arXiv:2601.20573v1 Announce Type: new 
Abstract: Speech emotion recognition (SER) is crucial in speech understanding and generation. Most approaches are based on either classification models or large language models. Different from previous methods, we propose Gen-SER, a novel approach that reformulates SER as a distribution shift problem via generative models. We propose to project discrete class labels into a continuous space, and obtain the terminal distribution via sinusoidal taxonomy encoding. The target-matching-based generative model is adopted to transform the initial distribution into the terminal distribution efficiently. The classification is achieved by calculating the similarity of the generated terminal distribution and ground truth terminal distribution. The experimental results confirm the efficacy of the proposed method, demonstrating its extensibility to various speech-understanding tasks and suggesting its potential applicability to a broader range of classification tasks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20573v1</guid></item><item><title>[cs updates on arXiv.org] MeCo: Enhancing LLM-Empowered Multi-Robot Collaboration via Similar Task Memoization</title><link>https://arxiv.org/abs/2601.20577</link><description>arXiv:2601.20577v1 Announce Type: new 
Abstract: Multi-robot systems have been widely deployed in real-world applications, providing significant improvements in efficiency and reductions in labor costs. However, most existing multi-robot collaboration methods rely on extensive task-specific training, which limits their adaptability to new or diverse scenarios. Recent research leverages the language understanding and reasoning capabilities of large language models (LLMs) to enable more flexible collaboration without specialized training. Yet, current LLM-empowered approaches remain inefficient: when confronted with identical or similar tasks, they must replan from scratch because they omit task-level similarities. To address this limitation, we propose MeCo, a similarity-aware multi-robot collaboration framework that applies the principle of ``cache and reuse'' (a.k.a., memoization) to reduce redundant computation. Unlike simple task repetition, identifying and reusing solutions for similar but not identical tasks is far more challenging, particularly in multi-robot settings. To this end, MeCo introduces a new similarity testing method that retrieves previously solved tasks with high relevance, enabling effective plan reuse without re-invoking LLMs. Furthermore, we present MeCoBench, the first benchmark designed to evaluate performance on similar-task collaboration scenarios. Experimental results show that MeCo substantially reduces planning costs and improves success rates compared with state-of-the-art approaches.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20577v1</guid></item><item><title>[cs updates on arXiv.org] Inequality in Congestion Games with Learning Agents</title><link>https://arxiv.org/abs/2601.20578</link><description>arXiv:2601.20578v1 Announce Type: new 
Abstract: Who benefits from expanding transport networks? While designed to improve mobility, such interventions can also create inequality. In this paper, we show that disparities arise not only from the structure of the network itself but also from differences in how commuters adapt to it. We model commuters as reinforcement learning agents who adapt their travel choices at different learning rates, reflecting unequal access to resources and information. To capture potential efficiency-fairness tradeoffs, we introduce the Price of Learning (PoL), a measure of inefficiency during learning. We analyze both a stylized network -- inspired in the well-known Braess's paradox, yet with two-source nodes -- and an abstraction of a real-world metro system (Amsterdam). Our simulations show that network expansions can simultaneously increase efficiency and amplify inequality, especially when faster learners disproportionately benefit from new routes before others adapt. These results highlight that transport policies must account not only for equilibrium outcomes but also for the heterogeneous ways commuters adapt, since both shape the balance between efficiency and fairness.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20578v1</guid></item><item><title>[cs updates on arXiv.org] Dependable Connectivity for Industrial Wireless Communication Networks</title><link>https://arxiv.org/abs/2601.20580</link><description>arXiv:2601.20580v1 Announce Type: new 
Abstract: Dependability - a system's ability to consistently provide reliable services by ensuring safety and maintainability in the face of internal or external disruptions - is a fundamental requirement for industrial wireless communication networks (IWCNs). While 5G ultra-reliable low-latency communication (URLLC) addresses some aspects of this challenge, its evolution toward holistic dependability in 6G must encompass reliability, availability, safety, and security. This paper provides a comprehensive framework for dependable IWCNs, bridging theory and practice. We first establish the theoretical foundations of dependability, including outlining its key attributes and presenting analytical tools to study it. Next, we explore practical enablers, such as adaptive multiple access schemes leveraging real-time monitoring and time-sensitive networking to ensure end-to-end determinism. A case study demonstrates how intelligent wake-up protocols improve event detection probability by orders of magnitude compared to conventional duty cycling. Finally, we outline open challenges and future directions for a 6G-driven dependable IWCN.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20580v1</guid></item><item><title>[cs updates on arXiv.org] Single-Nodal Spontaneous Symmetry Breaking in NLP Models</title><link>https://arxiv.org/abs/2601.20582</link><description>arXiv:2601.20582v1 Announce Type: new 
Abstract: Spontaneous symmetry breaking in statistical mechanics primarily occurs during phase transitions at the thermodynamic limit where the Hamiltonian preserves inversion symmetry, yet the low-temperature free energy exhibits reduced symmetry. Herein, we demonstrate the emergence of spontaneous symmetry breaking in natural language processing (NLP) models during both pre-training and fine-tuning, even under deterministic dynamics and within a finite training architecture. This phenomenon occurs at the level of individual attention heads and is scaled-down to its small subset of nodes and also valid at a single-nodal level, where nodes acquire the capacity to learn a limited set of tokens after pre-training or labels after fine-tuning for a specific classification task. As the number of nodes increases, a crossover in learning ability occurs, governed by the tradeoff between a decrease following random-guess among increased possible outputs, and enhancement following nodal cooperation, which exceeds the sum of individual nodal capabilities. In contrast to spin-glass systems, where a microscopic state of frozen spins cannot be directly linked to the free-energy minimization goal, each nodal function in this framework contributes explicitly to the global network task and can be upper-bounded using convex hull analysis. Results are demonstrated using BERT-6 architecture pre-trained on Wikipedia dataset and fine-tuned on the FewRel classification task.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20582v1</guid></item><item><title>[cs updates on arXiv.org] Quantitative synthetic aperture radar inversion</title><link>https://arxiv.org/abs/2601.20583</link><description>arXiv:2601.20583v1 Announce Type: new 
Abstract: We study an inverse scattering problem for monostatic synthetic aperture radar (SAR): Estimate the wave speed in a heterogeneous, isotropic and nonmagnetic medium probed by waves emitted and measured by a moving antenna. The forward map, from the wave speed to the measurements, is derived from Maxwell's equations. It is a nonlinear map that accounts for multiple scattering and it is very oscillatory at high frequencies. This makes the standard, nonlinear least squares data fitting formulation of the inverse problem difficult to solve. We introduce an alternative, two-step approach: The first step computes the nonlinear map from the measurements to an approximation of the electric field inside the unknown medium aka, the internal wave. This is done for each antenna location in a non-iterative manner.
  The internal wave fits the data by construction, but it does not solve Maxwell's equations. The second step uses optimization to minimize the discrepancy between the internal wave and the solution of Maxwell's equations, for all antenna locations. The optimization is iterative. The first step defines an imaging function whose computational cost is comparable to that of standard SAR imaging, but it gives a better estimate of the support of targets. Further iterations improve the quantitative estimation of the wave speed. We assess the performance of the method with numerical simulations and compare the results with those of standard inversion.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20583v1</guid></item><item><title>[cs updates on arXiv.org] Ranking-aware Reinforcement Learning for Ordinal Ranking</title><link>https://arxiv.org/abs/2601.20585</link><description>arXiv:2601.20585v1 Announce Type: new 
Abstract: Ordinal regression and ranking are challenging due to inherent ordinal dependencies that conventional methods struggle to model. We propose Ranking-Aware Reinforcement Learning (RARL), a novel RL framework that explicitly learns these relationships. At its core, RARL features a unified objective that synergistically integrates regression and Learning-to-Rank (L2R), enabling mutual improvement between the two tasks. This is driven by a ranking-aware verifiable reward that jointly assesses regression precision and ranking accuracy, facilitating direct model updates via policy optimization. To further enhance training, we introduce Response Mutation Operations (RMO), which inject controlled noise to improve exploration and prevent stagnation at saddle points. The effectiveness of RARL is validated through extensive experiments on three distinct benchmarks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20585v1</guid></item><item><title>[cs updates on arXiv.org] Energy Efficient Downlink mMIMO Using Dynamic Antenna and Power Adaptation</title><link>https://arxiv.org/abs/2601.20586</link><description>arXiv:2601.20586v1 Announce Type: new 
Abstract: Massive multiple-input multiple-output (mMIMO) technology and its future evolutions are expected to address the high data rate demands of sixth generation (6G) communication systems. At the same time, network energy savings (NES) is essential in reducing the operational costs and meeting the sustainability goals of network operators. In this regard, we propose a dynamic scheme for joint antenna and power adaptation to improve NES from a user scheduling and resource allocation perspective. Antenna adaptation is performed using the multiple channel state information resource signal (CSI-RS) framework. Furthermore, the recently introduced transmit power-aware link adaptation scheme, referred to as POLITE for short, is used as the power adaptation technique. The proposed scheme adapts to variations in users' instantaneous traffic and channel conditions to opportunistically maximize NES while also inherently accounting for the user throughput. Numerical simulation results show that the proposed scheme consistently achieves a balance between NES and user perceived throughput (UPT) for different network load conditions. Especially in low and light load conditions, the proposed scheme significantly improves the intra-cell interference and boosts the overall NES, while ensuring that UPT is unaffected.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20586v1</guid></item><item><title>[cs updates on arXiv.org] AutoOverlap: Enabling Fine-Grained Overlap of Computation and Communication with Chunk-Based Scheduling</title><link>https://arxiv.org/abs/2601.20595</link><description>arXiv:2601.20595v1 Announce Type: new 
Abstract: Communication has become a first-order bottleneck in large-cale GPU workloads, and existing distributed compilers address it mainly by overlapping whole compute and communication kernels at the stream level. This coarse granularity incurs extra kernel launches, forces device-wide synchronizations at kernel boundaries, and leaves substantial slack when the slowest tile or kernel stretches the communication tail. We present AutoOverlap, a compiler and runtime that enables automatic fine-grained overlap inside a single fused kernel. AutoOverlap introduces a communication chunk abstraction that decouples communication granularity from kernel structure and backend mechanisms, allowing chunk-level plans to be ported from existing distributed compilers, written directly by users, or instantiated from reusable templates. Given a local Triton kernel and a chunk schedule, AutoOverlap performs transformations to align computation with chunk availability. Implemented as a source-to-source compiler on Triton, AutoOverlap delivers an average end-to-end speedup of 1.3$\times$ and up to 4.7$\times$ on multi-GPU workloads.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20595v1</guid></item><item><title>[cs updates on arXiv.org] StructAlign: Structured Cross-Modal Alignment for Continual Text-to-Video Retrieval</title><link>https://arxiv.org/abs/2601.20597</link><description>arXiv:2601.20597v1 Announce Type: new 
Abstract: Continual Text-to-Video Retrieval (CTVR) is a challenging multimodal continual learning setting, where models must incrementally learn new semantic categories while maintaining accurate text-video alignment for previously learned ones, thus making it particularly prone to catastrophic forgetting. A key challenge in CTVR is feature drift, which manifests in two forms: intra-modal feature drift caused by continual learning within each modality, and non-cooperative feature drift across modalities that leads to modality misalignment. To mitigate these issues, we propose StructAlign, a structured cross-modal alignment method for CTVR. First, StructAlign introduces a simplex Equiangular Tight Frame (ETF) geometry as a unified geometric prior to mitigate modality misalignment. Building upon this geometric prior, we design a cross-modal ETF alignment loss that aligns text and video features with category-level ETF prototypes, encouraging the learned representations to form an approximate simplex ETF geometry. In addition, to suppress intra-modal feature drift, we design a Cross-modal Relation Preserving loss, which leverages complementary modalities to preserve cross-modal similarity relations, providing stable relational supervision for feature updates. By jointly addressing non-cooperative feature drift across modalities and intra-modal feature drift, StructAlign effectively alleviates catastrophic forgetting in CTVR. Extensive experiments on benchmark datasets demonstrate that our method consistently outperforms state-of-the-art continual retrieval approaches.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20597v1</guid></item><item><title>[cs updates on arXiv.org] Person Re-ID in 2025: Supervised, Self-Supervised, and Language-Aligned. What Works?</title><link>https://arxiv.org/abs/2601.20598</link><description>arXiv:2601.20598v1 Announce Type: new 
Abstract: Person Re-Identification (ReID) remains a challenging problem in computer vision. This work reviews various training paradigm and evaluates the robustness of state-of-the-art ReID models in cross-domain applications and examines the role of foundation models in improving generalization through richer, more transferable visual representations. We compare three training paradigms, supervised, self-supervised, and language-aligned models. Through the study the aim is to answer the following questions: Can supervised models generalize in cross-domain scenarios? How does foundation models like SigLIP2 perform for the ReID tasks? What are the weaknesses of current supervised and foundational models for ReID? We have conducted the analysis across 11 models and 9 datasets. Our results show a clear split: supervised models dominate their training domain but crumble on cross-domain data. Language-aligned models, however, show surprising robustness cross-domain for ReID tasks, even though they are not explicitly trained to do so. Code and data available at: https://github.com/moiiai-tech/object-reid-benchmark.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20598v1</guid></item><item><title>[cs updates on arXiv.org] Regularized Gradient Temporal-Difference Learning</title><link>https://arxiv.org/abs/2601.20599</link><description>arXiv:2601.20599v1 Announce Type: new 
Abstract: Gradient temporal-difference (GTD) learning algorithms are widely used for off-policy policy evaluation with function approximation. However, existing convergence analyses rely on the restrictive assumption that the so-called feature interaction matrix (FIM) is nonsingular. In practice, the FIM can become singular and leads to instability or degraded performance. In this paper, we propose a regularized optimization objective by reformulating the mean-square projected Bellman error (MSPBE) minimization. This formulation naturally yields a regularized GTD algorithms, referred to as R-GTD, which guarantees convergence to a unique solution even when the FIM is singular. We establish theoretical convergence guarantees and explicit error bounds for the proposed method, and validate its effectiveness through empirical experiments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20599v1</guid></item><item><title>[cs updates on arXiv.org] Shortest LCD embeddings of binary, ternary and quaternary linear codes</title><link>https://arxiv.org/abs/2601.20600</link><description>arXiv:2601.20600v1 Announce Type: new 
Abstract: In the recent years, there has been active research on self-orthogonal embeddings of linear codes since they yielded some optimal self-orthogonal codes. LCD codes have a trivial hull so they are counterparts of self-orthogonal codes. So it is a natural question whether one can embed linear codes into optimal LCD codes. To answer it, we first determine the number of columns to be added to a generator matrix of a linear code in order to embed the given code into an LCD code. Then we characterize all possible forms of shortest LCD embeddings of a linear code. As examples, we start from binary and ternary Hamming codes of small lengths and obtain optimal LCD codes with minimum distance 4. Furthermore, we find new ternary LCD codes with parameters including $[23, 4, 14]$, $[23, 5, 12]$, $[24, 6, 12]$, and $[25, 5, 14]$ and a new quaternary LCD $[21, 10, 8]$ code, each of which has minimum distance one greater than those of known codes. This shows that our shortest LCD embedding method is useful in finding optimal LCD codes over various fields.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20600v1</guid></item><item><title>[cs updates on arXiv.org] CLEAR-Mamba:Towards Accurate, Adaptive and Trustworthy Multi-Sequence Ophthalmic Angiography Classification</title><link>https://arxiv.org/abs/2601.20601</link><description>arXiv:2601.20601v1 Announce Type: new 
Abstract: Medical image classification is a core task in computer-aided diagnosis (CAD), playing a pivotal role in early disease detection, treatment planning, and patient prognosis assessment. In ophthalmic practice, fluorescein fundus angiography (FFA) and indocyanine green angiography (ICGA) provide hemodynamic and lesion-structural information that conventional fundus photography cannot capture. However, due to the single-modality nature, subtle lesion patterns, and significant inter-device variability, existing methods still face limitations in generalization and high-confidence prediction. To address these challenges, we propose CLEAR-Mamba, an enhanced framework built upon MedMamba with optimizations in both architecture and training strategy. Architecturally, we introduce HaC, a hypernetwork-based adaptive conditioning layer that dynamically generates parameters according to input feature distributions, thereby improving cross-domain adaptability. From a training perspective, we develop RaP, a reliability-aware prediction scheme built upon evidential uncertainty learning, which encourages the model to emphasize low-confidence samples and improves overall stability and reliability. We further construct a large-scale ophthalmic angiography dataset covering both FFA and ICGA modalities, comprising multiple retinal disease categories for model training and evaluation. Experimental results demonstrate that CLEAR-Mamba consistently outperforms multiple baseline models, including the original MedMamba, across various metrics-showing particular advantages in multi-disease classification and reliability-aware prediction. This study provides an effective solution that balances generalizability and reliability for modality-specific medical image classification tasks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20601v1</guid></item><item><title>[cs updates on arXiv.org] Dialogical Reasoning Across AI Architectures: A Multi-Model Framework for Testing AI Alignment Strategies</title><link>https://arxiv.org/abs/2601.20604</link><description>arXiv:2601.20604v1 Announce Type: new 
Abstract: This paper introduces a methodological framework for empirically testing AI alignment strategies through structured multi-model dialogue. Drawing on Peace Studies traditions - particularly interest-based negotiation, conflict transformation, and commons governance - we operationalize Viral Collaborative Wisdom (VCW), an approach that reframes alignment from a control problem to a relationship problem developed through dialogical reasoning.
  Our experimental design assigns four distinct roles (Proposer, Responder, Monitor, Translator) to different AI systems across six conditions, testing whether current large language models can engage substantively with complex alignment frameworks. Using Claude, Gemini, and GPT-4o, we conducted 72 dialogue turns totaling 576,822 characters of structured exchange.
  Results demonstrate that AI systems can engage meaningfully with Peace Studies concepts, surface complementary objections from different architectural perspectives, and generate emergent insights not present in initial framings - including the novel synthesis of "VCW as transitional framework." Cross-architecture patterns reveal that different models foreground different concerns: Claude emphasized verification challenges, Gemini focused on bias and scalability, and GPT-4o highlighted implementation barriers.
  The framework provides researchers with replicable methods for stress-testing alignment proposals before implementation, while the findings offer preliminary evidence about AI capacity for the kind of dialogical reasoning VCW proposes. We discuss limitations, including the observation that dialogues engaged more with process elements than with foundational claims about AI nature, and outline directions for future research including human-AI hybrid protocols and extended dialogue studies.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20604v1</guid></item><item><title>[cs updates on arXiv.org] CoBA: Integrated Deep Learning Model for Reliable Low-Altitude UAV Classification in mmWave Radio Networks</title><link>https://arxiv.org/abs/2601.20605</link><description>arXiv:2601.20605v1 Announce Type: new 
Abstract: Uncrewed Aerial Vehicles (UAVs) are increasingly used in civilian and industrial applications, making secure low-altitude operations crucial. In dense mmWave environments, accurately classifying low-altitude UAVs as either inside authorized or restricted airspaces remains challenging, requiring models that handle complex propagation and signal variability. This paper proposes a deep learning model, referred to as CoBA, which stands for integrated Convolutional Neural Network (CNN), Bidirectional Long Short-Term Memory (BiLSTM), and Attention which leverages Fifth Generation (5G) millimeter-wave (mmWave) radio measurements to classify UAV operations in authorized and restricted airspaces at low altitude. The proposed CoBA model integrates convolutional, bidirectional recurrent, and attention layers to capture both spatial and temporal patterns in UAV radio measurements. To validate the model, a dedicated dataset is collected using the 5G mmWave network at TalTech, with controlled low altitude UAV flights in authorized and restricted scenarios. The model is evaluated against conventional ML models and a fingerprinting-based benchmark. Experimental results show that CoBA achieves superior accuracy, significantly outperforming all baseline models and demonstrating its potential for reliable and regulated UAV airspace monitoring.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20605v1</guid></item><item><title>[cs updates on arXiv.org] WFR-MFM: One-Step Inference for Dynamic Unbalanced Optimal Transport</title><link>https://arxiv.org/abs/2601.20606</link><description>arXiv:2601.20606v1 Announce Type: new 
Abstract: Reconstructing dynamical evolution from limited observations is a fundamental challenge in single-cell biology, where dynamic unbalanced optimal transport provides a principled framework for modeling coupled transport and mass variation. However, existing approaches rely on trajectory simulation at inference time, making inference a key bottleneck for scalable applications. In this work, we propose a mean-flow framework for unbalanced flow matching that summarizes both transport and mass-growth dynamics over arbitrary time intervals using mean velocity and mass-growth fields, enabling fast one-step generation without trajectory simulation. To solve dynamic unbalanced optimal transport under the Wasserstein-Fisher-Rao geometry, we further build on this framework to develop Wasserstein-Fisher-Rao Mean Flow Matching (WFR-MFM). Across synthetic and real single-cell RNA sequencing datasets, WFR-MFM achieves orders-of-magnitude faster inference than a range of existing baselines while maintaining high predictive accuracy, and enables efficient perturbation response prediction on large synthetic datasets with thousands of conditions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20606v1</guid></item><item><title>[cs updates on arXiv.org] ACFormer: Mitigating Non-linearity with Auto Convolutional Encoder for Time Series Forecasting</title><link>https://arxiv.org/abs/2601.20611</link><description>arXiv:2601.20611v1 Announce Type: new 
Abstract: Time series forecasting (TSF) faces challenges in modeling complex intra-channel temporal dependencies and inter-channel correlations. Although recent research has highlighted the efficiency of linear architectures in capturing global trends, these models often struggle with non-linear signals. To address this gap, we conducted a systematic receptive field analysis of convolutional neural network (CNN) TSF models. We introduce the "individual receptive field" to uncover granular structural dependencies, revealing that convolutional layers act as feature extractors that mirror channel-wise attention while exhibiting superior robustness to non-linear fluctuations. Based on these insights, we propose ACFormer, an architecture designed to reconcile the efficiency of linear projections with the non-linear feature-extraction power of convolutions. ACFormer captures fine-grained information through a shared compression module, preserves temporal locality via gated attention, and reconstructs variable-specific temporal patterns using an independent patch expansion layer. Extensive experiments on multiple benchmark datasets demonstrate that ACFormer consistently achieves state-of-the-art performance, effectively mitigating the inherent drawbacks of linear models in capturing high-frequency components.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20611v1</guid></item><item><title>[cs updates on arXiv.org] AgentIF-OneDay: A Task-level Instruction-Following Benchmark for General AI Agents in Daily Scenarios</title><link>https://arxiv.org/abs/2601.20613</link><description>arXiv:2601.20613v1 Announce Type: new 
Abstract: The capacity of AI agents to effectively handle tasks of increasing duration and complexity continues to grow, demonstrating exceptional performance in coding, deep research, and complex problem-solving evaluations. However, in daily scenarios, the perception of these advanced AI capabilities among general users remains limited. We argue that current evaluations prioritize increasing task difficulty without sufficiently addressing the diversity of agentic tasks necessary to cover the daily work, life, and learning activities of a broad demographic. To address this, we propose AgentIF-OneDay, aimed at determining whether general users can utilize natural language instructions and AI agents to complete a diverse array of daily tasks. These tasks require not only solving problems through dialogue but also understanding various attachment types and delivering tangible file-based results. The benchmark is structured around three user-centric categories: Open Workflow Execution, which assesses adherence to explicit and complex workflows; Latent Instruction, which requires agents to infer implicit instructions from attachments; and Iterative Refinement, which involves modifying or expanding upon ongoing work. We employ instance-level rubrics and a refined evaluation pipeline that aligns LLM-based verification with human judgment, achieving an 80.1% agreement rate using Gemini-3-Pro. AgentIF-OneDay comprises 104 tasks covering 767 scoring points. We benchmarked four leading general AI agents and found that agent products built based on APIs and ChatGPT agents based on agent RL remain in the first tier simultaneously. Leading LLM APIs and open-source models have internalized agentic capabilities, enabling AI application teams to develop cutting-edge Agent products.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20613v1</guid></item><item><title>[cs updates on arXiv.org] Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation</title><link>https://arxiv.org/abs/2601.20614</link><description>arXiv:2601.20614v1 Announce Type: new 
Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions. Data-wise, augmentation approaches primarily rephrase questions to enhance diversity without systematically increasing intrinsic difficulty. To address these issues, we propose a two-dual MathForge framework to improve mathematical reasoning by targeting harder questions from both perspectives, which comprises a Difficulty-Aware Group Policy Optimization (DGPO) algorithm and a Multi-Aspect Question Reformulation (MQR) strategy. Specifically, DGPO first rectifies the implicit imbalance in GRPO via difficulty-balanced group advantage estimation, and further prioritizes harder questions by difficulty-aware question-level weighting. Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer. Overall, MathForge forms a synergistic loop: MQR expands the data frontier, and DGPO effectively learns from the augmented data. Extensive experiments show that MathForge significantly outperforms existing methods on various mathematical reasoning tasks. The code and augmented data are all available at https://github.com/AMAP-ML/MathForge.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20614v1</guid></item><item><title>[cs updates on arXiv.org] DRAINCODE: Stealthy Energy Consumption Attacks on Retrieval-Augmented Code Generation via Context Poisoning</title><link>https://arxiv.org/abs/2601.20615</link><description>arXiv:2601.20615v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated impressive capabilities in code generation by leveraging retrieval-augmented generation (RAG) methods. However, the computational costs associated with LLM inference, particularly in terms of latency and energy consumption, have received limited attention in the security context. This paper introduces DrainCode, the first adversarial attack targeting the computational efficiency of RAG-based code generation systems. By strategically poisoning retrieval contexts through a mutation-based approach, DrainCode forces LLMs to produce significantly longer outputs, thereby increasing GPU latency and energy consumption. We evaluate the effectiveness of DrainCode across multiple models. Our experiments show that DrainCode achieves up to an 85% increase in latency, a 49% increase in energy consumption, and more than a 3x increase in output length compared to the baseline. Furthermore, we demonstrate the generalizability of the attack across different prompting strategies and its effectiveness compared to different defenses. The results highlight DrainCode as a potential method for increasing the computational overhead of LLMs, making it useful for evaluating LLM security in resource-constrained environments. We provide code and data at https://github.com/DeepSoftwareAnalytics/DrainCode.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20615v1</guid></item><item><title>[cs updates on arXiv.org] Agent Benchmarks Fail Public Sector Requirements</title><link>https://arxiv.org/abs/2601.20617</link><description>arXiv:2601.20617v1 Announce Type: new 
Abstract: Deploying Large Language Model-based agents (LLM agents) in the public sector requires assuring that they meet the stringent legal, procedural, and structural requirements of public-sector institutions. Practitioners and researchers often turn to benchmarks for such assessments. However, it remains unclear what criteria benchmarks must meet to ensure they adequately reflect public-sector requirements, or how many existing benchmarks do so. In this paper, we first define such criteria based on a first-principles survey of public administration literature: benchmarks must be \emph{process-based}, \emph{realistic}, \emph{public-sector-specific} and report \emph{metrics} that reflect the unique requirements of the public sector. We analyse more than 1,300 benchmark papers for these criteria using an expert-validated LLM-assisted pipeline. Our results show that no single benchmark meets all of the criteria. Our findings provide a call to action for both researchers to develop public sector-relevant benchmarks and for public-sector officials to apply these criteria when evaluating their own agentic use cases.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20617v1</guid></item><item><title>[cs updates on arXiv.org] GDCNet: Generative Discrepancy Comparison Network for Multimodal Sarcasm Detection</title><link>https://arxiv.org/abs/2601.20618</link><description>arXiv:2601.20618v1 Announce Type: new 
Abstract: Multimodal sarcasm detection (MSD) aims to identify sarcasm within image-text pairs by modeling semantic incongruities across modalities. Existing methods often exploit cross-modal embedding misalignment to detect inconsistency but struggle when visual and textual content are loosely related or semantically indirect. While recent approaches leverage large language models (LLMs) to generate sarcastic cues, the inherent diversity and subjectivity of these generations often introduce noise. To address these limitations, we propose the Generative Discrepancy Comparison Network (GDCNet). This framework captures cross-modal conflicts by utilizing descriptive, factually grounded image captions generated by Multimodal LLMs (MLLMs) as stable semantic anchors. Specifically, GDCNet computes semantic and sentiment discrepancies between the generated objective description and the original text, alongside measuring visual-textual fidelity. These discrepancy features are then fused with visual and textual representations via a gated module to adaptively balance modality contributions. Extensive experiments on MSD benchmarks demonstrate GDCNet's superior accuracy and robustness, establishing a new state-of-the-art on the MMSD2.0 benchmark.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20618v1</guid></item><item><title>[cs updates on arXiv.org] SketchDynamics: Exploring Free-Form Sketches for Dynamic Intent Expression in Animation Generation</title><link>https://arxiv.org/abs/2601.20622</link><description>arXiv:2601.20622v1 Announce Type: new 
Abstract: Sketching provides an intuitive way to convey dynamic intent in animation authoring (i.e., how elements change over time and space), making it a natural medium for automatic content creation. Yet existing approaches often constrain sketches to fixed command tokens or predefined visual forms, overlooking their freeform nature and the central role of humans in shaping intention. To address this, we introduce an interaction paradigm where users convey dynamic intent to a vision-language model via free-form sketching, instantiated here in a sketch storyboard to motion graphics workflow. We implement an interface and improve it through a three-stage study with 24 participants. The study shows how sketches convey motion with minimal input, how their inherent ambiguity requires users to be involved for clarification, and how sketches can visually guide video refinement. Our findings reveal the potential of sketch and AI interaction to bridge the gap between intention and outcome, and demonstrate its applicability to 3D animation and video generation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20622v1</guid></item><item><title>[cs updates on arXiv.org] When Vision Meets Texts in Listwise Reranking</title><link>https://arxiv.org/abs/2601.20623</link><description>arXiv:2601.20623v1 Announce Type: new 
Abstract: Recent advancements in information retrieval have highlighted the potential of integrating visual and textual information, yet effective reranking for image-text documents remains challenging due to the modality gap and scarcity of aligned datasets. Meanwhile, existing approaches often rely on large models (7B to 32B parameters) with reasoning-based distillation, incurring unnecessary computational overhead while primarily focusing on textual modalities. In this paper, we propose Rank-Nexus, a multimodal image-text document reranker that performs listwise qualitative reranking on retrieved lists incorporating both images and texts. To bridge the modality gap, we introduce a progressive cross-modal training strategy. We first train modalities separately: leveraging abundant text reranking data, we distill knowledge into the text branch. For images, where data is scarce, we construct distilled pairs from multimodal large language model (MLLM) captions on image retrieval benchmarks. Subsequently, we distill a joint image-text reranking dataset. Rank-Nexus achieves outstanding performance on text reranking benchmarks (TREC, BEIR) and the challenging image reranking benchmark (INQUIRE, MMDocIR), using only a lightweight 2B pretrained visual-language model. This efficient design ensures strong generalization across diverse multimodal scenarios without excessive parameters or reasoning overhead.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20623v1</guid></item><item><title>[cs updates on arXiv.org] Immersive Volumetric Video Playback: Near-RT Resource Allocation and O-RAN-based Implementation</title><link>https://arxiv.org/abs/2601.20625</link><description>arXiv:2601.20625v1 Announce Type: new 
Abstract: Immersive volumetric video streaming in extended reality (XR) demands ultra-low motion-to-photon (MTP) latency, which conventional edge-centric architectures struggle to meet due to per-frame computationally intensive rendering tightly coupled with user motion. To address this challenge, we propose an Open Radio Access Network (O-RAN)-integrated playback framework that jointly orchestrates radio, compute, and content resources in near real time (Near-RT) control loop. The system formulates the rendered-pixel ratio as a continuous control variable and jointly optimizes it over the Open Cloud (O-Cloud) compute, gNB transmit power, and bandwidth under a Weber-Fechner quality of experience (QoE) model, explicitly balancing resolution, computation, and latency. A Soft Actor-Critic (SAC) agent with structured action decomposition and QoE-aware reward shaping resolves the resulting high-dimensional control problem. Experiments on a 5G O-RAN testbed and system simulations show that SAC reduces median MTP latency by above $11\%$ and improves both mean QoE and fairness, demonstrating the feasibility of RIC-driven joint radio-compute-content control for scalable, latency-aware immersive streaming.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20625v1</guid></item><item><title>[cs updates on arXiv.org] DIVERSE: Disagreement-Inducing Vector Evolution for Rashomon Set Exploration</title><link>https://arxiv.org/abs/2601.20627</link><description>arXiv:2601.20627v1 Announce Type: new 
Abstract: We propose DIVERSE, a framework for systematically exploring the Rashomon set of deep neural networks, the collection of models that match a reference model's accuracy while differing in their predictive behavior. DIVERSE augments a pretrained model with Feature-wise Linear Modulation (FiLM) layers and uses Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to search a latent modulation space, generating diverse model variants without retraining or gradient access. Across MNIST, PneumoniaMNIST, and CIFAR-10, DIVERSE uncovers multiple high-performing yet functionally distinct models. Our experiments show that DIVERSE offers a competitive and efficient exploration of the Rashomon set, making it feasible to construct diverse sets that maintain robustness and performance while supporting well-balanced model multiplicity. While retraining remains the baseline to generate Rashomon sets, DIVERSE achieves comparable diversity at reduced computational cost.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20627v1</guid></item><item><title>[cs updates on arXiv.org] /dev/SDB: Software Defined Boot -- A novel standard for diskless booting anywhere and everywhere</title><link>https://arxiv.org/abs/2601.20629</link><description>arXiv:2601.20629v1 Announce Type: new 
Abstract: A computer is nothing but a device that processes the instructions supplied to it. However, as computers evolved, the instructions or codes started to be more complicated. As computers started to be used by non-technical people, it became imperative that the users be able to use the machine without having underlying knowledge of the code or the hardware. And operating system became the backbone for translating the inputs from the user to actual operation on the hardware. With the increasing complexity and the choices of operating system, it became clear that different groups of people, especially in an enterprise scenario, required different operating systems. Installing them all on a single machine, for shared computers became a difficult task, giving rise to network-based booting. But network-based booting was confined to only wired connectivity, keeping it restricted to very small geographical areas. The proposed system, /dev/SDB, is aimed at creating a standard where any user, anyone on the globe, can access the operating system authorized to them without having to be on the corporate network. It aims to offer the same over Wi-Fi as well as cellular connectivity, ensuring employees can truly work from anywhere, while following the policies for operating systems and without redundant hardware.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20629v1</guid></item><item><title>[cs updates on arXiv.org] A Foundation Model for Virtual Sensors</title><link>https://arxiv.org/abs/2601.20634</link><description>arXiv:2601.20634v1 Announce Type: new 
Abstract: Virtual sensors use machine learning to predict target signals from available measurements, replacing expensive physical sensors in critical applications. Existing virtual sensor approaches require application-specific models with hand-selected inputs for each sensor, cannot leverage task synergies, and lack consistent benchmarks. At the same time, emerging time series foundation models are computationally expensive and limited to predicting their input signals, making them incompatible with virtual sensors. We introduce the first foundation model for virtual sensors addressing both limitations. Our unified model can simultaneously predict diverse virtual sensors exploiting synergies while maintaining computational efficiency. It learns relevant input signals for each virtual sensor, eliminating expert knowledge requirements while adding explainability. In our large-scale evaluation on a standard benchmark and an application-specific dataset with over 18 billion samples, our architecture achieves 415x reduction in computation time and 951x reduction in memory requirements, while maintaining or even improving predictive quality compared to baselines. Our model scales gracefully to hundreds of virtual sensors with nearly constant parameter count, enabling practical deployment in large-scale sensor networks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20634v1</guid></item><item><title>[cs updates on arXiv.org] An Empirical Investigation of Neural ODEs and Symbolic Regression for Dynamical Systems</title><link>https://arxiv.org/abs/2601.20637</link><description>arXiv:2601.20637v1 Announce Type: new 
Abstract: Accurately modelling the dynamics of complex systems and discovering their governing differential equations are critical tasks for accelerating scientific discovery. Using noisy, synthetic data from two damped oscillatory systems, we explore the extrapolation capabilities of Neural Ordinary Differential Equations (NODEs) and the ability of Symbolic Regression (SR) to recover the underlying equations. Our study yields three key insights. First, we demonstrate that NODEs can extrapolate effectively to new boundary conditions, provided the resulting trajectories share dynamic similarity with the training data. Second, SR successfully recovers the equations from noisy ground-truth data, though its performance is contingent on the correct selection of input variables. Finally, we find that SR recovers two out of the three governing equations, along with a good approximation for the third, when using data generated by a NODE trained on just 10% of the full simulation. While this last finding highlights an area for future work, our results suggest that using NODEs to enrich limited data and enable symbolic regression to infer physical laws represents a promising new approach for scientific discovery.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20637v1</guid></item><item><title>[cs updates on arXiv.org] Supply Chain Insecurity: Exposing Vulnerabilities in iOS Dependency Management Systems</title><link>https://arxiv.org/abs/2601.20638</link><description>arXiv:2601.20638v1 Announce Type: new 
Abstract: Dependency management systems are a critical component in software development, enabling projects to incorporate existing functionality efficiently. However, misconfigurations and malicious actors in these systems pose severe security risks, leading to supply chain attacks. Despite the widespread use of smartphone apps, the security of dependency management systems in the iOS software supply chain has received limited attention. In this paper, we focus on CocoaPods, one of the most widely used dependency management systems for iOS app development, but also examine the security of Carthage and Swift Package Manager (SwiftPM). We demonstrate that iOS apps expose internal package names and versions. Attackers can exploit this leakage to register previously unclaimed dependencies in CocoaPods, enabling remote code execution (RCE) on developer machines and build servers. Additionally, we show that attackers can compromise dependencies by reclaiming abandoned domains and GitHub URLs. Analyzing a dataset of 9,212 apps, we quantify how many apps are susceptible to these vulnerabilities. Further, we inspect the use of vulnerable dependencies within public GitHub repositories. Our findings reveal that popular apps disclose internal dependency information, enabling dependency confusion attacks. Furthermore, we show that hijacking a single CocoaPod library through an abandoned domain could compromise 63 iOS apps, affecting millions of users. Finally, we compare iOS dependency management systems with Cargo, Go modules, Maven, npm, and pip to discuss mitigation strategies for the identified threats.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20638v1</guid></item><item><title>[cs updates on arXiv.org] Investigating the Development of Task-Oriented Communication in Vision-Language Models</title><link>https://arxiv.org/abs/2601.20641</link><description>arXiv:2601.20641v1 Announce Type: new 
Abstract: We investigate whether \emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks. Our focus is on two core properties such task-oriented protocols may exhibit: Efficiency -- conveying task-relevant information more concisely than natural language, and Covertness -- becoming difficult for external observers to interpret, raising concerns about transparency and control. To investigate these aspects, we use a referential-game framework in which vision-language model (VLM) agents communicate, providing a controlled, measurable setting for evaluating language variants. Experiments show that VLMs can develop effective, task-adapted communication patterns. At the same time, they can develop covert protocols that are difficult for humans and external agents to interpret. We also observe spontaneous coordination between similar models without explicitly shared protocols. These findings highlight both the potential and the risks of task-oriented communication, and position referential games as a valuable testbed for future work in this area.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20641v1</guid></item><item><title>[cs updates on arXiv.org] Detecting and Mitigating Memorization in Diffusion Models through Anisotropy of the Log-Probability</title><link>https://arxiv.org/abs/2601.20642</link><description>arXiv:2601.20642v1 Announce Type: new 
Abstract: Diffusion-based image generative models produce high-fidelity images through iterative denoising but remain vulnerable to memorization, where they unintentionally reproduce exact copies or parts of training images. Recent memorization detection methods are primarily based on the norm of score difference as indicators of memorization. We prove that such norm-based metrics are mainly effective under the assumption of isotropic log-probability distributions, which generally holds at high or medium noise levels. In contrast, analyzing the anisotropic regime reveals that memorized samples exhibit strong angular alignment between the guidance vector and unconditional scores in the low-noise setting. Through these insights, we develop a memorization detection metric by integrating isotropic norm and anisotropic alignment. Our detection metric can be computed directly on pure noise inputs via two conditional and unconditional forward passes, eliminating the need for costly denoising steps. Detection experiments on Stable Diffusion v1.4 and v2 show that our metric outperforms existing denoising-free detection methods while being at least approximately 5x faster than the previous best approach. Finally, we demonstrate the effectiveness of our approach by utilizing a mitigation strategy that adapts memorized prompts based on our developed metric.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20642v1</guid></item><item><title>[cs updates on arXiv.org] TGSBM: Transformer-Guided Stochastic Block Model for Link Prediction</title><link>https://arxiv.org/abs/2601.20646</link><description>arXiv:2601.20646v1 Announce Type: new 
Abstract: Link prediction is a cornerstone of the Web ecosystem, powering applications from recommendation and search to knowledge graph completion and collaboration forecasting. However, large-scale networks present unique challenges: they contain hundreds of thousands of nodes and edges with heterogeneous and overlapping community structures that evolve over time. Existing approaches face notable limitations: traditional graph neural networks struggle to capture global structural dependencies, while recent graph transformers achieve strong performance but incur quadratic complexity and lack interpretable latent structure. We propose \textbf{TGSBM} (Transformer-Guided Stochastic Block Model), a framework that integrates the principled generative structure of Overlapping Stochastic Block Models with the representational power of sparse Graph Transformers. TGSBM comprises three main components: (i) \emph{expander-augmented sparse attention} that enables near-linear complexity and efficient global mixing, (ii) a \emph{neural variational encoder} that infers structured posteriors over community memberships and strengths, and (iii) a \emph{neural edge decoder} that reconstructs links via OSBM's generative process, preserving interpretability. Experiments across diverse benchmarks demonstrate competitive performance (mean rank 1.6 under HeaRT protocol), superior scalability (up to $6\times$ faster training), and interpretable community structures. These results position TGSBM as a practical approach that strikes a balance between accuracy, efficiency, and transparency for large-scale link prediction.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20646v1</guid></item><item><title>[cs updates on arXiv.org] P2S: Probabilistic Process Supervision for General-Domain Reasoning Question Answering</title><link>https://arxiv.org/abs/2601.20649</link><description>arXiv:2601.20649v1 Announce Type: new 
Abstract: While reinforcement learning with verifiable rewards (RLVR) has advanced LLM reasoning in structured domains like mathematics and programming, its application to general-domain reasoning tasks remains challenging due to the absence of verifiable reward signals. To this end, methods like Reinforcement Learning with Reference Probability Reward (RLPR) have emerged, leveraging the probability of generating the final answer as a reward signal. However, these outcome-focused approaches neglect crucial step-by-step supervision of the reasoning process itself. To address this gap, we introduce Probabilistic Process Supervision (P2S), a novel self-supervision framework that provides fine-grained process rewards without requiring a separate reward model or human-annotated reasoning steps. During reinforcement learning, P2S synthesizes and filters a high-quality reference reasoning chain (gold-CoT). The core of our method is to calculate a Path Faithfulness Reward (PFR) for each reasoning step, which is derived from the conditional probability of generating the gold-CoT's suffix, given the model's current reasoning prefix. Crucially, this PFR can be flexibly integrated with any outcome-based reward, directly tackling the reward sparsity problem by providing dense guidance. Extensive experiments on reading comprehension and medical Question Answering benchmarks show that P2S significantly outperforms strong baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20649v1</guid></item><item><title>[cs updates on arXiv.org] The Multiserver-Job Stochastic Recurrence Equation for Cloud Computing Performance Evaluation</title><link>https://arxiv.org/abs/2601.20653</link><description>arXiv:2601.20653v1 Announce Type: new 
Abstract: We study the Multiserver-Job Queuing Model (MJQM) with general independent arrivals and service times under FCFS scheduling, using stochastic recurrence equations (SREs) and ergodic theory. We prove the monotonicity and separability properties of the MJQM SRE, enabling the application of the monotone-separable extension of Loynes' theorem and the formal definition of the MJQM stability condition. Based on these results, we introduce and implement two algorithms: one for drawing sub-perfect samples (SPS) of the system's workload and the second one to estimate the system's stability condition given the statistics of the jobs' input stream. The SPS algorithm allows for a massive GPU parallelization, greatly improving the efficiency of performance metrics evaluation. We also show that this approach extends to more complex systems, including MJQMs with typed resources.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20653v1</guid></item><item><title>[cs updates on arXiv.org] OnePiece: A Large-Scale Distributed Inference System with RDMA for Complex AI-Generated Content (AIGC) Workflows</title><link>https://arxiv.org/abs/2601.20655</link><description>arXiv:2601.20655v1 Announce Type: new 
Abstract: The rapid growth of AI-generated content (AIGC) has enabled high-quality creative production across diverse domains, yet existing systems face critical inefficiencies in throughput, resource utilization, and scalability under concurrent workloads. This paper introduces OnePiece, a large-scale distributed inference system with RDMA optimized for multi-stage AIGC workflows. By decomposing pipelines into fine-grained microservices and leveraging one-sided RDMA communication, OnePiece significantly reduces inter-node latency and CPU overhead while improving GPU utilization. The system incorporates a novel double-ring buffer design to resolve deadlocks in RDMA-aware memory access without CPU involvement. Additionally, a dynamic Node Manager allocates resources elastically across workflow stages in response to real-time load. Experimental results demonstrate that OnePiece reduces GPU resource consumption by 16x in Wan2.1 image-to-video generation compared to monolithic inference pipelines, offering a scalable, fault-tolerant, and efficient solution for production AIGC environments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20655v1</guid></item><item><title>[cs updates on arXiv.org] FD-MAD: Frequency-Domain Residual Analysis for Face Morphing Attack Detection</title><link>https://arxiv.org/abs/2601.20656</link><description>arXiv:2601.20656v1 Announce Type: new 
Abstract: Face morphing attacks present a significant threat to face recognition systems used in electronic identity enrolment and border control, particularly in single-image morphing attack detection (S-MAD) scenarios where no trusted reference is available. In spite of the vast amount of research on this problem, morph detection systems struggle in cross-dataset scenarios. To address this problem, we introduce a region-aware frequency-based morph detection strategy that drastically improves over strong baseline methods in challenging cross-dataset and cross-morph settings using a lightweight approach. Having observed the separability of bona fide and morph samples in the frequency domain of different facial parts, our approach 1) introduces the concept of residual frequency domain, where the frequency of the signal is decoupled from the natural spectral decay to easily discriminate between morph and bona fide data; 2) additionally, we reason in a global and local manner by combining the evidence from different facial regions in a Markov Random Field, which infers a globally consistent decision. The proposed method, trained exclusively on the synthetic morphing attack detection development dataset (SMDD), is evaluated in challenging cross-dataset and cross-morph settings on FRLL-Morph and MAD22 sets. Our approach achieves an average equal error rate (EER) of 1.85\% on FRLL-Morph and ranks second on MAD22 with an average EER of 6.12\%, while also obtaining a good bona fide presentation classification error rate (BPCER) at a low attack presentation classification error rate (APCER) using only spectral features. These findings indicate that Fourier-domain residual modeling with structured regional fusion offers a competitive alternative to deep S-MAD architectures.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20656v1</guid></item><item><title>[cs updates on arXiv.org] A Dialectic Pipeline for Improving LLM Robustness</title><link>https://arxiv.org/abs/2601.20659</link><description>arXiv:2601.20659v1 Announce Type: new 
Abstract: Assessing ways in which Language Models can reduce their hallucinations and improve the outputs' quality is crucial to ensure their large-scale use.
  However, methods such as fine-tuning on domain-specific data or the training of a separate \textit{ad hoc} verifier require demanding computational resources (not feasible for many user applications) and constrain the models to specific fields of knowledge.
  In this thesis, we propose a dialectic pipeline that preserves LLMs' generalization abilities while improving the quality of its answer via self-dialogue, enabling it to reflect upon and correct tentative wrong answers.
  We experimented with different pipeline settings, testing our proposed method on different datasets and on different families of models. All the pipeline stages are enriched with the relevant context (in an oracle-RAG setting) and a study on the impact of its summarization or its filtering is conducted.
  We find that our proposed dialectic pipeline is able to outperform by significative margins the standard model answers and that it consistently achieves higher performances than Chain-of-Thought only prompting.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20659v1</guid></item><item><title>[cs updates on arXiv.org] ProSkill: Segment-Level Skill Assessment in Procedural Videos</title><link>https://arxiv.org/abs/2601.20661</link><description>arXiv:2601.20661v1 Announce Type: new 
Abstract: Skill assessment in procedural videos is crucial for the objective evaluation of human performance in settings such as manufacturing and procedural daily tasks. Current research on skill assessment has predominantly focused on sports and lacks large-scale datasets for complex procedural activities. Existing studies typically involve only a limited number of actions, focus on either pairwise assessments (e.g., A is better than B) or on binary labels (e.g., good execution vs needs improvement). In response to these shortcomings, we introduce ProSkill, the first benchmark dataset for action-level skill assessment in procedural tasks. ProSkill provides absolute skill assessment annotations, along with pairwise ones. This is enabled by a novel and scalable annotation protocol that allows for the creation of an absolute skill assessment ranking starting from pairwise assessments. This protocol leverages a Swiss Tournament scheme for efficient pairwise comparisons, which are then aggregated into consistent, continuous global scores using an ELO-based rating system. We use our dataset to benchmark the main state-of-the-art skill assessment algorithms, including both ranking-based and pairwise paradigms. The suboptimal results achieved by the current state-of-the-art highlight the challenges and thus the value of ProSkill in the context of skill assessment for procedural videos. All data and code are available at https://fpv-iplab.github.io/ProSkill/</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20661v1</guid></item><item><title>[cs updates on arXiv.org] Lila: Decentralized Build Reproducibility Monitoring for the Functional Package Management Model</title><link>https://arxiv.org/abs/2601.20662</link><description>arXiv:2601.20662v1 Announce Type: new 
Abstract: Ensuring the integrity of software build artifacts is an increasingly important concern for modern software engineering, driven by increasingly sophisticated attacks on build systems, distribution channels, and development infrastructures. Reproducible builds $\unicode{x2013}$ where binaries built independently from the same source code can be verified to be bit-for-bit identical to the distributed artifacts $\unicode{x2013}$ provide a principled foundation for transparency and trust in software distribution.
  Despite their potential, the large-scale adoption of reproducible builds faces two significant challenges: achieving high reproducibility rates across vast software collections and establishing reproducibility monitoring infrastructure that can operate at very large scale. While recent studies have shown that high reproducibility rates are achievable at scale $\unicode{x2013}$ demonstrated by the Nix ecosystem achieving over 90% reproducibility on more than 80,000 packages $\unicode{x2013}$ the problem of effective reproducibility monitoring remains largely unsolved.
  In this work, we address the reproducibility monitoring challenge by introducing Lila, a decentralized system for reproducibility assessment tailored to the functional package management model. Lila enables distributed reporting of build results and aggregation into a reproducibility database, benefiting both practitioners and future empirical build reproducibility studies.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20662v1</guid></item><item><title>[cs updates on arXiv.org] A Multi-Camera Optical Tag Neuronavigation and AR Augmentation Framework for Non-Invasive Brain Stimulation</title><link>https://arxiv.org/abs/2601.20663</link><description>arXiv:2601.20663v1 Announce Type: new 
Abstract: Accurate neuronavigation is essential for generating the intended effect with transcranial magnetic stimulation (TMS). Precise coil placement also directly influences stimulation efficacy. Traditional neuronavigation systems often rely on costly and still hard to use and error-prone tracking systems. To solve these limitations, we present a computer-vision-based neuronavigation system for real-time tracking of patient and TMS instrumentation. The system can feed the necessary data for a digital twin to track TMS stimulation targets. We integrate a self-coordinating optical tracking system with multiple consumer-grade cameras and visible tags with a dynamic 3D brain model in Unity. This model updates in real time to represent the current stimulation coil position and the estimated stimulation point to intuitively visualize neural targets for clinicians. We incorporate an augmented reality (AR) module to bridge the gap between the visualization of the digital twin and the real world and project the brain model in real-time onto the head of a patient. AR headsets or mobile AR devices allow clinicians to interactively view and adjust the placement of the stimulation transducer intuitively instead of guidance through abstract numbers and 6D cross hairs on an external screen. The proposed technique provides improved spatial precision as well as accuracy. A case study with ten participants with a medical background also demonstrates that the system has high usability.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20663v1</guid></item><item><title>[cs updates on arXiv.org] ALER: An Active Learning Hybrid System for Efficient Entity Resolution</title><link>https://arxiv.org/abs/2601.20664</link><description>arXiv:2601.20664v1 Announce Type: new 
Abstract: Entity Resolution (ER) is a critical task for data integration, yet state-of-the-art supervised deep learning models remain impractical for many real-world applications due to their need for massive, expensive-to-obtain labeled datasets. While Active Learning (AL) offers a potential solution to this "label scarcity" problem, existing approaches introduce severe scalability bottlenecks. Specifically, they achieve high accuracy but incur prohibitive computational costs by re-training complex models from scratch or solving NP-hard selection problems in every iteration. In this paper, we propose ALER, a novel, semi-supervised pipeline designed to bridge the gap between semantic accuracy and computational scalability. ALER eliminates the training bottleneck by using a frozen bi-encoder architecture to generate static embeddings once and then iteratively training a lightweight classifier on top. To address the memory bottleneck associated with large-scale candidate pools, we first select a representative sample of the data and then use K-Means to partition this sample into semantically coherent chunks, enabling an efficient AL loop. We further propose a hybrid query strategy that combines "confused" and "confident" pairs to efficiently refine the decision boundary while correcting high-confidence errors.Extensive evaluation demonstrates ALER's superior efficiency, particularly on the large-scale DBLP dataset: it accelerates the training loop by 1.3x while drastically reducing resolution latency by a factor of 3.8 compared to the fastest baseline.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20664v1</guid></item><item><title>[cs updates on arXiv.org] Learning Contextual Runtime Monitors for Safe AI-Based Autonomy</title><link>https://arxiv.org/abs/2601.20666</link><description>arXiv:2601.20666v1 Announce Type: new 
Abstract: We introduce a novel framework for learning context-aware runtime monitors for AI-based control ensembles. Machine-learning (ML) controllers are increasingly deployed in (autonomous) cyber-physical systems because of their ability to solve complex decision-making tasks. However, their accuracy can degrade sharply in unfamiliar environments, creating significant safety concerns. Traditional ensemble methods aim to improve robustness by averaging or voting across multiple controllers, yet this often dilutes the specialized strengths that individual controllers exhibit in different operating contexts. We argue that, rather than blending controller outputs, a monitoring framework should identify and exploit these contextual strengths. In this paper, we reformulate the design of safe AI-based control ensembles as a contextual monitoring problem. A monitor continuously observes the system's context and selects the controller best suited to the current conditions. To achieve this, we cast monitor learning as a contextual learning task and draw on techniques from contextual multi-armed bandits. Our approach comes with two key benefits: (1) theoretical safety guarantees during controller selection, and (2) improved utilization of controller diversity. We validate our framework in two simulated autonomous driving scenarios, demonstrating significant improvements in both safety and performance compared to non-contextual baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20666v1</guid></item><item><title>[cs updates on arXiv.org] GPO: Growing Policy Optimization for Legged Robot Locomotion and Whole-Body Control</title><link>https://arxiv.org/abs/2601.20668</link><description>arXiv:2601.20668v1 Announce Type: new 
Abstract: Training reinforcement learning (RL) policies for legged robots remains challenging due to high-dimensional continuous actions, hardware constraints, and limited exploration. Existing methods for locomotion and whole-body control work well for position-based control with environment-specific heuristics (e.g., reward shaping, curriculum design, and manual initialization), but are less effective for torque-based control, where sufficiently exploring the action space and obtaining informative gradient signals for training is significantly more difficult. We introduce Growing Policy Optimization (GPO), a training framework that applies a time-varying action transformation to restrict the effective action space in the early stage, thereby encouraging more effective data collection and policy learning, and then progressively expands it to enhance exploration and achieve higher expected return. We prove that this transformation preserves the PPO update rule and introduces only bounded, vanishing gradient distortion, thereby ensuring stable training. We evaluate GPO on both quadruped and hexapod robots, including zero-shot deployment of simulation-trained policies on hardware. Policies trained with GPO consistently achieve better performance. These results suggest that GPO provides a general, environment-agnostic optimization framework for learning legged locomotion.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20668v1</guid></item><item><title>[cs updates on arXiv.org] Overview of the TREC 2025 Tip-of-the-Tongue track</title><link>https://arxiv.org/abs/2601.20671</link><description>arXiv:2601.20671v1 Announce Type: new 
Abstract: Tip-of-the-tongue (ToT) known-item retrieval involves re-finding an item for which the searcher does not reliably recall an identifier. ToT information requests (or queries) are verbose and tend to include several complex phenomena, making them especially difficult for existing information retrieval systems. The TREC 2025 ToT track focused on a single ad-hoc retrieval task. This year, we extended the track to general domain and incorporated different sets of test queries from diverse sources, namely from the MS-ToT dataset, manual topic development, and LLM-based synthetic query generation. This year, 9 groups (including the track coordinators) submitted 32 runs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20671v1</guid></item><item><title>[cs updates on arXiv.org] Harnessing Large Language Models for Precision Querying and Retrieval-Augmented Knowledge Extraction in Clinical Data Science</title><link>https://arxiv.org/abs/2601.20674</link><description>arXiv:2601.20674v1 Announce Type: new 
Abstract: This study applies Large Language Models (LLMs) to two foundational Electronic Health Record (EHR) data science tasks: structured data querying (using programmatic languages, Python/Pandas) and information extraction from unstructured clinical text via a Retrieval Augmented Generation (RAG) pipeline. We test the ability of LLMs to interact accurately with large structured datasets for analytics and the reliability of LLMs in extracting semantically correct information from free text health records when supported by RAG. To this end, we presented a flexible evaluation framework that automatically generates synthetic question and answer pairs tailored to the characteristics of each dataset or task. Experiments were conducted on a curated subset of MIMIC III, (four structured tables and one clinical note type), using a mix of locally hosted and API-based LLMs. Evaluation combined exact-match metrics, semantic similarity, and human judgment. Our findings demonstrate the potential of LLMs to support precise querying and accurate information extraction in clinical workflows.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20674v1</guid></item><item><title>[cs updates on arXiv.org] bi-modal textual prompt learning for vision-language models in remote sensing</title><link>https://arxiv.org/abs/2601.20675</link><description>arXiv:2601.20675v1 Announce Type: new 
Abstract: Prompt learning (PL) has emerged as an effective strategy to adapt vision-language models (VLMs), such as CLIP, for downstream tasks under limited supervision. While PL has demonstrated strong generalization on natural image datasets, its transferability to remote sensing (RS) imagery remains underexplored. RS data present unique challenges, including multi-label scenes, high intra-class variability, and diverse spatial resolutions, that hinder the direct applicability of existing PL methods. In particular, current prompt-based approaches often struggle to identify dominant semantic cues and fail to generalize to novel classes in RS scenarios. To address these challenges, we propose BiMoRS, a lightweight bi-modal prompt learning framework tailored for RS tasks. BiMoRS employs a frozen image captioning model (e.g., BLIP-2) to extract textual semantic summaries from RS images. These captions are tokenized using a BERT tokenizer and fused with high-level visual features from the CLIP encoder. A lightweight cross-attention module then conditions a learnable query prompt on the fused textual-visual representation, yielding contextualized prompts without altering the CLIP backbone. We evaluate BiMoRS on four RS datasets across three domain generalization (DG) tasks and observe consistent performance gains, outperforming strong baselines by up to 2% on average. Codes are available at https://github.com/ipankhi/BiMoRS.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20675v1</guid></item><item><title>[cs updates on arXiv.org] Efficient Multimodal Planning Agent for Visual Question-Answering</title><link>https://arxiv.org/abs/2601.20676</link><description>arXiv:2601.20676v1 Announce Type: new 
Abstract: Visual Question-Answering (VQA) is a challenging multimodal task that requires integrating visual and textual information to generate accurate responses. While multimodal Retrieval-Augmented Generation (mRAG) has shown promise in enhancing VQA systems by providing more evidence on both image and text sides, the default procedure that addresses VQA queries, especially the knowledge-intensive ones, often relies on multi-stage pipelines of mRAG with inherent dependencies. To mitigate the inefficiency limitations while maintaining VQA task performance, this paper proposes a method that trains a multimodal planning agent, dynamically decomposing the mRAG pipeline to solve the VQA task. Our method optimizes the trade-off between efficiency and effectiveness by training the agent to intelligently determine the necessity of each mRAG step. In our experiments, the agent can help reduce redundant computations, cutting search time by over 60\% compared to existing methods and decreasing costly tool calls. Meanwhile, experiments demonstrate that our method outperforms all baselines, including a Deep Research agent and a carefully designed prompt-based method, on average over six various datasets. Code will be released.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20676v1</guid></item><item><title>[cs updates on arXiv.org] Unconditional full linear convergence and quasi-optimal complexity of smoothed adaptive finite element methods</title><link>https://arxiv.org/abs/2601.20677</link><description>arXiv:2601.20677v1 Announce Type: new 
Abstract: We present the first rigorous convergence analysis of the smoothed adaptive finite element method (S-AFEM) proposed in [Mulita, Giani, Heltai: SIAM J. Sci. Comput. 43, 2021]. S-AFEM modifies the classical adaptive finite element method (AFEM) by performing accurate discrete solves only on periodically determined mesh levels, while the intermediate levels employ a fixed number of cheap smoothing iterations. Numerical experiments in that work showed that this strategy generates adapted meshes comparable to those of AFEM at substantially lower computational cost. In this paper, we prove unconditional full R-linear convergence of a suitable quasi-error quantity and, for sufficiently small adaptivity parameters, optimal convergence rates with respect to the overall computational cost. The analysis requires only a mild uniform stability assumption on the employed smoother, satisfied by standard methods such as Richardson, Gauss-Seidel, conjugate gradient, and multigrid schemes. Our results apply to general second-order linear elliptic PDEs and show that S-AFEM retains all desired abstract convergence guarantees of AFEM while reducing the cumulative computational time. Numerical experiments validate the theory, analyze runtime performance, and underline the potential of S-AFEM for speed-up in AFEM computations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20677v1</guid></item><item><title>[cs updates on arXiv.org] Helper-Assisted Coding for Gaussian Wiretap Channels: Deep Learning Meets PhySec</title><link>https://arxiv.org/abs/2601.20678</link><description>arXiv:2601.20678v1 Announce Type: new 
Abstract: Consider the Gaussian wiretap channel, where a transmitter wishes to send a confidential message to a legitimate receiver in the presence of an eavesdropper. It is well known that if the eavesdropper experiences less channel noise than the legitimate receiver, then it is impossible for the transmitter to achieve positive secrecy rates. A known solution to this issue consists in involving a second transmitter, referred to as a helper, to help the first transmitter to achieve security. While such a solution has been studied for the asymptotic blocklength regime and via non-constructive coding schemes, in this paper, for the first time, we design explicit and short blocklength codes using deep learning and cryptographic tools to demonstrate the benefit and practicality of cooperation between two transmitters over the wiretap channel. Specifically, our proposed codes show strict improvement in terms of information leakage compared to existing codes that do not consider a helper. Our code design approach relies on a reliability layer, implemented with an autoencoder architecture based on the successive interference cancellation method, and a security layer implemented with universal hash functions. We also propose an alternative autoencoder architecture that significantly reduces training time by allowing the decoders to independently estimate messages without successively canceling interference by the receiver during training. Additionally, we show that our code design is also applicable to the multiple access wiretap channel with helpers, where two transmitters send confidential messages to the legitimate receiver.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20678v1</guid></item><item><title>[cs updates on arXiv.org] ShieldedCode: Learning Robust Representations for Virtual Machine Protected Code</title><link>https://arxiv.org/abs/2601.20679</link><description>arXiv:2601.20679v1 Announce Type: new 
Abstract: Large language models (LLMs) have achieved remarkable progress in code generation, yet their potential for software protection remains largely untapped. Reverse engineering continues to threaten software security, while traditional virtual machine protection (VMP) relies on rigid, rule-based transformations that are costly to design and vulnerable to automated analysis. In this work, we present the first protection-aware framework that learns robust representations of VMP-protected code. Our approach builds large-scale paired datasets of source code and normalized VM implementations, and introduces hierarchical dependency modeling at intra-, preceding-, and inter-instruction levels. We jointly optimize language modeling with functionality-aware and protection-aware contrastive objectives to capture both semantic equivalence and protection strength. To further assess resilience, we propose a protection effectiveness optimization task that quantifies and ranks different VM variants derived from the same source. Coupled with a two-stage continual pre-training and fine-tuning pipeline, our method enables models to generate, compare, and reason over protected code. Extensive experiments show that our framework significantly improves robustness across diverse protection levels, opening a new research direction for learning-based software defense. In this work, we present ShieldedCode, the first protection-aware framework that learns robust representations of VMP-protected code. Our method achieves 26.95% Pass@1 on L0 VM code generation compared to 22.58% for GPT-4o., and improves binary similarity detection Recall@1 by 10% over state of art methods like jTrans.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20679v1</guid></item><item><title>[cs updates on arXiv.org] Online Density-Based Clustering for Real-Time Narrative Evolution Monitorin</title><link>https://arxiv.org/abs/2601.20680</link><description>arXiv:2601.20680v1 Announce Type: new 
Abstract: Automated narrative intelligence systems for social media monitoring face significant scalability challenges when processing continuous data streams using traditional batch clustering algorithms. We investigate the replacement of HDBSCAN (offline clustering) with online (streaming/incremental) clustering methods in a production narrative report generation pipeline. The proposed system employs a three-stage architecture (data collection, modeling, dashboard generation) that processes thousands of multilingual social media documents daily. While HDBSCAN excels at discovering hierarchical density-based clusters and handling noise, its batch-only nature necessitates complete retraining for each time window, resulting in memory constraints, computational inefficiency, and inability to adapt to evolving narratives in real-time. This work evaluates a bunch of online clustering algorithms across dimensions of cluster quality preservation, computational efficiency, memory footprint, and integration compatibility with existing workflows. We propose evaluation criteria that balance traditional clustering metrics (Silhouette Coefficient, Davies-Bouldin Index) with narrative metrics (narrative distinctness, contingency and variance). Our methodology includes sliding-window simulations on historical datasets from Ukraine information space, enabling comparative analysis of algorithmic trade-offs in realistic operational contexts. This research addresses a critical gap between batch-oriented topic modeling frameworks and the streaming nature of social media monitoring, with implications for computational social science, crisis informatics, and narrative surveillance systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20680v1</guid></item><item><title>[cs updates on arXiv.org] Tendon-based modelling, estimation and control for a simulated high-DoF anthropomorphic hand model</title><link>https://arxiv.org/abs/2601.20682</link><description>arXiv:2601.20682v1 Announce Type: new 
Abstract: Tendon-driven anthropomorphic robotic hands often lack direct joint angle sensing, as the integration of joint encoders can compromise mechanical compactness and dexterity. This paper presents a computational method for estimating joint positions from measured tendon displacements and tensions. An efficient kinematic modeling framework for anthropomorphic hands is first introduced based on the Denavit-Hartenberg convention. Using a simplified tendon model, a system of nonlinear equations relating tendon states to joint positions is derived and solved via a nonlinear optimization approach. The estimated joint angles are then employed for closed-loop control through a Jacobian-based proportional-integral (PI) controller augmented with a feedforward term, enabling gesture tracking without direct joint sensing. The effectiveness and limitations of the proposed estimation and control framework are demonstrated in the MuJoCo simulation environment using the Anatomically Correct Biomechatronic Hand, featuring five degrees of freedom for each long finger and six degrees of freedom for the thumb.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20682v1</guid></item><item><title>[cs updates on arXiv.org] Polite But Boring? Trade-offs Between Engagement and Psychological Reactance to Chatbot Feedback Styles</title><link>https://arxiv.org/abs/2601.20683</link><description>arXiv:2601.20683v1 Announce Type: new 
Abstract: As conversational agents become increasingly common in behaviour change interventions, understanding optimal feedback delivery mechanisms becomes increasingly important. However, choosing a style that both lessens psychological reactance (perceived threats to freedom) while simultaneously eliciting feelings of surprise and engagement represents a complex design problem. We explored how three different feedback styles: 'Direct', 'Politeness', and 'Verbal Leakage' (slips or disfluencies to reveal a desired behaviour) affect user perceptions and behavioural intentions. Matching expectations from literature, the 'Direct' chatbot led to lower behavioural intentions and higher reactance, while the 'Politeness' chatbot evoked higher behavioural intentions and lower reactance. However, 'Politeness' was also seen as unsurprising and unengaging by participants. In contrast, 'Verbal Leakage' evoked reactance, yet also elicited higher feelings of surprise, engagement, and humour. These findings highlight that effective feedback requires navigating trade-offs between user reactance and engagement, with novel approaches such as 'Verbal Leakage' offering promising alternative design opportunities.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20683v1</guid></item><item><title>[cs updates on arXiv.org] MuRAL-CPD: Active Learning for Multiresolution Change Point Detection</title><link>https://arxiv.org/abs/2601.20686</link><description>arXiv:2601.20686v1 Announce Type: new 
Abstract: Change Point Detection (CPD) is a critical task in time series analysis, aiming to identify moments when the underlying data-generating process shifts. Traditional CPD methods often rely on unsupervised techniques, which lack adaptability to task-specific definitions of change and cannot benefit from user knowledge. To address these limitations, we propose MuRAL-CPD, a novel semi-supervised method that integrates active learning into a multiresolution CPD algorithm. MuRAL-CPD leverages a wavelet-based multiresolution decomposition to detect changes across multiple temporal scales and incorporates user feedback to iteratively optimize key hyperparameters. This interaction enables the model to align its notion of change with that of the user, improving both accuracy and interpretability. Our experimental results on several real-world datasets show the effectiveness of MuRAL-CPD against state-of-the-art methods, particularly in scenarios where minimal supervision is available.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20686v1</guid></item><item><title>[cs updates on arXiv.org] Positive-Unlabeled Reinforcement Learning Distillation for On-Premise Small Models</title><link>https://arxiv.org/abs/2601.20687</link><description>arXiv:2601.20687v1 Announce Type: new 
Abstract: Due to constraints on privacy, cost, and latency, on-premise deployment of small models is increasingly common. However, most practical pipelines stop at supervised fine-tuning (SFT) and fail to reach the reinforcement learning (RL) alignment stage. The main reason is that RL alignment typically requires either expensive human preference annotation or heavy reliance on high-quality reward models with large-scale API usage and ongoing engineering maintenance, both of which are ill-suited to on-premise settings. To bridge this gap, we propose a positive-unlabeled (PU) RL distillation method for on-premise small-model deployment. Without human-labeled preferences or a reward model, our method distills the teacher's preference-optimization capability from black-box generations into a locally trainable student. For each prompt, we query the teacher once to obtain an anchor response, locally sample multiple student candidates, and perform anchor-conditioned self-ranking to induce pairwise or listwise preferences, enabling a fully local training loop via direct preference optimization or group relative policy optimization. Theoretical analysis justifies that the induced preference signal by our method is order-consistent and concentrates on near-optimal candidates, supporting its stability for preference optimization. Experiments demonstrate that our method achieves consistently strong performance under a low-cost setting.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20687v1</guid></item><item><title>[cs updates on arXiv.org] Decoupling Perception and Calibration: Label-Efficient Image Quality Assessment Framework</title><link>https://arxiv.org/abs/2601.20689</link><description>arXiv:2601.20689v1 Announce Type: new 
Abstract: Recent multimodal large language models (MLLMs) have demonstrated strong capabilities in image quality assessment (IQA) tasks. However, adapting such large-scale models is computationally expensive and still relies on substantial Mean Opinion Score (MOS) annotations. We argue that for MLLM-based IQA, the core bottleneck lies not in the quality perception capacity of MLLMs, but in MOS scale calibration. Therefore, we propose LEAF, a Label-Efficient Image Quality Assessment Framework that distills perceptual quality priors from an MLLM teacher into a lightweight student regressor, enabling MOS calibration with minimal human supervision. Specifically, the teacher conducts dense supervision through point-wise judgments and pair-wise preferences, with an estimate of decision reliability. Guided by these signals, the student learns the teacher's quality perception patterns through joint distillation and is calibrated on a small MOS subset to align with human annotations. Experiments on both user-generated and AI-generated IQA benchmarks demonstrate that our method significantly reduces the need for human annotations while maintaining strong MOS-aligned correlations, making lightweight IQA practical under limited annotation budgets.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20689v1</guid></item><item><title>[cs updates on arXiv.org] Optimal Transport Group Counterfactual Explanations</title><link>https://arxiv.org/abs/2601.20692</link><description>arXiv:2601.20692v1 Announce Type: new 
Abstract: Group counterfactual explanations find a set of counterfactual instances to explain a group of input instances contrastively. However, existing methods either (i) optimize counterfactuals only for a fixed group and do not generalize to new group members, (ii) strictly rely on strong model assumptions (e.g., linearity) for tractability or/and (iii) poorly control the counterfactual group geometry distortion. We instead learn an explicit optimal transport map that sends any group instance to its counterfactual without re-optimization, minimizing the group's total transport cost. This enables generalization with fewer parameters, making it easier to interpret the common actionable recourse. For linear classifiers, we prove that functions representing group counterfactuals are derived via mathematical optimization, identifying the underlying convex optimization type (QP, QCQP, ...). Experiments show that they accurately generalize, preserve group geometry and incur only negligible additional transport cost compared to baseline methods. If model linearity cannot be exploited, our approach also significantly outperforms the baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20692v1</guid></item><item><title>[cs updates on arXiv.org] Is Pure Exploitation Sufficient in Exogenous MDPs with Linear Function Approximation?</title><link>https://arxiv.org/abs/2601.20694</link><description>arXiv:2601.20694v1 Announce Type: new 
Abstract: Exogenous MDPs (Exo-MDPs) capture sequential decision-making where uncertainty comes solely from exogenous inputs that evolve independently of the learner's actions. This structure is especially common in operations research applications such as inventory control, energy storage, and resource allocation, where exogenous randomness (e.g., demand, arrivals, or prices) drives system behavior. Despite decades of empirical evidence that greedy, exploitation-only methods work remarkably well in these settings, theory has lagged behind: all existing regret guarantees for Exo-MDPs rely on explicit exploration or tabular assumptions. We show that exploration is unnecessary. We propose Pure Exploitation Learning (PEL) and prove the first general finite-sample regret bounds for exploitation-only algorithms in Exo-MDPs. In the tabular case, PEL achieves $\widetilde{O}(H^2|\Xi|\sqrt{K})$. For large, continuous endogenous state spaces, we introduce LSVI-PE, a simple linear-approximation method whose regret is polynomial in the feature dimension, exogenous state space, and horizon, independent of the endogenous state and action spaces. Our analysis introduces two new tools: counterfactual trajectories and Bellman-closed feature transport, which together allow greedy policies to have accurate value estimates without optimism. Experiments on synthetic and resource-management tasks show that PEL consistently outperforming baselines. Overall, our results overturn the conventional wisdom that exploration is required, demonstrating that in Exo-MDPs, pure exploitation is enough.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20694v1</guid></item><item><title>[cs updates on arXiv.org] Enterprise Resource Planning Using Multi-type Transformers in Ferro-Titanium Industry</title><link>https://arxiv.org/abs/2601.20696</link><description>arXiv:2601.20696v1 Announce Type: new 
Abstract: Combinatorial optimization problems such as the Job-Shop Scheduling Problem (JSP) and Knapsack Problem (KP) are fundamental challenges in operations research, logistics, and eterprise resource planning (ERP). These problems often require sophisticated algorithms to achieve near-optimal solutions within practical time constraints. Recent advances in deep learning have introduced transformer-based architectures as promising alternatives to traditional heuristics and metaheuristics. We leverage the Multi-Type Transformer (MTT) architecture to address these benchmarks in a unified framework. We present an extensive experimental evaluation across standard benchmark datasets for JSP and KP, demonstrating that MTT achieves competitive performance on different size of these benchmark problems. We showcase the potential of multi-type attention on a real application in Ferro-Titanium industry. To the best of our knowledge, we are the first to apply multi-type transformers in real manufacturing.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20696v1</guid></item><item><title>[cs updates on arXiv.org] Reflected wireless signals under random spatial sampling</title><link>https://arxiv.org/abs/2601.20699</link><description>arXiv:2601.20699v1 Announce Type: new 
Abstract: We present a propagation model showing that a transmitter randomly positioned in space generates unbounded peaks in the histogram of the resulting power, provided the signal strength is an oscillating or non-monotonic function of distance. Specifically, these peaks are singularities in the empirical probability density that occur at turning point values of the deterministic propagation model. We explain the underlying mechanism of this phenomenon through a concise mathematical argument. This observation has direct implications for estimating random propagation effects such as fading, particularly when reflections off walls are involved.
  Motivated by understanding intelligent surfaces, we apply this fundamental result to a physical model consisting of a single transmitter between two parallel passive walls. We analyze signal fading due to reflections and observe power oscillations resulting from wall reflections -- a phenomenon long studied in waveguides but relatively unexplored in wireless networks. For the special case where the transmitter is placed halfway between the walls, we present a compact closed-form expression for the received signal involving the Lerch transcendent function. The insights from this work can inform design decisions for intelligent surfaces deployed in cities.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20699v1</guid></item><item><title>[cs updates on arXiv.org] One Step Is Enough: Dispersive MeanFlow Policy Optimization</title><link>https://arxiv.org/abs/2601.20701</link><description>arXiv:2601.20701v1 Announce Type: new 
Abstract: Real-time robotic control demands fast action generation. However, existing generative policies based on diffusion and flow matching require multi-step
  sampling, fundamentally limiting deployment in time-critical scenarios. We propose Dispersive MeanFlow Policy Optimization (DMPO), a unified framework that
  enables true one-step generation through three key components: MeanFlow for mathematically-derived single-step inference without knowledge distillation,
  dispersive regularization to prevent representation collapse, and reinforcement learning (RL) fine-tuning to surpass expert demonstrations. Experiments
  across RoboMimic manipulation and OpenAI Gym locomotion benchmarks demonstrate competitive or superior performance compared to multi-step baselines. With
  our lightweight model architecture and the three key algorithmic components working in synergy, DMPO exceeds real-time control requirements (&gt;120Hz) with
  5-20x inference speedup, reaching hundreds of Hertz on high-performance GPUs. Physical deployment on a Franka-Emika-Panda robot validates real-world
  applicability.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20701v1</guid></item><item><title>[cs updates on arXiv.org] Structurally Human, Semantically Biased: Detecting LLM-Generated References with Embeddings and GNNs</title><link>https://arxiv.org/abs/2601.20704</link><description>arXiv:2601.20704v1 Announce Type: new 
Abstract: Large language models are increasingly used to curate bibliographies, raising the question: are their reference lists distinguishable from human ones? We build paired citation graphs, ground truth and GPT-4o-generated (from parametric knowledge), for 10,000 focal papers ($\approx$ 275k references) from SciSciNet, and added a field-matched random baseline that preserves out-degree and field distributions while breaking latent structure. We compare (i) structure-only node features (degree/closeness/eigenvector centrality, clustering, edge count) with (ii) 3072-D title/abstract embeddings, using an RF on graph-level aggregates and Graph Neural Networks with node features. Structure alone barely separates GPT from ground truth (RF accuracy $\approx$ 0.60) despite cleanly rejecting the random baseline ($\approx$ 0.89--0.92). By contrast, embeddings sharply increase separability: RF on aggregated embeddings reaches $\approx$ 0.83, and GNNs with embedding node features achieve 93\% test accuracy on GPT vs.\ ground truth. We show the robustness of our findings by replicating the pipeline with Claude Sonnet 4.5 and with multiple embedding models (OpenAI and SPECTER), with RF separability for ground truth vs.\ Claude $\approx 0.77$ and clean rejection of the random baseline. Thus, LLM bibliographies, generated purely from parametric knowledge, closely mimic human citation topology, but leave detectable semantic fingerprints; detection and debiasing should target content signals rather than global graph structure.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20704v1</guid></item><item><title>[cs updates on arXiv.org] LEMON: How Well Do MLLMs Perform Temporal Multimodal Understanding on Instructional Videos?</title><link>https://arxiv.org/abs/2601.20705</link><description>arXiv:2601.20705v1 Announce Type: new 
Abstract: Recent multimodal large language models (MLLMs) have shown remarkable progress across vision, audio, and language tasks, yet their performance on long-form, knowledge-intensive, and temporally structured educational content remains largely unexplored. To bridge this gap, we introduce LEMON, a Lecture-based Evaluation benchmark for MultimOdal uNderstanding, focusing on STEM lecture videos that require long-horizon reasoning and cross-modal integration. LEMON comprises 2,277 video segments spanning 5 disciplines and 29 courses, with an average duration of 196.1 seconds, yielding 4,181 high-quality QA pairs, including 3,413 multiple-choice and 768 open-ended questions. Distinct from existing video benchmarks, LEMON features: (1) semantic richness and disciplinary density, (2) tightly coupled video-audio-text modalities, (3) explicit temporal and pedagogical structure, and (4) contextually linked multi-turn questioning. It further encompasses six major tasks and twelve subtasks, covering the full cognitive spectrum from perception to reasoning and then to generation. Comprehensive experiments reveal substantial performance gaps across tasks, highlighting that even state-of-the-art MLLMs like GPT-4o struggle with temporal reasoning and instructional prediction. We expect LEMON to serve as an extensible and challenging benchmark for advancing multimodal perception, reasoning, and generation in long-form instructional contents.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20705v1</guid></item><item><title>[cs updates on arXiv.org] Beyond GEMM-Centric NPUs: Enabling Efficient Diffusion LLM Sampling</title><link>https://arxiv.org/abs/2601.20706</link><description>arXiv:2601.20706v1 Announce Type: new 
Abstract: Diffusion Large Language Models (dLLMs) introduce iterative denoising to enable parallel token generation, but their sampling phase displays fundamentally different characteristics compared to GEMM-centric transformer layers. Profiling on modern GPUs reveals that sampling can account for up to 70% of total model inference latency-primarily due to substantial memory loads and writes from vocabulary-wide logits, reduction-based token selection, and iterative masked updates. These processes demand large on-chip SRAM and involve irregular memory accesses that conventional NPUs struggle to handle efficiently. To address this, we identify a set of critical instructions that an NPU architecture must specifically optimize for dLLM sampling. Our design employs lightweight non-GEMM vector primitives, in-place memory reuse strategies, and a decoupled mixed-precision memory hierarchy. Together, these optimizations deliver up to a 2.53x speedup over the NVIDIA RTX A6000 GPU under an equivalent nm technology node. We also open-source our cycle-accurate simulation and post-synthesis RTL verification code, confirming functional equivalence with current dLLM PyTorch implementations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20706v1</guid></item><item><title>[cs updates on arXiv.org] MedViz: An Agent-based, Visual-guided Research Assistant for Navigating Biomedical Literature</title><link>https://arxiv.org/abs/2601.20709</link><description>arXiv:2601.20709v1 Announce Type: new 
Abstract: Biomedical researchers face increasing challenges in navigating millions of publications in diverse domains. Traditional search engines typically return articles as ranked text lists, offering little support for global exploration or in-depth analysis. Although recent advances in generative AI and large language models have shown promise in tasks such as summarization, extraction, and question answering, their dialog-based implementations are poorly integrated with literature search workflows. To address this gap, we introduce MedViz, a visual analytics system that integrates multiple AI agents with interactive visualization to support the exploration of the large-scale biomedical literature. MedViz combines a semantic map of millions of articles with agent-driven functions for querying, summarizing, and hypothesis generation, allowing researchers to iteratively refine questions, identify trends, and uncover hidden connections. By bridging intelligent agents with interactive visualization, MedViz transforms biomedical literature search into a dynamic, exploratory process that accelerates knowledge discovery.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20709v1</guid></item><item><title>[cs updates on arXiv.org] Adapting the Behavior of Reinforcement Learning Agents to Changing Action Spaces and Reward Functions</title><link>https://arxiv.org/abs/2601.20714</link><description>arXiv:2601.20714v1 Announce Type: new 
Abstract: Reinforcement Learning (RL) agents often struggle in real-world applications where environmental conditions are non-stationary, particularly when reward functions shift or the available action space expands. This paper introduces MORPHIN, a self-adaptive Q-learning framework that enables on-the-fly adaptation without full retraining. By integrating concept drift detection with dynamic adjustments to learning and exploration hyperparameters, MORPHIN adapts agents to changes in both the reward function and on-the-fly expansions of the agent's action space, while preserving prior policy knowledge to prevent catastrophic forgetting. We validate our approach using a Gridworld benchmark and a traffic signal control simulation. The results demonstrate that MORPHIN achieves superior convergence speed and continuous adaptation compared to a standard Q-learning baseline, improving learning efficiency by up to 1.7x.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20714v1</guid></item><item><title>[cs updates on arXiv.org] Fully Dynamic Algorithms for Graph Spanners via Low-Diameter Router Decomposition</title><link>https://arxiv.org/abs/2601.20718</link><description>arXiv:2601.20718v1 Announce Type: new 
Abstract: A $t$-spanner of an undirected $n$-vertex graph $G$ is a sparse subgraph $H$ of $G$ that preserves all pairwise distances between its vertices to within multiplicative factor $t$, also called the \emph{stretch}. We investigate the problem of maintaining spanners in the fully dynamic setting with an adaptive adversary. Despite a long line of research, this problem is still poorly understood: no algorithm achieving a sublogarithmic stretch, a sublinear in $n$ update time, and a strongly subquadratic in $n$ spanner size is currently known.
  One of our main results is a deterministic algorithm, that, for any $512 \leq k \leq (\log n)^{1/49}$ and $1/k\leq \delta \leq 1/400$, maintains a spanner $H$ of a fully dynamic graph with stretch $poly(k)\cdot 2^{O(1/\delta^6)}$ and size $|E(H)|\leq O(n^{1+O(1/k)})$, with worst-case update time $n^{O(\delta)}$ and recourse $n^{O(1/k)}$. Our algorithm relies on a new technical tool that we develop, called low-diameter router decomposition. We design a deterministic algorithm that maintains a decomposition of a fully dynamic graph into edge-disjoint clusters with bounded vertex overlap, where each cluster $C$ is a bounded-diameter router, meaning that any reasonable multicommodity demand over the vertices of $C$ can be routed along short paths and with low congestion. A similar graph decomposition notion was introduced by [Haeupler et al., STOC 2022] and strengthened by [Haeupler et al., FOCS 2024]. However, in contrast to these and other prior works, the decomposition that our algorithm maintains is proper, ensuring that the routing paths between the pairs of vertices of each cluster $C$ are contained inside $C$, rather than in the entire graph $G$. We show additional applications of our router decomposition, including dynamic algorithms for fault-tolerant spanners and low-congestion spanners.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20718v1</guid></item><item><title>[cs updates on arXiv.org] Li-ViP3D++: Query-Gated Deformable Camera-LiDAR Fusion for End-to-End Perception and Trajectory Prediction</title><link>https://arxiv.org/abs/2601.20720</link><description>arXiv:2601.20720v1 Announce Type: new 
Abstract: End-to-end perception and trajectory prediction from raw sensor data is one of the key capabilities for autonomous driving. Modular pipelines restrict information flow and can amplify upstream errors. Recent query-based, fully differentiable perception-and-prediction (PnP) models mitigate these issues, yet the complementarity of cameras and LiDAR in the query-space has not been sufficiently explored. Models often rely on fusion schemes that introduce heuristic alignment and discrete selection steps which prevent full utilization of available information and can introduce unwanted bias. We propose Li-ViP3D++, a query-based multimodal PnP framework that introduces Query-Gated Deformable Fusion (QGDF) to integrate multi-view RGB and LiDAR in query space. QGDF (i) aggregates image evidence via masked attention across cameras and feature levels, (ii) extracts LiDAR context through fully differentiable BEV sampling with learned per-query offsets, and (iii) applies query-conditioned gating to adaptively weight visual and geometric cues per agent. The resulting architecture jointly optimizes detection, tracking, and multi-hypothesis trajectory forecasting in a single end-to-end model. On nuScenes, Li-ViP3D++ improves end-to-end behavior and detection quality, achieving higher EPA (0.335) and mAP (0.502) while substantially reducing false positives (FP ratio 0.147), and it is faster than the prior Li-ViP3D variant (139.82 ms vs. 145.91 ms). These results indicate that query-space, fully differentiable camera-LiDAR fusion can increase robustness of end-to-end PnP without sacrificing deployability.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20720v1</guid></item><item><title>[cs updates on arXiv.org] Distributed Learning over Noisy Communication Networks</title><link>https://arxiv.org/abs/2601.20723</link><description>arXiv:2601.20723v1 Announce Type: new 
Abstract: We study binary coordination games over graphs under log-linear learning when neighbor actions are conveyed through explicit noisy communication links. Each edge is modeled as either a binary symmetric channel (BSC) or a binary erasure channel (BEC). We analyze two operational regimes. For binary symmetric and binary erasure channels, we provide a structural characterization of the induced learning dynamics. In a fast-communication regime, agents update using channel-averaged payoffs; the resulting learning dynamics coincide with a Gibbs sampler for a scaled coordination potential, where channel reliability enters only through a scalar attenuation coefficient. In a snapshot regime, agents update from a single noisy realization and ignore channel statistics; the induced Markov chain is generally nonreversible, but admits a high-temperature expansion whose drift matches that of the fast Gibbs sampler with the same attenuation. We further formalize a finite-$K$ communication budget, which interpolates between snapshot and fast behavior as the number of channel uses per update grows. This viewpoint yields a communication-theoretic interpretation in terms of retransmissions and repetition coding, and extends naturally to heterogeneous link reliabilities via effective edge weights. Numerical experiments illustrate the theory and quantify the tradeoff between communication resources and steady-state coordination quality.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20723v1</guid></item><item><title>[cs updates on arXiv.org] Audit Trails for Accountability in Large Language Models</title><link>https://arxiv.org/abs/2601.20727</link><description>arXiv:2601.20727v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly embedded in consequential decisions across healthcare, finance, employment, and public services. Yet accountability remains fragile because process transparency is rarely recorded in a durable and reviewable form. We propose LLM audit trails as a sociotechnical mechanism for continuous accountability. An audit trail is a chronological, tamper-evident, context-rich ledger of lifecycle events and decisions that links technical provenance (models, data, training and evaluation runs, deployments, monitoring) with governance records (approvals, waivers, and attestations), so organizations can reconstruct what changed, when, and who authorized it.
  This paper contributes: (1) a lifecycle framework that specifies event types, required metadata, and governance rationales; (2) a reference architecture with lightweight emitters, append only audit stores, and an auditor interface supporting cross organizational traceability; and (3) a reusable, open-source Python implementation that instantiates this audit layer in LLM workflows with minimal integration effort. We conclude by discussing limitations and directions for adoption.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20727v1</guid></item><item><title>[cs updates on arXiv.org] Deep Semi-Supervised Survival Analysis for Predicting Cancer Prognosis</title><link>https://arxiv.org/abs/2601.20729</link><description>arXiv:2601.20729v1 Announce Type: new 
Abstract: The Cox Proportional Hazards (PH) model is widely used in survival analysis. Recently, artificial neural network (ANN)-based Cox-PH models have been developed. However, training these Cox models with high-dimensional features typically requires a substantial number of labeled samples containing information about time-to-event. The limited availability of labeled data for training often constrains the performance of ANN-based Cox models. To address this issue, we employed a deep semi-supervised learning (DSSL) approach to develop single- and multi-modal ANN-based Cox models based on the Mean Teacher (MT) framework, which utilizes both labeled and unlabeled data for training. We applied our model, named Cox-MT, to predict the prognosis of several types of cancer using data from The Cancer Genome Atlas (TCGA). Our single-modal Cox-MT models, utilizing TCGA RNA-seq data or whole slide images, significantly outperformed the existing ANN-based Cox model, Cox-nnet, using the same data set across four types of cancer considered. As the number of unlabeled samples increased, the performance of Cox-MT significantly improved with a given set of labeled data. Furthermore, our multi-modal Cox-MT model demonstrated considerably better performance than the single-modal model. In summary, the Cox-MT model effectively leverages both labeled and unlabeled data to significantly enhance prediction accuracy compared to existing ANN-based Cox models trained solely on labeled data.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20729v1</guid></item><item><title>[cs updates on arXiv.org] AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts</title><link>https://arxiv.org/abs/2601.20730</link><description>arXiv:2601.20730v1 Announce Type: new 
Abstract: The evolution of Large Language Models (LLMs) into autonomous agents necessitates the management of extensive, dynamic contexts. Current benchmarks, however, remain largely static, relying on passive retrieval tasks that fail to simulate the complexities of agent-environment interaction, such as non-linear reasoning and iterative feedback. To address this, we introduce \textbf{AgentLongBench}, which evaluates agents through simulated environment rollouts based on Lateral Thinking Puzzles. This framework generates rigorous interaction trajectories across knowledge-intensive and knowledge-free scenarios. Experiments with state-of-the-art models and memory systems (32K to 4M tokens) expose a critical weakness: while adept at static retrieval, agents struggle with the dynamic information synthesis essential for workflows. Our analysis indicates that this degradation is driven by the minimum number of tokens required to resolve a query. This factor explains why the high information density inherent in massive tool responses poses a significantly greater challenge than the memory fragmentation typical of long-turn dialogues.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20730v1</guid></item><item><title>[cs updates on arXiv.org] QueerGen: How LLMs Reflect Societal Norms on Gender and Sexuality in Sentence Completion Tasks</title><link>https://arxiv.org/abs/2601.20731</link><description>arXiv:2601.20731v1 Announce Type: new 
Abstract: This paper examines how Large Language Models (LLMs) reproduce societal norms, particularly heterocisnormativity, and how these norms translate into measurable biases in their text generations. We investigate whether explicit information about a subject's gender or sexuality influences LLM responses across three subject categories: queer-marked, non-queer-marked, and the normalized "unmarked" category. Representational imbalances are operationalized as measurable differences in English sentence completions across four dimensions: sentiment, regard, toxicity, and prediction diversity. Our findings show that Masked Language Models (MLMs) produce the least favorable sentiment, higher toxicity, and more negative regard for queer-marked subjects. Autoregressive Language Models (ARLMs) partially mitigate these patterns, while closed-access ARLMs tend to produce more harmful outputs for unmarked subjects. Results suggest that LLMs reproduce normative social assumptions, though the form and degree of bias depend strongly on specific model characteristics, which may redistribute, but not eliminate, representational harms.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20731v1</guid></item><item><title>[cs updates on arXiv.org] Continual GUI Agents</title><link>https://arxiv.org/abs/2601.20732</link><description>arXiv:2601.20732v1 Announce Type: new 
Abstract: As digital environments (data distribution) are in flux, with new GUI data arriving over time-introducing new domains or resolutions-agents trained on static environments deteriorate in performance. In this work, we introduce Continual GUI Agents, a new task that requires GUI agents to perform continual learning under shifted domains and resolutions. We find existing methods fail to maintain stable grounding as GUI distributions shift over time, due to the diversity of UI interaction points and regions in fluxing scenarios. To address this, we introduce GUI-Anchoring in Flux (GUI-AiF), a new reinforcement fine-tuning framework that stabilizes continual learning through two novel rewards: Anchoring Point Reward in Flux (APR-iF) and Anchoring Region Reward in Flux (ARR-iF). These rewards guide the agents to align with shifting interaction points and regions, mitigating the tendency of existing reward strategies to over-adapt to static grounding cues (e.g., fixed coordinates or element scales). Extensive experiments show GUI-AiF surpasses state-of-the-art baselines. Our work establishes the first continual learning framework for GUI agents, revealing the untapped potential of reinforcement fine-tuning for continual GUI Agents.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20732v1</guid></item><item><title>[cs updates on arXiv.org] Implementing Metric Temporal Answer Set Programming</title><link>https://arxiv.org/abs/2601.20735</link><description>arXiv:2601.20735v1 Announce Type: new 
Abstract: We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constraints, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP's grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20735v1</guid></item><item><title>[cs updates on arXiv.org] A Human-Centred AI System for Multi-Actor Planning and Collaboration in Family Learning</title><link>https://arxiv.org/abs/2601.20737</link><description>arXiv:2601.20737v1 Announce Type: new 
Abstract: Family learning takes place in everyday routines where children and caregivers read, practice, and develop new skills together. Despite growing interest in AI tutors, most existing systems are designed for single learners or classroom settings and do not address the distributed planning, coordination, and execution demands of learning at home. This paper introduces ParPal, a human-centred, LLM-powered system that supports multi-actor family learning by decomposing learning goals into actionable subtasks, allocating them across caregivers under realistic availability and expertise constraints, and providing caregiver-in-the-loop tutoring support with visibility into individual and collective contributions. Through expert evaluation of generated weekly learning plans and a one-week field deployment with 11 families, we identify systematic failure modes in current LLM-based planning, including misalignment with role expertise, unnecessary or costly collaboration, missing pedagogical learning trajectories, and physically or temporally infeasible tasks. While ParPal improves coordination clarity and recognition of caregiving effort, these findings expose fundamental limitations in how current LLMs operationalize pedagogical knowledge, reason about collaboration, and account for real-world, embodied constraints. We discuss implications for human-centred AI design and AI methodology, positioning multi-actor family learning as a critical testbed for advancing planning, adaptation, and pedagogical structure in next-generation AI systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20737v1</guid></item><item><title>[cs updates on arXiv.org] SA-PEF: Step-Ahead Partial Error Feedback for Efficient Federated Learning</title><link>https://arxiv.org/abs/2601.20738</link><description>arXiv:2601.20738v1 Announce Type: new 
Abstract: Biased gradient compression with error feedback (EF) reduces communication in federated learning (FL), but under non-IID data, the residual error can decay slowly, causing gradient mismatch and stalled progress in the early rounds. We propose step-ahead partial error feedback (SA-PEF), which integrates step-ahead (SA) correction with partial error feedback (PEF). SA-PEF recovers EF when the step-ahead coefficient $\alpha=0$ and step-ahead EF (SAEF) when $\alpha=1$. For non-convex objectives and $\delta$-contractive compressors, we establish a second-moment bound and a residual recursion that guarantee convergence to stationarity under heterogeneous data and partial client participation. The resulting rates match standard non-convex Fed-SGD guarantees up to constant factors, achieving $O((\eta,\eta_0TR)^{-1})$ convergence to a variance/heterogeneity floor with a fixed inner step size. Our analysis reveals a step-ahead-controlled residual contraction $\rho_r$ that explains the observed acceleration in the early training phase. To balance SAEF's rapid warm-up with EF's long-term stability, we select $\alpha$ near its theory-predicted optimum. Experiments across diverse architectures and datasets show that SA-PEF consistently reaches target accuracy faster than EF.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20738v1</guid></item><item><title>[cs updates on arXiv.org] Compression Tells Intelligence: Visual Coding, Visual Token Technology, and the Unification</title><link>https://arxiv.org/abs/2601.20742</link><description>arXiv:2601.20742v1 Announce Type: new 
Abstract: "Compression Tells Intelligence", is supported by research in artificial intelligence, particularly concerning (multimodal) large language models (LLMs/MLLMs), where compression efficiency often correlates with improved model performance and capabilities. For compression, classical visual coding based on traditional information theory has developed over decades, achieving great success with numerous international industrial standards widely applied in multimedia (e.g., image/video) systems. Except that, the recent emergingvisual token technology of generative multi-modal large models also shares a similar fundamental objective like visual coding: maximizing semantic information fidelity during the representation learning while minimizing computational cost. Therefore, this paper provides a comprehensive overview of two dominant technique families first -- Visual Coding and Vision Token Technology -- then we further unify them from the aspect of optimization, discussing the essence of compression efficiency and model performance trade-off behind. Next, based on the proposed unified formulation bridging visual coding andvisual token technology, we synthesize bidirectional insights of themselves and forecast the next-gen visual codec and token techniques. Last but not least, we experimentally show a large potential of the task-oriented token developments in the more practical tasks like multimodal LLMs (MLLMs), AI-generated content (AIGC), and embodied AI, as well as shedding light on the future possibility of standardizing a general token technology like the traditional codecs (e.g., H.264/265) with high efficiency for a wide range of intelligent tasks in a unified and effective manner.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20742v1</guid></item><item><title>[cs updates on arXiv.org] HESTIA: A Hessian-Guided Differentiable Quantization-Aware Training Framework for Extremely Low-Bit LLMs</title><link>https://arxiv.org/abs/2601.20745</link><description>arXiv:2601.20745v1 Announce Type: new 
Abstract: As large language models (LLMs) continue to scale, deployment is increasingly bottlenecked by the memory wall, motivating a shift toward extremely low-bit quantization. However, most quantization-aware training (QAT) methods apply hard rounding and the straight-through estimator (STE) from the beginning of the training, which prematurely discretizes the optimization landscape and induces persistent gradient mismatch between latent weights and quantized weights, hindering effective optimization of quantized models. To address this, we propose Hestia, a Hessian-guided differentiable QAT framework for extremely low-bit LLMs, which replaces the rigid step function with a temperature-controlled softmax relaxation to maintain gradient flow early in training while progressively hardening quantization. Furthermore, Hestia leverages a tensor-wise Hessian trace metric as a lightweight curvature signal to drive fine-grained temperature annealing, enabling sensitivity-aware discretization across the model. Evaluations on Llama-3.2 show that Hestia consistently outperforms existing ternary QAT baselines, yielding average zero-shot improvements of 5.39% and 4.34% for the 1B and 3B models. These results indicate that Hessian-guided relaxation effectively recovers representational capacity, establishing a more robust training path for 1.58-bit LLMs. The code is available at https://github.com/hestia2026/Hestia.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20745v1</guid></item><item><title>[cs updates on arXiv.org] Like a Therapist, But Not: Reddit Narratives of AI in Mental Health Contexts</title><link>https://arxiv.org/abs/2601.20747</link><description>arXiv:2601.20747v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly used for emotional support and mental health-related interactions outside clinical settings, yet little is known about how people evaluate and relate to these systems in everyday use. We analyze 5,126 Reddit posts from 47 mental health communities describing experiential or exploratory use of AI for emotional support or therapy. Grounded in the Technology Acceptance Model and therapeutic alliance theory, we develop a theory-informed annotation framework and apply a hybrid LLM-human pipeline to analyze evaluative language, adoption-related attitudes, and relational alignment at scale. Our results show that engagement is shaped primarily by narrated outcomes, trust, and response quality, rather than emotional bond alone. Positive sentiment is most strongly associated with task and goal alignment, while companionship-oriented use more often involves misaligned alliances and reported risks such as dependence and symptom escalation. Overall, this work demonstrates how theory-grounded constructs can be operationalized in large-scale discourse analysis and highlights the importance of studying how users interpret language technologies in sensitive, real-world contexts.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20747v1</guid></item><item><title>[cs updates on arXiv.org] Learning to Live with AI: How Students Develop AI Literacy Through Naturalistic ChatGPT Interaction</title><link>https://arxiv.org/abs/2601.20749</link><description>arXiv:2601.20749v1 Announce Type: new 
Abstract: How do students develop AI literacy through everyday practice rather than formal instruction? While normative AI literacy frameworks proliferate, empirical understanding of how students actually learn to work with generative AI remains limited. This study analyzes 10,536 ChatGPT messages from 36 undergraduates over one academic year, revealing five use genres -- academic workhorse, emotional companion, metacognitive partner, repair and negotiation, and trust calibration -- that constitute distinct configurations of student-AI learning. Drawing on domestication theory and emerging frameworks for AI literacy, we demonstrate that functional AI competence emerges through ongoing relational negotiation rather than one-time adoption. Students develop sophisticated genre portfolios, strategically matching interaction patterns to learning needs while exercising critical judgment about AI limitations. Notably, repair work during AI breakdowns produces substantial learning about AI capabilities, developing what we term "repair literacy" -- a crucial but underexplored dimension of AI competence. Our findings offer educators empirically grounded insights into how students actually learn to work with generative AI, with implications for AI literacy pedagogy, responsible AI integration, and the design of AI-enabled learning environments that support student agency.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20749v1</guid></item><item><title>[cs updates on arXiv.org] Adaptive domain decomposition method for time-dependent problems with applications in fluid dynamics</title><link>https://arxiv.org/abs/2601.20750</link><description>arXiv:2601.20750v1 Announce Type: new 
Abstract: We deal with the numerical solution of the time-dependent partial differential equations using the adaptive space-time discontinuous Galerkin (DG) method. The discretization leads to a nonlinear algebraic system at each time level, the size of the system is varying due to mesh adaptation. A Newton-like iterative solver leads to a sequence of linear algebraic systems which are solved by GMRES solver with a domain decomposition preconditioner. Particularly, we consider additive and hybrid two-level Schwarz preconditioners which are efficient and easy to implement for DG discretization. We study the convergence of the linear solver in dependence on the number of subdomains and the number of element of the coarse grid. We propose a simplified cost model measuring the computational costs in terms of floating-point operations, the speed of computation, and the wall-clock time for communications among computer cores. Moreover, the cost model serves as a base of the presented adaptive domain decomposition method which chooses the number of subdomains and the number of element of the coarse grid in order to minimize the computational costs. The efficiency of the proposed technique is demonstrated by two benchmark problems of compressible flow simulations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20750v1</guid></item><item><title>[cs updates on arXiv.org] GraphAllocBench: A Flexible Benchmark for Preference-Conditioned Multi-Objective Policy Learning</title><link>https://arxiv.org/abs/2601.20753</link><description>arXiv:2601.20753v1 Announce Type: new 
Abstract: Preference-Conditioned Policy Learning (PCPL) in Multi-Objective Reinforcement Learning (MORL) aims to approximate diverse Pareto-optimal solutions by conditioning policies on user-specified preferences over objectives. This enables a single model to flexibly adapt to arbitrary trade-offs at run-time by producing a policy on or near the Pareto front. However, existing benchmarks for PCPL are largely restricted to toy tasks and fixed environments, limiting their realism and scalability. To address this gap, we introduce GraphAllocBench, a flexible benchmark built on a novel graph-based resource allocation sandbox environment inspired by city management, which we call CityPlannerEnv. GraphAllocBench provides a rich suite of problems with diverse objective functions, varying preference conditions, and high-dimensional scalability. We also propose two new evaluation metrics -- Proportion of Non-Dominated Solutions (PNDS) and Ordering Score (OS) -- that directly capture preference consistency while complementing the widely used hypervolume metric. Through experiments with Multi-Layer Perceptrons (MLPs) and graph-aware models, we show that GraphAllocBench exposes the limitations of existing MORL approaches and paves the way for using graph-based methods such as Graph Neural Networks in complex, high-dimensional combinatorial allocation tasks. Beyond its predefined problem set, GraphAllocBench enables users to flexibly vary objectives, preferences, and allocation rules, establishing it as a versatile and extensible benchmark for advancing PCPL. Code: https://anonymous.4open.science/r/GraphAllocBench</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20753v1</guid></item><item><title>[cs updates on arXiv.org] ProfInfer: An eBPF-based Fine-Grained LLM Inference Profiler</title><link>https://arxiv.org/abs/2601.20755</link><description>arXiv:2601.20755v1 Announce Type: new 
Abstract: As large language models (LLMs) move from research to production, understanding how inference engines behave in real time has become both essential and elusive. Unlike general-purpose engines such as ONNX Runtime, today's LLM inference systems offer little operator-level visibility, leaving developers blind to where time and resources go. Even basic questions -- is this workload memory-bound or compute-bound? -- often remain unanswered. To close this gap, we develop a fine-grained, non-intrusive profiling framework for modern LLM inference engines, exemplified by llama.cpp but applicable to similar runtime architectures. Built on extended Berkeley Packet Filter (eBPF) technology, our system dynamically attaches probes to runtime functions across multiple layers -- without modifying or recompiling the source. It transforms collected traces into rich visualizations of operators, graphs, timelines, and hardware counter trends, exposing how dense inference, Mixture-of-Experts routing, and operator offloading behave in practice. With less than 4% runtime overhead and high profiling fidelity, our framework makes LLM inference both transparent and diagnosable, turning performance profiling into a practical tool for optimization, scheduling, and resource-aware deployment.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20755v1</guid></item><item><title>[cs updates on arXiv.org] Supervised Guidance Training for Infinite-Dimensional Diffusion Models</title><link>https://arxiv.org/abs/2601.20756</link><description>arXiv:2601.20756v1 Announce Type: new 
Abstract: Score-based diffusion models have recently been extended to infinite-dimensional function spaces, with uses such as inverse problems arising from partial differential equations. In the Bayesian formulation of inverse problems, the aim is to sample from a posterior distribution over functions obtained by conditioning a prior on noisy observations. While diffusion models provide expressive priors in function space, the theory of conditioning them to sample from the posterior remains open. We address this, assuming that either the prior lies in the Cameron-Martin space, or is absolutely continuous with respect to a Gaussian measure. We prove that the models can be conditioned using an infinite-dimensional extension of Doob's $h$-transform, and that the conditional score decomposes into an unconditional score and a guidance term. As the guidance term is intractable, we propose a simulation-free score matching objective (called Supervised Guidance Training) enabling efficient and stable posterior sampling. We illustrate the theory with numerical examples on Bayesian inverse problems in function spaces. In summary, our work offers the first function-space method for fine-tuning trained diffusion models to accurately sample from a posterior.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20756v1</guid></item><item><title>[cs updates on arXiv.org] Persona Prompting as a Lens on LLM Social Reasoning</title><link>https://arxiv.org/abs/2601.20757</link><description>arXiv:2601.20757v1 Announce Type: new 
Abstract: For socially sensitive tasks like hate speech detection, the quality of explanations from Large Language Models (LLMs) is crucial for factors like user trust and model alignment. While Persona prompting (PP) is increasingly used as a way to steer model towards user-specific generation, its effect on model rationales remains underexplored. We investigate how LLM-generated rationales vary when conditioned on different simulated demographic personas. Using datasets annotated with word-level rationales, we measure agreement with human annotations from different demographic groups, and assess the impact of PP on model bias and human alignment. Our evaluation across three LLMs results reveals three key findings: (1) PP improving classification on the most subjective task (hate speech) but degrading rationale quality. (2) Simulated personas fail to align with their real-world demographic counterparts, and high inter-persona agreement shows models are resistant to significant steering. (3) Models exhibit consistent demographic biases and a strong tendency to over-flag content as harmful, regardless of PP. Our findings reveal a critical trade-off: while PP can improve classification in socially-sensitive tasks, it often comes at the cost of rationale quality and fails to mitigate underlying biases, urging caution in its application.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20757v1</guid></item><item><title>[cs updates on arXiv.org] ScaleFree: Dynamic KDE for Multiscale Point Cloud Exploration in VR</title><link>https://arxiv.org/abs/2601.20758</link><description>arXiv:2601.20758v1 Announce Type: new 
Abstract: We present ScaleFree, a GPU-accelerated adaptive Kernel Density Estimation (KDE) algorithm for scalable, interactive multiscale point cloud exploration. With this technique, we cater to the massive datasets and complex multiscale structures in advanced scientific computing, such as cosmological simulations with billions of particles. Effective exploration of such data requires a full 3D understanding of spatial structures, a capability for which immersive environments such as VR are particularly well suited. However, simultaneously supporting global multiscale context and fine-grained local detail remains a significant challenge. A key difficulty lies in dynamically generating continuous density fields from point clouds to facilitate the seamless scale transitions: while KDE is widely used, precomputed fields restrict the accuracy of interaction and omit fine-scale structures, while dynamic computation is often too costly for real-time VR interaction. We address this challenge by leveraging GPU acceleration with k-d-tree-based spatial queries and parallel reduction within a thread group for on-the-fly density estimation. With this approach, we can recalculate scalar fields dynamically as users shift their focus across scales. We demonstrate the benefits of adaptive density estimation through two data exploration tasks: adaptive selection and progressive navigation. Through performance experiments, we demonstrate that ScaleFree with GPU-parallel implementation achieves orders-of-magnitude speedups over sequential and multi-core CPU baselines. In a controlled experiment, we further confirm that our adaptive selection technique improves accuracy and efficiency in multiscale selection tasks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20758v1</guid></item><item><title>[cs updates on arXiv.org] The Latent Space of Equational Theories</title><link>https://arxiv.org/abs/2601.20759</link><description>arXiv:2601.20759v1 Announce Type: new 
Abstract: Building on the collaborative Equational Theories project initiated by Terence Tao fifteen months ago, and combining it with ideas coming from machine learning and finite model theory, we construct a latent space of equational theories where each equational theory is located at a specific location, determined by its statistical behavior with respect to a large sample of finite magmas. This experiment enables us to observe for the first time how reasoning flows and produces surprisingly oriented and well-structured chains of logical implications in the latent space of equational theories.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20759v1</guid></item><item><title>[cs updates on arXiv.org] Exploring Re-inforcement Learning via Human Feedback under User Heterogeneity</title><link>https://arxiv.org/abs/2601.20760</link><description>arXiv:2601.20760v1 Announce Type: new 
Abstract: Re-inforcement learning from human feedback (RLHF) has been effective in the task of AI alignment. However, one of the key assumptions of RLHF is that the annotators (referred to as workers from here on out) have a homogeneous response space. This assumption is not true in most practical settings and there have been studies done in the past to challenge this notion. This work has been inspired by such studies and explores one of the ways to deal with heterogeneity in worker preferences - by clustering workers with similar preferences and personalising reward models for each cluster. This work provides an algorithm that encourages simultaneous learning of reward models and worker embeddings. This algorithm is then empirically tested against the Reddit TL;DR dataset with unique worker IDs. We have shown that clustering users into different groups based on their preferences and created personalised reward models improves win-rate of the said models. Along with results and visualisations, this work aims to act as a stepping stone to more complicated models and gives a list of possible future extensions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20760v1</guid></item><item><title>[cs updates on arXiv.org] Anytime-Valid Quantum Tomography via Confidence Sequences</title><link>https://arxiv.org/abs/2601.20761</link><description>arXiv:2601.20761v1 Announce Type: new 
Abstract: In this letter, we address the problem of developing quantum state tomography (QST) methods that remain valid at any time during a sequence of measurements. Specifically, the aim is to provide a rigorous quantification of the uncertainty associated with the current state estimate as data are acquired incrementally. To this end, the proposed framework augments existing QST techniques by associating current point estimates of the state with confidence sets that are guaranteed to contain the true quantum state with a user-defined probability. The methodology is grounded in recent statistical advances in anytime-valid confidence sequences. Numerical results confirm the theoretical coverage properties of the proposed anytime-valid QST.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20761v1</guid></item><item><title>[cs updates on arXiv.org] Agentic Fog: A Policy-driven Framework for Distributed Intelligence in Fog Computing</title><link>https://arxiv.org/abs/2601.20764</link><description>arXiv:2601.20764v1 Announce Type: new 
Abstract: Fog and edge computing require adaptive control schemes that can handle partial observability, severe latency requirements, and dynamically changing workloads. Recent research on Agentic AI (AAI) increasingly integrates reasoning systems powered by Large Language Models; however, these tools are not applicable to infrastructure-level systems due to their high computational cost, stochastic nature, and poor formal analyzability. In this paper, a generic model, Agentic Fog (AF), is presented, in which fog nodes are represented as policy-driven autonomous agents that communicate via p2p interactions based on shared memory and localized coordination. The suggested architecture decomposes a system's goals into abstract policy guidance and formalizes decentralized fog coordination as an exact potential game. The framework is guaranteed to converge and remain stable under asynchronous updates, bounded-rational best-response dynamics, and node failures. Simulations demonstrate that the AF system achieves lower average latency and adapts more efficiently to varying demand than greedy heuristics and integer linear programming under dynamic conditions. The sensitivity analysis also demonstrates the capability to perform optimally under different memory and coordination conditions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20764v1</guid></item><item><title>[cs updates on arXiv.org] Less is More: Clustered Cross-Covariance Control for Offline RL</title><link>https://arxiv.org/abs/2601.20765</link><description>arXiv:2601.20765v1 Announce Type: new 
Abstract: A fundamental challenge in offline reinforcement learning is distributional shift. Scarce data or datasets dominated by out-of-distribution (OOD) areas exacerbate this issue. Our theoretical analysis and experiments show that the standard squared error objective induces a harmful TD cross covariance. This effect amplifies in OOD areas, biasing optimization and degrading policy learning. To counteract this mechanism, we develop two complementary strategies: partitioned buffer sampling that restricts updates to localized replay partitions, attenuates irregular covariance effects, and aligns update directions, yielding a scheme that is easy to integrate with existing implementations, namely Clustered Cross-Covariance Control for TD (C^4). We also introduce an explicit gradient-based corrective penalty that cancels the covariance induced bias within each update. We prove that buffer partitioning preserves the lower bound property of the maximization objective, and that these constraints mitigate excessive conservatism in extreme OOD areas without altering the core behavior of policy constrained offline reinforcement learning. Empirically, our method showcases higher stability and up to 30% improvement in returns over prior methods, especially with small datasets and splits that emphasize OOD areas.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20765v1</guid></item><item><title>[cs updates on arXiv.org] COMET-SG1: Lightweight Autoregressive Regressor for Edge and Embedded AI</title><link>https://arxiv.org/abs/2601.20772</link><description>arXiv:2601.20772v1 Announce Type: new 
Abstract: COMET-SG1 is a lightweight, stability-oriented autoregressive regression model designed for time-series prediction on edge and embedded AI systems. Unlike recurrent neural networks or transformer-based sequence models, COMET-SG1 operates through linear behavior-space encoding, memory-anchored transition estimation, and deterministic state updates. This structure prioritizes bounded long-horizon behavior under fully autoregressive inference, a critical requirement for edge deployment where prediction errors accumulate over time. Experiments on non-stationary synthetic time-series data demonstrate that COMET-SG1 achieves competitive short-horizon accuracy while exhibiting significantly reduced long-horizon drift compared to MLP, LSTM, and k-nearest neighbor baselines. With a compact parameter footprint and operations compatible with fixed-point arithmetic, COMET-SG1 provides a practical and interpretable approach for stable autoregressive prediction in edge and embedded AI applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20772v1</guid></item><item><title>[cs updates on arXiv.org] Smoothing the Black-Box: Signed-Distance Supervision for Black-Box Model Copying</title><link>https://arxiv.org/abs/2601.20773</link><description>arXiv:2601.20773v1 Announce Type: new 
Abstract: Deployed machine learning systems must continuously evolve as data, architectures, and regulations change, often without access to original training data or model internals. In such settings, black-box copying provides a practical refactoring mechanism, i.e. upgrading legacy models by learning replicas from input-output queries alone. When restricted to hard-label outputs, copying turns into a discontinuous surface reconstruction problem from pointwise queries, severely limiting the ability to recover boundary geometry efficiently. We propose a distance-based copying (distillation) framework that replaces hard-label supervision with signed distances to the teacher's decision boundary, converting copying into a smooth regression problem that exploits local geometry. We develop an $\alpha$-governed smoothing and regularization scheme with H\"older/Lipschitz control over the induced target surface, and introduce two model-agnostic algorithms to estimate signed distances under label-only access. Experiments on synthetic problems and UCI benchmarks show consistent improvements in fidelity and generalization accuracy over hard-label baselines, while enabling distance outputs as uncertainty-related signals for black-box replicas.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20773v1</guid></item><item><title>[cs updates on arXiv.org] When More Data Doesn't Help: Limits of Adaptation in Multitask Learning</title><link>https://arxiv.org/abs/2601.20774</link><description>arXiv:2601.20774v1 Announce Type: new 
Abstract: Multitask learning and related frameworks have achieved tremendous success in modern applications. In multitask learning problem, we are given a set of heterogeneous datasets collected from related source tasks and hope to enhance the performance above what we could hope to achieve by solving each of them individually. The recent work of arXiv:2006.15785 has showed that, without access to distributional information, no algorithm based on aggregating samples alone can guarantee optimal risk as long as the sample size per task is bounded.
  In this paper, we focus on understanding the statistical limits of multitask learning. We go beyond the no-free-lunch theorem in arXiv:2006.15785 by establishing a stronger impossibility result of adaptation that holds for arbitrarily large sample size per task. This improvement conveys an important message that the hardness of multitask learning cannot be overcame by having abundant data per task. We also discuss the notion of optimal adaptivity that may be of future interests.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20774v1</guid></item><item><title>[cs updates on arXiv.org] Active Learning for Decision Trees with Provable Guarantees</title><link>https://arxiv.org/abs/2601.20775</link><description>arXiv:2601.20775v1 Announce Type: new 
Abstract: This paper advances the theoretical understanding of active learning label complexity for decision trees as binary classifiers. We make two main contributions. First, we provide the first analysis of the disagreement coefficient for decision trees-a key parameter governing active learning label complexity. Our analysis holds under two natural assumptions required for achieving polylogarithmic label complexity, (i) each root-to-leaf path queries distinct feature dimensions, and (ii) the input data has a regular, grid-like structure. We show these assumptions are essential, as relaxing them leads to polynomial label complexity. Second, we present the first general active learning algorithm for binary classification that achieves a multiplicative error guarantee, producing a $(1+\epsilon)$-approximate classifier. By combining these results, we design an active learning algorithm for decision trees that uses only a polylogarithmic number of label queries in the dataset size, under the stated assumptions. Finally, we establish a label complexity lower bound, showing our algorithm's dependence on the error tolerance $\epsilon$ is close to optimal.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20775v1</guid></item><item><title>[cs updates on arXiv.org] Learning From a Steady Hand: A Weakly Supervised Agent for Robot Assistance under Microscopy</title><link>https://arxiv.org/abs/2601.20776</link><description>arXiv:2601.20776v1 Announce Type: new 
Abstract: This paper rethinks steady-hand robotic manipulation by using a weakly supervised framework that fuses calibration-aware perception with admittance control. Unlike conventional automation that relies on labor-intensive 2D labeling, our framework leverages reusable warm-up trajectories to extract implicit spatial information, thereby achieving calibration-aware, depth-resolved perception without the need for external fiducials or manual depth annotation. By explicitly characterizing residuals from observation and calibration models, the system establishes a task-space error budget from recorded warm-ups. The uncertainty budget yields a lateral closed-loop accuracy of approx. 49 micrometers at 95% confidence (worst-case testing subset) and a depth accuracy of &lt;= 291 micrometers at 95% confidence bound during large in-plane moves. In a within-subject user study (N=8), the learned agent reduces overall NASA-TLX workload by 77.1% relative to the simple steady-hand assistance baseline. These results demonstrate that the weakly supervised agent improves the reliability of microscope-guided biomedical micromanipulation without introducing complex setup requirements, offering a practical framework for microscope-guided intervention.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20776v1</guid></item><item><title>[cs updates on arXiv.org] Independence of Approximate Clones</title><link>https://arxiv.org/abs/2601.20779</link><description>arXiv:2601.20779v1 Announce Type: new 
Abstract: In an ordinal election, two candidates are said to be perfect clones if every voter ranks them adjacently. The independence of clones axiom then states that removing one of the two clones should not change the election outcome. This axiom has been extensively studied in social choice theory, and several voting rules are known to satisfy it (such as IRV, Ranked Pairs and Schulze). However, perfect clones are unlikely to occur in practice, especially for political elections with many voters.
  In this work, we study different notions of approximate clones in ordinal elections. Informally, two candidates are approximate clones in a preference profile if they are close to being perfect clones. We discuss two measures to quantify this proximity, and we show under which conditions the voting rules that are known to be independent of clones are also independent of approximate clones. In particular, we show that for elections with at least four candidates, none of these rules are independent of approximate clones in the general case. However, we find a more positive result for the case of three candidates. Finally, we conduct an empirical study of approximate clones and independence of approximate clones based on three real-world datasets: votes in local Scottish elections, votes in mini-jury deliberations, and votes of judges in figure skating competitions. We find that approximate clones are common in some contexts, and that the closest two candidates are to being perfect clones, the less likely their removal is to change the election outcome, especially for voting rules that are independent of perfect clones.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20779v1</guid></item><item><title>[cs updates on arXiv.org] The Monotone Priority System: Foundations of Contract-Specific Sequencing</title><link>https://arxiv.org/abs/2601.20783</link><description>arXiv:2601.20783v1 Announce Type: new 
Abstract: Modern blockchain applications benefit from the ability to specify sequencing constraints on the transactions that interact with them. This paper proposes a principled and axiomatically justified way of adding sequencing constraints on smart contract function calls that balances expressivity with the tractability of block production. Specifically, we propose a system in which contract developers are allowed to set an integer global priority for each of their calls, so long as that the call's chosen priority is no higher than the priority of any of its referenced calls. Block builders must then simply sequence transactions in priority order (from high to low priority), breaking ties however they would like. We show that this system is the unique system that satisfies five independent axioms.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20783v1</guid></item><item><title>[cs updates on arXiv.org] REASON: Accelerating Probabilistic Logical Reasoning for Scalable Neuro-Symbolic Intelligence</title><link>https://arxiv.org/abs/2601.20784</link><description>arXiv:2601.20784v1 Announce Type: new 
Abstract: Neuro-symbolic AI systems integrate neural perception with symbolic reasoning to enable data-efficient, interpretable, and robust intelligence beyond purely neural models. Although this compositional paradigm has shown superior performance in domains such as reasoning, planning, and verification, its deployment remains challenging due to severe inefficiencies in symbolic and probabilistic inference. Through systematic analysis of representative neuro-symbolic workloads, we identify probabilistic logical reasoning as the inefficiency bottleneck, characterized by irregular control flow, low arithmetic intensity, uncoalesced memory accesses, and poor hardware utilization on CPUs and GPUs.
  This paper presents REASON, an integrated acceleration framework for probabilistic logical reasoning in neuro-symbolic AI. REASON introduces a unified directed acyclic graph representation that captures common structure across symbolic and probabilistic models, coupled with adaptive pruning and regularization. At the architecture level, REASON features a reconfigurable, tree-based processing fabric optimized for irregular traversal, symbolic deduction, and probabilistic aggregation. At the system level, REASON is tightly integrated with GPU streaming multiprocessors through a programmable interface and multi-level pipeline that efficiently orchestrates compositional execution. Evaluated across six neuro-symbolic workloads, REASON achieves 12-50x speedup and 310-681x energy efficiency over desktop and edge GPUs under TSMC 28 nm node. REASON enables real-time probabilistic logical reasoning, completing end-to-end tasks in 0.8 s with 6 mm2 area and 2.12 W power, demonstrating that targeted acceleration of probabilistic logical reasoning is critical for practical and scalable neuro-symbolic AI and positioning REASON as a foundational system architecture for next-generation cognitive intelligence.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20784v1</guid></item><item><title>[cs updates on arXiv.org] SERA: Soft-Verified Efficient Repository Agents</title><link>https://arxiv.org/abs/2601.20789</link><description>arXiv:2601.20789v1 Announce Type: new 
Abstract: Open-weight coding agents should hold a fundamental advantage over closed-source systems: they can be specialized to private codebases, encoding repository-specific information directly in their weights. Yet the cost and complexity of training has kept this advantage theoretical. We show it is now practical. We present Soft-Verified Efficient Repository Agents (SERA), an efficient method for training coding agents that enables the rapid and cheap creation of agents specialized to private codebases. Using only supervised finetuning (SFT), SERA achieves state-of-the-art results among fully open-source (open data, method, code) models while matching the performance of frontier open-weight models like Devstral-Small-2. Creating SERA models is 26x cheaper than reinforcement learning and 57x cheaper than previous synthetic data methods to reach equivalent performance. Our method, Soft Verified Generation (SVG), generates thousands of trajectories from a single code repository. Combined with cost-efficiency, this enables specialization to private codebases. Beyond repository specialization, we apply SVG to a larger corpus of codebases, generating over 200,000 synthetic trajectories. We use this dataset to provide detailed analysis of scaling laws, ablations, and confounding factors for training coding agents. Overall, we believe our work will greatly accelerate research on open coding agents and showcase the advantage of open-source models that can specialize to private codebases. We release SERA as the first model in Ai2's Open Coding Agents series, along with all our code, data, and Claude Code integration to support the research community.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20789v1</guid></item><item><title>[cs updates on arXiv.org] FAIRT2V: Training-Free Debiasing for Text-to-Video Diffusion Models</title><link>https://arxiv.org/abs/2601.20791</link><description>arXiv:2601.20791v1 Announce Type: new 
Abstract: Text-to-video (T2V) diffusion models have achieved rapid progress, yet their demographic biases, particularly gender bias, remain largely unexplored. We present FairT2V, a training-free debiasing framework for text-to-video generation that mitigates encoder-induced bias without finetuning. We first analyze demographic bias in T2V models and show that it primarily originates from pretrained text encoders, which encode implicit gender associations even for neutral prompts. We quantify this effect with a gender-leaning score that correlates with bias in generated videos.
  Based on this insight, FairT2V mitigates demographic bias by neutralizing prompt embeddings via anchor-based spherical geodesic transformations while preserving semantics. To maintain temporal coherence, we apply debiasing only during early identity-forming steps through a dynamic denoising schedule. We further propose a video-level fairness evaluation protocol combining VideoLLM-based reasoning with human verification. Experiments on the modern T2V model Open-Sora show that FairT2V substantially reduces demographic bias across occupations with minimal impact on video quality.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20791v1</guid></item><item><title>[cs updates on arXiv.org] Jurisdiction as Structural Barrier: How Privacy Policy Organization May Reduce Visibility of Substantive Disclosures</title><link>https://arxiv.org/abs/2601.20792</link><description>arXiv:2601.20792v1 Announce Type: new 
Abstract: Privacy policies are supposed to provide notice. But what if substantive information appears only where users skip it? We identify a structural pattern we call jurisdiction-siloed disclosure: information about data practices appearing in specific, actionable form only within regional compliance sections labeled "California Residents" or "EU/UK Users," while general sections use vague or qualified language for the same practices.
  Our audit of 123 major companies identifies 282 potential instances across 77 companies (62.6% of this purposive sample). A conservative estimate restricted to practice categories validated against OPP-115 human annotations finds 138 instances across 54 companies (44%); post-2018 categories central to our findings await independent validation. If users skip jurisdiction-labeled sections as information foraging theory predicts, users outside regulated jurisdictions would receive less specific information about practices affecting them--a transparency failure operating through document architecture rather than omission.
  We propose universal substantive disclosure: practices affecting all users should appear in the main policy body, with regional sections containing only procedural rights information. This standard finds support in analogous disclosure regimes (securities, truth-in-lending, nutritional labeling) where material information must reach all affected parties. Regulators could operationalize this through the FTC's "clear and conspicuous" standard and GDPR transparency principles.
  This work is hypothesis-generating: we establish that the structural pattern exists and ground the transparency concern in behavioral theory, but direct measurement of jurisdiction-specific section skipping remains the critical validation priority. We release our methodology and annotated dataset to enable replication.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20792v1</guid></item><item><title>[cs updates on arXiv.org] Dissecting Multimodal In-Context Learning: Modality Asymmetries and Circuit Dynamics in modern Transformers</title><link>https://arxiv.org/abs/2601.20796</link><description>arXiv:2601.20796v1 Announce Type: new 
Abstract: Transformer-based multimodal large language models often exhibit in-context learning (ICL) abilities. Motivated by this phenomenon, we ask: how do transformers learn to associate information across modalities from in-context examples? We investigate this question through controlled experiments on small transformers trained on synthetic classification tasks, enabling precise manipulation of data statistics and model architecture. We begin by revisiting core principles of unimodal ICL in modern transformers. While several prior findings replicate, we find that Rotary Position Embeddings (RoPE) increases the data complexity threshold for ICL. Extending to the multimodal setting reveals a fundamental learning asymmetry: when pretrained on high-diversity data from a primary modality, surprisingly low data complexity in the secondary modality suffices for multimodal ICL to emerge. Mechanistic analysis shows that both settings rely on an induction-style mechanism that copies labels from matching in-context exemplars; multimodal training refines and extends these circuits across modalities. Our findings provide a mechanistic foundation for understanding multimodal ICL in modern transformers and introduce a controlled testbed for future investigation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20796v1</guid></item><item><title>[cs updates on arXiv.org] A Methodology for Designing Knowledge-Driven Missions for Robots</title><link>https://arxiv.org/abs/2601.20797</link><description>arXiv:2601.20797v1 Announce Type: new 
Abstract: This paper presents a comprehensive methodology for implementing knowledge graphs in ROS 2 systems, aiming to enhance the efficiency and intelligence of autonomous robotic missions. The methodology encompasses several key steps: defining initial and target conditions, structuring tasks and subtasks, planning their sequence, representing task-related data in a knowledge graph, and designing the mission using a high-level language. Each step builds on the previous one to ensure a cohesive process from initial setup to final execution. A practical implementation within the Aerostack2 framework is demonstrated through a simulated search and rescue mission in a Gazebo environment, where drones autonomously locate a target. This implementation highlights the effectiveness of the methodology in improving decision-making and mission performance by leveraging knowledge graphs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20797v1</guid></item><item><title>[cs updates on arXiv.org] Reinforcement Learning via Self-Distillation</title><link>https://arxiv.org/abs/2601.20802</link><description>arXiv:2601.20802v1 Announce Type: new 
Abstract: Large language models are increasingly post-trained with reinforcement learning in verifiable domains such as code and math. Yet, current methods for reinforcement learning with verifiable rewards (RLVR) learn only from a scalar outcome reward per attempt, creating a severe credit-assignment bottleneck. Many verifiable environments actually provide rich textual feedback, such as runtime errors or judge evaluations, that explain why an attempt failed. We formalize this setting as reinforcement learning with rich feedback and introduce Self-Distillation Policy Optimization (SDPO), which converts tokenized feedback into a dense learning signal without any external teacher or explicit reward model. SDPO treats the current model conditioned on feedback as a self-teacher and distills its feedback-informed next-token predictions back into the policy. In this way, SDPO leverages the model's ability to retrospectively identify its own mistakes in-context. Across scientific reasoning, tool use, and competitive programming on LiveCodeBench v6, SDPO improves sample efficiency and final accuracy over strong RLVR baselines. Notably, SDPO also outperforms baselines in standard RLVR environments that only return scalar feedback by using successful rollouts as implicit feedback for failed attempts. Finally, applying SDPO to individual questions at test time accelerates discovery on difficult binary-reward tasks, achieving the same discovery probability as best-of-k sampling or multi-turn conversations with 3x fewer attempts.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20802v1</guid></item><item><title>[cs updates on arXiv.org] Structured Semantic Information Helps Retrieve Better Examples for In-Context Learning in Few-Shot Relation Extraction</title><link>https://arxiv.org/abs/2601.20803</link><description>arXiv:2601.20803v1 Announce Type: new 
Abstract: This paper presents several strategies to automatically obtain additional examples for in-context learning of one-shot relation extraction. Specifically, we introduce a novel strategy for example selection, in which new examples are selected based on the similarity of their underlying syntactic-semantic structure to the provided one-shot example. We show that this method results in complementary word choices and sentence structures when compared to LLM-generated examples. When these strategies are combined, the resulting hybrid system achieves a more holistic picture of the relations of interest than either method alone. Our framework transfers well across datasets (FS-TACRED and FS-FewRel) and LLM families (Qwen and Gemma). Overall, our hybrid selection method consistently outperforms alternative strategies and achieves state-of-the-art performance on FS-TACRED and strong gains on a customized FewRel subset.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20803v1</guid></item><item><title>[cs updates on arXiv.org] How Disciplinary Partnerships Shape Research Landscape in U.S. Library and Information Science Schools</title><link>https://arxiv.org/abs/2601.20806</link><description>arXiv:2601.20806v1 Announce Type: new 
Abstract: This study provides the first comprehensive empirical mapping of how organizational structures and research portfolios co-occur across U.S. Library and Information Science (LIS) schools. Analyzing 14,705 publications from 1,264 faculty members across 44 institutions (2013--2024), we employ computational methods including word embeddings and topic modeling to identify 16 distinct research themes organized into three foundational dimensions: Library and Knowledge Organization (LKO), Human-Centered Technology (HCT), and Computing Systems (CS). Our mixed-method analysis reveals significant differences in research composition across organizational types: Computer-affiliated schools cluster tightly in computationally-intensive research and differ significantly from all other school types, while independent Information schools demonstrate the greatest research diversity. Temporal analysis of LIS schools reveals complex evolutionary dynamics: 51.4% are moving toward HCT, 37.8% toward CS, and 37.8% toward LKO, with many schools simultaneously shifting along multiple dimensions. Contrary to narratives of computational dominance, HCT emerged as LIS's primary growth vector. These patterns challenge assumptions about field fragmentation, revealing structured diversification shaped by but not determined by organizational positioning. The study provides empirical foundations for institutional strategic planning, accreditation policy, and understanding LIS's evolving disciplinary identity amid computational transformation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20806v1</guid></item><item><title>[cs updates on arXiv.org] Context-Augmented Code Generation Using Programming Knowledge Graphs</title><link>https://arxiv.org/abs/2601.20810</link><description>arXiv:2601.20810v1 Announce Type: new 
Abstract: Large Language Models (LLMs) excel at code generation but struggle with complex problems. Retrieval-Augmented Generation (RAG) mitigates this issue by integrating external knowledge, yet retrieval models often miss relevant context, and generation models hallucinate with irrelevant data. We propose Programming Knowledge Graph (PKG) for semantic representation and fine-grained retrieval of code and text. Our approach enhances retrieval precision through tree pruning and mitigates hallucinations via a re-ranking mechanism that integrates non-RAG solutions. Structuring external data into finer-grained nodes improves retrieval granularity. Evaluations on HumanEval and MBPP show up to 20% pass@1 accuracy gains and a 34% improvement over baselines on MBPP. Our findings demonstrate that our proposed PKG approach along with re-ranker effectively address complex problems while maintaining minimal negative impact on solutions that are already correct without RAG. The replication package is published at https://github.com/iamshahd/ProgrammingKnowledgeGraph</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20810v1</guid></item><item><title>[cs updates on arXiv.org] GNN Explanations that do not Explain and How to find Them</title><link>https://arxiv.org/abs/2601.20815</link><description>arXiv:2601.20815v1 Announce Type: new 
Abstract: Explanations provided by Self-explainable Graph Neural Networks (SE-GNNs) are fundamental for understanding the model's inner workings and for identifying potential misuse of sensitive attributes. Although recent works have highlighted that these explanations can be suboptimal and potentially misleading, a characterization of their failure cases is unavailable. In this work, we identify a critical failure of SE-GNN explanations: explanations can be unambiguously unrelated to how the SE-GNNs infer labels. We show that, on the one hand, many SE-GNNs can achieve optimal true risk while producing these degenerate explanations, and on the other, most faithfulness metrics can fail to identify these failure modes. Our empirical analysis reveals that degenerate explanations can be maliciously planted (allowing an attacker to hide the use of sensitive attributes) and can also emerge naturally, highlighting the need for reliable auditing. To address this, we introduce a novel faithfulness metric that reliably marks degenerate explanations as unfaithful, in both malicious and natural settings. Our code is available in the supplemental.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20815v1</guid></item><item><title>[cs updates on arXiv.org] Repeater-Assisted Massive MIMO Full-Duplex Communications</title><link>https://arxiv.org/abs/2601.20822</link><description>arXiv:2601.20822v1 Announce Type: new 
Abstract: We consider a wireless network comprising multiple singleantenna repeaters that amplify and instantaneously re-transmit received signals in a full-duplex (FD) communication setting. Specifically, we study a massive multiple-input multiple output base station that simultaneously serves multiple uplink (UL) and downlink (DL) user equipment (UE) over the same frequency band. The focus is on the problem of repeater weight optimization at each active repeater to maximize the sum of the weighted minimum spectral efficiencies (SEs) for both UL and DL UEs. The resulting non-convex optimization problem is tackled using a successive convex approximation technique. To demonstrate the effectiveness of the proposed approach, we evaluate its performance against benchmark systems with and without repeater assistance. The optimized FD design achieves SE improvements of up to 4-fold and 2.5-fold compared to its half-duplex counterpart.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20822v1</guid></item><item><title>[cs updates on arXiv.org] Construction and Decoding of Convolutional Codes with optimal Column Distances</title><link>https://arxiv.org/abs/2601.20825</link><description>arXiv:2601.20825v1 Announce Type: new 
Abstract: The construction of Maximum Distance Profile (MDP) convolutional codes in general requires the use of very large finite fields. In contrast convolutional codes with optimal column distances maximize the column distances for a given arbitrary finite field. In this paper, we present a construction of such convolutional codes. In addition, we prove that for the considered parameters the codes that we constructed are the only ones achieving optimal column distances. The structure of the presented convolutional codes with optimal column distances is strongly related to first order Reed-Muller block codes and we leverage this fact to develop a reduced complexity version of the Viterbi algorithm for these codes.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20825v1</guid></item><item><title>[cs updates on arXiv.org] Low-Complexity Pilot-Aided Doppler Ambiguity Estimation for OTFS Parametric Channel Estimation</title><link>https://arxiv.org/abs/2601.20827</link><description>arXiv:2601.20827v1 Announce Type: new 
Abstract: Orthogonal Time Frequency Space (OTFS) modulation offers robust performance in high-mobility scenarios by transforming time-varying channels into the delay-Doppler (DD) domain. However, in high-mobility environment such as emerging 5G Non-Terrestrial Networks (NTN), the extreme orbital velocities of Low Earth Orbit (LEO) satellites frequently cause the physical Doppler shifts to exceed the fundamental grid range. This Doppler ambiguity induces severe model mismatch and renders traditional MLE channel estimators ineffective. To address this challenge, this paper proposes a novel low-complexity pilot-aided Doppler ambiguity detection and compensation framework. We first mathematically derive the OTFS input-output relationship in the presence of aliasing, revealing that Doppler ambiguity manifests itself as a distinct phase rotation along the delay dimension. Leveraging this insight, we developed a two-stage estimator that utilizes pairwise phase differences between pilot symbols to identify the integer ambiguity, followed by a refined Maximum Likelihood Estimation (MLE) for channel recovery. We investigate two pilot arrangements, Embedded Pilot with Guard Zone (EP-GZ) and Data-Surrounded Pilot (DSP), to analyze the trade-off between interference suppression and spectral efficiency. Simulation results demonstrate that the proposed scheme effectively eliminates the error floor caused by ambiguity, achieving Bit Error Rate (BER) and Normalized Mean Square Error (NMSE) performance comparable to the exhaustive search benchmark while maintaining a computational complexity similar to standard MLE.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20827v1</guid></item><item><title>[cs updates on arXiv.org] Training Reasoning Models on Saturated Problems via Failure-Prefix Conditioning</title><link>https://arxiv.org/abs/2601.20829</link><description>arXiv:2601.20829v1 Announce Type: new 
Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has substantially improved the reasoning abilities of large language models (LLMs), yet training often stalls as problems become saturated. We identify the core challenge as the poor accessibility of informative failures: learning signals exist but are rarely encountered during standard rollouts. To address this, we propose failure-prefix conditioning, a simple and effective method for learning from saturated problems. Rather than starting from the original question, our approach reallocates exploration by conditioning training on prefixes derived from rare incorrect reasoning trajectories, thereby exposing the model to failure-prone states. We observe that failure-prefix conditioning yields performance gains matching those of training on medium-difficulty problems, while preserving token efficiency. Furthermore, we analyze the model's robustness, finding that our method reduces performance degradation under misleading failure prefixes, albeit with a mild trade-off in adherence to correct early reasoning. Finally, we demonstrate that an iterative approach, which refreshes failure prefixes during training, unlocks additional gains after performance plateaus. Overall, our results suggest that failure-prefix conditioning offers an effective pathway to extend RLVR training on saturated problems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20829v1</guid></item><item><title>[cs updates on arXiv.org] MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents</title><link>https://arxiv.org/abs/2601.20831</link><description>arXiv:2601.20831v1 Announce Type: new 
Abstract: Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents that are expected to operate under strict memory and compute constraints, online. In this work, we propose MemCtrl, a novel framework that uses Multimodal Large Language Models (MLLMs) for pruning memory online. MemCtrl augments MLLMs with a trainable memory head \mu that acts as a gate to determine which observations or reflections to retain, update, or discard during exploration. We evaluate with training two types of \mu, 1) via an offline expert, and 2) via online RL, and observe significant improvement in overall embodied task completion ability on \mu-augmented MLLMs. In particular, on augmenting two low performing MLLMs with MemCtrl on multiple subsets of the EmbodiedBench benchmark, we observe that \mu-augmented MLLMs show an improvement of around 16% on average, with over 20% on specific instruction subsets. Finally, we present a qualitative analysis on the memory fragments collected by \mu, noting the superior performance of \mu augmented MLLMs on long and complex instruction types.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20831v1</guid></item><item><title>[cs updates on arXiv.org] Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives</title><link>https://arxiv.org/abs/2601.20833</link><description>arXiv:2601.20833v1 Announce Type: new 
Abstract: Autonomous scientific discovery with large language model (LLM)-based agents has recently made substantial progress, demonstrating the ability to automate end-to-end research workflows. However, existing systems largely rely on runtime-centric execution paradigms, repeatedly reading, summarizing, and reasoning over large volumes of scientific literature online. This on-the-spot computation strategy incurs high computational cost, suffers from context window limitations, and often leads to brittle reasoning and hallucination. We propose Idea2Story, a pre-computation-driven framework for autonomous scientific discovery that shifts literature understanding from online reasoning to offline knowledge construction. Idea2Story continuously collects peer-reviewed papers together with their review feedback, extracts core methodological units, composes reusable research patterns, and organizes them into a structured methodological knowledge graph. At runtime, underspecified user research intents are aligned to established research paradigms, enabling efficient retrieval and reuse of high-quality research patterns instead of open-ended generation and trial-and-error. By grounding research planning and execution in a pre-built knowledge graph, Idea2Story alleviates the context window bottleneck of LLMs and substantially reduces repeated runtime reasoning over literature. We conduct qualitative analyses and preliminary empirical studies demonstrating that Idea2Story can generate coherent, methodologically grounded, and novel research patterns, and can produce several high-quality research demonstrations in an end-to-end setting. These results suggest that offline knowledge construction provides a practical and scalable foundation for reliable autonomous scientific discovery.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20833v1</guid></item><item><title>[cs updates on arXiv.org] Linear representations in language models can change dramatically over a conversation</title><link>https://arxiv.org/abs/2601.20834</link><description>arXiv:2601.20834v1 Announce Type: new 
Abstract: Language model representations often contain linear directions that correspond to high-level concepts. Here, we study the dynamics of these representations: how representations evolve along these dimensions within the context of (simulated) conversations. We find that linear representations can change dramatically over a conversation; for example, information that is represented as factual at the beginning of a conversation can be represented as non-factual at the end and vice versa. These changes are content-dependent; while representations of conversation-relevant information may change, generic information is generally preserved. These changes are robust even for dimensions that disentangle factuality from more superficial response patterns, and occur across different model families and layers of the model. These representation changes do not require on-policy conversations; even replaying a conversation script written by an entirely different model can produce similar changes. However, adaptation is much weaker from simply having a sci-fi story in context that is framed more explicitly as such. We also show that steering along a representational direction can have dramatically different effects at different points in a conversation. These results are consistent with the idea that representations may evolve in response to the model playing a particular role that is cued by a conversation. Our findings may pose challenges for interpretability and steering -- in particular, they imply that it may be misleading to use static interpretations of features or directions, or probes that assume a particular range of features consistently corresponds to a particular ground-truth value. However, these types of representational dynamics also point to exciting new research directions for understanding how models adapt to context.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20834v1</guid></item><item><title>[cs updates on arXiv.org] Open-Vocabulary Functional 3D Human-Scene Interaction Generation</title><link>https://arxiv.org/abs/2601.20835</link><description>arXiv:2601.20835v1 Announce Type: new 
Abstract: Generating 3D humans that functionally interact with 3D scenes remains an open problem with applications in embodied AI, robotics, and interactive content creation. The key challenge involves reasoning about both the semantics of functional elements in 3D scenes and the 3D human poses required to achieve functionality-aware interaction. Unfortunately, existing methods typically lack explicit reasoning over object functionality and the corresponding human-scene contact, resulting in implausible or functionally incorrect interactions. In this work, we propose FunHSI, a training-free, functionality-driven framework that enables functionally correct human-scene interactions from open-vocabulary task prompts. Given a task prompt, FunHSI performs functionality-aware contact reasoning to identify functional scene elements, reconstruct their 3D geometry, and model high-level interactions via a contact graph. We then leverage vision-language models to synthesize a human performing the task in the image and estimate proposed 3D body and hand poses. Finally, the proposed 3D body configuration is refined via stage-wise optimization to ensure physical plausibility and functional correctness. In contrast to existing methods, FunHSI not only synthesizes more plausible general 3D interactions, such as "sitting on a sofa'', while supporting fine-grained functional human-scene interactions, e.g., "increasing the room temperature''. Extensive experiments demonstrate that FunHSI consistently generates functionally correct and physically plausible human-scene interactions across diverse indoor and outdoor scenes.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20835v1</guid></item><item><title>[cs updates on arXiv.org] Reward Models Inherit Value Biases from Pretraining</title><link>https://arxiv.org/abs/2601.20838</link><description>arXiv:2601.20838v1 Announce Type: new 
Abstract: Reward models (RMs) are central to aligning large language models (LLMs) with human values but have received less attention than pre-trained and post-trained LLMs themselves. Because RMs are initialized from LLMs, they inherit representations that shape their behavior, but the nature and extent of this influence remain understudied. In a comprehensive study of 10 leading open-weight RMs using validated psycholinguistic corpora, we show that RMs exhibit significant differences along multiple dimensions of human value as a function of their base model. Using the "Big Two" psychological axes, we show a robust preference of Llama RMs for "agency" and a corresponding robust preference of Gemma RMs for "communion." This phenomenon holds even when the preference data and finetuning process are identical, and we trace it back to the logits of the respective instruction-tuned and pre-trained models. These log-probability differences themselves can be formulated as an implicit RM; we derive usable implicit reward scores and show that they exhibit the very same agency/communion difference. We run experiments training RMs with ablations for preference data source and quantity, which demonstrate that this effect is not only repeatable but surprisingly durable. Despite RMs being designed to represent human preferences, our evidence shows that their outputs are influenced by the pretrained LLMs on which they are based. This work underscores the importance of safety and alignment efforts at the pretraining stage, and makes clear that open-source developers' choice of base model is as much a consideration of values as of performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20838v1</guid></item><item><title>[cs updates on arXiv.org] Fast Solvers for the Reynolds Equation on Piecewise Linear Geometries</title><link>https://arxiv.org/abs/2601.20841</link><description>arXiv:2601.20841v1 Announce Type: new 
Abstract: The Reynolds equation is derived from the incompressible Navier Stokes equations under the lubrication assumptions of a long and thin domain geometry and a small scaled Reynolds number. The Reynolds equation is an elliptic differential equation and a dramatic simplification from the governing equations. When the fluid domain is piecewise linear, the Reynolds equation has an exact solution that we formulate by coupling the exact solutions of each piecewise component. We consider a formulation specifically for piecewise constant heights, and a more general formulation for piecewise linear heights; in both cases the linear system is inverted using the Schur complement. These methods can also be applied in the case of non-linear heights by approximating the height as piecewise constant or piecewise linear, in which case the methods achieve second order accuracy. We assess the time complexity of the two methods, and determine that the method for piecewise linear heights is linear time for the number of piecewise components. As an application of these methods, we explore the limits of validity for lubrication theory by comparing the solutions of the Reynolds and the Stokes equations for a variety of linear and non-linear textured slider geometries.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20841v1</guid></item><item><title>[cs updates on arXiv.org] Deep Researcher with Sequential Plan Reflection and Candidates Crossover (Deep Researcher Reflect Evolve)</title><link>https://arxiv.org/abs/2601.20843</link><description>arXiv:2601.20843v1 Announce Type: new 
Abstract: This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm. Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm. The sequential refinement process is demonstrated as an efficient method that allows the agent to maintain a centralized Global Research Context, enabling it to look back at current progress, reason about the research plan, and intelligently make changes at runtime. This dynamic adaptation contrasts with parallel approaches, which often suffer from siloed knowledge. The Candidates Crossover algorithm further enhances search efficiency by deploying multiple LLM candidates with varied parameters to explore a larger search space, with their findings synthesized to curate a comprehensive final research response. The process concludes with One Shot Report Generation, ensuring the final document is informed by a unified narrative and high fact density. Powered by the Gemini 2.5 Pro model, our Deep Researcher was evaluated on the DeepResearch Bench, a globally recognized benchmark of 100 doctoral level research tasks. Our architecture achieved an overall score of 46.21, demonstrating superior performance by surpassing leading deep research agents such as Claude Researcher, Nvidia AIQ Research Assistant, Perplexity Research, Kimi Researcher and Grok Deeper Search present on the DeepResearch Bench actively running leaderboard. This performance marginally exceeds our previous work, Static DRA, and reinforces the finding that sequential scaling consistently outperforms the parallel self consistency paradigm.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20843v1</guid></item><item><title>[cs updates on arXiv.org] $\mathbb{R}^{2k}$ is Theoretically Large Enough for Embedding-based Top-$k$ Retrieval</title><link>https://arxiv.org/abs/2601.20844</link><description>arXiv:2601.20844v1 Announce Type: new 
Abstract: This paper studies the minimal dimension required to embed subset memberships ($m$ elements and ${m\choose k}$ subsets of at most $k$ elements) into vector spaces, denoted as Minimal Embeddable Dimension (MED). The tight bounds of MED are derived theoretically and supported empirically for various notions of "distances" or "similarities," including the $\ell_2$ metric, inner product, and cosine similarity. In addition, we conduct numerical simulation in a more achievable setting, where the ${m\choose k}$ subset embeddings are chosen as the centroid of the embeddings of the contained elements. Our simulation easily realizes a logarithmic dependency between the MED and the number of elements to embed. These findings imply that embedding-based retrieval limitations stem primarily from learnability challenges, not geometric constraints, guiding future algorithm design.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20844v1</guid></item><item><title>[cs updates on arXiv.org] PatchFormer: A Patch-Based Time Series Foundation Model with Hierarchical Masked Reconstruction and Cross-Domain Transfer Learning for Zero-Shot Multi-Horizon Forecasting</title><link>https://arxiv.org/abs/2601.20845</link><description>arXiv:2601.20845v1 Announce Type: new 
Abstract: Time series forecasting is a fundamental problem with applications in climate, energy, healthcare, and finance. Many existing approaches require domain-specific feature engineering and substantial labeled data for each task. We introduce PatchFormer, a patch-based time series foundation model that uses hierarchical masked reconstruction for self-supervised pretraining and lightweight adapters for efficient transfer. PatchFormer segments time series into patches and learns multiscale temporal representations with learnable aggregation across temporal scales. Pretraining uses masked patch reconstruction with dynamic masking and objectives that encourage both local accuracy and global consistency, followed by cross-domain knowledge distillation. Experiments on 24 benchmark datasets spanning weather, energy, traffic, finance, and healthcare demonstrate state-of-the-art zero-shot multi-horizon forecasting, reducing mean squared error by 27.3 percent relative to strong baselines while requiring 94 percent less task-specific training data. The model exhibits near log-linear scaling with more pretraining data up to 100 billion points and processes length-512 sequences 3.8x faster than full-sequence transformers.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20845v1</guid></item><item><title>[cs updates on arXiv.org] End-to-end example-based sim-to-real RL policy transfer based on neural stylisation with application to robotic cutting</title><link>https://arxiv.org/abs/2601.20846</link><description>arXiv:2601.20846v1 Announce Type: new 
Abstract: Whereas reinforcement learning has been applied with success to a range of robotic control problems in complex, uncertain environments, reliance on extensive data - typically sourced from simulation environments - limits real-world deployment due to the domain gap between simulated and physical systems, coupled with limited real-world sample availability. We propose a novel method for sim-to-real transfer of reinforcement learning policies, based on a reinterpretation of neural style transfer from image processing to synthesise novel training data from unpaired unlabelled real world datasets. We employ a variational autoencoder to jointly learn self-supervised feature representations for style transfer and generate weakly paired source-target trajectories to improve physical realism of synthesised trajectories. We demonstrate the application of our approach based on the case study of robot cutting of unknown materials. Compared to baseline methods, including our previous work, CycleGAN, and conditional variational autoencoder-based time series translation, our approach achieves improved task completion time and behavioural stability with minimal real-world data. Our framework demonstrates robustness to geometric and material variation, and highlights the feasibility of policy adaptation in challenging contact-rich tasks where real-world reward information is unavailable.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20846v1</guid></item><item><title>[cs updates on arXiv.org] A New Dataset and Framework for Robust Road Surface Classification via Camera-IMU Fusion</title><link>https://arxiv.org/abs/2601.20847</link><description>arXiv:2601.20847v1 Announce Type: new 
Abstract: Road surface classification (RSC) is a key enabler for environment-aware predictive maintenance systems. However, existing RSC techniques often fail to generalize beyond narrow operational conditions due to limited sensing modalities and datasets that lack environmental diversity. This work addresses these limitations by introducing a multimodal framework that fuses images and inertial measurements using a lightweight bidirectional cross-attention module followed by an adaptive gating layer that adjusts modality contributions under domain shifts. Given the limitations of current benchmarks, especially regarding lack of variability, we introduce ROAD, a new dataset composed of three complementary subsets: (i) real-world multimodal recordings with RGB-IMU streams synchronized using a gold-standard industry datalogger, captured across diverse lighting, weather, and surface conditions; (ii) a large vision-only subset designed to assess robustness under adverse illumination and heterogeneous capture setups; and (iii) a synthetic subset generated to study out-of-distribution generalization in scenarios difficult to obtain in practice. Experiments show that our method achieves a +1.4 pp improvement over the previous state-of-the-art on the PVS benchmark and an +11.6 pp improvement on our multimodal ROAD subset, with consistently higher F1-scores on minority classes. The framework also demonstrates stable performance across challenging visual conditions, including nighttime, heavy rain, and mixed-surface transitions. These findings indicate that combining affordable camera and IMU sensors with multimodal attention mechanisms provides a scalable, robust foundation for road surface understanding, particularly relevant for regions where environmental variability and cost constraints limit the adoption of high-end sensing suites.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20847v1</guid></item><item><title>[cs updates on arXiv.org] Post-Training Fairness Control: A Single-Train Framework for Dynamic Fairness in Recommendation</title><link>https://arxiv.org/abs/2601.20848</link><description>arXiv:2601.20848v1 Announce Type: new 
Abstract: Despite growing efforts to mitigate unfairness in recommender systems, existing fairness-aware methods typically fix the fairness requirement at training time and provide limited post-training flexibility. However, in real-world scenarios, diverse stakeholders may demand differing fairness requirements over time, so retraining for different fairness requirements becomes prohibitive. To address this limitation, we propose Cofair, a single-train framework that enables post-training fairness control in recommendation. Specifically, Cofair introduces a shared representation layer with fairness-conditioned adapter modules to produce user embeddings specialized for varied fairness levels, along with a user-level regularization term that guarantees user-wise monotonic fairness improvements across these levels. We theoretically establish that the adversarial objective of Cofair upper bounds demographic parity and the regularization term enforces progressive fairness at user level. Comprehensive experiments on multiple datasets and backbone models demonstrate that our framework provides dynamic fairness at different levels, delivering comparable or better fairness-accuracy curves than state-of-the-art baselines, without the need to retrain for each new fairness requirement. Our code is publicly available at https://github.com/weixinchen98/Cofair.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20848v1</guid></item><item><title>[cs updates on arXiv.org] C3Box: A CLIP-based Class-Incremental Learning Toolbox</title><link>https://arxiv.org/abs/2601.20852</link><description>arXiv:2601.20852v1 Announce Type: new 
Abstract: Traditional machine learning systems are typically designed for static data distributions, which suffer from catastrophic forgetting when learning from evolving data streams. Class-Incremental Learning (CIL) addresses this challenge by enabling learning systems to continuously learn new classes while preserving prior knowledge. With the rise of pre-trained models (PTMs) such as CLIP, leveraging their strong generalization and semantic alignment capabilities has become a promising direction in CIL. However, existing CLIP-based CIL methods are often scattered across disparate codebases, rely on inconsistent configurations, hindering fair comparisons, reproducibility, and practical adoption. Therefore, we propose C3Box (CLIP-based Class-inCremental learning toolBOX), a modular and comprehensive Python toolbox. C3Box integrates representative traditional CIL methods, ViT-based CIL methods, and state-of-the-art CLIP-based CIL methods into a unified CLIP-based framework. By inheriting the streamlined design of PyCIL, C3Box provides a JSON-based configuration and standardized execution pipeline. This design enables reproducible experimentation with low engineering overhead and makes C3Box a reliable benchmark platform for continual learning research. Designed to be user-friendly, C3Box relies only on widely used open-source libraries and supports major operating systems. The code is available at https://github.com/LAMDA-CL/C3Box.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20852v1</guid></item><item><title>[cs updates on arXiv.org] Exploring Transformer Placement in Variational Autoencoders for Tabular Data Generation</title><link>https://arxiv.org/abs/2601.20854</link><description>arXiv:2601.20854v1 Announce Type: new 
Abstract: Tabular data remains a challenging domain for generative models. In particular, the standard Variational Autoencoder (VAE) architecture, typically composed of multilayer perceptrons, struggles to model relationships between features, especially when handling mixed data types. In contrast, Transformers, through their attention mechanism, are better suited for capturing complex feature interactions. In this paper, we empirically investigate the impact of integrating Transformers into different components of a VAE. We conduct experiments on 57 datasets from the OpenML CC18 suite and draw two main conclusions. First, results indicate that positioning Transformers to leverage latent and decoder representations leads to a trade-off between fidelity and diversity. Second, we observe a high similarity between consecutive blocks of a Transformer in all components. In particular, in the decoder, the relationship between the input and output of a Transformer is approximately linear.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20854v1</guid></item><item><title>[cs updates on arXiv.org] SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language Models</title><link>https://arxiv.org/abs/2601.20856</link><description>arXiv:2601.20856v1 Announce Type: new 
Abstract: Although the capabilities of large language models have been increasingly tested on complex reasoning tasks, their long-horizon planning abilities have not yet been extensively investigated. In this work, we provide a systematic assessment of the planning and long-horizon reasoning capabilities of state-of-the-art Large Reasoning Models (LRMs). We propose a novel benchmark based on Sokoban puzzles, intentionally simplified to isolate long-horizon planning from state persistence. Our findings reveal a consistent degradation in planning performance when more than 25 moves are required to reach the solution, suggesting a fundamental constraint on forward planning capacity. We show that equipping LRMs with Planning Domain Definition Language (PDDL) parsing, validation, and solving tools allows for modest improvements, suggesting inherent architectural limitations which might not be overcome by test-time scaling approaches alone.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20856v1</guid></item><item><title>[cs updates on arXiv.org] FreeFix: Boosting 3D Gaussian Splatting via Fine-Tuning-Free Diffusion Models</title><link>https://arxiv.org/abs/2601.20857</link><description>arXiv:2601.20857v1 Announce Type: new 
Abstract: Neural Radiance Fields and 3D Gaussian Splatting have advanced novel view synthesis, yet still rely on dense inputs and often degrade at extrapolated views. Recent approaches leverage generative models, such as diffusion models, to provide additional supervision, but face a trade-off between generalization and fidelity: fine-tuning diffusion models for artifact removal improves fidelity but risks overfitting, while fine-tuning-free methods preserve generalization but often yield lower fidelity. We introduce FreeFix, a fine-tuning-free approach that pushes the boundary of this trade-off by enhancing extrapolated rendering with pretrained image diffusion models. We present an interleaved 2D-3D refinement strategy, showing that image diffusion models can be leveraged for consistent refinement without relying on costly video diffusion models. Furthermore, we take a closer look at the guidance signal for 2D refinement and propose a per-pixel confidence mask to identify uncertain regions for targeted improvement. Experiments across multiple datasets show that FreeFix improves multi-frame consistency and achieves performance comparable to or surpassing fine-tuning-based methods, while retaining strong generalization ability.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20857v1</guid></item><item><title>[cs updates on arXiv.org] When Flores Bloomz Wrong: Cross-Direction Contamination in Machine Translation Evaluation</title><link>https://arxiv.org/abs/2601.20858</link><description>arXiv:2601.20858v1 Announce Type: new 
Abstract: Large language models (LLMs) can be benchmark-contaminated, resulting in inflated scores that mask memorization as generalization, and in multilingual settings, this memorization can even transfer to "uncontaminated" languages. Using the FLORES-200 translation benchmark as a diagnostic, we study two 7-8B instruction-tuned multilingual LLMs: Bloomz, which was trained on FLORES, and Llama as an uncontaminated control. We confirm Bloomz's FLORES contamination and demonstrate that machine translation contamination can be cross-directional, artificially boosting performance in unseen translation directions due to target-side memorization. Further analysis shows that recall of memorized references often persists despite various source-side perturbation efforts like paraphrasing and named entity replacement. However, replacing named entities leads to a consistent decrease in BLEU, suggesting an effective probing method for memorization in contaminated models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20858v1</guid></item><item><title>[cs updates on arXiv.org] Evolutionary Strategies lead to Catastrophic Forgetting in LLMs</title><link>https://arxiv.org/abs/2601.20861</link><description>arXiv:2601.20861v1 Announce Type: new 
Abstract: One of the biggest missing capabilities in current AI systems is the ability to learn continuously after deployment. Implementing such continually learning systems have several challenges, one of which is the large memory requirement of gradient-based algorithms that are used to train state-of-the-art LLMs. Evolutionary Strategies (ES) have recently re-emerged as a gradient-free alternative to traditional learning algorithms and have shown encouraging performance on specific tasks in LLMs. In this paper, we perform a comprehensive analysis of ES and specifically evaluate its forgetting curves when training for an increasing number of update steps. We first find that ES is able to reach performance numbers close to GRPO for math and reasoning tasks with a comparable compute budget. However, and most importantly for continual learning, the performance gains in ES is accompanied by significant forgetting of prior abilities, limiting its applicability for training models online. We also explore the reason behind this behavior and show that the updates made using ES are much less sparse and have orders of magnitude larger $\ell_2$ norm compared to corresponding GRPO updates, explaining the contrasting forgetting curves between the two algorithms. With this study, we aim to highlight the issue of forgetting in gradient-free algorithms like ES and hope to inspire future work to mitigate these issues.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20861v1</guid></item><item><title>[cs updates on arXiv.org] Critical Transit Infrastructure in Smart Cities and Urban Air Quality: A Multi-City Seasonal Comparison of Ridership and PM2.5</title><link>https://arxiv.org/abs/2601.19937</link><description>arXiv:2601.19937v1 Announce Type: cross 
Abstract: Public transit is a critical component of urban mobility and equity, yet mobility and air-quality linkages are rarely operationalized in reproducible smart-city analytics workflows. This study develops a transparent, multi-source monitoring dataset that integrates agency-reported transit ridership with ambient fine particulate matter PM2.5 from the U.S. EPA Air Quality System (AQS) for four U.S. metropolitan areas - New York City, Chicago, Las Vegas, and Phoenix, using two seasonal snapshots (March and October 2024). We harmonize heterogeneous ridership feeds (daily and stop-level) to monthly system totals and pair them with monthly mean PM2.5 , reporting both absolute and per-capita metrics to enable cross-city comparability. Results show pronounced structural differences in transit scale and intensity, with consistent seasonal shifts in both ridership and PM2.5 that vary by urban context. A set of lightweight regression specifications is used as a descriptive sensitivity analysis, indicating that apparent mobility-PM2.5 relationships are not uniform across cities or seasons and are strongly shaped by baseline city effects. Overall, the paper positions integrated mobility and environment monitoring as a practical smart-city capability, offering a scalable framework for tracking infrastructure utilization alongside exposure-relevant air-quality indicators to support sustainable communities and public-health-aware urban resilience.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19937v1</guid></item><item><title>[cs updates on arXiv.org] MK-SGC-SC: Multiple Kernel guided Sparse Graph Construction in Spectral Clustering for Unsupervised Speaker Diarization</title><link>https://arxiv.org/abs/2601.19946</link><description>arXiv:2601.19946v1 Announce Type: cross 
Abstract: Speaker diarization aims to segment audio recordings into regions corresponding to individual speakers. Although unsupervised speaker diarization is inherently challenging, the prospect of identifying speaker regions without pretraining or weak supervision motivates research on clustering techniques. In this work, we share the notable observation that measuring multiple kernel similarities of speaker embeddings to thereafter craft a sparse graph for spectral clustering in a principled manner is sufficient to achieve state-of-the-art performances in a fully unsupervised setting. Specifically, we consider four polynomial kernels and a degree one arccosine kernel to measure similarities in speaker embeddings, using which sparse graphs are constructed in a principled manner to emphasize local similarities. Experiments show the proposed approach excels in unsupervised speaker diarization over a variety of challenging environments in the DIHARD-III, AMI, and VoxConverse corpora. To encourage further research, our implementations are available at https://github.com/nikhilraghav29/MK-SGC-SC.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19946v1</guid></item><item><title>[cs updates on arXiv.org] VoxPrivacy: A Benchmark for Evaluating Interactional Privacy of Speech Language Models</title><link>https://arxiv.org/abs/2601.19956</link><description>arXiv:2601.19956v1 Announce Type: cross 
Abstract: As Speech Language Models (SLMs) transition from personal devices to shared, multi-user environments such as smart homes, a new challenge emerges: the model is expected to distinguish between users to manage information flow appropriately. Without this capability, an SLM could reveal one user's confidential schedule to another, a privacy failure we term interactional privacy. Thus, the ability to generate speaker-aware responses becomes essential for SLM safe deployment. Current SLM benchmarks test dialogue ability but overlook speaker identity. Multi-speaker benchmarks check who said what without assessing whether SLMs adapt their responses. Privacy benchmarks focus on globally sensitive data (e.g., bank passwords) while neglecting contextual privacy-sensitive information (e.g., a user's private appointment). To address this gap, we introduce VoxPrivacy, the first benchmark designed to evaluate interactional privacy in SLMs. VoxPrivacy spans three tiers of increasing difficulty, from following direct secrecy commands to proactively protecting privacy. Our evaluation of nine SLMs on a 32-hour bilingual dataset reveals a widespread vulnerability: most open-source models perform close to random chance (around 50% accuracy) on conditional privacy decisions, while even strong closed-source systems fall short on proactive privacy inference. We further validate these findings on Real-VoxPrivacy, a human-recorded subset, confirming that failures observed on synthetic data persist in real speech. Finally, we demonstrate a viable path forward: by fine-tuning on a new 4,000-hour training set, we improve privacy-preserving abilities while maintaining robustness. To support future work, we release the VoxPrivacy benchmark, the large-scale training set, and the fine-tuned model to foster the development of safer and more context-aware SLMs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19956v1</guid></item><item><title>[cs updates on arXiv.org] Deep Neural Networks as Iterated Function Systems and a Generalization Bound</title><link>https://arxiv.org/abs/2601.19958</link><description>arXiv:2601.19958v1 Announce Type: cross 
Abstract: Deep neural networks (DNNs) achieve remarkable performance on a wide range of tasks, yet their mathematical analysis remains fragmented: stability and generalization are typically studied in disparate frameworks and on a case-by-case basis. Architecturally, DNNs rely on the recursive application of parametrized functions, a mechanism that can be unstable and difficult to train, making stability a primary concern. Even when training succeeds, there are few rigorous results on how well such models generalize beyond the observed data, especially in the generative setting. In this work, we leverage the theory of stochastic Iterated Function Systems (IFS) and show that two important deep architectures can be viewed as, or canonically associated with, place-dependent IFS. This connection allows us to import results from random dynamical systems to (i) establish the existence and uniqueness of invariant measures under suitable contractivity assumptions, and (ii) derive a Wasserstein generalization bound for generative modeling. The bound naturally leads to a new training objective that directly controls the collage-type approximation error between the data distribution and its image under the learned transfer operator. We illustrate the theory on a controlled 2D example and empirically evaluate the proposed objective on standard image datasets (MNIST, CelebA, CIFAR-10).</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19958v1</guid></item><item><title>[cs updates on arXiv.org] Do we really need Self-Attention for Streaming Automatic Speech Recognition?</title><link>https://arxiv.org/abs/2601.19960</link><description>arXiv:2601.19960v1 Announce Type: cross 
Abstract: Transformer-based architectures are the most used architectures in many deep learning fields like Natural Language Processing, Computer Vision or Speech processing. It may encourage the direct use of Transformers in the constrained tasks, without questioning whether it will yield the same benefits as in standard tasks.  Given specific constraints, it is essential to evaluate the relevance of transformer models. This work questions the suitability of transformers for specific domains. We argue that the high computational requirements and latency issues associated with these models do not align well with streaming applications. Our study promotes the search for alternative strategies to improve efficiency without sacrificing performance.  In light of this observation, our paper critically examines the usefulness of transformer architecture in such constrained environments. As a first attempt, we show that the computational cost for Streaming Automatic Speech Recognition (ASR) can be reduced using deformable convolution instead of Self-Attention. Furthermore, we show that Self-Attention mechanisms can be entirely removed and not replaced, without observing significant degradation in the Word Error Rate.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19960v1</guid></item><item><title>[cs updates on arXiv.org] Exploring the holographic entropy cone via reinforcement learning</title><link>https://arxiv.org/abs/2601.19979</link><description>arXiv:2601.19979v1 Announce Type: cross 
Abstract: We develop a reinforcement learning algorithm to study the holographic entropy cone. Given a target entropy vector, our algorithm searches for a graph realization whose min-cut entropies match the target vector. If the target vector does not admit such a graph realization, it must lie outside the cone, in which case the algorithm finds a graph whose corresponding entropy vector most nearly approximates the target and allows us to probe the location of the facets. For the $\sf N=3$ cone, we confirm that our algorithm successfully rediscovers monogamy of mutual information beginning with a target vector outside the holographic entropy cone. We then apply the algorithm to the $\sf N=6$ cone, analyzing the 6 "mystery" extreme rays of the subadditivity cone from arXiv:2412.15364 that satisfy all known holographic entropy inequalities yet lacked graph realizations. We found realizations for 3 of them, proving they are genuine extreme rays of the holographic entropy cone, while providing evidence that the remaining 3 are not realizable, implying unknown holographic inequalities exist for $\sf N=6$.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19979v1</guid></item><item><title>[cs updates on arXiv.org] FORM Version 5.0</title><link>https://arxiv.org/abs/2601.19982</link><description>arXiv:2601.19982v1 Announce Type: cross 
Abstract: We present FORM 5, a major release of the symbolic-manipulation system FORM. Version 5 introduces an integrated diagram generator, based on the GRACE graph-generator, to produce Feynman diagrams directly from FORM scripts. This release also adds support for arbitrary precision floating point coefficients, together with statements for the numerical evaluation of common mathematical functions as well as multiple zeta values and Euler sums. In addition, FORM 5 provides an interface to the FLINT library, offering substantially faster polynomial arithmetic. Various further functions and commands have been added alongside these major features, as well as performance improvements for TFORM and improved compression of FORM's temporary files. Compatibility with the previous release, FORM 4.3.1, is retained except where prior behaviour contradicted the manual or was experimental.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19982v1</guid></item><item><title>[cs updates on arXiv.org] The Sound of Noise: Leveraging the Inductive Bias of Pre-trained Audio Transformers for Glitch Identification in LIGO</title><link>https://arxiv.org/abs/2601.20034</link><description>arXiv:2601.20034v1 Announce Type: cross 
Abstract: Transient noise artifacts, or glitches, fundamentally limit the sensitivity of gravitational-wave (GW) interferometers and can mimic true astrophysical signals, particularly the short-duration intermediate-mass black hole (IMBH) mergers. Current glitch classification methods, such as Gravity Spy, rely on supervised models trained from scratch using labeled datasets. These approaches suffer from a significant ``label bottleneck," requiring massive, expertly annotated datasets to achieve high accuracy and often struggling to generalize to new glitch morphologies or exotic GW signals encountered in observing runs. In this work, we present a novel cross-domain framework that treats GW strain data through the lens of audio processing. We utilize the Audio Spectrogram Transformer (AST), a model pre-trained on large-scale audio datasets, and adapt it to the GW domain. Instead of learning time-frequency features from scratch, our method exploits the strong inductive bias inherent in pre-trained audio models, transferring learned representations of natural sound to the characterization of detector noise and GW signals, including IMBHs. We validate this approach by analyzing strain data from the third (O3) and fourth (O4) observing runs of the LIGO detectors. We used t-Distributed Stochastic Neighbor Embedding (t-SNE), an unsupervised clustering technique, to visualize the AST-derived embeddings of signals and glitches, revealing well-separated groups that align closely with independently validated Gravity Spy glitch classes. Our results indicate that the inductive bias from audio pre-training allows superior feature extraction compared to traditional supervised techniques, offering a robust, data-efficient pathway for discovering new, anomalous transients, and classifying complex noise artifacts in the era of next-generation detectors.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20034v1</guid></item><item><title>[cs updates on arXiv.org] Minimax Rates for Hyperbolic Hierarchical Learning</title><link>https://arxiv.org/abs/2601.20047</link><description>arXiv:2601.20047v1 Announce Type: cross 
Abstract: We prove an exponential separation in sample complexity between Euclidean and hyperbolic representations for learning on hierarchical data under standard Lipschitz regularization. For depth-$R$ hierarchies with branching factor $m$, we first establish a geometric obstruction for Euclidean space: any bounded-radius embedding forces volumetric collapse, mapping exponentially many tree-distant points to nearby locations. This necessitates Lipschitz constants scaling as $\exp(\Omega(R))$ to realize even simple hierarchical targets, yielding exponential sample complexity under capacity control. We then show this obstruction vanishes in hyperbolic space: constant-distortion hyperbolic embeddings admit $O(1)$-Lipschitz realizability, enabling learning with $n = O(mR \log m)$ samples. A matching $\Omega(mR \log m)$ lower bound via Fano's inequality establishes that hyperbolic representations achieve the information-theoretic optimum. We also show a geometry-independent bottleneck: any rank-$k$ prediction space captures only $O(k)$ canonical hierarchical contrasts.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20047v1</guid></item><item><title>[cs updates on arXiv.org] Explainable deep learning reveals the physical mechanisms behind the turbulent kinetic energy equation</title><link>https://arxiv.org/abs/2601.20052</link><description>arXiv:2601.20052v1 Announce Type: cross 
Abstract: In this work, we investigate the physical mechanisms governing turbulent kinetic energy transport using explainable deep learning (XDL). An XDL model based on SHapley Additive exPlanations (SHAP) is used to identify and percolate high-importance structures for the evolution of the turbulent kinetic energy budget terms of a turbulent channel flow at a friction Reynolds number of $Re_\tau = 125$. The results show that the important structures are predominantly located in the near-wall region and are more frequently associated with sweep-type events. In the viscous layer, the SHAP structures relevant for production and viscous diffusion are almost entirely contained within those relevant for dissipation, revealing a clear hierarchical organization of near-wall turbulence. In the outer layer, this hierarchical organization breaks down and only velocity-pressure-gradient correlation and turbulent transport SHAP structures remain, with a moderate spatial coincidence of approximately $60\%$. Finally, we show that none of the coherent structures classically studied in turbulence are capable of representing the mechanisms behind the various terms of the turbulent kinetic energy budget throughout the channel. These results reveal dissipation as the dominant organizing mechanism of near-wall turbulence, constraining production and viscous diffusion within a single structural hierarchy that breaks down in the outer layer.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20052v1</guid></item><item><title>[cs updates on arXiv.org] Randomized Feasibility Methods for Constrained Optimization with Adaptive Step Sizes</title><link>https://arxiv.org/abs/2601.20076</link><description>arXiv:2601.20076v1 Announce Type: cross 
Abstract: We consider minimizing an objective function subject to constraints defined by the intersection of lower-level sets of convex functions. We study two cases: (i) strongly convex and Lipschitz-smooth objective function and (ii) convex but possibly nonsmooth objective function. To deal with the constraints that are not easy to project on, we use a randomized feasibility algorithm with Polyak steps and a random number of sampled constraints per iteration, while taking (sub)gradient steps to minimize the objective function. For case (i), we prove linear convergence in expectation of the objective function values to any prescribed tolerance using an adaptive stepsize. For case (ii), we develop a fully problem parameter-free and adaptive stepsize scheme that yields an $O(1/\sqrt{T})$ worst-case rate in expectation. The infeasibility of the iterates decreases geometrically with the number of feasibility updates almost surely, while for the averaged iterates, we establish an expected lower bound on the function values relative to the optimal value that depends on the distribution for the random number of sampled constraints. For certain choices of sample-size growth, optimal rates are achieved. Finally, simulations on a Quadratically Constrained Quadratic Programming (QCQP) problem and Support Vector Machines (SVM) demonstrate the computational efficiency of our algorithm compared to other state-of-the-art methods.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20076v1</guid></item><item><title>[cs updates on arXiv.org] The Interplay Between Domination and Separation in Graphs</title><link>https://arxiv.org/abs/2601.20153</link><description>arXiv:2601.20153v1 Announce Type: cross 
Abstract: In the literature, several identification problems in graphs have been studied, of which, the most widely studied are the ones based on dominating sets as a tool of identification. Hereby, the objective is to separate any two vertices of a graph by their unique neighborhoods in a suitably chosen dominating or total-dominating set. Such a (total-)dominating set endowed with a separation property is often referred to as a code of the graph. In this paper, we study the four separation properties location, closed-separation, open-separation and full-separation. We address the complexity of finding minimum separating sets in a graph and study the interplay of these separation properties with several codes (establishing a particularly close relation between separation and codes based on domination) as well as the interplay of separation and complementation (showing that location and full-separation are the same on a graph and its complement, whereas closed-separation in a graph corresponds to open-separation in its complement).</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20153v1</guid></item><item><title>[cs updates on arXiv.org] Bias-Reduced Estimation of Finite Mixtures: An Application to Latent Group Structures in Panel Data</title><link>https://arxiv.org/abs/2601.20197</link><description>arXiv:2601.20197v1 Announce Type: cross 
Abstract: Finite mixture models are widely used in econometric analyses to capture unobserved heterogeneity. This paper shows that maximum likelihood estimation of finite mixtures of parametric densities can suffer from substantial finite-sample bias in all parameters under mild regularity conditions. The bias arises from the influence of outliers in component densities with unbounded or large support and increases with the degree of overlap among mixture components. I show that maximizing the classification-mixture likelihood function, equipped with a consistent classifier, yields parameter estimates that are less biased than those obtained by standard maximum likelihood estimation (MLE). I then derive the asymptotic distribution of the resulting estimator and provide conditions under which oracle efficiency is achieved. Monte Carlo simulations show that conventional mixture MLE exhibits pronounced finite-sample bias, which diminishes as the sample size or the statistical distance between component densities tends to infinity. The simulations further show that the proposed estimation strategy generally outperforms standard MLE in finite samples in terms of both bias and mean squared errors under relatively weak assumptions. An empirical application to latent group panel structures using health administrative data shows that the proposed approach reduces out-of-sample prediction error by approximately 17.6% relative to the best results obtained from standard MLE procedures.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20197v1</guid></item><item><title>[cs updates on arXiv.org] Quantum statistics from classical simulations via generative Gibbs sampling</title><link>https://arxiv.org/abs/2601.20228</link><description>arXiv:2601.20228v1 Announce Type: cross 
Abstract: Accurate simulation of nuclear quantum effects is essential for molecular modeling but expensive using path integral molecular dynamics (PIMD). We present GG-PI, a ring-polymer-based framework that combines generative modeling of the single-bead conditional density with Gibbs sampling to recover quantum statistics from classical simulation data. GG-PI uses inexpensive standard classical simulations or existing data for training and allows transfer across temperatures without retraining. On standard test systems, GG-PI significantly reduces wall clock time compared to PIMD. Our approach extends easily to a wide range of problems with similar Markov structure.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20228v1</guid></item><item><title>[cs updates on arXiv.org] Efficient Evaluation of LLM Performance with Statistical Guarantees</title><link>https://arxiv.org/abs/2601.20251</link><description>arXiv:2601.20251v1 Announce Type: cross 
Abstract: Exhaustively evaluating many large language models (LLMs) on a large suite of benchmarks is expensive. We cast benchmarking as finite-population inference and, under a fixed query budget, seek tight confidence intervals (CIs) for model accuracy with valid frequentist coverage. We propose Factorized Active Querying (FAQ), which (a) leverages historical information through a Bayesian factor model; (b) adaptively selects questions using a hybrid variance-reduction/active-learning sampling policy; and (c) maintains validity through Proactive Active Inference -- a finite-population extension of active inference (Zrnic &amp; Candes, 2024) that enables direct question selection while preserving coverage. With negligible overhead cost, FAQ delivers up to $5\times$ effective sample size gains over strong baselines on two benchmark suites, across varying historical-data missingness levels: this means that it matches the CI width of uniform sampling while using up to $5\times$ fewer queries. We release our source code and our curated datasets to support reproducible evaluation and future research.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20251v1</guid></item><item><title>[cs updates on arXiv.org] A Quantum Photonic Approach to Graph Coloring</title><link>https://arxiv.org/abs/2601.20263</link><description>arXiv:2601.20263v1 Announce Type: cross 
Abstract: Gaussian Boson Sampling (GBS) is a quantum computational model that leverages linear optics to solve sampling problems believed to be classically intractable. Recent experimental breakthroughs have demonstrated quantum advantage using GBS, motivating its application to real-world combinatorial optimization problems.
  In this work, we reformulate the graph coloring problem as an integer programming problem using the independent set formulation. This enables the use of GBS to identify cliques in the complement graph, which correspond to independent sets in the original graph. Our method is benchmarked against classical heuristics and exact algorithms on two sets of instances: Erd\H{o}s-R\'enyi random graphs and graphs derived from a smart-charging use case. The results demonstrate that GBS can provide competitive solutions, highlighting its potential as a quantum-enhanced heuristic for graph-based optimization.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20263v1</guid></item><item><title>[cs updates on arXiv.org] Empirical Likelihood-Based Fairness Auditing: Distribution-Free Certification and Flagging</title><link>https://arxiv.org/abs/2601.20269</link><description>arXiv:2601.20269v1 Announce Type: cross 
Abstract: Machine learning models in high-stakes applications, such as recidivism prediction and automated personnel selection, often exhibit systematic performance disparities across sensitive subpopulations, raising critical concerns regarding algorithmic bias. Fairness auditing addresses these risks through two primary functions: certification, which verifies adherence to fairness constraints; and flagging, which isolates specific demographic groups experiencing disparate treatment. However, existing auditing techniques are frequently limited by restrictive distributional assumptions or prohibitive computational overhead. We propose a novel empirical likelihood-based (EL) framework that constructs robust statistical measures for model performance disparities. Unlike traditional methods, our approach is non-parametric; the proposed disparity statistics follow asymptotically chi-square or mixed chi-square distributions, ensuring valid inference without assuming underlying data distributions. This framework uses a constrained optimization profile that admits stable numerical solutions, facilitating both large-scale certification and efficient subpopulation discovery. Empirically, the EL methods outperform bootstrap-based approaches, yielding coverage rates closer to nominal levels while reducing computational latency by several orders of magnitude. We demonstrate the practical utility of this framework on the COMPAS dataset, where it successfully flags intersectional biases, specifically identifying a significantly higher positive prediction rate for African-American males under 25 and a systemic under-prediction for Caucasian females relative to the population mean.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20269v1</guid></item><item><title>[cs updates on arXiv.org] Do Whitepaper Claims Predict Market Behavior? Evidence from Cryptocurrency Factor Analysis</title><link>https://arxiv.org/abs/2601.20336</link><description>arXiv:2601.20336v1 Announce Type: cross 
Abstract: Cryptocurrency projects articulate value propositions through whitepapers, making claims about functionality and technical capabilities. This study investigates whether these narratives align with observed market behavior. We construct a pipeline combining zero-shot NLP classification (BART-MNLI) with CP tensor decomposition to compare three spaces: (1) a claims matrix from 24 whitepapers across 10 semantic categories, (2) market statistics for 49 assets over two years of hourly data, and (3) latent factors from tensor decomposition (rank 2, 92.45% variance explained). Using Procrustes rotation and Tucker's congruence coefficient, we test alignment across 23 common entities.
  Results show weak alignment: claims-statistics (phi=0.341, p=0.332), claims-factors (phi=0.077, p=0.747), and statistics-factors (phi=0.197, p&lt;0.001). The statistics-factors significance validates our methodology, confirming the pipeline detects relationships when present. Inter-model validation with DeBERTa-v3 yields 32% exact agreement but 67% top-3 agreement. Cross-sectional analysis reveals heterogeneous contributions: NEAR, MKR, ATOM show positive alignment while ENS, UNI, Bitcoin diverge most. Excluding Bitcoin confirms results are not driven by market dominance.
  We interpret findings as weak alignment between whitepaper narratives and market factor structure. Limited power (n=23) precludes distinguishing weak from no alignment, but strong alignment (phi&gt;=0.70) can be confidently rejected. Implications for narrative economics and investment analysis are discussed.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20336v1</guid></item><item><title>[cs updates on arXiv.org] Convergence Analysis of Randomized Subspace Normalized SGD under Heavy-Tailed Noise</title><link>https://arxiv.org/abs/2601.20399</link><description>arXiv:2601.20399v1 Announce Type: cross 
Abstract: Randomized subspace methods reduce per-iteration cost; however, in nonconvex optimization, most analyses are expectation-based, and high-probability bounds remain scarce even under sub-Gaussian noise. We first prove that randomized subspace SGD (RS-SGD) admits a high-probability convergence bound under sub-Gaussian noise, achieving the same order of oracle complexity as prior in-expectation results. Motivated by the prevalence of heavy-tailed gradients in modern machine learning, we then propose randomized subspace normalized SGD (RS-NSGD), which integrates direction normalization into subspace updates. Assuming the noise has bounded $p$-th moments, we establish both in-expectation and high-probability convergence guarantees, and show that RS-NSGD can achieve better oracle complexity than full-dimensional normalized SGD.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20399v1</guid></item><item><title>[cs updates on arXiv.org] Assembling the Mind's Mosaic: Towards EEG Semantic Intent Decoding</title><link>https://arxiv.org/abs/2601.20447</link><description>arXiv:2601.20447v1 Announce Type: cross 
Abstract: Enabling natural communication through brain-computer interfaces (BCIs) remains one of the most profound challenges in neuroscience and neurotechnology. While existing frameworks offer partial solutions, they are constrained by oversimplified semantic representations and a lack of interpretability. To overcome these limitations, we introduce Semantic Intent Decoding (SID), a novel framework that translates neural activity into natural language by modeling meaning as a flexible set of compositional semantic units. SID is built on three core principles: semantic compositionality, continuity and expandability of semantic space, and fidelity in reconstruction. We present BrainMosaic, a deep learning architecture implementing SID. BrainMosaic decodes multiple semantic units from EEG/SEEG signals using set matching and then reconstructs coherent sentences through semantic-guided reconstruction. This approach moves beyond traditional pipelines that rely on fixed-class classification or unconstrained generation, enabling a more interpretable and expressive communication paradigm. Extensive experiments on multilingual EEG and clinical SEEG datasets demonstrate that SID and BrainMosaic offer substantial advantages over existing frameworks, paving the way for natural and effective BCI-mediated communication.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20447v1</guid></item><item><title>[cs updates on arXiv.org] Erasing Your Voice Before It's Heard: Training-free Speaker Unlearning for Zero-shot Text-to-Speech</title><link>https://arxiv.org/abs/2601.20481</link><description>arXiv:2601.20481v1 Announce Type: cross 
Abstract: Modern zero-shot text-to-speech (TTS) models offer unprecedented expressivity but also pose serious crime risks, as they can synthesize voices of individuals who never consented. In this context, speaker unlearning aims to prevent the generation of specific speaker identities upon request. Existing approaches, reliant on retraining, are costly and limited to speakers seen in the training set. We present TruS, a training-free speaker unlearning framework that shifts the paradigm from data deletion to inference-time control. TruS steers identity-specific hidden activations to suppress target speakers while preserving other attributes (e.g., prosody and emotion). Experimental results show that TruS effectively prevents voice generation on both seen and unseen opt-out speakers, establishing a scalable safeguard for speech synthesis. The demo and code are available on http://mmai.ewha.ac.kr/trus.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20481v1</guid></item><item><title>[cs updates on arXiv.org] Physics-informed Blind Reconstruction of Dense Fields from Sparse Measurements using Neural Networks with a Differentiable Simulator</title><link>https://arxiv.org/abs/2601.20496</link><description>arXiv:2601.20496v1 Announce Type: cross 
Abstract: Generating dense physical fields from sparse measurements is a fundamental question in sampling, signal processing, and many other applications. State-of-the-art methods either use spatial statistics or rely on examples of dense fields in the training phase, which often are not available, and thus rely on synthetic data. Here, we present a reconstruction method that generates dense fields from sparse measurements, without assuming availability of the spatial statistics, nor of examples of the dense fields. This is made possible through the introduction of an automatically differentiable numerical simulator into the training phase of the method. The method is shown to have superior results over statistical and neural network based methods on a set of three standard problems from fluid mechanics.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20496v1</guid></item><item><title>[cs updates on arXiv.org] Incorporating data drift to perform survival analysis on credit risk</title><link>https://arxiv.org/abs/2601.20533</link><description>arXiv:2601.20533v1 Announce Type: cross 
Abstract: Survival analysis has become a standard approach for modelling time to default by time-varying covariates in credit risk. Unlike most existing methods that implicitly assume a stationary data-generating process, in practise, mortgage portfolios are exposed to various forms of data drift caused by changing borrower behaviour, macroeconomic conditions, policy regimes and so on. This study investigates the impact of data drift on survival-based credit risk models and proposes a dynamic joint modelling framework to improve robustness under non-stationary environments. The proposed model integrates a longitudinal behavioural marker derived from balance dynamics with a discrete-time hazard formulation, combined with landmark one-hot encoding and isotonic calibration. Three types of data drift (sudden, incremental and recurring) are simulated and analysed on mortgage loan datasets from Freddie Mac. Experiments and corresponding evidence show that the proposed landmark-based joint model consistently outperforms classical survival models, tree-based drift-adaptive learners and gradient boosting methods in terms of discrimination and calibration across all drift scenarios, which confirms the superiority of our model design.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20533v1</guid></item><item><title>[cs updates on arXiv.org] On Triangles in Colored Pseudoline Arrangements</title><link>https://arxiv.org/abs/2601.20574</link><description>arXiv:2601.20574v1 Announce Type: cross 
Abstract: We consider the faces in pseudoline arrangements in which the pseudolines are colored with two colors. Bj\"orner, Las Vergnas, Sturmfels, White, and Ziegler conjecture the existence of a two-colored triangle in such arrangements. We consider variants of this problem. We show that in any non-trivial two-coloring of a pseudoline arrangement there exists a two-colored triangle or quadrangle. We also investigate the existence of a bichromatic triangle assuming certain structures on the coloring.
  Previously, several authors investigated the chromatic number and independence number of hypergraphs whose vertices correspond to the pseudolines of an arrangement and the hyperedges correspond to the faces of the arrangement. We show that the maximum of the independence numbers of such hypergraphs is $\lceil \frac{2}{3}n-1\rceil$. We also prove that if we only consider the triangular faces then this maximum becomes $n-\Theta(\log n)$.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20574v1</guid></item><item><title>[cs updates on arXiv.org] SegRap2025: A Benchmark of Gross Tumor Volume and Lymph Node Clinical Target Volume Segmentation for Radiotherapy Planning of Nasopharyngeal Carcinoma</title><link>https://arxiv.org/abs/2601.20575</link><description>arXiv:2601.20575v1 Announce Type: cross 
Abstract: Accurate delineation of Gross Tumor Volume (GTV), Lymph Node Clinical Target Volume (LN CTV), and Organ-at-Risk (OAR) from Computed Tomography (CT) scans is essential for precise radiotherapy planning in Nasopharyngeal Carcinoma (NPC). Building upon SegRap2023, which focused on OAR and GTV segmentation using single-center paired non-contrast CT (ncCT) and contrast-enhanced CT (ceCT) scans, the SegRap2025 challenge aims to enhance the generalizability and robustness of segmentation models across imaging centers and modalities. SegRap2025 comprises two tasks: Task01 addresses GTV segmentation using paired CT from the SegRap2023 dataset, with an additional external testing set to evaluate cross-center generalization, and Task02 focuses on LN CTV segmentation using multi-center training data and an unseen external testing set, where each case contains paired CT scans or a single modality, emphasizing both cross-center and cross-modality robustness. This paper presents the challenge setup and provides a comprehensive analysis of the solutions submitted by ten participating teams. For GTV segmentation task, the top-performing models achieved average Dice Similarity Coefficient (DSC) of 74.61% and 56.79% on the internal and external testing cohorts, respectively. For LN CTV segmentation task, the highest average DSC values reached 60.24%, 60.50%, and 57.23% on paired CT, ceCT-only, and ncCT-only subsets, respectively. SegRap2025 establishes a large-scale multi-center, multi-modality benchmark for evaluating the generalization and robustness in radiotherapy target segmentation, providing valuable insights toward clinically applicable automated radiotherapy planning systems. The benchmark is available at: https://hilab-git.github.io/SegRap2025_Challenge.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20575v1</guid></item><item><title>[cs updates on arXiv.org] Exact Graph Learning via Integer Programming</title><link>https://arxiv.org/abs/2601.20589</link><description>arXiv:2601.20589v1 Announce Type: cross 
Abstract: Learning the dependence structure among variables in complex systems is a central problem across medical, natural, and social sciences. These structures can be naturally represented by graphs, and the task of inferring such graphs from data is known as graph learning or as causal discovery if the graphs are given a causal interpretation. Existing approaches typically rely on restrictive assumptions about the data-generating process, employ greedy oracle algorithms, or solve approximate formulations of the graph learning problem. As a result, they are either sensitive to violations of central assumptions or fail to guarantee globally optimal solutions. We address these limitations by introducing a nonparametric graph learning framework based on nonparametric conditional independence testing and integer programming. We reformulate the graph learning problem as an integer-programming problem and prove that solving the integer-programming problem provides a globally optimal solution to the original graph learning problem. Our method leverages efficient encodings of graphical separation criteria, enabling the exact recovery of larger graphs than was previously feasible. We provide an implementation in the openly available R package 'glip' which supports learning (acyclic) directed (mixed) graphs and chain graphs. From the resulting output one can compute representations of the corresponding Markov equivalence classes or weak equivalence classes. Empirically, we demonstrate that our approach is faster than other existing exact graph learning procedures for a large fraction of instances and graphs of various sizes. GLIP also achieves state-of-the-art performance on simulated data and benchmark datasets across all aforementioned classes of graphs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20589v1</guid></item><item><title>[cs updates on arXiv.org] Trigger Optimization and Event Classification for Dark Matter Searches in the CYGNO Experiment Using Machine Learning</title><link>https://arxiv.org/abs/2601.20626</link><description>arXiv:2601.20626v1 Announce Type: cross 
Abstract: The CYGNO experiment employs an optical-readout Time Projection Chamber (TPC) to search for rare low-energy interactions using finely resolved scintillation images. While the optical readout provides rich topological information, it produces large, sparse megapixel images that challenge real-time triggering, data reduction, and background discrimination.
  We summarize two complementary machine-learning approaches developed within CYGNO. First, we present a fast and fully unsupervised strategy for online data reduction based on reconstruction-based anomaly detection. A convolutional autoencoder trained exclusively on pedestal images (i.e. frames acquired with GEM amplification disabled) learns the detector noise morphology and highlights particle-induced structures through localized reconstruction residuals, from which compact Regions of Interest (ROIs) are extracted. On real prototype data, the selected configuration retains (93.0 +/- 0.2)% of reconstructed signal intensity while discarding (97.8 +/- 0.1)% of the image area, with ~25 ms per-frame inference time on a consumer GPU.
  Second, we report a weakly supervised application of the Classification Without Labels (CWoLa) framework to data acquired with an Americium--Beryllium neutron source. Using only mixed AmBe and standard datasets (no event-level labels), a convolutional classifier learns to identify nuclear-recoil-like topologies. The achieved performance approaches the theoretical limit imposed by the mixture composition and isolates a high-score population with compact, approximately circular morphologies consistent with nuclear recoils.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20626v1</guid></item><item><title>[cs updates on arXiv.org] A scalable flow-based approach to mitigate topological freezing</title><link>https://arxiv.org/abs/2601.20708</link><description>arXiv:2601.20708v1 Announce Type: cross 
Abstract: As lattice gauge theories with non-trivial topological features are driven towards the continuum limit, standard Markov Chain Monte Carlo simulations suffer for topological freezing, i.e., a dramatic growth of autocorrelations in topological observables. A widely used strategy is the adoption of Open Boundary Conditions (OBC), which restores ergodic sampling of topology but at the price of breaking translation invariance and introducing unphysical boundary artifacts. In this contribution we summarize a scalable, exact flow-based strategy to remove them by transporting configurations from a prior with a OBC defect to a fully periodic ensemble, and apply it to 4d SU(3) Yang--Mills theory. The method is based on a Stochastic Normalizing Flow (SNF) that alternates non-equilibrium Monte Carlo updates with localized, gauge-equivariant defect coupling layers implemented via masked parametric stout smearing. Training is performed by minimizing the average dissipated work, equivalent to a Kullback--Leibler divergence between forward and reverse non-equilibrium path measures, to achieve more reversible trajectories and improved efficiency. We discuss the scaling with the number of degrees of freedom affected by the defect and show that defect SNFs achieve better performances than purely stochastic non-equilibrium methods at comparable cost. Finally, we validate the approach by reproducing reference results for the topological susceptibility.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20708v1</guid></item><item><title>[cs updates on arXiv.org] Leveraging Second-Order Curvature for Efficient Learned Image Compression: Theory and Empirical Evidence</title><link>https://arxiv.org/abs/2601.20769</link><description>arXiv:2601.20769v1 Announce Type: cross 
Abstract: Training learned image compression (LIC) models entails navigating a challenging optimization landscape defined by the fundamental trade-off between rate and distortion. Standard first-order optimizers, such as SGD and Adam, struggle with \emph{gradient conflicts} arising from competing objectives, leading to slow convergence and suboptimal rate-distortion performance. In this work, we demonstrate that a simple utilization of a second-order quasi-Newton optimizer, \textbf{SOAP}, dramatically improves both training efficiency and final performance across diverse LICs. Our theoretical and empirical analyses reveal that Newton preconditioning inherently resolves the intra-step and inter-step update conflicts intrinsic to the R-D objective, facilitating faster, more stable convergence. Beyond acceleration, we uncover a critical deployability benefit: second-order trained models exhibit significantly fewer activation and latent outliers. This substantially enhances robustness to post-training quantization. Together, these results establish second-order optimization, achievable as a seamless drop-in replacement of the imported optimizer, as a powerful, practical tool for advancing the efficiency and real-world readiness of LICs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20769v1</guid></item><item><title>[cs updates on arXiv.org] Cross-Country Learning for National Infectious Disease Forecasting Using European Data</title><link>https://arxiv.org/abs/2601.20771</link><description>arXiv:2601.20771v1 Announce Type: cross 
Abstract: Accurate forecasting of infectious disease incidence is critical for public health planning and timely intervention. While most data-driven forecasting approaches rely primarily on historical data from a single country, such data are often limited in length and variability, restricting the performance of machine learning (ML) models. In this work, we investigate a cross-country learning approach for infectious disease forecasting, in which a single model is trained on time series data from multiple countries and evaluated on a country of interest. This setting enables the model to exploit shared epidemic dynamics across countries and to benefit from an enlarged training set. We examine this approach through a case study on COVID-19 case forecasting in Cyprus, using surveillance data from European countries. We evaluate multiple ML models and analyse the impact of the lookback window length and cross-country `data augmentation' on multi-step forecasting performance. Our results show that incorporating data from other countries can lead to consistent improvements over models trained solely on national data. Although the empirical focus is on Cyprus and COVID-19, the proposed framework and findings are applicable to infectious disease forecasting more broadly, particularly in settings with limited national historical data.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20771v1</guid></item><item><title>[cs updates on arXiv.org] Multi-Mode Pinching Antenna Systems Enabled Multi-User Communications</title><link>https://arxiv.org/abs/2601.20780</link><description>arXiv:2601.20780v1 Announce Type: cross 
Abstract: This paper proposes a novel multi-mode pinching-antenna systems (PASS) framework. Multiple data streams can be transmitted within a single waveguide through multiple guided modes, thus facilitating efficient multi-user communications through the mode-domain multiplexing. A physic model is derived, which reveals the mode-selective power radiation feature of pinching antennas (PAs). A two-mode PASS enabled two-user downlink communication system is investigated. Considering the mode selectivity of PA power radiation, a practical PA grouping scheme is proposed, where each PA group matches with one specific guided mode and mainly radiates its signal sequentially. Depending on whether the guided mode leaks power to unmatched PAs or not, the proposed PA grouping scheme operates in either the non-leakage or weak-leakage regime. Based on this, the baseband beamforming and PA locations are jointly optimized for sum rate maximization, subject to each user's minimum rate requirement. 1) A simple two-PA case in non-leakage regime is first considered. To solve the formulated problem, a channel orthogonality based solution is proposed. The channel orthogonality is ensured by large-scale and wavelength-scale equality constraints on PA locations. Thus, the optimal beamforming reduces to maximum-ratio transmission (MRT). Moreover, the optimal PA locations are obtained via a Newton-based one-dimension search algorithm that enforces two-scale PA-location constraints by Newton's method. 2) A general multi-PA case in both non-leakage and weak-leakage regimes is further considered. A low-complexity particle-swarm optimization with zero-forcing beamforming (PSO-ZF) algorithm is developed, thus effectively tackling the high-oscillatory and strong-coupled problem. Simulation results demonstrate the superiority of the proposed multi-mode PASS over conventional single-mode PASS and fixed-antenna structures.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20780v1</guid></item><item><title>[cs updates on arXiv.org] Neural Quantum States in Mixed Precision</title><link>https://arxiv.org/abs/2601.20782</link><description>arXiv:2601.20782v1 Announce Type: cross 
Abstract: Scientific computing has long relied on double precision (64-bit floating point) arithmetic to guarantee accuracy in simulations of real-world phenomena. However, the growing availability of hardware accelerators such as Graphics Processing Units (GPUs) has made low-precision formats attractive due to their superior performance, reduced memory footprint, and improved energy efficiency. In this work, we investigate the role of mixed-precision arithmetic in neural-network based Variational Monte Carlo (VMC), a widely used method for solving computationally otherwise intractable quantum many-body systems. We first derive general analytical bounds on the error introduced by reduced precision on Metropolis-Hastings MCMC, and then empirically validate these bounds on the use-case of VMC. We demonstrate that significant portions of the algorithm, in particular, sampling the quantum state, can be executed in half precision without loss of accuracy. More broadly, this work provides a theoretical framework to assess the applicability of mixed-precision arithmetic in machine-learning approaches that rely on MCMC sampling. In the context of VMC, we additionally demonstrate the practical effectiveness of mixed-precision strategies, enabling more scalable and energy-efficient simulations of quantum many-body systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20782v1</guid></item><item><title>[cs updates on arXiv.org] Demystifying Prediction Powered Inference</title><link>https://arxiv.org/abs/2601.20819</link><description>arXiv:2601.20819v1 Announce Type: cross 
Abstract: Machine learning predictions are increasingly used to supplement incomplete or costly-to-measure outcomes in fields such as biomedical research, environmental science, and social science. However, treating predictions as ground truth introduces bias while ignoring them wastes valuable information. Prediction-Powered Inference (PPI) offers a principled framework that leverages predictions from large unlabeled datasets to improve statistical efficiency while maintaining valid inference through explicit bias correction using a smaller labeled subset. Despite its potential, the growing PPI variants and the subtle distinctions between them have made it challenging for practitioners to determine when and how to apply these methods responsibly. This paper demystifies PPI by synthesizing its theoretical foundations, methodological extensions, connections to existing statistics literature, and diagnostic tools into a unified practical workflow. Using the Mosaiks housing price data, we show that PPI variants produce tighter confidence intervals than complete-case analysis, but that double-dipping, i.e. reusing training data for inference, leads to anti-conservative confidence intervals and coverages. Under missing-not-at-random mechanisms, all methods, including classical inference using only labeled data, yield biased estimates. We provide a decision flowchart linking assumption violations to appropriate PPI variants, a summary table of selective methods, and practical diagnostic strategies for evaluating core assumptions. By framing PPI as a general recipe rather than a single estimator, this work bridges methodological innovation and applied practice, helping researchers responsibly integrate predictions into valid inference.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20819v1</guid></item><item><title>[cs updates on arXiv.org] VSCOUT: A Hybrid Variational Autoencoder Approach to Outlier Detection in High-Dimensional Retrospective Monitoring</title><link>https://arxiv.org/abs/2601.20830</link><description>arXiv:2601.20830v1 Announce Type: cross 
Abstract: Modern industrial and service processes generate high-dimensional, non-Gaussian, and contamination-prone data that challenge the foundational assumptions of classical Statistical Process Control (SPC). Heavy tails, multimodality, nonlinear dependencies, and sparse special-cause observations can distort baseline estimation, mask true anomalies, and prevent reliable identification of an in-control (IC) reference set. To address these challenges, we introduce VSCOUT, a distribution-free framework designed specifically for retrospective (Phase I) monitoring in high-dimensional settings. VSCOUT combines an Automatic Relevance Determination Variational Autoencoder (ARD-VAE) architecture with ensemble-based latent outlier filtering and changepoint detection. The ARD prior isolates the most informative latent dimensions, while the ensemble and changepoint filters identify pointwise and structural contamination within the determined latent space. A second-stage retraining step removes flagged observations and re-estimates the latent structure using only the retained inliers, mitigating masking and stabilizing the IC latent manifold. This two-stage refinement produces a clean and reliable IC baseline suitable for subsequent Phase II deployment. Extensive experiments across benchmark datasets demonstrate that VSCOUT achieves superior sensitivity to special-cause structure while maintaining controlled false alarms, outperforming classical SPC procedures, robust estimators, and modern machine-learning baselines. Its scalability, distributional flexibility, and resilience to complex contamination patterns position VSCOUT as a practical and effective method for retrospective modeling and anomaly detection in AI-enabled environments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.20830v1</guid></item><item><title>[cs updates on arXiv.org] A Roadmap for Greater Public Use of Privacy-Sensitive Government Data: Workshop Report</title><link>https://arxiv.org/abs/2208.01636</link><description>arXiv:2208.01636v2 Announce Type: replace 
Abstract: Government agencies collect and manage a wide range of ever-growing datasets. While such data has the potential to support research and evidence-based policy making, there are concerns that the dissemination of such data could infringe upon the privacy of the individuals (or organizations) from whom such data was collected. To appraise the current state of data sharing, as well as learn about opportunities for stimulating such sharing at a faster pace, a virtual workshop was held on May 21st and 26th, 2021, sponsored by the National Science Foundation (NSF) and National Institute of Standards and Technologies (NIST), and the White House Office of Science and Technology Policy (OSTP), where a multinational collection of researchers and practitioners were brought together to discuss their experiences and learn about recently developed technologies for managing privacy while sharing data. The workshop specifically focused on challenges and successes in government data sharing at various levels. The first day focused on successful examples of new technology applied to sharing of public data, including formal privacy techniques, synthetic data, and cryptographic approaches. Day two emphasized brainstorming sessions on some of the challenges and directions to address them.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2208.01636v2</guid></item><item><title>[cs updates on arXiv.org] FC-PINO: High Precision Physics-Informed Neural Operators via Fourier Continuation</title><link>https://arxiv.org/abs/2211.15960</link><description>arXiv:2211.15960v3 Announce Type: replace 
Abstract: The physics-informed neural operator (PINO) is a machine learning paradigm that has demonstrated promising results for learning solutions to partial differential equations (PDEs). It leverages the Fourier Neural Operator to learn solution operators in function spaces and leverages physics losses during training to penalize deviations from known physics laws. Spectral differentiation provides an efficient way to compute derivatives for the physics losses, but it inherently assumes periodicity. When applied to non-periodic functions, this assumption can lead to significant errors, including Gibbs phenomena near domain boundaries which degrade the accuracy of both function representations and derivative computations. To overcome this limitation, we introduce the FC-PINO (Fourier-Continuation-based Physics-Informed Neural Operator) architecture which extends the accuracy and efficiency of PINO and spectral differentiation to non-periodic and non-smooth PDEs. In FC-PINO, we propose integrating Fourier continuation into the PINO framework, and test two different continuation approaches: FC-Legendre and FC-Gram. By transforming non-periodic signals into periodic functions on extended domains in a well-conditioned manner, Fourier continuation enables fast and accurate derivative computations. This approach avoids the discretization sensitivity of finite differences and the memory overhead of automatic differentiation. We demonstrate that standard PINO fails (without padding) or struggles (even with padding) to solve non-periodic and non-smooth PDEs with high precision, across challenging benchmarks. In contrast, the proposed FC-PINO provides accurate, robust, and scalable solutions, substantially outperforming PINO alternatives, and demonstrating that Fourier continuation is critical for extending PINO to a wider range of PDE problems when high-precision solutions are needed.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2211.15960v3</guid></item><item><title>[cs updates on arXiv.org] Fusion of Visual-Inertial Odometry with LiDAR Relative Localization for Cooperative Guidance of a Micro-Scale Aerial Vehicle</title><link>https://arxiv.org/abs/2306.17544</link><description>arXiv:2306.17544v3 Announce Type: replace 
Abstract: A novel relative localization approach for guidance of a micro-scale Unmanned Aerial Vehicle (UAV) by a well-equipped aerial robot fusing Visual-Inertial Odometry (VIO) with Light Detection and Ranging (LiDAR) is proposed in this paper. LiDAR-based localization is accurate and robust to challenging environmental conditions, but 3D LiDARs are relatively heavy and require large UAV platforms, in contrast to lightweight cameras. However, visual-based self-localization methods exhibit lower accuracy and can suffer from significant drift with respect to the global reference frame. To benefit from both sensory modalities, we focus on cooperative navigation in a heterogeneous team of a primary LiDAR-equipped UAV and a secondary micro-scale camera-equipped UAV. We propose a novel cooperative approach combining LiDAR relative localization data with VIO output on board the primary UAV to obtain an accurate pose of the secondary UAV. The pose estimate is used to precisely and reliably guide the secondary UAV along trajectories defined in the primary UAV reference frame. The experimental evaluation has shown the superior accuracy of our method to the raw VIO output, reaching the average 3D Absolute Trajectory Error (ATE) of 0.28 m, and demonstrated its capability to guide the secondary UAV along desired trajectories while mitigating VIO drift. Thus, such a heterogeneous system can explore large areas with LiDAR precision, as well as visit locations inaccessible to the large LiDAR-carrying UAV platforms, as was showcased in a real-world cooperative mapping scenario.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2306.17544v3</guid></item><item><title>[cs updates on arXiv.org] Membership Privacy Risks of Sharpness Aware Minimization</title><link>https://arxiv.org/abs/2310.00488</link><description>arXiv:2310.00488v4 Announce Type: replace 
Abstract: Optimization algorithms that seek flatter minima, such as Sharpness-Aware Minimization (SAM), are credited with improved generalization and robustness to noise. We ask whether such gains impact membership privacy. Surprisingly, we find that SAM is more prone to Membership Inference Attacks (MIA) than classical SGD across multiple datasets and attack methods, despite achieving lower test error. This suggests that the geometric mechanism of SAM that improves generalization simultaneously exacerbates membership leakage. We investigate this phenomenon through extensive analysis of memorization and influence scores. Our results reveal that SAM is more capable of capturing atypical subpatterns, leading to higher memorization scores of samples. Conversely, SGD depends more heavily on majority features, exhibiting worse generalization on atypical subgroups and lower memorization. Crucially, this characteristic of SAM can be linked to lower variance in the prediction confidence of unseen samples, thereby amplifying membership signals. Finally, we model SAM under a perfectly interpolating linear regime and theoretically show that sharpness regularization inherently reduces variance, guaranteeing a higher MIA advantage for confidence and likelihood ratio attacks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2310.00488v4</guid></item><item><title>[cs updates on arXiv.org] Robust MAE-Driven NAS: From Mask Reconstruction to Architecture Innovation</title><link>https://arxiv.org/abs/2311.12086</link><description>arXiv:2311.12086v3 Announce Type: replace 
Abstract: Neural Architecture Search (NAS) relies heavily on labeled data, which is labor-intensive and time-consuming to obtain. In this paper, we propose a novel NAS method based on an unsupervised paradigm, specifically Masked Autoencoders (MAE), thereby eliminating the need for labeled data. By replacing the supervised learning objective with an image reconstruction task, our approach enables the efficient discovery of network architectures without compromising performance and generalization ability. Additionally, we address the problem of performance collapse encountered in the widely-used Differentiable Architecture Search (DARTS) in the unsupervised setting by designing a hierarchical decoder. Extensive experiments across various datasets demonstrate the effectiveness and robustness of our method, offering empirical evidence of its superiority over the counterparts.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2311.12086v3</guid></item><item><title>[cs updates on arXiv.org] UDEEP: Edge-based Computer Vision for In-Situ Underwater Crayfish and Plastic Detection</title><link>https://arxiv.org/abs/2401.06157</link><description>arXiv:2401.06157v2 Announce Type: replace 
Abstract: Invasive signal crayfish have a detrimental impact on ecosystems. They spread the fungal-type crayfish plague disease (Aphanomyces astaci) that is lethal to the native white clawed crayfish, the only native crayfish species in Britain. Invasive signal crayfish extensively burrow, causing habitat destruction, erosion of river banks and adverse changes in water quality, while also competing with native species for resources leading to declines in native populations. Moreover, pollution exacerbates the vulnerability of White-clawed crayfish, with their populations declining by over 90%. To safeguard aquatic ecosystems, it is imperative to address the challenges posed by invasive species and pollution in aquatic ecosystem's. This article introduces the Cognitive Edge Device (CED) computing platform for the detection of crayfish and plastic. It also presents two publicly available underwater datasets, annotated with sequences of crayfish and aquatic plastic debris. Four You Only Look Once (YOLO) variants were trained and evaluated for crayfish and plastic object detection. YOLOv5s achieved the highest detection accuracy, with an mAP@0.5 of 0.90, and achieved the best precision</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2401.06157v2</guid></item><item><title>[cs updates on arXiv.org] A Comprehensive Exploration of Personalized Learning in Smart Education: From Student Modeling to Personalized Recommendations</title><link>https://arxiv.org/abs/2402.01666</link><description>arXiv:2402.01666v2 Announce Type: replace 
Abstract: With the development of artificial intelligence, personalized learning has attracted much attention as an integral part of intelligent education. In recent years, countries and regions such as China, the United States, and the European Union have increasingly recognized the importance of personalized learning, emphasizing its potential to integrate large-scale education with individualized instruction effectively. This survey provides a comprehensive analysis of personalized learning by reviewing relevant studies published in major conferences and journals between January 2017 and April 2025. We examine its definition, objectives, and underlying educational theories, highlighting its pedagogical significance. Furthermore, we explore personalized learning from two key dimensions: student modeling and personalized recommendations. Student modeling is analyzed from both cognitive and non-cognitive perspectives, while recommendation approaches are categorized based on their specific objectives. Additionally, we investigate the interplay between these components and their role in enhancing personalized learning. Beyond theoretical and algorithmic insights, this survey reviews real-world applications, demonstrating personalized learning's effectiveness in educational practice. Finally, we discuss key challenges and future directions, offering a multidimensional perspective that bridges theory and practice.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2402.01666v2</guid></item><item><title>[cs updates on arXiv.org] LLM Multi-Agent Systems: Challenges and Open Problems</title><link>https://arxiv.org/abs/2402.03578</link><description>arXiv:2402.03578v3 Announce Type: replace 
Abstract: This paper explores multi-agent systems and identify challenges that remain inadequately addressed. By leveraging the diverse capabilities and roles of individual agents, multi-agent systems can tackle complex tasks through agent collaboration. We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multi-agent systems. We also explore potential applications of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2402.03578v3</guid></item><item><title>[cs updates on arXiv.org] GenCode: A Generic Data Augmentation Framework for Boosting Deep Learning-Based Code Understanding</title><link>https://arxiv.org/abs/2402.15769</link><description>arXiv:2402.15769v3 Announce Type: replace 
Abstract: Pre-trained code models lead the era of code intelligence, with multiple models designed with impressive performance. However, one important problem, data augmentation for code data that automatically helps developers prepare training data lacks study in this field. In this paper, we introduce a generic data augmentation framework, GenCode, to enhance the training of code understanding models. Simply speaking, GenCode follows a generation-and-selection paradigm to prepare useful training code data. Specifically, it employs code augmentation techniques to generate new code candidates first and then identifies important ones as the training data by influence scores. To evaluate the effectiveness of GenCode, we conduct experiments on four code understanding tasks (e.g., code clone detection) and three pre-trained code models (e.g., CodeT5) and two recent released code-specific Large Language Models (LLMs) (e.g., Qwen2.5-Coder). Compared to the state-of-the-art (SOTA) code augmentation method MixCode, GenCode produces pre-trained code models with 2.92% higher accuracy and 4.90% adversarial robustness on average. For code-specific LLMs, GenCode achieves an average improvement of 0.93% in accuracy and 0.98% in natural robustness.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2402.15769v3</guid></item><item><title>[cs updates on arXiv.org] GPT2MEG: Quantizing MEG for Autoregressive Generation</title><link>https://arxiv.org/abs/2404.09256</link><description>arXiv:2404.09256v2 Announce Type: replace 
Abstract: Foundation models trained with self-supervised objectives are increasingly applied to brain recordings, but autoregressive generation of realistic multichannel neural time series remains comparatively underexplored, particularly for Magnetoencephalography (MEG). We study (i) modified multichannel WaveNet variants and (ii) a GPT-2-style Transformer, autoregressively trained by next-step prediction on unlabelled MEG. For the Transformer, we propose a simple quantization/tokenization and embedding scheme (channel, subject, and task-condition embeddings) that repurposes a language-model architecture for continuous, high-rate multichannel time series and enables conditional simulation of task-evoked activity. Across forecasting, long-horizon generation, and downstream decoding, GPT2MEG more faithfully reproduces temporal, spectral, and task-evoked statistics of real MEG than WaveNet variants and linear autoregressive baselines, and scales to multiple subjects via subject embeddings. Code available at https://github.com/ricsinaruto/MEG-transfer-decoding.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2404.09256v2</guid></item><item><title>[cs updates on arXiv.org] Lipschitz-Regularized Critics Lead to Policy Robustness Against Transition Dynamics Uncertainty</title><link>https://arxiv.org/abs/2404.13879</link><description>arXiv:2404.13879v4 Announce Type: replace 
Abstract: Uncertainties in transition dynamics pose a critical challenge in reinforcement learning (RL), often resulting in performance degradation of trained policies when deployed on hardware. Many robust RL approaches follow two strategies: enforcing smoothness in actor or actor-critic modules with Lipschitz regularization, or learning robust Bellman operators. However, the first strategy does not investigate the impact of critic-only Lipschitz regularization on policy robustness, while the second lacks comprehensive validation in real-world scenarios. Building on this gap and prior work, we propose PPO-PGDLC, an algorithm based on Proximal Policy Optimization (PPO) that integrates Projected Gradient Descent (PGD) with a Lipschitz-regularized critic (LC). The PGD component calculates the adversarial state within an uncertainty set to approximate the robust Bellman operator, and the Lipschitz-regularized critic further improves the smoothness of learned policies. Experimental results on two classic control tasks and one real-world robotic locomotion task demonstrates that, compared to several baseline algorithms, PPO-PGDLC achieves better performance and predicts smoother actions under environmental perturbations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2404.13879v4</guid></item><item><title>[cs updates on arXiv.org] Equilibrium Selection for Multi-agent Reinforcement Learning: A Unified Framework</title><link>https://arxiv.org/abs/2406.08844</link><description>arXiv:2406.08844v2 Announce Type: replace 
Abstract: While multi-agent reinforcement learning (MARL) has produced numerous algorithms that converge to Nash or related equilibria, such equilibria are often non-unique and can exhibit widely varying efficiency.
  This raises a fundamental question: how can one design learning dynamics that not only converge to equilibrium but also select equilibria with desirable performance, such as high social welfare? In contrast to the MARL literature, equilibrium selection has been extensively studied in normal-form games, where decentralized dynamics are known to converge to potential-maximizing or Pareto-optimal Nash equilibria (NEs). Motivated by these results, we study equilibrium selection in finite-horizon stochastic games. We propose a unified actor-critic framework in which a critic learns state-action value functions, and an actor applies a classical equilibrium-selection rule state-wise, treating learned values as stage-game payoffs. We show that, under standard stochastic stability assumptions, the stochastically stable policies of the resulting dynamics inherit the equilibrium selection properties of the underlying normal-form learning rule. As consequences, we obtain potential-maximizing policies in Markov potential games and Pareto-optimal (Markov perfect) equilibria in general-sum stochastic games, together with sample-based implementation of the framework.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2406.08844v2</guid></item><item><title>[cs updates on arXiv.org] An Actionable Framework for Assessing Bias and Fairness in Large Language Model Use Cases</title><link>https://arxiv.org/abs/2407.10853</link><description>arXiv:2407.10853v4 Announce Type: replace 
Abstract: Bias and fairness risks in Large Language Models (LLMs) vary substantially across deployment contexts, yet existing approaches lack systematic guidance for selecting appropriate evaluation metrics. We present a decision framework that maps LLM use cases, characterized by a model and population of prompts, to relevant bias and fairness metrics based on task type, whether prompts contain protected attribute mentions, and stakeholder priorities. Our framework addresses toxicity, stereotyping, counterfactual unfairness, and allocational harms, and introduces novel metrics based on stereotype classifiers and counterfactual adaptations of text similarity measures. All metrics require only LLM outputs for computation, simplifying implementation while avoiding embedding-based approaches that often correlate poorly with downstream harms. We provide an open-source Python library, LangFair, for practical adoption. Extensive experiments demonstrate that fairness risks cannot be reliably assessed from benchmark performance alone: results on one prompt dataset likely overstate or understate risks for another, underscoring that fairness evaluation must be grounded in the specific deployment context.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2407.10853v4</guid></item><item><title>[cs updates on arXiv.org] LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP</title><link>https://arxiv.org/abs/2408.04628</link><description>arXiv:2408.04628v2 Announce Type: replace 
Abstract: Standard natural language processing (NLP) pipelines operate on symbolic representations of language, which typically consist of sequences of discrete tokens. However, creating an analogous representation for ancient logographic writing systems is an extremely labor intensive process that requires expert knowledge. At present, a large portion of logographic data persists in a purely visual form due to the absence of transcription -- this issue poses a bottleneck for researchers seeking to apply NLP toolkits to study ancient logographic languages: most of the relevant data are images of writing.
  This paper investigates whether direct processing of visual representations of language offers a potential solution. We introduce LogogramNLP, the first benchmark enabling NLP analysis of ancient logographic languages, featuring both transcribed and visual datasets for four writing systems along with annotations for tasks like classification, translation, and parsing. Our experiments compare systems that employ recent visual and text encoding strategies as backbones. The results demonstrate that visual representations outperform textual representations for some investigated tasks, suggesting that visual processing pipelines may unlock a large amount of cultural heritage data of logographic languages for NLP-based analyses.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2408.04628v2</guid></item><item><title>[cs updates on arXiv.org] Learning Deep Tree-based Retriever for Efficient Recommendation: Theory and Method</title><link>https://arxiv.org/abs/2408.11345</link><description>arXiv:2408.11345v5 Announce Type: replace 
Abstract: Although advancements in deep learning have significantly enhanced the recommendation accuracy of deep recommendation models, these methods still suffer from low recommendation efficiency. Recently proposed tree-based deep recommendation models alleviate the problem by directly learning tree structure and representations under the guidance of recommendation objectives. To guarantee the effectiveness of beam search for recommendation accuracy, these models strive to ensure that the tree adheres to the max-heap assumption, where a parent node's preference should be the maximum among its children's preferences. However, they employ a one-versus-all strategy, framing the training task as a series of independent binary classification objectives for each node, which limits their ability to fully satisfy the max-heap assumption. To this end, we propose a Deep Tree-based Retriever (DTR for short) for efficient recommendation. DTR frames the training task as a softmax-based multi-class classification over tree nodes at the same level, enabling explicit horizontal competition and more discriminative top-k selection among them, which mimics the beam search behavior during training. To mitigate the suboptimality induced by the labeling of non-leaf nodes, we propose a rectification method for the loss function, which further aligns with the max-heap assumption in expectation. As the number of tree nodes grows exponentially with the levels, we employ sampled softmax to approximate optimization and thereby enhance efficiency. Furthermore, we propose a tree-based sampling method to reduce the bias inherent in sampled softmax. Theoretical results reveal DTR's generalization capability, and both the rectification method and tree-based sampling contribute to improved generalization. The experiments are conducted on four real-world datasets, validating the effectiveness of the proposed method.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2408.11345v5</guid></item><item><title>[cs updates on arXiv.org] SimBench: A Framework for Evaluating and Diagnosing LLM-Based Digital-Twin Generation for Multi-Physics Simulation</title><link>https://arxiv.org/abs/2408.11987</link><description>arXiv:2408.11987v2 Announce Type: replace 
Abstract: We introduce SimBench, a benchmark designed to evaluate the proficiency of simulator-oriented LLMs (S-LLMs) in generating digital twins (DTs) that can be used in simulators for virtual testing. Given a collection of S-LLMs, this benchmark ranks them according to their ability to produce high-quality DTs. We demonstrate this by comparing over 33 open- and closed-source S-LLMs. Using multi-turn interactions, SimBench employs an LLM-as-a-judge (J-LLM) that leverages both predefined rules and human-in-the-loop guidance to assign scores for the DTs generated by the S-LLM, thus providing a consistent and expert-inspired evaluation protocol. The J-LLM is specific to a simulator, and herein the proposed benchmarking approach is demonstrated in conjunction with the open-sourceChrono multi-physics simulator. Chrono provided the backdrop used to assess an S-LLM in relation to the latter's ability to create digital twins for multibody dynamics, finite element analysis, vehicle dynamics, robotic dynamics, and sensor simulations. The proposed benchmarking principle is broadly applicable and enables the assessment of an S-LLM's ability to generate digital twins for other simulation packages, e.g., ANSYS, ABAQUS, OpenFOAM, StarCCM+, IsaacSim, and pyBullet.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2408.11987v2</guid></item><item><title>[cs updates on arXiv.org] A multiscale approach to the stationary Ginzburg-Landau equations of superconductivity</title><link>https://arxiv.org/abs/2409.12023</link><description>arXiv:2409.12023v3 Announce Type: replace 
Abstract: In this work, we study the numerical approximation of minimizers of the Ginzburg-Landau free energy, a common model to describe the behavior of superconductors under magnetic fields. The unknowns are the order parameter, which characterizes the density of superconducting charge carriers, and the magnetic vector potential, which allows to deduce the magnetic field that penetrates the superconductor. Physically important and numerically challenging are especially settings which involve lattices of quantized vortices which can be formed in materials with a large Ginzburg-Landau parameter $\kappa$. In particular, $\kappa$ introduces a severe mesh resolution condition for numerical approximations. In order to reduce these computational restrictions, we investigate a particular discretization which is based on mixed meshes where we apply a Lagrange finite element approach for the vector potential and a localized orthogonal decomposition (LOD) approach for the order parameter. We justify the proposed method by a rigorous a-priori error analysis (in $L^2$ and $H^1$) in which we keep track of the influence of $\kappa$ in all error contributions. This allows us to conclude $\kappa$-dependent resolution conditions for the various meshes and which only impose moderate practical constraints compared to a conventional finite element discretization. Finally, our theoretical findings are illustrated by numerical experiments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2409.12023v3</guid></item><item><title>[cs updates on arXiv.org] Improving Fine-Grained Control via Aggregation of Multiple Diffusion Models</title><link>https://arxiv.org/abs/2410.01262</link><description>arXiv:2410.01262v5 Announce Type: replace 
Abstract: While many diffusion models perform well when controlling particular aspects such as style, character, and interaction, they struggle with fine-grained control due to dataset limitations and intricate model architecture design. This paper introduces a novel training-free algorithm for fine-grained generation, called Aggregation of Multiple Diffusion Models (AMDM). The algorithm integrates features in the latent data space from multiple diffusion models within the same ecosystem into a specified model, thereby activating particular features and enabling fine-grained control. Experimental results demonstrate that AMDM significantly improves fine-grained control without training, validating its effectiveness. Additionally, it reveals that diffusion models initially focus on features such as position, attributes, and style, with later stages improving generation quality and consistency. AMDM offers a new perspective for tackling the challenges of fine-grained conditional generation in diffusion models. Specifically, it allows us to fully utilize existing or develop new conditional diffusion models that control specific aspects, and then aggregate them using the AMDM algorithm. This eliminates the need for constructing complex datasets, designing intricate model architectures, and incurring high training costs. Code is available at: https://github.com/Hammour-steak/AMDM.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2410.01262v5</guid></item><item><title>[cs updates on arXiv.org] HyResPINNs: A Hybrid Residual Physics-Informed Neural Network Architecture Designed to Balance Expressiveness and Trainability</title><link>https://arxiv.org/abs/2410.03573</link><description>arXiv:2410.03573v3 Announce Type: replace 
Abstract: Physics-informed neural networks (PINNs) have emerged as a powerful approach for solving partial differential equations (PDEs) by training neural networks with loss functions that incorporate physical constraints. In this work, we introduce HyResPINNs, a two-level convex-gated architecture designed to maximize approximation expressiveness for a fixed number of degrees of freedom (DoF). The first level involves a trainable, per-block combination of smooth basis functions with trainable sparsity, and deep neural networks; the second involves the ability to gate entire blocks (much like in ResNets or Highway Nets), allowing for expressivity along the depth dimension of the architecture. Our empirical evaluation on a diverse set of challenging PDE problems demonstrates that HyResPINNs consistently achieve superior accuracy to baseline methods while remaining competitive relative to training times. These results highlight the potential of HyResPINNs to combine desirable features from traditional scientific computing methods and modern machine learning, paving the way for more robust and expressive approaches to physics-informed modeling.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2410.03573v3</guid></item><item><title>[cs updates on arXiv.org] Parameterized Spanning Tree Congestion</title><link>https://arxiv.org/abs/2410.08314</link><description>arXiv:2410.08314v5 Announce Type: replace 
Abstract: In this paper we study the Spanning Tree Congestion problem, where we are given a graph $G=(V,E)$ and are asked to find a spanning tree $T$ of minimum maximum congestion. Here, the congestion of an edge $e\in T$ is the number of edges $uv\in E$ such that the (unique) path from $u$ to $v$ in $T$ traverses $e$. We consider this well-studied NP-hard problem from the point of view of (structural) parameterized complexity and obtain the following results.
  We resolve a natural open problem by showing that Spanning Tree Congestion is not FPT parameterized by treewidth (under standard assumptions). More strongly, we present a generic reduction which applies to (almost) any parameter of the form ``vertex-deletion distance to class $\mathcal{C}$'', thus obtaining W[1]-hardness for parameters more restricted than treewidth, including tree-depth plus feedback vertex set, or incomparable to treewidth, such as twin cover. Via a slight tweak of the same reduction we also show that the problem is NP-complete on graphs of modular-width $4$.
  Even though it is known that Spanning Tree Congestion remains NP-hard on instances with only one vertex of unbounded degree, it is currently open whether the problem remains hard on bounded-degree graphs. We resolve this question by showing NP-hardness on graphs of maximum degree 8.
  Complementing the problem's W[1]-hardness for treewidth...</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2410.08314v5</guid></item><item><title>[cs updates on arXiv.org] Striking a Balance: Evaluating How Aggregations of Multiple Forecasts Impact Judgment Under Uncertainty</title><link>https://arxiv.org/abs/2411.02576</link><description>arXiv:2411.02576v2 Announce Type: replace 
Abstract: Decision-makers consult multiple forecasts to account for uncertainties when forming judgments about future events. While prior works have compared unaggregated and highly-aggregated designs for displaying multiple forecasts (e.g., Multiple Forecast Visualizations versus confidence interval plots), it remains unclear how partial aggregation impacts judgment. To investigate the effect of partial aggregation, we curated three designs that partially aggregate multiple forecasts. Through two large-scale studies (Experiment 1 n = 695 and Experiment 2 n = 389) across 14 judgment-related metrics, we observed that one design (Horizon Sampled MFV) significantly enhanced participants' ability to predict future trends, thereby reducing their surprise when confronted with the actual outcomes. Grounded in empirical evidence, we provide insights into how to design visualizations for multiple forecasts to communicate uncertainty more effectively. Specifically, since no approach excels in all metrics, we advise choosing different designs based on communication goals and prior knowledge of forecasts.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2411.02576v2</guid></item><item><title>[cs updates on arXiv.org] TIPO: Text to Image with Text Presampling for Prompt Optimization</title><link>https://arxiv.org/abs/2411.08127</link><description>arXiv:2411.08127v4 Announce Type: replace 
Abstract: TIPO (Text-to-Image Prompt Optimization) introduces an efficient approach for automatic prompt refinement in text-to-image (T2I) generation. Starting from simple user prompts, TIPO leverages a lightweight pre-trained model to expand these prompts into richer and more detailed versions. Conceptually, TIPO samples refined prompts from a targeted sub-distribution within the broader semantic space, preserving the original intent while significantly improving visual quality, coherence, and detail. Unlike resource-intensive methods based on large language models (LLMs) or reinforcement learning (RL), TIPO offers strong computational efficiency and scalability, opening new possibilities for effective automated prompt engineering in T2I tasks. Extensive experiments across multiple domains demonstrate that TIPO achieves stronger text alignment, reduced visual artifacts, and consistently higher human preference rates, while maintaining competitive aesthetic quality. These results highlight the effectiveness of distribution-aligned prompt engineering and point toward broader opportunities for scalable, automated refinement in text-to-image generation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2411.08127v4</guid></item><item><title>[cs updates on arXiv.org] LLMStinger: Jailbreaking LLMs using RL fine-tuned LLMs</title><link>https://arxiv.org/abs/2411.08862</link><description>arXiv:2411.08862v2 Announce Type: replace 
Abstract: We introduce LLMStinger, a novel approach that leverages Large Language Models (LLMs) to automatically generate adversarial suffixes for jailbreak attacks. Unlike traditional methods, which require complex prompt engineering or white-box access, LLMStinger uses a reinforcement learning (RL) loop to fine-tune an attacker LLM, generating new suffixes based on existing attacks for harmful questions from the HarmBench benchmark. Our method significantly outperforms existing red-teaming approaches (we compared against 15 of the latest methods), achieving a +57.2% improvement in Attack Success Rate (ASR) on LLaMA2-7B-chat and a +50.3% ASR increase on Claude 2, both models known for their extensive safety measures. Additionally, we achieved a 94.97% ASR on GPT-3.5 and 99.4% on Gemma-2B-it, demonstrating the robustness and adaptability of LLMStinger across open and closed-source models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2411.08862v2</guid></item><item><title>[cs updates on arXiv.org] Run-Length-Limited ISI-Mitigation (RLIM) Coding for Molecular Communication</title><link>https://arxiv.org/abs/2411.15955</link><description>arXiv:2411.15955v4 Announce Type: replace 
Abstract: Inter-symbol interference (ISI) limits reliability in diffusion-based molecular communication (MC) channels. We propose RLIM, a family of run-length-limited (RLL) codes that form fixed-size codebooks by minimizing the total number of 1-bits, increasing the per-symbol molecule budget under standard power normalizations and thus improving reliability. We develop a provably optimal linear-time greedy decoder that is equivalent to Viterbi decoding under a deterministic last-wins tie-break and has lower computational complexity; empirically, it outperforms first-wins and random Viterbi variants on RLL baselines. Extensive binomial and particle-tracking simulations show that RLIM achieves lower bit error rate (BER) than classical RLL and other prominent coding schemes across a broad range of scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2411.15955v4</guid></item><item><title>[cs updates on arXiv.org] NLPrompt: Noise-Label Prompt Learning for Vision-Language Models</title><link>https://arxiv.org/abs/2412.01256</link><description>arXiv:2412.01256v3 Announce Type: replace 
Abstract: The emergence of vision-language foundation models, such as CLIP, has revolutionized image-text representation, enabling a broad range of applications via prompt learning. Despite its promise, real-world datasets often contain noisy labels that can degrade prompt learning performance. In this paper, we demonstrate that using mean absolute error (MAE) loss in prompt learning, named PromptMAE, significantly enhances robustness against noisy labels while maintaining high accuracy. Though MAE is straightforward and recognized for its robustness, it is rarely used in noisy-label learning due to its slow convergence and poor performance outside prompt learning scenarios. To elucidate the robustness of PromptMAE, we leverage feature learning theory to show that MAE can suppress the influence of noisy samples, thereby improving the signal-to-noise ratio and enhancing overall robustness. Additionally, we introduce PromptOT, a prompt-based optimal transport data purification method to enhance the robustness further. PromptOT employs text features in vision-language models as prototypes to construct an optimal transportation matrix. This matrix effectively partitions datasets into clean and noisy subsets, allowing for the application of cross-entropy loss to the clean subset and MAE loss to the noisy subset. Our Noise-Label Prompt Learning method, named NLPrompt, offers a simple and efficient approach that leverages the expressive representations and precise alignment capabilities of vision-language models for robust prompt learning. We validate NLPrompt through extensive experiments across various noise settings, demonstrating significant performance improvements.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.01256v3</guid></item><item><title>[cs updates on arXiv.org] Progressive-Resolution Policy Distillation: Leveraging Coarse-Resolution Simulations for Time-Efficient Fine-Resolution Policy Learning</title><link>https://arxiv.org/abs/2412.07477</link><description>arXiv:2412.07477v4 Announce Type: replace 
Abstract: In earthwork and construction, excavators often encounter large rocks mixed with various soil conditions, requiring skilled operators. This paper presents a framework for achieving autonomous excavation using reinforcement learning (RL) through a rock excavation simulator. In the simulation, resolution can be defined by the particle size/number in the whole soil space. Fine-resolution simulations closely mimic real-world behavior but demand significant calculation time and challenging sample collection, while coarse-resolution simulations enable faster sample collection but deviate from real-world behavior. To combine the advantages of both resolutions, we explore using policies developed in coarse-resolution simulations for pre-training in fine-resolution simulations. To this end, we propose a novel policy learning framework called Progressive-Resolution Policy Distillation (PRPD), which progressively transfers policies through some middle-resolution simulations with conservative policy transfer to avoid domain gaps that could lead to policy transfer failure. Validation in a rock excavation simulator and nine real-world rock environments demonstrated that PRPD reduced sampling time to less than 1/7 while maintaining task success rates comparable to those achieved through policy learning in a fine-resolution simulation. Additional videos and supplementary results are available on our project page: https://yuki-kadokawa.github.io/prpd/</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.07477v4</guid></item><item><title>[cs updates on arXiv.org] Hierarchical Multi-Agent DRL Based Dynamic Cluster Reconfiguration for UAV Mobility Management</title><link>https://arxiv.org/abs/2412.16167</link><description>arXiv:2412.16167v2 Announce Type: replace 
Abstract: Multi-connectivity involves dynamic cluster formation among distributed access points (APs) and coordinated resource allocation from these APs, highlighting the need for efficient mobility management strategies for users with multi-connectivity. In this paper, we propose a novel mobility management scheme for unmanned aerial vehicles (UAVs) that uses dynamic cluster reconfiguration with energy-efficient power allocation in a wireless interference network. Our objective encompasses meeting stringent reliability demands, minimizing joint power consumption, and reducing the frequency of cluster reconfiguration. To achieve these objectives, we propose a hierarchical multi-agent deep reinforcement learning (H-MADRL) framework, specifically tailored for dynamic clustering and power allocation. The edge cloud connected with a set of APs through low latency optical back-haul links hosts the high-level agent responsible for the optimal clustering policy, while low-level agents reside in the APs and are responsible for the power allocation policy. To further improve the learning efficiency, we propose a novel action-observation transition-driven learning algorithm that allows the low-level agents to use the action space from the high-level agent as part of the local observation space. This allows the lower-level agents to share partial information about the clustering policy and allocate the power more efficiently. The simulation results demonstrate that our proposed distributed algorithm achieves comparable performance to the centralized algorithm. Additionally, it offers better scalability, as the decision time for clustering and power allocation increases by only 10% when doubling the number of APs, compared to a 90% increase observed with the centralized approach.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.16167v2</guid></item><item><title>[cs updates on arXiv.org] Speeding up an unsteady flow simulation by adaptive BDDC and Krylov subspace recycling</title><link>https://arxiv.org/abs/2412.17543</link><description>arXiv:2412.17543v3 Announce Type: replace 
Abstract: We deal with accelerating the solution of a sequence of large linear systems solved by preconditioned conjugate gradient method (PCG). The sequence originates from time-stepping within a simulation of an unsteady incompressible flow. We apply a pressure correction scheme and focus on the solution of the Poisson problem for the pressure corrector. Its scalable solution presents the main computational challenge in many applications. The right-hand side of the problem changes in each time step, while the system matrix is constant and symmetric positive definite. The acceleration techniques are studied on a representative problem of flow around a unit sphere. Our baseline approach is based on a parallel solution of each problem in the sequence by nonoverlapping domain decomposition method. The interface problem is solved by PCG with the three-level BDDC preconditioner. As a preliminary step, an appropriate stopping criterion for the PCG iterations is chosen. Next, two techniques for accelerating the solution are gradually added to the baseline approach. Deflation is used within PCG with several approaches to Krylov subspace recycling. Finally, we add the adaptive selection of the coarse space within the three-level BDDC method. The paper is rich in experiments with careful measurements of computational times on a parallel supercomputer. The combination of the acceleration techniques eventually leads to saving more than 40 % of the computational time.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.17543v3</guid></item><item><title>[cs updates on arXiv.org] Are LLMs Really Not Knowledgeable? Mining the Submerged Knowledge in LLMs' Memory</title><link>https://arxiv.org/abs/2412.20846</link><description>arXiv:2412.20846v2 Announce Type: replace 
Abstract: Large language models (LLMs) have shown promise as parametric knowledge bases, but often underperform on question answering (QA) tasks due to hallucinations and uncertainty. While prior work attributes these failures to knowledge gaps in the model's parameters, we uncover a complementary phenomenon: LLMs frequently retain correct knowledge even when generating incorrect or "unsure" answers. By analyzing the token-level output distributions, we find that correct answers often appear among high-probability candidates, despite not being selected. Motivated by this, we propose Hits@k, a novel metric to evaluate latent knowledge retention independent of answer surface form. Our experiments reveal that LLMs possess significantly more factual knowledge than is reflected by standard QA accuracy. Building on these insights, we further examine the prevailing few-shot QA paradigm. We find that prompting strategies which allow "unsure" outputs can inadvertently suppress correct answers by discouraging low-confidence generation. We design a set of quantitative experiments to measure this suppression effect, offering practical guidance for future prompt and decoding design in knowledge-intensive tasks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2412.20846v2</guid></item><item><title>[cs updates on arXiv.org] Structural and Statistical Audio Texture Knowledge Distillation for Environmental Sound Classification</title><link>https://arxiv.org/abs/2501.01921</link><description>arXiv:2501.01921v2 Announce Type: replace 
Abstract: While knowledge distillation has shown success in various audio tasks, its application to environmental sound classification often overlooks essential low-level audio texture features needed to capture local patterns in complex acoustic environments. To address this gap, the Structural and Statistical Audio Texture Knowledge Distillation (SSATKD) framework is proposed, which combines high-level contextual information with low-level structural and statistical audio textures extracted from intermediate layers. To evaluate its generalizability to a broad range of applications, SSATKD is tested on four diverse datasets within the environmental sound classification domain, namely two passive sonar datasets: DeepShip and Vessel Type Underwater Acoustic Data (VTUAD) and two general environmental sound datasets: Environmental Sound Classification 50 (ESC-50) and UrbanSound8K. Two teacher adaptation strategies are explored: classifier-head-only adaptation and full fine-tuning. The framework is further evaluated using various convolutional and transformer-based teacher models. Experimental results demonstrate consistent accuracy improvements across all datasets and settings, confirming the effectiveness and robustness of SSATKD in real-world sound classification tasks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2501.01921v2</guid></item><item><title>[cs updates on arXiv.org] FLOL: Fast Baselines for Real-World Low-Light Enhancement</title><link>https://arxiv.org/abs/2501.09718</link><description>arXiv:2501.09718v2 Announce Type: replace 
Abstract: Low-Light Image Enhancement (LLIE) is a key task in computational photography and imaging. The problem of enhancing images captured during night or in dark environments has been well-studied in the computer vision literature. However, current deep learning-based solutions struggle with efficiency and robustness for real-world scenarios (e.g., scenes with noise, saturated pixels). We propose a lightweight neural network that combines image processing in the frequency and spatial domains. Our baseline method, FLOL, is one of the fastest models for this task, achieving results comparable to the state-of-the-art on popular real-world benchmarks such as LOLv2, LSRW, MIT-5K and UHD-LL. Moreover, we are able to process 1080p images in real-time under 12ms. Code and models at https://github.com/cidautai/FLOL</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2501.09718v2</guid></item><item><title>[cs updates on arXiv.org] Dense-SfM: Structure from Motion with Dense Consistent Matching</title><link>https://arxiv.org/abs/2501.14277</link><description>arXiv:2501.14277v3 Announce Type: replace 
Abstract: We present Dense-SfM, a novel Structure from Motion (SfM) framework designed for dense and accurate 3D reconstruction from multi-view images. Sparse keypoint matching, which traditional SfM methods often rely on, limits both accuracy and point density, especially in texture-less areas. Dense-SfM addresses this limitation by integrating dense matching with a Gaussian Splatting (GS) based track extension which gives more consistent, longer feature tracks. To further improve reconstruction accuracy, Dense-SfM is equipped with a multi-view kernelized matching module leveraging transformer and Gaussian Process architectures, for robust track refinement across multi-views. Evaluations on the ETH3D and Texture-Poor SfM datasets show that Dense-SfM offers significant improvements in accuracy and density over state-of-the-art methods. Project page: https://icetea-cv.github.io/densesfm/.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2501.14277v3</guid></item><item><title>[cs updates on arXiv.org] Helping Johnny Make Sense of Privacy Policies with LLMs</title><link>https://arxiv.org/abs/2501.16033</link><description>arXiv:2501.16033v2 Announce Type: replace 
Abstract: Understanding and engaging with privacy policies is crucial for online privacy, yet these documents remain notoriously complex and difficult to navigate. We present PRISMe, an interactive browser extension that combines LLM-based policy assessment with a dashboard and customizable chat interface, enabling users to skim quick overviews or explore policy details in depth while browsing. We conduct a user study (N=22) with participants of diverse privacy knowledge to investigate how users interpret the tool's explanations and how it shapes their engagement with privacy policies, identifying distinct interaction patterns. Participants valued the clear overviews and conversational depth, but flagged some issues, particularly adversarial robustness and hallucination risks. Thus, we investigate how a retrieval-augmented generation (RAG) approach can alleviate issues by re-running the chat queries from the study. Our findings surface design challenges as well as technical trade-offs, contributing actionable insights for developing future user-centered, trustworthy privacy policy analysis tools.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2501.16033v2</guid></item><item><title>[cs updates on arXiv.org] Enhancing Model Defense Against Jailbreaks with Proactive Safety Reasoning</title><link>https://arxiv.org/abs/2501.19180</link><description>arXiv:2501.19180v2 Announce Type: replace 
Abstract: Large language models (LLMs) are vital for a wide range of applications yet remain susceptible to jailbreak threats, which could lead to the generation of inappropriate responses. Conventional defenses, such as refusal and adversarial training, often fail to cover corner cases or rare domains, leaving LLMs still vulnerable to more sophisticated attacks. We propose a novel defense strategy, Safety Chain-of-Thought (SCoT), which harnesses the enhanced \textit{reasoning capabilities} of LLMs for proactive assessment of harmful inputs, rather than simply blocking them. SCoT augments any refusal training datasets to critically analyze the intent behind each request before generating answers. By employing proactive reasoning, SCoT enhances the generalization of LLMs across varied harmful queries and scenarios not covered in the safety alignment corpus. Additionally, it generates detailed refusals specifying the rules violated. Comparative evaluations show that SCoT significantly surpasses existing defenses, reducing vulnerability to out-of-distribution issues and adversarial manipulations while maintaining strong general capabilities.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2501.19180v2</guid></item><item><title>[cs updates on arXiv.org] CTC-DRO: Robust Optimization for Reducing Language Disparities in Speech Recognition</title><link>https://arxiv.org/abs/2502.01777</link><description>arXiv:2502.01777v3 Announce Type: replace 
Abstract: Modern deep learning models often achieve high overall performance, but consistently fail on specific subgroups. Group distributionally robust optimization (group DRO) addresses this problem by minimizing the worst-group loss, but it fails when group losses misrepresent performance differences between groups. This is common in domains like speech, where the widely used connectionist temporal classification (CTC) loss not only scales with input length but also varies with linguistic and acoustic properties, leading to spurious differences between group losses. We present CTC-DRO, which addresses the shortcomings of the group DRO objective by smoothing the group weight update to prevent overemphasis on consistently high-loss groups, while using input length-matched batching to mitigate CTC's scaling issues. We evaluate CTC-DRO on the task of multilingual automatic speech recognition (ASR) across five language sets from the diverse ML-SUPERB 2.0 benchmark. CTC-DRO consistently outperforms group DRO and CTC-based baseline models, reducing the worst-language error by up to 47.1% and the average error by up to 32.9%. CTC-DRO can be applied to ASR with minimal computational costs, and, while motivated by multilingual ASR, offers the potential for reducing group disparities in other domains with similar challenges.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.01777v3</guid></item><item><title>[cs updates on arXiv.org] Mitigating Sensitive Information Leakage in LLMs4Code through Machine Unlearning</title><link>https://arxiv.org/abs/2502.05739</link><description>arXiv:2502.05739v2 Announce Type: replace 
Abstract: Large Language Models for Code (LLMs4Code) have achieved strong performance in code generation, but recent studies reveal that they may memorize and leak sensitive information contained in training data, posing serious privacy risks. To address this gap, this work presents the first comprehensive empirical study on applying machine unlearning to mitigate sensitive information leakage in LLMs4Code. We first construct a dedicated benchmark that includes: (i) a synthetic forget set containing diverse forms of personal information, and (ii) a retain set designed to evaluate whether code-generation capability is preserved after unlearning. Using this benchmark, we systematically assess three representative unlearning algorithms (GA, GA+GD, GA+KL) across three widely used open-source LLMs4Code models (AIXCoder-7B, CodeLlama-7B, CodeQwen-7B). Experimental results demonstrate that machine unlearning can substantially reduce direct memorization-based leakage: on average, the direct leak rate drops by more than 50% while retaining about over 91% of the original code-generation performance. Moreover, by analyzing post-unlearning outputs, we uncover a consistent shift from direct to indirect leakage, revealing an underexplored vulnerability that persists even when the target data has been successfully forgotten. Our findings show that machine unlearning is a feasible and effective solution for enhancing privacy protection in LLMs4Code, while also highlighting the need for future techniques capable of mitigating both direct and indirect leakage simultaneously.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.05739v2</guid></item><item><title>[cs updates on arXiv.org] Universal Sequence Preconditioning</title><link>https://arxiv.org/abs/2502.06545</link><description>arXiv:2502.06545v5 Announce Type: replace 
Abstract: We study the problem of preconditioning in sequential prediction. From the theoretical lens of linear dynamical systems, we show that convolving the target sequence corresponds to applying a polynomial to the hidden transition matrix. Building on this insight, we propose a universal preconditioning method that convolves the target with coefficients from orthogonal polynomials such as Chebyshev or Legendre. We prove that this approach reduces regret for two distinct prediction algorithms and yields the first ever sublinear and hidden-dimension-independent regret bounds (up to logarithmic factors) that hold for systems with marginally table and asymmetric transition matrices. Finally, extensive synthetic and real-world experiments show that this simple preconditioning strategy improves the performance of a diverse range of algorithms, including recurrent neural networks, and generalizes to signals beyond linear dynamical systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.06545v5</guid></item><item><title>[cs updates on arXiv.org] DiffRatio: Training One-Step Diffusion Models Without Teacher Supervision</title><link>https://arxiv.org/abs/2502.08005</link><description>arXiv:2502.08005v5 Announce Type: replace 
Abstract: Score-based distillation methods (e.g., variational score distillation) train one-step diffusion models by first pre-training a teacher score model and then distilling it into a one-step student model. However, the gradient estimator in the distillation stage usually suffers from two sources of bias: (1) biased teacher supervision due to score estimation error incurred during pre-training, and (2) the student model's score estimation error during distillation. These biases can degrade the quality of the resulting one-step diffusion model. To address this, we propose DiffRatio, a new framework for training one-step diffusion models: instead of estimating the teacher and student scores independently and then taking their difference, we directly estimate the score difference as the gradient of a learned log density ratio between the student and data distributions across diffusion time steps. This approach greatly simplifies the training pipeline, significantly reduces gradient estimation bias, and improves one-step generation quality. Additionally, it also reduces auxiliary network size by using a lightweight density-ratio network instead of two full score networks, which improves computational and memory efficiency. DiffRatio achieves competitive one-step generation results on CIFAR-10 and ImageNet (64x64 and 512x512), outperforming most teacher-supervised distillation methods. Moreover, the learned density ratio naturally serves as a verifier, enabling a principled inference-time parallel scaling scheme that further improves the generation quality without external rewards or additional sequential computation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.08005v5</guid></item><item><title>[cs updates on arXiv.org] Summaries as Centroids for Interpretable and Scalable Text Clustering</title><link>https://arxiv.org/abs/2502.09667</link><description>arXiv:2502.09667v4 Announce Type: replace 
Abstract: We introduce k-NLPmeans and k-LLMmeans, text-clustering variants of k-means that periodically replace numeric centroids with textual summaries. The key idea, summary-as-centroid, retains k-means assignments in embedding space while producing human-readable, auditable cluster prototypes. The method is LLM-optional: k-NLPmeans uses lightweight, deterministic summarizers, enabling offline, low-cost, and stable operation; k-LLMmeans is a drop-in upgrade that uses an LLM for summaries under a fixed per-iteration budget whose cost does not grow with dataset size. We also present a mini-batch extension for real-time clustering of streaming text. Across diverse datasets, embedding models, and summarization strategies, our approach consistently outperforms classical baselines and approaches the accuracy of recent LLM-based clustering-without extensive LLM calls. Finally, we provide a case study on sequential text streams and release a StackExchange-derived benchmark for evaluating streaming text clustering.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.09667v4</guid></item><item><title>[cs updates on arXiv.org] MAnchors: Memorization-Based Acceleration of Anchors via Rule Reuse and Transformation</title><link>https://arxiv.org/abs/2502.11068</link><description>arXiv:2502.11068v2 Announce Type: replace 
Abstract: Anchors is a popular local model-agnostic explanation technique whose applicability is limited by its computational inefficiency. To address this limitation, we propose a memorization-based framework that accelerates Anchors while preserving explanation fidelity and interpretability. Our approach leverages the iterative nature of Anchors' algorithm which gradually refines an explanation until it is precise enough for a given input by storing and reusing intermediate results obtained during prior explanations. Specifically, we maintain a memory of low-precision, high-coverage rules and introduce a rule transformation framework to adapt them to new inputs: the horizontal transformation adapts a pre-trained explanation to the current input by replacing features, and the vertical transformation refines the general explanation until it is precise enough for the input. We evaluate our method across tabular, text, and image datasets, demonstrating that it significantly reduces explanation generation time while maintaining fidelity and interpretability, thereby enabling the practical adoption of Anchors in time-sensitive applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.11068v2</guid></item><item><title>[cs updates on arXiv.org] Reducing Hallucinations in Language Model-based SPARQL Query Generation Using Post-Generation Memory Retrieval</title><link>https://arxiv.org/abs/2502.13369</link><description>arXiv:2502.13369v3 Announce Type: replace 
Abstract: The ability to generate SPARQL queries from natural language questions is crucial for ensuring efficient and accurate retrieval of structured data from knowledge graphs (KG). While large language models (LLMs) have been widely adopted for SPARQL query generation, they are often susceptible to hallucinations and out-of-distribution errors when generating KG elements, such as Uniform Resource Identifiers (URIs), based on opaque internal parametric knowledge. We propose PGMR (Post-Generation Memory Retrieval), a modular framework where the LLM produces an intermediate query using natural language placeholders for URIs, and a non-parametric memory module is subsequently employed to retrieve and resolve the correct KG URIs. PGMR significantly enhances query correctness (SQM) across various LLMs, datasets, and distribution shifts, while achieving the near-complete suppression of URI hallucinations. Critically, we demonstrate PGMR's superior safety and robustness: a retrieval confidence threshold enables PGMR to effectively refuse to answer queries that lack support, and the retriever proves highly resilient to memory noise, maintaining strong performance even when the non-parametric memory size is scaled up to 9 times with irrelevant, distracting entities.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.13369v3</guid></item><item><title>[cs updates on arXiv.org] BAGEL: Projection-Free Algorithm for Adversarially Constrained Online Convex Optimization</title><link>https://arxiv.org/abs/2502.16744</link><description>arXiv:2502.16744v2 Announce Type: replace 
Abstract: Projection-based algorithms for Constrained Online Convex Optimization (COCO) achieve optimal $\mathcal{O}(T^{1/2})$ regret guarantees but face scalability challenges due to the computational complexity of projections. To circumvent this, projection-free methods utilizing Linear Optimization Oracles (LOO) have been proposed, albeit typically achieving slower $\mathcal{O}(T^{3/4})$ regret rates. In this work, we examine whether the $\mathcal{O}(T^{1/2})$ rate can be recovered in the projection-free setting by strengthening the oracle assumption. We introduce BAGEL, an algorithm utilizing a Separation Oracle (SO) that achieves $\mathcal{O}(T^{1/2})$ regret and $\tilde{\mathcal{O}}(T^{1/2})$ cumulative constraint violation (CCV) for convex cost functions. Our analysis shows that by leveraging an infeasible projection via SO, we can match the time-horizon dependence of projection-based methods with $\tilde{\mathcal{O}}(T)$ oracle calls, provided dependence on the geometry of the action set. This establishes a specific regime where projection-free methods can attain the same convergence rates as projection-based counterparts.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.16744v2</guid></item><item><title>[cs updates on arXiv.org] Simple Sublinear Algorithms for $(\Delta+1)$ Vertex Coloring via Asymmetric Palette Sparsification</title><link>https://arxiv.org/abs/2502.17629</link><description>arXiv:2502.17629v4 Announce Type: replace 
Abstract: The palette sparsification theorem (PST) of Assadi, Chen, and Khanna (SODA 2019) states that in every graph $G$ with maximum degree $\Delta$, sampling a list of $O(\log{n})$ colors from $\{1,\ldots,\Delta+1\}$ for every vertex independently and uniformly, with high probability, allows for finding a $(\Delta+1)$ vertex coloring of $G$ by coloring each vertex only from its sampled list. PST naturally leads to a host of sublinear algorithms for $(\Delta+1)$ vertex coloring, including in semi-streaming, sublinear time, and MPC models, which are all proven to be nearly optimal, and in the case of the former two are the only known sublinear algorithms for this problem.
  While being a quite natural and simple-to-state theorem, PST suffers from two drawbacks. Firstly, all its known proofs require technical arguments that rely on sophisticated graph decompositions and probabilistic arguments. Secondly, finding the coloring of the graph from the sampled lists in an efficient manner requires a considerably complicated algorithm.
  We show that a natural weakening of PST addresses both these drawbacks while still leading to sublinear algorithms of similar quality (up to polylog factors). In particular, we prove an asymmetric palette sparsification theorem (APST) that allows for list sizes of the vertices to have different sizes and only bounds the average size of these lists. The benefit of this weaker requirement is that we can now easily show the graph can be $(\Delta+1)$ colored from the sampled lists using the standard greedy coloring algorithm. This way, we can recover nearly-optimal bounds for $(\Delta+1)$ vertex coloring in all the aforementioned models using algorithms that are much simpler to implement and analyze.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2502.17629v4</guid></item><item><title>[cs updates on arXiv.org] Legged Robot State Estimation Using Invariant Neural-Augmented Kalman Filter with a Neural Compensator</title><link>https://arxiv.org/abs/2503.00344</link><description>arXiv:2503.00344v3 Announce Type: replace 
Abstract: This paper presents an algorithm to improve state estimation for legged robots. Among existing model-based state estimation methods for legged robots, the contact-aided invariant extended Kalman filter defines the state on a Lie group to preserve invariance, thereby significantly accelerating convergence. It achieves more accurate state estimation by leveraging contact information as measurements for the update step. However, when the model exhibits strong nonlinearity, the estimation accuracy decreases. Such nonlinearities can cause initial errors to accumulate and lead to large drifts over time. To address this issue, we propose compensating for errors by augmenting the Kalman filter with an artificial neural network serving as a nonlinear function approximator. Furthermore, we design this neural network to respect the Lie group structure to ensure invariance, resulting in our proposed Invariant Neural-Augmented Kalman Filter (InNKF). The proposed algorithm offers improved state estimation performance by combining the strengths of model-based and learning-based approaches. Project webpage: https://seokju-lee.github.io/innkf_webpage</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.00344v3</guid></item><item><title>[cs updates on arXiv.org] Compositional Reasoning with Transformers, RNNs, and Chain of Thought</title><link>https://arxiv.org/abs/2503.01544</link><description>arXiv:2503.01544v2 Announce Type: replace 
Abstract: It is well understood that different neural network architectures are suited to different tasks, but is there always a single best architecture for a given task? We compare the expressive power of transformers, RNNs, and transformers with chain of thought tokens on a simple and natural class of tasks we term Compositional Reasoning Questions (CRQ). This family captures multi-step problems with tree-like compositional structure, such as evaluating Boolean formulas. We prove that under standard hardness assumptions, \emph{none} of these three architectures is capable of solving CRQs unless some hyperparameter (depth, embedding dimension, and number of chain of thought tokens, respectively) grows with the size of the input. We then provide constructions for solving CRQs with each architecture. For transformers, our construction uses depth that is logarithmic in the problem size. For RNNs, logarithmic embedding dimension is necessary and sufficient, so long as the inputs are provided in a certain order. For transformers with chain of thought, our construction uses $n$ CoT tokens for input size $n$. These results show that, while CRQs are inherently hard, there are several different ways for language models to overcome this hardness. Even for a single class of problems, each architecture has strengths and weaknesses, and none is strictly better than the others.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.01544v2</guid></item><item><title>[cs updates on arXiv.org] Depth-Width tradeoffs in Algorithmic Reasoning of Graph Tasks with Transformers</title><link>https://arxiv.org/abs/2503.01805</link><description>arXiv:2503.01805v2 Announce Type: replace 
Abstract: Transformers have revolutionized the field of machine learning. In particular, they can be used to solve complex algorithmic problems, including graph-based tasks. In such algorithmic tasks a key question is what is the minimal size of a transformer that can implement the task. Recent work has begun to explore this problem for graph-based tasks, showing that for sub-linear embedding dimension (i.e., model width) logarithmic depth suffices. However, an open question, which we address here, is what happens if width is allowed to grow linearly, while depth is kept fixed. Here we analyze this setting, and provide the surprising result that with linear width, constant depth suffices for solving a host of graph-based problems. This suggests that a moderate increase in width can allow much shallower models, which are advantageous in terms of inference and train time. For other problems, we show that quadratic width is required. Our results demonstrate the complex and intriguing landscape of transformer implementations of graph-based algorithms. We empirically investigate these trade-offs between the relative powers of depth and width and find tasks where wider models have the same accuracy as deep models, while having much faster train and inference time due to parallelizable hardware.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.01805v2</guid></item><item><title>[cs updates on arXiv.org] Rewarding Doubt: A Reinforcement Learning Approach to Calibrated Confidence Expression of Large Language Models</title><link>https://arxiv.org/abs/2503.02623</link><description>arXiv:2503.02623v5 Announce Type: replace 
Abstract: A safe and trustworthy use of Large Language Models (LLMs) requires an accurate expression of confidence in their answers. We propose a novel Reinforcement Learning approach that allows to directly fine-tune LLMs to express calibrated confidence estimates alongside their answers to factual questions. Our method optimizes a reward based on the logarithmic scoring rule, explicitly penalizing both over- and under-confidence. This encourages the model to align its confidence estimates with the actual predictive accuracy. The optimal policy under our reward design would result in perfectly calibrated confidence expressions. Unlike prior approaches that decouple confidence estimation from response generation, our method integrates confidence calibration seamlessly into the generative process of the LLM. Empirically, we demonstrate that models trained with our approach exhibit substantially improved calibration and generalize to unseen tasks without further fine-tuning, suggesting the emergence of general confidence awareness.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.02623v5</guid></item><item><title>[cs updates on arXiv.org] EgoLife: Towards Egocentric Life Assistant</title><link>https://arxiv.org/abs/2503.03803</link><description>arXiv:2503.03803v2 Announce Type: replace 
Abstract: We introduce EgoLife, a project to develop an egocentric life assistant that accompanies and enhances personal efficiency through AI-powered wearable glasses. To lay the foundation for this assistant, we conducted a comprehensive data collection study where six participants lived together for one week, continuously recording their daily activities - including discussions, shopping, cooking, socializing, and entertainment - using AI glasses for multimodal egocentric video capture, along with synchronized third-person-view video references. This effort resulted in the EgoLife Dataset, a comprehensive 300-hour egocentric, interpersonal, multiview, and multimodal daily life dataset with intensive annotation. Leveraging this dataset, we introduce EgoLifeQA, a suite of long-context, life-oriented question-answering tasks designed to provide meaningful assistance in daily life by addressing practical questions such as recalling past relevant events, monitoring health habits, and offering personalized recommendations. To address the key technical challenges of (1) developing robust visual-audio models for egocentric data, (2) enabling identity recognition, and (3) facilitating long-context question answering over extensive temporal information, we introduce EgoButler, an integrated system comprising EgoGPT and EgoRAG. EgoGPT is an omni-modal model trained on egocentric datasets, achieving state-of-the-art performance on egocentric video understanding. EgoRAG is a retrieval-based component that supports answering ultra-long-context questions. Our experimental studies verify their working mechanisms and reveal critical factors and bottlenecks, guiding future improvements. By releasing our datasets, models, and benchmarks, we aim to stimulate further research in egocentric AI assistants.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.03803v2</guid></item><item><title>[cs updates on arXiv.org] Achievable Rate Regions for Multi-terminal Quantum Channels via Coset Codes</title><link>https://arxiv.org/abs/2503.07804</link><description>arXiv:2503.07804v5 Announce Type: replace 
Abstract: We undertake a Shannon theoretic study of the problem of communicating bit streams over a 3-user quantum interference channel (QIC) and focus on characterizing inner bounds. Adopting the powerful technique of tilting, smoothing, and augmentation discovered by Sen recently, and combining with our coset code strategy, we derive a new inner bound to the classical-quantum capacity region of a 3-user QIC. The derived inner bound subsumes all currently known bounds and is proven to be strictly larger for identified examples.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.07804v5</guid></item><item><title>[cs updates on arXiv.org] AdaSCALE: Adaptive Scaling for OOD Detection</title><link>https://arxiv.org/abs/2503.08023</link><description>arXiv:2503.08023v3 Announce Type: replace 
Abstract: The ability of the deep learning model to recognize when a sample falls outside its learned distribution is critical for safe and reliable deployment. Recent state-of-the-art out-of-distribution (OOD) detection methods leverage activation shaping to improve the separation between in-distribution (ID) and OOD inputs. These approaches resort to sample-specific scaling but apply a static percentile threshold across all samples regardless of their nature, resulting in suboptimal ID-OOD separability. In this work, we propose \textbf{AdaSCALE}, an adaptive scaling procedure that dynamically adjusts the percentile threshold based on a sample's estimated OOD likelihood. This estimation leverages our key observation: OOD samples exhibit significantly more pronounced activation shifts at high-magnitude activations under minor perturbation compared to ID samples. AdaSCALE enables stronger scaling for likely ID samples and weaker scaling for likely OOD samples, yielding highly separable energy scores. Our approach achieves state-of-the-art OOD detection performance, outperforming the latest rival OptFS by 14.94% in near-OOD and 21.67% in far-OOD datasets in average FPR@95 metric on the ImageNet-1k benchmark across eight diverse architectures. The code is available at: https://github.com/sudarshanregmi/AdaSCALE/</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.08023v3</guid></item><item><title>[cs updates on arXiv.org] Neuro Symbolic Knowledge Reasoning for Procedural Video Question Answering</title><link>https://arxiv.org/abs/2503.14957</link><description>arXiv:2503.14957v5 Announce Type: replace 
Abstract: In this work we present Knowledge Module Learning (KML) to understand and reason over procedural tasks that requires models to learn structured and compositional procedural knowledge. KML is a neurosymbolic framework that learns relation categories within a knowledge graph as neural knowledge modules and composes them into executable reasoning programs generated by large language models (LLMs). Each module encodes a specific procedural relation capturing how each entity type such as tools are related to steps, purpose of each tool, and steps of each task. Given a question conditioned on a task shown in a video, then KML performs multistep reasoning with transparent, traceable intermediate states. Our theoretical analysis demonstrated two desired properties of KML. KML satisfy strong optimal conditions for modelling KG relations as neural mappings, providing strong foundations for generalizable procedural reasoning. It also shows a bound on the expected error when it performs multistep reasoning. To evaluate this model, we construct a large procedural knowledge graph (PKG) consisting of diverse instructional domains by integrating the COIN instructional video dataset, and COIN ontology, commonsense relations from ConceptNet, and structured extractions from LLMs, followed by expert verification. We then generate question and answer pairs by applying graph traversal templates over the PKG, constructing the PKR-QA benchmark for procedural knowledge reasoning. Experiments show that KML improves structured reasoning performance while providing interpretable step-by-step traces, outperforming LLM-only and black-box neural baselines. Code is publicly available at https://github.com/LUNAProject22/KML.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.14957v5</guid></item><item><title>[cs updates on arXiv.org] Machine learning surrogate models of many-body dispersion interactions in polymer melts</title><link>https://arxiv.org/abs/2503.15149</link><description>arXiv:2503.15149v2 Announce Type: replace 
Abstract: Accurate prediction of many-body dispersion (MBD) interactions is essential for understanding the van der Waals forces that govern the behavior of many complex molecular systems. However, the high computational cost of MBD calculations limits their direct application in large-scale simulations. In this work, we introduce a machine learning surrogate model specifically designed to predict MBD forces in polymer melts, a system that demands accurate MBD description and offers structural advantages for machine learning approaches. Our model is based on a trimmed SchNet architecture that selectively retains the most relevant atomic connections and incorporates trainable radial basis functions for geometric encoding. We validate our surrogate model on datasets from polyethylene, polypropylene, and polyvinyl chloride melts, demonstrating high predictive accuracy and robust generalization across diverse polymer systems. In addition, the model captures key physical features, such as the characteristic decay behavior of MBD interactions, providing valuable insights for optimizing cutoff strategies. Characterized by high computational efficiency, our surrogate model enables practical incorporation of MBD effects into large-scale molecular simulations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.15149v2</guid></item><item><title>[cs updates on arXiv.org] CAPE: Connectivity-Aware Path Enforcement Loss for Curvilinear Structure Delineation</title><link>https://arxiv.org/abs/2504.00753</link><description>arXiv:2504.00753v2 Announce Type: replace 
Abstract: Promoting the connectivity of curvilinear structures, such as neuronal processes in biomedical scans and blood vessels in CT images, remains a key challenge in semantic segmentation. Traditional pixel-wise loss functions, including cross-entropy and Dice losses, often fail to capture high-level topological connectivity, resulting in topological mistakes in graphs obtained from prediction maps. In this paper, we propose CAPE (Connectivity-Aware Path Enforcement), a novel loss function designed to enforce connectivity in graphs obtained from segmentation maps by optimizing a graph connectivity metric. CAPE uses the graph representation of the ground truth to select node pairs and determine their corresponding paths within the predicted segmentation through a shortest-path algorithm. Using this, we penalize both disconnections and false positive connections, effectively promoting the model to preserve topological correctness. Experiments on 2D and 3D datasets, including neuron and blood vessel tracing demonstrate that CAPE significantly improves topology-aware metrics and outperforms state-of-the-art methods.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.00753v2</guid></item><item><title>[cs updates on arXiv.org] Smart Exploration in Reinforcement Learning using Bounded Uncertainty Models</title><link>https://arxiv.org/abs/2504.05978</link><description>arXiv:2504.05978v3 Announce Type: replace 
Abstract: Reinforcement learning (RL) is a powerful framework for decision-making in uncertain environments, but it often requires large amounts of data to learn an optimal policy. We address this challenge by incorporating prior model knowledge to guide exploration and accelerate the learning process. Specifically, we assume access to a model set that contains the true transition kernel and reward function. We optimize over this model set to obtain upper and lower bounds on the Q-function, which are then used to guide the exploration of the agent. We provide theoretical guarantees on the convergence of the Q-function to the optimal Q-function under the proposed class of exploring policies. Furthermore, we also introduce a data-driven regularized version of the model set optimization problem that ensures the convergence of the class of exploring policies to the optimal policy. Lastly, we show that when the model set has a specific structure, namely the bounded-parameter MDP (BMDP) framework, the regularized model set optimization problem becomes convex and simple to implement. In this setting, we also prove finite-time convergence to the optimal policy under mild assumptions. We demonstrate the effectiveness of the proposed exploration strategy, which we call BUMEX (Bounded Uncertainty Model-based Exploration), in a simulation study. The results indicate that the proposed method can significantly accelerate learning in benchmark examples. A toolbox is available at https://github.com/JvHulst/BUMEX.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.05978v3</guid></item><item><title>[cs updates on arXiv.org] Semantic Depth Matters: Explaining Errors of Deep Vision Networks through Perceived Class Similarities</title><link>https://arxiv.org/abs/2504.09956</link><description>arXiv:2504.09956v2 Announce Type: replace 
Abstract: Understanding deep neural network (DNN) behavior requires more than evaluating classification accuracy alone; analyzing errors and their predictability is equally crucial. Current evaluation methodologies lack transparency, particularly in explaining the underlying causes of network misclassifications. To address this, we introduce a novel framework that investigates the relationship between the semantic hierarchy depth perceived by a network and its real-data misclassification patterns. Central to our framework is the Similarity Depth (SD) metric, which quantifies the semantic hierarchy depth perceived by a network along with a method of evaluation of how closely the network's errors align with its internally perceived similarity structure. We also propose a graph-based visualization of model semantic relationships and misperceptions. A key advantage of our approach is that leveraging class templates -- representations derived from classifier layer weights -- is applicable to already trained networks without requiring additional data or experiments. Our approach reveals that deep vision networks encode specific semantic hierarchies and that high semantic depth improves the compliance between perceived class similarities and actual errors.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.09956v2</guid></item><item><title>[cs updates on arXiv.org] XY-Cut++: Advanced Layout Ordering via Hierarchical Mask Mechanism on a Novel Benchmark</title><link>https://arxiv.org/abs/2504.10258</link><description>arXiv:2504.10258v3 Announce Type: replace 
Abstract: Document Reading Order Recovery is a fundamental task in document image understanding, playing a pivotal role in enhancing Retrieval-Augmented Generation (RAG) and serving as a critical preprocessing step for large language models (LLMs). Existing methods often struggle with complex layouts(e.g., multi-column newspapers), high-overhead interactions between cross-modal elements (visual regions and textual semantics), and a lack of robust evaluation benchmarks. We introduce XY-Cut++, an advanced layout ordering method that integrates pre-mask processing, multi-granularity segmentation, and cross-modal matching to address these challenges. Our method significantly enhances layout ordering accuracy compared to traditional XY-Cut techniques. Specifically, XY-Cut++ achieves state-of-the-art performance (98.8 BLEU overall) while maintaining simplicity and efficiency. It outperforms existing baselines by up to 24\% and demonstrates consistent accuracy across simple and complex layouts on the newly introduced DocBench-100 dataset. This advancement establishes a reliable foundation for document structure recovery, setting a new standard for layout ordering tasks and facilitating more effective RAG and LLM preprocessing.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.10258v3</guid></item><item><title>[cs updates on arXiv.org] Diffusion Generative Recommendation with Continuous Tokens</title><link>https://arxiv.org/abs/2504.12007</link><description>arXiv:2504.12007v4 Announce Type: replace 
Abstract: Recent advances in generative artificial intelligence, particularly large language models (LLMs), have opened new opportunities for enhancing recommender systems (RecSys). Most existing LLM-based RecSys approaches operate in a discrete space, using vector-quantized tokenizers to align with the inherent discrete nature of language models. However, these quantization methods often result in lossy tokenization and suboptimal learning, primarily due to inaccurate gradient propagation caused by the non-differentiable argmin operation in standard vector quantization. Inspired by the emerging trend of embracing continuous tokens in language models, we propose ContRec, a novel framework that seamlessly integrates continuous tokens into LLM-based RecSys. Specifically, ContRec consists of two key modules: a sigma-VAE Tokenizer, which encodes users/items with continuous tokens; and a Dispersive Diffusion module, which captures implicit user preference. The tokenizer is trained with a continuous Variational Auto-Encoder (VAE) objective, where three effective techniques are adopted to avoid representation collapse. By conditioning on the previously generated tokens of the LLM backbone during user modeling, the Dispersive Diffusion module performs a conditional diffusion process with a novel Dispersive Loss, enabling high-quality user preference generation through next-token diffusion. Finally, ContRec leverages both the textual reasoning output from the LLM and the latent representations produced by the diffusion model for Top-K item retrieval, thereby delivering comprehensive recommendation results. Extensive experiments on four datasets demonstrate that ContRec consistently outperforms both traditional and SOTA LLM-based recommender systems. Our results highlight the potential of continuous tokenization and generative modeling for advancing the next generation of recommender systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.12007v4</guid></item><item><title>[cs updates on arXiv.org] On the Need to Rethink Trust in AI Assistants for Software Development: A Critical Review</title><link>https://arxiv.org/abs/2504.12461</link><description>arXiv:2504.12461v4 Announce Type: replace 
Abstract: Trust is a fundamental concept in human decision-making and collaboration that has long been studied in philosophy and psychology. However, software engineering (SE) articles often use the term trust informally; providing an explicit definition or embedding results in established trust models is rare. In SE research on AI assistants, this practice culminates in equating trust with the likelihood of accepting generated content, which, in isolation, does not capture the full conceptual complexity of trust. Without a common definition, true secondary research on trust is impossible. The objectives of our research were: (1) to present the psychological and philosophical foundations of human trust, (2) to systematically study how trust is conceptualized in SE and the related disciplines human-computer interaction and information systems, and (3) to discuss limitations of equating trust with content acceptance, outlining how SE research can adopt existing trust models to overcome the widespread informal use of the term trust. We conducted a literature review across disciplines and a critical review of recent SE articles with a focus on trust conceptualizations. We found that trust is rarely defined or conceptualized in SE articles. Related disciplines commonly embed their methodology and results in established trust models, clearly distinguishing, for example, between initial trust and trust formation and between appropriate and inappropriate trust. On a meta-scientific level, other disciplines even discuss whether and when trust can be applied to AI assistants at all. Our study reveals a significant maturity gap of trust research in SE compared to other disciplines. We provide concrete recommendations on how SE researchers can adopt established trust models and instruments to study trust in AI assistants beyond the acceptance of generated software artifacts.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.12461v4</guid></item><item><title>[cs updates on arXiv.org] Physics-Guided Multimodal Transformers are the Necessary Foundation for the Next Generation of Meteorological Science</title><link>https://arxiv.org/abs/2504.14174</link><description>arXiv:2504.14174v2 Announce Type: replace 
Abstract: This position paper argues that the next generation of artificial intelligence in meteorological and climate sciences must transition from fragmented hybrid heuristics toward a unified paradigm of physics-guided multimodal transformers. While purely data-driven models have achieved significant gains in predictive accuracy, they often treat atmospheric processes as mere visual patterns, frequently producing results that lack scientific consistency or violate fundamental physical laws. We contend that current ``hybrid'' attempts to bridge this gap remain ad-hoc and struggle to scale across the heterogeneous nature of meteorological data ranging from satellite imagery to sparse sensor measurements. We argue that the transformer architecture, through its inherent capacity for cross-modal alignment, provides the only viable foundation for a systematic integration of domain knowledge via physical constraint embedding and physics-informed loss functions. By advocating for this unified architectural shift, we aim to steer the community away from ``black-box'' curve fitting and toward AI systems that are inherently falsifiable, scientifically grounded, and robust enough to address the existential challenges of extreme weather and climate change.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.14174v2</guid></item><item><title>[cs updates on arXiv.org] NoWag: A Unified Framework for Shape Preserving Compression of Large Language Models</title><link>https://arxiv.org/abs/2504.14569</link><description>arXiv:2504.14569v5 Announce Type: replace 
Abstract: Large language models (LLMs) exhibit remarkable performance across various natural language processing tasks but suffer from immense computational and memory demands, limiting their deployment in resource-constrained environments. To address this challenge, we propose NoWag (Normalized Weight and Activation Guided Compression), a unified framework for one-shot shape preserving compression algorithms. We apply NoWag to compress Llama-2 (7B, 13B, 70B) and Llama-3 (8B, 70B) models using two popular shape-preserving techniques: vector quantization (NoWag-VQ) and unstructured/semi-structured pruning (NoWag-P). Our results show that NoWag-VQ significantly outperforms state-of-the-art one-shot vector quantization methods, while NoWag-P performs competitively against leading pruning techniques. These findings highlight underlying commonalities between these compression paradigms and suggest promising directions for future research. Our code is available at https://github.com/LawrenceRLiu/NoWag</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.14569v5</guid></item><item><title>[cs updates on arXiv.org] Range Image-Based Implicit Neural Compression for LiDAR Point Clouds</title><link>https://arxiv.org/abs/2504.17229</link><description>arXiv:2504.17229v2 Announce Type: replace 
Abstract: This paper presents a novel scheme to efficiently compress Light Detection and Ranging~(LiDAR) point clouds, enabling high-precision 3D scene archives, and such archives pave the way for a detailed understanding of the corresponding 3D scenes. We focus on 2D range images~(RIs) as a lightweight format for representing 3D LiDAR observations. Although conventional image compression techniques can be adapted to improve compression efficiency for RIs, their practical performance is expected to be limited due to differences in bit precision and the distinct pixel value distribution characteristics between natural images and RIs. We propose a novel implicit neural representation~(INR)--based RI compression method that effectively handles floating-point valued pixels. The proposed method divides RIs into depth and mask images and compresses them using patch-wise and pixel-wise INR architectures with model pruning and quantization, respectively. Experiments on the KITTI dataset show that the proposed method outperforms existing image, point cloud, RI, and INR-based compression methods in terms of 3D reconstruction and detection quality at low bitrates and decoding latency.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.17229v2</guid></item><item><title>[cs updates on arXiv.org] Doxing via the Lens: Revealing Location-related Privacy Leakage on Multi-modal Large Reasoning Models</title><link>https://arxiv.org/abs/2504.19373</link><description>arXiv:2504.19373v4 Announce Type: replace 
Abstract: Recent advances in multi-modal large reasoning models (MLRMs) have shown significant ability to interpret complex visual content. While these models enable impressive reasoning capabilities, they also introduce novel and underexplored privacy risks. In this paper, we identify a novel category of privacy leakage in MLRMs: Adversaries can infer sensitive geolocation information, such as a user's home address or neighborhood, from user-generated images, including selfies captured in private settings. To formalize and evaluate these risks, we propose a three-level visual privacy risk framework that categorizes image content based on contextual sensitivity and potential for location inference. We further introduce DoxBench, a curated dataset of 500 real-world images reflecting diverse privacy scenarios. Our evaluation across 11 advanced MLRMs and MLLMs demonstrates that these models consistently outperform non-expert humans in geolocation inference and can effectively leak location-related private information. This significantly lowers the barrier for adversaries to obtain users' sensitive geolocation information. We further analyze and identify two primary factors contributing to this vulnerability: (1) MLRMs exhibit strong reasoning capabilities by leveraging visual clues in combination with their internal world knowledge; and (2) MLRMs frequently rely on privacy-related visual clues for inference without any built-in mechanisms to suppress or avoid such usage. To better understand and demonstrate real-world attack feasibility, we propose GeoMiner, a collaborative attack framework that decomposes the prediction process into two stages: clue extraction and reasoning to improve geolocation performance while introducing a novel attack perspective. Our findings highlight the urgent need to reassess inference-time privacy risks in MLRMs to better protect users' sensitive information.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.19373v4</guid></item><item><title>[cs updates on arXiv.org] Mixture of Experts for Decentralized Generative AI and Reinforcement Learning in Wireless Networks: A Comprehensive Survey</title><link>https://arxiv.org/abs/2504.19660</link><description>arXiv:2504.19660v2 Announce Type: replace 
Abstract: Mixture of Experts (MoE) has emerged as a promising paradigm for scaling model capacity while preserving computational efficiency, particularly in large-scale machine learning architectures such as large language models (LLMs). Recent advances in MoE have facilitated its adoption in wireless networks to address the increasing complexity and heterogeneity of modern communication systems. This paper presents a comprehensive survey of the MoE framework in wireless networks, highlighting its potential in optimizing resource efficiency, improving scalability, and enhancing adaptability across diverse network tasks. We first introduce the fundamental concepts of MoE, including various gating mechanisms and the integration with generative AI (GenAI) and reinforcement learning (RL). Subsequently, we discuss the extensive applications of MoE across critical wireless communication scenarios, such as vehicular networks, unmanned aerial vehicles (UAVs), satellite communications, heterogeneous networks, integrated sensing and communication (ISAC), and mobile edge networks. Furthermore, key applications in channel prediction, physical layer signal processing, radio resource management, network optimization, and security are thoroughly examined. Additionally, we present a detailed overview of open-source datasets that are widely used in MoE-based models to support diverse machine learning tasks. Finally, this survey identifies crucial future research directions for MoE, emphasizing the importance of advanced training techniques, resource-aware gating strategies, and deeper integration with emerging 6G technologies.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.19660v2</guid></item><item><title>[cs updates on arXiv.org] Deep-ICE: the first globally optimal algorithm for minimizing 0-1 loss in two-layer ReLU and maxout networks</title><link>https://arxiv.org/abs/2505.05740</link><description>arXiv:2505.05740v2 Announce Type: replace 
Abstract: This paper introduces the first globally optimal algorithm for the empirical risk minimization problem of two-layer maxout and ReLU networks, i.e., minimizing the number of misclassifications. The algorithm has a worst-case time complexity of $O\left(N^{DK+1}\right)$, where $K$ denotes the number of hidden neurons and $D$ represents the number of features. It can be can be generalized to accommodate arbitrary computable loss functions without affecting its computational complexity. Our experiments demonstrate that the proposed algorithm provides provably exact solutions for small-scale datasets. To handle larger datasets, we introduce a novel coreset selection method that reduces the data size to a manageable scale, making it feasible for our algorithm. This extension enables efficient processing of large-scale datasets and achieves significantly improved performance, with a 20-30\% reduction in misclassifications for both training and prediction, compared to state-of-the-art approaches (neural networks trained using gradient descent and support vector machines), when applied to the same models (two-layer networks with fixed hidden nodes and linear models).</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.05740v2</guid></item><item><title>[cs updates on arXiv.org] NurValues: Real-World Nursing Values Evaluation for Large Language Models in Clinical Context</title><link>https://arxiv.org/abs/2505.08734</link><description>arXiv:2505.08734v2 Announce Type: replace 
Abstract: While LLMs have demonstrated medical knowledge and conversational ability, their deployment in clinical practice raises new risks: patients may place greater trust in LLM-generated responses than in nurses' professional judgments, potentially intensifying nurse-patient conflicts. Such risks highlight the urgent need of evaluating whether LLMs align with the core nursing values upheld by human nurses. This work introduces the first benchmark for nursing value alignment, consisting of five core value dimensions distilled from international nursing codes: Altruism, Human Dignity, Integrity, Justice, and Professionalism. We define two-level tasks on the benchmark, considering the two characteristics of emerging nurse-patient conflicts. The Easy-Level dataset consists of 2,200 value-aligned and value-violating instances, which are collected through a five-month longitudinal field study across three hospitals of varying tiers; The Hard-Level dataset is comprised of 2,200 dialogue-based instances that embed contextual cues and subtle misleading signals, which increase adversarial complexity and better reflect the subjectivity and bias of narrators in the context of emerging nurse-patient conflicts. We evaluate a total of 23 SoTA LLMs on their ability to align with nursing values, and find that general LLMs outperform medical ones, and Justice is the hardest value dimension. As the first real-world benchmark for healthcare value alignment, NurValues provides novel insights into how LLMs navigate ethical challenges in clinician-patient interactions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.08734v2</guid></item><item><title>[cs updates on arXiv.org] Cochain: Balancing Insufficient and Excessive Collaboration in LLM Agent Workflows</title><link>https://arxiv.org/abs/2505.10936</link><description>arXiv:2505.10936v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated impressive performance in executing complex reasoning tasks. Chain-of-thought effectively enhances reasoning capabilities by unlocking the potential of large models, while multi-agent systems provide more comprehensive solutions by integrating the collective intelligence of multiple agents. However, both approaches face significant limitations. Single-agent with chain-of-thought, due to the inherent complexity of designing cross-domain prompts, faces collaboration challenges. Meanwhile, multi-agent systems consume substantial tokens and inevitably dilute the primary problem, which is particularly problematic in business workflow tasks. To address these challenges, we propose Cochain, a collaboration prompting framework that effectively solves the business workflow collaboration problem by combining knowledge and prompts at a reduced cost. Specifically, we construct an integrated knowledge graph that incorporates knowledge from multiple stages. Furthermore, by maintaining and retrieving a prompts tree, we can obtain prompt information relevant to other stages of the business workflow. We perform extensive evaluations of Cochain across multiple datasets, demonstrating that Cochain outperforms all baselines in both prompt engineering and multi-agent LLMs. Additionally, expert evaluation results indicate that the use of a small model in combination with Cochain outperforms GPT-4.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.10936v2</guid></item><item><title>[cs updates on arXiv.org] QVGen: Pushing the Limit of Quantized Video Generative Models</title><link>https://arxiv.org/abs/2505.11497</link><description>arXiv:2505.11497v5 Announce Type: replace 
Abstract: Video diffusion models (DMs) have enabled high-quality video synthesis. Yet, their substantial computational and memory demands pose serious challenges to real-world deployment, even on high-end GPUs. As a commonly adopted solution, quantization has proven notable success in reducing cost for image DMs, while its direct application to video DMs remains ineffective. In this paper, we present QVGen, a novel quantization-aware training (QAT) framework tailored for high-performance and inference-efficient video DMs under extremely low-bit quantization (e.g., 4-bit or below). We begin with a theoretical analysis demonstrating that reducing the gradient norm is essential to facilitate convergence for QAT. To this end, we introduce auxiliary modules ($\Phi$) to mitigate large quantization errors, leading to significantly enhanced convergence. To eliminate the inference overhead of $\Phi$, we propose a rank-decay strategy that progressively eliminates $\Phi$. Specifically, we repeatedly employ singular value decomposition (SVD) and a proposed rank-based regularization $\mathbf{\gamma}$ to identify and decay low-contributing components. This strategy retains performance while zeroing out additional inference overhead. Extensive experiments across $4$ state-of-the-art (SOTA) video DMs, with parameter sizes ranging from $1.3\text{B}\sim14\text{B}$, show that QVGen is the first to reach full-precision comparable quality under 4-bit settings. Moreover, it significantly outperforms existing methods. For instance, our 3-bit CogVideoX-2B achieves improvements of $+25.28$ in Dynamic Degree and $+8.43$ in Scene Consistency on VBench. Code and models are available at https://github.com/ModelTC/QVGen.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.11497v5</guid></item><item><title>[cs updates on arXiv.org] MVAR: Visual Autoregressive Modeling with Scale and Spatial Markovian Conditioning</title><link>https://arxiv.org/abs/2505.12742</link><description>arXiv:2505.12742v2 Announce Type: replace 
Abstract: Essential to visual generation is efficient modeling of visual data priors. Conventional next-token prediction methods define the process as learning the conditional probability distribution of successive tokens. Recently, next-scale prediction methods redefine the process to learn the distribution over multi-scale representations, significantly reducing generation latency. However, these methods condition each scale on all previous scales and require each token to consider all preceding tokens, exhibiting scale and spatial redundancy. To better model the distribution by mitigating redundancy, we propose Markovian Visual AutoRegressive modeling (MVAR), a novel autoregressive framework that introduces scale and spatial Markov assumptions to reduce the complexity of conditional probability modeling. Specifically, we introduce a scale-Markov trajectory that only takes as input the features of adjacent preceding scale for next-scale prediction, enabling the adoption of a parallel training strategy that significantly reduces GPU memory consumption. Furthermore, we propose spatial-Markov attention, which restricts the attention of each token to a localized neighborhood of size k at corresponding positions on adjacent scales, rather than attending to every token across these scales, for the pursuit of reduced modeling complexity. Building on these improvements, we reduce the computational complexity of attention calculation from O(N^2) to O(Nk), enabling training with just eight NVIDIA RTX 4090 GPUs and eliminating the need for KV cache during inference. Extensive experiments on ImageNet demonstrate that MVAR achieves comparable or superior performance with both small model trained from scratch and large fine-tuned models, while reducing the average GPU memory footprint by 3.0x.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.12742v2</guid></item><item><title>[cs updates on arXiv.org] Field Matters: A Lightweight LLM-enhanced Method for CTR Prediction</title><link>https://arxiv.org/abs/2505.14057</link><description>arXiv:2505.14057v2 Announce Type: replace 
Abstract: Click-through rate (CTR) prediction is a fundamental task in modern recommender systems. In recent years, the integration of large language models (LLMs) has been shown to effectively enhance the performance of traditional CTR methods. However, existing LLM-enhanced methods often require extensive processing of detailed textual descriptions for large-scale instances or user/item entities, leading to substantial computational overhead. To address this challenge, this work introduces LLaCTR, a novel and lightweight LLM-enhanced CTR method that employs a field-level enhancement paradigm. Specifically, LLaCTR first utilizes LLMs to distill crucial and lightweight semantic knowledge from small-scale feature fields through self-supervised field-feature fine-tuning. Subsequently, it leverages this field-level semantic knowledge to enhance both feature representation and feature interactions. In our experiments, we integrate LLaCTR with six representative CTR models across four datasets, demonstrating its superior performance in terms of both effectiveness and efficiency compared to existing LLM-enhanced methods. Our code is available at https://github.com/istarryn/LLaCTR.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.14057v2</guid></item><item><title>[cs updates on arXiv.org] Byte Pair Encoding for Efficient Time Series Forecasting</title><link>https://arxiv.org/abs/2505.14411</link><description>arXiv:2505.14411v3 Announce Type: replace 
Abstract: Existing time series tokenization methods predominantly encode a constant number of samples into individual tokens. This inflexible approach can generate excessive tokens for even simple patterns like extended constant values, resulting in substantial computational overhead. Inspired by the success of byte pair encoding, we propose the first pattern-centric tokenization scheme for time series analysis. Based on a discrete vocabulary of frequent motifs, our method merges samples with underlying patterns into tokens, compressing time series adaptively. Exploiting our finite set of motifs and the continuous properties of time series, we further introduce conditional decoding as a lightweight yet powerful post-hoc optimization method, which requires no gradient computation and adds no computational overhead. On recent time series foundation models, our motif-based tokenization improves forecasting performance by 36% and boosts efficiency by 1990% on average. Conditional decoding further reduces MSE by up to 44%. In an extensive analysis, we demonstrate the adaptiveness of our tokenization to diverse temporal patterns, its generalization to unseen data, and its meaningful token representations capturing distinct time series properties, including statistical moments and trends.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.14411v3</guid></item><item><title>[cs updates on arXiv.org] From Prediction to Perfection: Introducing Refinement to Autoregressive Image Generation</title><link>https://arxiv.org/abs/2505.16324</link><description>arXiv:2505.16324v2 Announce Type: replace 
Abstract: Autoregressive (AR) image generators offer a language-model-friendly approach to image generation by predicting discrete image tokens in a causal sequence. However, unlike diffusion models, AR models lack a mechanism to refine previous predictions, limiting their generation quality. In this paper, we introduce TensorAR, a new AR paradigm that reformulates image generation from next-token prediction to next-tensor prediction. By generating overlapping windows of image patches (tensors) in a sliding fashion, TensorAR enables iterative refinement of previously generated content. To prevent information leakage during training, we propose a discrete tensor noising scheme, which perturbs input tokens via codebook-indexed noise. TensorAR is implemented as a plug-and-play module compatible with existing AR models. Extensive experiments on LlamaGEN, Open-MAGVIT2, and RAR demonstrate that TensorAR significantly improves the generation performance of autoregressive models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.16324v2</guid></item><item><title>[cs updates on arXiv.org] Beyond Face Swapping: A Diffusion-Based Digital Human Benchmark for Multimodal Deepfake Detection</title><link>https://arxiv.org/abs/2505.16512</link><description>arXiv:2505.16512v5 Announce Type: replace 
Abstract: In recent years, the explosive advancement of deepfake technology has posed a critical and escalating threat to public security: diffusion-based digital human generation. Unlike traditional face manipulation methods, such models can generate highly realistic videos with consistency via multimodal control signals. Their flexibility and covertness pose severe challenges to existing detection strategies. To bridge this gap, we introduce DigiFakeAV, the new large-scale multimodal digital human forgery dataset based on diffusion models. Leveraging five of the latest digital human generation methods and a voice cloning method, we systematically construct a dataset comprising 60,000 videos (8.4 million frames), covering multiple nationalities, skin tones, genders, and real-world scenarios, significantly enhancing data diversity and realism. User studies demonstrate that the misrecognition rate by participants for DigiFakeAV reaches as high as 68%. Moreover, the substantial performance degradation of existing detection models on our dataset further highlights its challenges. To address this problem, we propose DigiShield, an effective detection baseline based on spatiotemporal and cross-modal fusion. By jointly modeling the 3D spatiotemporal features of videos and the semantic-acoustic features of audio, DigiShield achieves state-of-the-art (SOTA) performance on the DigiFakeAV and shows strong generalization on other datasets.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.16512v5</guid></item><item><title>[cs updates on arXiv.org] Diagnosing Vision Language Models' Perception by Leveraging Human Methods for Color Vision Deficiencies</title><link>https://arxiv.org/abs/2505.17461</link><description>arXiv:2505.17461v2 Announce Type: replace 
Abstract: Large-scale Vision-Language Models (LVLMs) are being deployed in real-world settings that require visual inference. As capabilities improve, applications in navigation, education, and accessibility are becoming practical. These settings require accommodation of perceptual variation rather than assuming a uniform visual experience. Color perception illustrates this requirement: it is central to visual understanding yet varies across individuals due to Color Vision Deficiencies, an aspect largely ignored in multimodal AI. In this work, we examine whether LVLMs can account for variation in color perception using the Ishihara Test. We evaluate model behavior through generation, confidence, and internal representation, using Ishihara plates as controlled stimuli that expose perceptual differences. Although models possess factual knowledge about color vision deficiencies and can describe the test, they fail to reproduce the perceptual outcomes experienced by affected individuals and instead default to normative color perception. These results indicate that current systems lack mechanisms for representing alternative perceptual experiences, raising concerns for accessibility and inclusive deployment in multimodal settings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.17461v2</guid></item><item><title>[cs updates on arXiv.org] Multimodal Conversation Structure Understanding</title><link>https://arxiv.org/abs/2505.17536</link><description>arXiv:2505.17536v3 Announce Type: replace 
Abstract: While multimodal large language models (LLMs) excel at dialogue, whether they can adequately parse the structure of conversation -- conversational roles and threading -- remains underexplored. In this work, we introduce a suite of tasks and release TV-MMPC, a new annotated dataset, for multimodal conversation structure understanding. Our evaluation reveals that while all multimodal LLMs outperform our heuristic baseline, even the best-performing model we consider experiences a substantial drop in performance when character identities of the conversation are anonymized. Beyond evaluation, we carry out a sociolinguistic analysis of 350,842 utterances in TVQA. We find that while female characters initiate conversations at rates in proportion to their speaking time, they are 1.2 times more likely than men to be cast as an addressee or side-participant, and the presence of side-participants shifts the conversational register from personal to social.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.17536v3</guid></item><item><title>[cs updates on arXiv.org] DGRAG: Distributed Graph-based Retrieval-Augmented Generation in Edge-Cloud Systems</title><link>https://arxiv.org/abs/2505.19847</link><description>arXiv:2505.19847v2 Announce Type: replace 
Abstract: Retrieval-Augmented Generation (RAG) improves factuality by grounding LLMs in external knowledge, yet conventional centralized RAG requires aggregating distributed data, raising privacy risks and incurring high retrieval latency and cost. We present DGRAG, a distributed graph-driven RAG framework for edge-cloud collaborative systems. Each edge device organizes local documents into a knowledge graph and periodically uploads subgraph-level summaries to the cloud for lightweight global indexing without exposing raw data. At inference time, queries are first answered on the edge; a gate mechanism assesses the confidence and consistency of multiple local generations to decide whether to return a local answer or escalate the query. For escalated queries, the cloud performs summary-based matching to identify relevant edges, retrieves supporting evidence from them, and generates the final response with a cloud LLM. Experiments on distributed question answering show that DGRAG consistently outperforms decentralized baselines while substantially reducing cloud overhead.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.19847v2</guid></item><item><title>[cs updates on arXiv.org] In-context Language Learning for Endangered Languages in Speech Recognition</title><link>https://arxiv.org/abs/2505.20445</link><description>arXiv:2505.20445v5 Announce Type: replace 
Abstract: With approximately 7,000 languages spoken worldwide, current large language models (LLMs) support only a small subset. Prior research indicates LLMs can learn new languages for certain tasks without supervised data. We extend this investigation to speech recognition, investigating whether LLMs can learn unseen, low-resource languages through in-context learning (ICL). With experiments on four diverse endangered languages that LLMs have not been trained on, we find that providing more relevant text samples enhances performance in both language modelling and Automatic Speech Recognition (ASR) tasks. Furthermore, we show that the probability-based approach outperforms the traditional instruction-based approach in language learning. Lastly, we show ICL enables LLMs to achieve ASR performance that is comparable to or even surpasses dedicated language models trained specifically for these languages, while preserving the original capabilities of the LLMs. Our code is publicly available.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.20445v5</guid></item><item><title>[cs updates on arXiv.org] Embodied AI with Foundation Models for Mobile Service Robots: A Systematic Review</title><link>https://arxiv.org/abs/2505.20503</link><description>arXiv:2505.20503v2 Announce Type: replace 
Abstract: Rapid advancements in foundation models, including Large Language Models, Vision-Language Models, Multimodal Large Language Models, and Vision-Language-Action Models, have opened new avenues for embodied AI in mobile service robotics. By combining foundation models with the principles of embodied AI, where intelligent systems perceive, reason, and act through physical interaction, mobile service robots can achieve more flexible understanding, adaptive behavior, and robust task execution in dynamic real-world environments. Despite this progress, embodied AI for mobile service robots continues to face fundamental challenges related to the translation of natural language instructions into executable robot actions, multimodal perception in human-centered environments, uncertainty estimation for safe decision-making, and computational constraints for real-time onboard deployment. In this paper, we present the first systematic review focused specifically on the integration of foundation models in mobile service robotics. We analyze how recent advances in foundation models address these core challenges through language-conditioned control, multimodal sensor fusion, uncertainty-aware reasoning, and efficient model scaling. We further examine real-world applications in domestic assistance, healthcare, and service automation, highlighting how foundation models enable context-aware, socially responsive, and generalizable robot behaviors. Beyond technical considerations, we discuss ethical, societal, and human-interaction implications associated with deploying foundation model-enabled service robots in human environments. Finally, we outline future research directions emphasizing reliability and lifelong adaptation, privacy-aware and resource-constrained deployment, and governance and human-in-the-loop frameworks required for safe, scalable, and trustworthy mobile service robotics.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.20503v2</guid></item><item><title>[cs updates on arXiv.org] Lifted Forward Planning in Relational Factored Markov Decision Processes with Concurrent Actions</title><link>https://arxiv.org/abs/2505.22147</link><description>arXiv:2505.22147v2 Announce Type: replace 
Abstract: Decision making is a central problem in AI that can be formalized using a Markov Decision Process. A problem is that, with increasing numbers of (indistinguishable) objects, the state space grows exponentially. To compute policies, the state space has to be enumerated. Even more possibilities have to be enumerated if the size of the action space depends on the size of the state space, especially if we allow concurrent actions. To tackle the exponential blow-up in the action and state space, we present a first-order representation to store the spaces in polynomial instead of exponential size in the number of objects and introduce Foreplan, a relational forward planner, which uses this representation to efficiently compute policies for numerous indistinguishable objects and actions. Additionally, we introduce an even faster approximate version of Foreplan. Moreover, Foreplan identifies how many objects an agent should act on to achieve a certain task given restrictions. Further, we provide a theoretical analysis and an empirical evaluation of Foreplan, demonstrating a speedup of at least four orders of magnitude.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.22147v2</guid></item><item><title>[cs updates on arXiv.org] Orca: Browsing at Scale Through User-Driven and AI-Facilitated Orchestration Across Malleable Webpages</title><link>https://arxiv.org/abs/2505.22831</link><description>arXiv:2505.22831v2 Announce Type: replace 
Abstract: Web-based activities span multiple webpages. However, conventional browsers with stacks of tabs cannot support operating and synthesizing large volumes of information across pages. While recent AI systems enable fully automated web browsing and information synthesis, they often diminish user agency and hinder contextual understanding. We explore how AI could instead augment user interactions with content across webpages and mitigate cognitive and manual efforts. Through literature on information tasks and web browsing challenges, and an iterative design process, we present novel interactions with our prototype web browser, Orca. Leveraging AI, Orca supports user-driven exploration, operation, organization, and synthesis of web content at scale. To enable browsing at scale, webpages are treated as malleable materials that humans and AI can collaboratively manipulate and compose into a malleable, dynamic, and browser-level workspace. Our evaluation revealed an increased "appetite" for information foraging, enhanced control, and more flexible sensemaking across a broader web information landscape.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.22831v2</guid></item><item><title>[cs updates on arXiv.org] PromptVFX: Text-Driven Fields for Open-World 3D Gaussian Animation</title><link>https://arxiv.org/abs/2506.01091</link><description>arXiv:2506.01091v2 Announce Type: replace 
Abstract: Visual effects (VFX) are key to immersion in modern films, games, and AR/VR. Creating 3D effects requires specialized expertise and training in 3D animation software and can be time consuming. Generative solutions typically rely on computationally intense methods such as diffusion models which can be slow at 4D inference. We reformulate 3D animation as a field prediction task and introduce a text-driven framework that infers a time-varying 4D flow field acting on 3D Gaussians. By leveraging large language models (LLMs) and vision-language models (VLMs) for function generation, our approach interprets arbitrary prompts (e.g., "make the vase glow orange, then explode") and instantly updates color, opacity, and positions of 3D Gaussians in real time. This design avoids overheads such as mesh extraction, manual or physics-based simulations and allows both novice and expert users to animate volumetric scenes with minimal effort on a consumer device even in a web browser. Experimental results show that simple textual instructions suffice to generate compelling time-varying VFX, reducing the manual effort typically required for rigging or advanced modeling. We thus present a fast and accessible pathway to language-driven 3D content creation that can pave the way to democratize VFX further. Code available at https://obsphera.github.io/promptvfx/.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.01091v2</guid></item><item><title>[cs updates on arXiv.org] Strategic Dialogue Assessment: The Crooked Path to Innocence</title><link>https://arxiv.org/abs/2506.01195</link><description>arXiv:2506.01195v3 Announce Type: replace 
Abstract: Language is often used strategically, particularly in high-stakes, adversarial settings, yet most work on pragmatics and LLMs centers on cooperativity. This leaves a gap in the systematic understanding of strategic communication in adversarial settings. To address this, we introduce SDA (Strategic Dialogue Assessment), a framework grounded in Gricean and game-theoretic pragmatics to assess strategic use of language. It adapts the ME Game jury function to make it empirically estimable for analyzing dialogue. Our approach incorporates two key adaptations: a commitment-based taxonomy of discourse moves, which provides a finer-grained account of strategic effects, and the use of estimable proxies grounded in Gricean maxims to operationalize abstract constructs such as credibility. Together, these adaptations build on discourse theory by treating discourse as the strategic management of commitments, enabling systematic evaluation of how conversational moves advance or undermine discourse goals. We further derive three interpretable metrics-Benefit at Turn (BAT), Penalty at Turn (PAT), and Normalized Relative Benefit at Turn (NRBAT)-to quantify the perceived strategic effects of discourse moves. We also present CPD (the Crooked Path Dataset), an annotated dataset of real courtroom cross-examinations, to demonstrate the framework's effectiveness. Using these tools, we evaluate a range of LLMs and show that LLMs generally exhibit limited pragmatic understanding of strategic language. While model size shows an increase in performance on our metrics, reasoning ability does not help and largely hurts, introducing overcomplication and internal confusion.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.01195v3</guid></item><item><title>[cs updates on arXiv.org] Spiking Brain Compression: Post-Training Second-order Compression for Spiking Neural Networks</title><link>https://arxiv.org/abs/2506.03996</link><description>arXiv:2506.03996v3 Announce Type: replace 
Abstract: Spiking Neural Networks (SNNs) have emerged as a new generation of energy-efficient neural networks suitable for implementation on neuromorphic hardware. As neuromorphic hardware has limited memory and computational resources, parameter pruning and quantization have recently been explored to improve the efficiency of SNNs. State-of-the-art SNN pruning/quantization methods employ multiple compression and training iterations, increasing the cost for pre-trained or very large SNNs. In this paper, we propose a novel one-shot post-training compression framework, Spiking Brain Compression (SBC), that extends the classical Optimal Brain Surgeon method to SNNs. SBC replaces the current-based objective found in the common layer-wise compression method with a spike-train-based objective whose Hessian is cheaply computable, allowing a single backward pass to compress parameters and analytically rescale the rest. Applying SBC to SNN pruning and quantization across event-based and static datasets (up to ImageNet), including SEW-ResNet152 and spike-driven Transformers, we achieve state-of-the-art one-shot post-training compression for SNNs, with single- to double-digit accuracy gains over ANN compression baselines ported to SNNs. We further report a synaptic-operation-based energy proxy and a calibration-size ablation, demonstrating robust performance under sub-one-sample-per-class calibration.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.03996v3</guid></item><item><title>[cs updates on arXiv.org] Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning</title><link>https://arxiv.org/abs/2506.04207</link><description>arXiv:2506.04207v2 Announce Type: replace 
Abstract: Inspired by the remarkable reasoning capabilities of Deepseek-R1 in complex textual tasks, many works attempt to incentivize similar capabilities in Multimodal Large Language Models (MLLMs) by directly applying reinforcement learning (RL). However, they still struggle to activate complex reasoning. In this paper, rather than examining multimodal RL in isolation, we delve into current training pipelines and identify three crucial phenomena: 1) Effective cold start initialization is critical for enhancing MLLM reasoning. Intriguingly, we find that initializing with carefully selected text data alone can lead to performance surpassing many recent multimodal reasoning models, even before multimodal RL. 2) Standard GRPO applied to multimodal RL suffers from gradient stagnation, which degrades training stability and performance. 3) Subsequent text-only RL training, following the multimodal RL phase, further enhances multimodal reasoning. This staged training approach effectively balances perceptual grounding and cognitive reasoning development. By incorporating the above insights and addressing multimodal RL issues, we introduce ReVisual-R1, achieving a new state-of-the-art among open-source 7B MLLMs on challenging benchmarks including MathVerse, MathVision, WeMath, LogicVista, DynaMath, and challenging AIME2024 and AIME2025.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.04207v2</guid></item><item><title>[cs updates on arXiv.org] SeedVR2: One-Step Video Restoration via Diffusion Adversarial Post-Training</title><link>https://arxiv.org/abs/2506.05301</link><description>arXiv:2506.05301v2 Announce Type: replace 
Abstract: Recent advances in diffusion-based video restoration (VR) demonstrate significant improvement in visual quality, yet yield a prohibitive computational cost during inference. While several distillation-based approaches have exhibited the potential of one-step image restoration, extending existing approaches to VR remains challenging and underexplored, particularly when dealing with high-resolution video in real-world settings. In this work, we propose a one-step diffusion-based VR model, termed as SeedVR2, which performs adversarial VR training against real data. To handle the challenging high-resolution VR within a single step, we introduce several enhancements to both model architecture and training procedures. Specifically, an adaptive window attention mechanism is proposed, where the window size is dynamically adjusted to fit the output resolutions, avoiding window inconsistency observed under high-resolution VR using window attention with a predefined window size. To stabilize and improve the adversarial post-training towards VR, we further verify the effectiveness of a series of losses, including a proposed feature matching loss without significantly sacrificing training efficiency. Extensive experiments show that SeedVR2 can achieve comparable or even better performance compared with existing VR approaches in a single step.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.05301v2</guid></item><item><title>[cs updates on arXiv.org] DCP-Bench-Open: Evaluating LLMs for Constraint Modelling of Discrete Combinatorial Problems</title><link>https://arxiv.org/abs/2506.06052</link><description>arXiv:2506.06052v3 Announce Type: replace 
Abstract: Discrete Combinatorial Problems (DCPs) are prevalent in industrial decision-making and optimisation. However, while constraint solving technologies for DCPs have advanced significantly, the core process of formalising them, namely constraint modelling, requires significant expertise and remains a bottleneck for wider adoption. Aiming to alleviate this bottleneck, recent studies have explored using Large Language Models (LLMs) to transform combinatorial problem descriptions into executable constraint models. However, the existing evaluation datasets for discrete constraint modelling are often limited to small, homogeneous, or domain-specific problems, which do not capture the diversity of real-world scenarios. This work addresses this gap by introducing DCP-Bench-Open, a novel benchmark that includes a diverse set of well-known discrete combinatorial problems sourced from the Constraint Programming (CP) and Operations Research (OR) communities, structured explicitly for evaluating LLM-driven constraint modelling. With this dataset, and given the variety of modelling frameworks, we compare and evaluate the modelling capabilities of LLMs for three distinct constraint modelling systems, which vary in abstraction level and underlying syntax. Notably, the results show higher performance when modelling with a high-level Python-based framework. Additionally, we systematically evaluate the use of prompt-based and inference-time compute methods across different LLMs, which further increase accuracy, reaching up to 91% on this highly challenging benchmark. DCP-Bench-Open is publicly available.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.06052v3</guid></item><item><title>[cs updates on arXiv.org] HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization</title><link>https://arxiv.org/abs/2506.07972</link><description>arXiv:2506.07972v2 Announce Type: replace 
Abstract: While Large Language Models (LLMs) have demonstrated significant advancements in reasoning and agent-based problem-solving, current evaluation methodologies fail to adequately assess their capabilities: existing benchmarks either rely on closed-ended questions prone to saturation and memorization, or subjective comparisons that lack consistency and rigor. In this work, we introduce HeuriGym, an agentic framework designed for evaluating heuristic algorithms generated by LLMs for combinatorial optimization problems, characterized by clearly defined objectives and expansive solution spaces. HeuriGym empowers LLMs to propose heuristics, receive evaluative feedback via code execution, and iteratively refine their solutions. We evaluate nine state-of-the-art models on nine problems across domains such as computer systems, logistics, and biology, exposing persistent limitations in tool use, planning, and adaptive reasoning. To quantify performance, we propose the Quality-Yield Index (QYI), a metric that captures both solution pass rate and quality. Even top models like GPT-o4-mini-high and Gemini-2.5-Pro attain QYI scores of only 0.6, well below the expert baseline of 1. Our open-source benchmark aims to guide the development of LLMs toward more effective and realistic problem-solving in scientific and engineering domains.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.07972v2</guid></item><item><title>[cs updates on arXiv.org] Read as You See: Guiding Unimodal LLMs for Low-Resource Explainable Harmful Meme Detection</title><link>https://arxiv.org/abs/2506.08477</link><description>arXiv:2506.08477v2 Announce Type: replace 
Abstract: Detecting harmful memes is crucial for safeguarding the integrity and harmony of online environments, yet existing detection methods are often resource-intensive, inflexible, and lacking explainability, limiting their applicability in assisting real-world web content moderation. We propose U-CoT+, a resource-efficient framework that prioritizes accessibility, flexibility and transparency in harmful meme detection by fully harnessing the capabilities of lightweight unimodal large language models (LLMs). Instead of directly prompting or fine-tuning large multimodal models (LMMs) as black-box classifiers, we avoid immediate reasoning over complex visual inputs but decouple meme content recognition from meme harmfulness analysis through a high-fidelity meme-to-text pipeline, which collaborates lightweight LMMs and LLMs to convert multimodal memes into natural language descriptions that preserve critical visual information, thus enabling text-only LLMs to "see" memes by "reading". Grounded in textual inputs, we further guide unimodal LLMs' reasoning under zero-shot Chain-of-Thoughts (CoT) prompting with targeted, interpretable, context-aware, and easily obtained human-crafted guidelines, thus providing accountable step-by-step rationales, while enabling flexible and efficient adaptation to diverse sociocultural criteria of harmfulness. Extensive experiments on seven benchmark datasets show that U-CoT+ achieves performance comparable to resource-intensive baselines, highlighting its effectiveness and potential as a scalable, explainable, and low-resource solution to support harmful meme detection.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.08477v2</guid></item><item><title>[cs updates on arXiv.org] In-Context Bias Propagation in LLM-Based Tabular Data Generation</title><link>https://arxiv.org/abs/2506.09630</link><description>arXiv:2506.09630v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) are increasingly used for synthetic tabular data generation through in-context learning (ICL), offering a practical solution for data augmentation in data scarce scenarios. While prior work has shown the potential of LLMs to improve downstream task performance through augmenting underrepresented groups, these benefits often assume access to a subset of unbiased in-context examples, representative of the real dataset. In real-world settings, however, data is frequently noisy and demographically skewed. In this paper, we systematically study how statistical biases within in-context examples propagate to the distribution of synthetic tabular data, showing that even mild in-context biases lead to global statistical distortions. We further introduce an adversarial scenario where a malicious contributor can inject bias into the synthetic dataset via a subset of in-context examples, ultimately compromising the fairness of downstream classifiers for a targeted and protected subgroup. Finally, we evaluate mitigation strategies based on preprocessing in-context examples, demonstrating that while such interventions can attenuate disparity, the inherent sensitivity of LLMs to adversarial prompts remains a persistent challenge. Our findings highlight a critical new vulnerability in LLM-based data generation pipelines within sensitive domains.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.09630v2</guid></item><item><title>[cs updates on arXiv.org] Breaking Bad Molecules: Are MLLMs Ready for Structure-Level Molecular Detoxification?</title><link>https://arxiv.org/abs/2506.10912</link><description>arXiv:2506.10912v3 Announce Type: replace 
Abstract: Toxicity remains a leading cause of early-stage drug development failure. Despite advances in molecular design and property prediction, the task of molecular toxicity repair, generating structurally valid molecular alternatives with reduced toxicity, has not yet been systematically defined or benchmarked. To fill this gap, we introduce ToxiMol, the first benchmark task for general-purpose Multimodal Large Language Models (MLLMs) focused on molecular toxicity repair. We construct a standardized dataset covering 11 primary tasks and 660 representative toxic molecules spanning diverse mechanisms and granularities. We design a prompt annotation pipeline with mechanism-aware and task-adaptive capabilities, informed by expert toxicological knowledge. In parallel, we propose an automated evaluation framework, ToxiEval, which integrates toxicity endpoint prediction, synthetic accessibility, drug-likeness, and structural similarity into a high-throughput evaluation chain for repair success. We systematically assess 43 mainstream general-purpose MLLMs and conduct multiple ablation studies to analyze key issues, including evaluation metrics, candidate diversity, and failure attribution. Experimental results show that although current MLLMs still face significant challenges on this task, they begin to demonstrate promising capabilities in toxicity understanding, semantic constraint adherence, and structure-aware editing.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.10912v3</guid></item><item><title>[cs updates on arXiv.org] JAFAR: Jack up Any Feature at Any Resolution</title><link>https://arxiv.org/abs/2506.11136</link><description>arXiv:2506.11136v3 Announce Type: replace 
Abstract: Foundation Vision Encoders have become essential for a wide range of dense vision tasks. However, their low-resolution spatial feature outputs necessitate feature upsampling to produce the high-resolution modalities required for downstream tasks. In this work, we introduce JAFAR, a lightweight and flexible feature upsampler that enhances the spatial resolution of visual features from any Foundation Vision Encoder to an arbitrary target resolution. JAFAR employs an attention-based module designed to promote semantic alignment between high-resolution queries, derived from low-level image features, and semantically enriched low-resolution keys, using Spatial Feature Transform (SFT) modulation. Notably, despite the absence of high-resolution supervision, we demonstrate that learning at low upsampling ratios and resolutions generalizes remarkably well to significantly higher output scales. Extensive experiments show that JAFAR effectively recovers fine-grained spatial details and consistently outperforms existing feature upsampling methods across a diverse set of downstream tasks. Project page at https://jafar-upsampler.github.io</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.11136v3</guid></item><item><title>[cs updates on arXiv.org] Beyond Random Sampling: Efficient Language Model Pretraining via Curriculum Learning</title><link>https://arxiv.org/abs/2506.11300</link><description>arXiv:2506.11300v2 Announce Type: replace 
Abstract: Curriculum learning-organizing training data from easy to hard-has improved efficiency across machine learning domains, yet remains underexplored for language model pretraining. We present the first systematic investigation of curriculum learning in LLM pretraining, with over 200 models trained on up to 100B tokens across three strategies: vanilla curriculum learning, pacing-based sampling, and interleaved curricula, guided by six difficulty metrics spanning linguistic and information-theoretic properties. We evaluate performance on eight benchmarks under three realistic scenarios: limited data, unlimited data, and continual training. Our experiments show that curriculum learning consistently accelerates convergence in early and mid-training phases,reducing training steps by $18-45\%$ to reach baseline performance. When applied as a warmup strategy before standard random sampling, curriculum learning yields sustained improvements up to $3.5\%$. We identify compression ratio, lexical diversity (MTLD), and readability (Flesch Reading Ease) as the most effective difficulty signals. Our findings demonstrate that data ordering-orthogonal to existing data selection methods-provides a practical mechanism for more efficient LLM pretraining.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.11300v2</guid></item><item><title>[cs updates on arXiv.org] DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs</title><link>https://arxiv.org/abs/2506.11558</link><description>arXiv:2506.11558v4 Announce Type: replace 
Abstract: Large Language Models (LLMs) have recently been extended to the video domain, enabling sophisticated video-language understanding. However, existing Video LLMs often exhibit limitations in fine-grained temporal reasoning, restricting their ability to precisely attribute responses to specific video moments, especially under constrained supervision. We introduce DaMO, a data-efficient Video LLM explicitly designed for accurate temporal reasoning and multimodal understanding. At its core, the proposed Temporal-aware Fuseformer employs a hierarchical dual-stream architecture that progressively captures temporal dynamics within each modality and effectively fuses complementary visual and audio information. To further enhance computational efficiency, DaMO integrates a global residual that reduces spatial redundancy while preserving essential semantic details. We train DaMO via a structured four-stage progressive training paradigm, incrementally equipping the model with multimodal alignment, semantic grounding, and temporal reasoning capabilities. This work also contributes multiple datasets augmented from existing ones with LLM-generated temporally grounded QA pairs for tasks requiring temporal supervision. Comprehensive experiments on temporal grounding and video QA benchmarks demonstrate that DaMO consistently surpasses prior methods, particularly in tasks demanding precise temporal alignment and reasoning. Our work establishes a promising direction for data-efficient video-language modeling.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.11558v4</guid></item><item><title>[cs updates on arXiv.org] Taxonomy of reduction matrices for Graph Coarsening</title><link>https://arxiv.org/abs/2506.11743</link><description>arXiv:2506.11743v2 Announce Type: replace 
Abstract: Graph coarsening aims to diminish the size of a graph to lighten its memory footprint, and has numerous applications in graph signal processing and machine learning. It is usually defined using a reduction matrix and a lifting matrix, which, respectively, allows to project a graph signal from the original graph to the coarsened one and back. This results in a loss of information measured by the so-called Restricted Spectral Approximation (RSA). Most coarsening frameworks impose a fixed relationship between the reduction and lifting matrices, generally as pseudo-inverses of each other, and seek to define a coarsening that minimizes the RSA. In this paper, we remark that the roles of these two matrices are not entirely symmetric: indeed, putting constraints on the lifting matrix alone ensures the existence of important objects such as the coarsened graph's adjacency matrix or Laplacian. In light of this, in this paper, we introduce a more general notion of reduction matrix, that is not necessarily the pseudo-inverse of the lifting matrix. We establish a taxonomy of ``admissible'' families of reduction matrices, discuss the different properties that they must satisfy and whether they admit a closed-form description or not. We show that, for a fixed coarsening represented by a fixed lifting matrix, the RSA can be further reduced simply by modifying the reduction matrix. We explore different examples, including some based on a constrained optimization process of the RSA. Since this criterion has also been linked to the performance of Graph Neural Networks, we also illustrate the impact of this choices on different node classification tasks on coarsened graphs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.11743v2</guid></item><item><title>[cs updates on arXiv.org] Continuous Evolution Pool: Taming Recurring Concept Drift in Online Time Series Forecasting</title><link>https://arxiv.org/abs/2506.14790</link><description>arXiv:2506.14790v2 Announce Type: replace 
Abstract: Recurring concept drift poses a dual challenge in online time series forecasting: mitigating catastrophic forgetting while adhering to strict privacy constraints that prevent retaining historical data. Existing approaches predominantly rely on parameter updates or experience replay, which inevitably suffer from knowledge overwriting or privacy risks. To address this, we propose the Continuous Evolution Pool (CEP), a privacy-preserving framework that maintains a dynamic pool of specialized forecasters. Instead of storing raw samples, CEP utilizes lightweight statistical genes to decouple concept identification from forecasting. Specifically, it employs a Retrieval mechanism to identify the nearest concept based on gene similarity, an Evolution strategy to spawn new forecasters upon detecting distribution shifts, and an Elimination policy to prune obsolete models under memory constraints. Experiments on real-world datasets demonstrate that CEP significantly outperforms state-of-the-art baselines, reducing forecasting error by over 20% without accessing historical ground truth.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.14790v2</guid></item><item><title>[cs updates on arXiv.org] Locality in Residuated-Lattice Structures</title><link>https://arxiv.org/abs/2506.16206</link><description>arXiv:2506.16206v4 Announce Type: replace 
Abstract: Many-valued models generalise the structures from classical model theory by defining truth values for a model with an arbitrary algebra. Just as algebraic varieties provide semantics for many non-classical propositional logics, models defined over algebras in a variety provide the semantics for the corresponding non-classical predicate logics. In particular, models defined over varieties of residuated lattices represent the model theory for first-order substructural logics.
  In this paper we study the extent to which the classical locality theorems from Hanf and Gaifman hold true in the residuated lattice setting. We demonstrate that the answer is sensitive both to how locality is understood in the generalised context and the behaviour of the truth-defining algebra. In the case of Hanf's theorem, we will show that the theorem fails for the natural understanding of local neighbourhoods, but is recoverable with an alternative understanding for well-connected residuated lattices. For Gaifman's theorem, rather than consider Gaifman normal forms directly we focus on the main lemma of the theorem from textbook proofs - that models which satisfy the same basic local sentences are elementarily equivalent. We prove that for a number of different understandings of locality, provided the algebra is well-behaved enough to express locality in its syntax, this main lemma can be recovered. In each case we will see the importance of an order-interpreting connective which creates a link between the modelling relation for models and formulas and the valuation function from formulas into the algebra. This link enables a syntactic encoding of back-and-forth systems providing the main technical ingredient to proofs of the main locality results.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.16206v4</guid></item><item><title>[cs updates on arXiv.org] Beyond Syntax: Action Semantics Learning for App Agents</title><link>https://arxiv.org/abs/2506.17697</link><description>arXiv:2506.17697v2 Announce Type: replace 
Abstract: The recent development of Large Language Models (LLMs) enables the rise of App agents that interpret user intent and operate smartphone Apps through actions such as clicking and scrolling. While prompt-based solutions with proprietary LLM APIs show promising ability, they incur heavy compute costs and external API dependency. Fine-tuning smaller open-source LLMs solves these limitations. However, current supervised fine-tuning methods use a syntax learning paradigm that forces agents to reproduce exactly the ground truth action strings, leading to out-of-distribution (OOD) vulnerability. To fill this gap, we propose Action Semantics Learning (ASL), a novel learning framework, where the learning objective is capturing the semantics of the ground truth actions. Specifically, inspired by the programming language theory, we define the action semantics for App agents as the state transition induced by the action in the user interface. Building on this insight, ASL employs a novel SEmantic Estimator~(SEE) to compute a semantic similarity to train the App agents in generating actions aligned with the semantics of ground truth actions, even when their syntactic forms differ. SEE is a flexible module that can be applied in both supervised and reinforcement fine-tuning paradigms. To support the effectiveness of ASL, we theoretically demonstrate the superior robustness of ASL for the OOD problem compared with the existing syntax learning paradigm. Extensive experiments across multiple offline and online benchmarks demonstrate that ASL significantly improves the accuracy and generalisation of App agents compared to existing methods.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.17697v2</guid></item><item><title>[cs updates on arXiv.org] Neural Cellular Automata: From Cells to Pixels</title><link>https://arxiv.org/abs/2506.22899</link><description>arXiv:2506.22899v2 Announce Type: replace 
Abstract: Neural Cellular Automata (NCAs) are bio-inspired dynamical systems in which identical cells iteratively apply a learned local update rule to self-organize into complex patterns, exhibiting regeneration, robustness, and spontaneous dynamics. Despite their success in texture synthesis and morphogenesis, NCAs remain largely confined to low-resolution outputs. This limitation stems from (1) training time and memory requirements that grow quadratically with grid size, (2) the strictly local propagation of information that impedes long-range cell communication, and (3) the heavy compute demands of real-time inference at high resolution. In this work, we overcome this limitation by pairing an NCA that evolves on a coarse grid with a lightweight implicit decoder that maps cell states and local coordinates to appearance attributes, enabling the same model to render outputs at arbitrary resolution. Moreover, because both the decoder and NCA updates are local, inference remains highly parallelizable. To supervise high-resolution outputs efficiently, we introduce task-specific losses for morphogenesis (growth from a seed) and texture synthesis with minimal additional memory and computation overhead. Our experiments across 2D/3D grids and mesh domains demonstrate that our hybrid models produce high-resolution outputs in real-time, and preserve the characteristic self-organizing behavior of NCAs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.22899v2</guid></item><item><title>[cs updates on arXiv.org] Governing Strategic Dynamics: Equilibrium Stabilization via Divergence-Driven Control</title><link>https://arxiv.org/abs/2506.23734</link><description>arXiv:2506.23734v2 Announce Type: replace 
Abstract: Black-box coevolution in mixed-motive games is often undermined by opponent-drift non-stationarity and noisy rollouts, which distort progress signals and can induce cycling, Red-Queen dynamics, and detachment. We propose the \emph{Marker Gene Method} (MGM), a curriculum-inspired governance mechanism that stabilizes selection by anchoring evaluation to cross-generational marker individuals, together with DWAM and conservative marker-update rules to reduce spurious updates. We also introduce NGD-Div, which adapts the key update threshold using a divergence proxy and natural-gradient optimization. We provide theoretical analysis in strictly competitive settings and evaluate MGM integrated with evolution strategies (MGM-E-NES) on coordination games and a resource-depletion Markov game. MGM-E-NES reliably recovers target coordination in Stag Hunt and Battle of the Sexes, achieving final cooperation probabilities close to $(1,1)$ (e.g., $0.991\pm0.01/1.00\pm0.00$ and $0.97\pm0.00/0.97\pm0.00$ for the two players). In the Markov resource game, it maintains high and stable state-conditioned cooperation across 30 seeds, with final cooperation of $\approx 0.954/0.980/0.916$ in \textsc{Rich}/\textsc{Poor}/\textsc{Collapsed} (both players; small standard deviations), indicating welfare-aligned and state-dependent behavior. Overall, MGM-E-NES transfers across tasks with minimal hyperparameter changes and yields consistently stable training dynamics, showing that top-level governance can substantially improve the robustness of black-box coevolution in dynamic environments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.23734v2</guid></item><item><title>[cs updates on arXiv.org] FAIR-MATCH: A Multi-Objective Framework for Bias Mitigation in Reciprocal Dating Recommendations</title><link>https://arxiv.org/abs/2507.01063</link><description>arXiv:2507.01063v2 Announce Type: replace 
Abstract: Online dating platforms have fundamentally transformed the formation of romantic relationships, with millions of users worldwide relying on algorithmic matching systems to find compatible partners. However, current recommendation systems in dating applications suffer from significant algorithmic deficiencies, including but not limited to popularity bias, filter bubble effects, and inadequate reciprocity modeling that limit effectiveness and introduce harmful biases. This research integrates foundational work with recent empirical findings to deliver a detailed analysis of dating app recommendation systems, highlighting key issues and suggesting research-backed solutions. Through analysis of reciprocal recommendation frameworks, fairness evaluation metrics, and industry implementations, we demonstrate that current systems achieve modest performance with collaborative filtering reaching 25.1\% while reciprocal methods achieve 28.7\%. Our proposed mathematical framework addresses these limitations through enhanced similarity measures, multi-objective optimization, and fairness-aware algorithms that maintain competitive accuracy while improving demographic representation to reduce algorithmic bias.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.01063v2</guid></item><item><title>[cs updates on arXiv.org] Symbiotic Backscatter Communication: A Design Perspective on the Modulation Scheme of Backscatter Devices</title><link>https://arxiv.org/abs/2507.01782</link><description>arXiv:2507.01782v3 Announce Type: replace 
Abstract: Symbiotic Backscatter Communication (SBC) has emerged as a spectrum-efficient and low-power communication technology, where backscatter devices (BDs) modulate and reflect incident radio frequency (RF) signals from primary transmitters (PTs). While previous studies have assumed a circularly symmetric complex Gaussian (CSCG) distribution for the BD's signal, this assumption may not be practical because the high complexity of generating CSCG signals is not supported by the low-cost BD. In this paper, we address this gap by investigating SBC for two low-complexity modulation schemes, i.e., $M$-ary amplitude-shift keying (MASK) and $M$-ary phase-shift keying (MPSK), where BD's signals inherently deviate from CSCG distribution. Our goal is to derive the achievable rate of the PT and BD under the MASK/MPSK and to design MASK/MPSK modulation scheme for maximizing the PT's rate. Towards this end, we first derive the expressions of both the PT's rate and BD's rate. Theoretical results reveal that whether or not the BD improves the PT's rate depends on the phase of MASK/MPSK modulation, while the BD's rate is independent of this phase. We then formulate two optimization problems to maximize the PT's rate by adjusting the phase under the MASK and MPSK modulation schemes, respectively, and derive the optimal phases for each modulation scheme in closed forms. Simulation results demonstrate that the optimal phase of MASK/MPSK can ensure an improvement in the PT's rate, and reveal that a low-order ASK modulation is better than a low-order PSK for the BD in terms of improving PT's rate, especially when the direct link is not significantly weaker than the backscatter link in SBC.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.01782v3</guid></item><item><title>[cs updates on arXiv.org] Generalization in Reinforcement Learning for Radio Access Networks</title><link>https://arxiv.org/abs/2507.06602</link><description>arXiv:2507.06602v3 Announce Type: replace 
Abstract: Modern RAN operate in highly dynamic and heterogeneous environments, where hand-tuned, rule-based RRM algorithms often underperform. While RL can surpass such heuristics in constrained settings, the diversity of deployments and unpredictable radio conditions introduce major generalization challenges. Data-driven policies frequently overfit to training conditions, degrading performance in unseen scenarios. To address this, we propose a generalization-centered RL framework for RAN control that: (i) robustly reconstructs dynamically varying states from partial and noisy observations, while encoding static and semi-static information, such as radio nodes, cell attributes, and their topology, through graph representations; (ii) applies domain randomization to broaden the training distribution; and (iii) distributes data generation across multiple actors while centralizing training in a cloud-compatible architecture aligned with O-RAN principles. Although generalization increases computational and data-management complexity, our distributed design mitigates this by scaling data collection and training across diverse network conditions. Applied to downlink link adaptation in five 5G benchmarks, our policy improves average throughput and spectral efficiency by ~10% over an OLLA baseline (10% BLER target) in full-buffer MIMO/mMIMO and by &gt;20% under high mobility. It matches specialized RL in full-buffer traffic and achieves up to 4- and 2-fold gains in eMBB and mixed-traffic benchmarks, respectively. In nine-cell deployments, GAT models offer 30% higher throughput over MLP baselines. These results, combined with our scalable architecture, offer a path toward AI-native 6G RAN using a single, generalizable RL agent.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.06602v3</guid></item><item><title>[cs updates on arXiv.org] BlindSight: Harnessing Sparsity for Efficient Vision-Language Models</title><link>https://arxiv.org/abs/2507.09071</link><description>arXiv:2507.09071v2 Announce Type: replace 
Abstract: Large vision-language models (VLMs) enable joint processing of text and images. However, incorporating vision data significantly increases the prompt length, resulting in a longer time to first token (TTFT). This bottleneck can be alleviated by leveraging the inherent sparsity in the attention computation. Analyzing these attention patterns in VLMs when processing a series of images, we observe the absence of inter-image attention in a substantial portion of layers. Based on this, we propose BlindSight: an approach to optimize multi-image VLM inference using an input-template-aware attention sparsity mask with no runtime overhead. We utilize a dataset to derive a prompt-agnostic categorization for attention heads: Dense, Sink, Intra-Image, and Intra-Image+Sink. We develop a Triton-based GPU kernel to leverage this sparsity. BlindSight achieves a 1.8-3.2x speedup in the attention computation (prompt length 36K-300K). BlindSight generalizes across VLMs (Qwen2-VL, Qwen2.5-VL, Gemma 3), with only a 0.78% absolute accuracy degradation on average on multi-image comprehension benchmarks. Finally, we advocate for the design of efficient VLMs that combine BlindSight-inspired sparse and dense layers.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.09071v2</guid></item><item><title>[cs updates on arXiv.org] The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner</title><link>https://arxiv.org/abs/2507.13332</link><description>arXiv:2507.13332v3 Announce Type: replace 
Abstract: Length generalization, the ability to solve problems of longer sequences than those observed during training, poses a core challenge of Transformer-based large language models (LLM). Although existing studies have predominantly focused on data-driven approaches for arithmetic operations and symbolic manipulation tasks, these approaches tend to be task-specific with limited overall performance. To pursue a more general solution, this paper focuses on a broader case of reasoning problems that are computable, i.e., problems that algorithms can solve, thus can be solved by the Turing Machine. From this perspective, this paper proposes Turing MAchine Imitation Learning (TAIL) to improve the length generalization ability of LLMs. TAIL synthesizes chain-of-thoughts (CoT) data that imitate the execution process of a Turing Machine by computer programs, which linearly expands the reasoning steps into atomic states to alleviate shortcut learning and explicit memory fetch mechanism to reduce the difficulties of dynamic and long-range data access in elementary operations. To validate the reliability and universality of TAIL, we construct a challenging synthetic dataset covering 8 classes of algorithms and 18 tasks. Without bells and whistles, TAIL significantly improves the length generalization ability as well as the performance of Qwen2.5-7B on various tasks using only synthetic data, surpassing previous methods and DeepSeek-R1. The experimental results reveal that the key concepts in the Turing Machine, instead of the thinking styles, are indispensable for TAIL for length generalization, through which the model exhibits read-and-write behaviors consistent with the properties of the Turing Machine in their attention layers. This work provides a promising direction for future research in the learning of LLM reasoning from synthetic data.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.13332v3</guid></item><item><title>[cs updates on arXiv.org] AEDR: Training-Free AI-Generated Image Attribution via Autoencoder Double-Reconstruction</title><link>https://arxiv.org/abs/2507.18988</link><description>arXiv:2507.18988v2 Announce Type: replace 
Abstract: The rapid advancement of image-generation technologies has made it possible for anyone to create photorealistic images using generative models, raising significant security concerns. To mitigate malicious use, tracing the origin of such images is essential. Reconstruction-based attribution methods offer a promising solution, but they often suffer from reduced accuracy and high computational costs when applied to state-of-the-art (SOTA) models. To address these challenges, we propose AEDR (AutoEncoder Double-Reconstruction), a novel training-free attribution method designed for generative models with continuous autoencoders. Unlike existing reconstruction-based approaches that rely on the value of a single reconstruction loss, AEDR performs two consecutive reconstructions using the model's autoencoder, and adopts the ratio of these two reconstruction losses as the attribution signal. This signal is further calibrated using the image homogeneity metric to improve accuracy, which inherently cancels out absolute biases caused by image complexity, with autoencoder-based reconstruction ensuring superior computational efficiency. Experiments on eight top latent diffusion models show that AEDR achieves 25.5% higher attribution accuracy than existing reconstruction-based methods, while requiring only 1% of the computational time.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.18988v2</guid></item><item><title>[cs updates on arXiv.org] Sparse Equation Matching: A Derivative-Free Learning for General-Order Dynamical Systems</title><link>https://arxiv.org/abs/2507.20072</link><description>arXiv:2507.20072v2 Announce Type: replace 
Abstract: Equation discovery is a fundamental learning task for uncovering the underlying dynamics of complex systems, with wide-ranging applications in areas such as brain connectivity analysis, climate modeling, gene regulation, and physical simulation. However, many existing approaches rely on accurate derivative estimation and are limited to first-order dynamical systems, restricting their applicability in real-world scenarios. In this work, we propose Sparse Equation Matching (SEM), a unified framework that encompasses several existing equation discovery methods under a common formulation. SEM introduces an integral-based sparse regression approach using Green's functions, enabling derivative-free estimation of differential operators and their associated driving functions in general-order dynamical systems. The effectiveness of SEM is demonstrated through extensive simulations, benchmarking its performance against derivative-based approaches. We then apply SEM to electroencephalographic (EEG) data recorded during multiple oculomotor tasks, collected from 52 participants in a brain-computer interface experiment. Our method identifies active brain regions across participants and reveals task-specific connectivity patterns. These findings offer valuable insights into brain connectivity and the underlying neural mechanisms.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.20072v2</guid></item><item><title>[cs updates on arXiv.org] IntentFlow: Investigating Fluid Dynamics of Intent Communication in Generative AI</title><link>https://arxiv.org/abs/2507.22134</link><description>arXiv:2507.22134v4 Announce Type: replace 
Abstract: Generative AI shifts interaction toward intent-based outcome specification, despite user intents being inherently vague, fluid, and evolving. While a growing body of HCI research has proposed diverse interaction techniques to support this process, there is limited understanding of what the key aspects of intent communication are and how they interplay to shape users' workflows. To bridge this gap, we first conduct a systematic literature review of 46 HCI papers and identify four core aspects of intent communication support: intent articulation, exploration, management, and synchronization. To investigate how these aspects interplay in practice, we developed IntentFlow, a research probe that embodies all four aspects for a writing task, and conducted a comparative study (N=12). Our action-level behavioral analysis reveals that comprehensive support enables verification-driven refinement and progressive intent curation, reduces cognitive effort, and improves users' sense of control and understanding of intent-output alignment. We conclude with design implications for building generative AI systems that support intent communication as a dynamic, iterative process.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.22134v4</guid></item><item><title>[cs updates on arXiv.org] DA-Occ: Direction-Aware 2D Convolution for Efficient and Geometry-Preserving 3D Occupancy Prediction</title><link>https://arxiv.org/abs/2507.23599</link><description>arXiv:2507.23599v3 Announce Type: replace 
Abstract: Efficient and high-accuracy 3D occupancy prediction is crucial for ensuring the performance of autonomous driving (AD) systems. However, many existing methods involve trade-offs between accuracy and efficiency. Some achieve high precision but with slow inference speed, while others adopt purely bird's-eye-view (BEV)-based 2D representations to accelerate processing, inevitably sacrificing vertical cues and compromising geometric integrity. To overcome these limitations, we propose a pure 2D framework that achieves efficient 3D occupancy prediction while preserving geometric integrity. Unlike conventional Lift-Splat-Shoot (LSS) methods that rely solely on depth scores to lift 2D features into 3D space, our approach additionally introduces a height-score projection to encode vertical geometric structure. We further employ direction-aware convolution to extract geometric features along both vertical and horizontal orientations, effectively balancing accuracy and computational efficiency. On the Occ3D-nuScenes, the proposed method achieves an mIoU of 39.3\% and an inference speed of 27.7 FPS, effectively balancing accuracy and efficiency. In simulations on edge devices, the inference speed reaches 14.8 FPS, further demonstrating the method's applicability for real-time deployment in resource-constrained environments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.23599v3</guid></item><item><title>[cs updates on arXiv.org] Mind the Gap: The Divergence Between Human and LLM-Generated Tasks</title><link>https://arxiv.org/abs/2508.00282</link><description>arXiv:2508.00282v3 Announce Type: replace 
Abstract: Humans constantly generate a diverse range of tasks guided by internal motivations. While generative agents powered by large language models (LLMs) aim to simulate this complex behavior, it remains uncertain whether they operate on similar cognitive principles. To address this, we conducted a task-generation experiment comparing human responses with those of an LLM agent (GPT-4o). We find that human task generation is consistently influenced by psychological drivers, including personal values (e.g., Openness to Change) and cognitive style. Even when these psychological drivers are explicitly provided to the LLM, it fails to reflect the corresponding behavioral patterns. They produce tasks that are markedly less social, less physical, and thematically biased toward abstraction. Interestingly, while the LLM's tasks were perceived as more fun and novel, this highlights a disconnect between its linguistic proficiency and its capacity to generate human-like, embodied goals. We conclude that there is a core gap between the value-driven, embodied nature of human cognition and the statistical patterns of LLMs, highlighting the necessity of incorporating intrinsic motivation and physical grounding into the design of more human-aligned agents.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.00282v3</guid></item><item><title>[cs updates on arXiv.org] A Message Passing Realization of Expected Free Energy Minimization</title><link>https://arxiv.org/abs/2508.02197</link><description>arXiv:2508.02197v2 Announce Type: replace 
Abstract: We present a message passing approach to Expected Free Energy (EFE) minimization on factor graphs, based on the theory introduced in arXiv:2504.14898. By reformulating EFE minimization as Variational Free Energy minimization with epistemic priors, we transform a combinatorial search problem into a tractable inference problem solvable through standard variational techniques. Applying our message passing method to factorized state-space models enables efficient policy inference. We evaluate our method on environments with epistemic uncertainty: a stochastic gridworld and a partially observable Minigrid task. Agents using our approach consistently outperform conventional KL-control agents on these tasks, showing more robust planning and efficient exploration under uncertainty. In the stochastic gridworld environment, EFE-minimizing agents avoid risky paths, while in the partially observable minigrid setting, they conduct more systematic information-seeking. This approach bridges active inference theory with practical implementations, providing empirical evidence for the efficiency of epistemic priors in artificial agents.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.02197v2</guid></item><item><title>[cs updates on arXiv.org] X-SAM: From Segment Anything to Any Segmentation</title><link>https://arxiv.org/abs/2508.04655</link><description>arXiv:2508.04655v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) demonstrate strong capabilities in broad knowledge representation, yet they are inherently deficient in pixel-level perceptual understanding. Although the Segment Anything Model (SAM) represents a significant advancement in visual-prompt-driven image segmentation, it exhibits notable limitations in multi-mask prediction and category-specific segmentation tasks, and it cannot integrate all segmentation tasks within a unified model architecture. To address these limitations, we present X-SAM, a streamlined Multimodal Large Language Model (MLLM) framework that extends the segmentation paradigm from \textit{segment anything} to \textit{any segmentation}. Specifically, we introduce a novel unified framework that enables more advanced pixel-level perceptual comprehension for MLLMs. Furthermore, we propose a new segmentation task, termed Visual GrounDed (VGD) segmentation, which segments all instance objects with interactive visual prompts and empowers MLLMs with visual grounded, pixel-wise interpretative capabilities. To enable effective training on diverse data sources, we present a unified training strategy that supports co-training across multiple datasets. Experimental results demonstrate that X-SAM achieves state-of-the-art performance on a wide range of image segmentation benchmarks, highlighting its efficiency for multimodal, pixel-level visual understanding. Code is available at https://github.com/wanghao9610/X-SAM.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.04655v2</guid></item><item><title>[cs updates on arXiv.org] Rethinking Creativity Evaluation: A Critical Analysis of Existing Creativity Evaluations</title><link>https://arxiv.org/abs/2508.05470</link><description>arXiv:2508.05470v4 Announce Type: replace 
Abstract: We examine, analyze, and compare four representative creativity measures--perplexity, LLM-as-a-Judge, the Creativity Index (CI; measuring n-gram overlap with web corpora), and syntactic templates (detecting repetition of common part-of-speech patterns)--across the diverse creative domains, such as creative writing, unconventional problem-solving, and research ideation. For each domain, we compile datasets with human-aligned creative and uncreative examples and evaluate each metric's ability to discriminate between the two sets. Our analyses reveal limited consistency both across domains and metrics, as metrics that distinguish creativity in one domain fail in others (e.g., CI correctly distinguishes in creative writing but fails in problem-solving), and different metrics often disagree on the same data points (e.g., CI suggests one set to be more creative, while perplexity indicates the other set to be more creative.) We highlight key limitations, such as perplexity reflecting fluency rather than novelty; LLM-as-a-Judge producing inconsistent judgments under minor prompt variations and exhibiting bias towards particular labels; CI primarily measuring lexical diversity, with high sensitivity to implementation choices; and syntactic templates being ineffective in settings dominated by formulaic language. Our findings underscore the need for more robust, generalizable evaluation frameworks that better align with human judgments of creativity.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.05470v4</guid></item><item><title>[cs updates on arXiv.org] Arce: Augmented Roberta with Contextualized Elucidations for Ner in Automated Rule Checking</title><link>https://arxiv.org/abs/2508.07286</link><description>arXiv:2508.07286v3 Announce Type: replace 
Abstract: Accurate information extraction from specialized texts is a critical challenge for automated rule checking (ARC) in the architecture, engineering, and construction (AEC) domain. While large language models (LLMs) possess strong reasoning capabilities, their deployment in resource-constrained AEC environments is often impractical. Conversely, standard efficient models struggle with the significant domain gap. Although this gap can be mitigated by pre-training on large, humancurated corpora, such approaches are labor-intensive and costly. To address this, we propose ARCE (Augmented RoBERTa with Contextualized Elucidations), a novel knowledge distillation framework that leverages LLMs to synthesize a task-oriented corpus, termed Cote, for incrementally pre-training smaller models. ARCE systematically explores the optimal strategy for knowledge transfer. Our extensive experiments demonstrate that ARCE establishes a new state-of-the-art on a benchmark AEC dataset, achieving a Macro-F1 score of 77.20% and outperforming both domain-specific baselines and fine-tuned LLMs. Crucially, our study reveals a less is more principle: simple, direct explanations prove significantly more effective for domain adaptation than complex, role-based rationales in the NER task, which tend to introduce semantic noise. The source code will be made publicly available upon acceptance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.07286v3</guid></item><item><title>[cs updates on arXiv.org] Splat Feature Solver</title><link>https://arxiv.org/abs/2508.12216</link><description>arXiv:2508.12216v2 Announce Type: replace 
Abstract: Feature lifting has emerged as a crucial component in 3D scene understanding, enabling the attachment of rich image feature descriptors (e.g., DINO, CLIP) onto splat-based 3D representations. The core challenge lies in optimally assigning rich general attributes to 3D primitives while addressing the inconsistency issues from multi-view images. We present a unified, kernel- and feature-agnostic formulation of the feature lifting problem as a sparse linear inverse problem, which can be solved efficiently in closed form. Our approach admits a provable upper bound on the global optimal error under convex losses for delivering high quality lifted features. To address inconsistencies and noise in multi-view observations, we introduce two complementary regularization strategies to stabilize the solution and enhance semantic fidelity. Tikhonov Guidance enforces numerical stability through soft diagonal dominance, while Post-Lifting Aggregation filters noisy inputs via feature clustering. Extensive experiments demonstrate that our approach achieves state-of-the-art performance on open-vocabulary 3D segmentation benchmarks, outperforming training-based, grouping-based, and heuristic-forward baselines while producing lifted features in minutes. Our \textbf{code} is available in the \href{https://github.com/saliteta/splat-distiller/tree/main}{\textcolor{blue}{GitHub}}. We provide additional \href{https://splat-distiller.pages.dev/}{\textcolor{blue}{website}} for more visualization, as well as the \href{https://www.youtube.com/watch?v=CH-G5hbvArM}{\textcolor{blue}{video}}.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.12216v2</guid></item><item><title>[cs updates on arXiv.org] OPERA: A Reinforcement Learning--Enhanced Orchestrated Planner-Executor Architecture for Reasoning-Oriented Multi-Hop Retrieval</title><link>https://arxiv.org/abs/2508.16438</link><description>arXiv:2508.16438v3 Announce Type: replace 
Abstract: Recent advances in large language models (LLMs) and dense retrievers have driven significant progress in retrieval-augmented generation (RAG). However, existing approaches face significant challenges in complex reasoning-oriented multi-hop retrieval tasks: 1) Ineffective reasoning-oriented planning: Prior methods struggle to generate robust multi-step plans for complex queries, as rule-based decomposers perform poorly on out-of-template questions. 2) Suboptimal reasoning-driven retrieval: Related methods employ limited query reformulation, leading to iterative retrieval loops that often fail to locate golden documents. 3) Insufficient reasoning-guided filtering: Prevailing methods lack the fine-grained reasoning to effectively filter salient information from noisy results, hindering utilization of retrieved knowledge. Fundamentally, these limitations all stem from the weak coupling between retrieval and reasoning in current RAG architectures. We introduce the Orchestrated Planner-Executor Reasoning Architecture (OPERA), a novel reasoning-driven retrieval framework. OPERA's Goal Planning Module (GPM) decomposes questions into sub-goals, which are executed by a Reason-Execute Module (REM) with specialized components for precise reasoning and effective retrieval. To train OPERA, we propose Multi-Agents Progressive Group Relative Policy Optimization (MAPGRPO), a novel variant of GRPO. Experiments on complex multi-hop benchmarks show OPERA's superior performance, validating both the MAPGRPO method and OPERA's design.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.16438v3</guid></item><item><title>[cs updates on arXiv.org] MSPCaps: A Multi-Scale Patchify Capsule Network with Cross-Agreement Routing for Visual Recognition</title><link>https://arxiv.org/abs/2508.16922</link><description>arXiv:2508.16922v2 Announce Type: replace 
Abstract: Capsule Network (CapsNet) has demonstrated significant potential in visual recognition by capturing spatial relationships and part-whole hierarchies for learning equivariant feature representations. However, existing CapsNet and variants often rely on a single high-level feature map, overlooking the rich complementary information from multi-scale features. Furthermore, conventional feature fusion strategies (e.g., addition and concatenation) struggle to reconcile multi-scale feature discrepancies, leading to suboptimal classification performance. To address these limitations, we propose the Multi-Scale Patchify Capsule Network (MSPCaps), a novel architecture that integrates multi-scale feature learning and efficient capsule routing. Specifically, MSPCaps consists of three key components: a Multi-Scale ResNet Backbone (MSRB), a Patchify Capsule Layer (PatchifyCaps), and Cross-Agreement Routing (CAR) blocks. First, the MSRB extracts diverse multi-scale feature representations from input images, preserving both fine-grained details and global contextual information. Second, the PatchifyCaps partitions these multi-scale features into primary capsules using a uniform patch size, equipping the model with the ability to learn from diverse receptive fields. Finally, the CAR block adaptively routes the multi-scale capsules by identifying cross-scale prediction pairs with maximum agreement. Unlike the simple concatenation of multiple self-routing blocks, CAR ensures that only the most coherent capsules contribute to the final voting. Our proposed MSPCaps achieves remarkable scalability and superior robustness, consistently surpassing multiple baseline methods in terms of classification accuracy, with configurations ranging from a highly efficient Tiny model (344.3K parameters) to a powerful Large model (10.9M parameters), highlighting its potential in advancing feature representation learning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.16922v2</guid></item><item><title>[cs updates on arXiv.org] Preconditioned pseudo-time continuation for parameterized inverse problems</title><link>https://arxiv.org/abs/2508.21155</link><description>arXiv:2508.21155v2 Announce Type: replace 
Abstract: We consider parameterized variational inverse problems that are constrained by partial differential equations (PDEs). We seek to efficiently compute the solution of the inverse problem when auxiliary model parameters, which appear in the governing PDE, are varied. Computing the solution of the inverse problem for different auxiliary parameter values is crucial for uncertainty quantification. This, however, is computationally challenging since it requires solving many optimization problems for different realizations of the auxiliary parameters. We leverage pseudo-time continuation and solve an initial value problem to evolve the optimal solution along an auxiliary parameter path. This article introduces the use of an adaptive quasi-Newton Hessian preconditioner to accelerate the computation. Our proposed preconditioner exploits properties of the pseudo-time continuation process to achieve reliable and efficient computation. We elaborate our proposed framework and elucidate its properties for two nonlinear inverse problems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.21155v2</guid></item><item><title>[cs updates on arXiv.org] Playing Markov Games Without Observing Payoffs</title><link>https://arxiv.org/abs/2509.00179</link><description>arXiv:2509.00179v3 Announce Type: replace 
Abstract: Optimization under uncertainty is a fundamental problem in learning and decision-making, particularly in multi-agent systems. Previously, Feldman, Kalai, and Tennenholtz [2010] demonstrated the ability to efficiently compete in repeated symmetric two-player matrix games without observing payoffs, as long as the opponents actions are observed. In this paper, we introduce and formalize a new class of zero-sum symmetric Markov games, which extends the notion of symmetry from matrix games to the Markovian setting. We show that even without observing payoffs, a player who knows the transition dynamics and observes only the opponents sequence of actions can still compete against an adversary who may have complete knowledge of the game. We formalize three distinct notions of symmetry in this setting and show that, under these conditions, the learning problem can be reduced to an instance of online learning, enabling the player to asymptotically match the return of the opponent despite lacking payoff observations. Our algorithms apply to both matrix and Markov games, and run in polynomial time with respect to the size of the game and the number of episodes. Our work broadens the class of games in which robust learning is possible under severe informational disadvantage and deepens the connection between online learning and adversarial game theory.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.00179v3</guid></item><item><title>[cs updates on arXiv.org] FNODE: Flow-Matching for data-driven simulation of constrained multibody systems</title><link>https://arxiv.org/abs/2509.00183</link><description>arXiv:2509.00183v3 Announce Type: replace 
Abstract: Data-driven modeling of constrained multibody dynamics remains challenged by (i) the training cost of Neural ODEs, which typically require backpropagation through an ODE solver, and (ii) error accumulation in rollout predictions. We introduce a Flow-Matching Neural ODE (FNODE) framework that learns the acceleration mapping directly from trajectory data by supervising accelerations rather than integrated states, turning training into a supervised regression problem and eliminating the ODE-adjoint/solver backpropagation bottleneck. Acceleration targets are obtained efficiently via numerical differentiation using a hybrid fast Fourier transform (FFT) and finite-difference (FD) scheme. Kinematic constraints are enforced through coordinate partitioning: FNODE learns accelerations only for the independent generalized coordinates, while the dependent coordinates are recovered by solving the position-level constraint equations. We evaluate FNODE on single and triple mass-spring-damper systems, a double pendulum, a slider crank with and without friction, a vehicle model, and a cart-pole, and compare against MBD-NODE, LSTM, and fully connected baselines. Across these benchmarks, FNODE achieves improved prediction accuracy and training/runtime efficiency, while maintaining constraint satisfaction through the partitioning procedure. Our code and scripts are released as open source to support reproducibility and follow-on research.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.00183v3</guid></item><item><title>[cs updates on arXiv.org] Energy Efficient Exact and Approximate Systolic Array Architecture for Matrix Multiplication</title><link>https://arxiv.org/abs/2509.00778</link><description>arXiv:2509.00778v2 Announce Type: replace 
Abstract: Deep Neural Networks (DNNs) require highly efficient matrix multiplication engines for complex computations. This paper presents a systolic array architecture incorporating novel exact and approximate processing elements (PEs), designed using energy-efficient positive partial product and negative partial product cells, termed as PPC and NPPC, respectively. The proposed 8-bit exact and approximate PE designs are employed in a 8x8 systolic array, which achieves a energy savings of 22% and 32%, respectively, compared to the existing design. To demonstrate their effectiveness, the proposed PEs are integrated into a systolic array (SA) for Discrete Cosine Transform (DCT) computation, achieving high output quality with a PSNR of 38.21,dB. Furthermore, in an edge detection application using convolution, the approximate PE achieves a PSNR of 30.45,dB. These results highlight the potential of the proposed design to deliver significant energy efficiency while maintaining competitive output quality, making it well-suited for error-resilient image and vision processing applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.00778v2</guid></item><item><title>[cs updates on arXiv.org] Robust Deep Monte Carlo Counterfactual Regret Minimization: Addressing Theoretical Risks in Neural Fictitious Self-Play</title><link>https://arxiv.org/abs/2509.00923</link><description>arXiv:2509.00923v2 Announce Type: replace 
Abstract: Monte Carlo Counterfactual Regret Minimization (MCCFR) has emerged as a cornerstone algorithm for solving extensive-form games, but its integration with deep neural networks introduces scale-dependent challenges that manifest differently across game complexities. This paper presents a comprehensive analysis of how neural MCCFR component effectiveness varies with game scale and proposes an adaptive framework for selective component deployment. We identify that theoretical risks such as nonstationary target distribution shifts, action support collapse, variance explosion, and warm-starting bias have scale-dependent manifestation patterns, requiring different mitigation strategies for small versus large games. Our proposed Robust Deep MCCFR framework incorporates target networks with delayed updates, uniform exploration mixing, variance-aware training objectives, and comprehensive diagnostic monitoring. Through systematic ablation studies on Kuhn and Leduc Poker, we demonstrate scale-dependent component effectiveness and identify critical component interactions. The best configuration achieves final exploitability of 0.0628 on Kuhn Poker, representing a 60% improvement over the classical framework (0.156). On the more complex Leduc Poker domain, selective component usage achieves exploitability of 0.2386, a 23.5% improvement over the classical framework (0.3703) and highlighting the importance of careful component selection over comprehensive mitigation. Our contributions include: (1) a formal theoretical analysis of risks in neural MCCFR, (2) a principled mitigation framework with convergence guarantees, (3) comprehensive multi-scale experimental validation revealing scale-dependent component interactions, and (4) practical guidelines for deployment in larger games.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.00923v2</guid></item><item><title>[cs updates on arXiv.org] Abex-rat: Synergizing Abstractive Augmentation and Adversarial Training for Classification of Occupational Accident Reports</title><link>https://arxiv.org/abs/2509.02072</link><description>arXiv:2509.02072v4 Announce Type: replace 
Abstract: The automatic classification of occupational accident reports is pivotal for workplace safety analysis but is persistently hindered by severe class imbalance and data scarcity. In this paper, we propose ABEX-RAT, a resource-efficient framework that synergizes generative data augmentation with robust adversarial learning. Unlike computationally expensive large language models (LLMs) fine-tuning, our approach employs a two-stage abstractive-expansive (ABEX) pipeline: it first utilizes a prompt-guided LLM to distill label-critical semantics into concise abstracts, which are then expanded into diverse synthetic samples to balance the data distribution. Subsequently, we train a lightweight classifier using a random adversarial training (RAT) protocol, which stochastically injects perturbations to enhance generalization without significant computational overhead. Experimental results on the OSHA dataset demonstrate that ABEXRAT establishes a new state-of-the-art, achieving a Macro-F1 score of 90.32% and significantly outperforming both traditional baselines and fine-tuned large models. This confirms that targeted augmentation combined with robust training offers a superior, data-efficient alternative for specialized domain classification. The source code will be made publicly available upon acceptance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.02072v4</guid></item><item><title>[cs updates on arXiv.org] Mask-GCG: Are All Tokens in Adversarial Suffixes Necessary for Jailbreak Attacks?</title><link>https://arxiv.org/abs/2509.06350</link><description>arXiv:2509.06350v2 Announce Type: replace 
Abstract: Jailbreak attacks on Large Language Models (LLMs) have demonstrated various successful methods whereby attackers manipulate models into generating harmful responses that they are designed to avoid. Among these, Greedy Coordinate Gradient (GCG) has emerged as a general and effective approach that optimizes the tokens in a suffix to generate jailbreakable prompts. While several improved variants of GCG have been proposed, they all rely on fixed-length suffixes. However, the potential redundancy within these suffixes remains unexplored. In this work, we propose Mask-GCG, a plug-and-play method that employs learnable token masking to identify impactful tokens within the suffix. Our approach increases the update probability for tokens at high-impact positions while pruning those at low-impact positions. This pruning not only reduces redundancy but also decreases the size of the gradient space, thereby lowering computational overhead and shortening the time required to achieve successful attacks compared to GCG. We evaluate Mask-GCG by applying it to the original GCG and several improved variants. Experimental results show that most tokens in the suffix contribute significantly to attack success, and pruning a minority of low-impact tokens does not affect the loss values or compromise the attack success rate (ASR), thereby revealing token redundancy in LLM prompts. Our findings provide insights for developing efficient and interpretable LLMs from the perspective of jailbreak attacks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.06350v2</guid></item><item><title>[cs updates on arXiv.org] OmniEVA: Embodied Versatile Planner via Task-Adaptive 3D-Grounded and Embodiment-aware Reasoning</title><link>https://arxiv.org/abs/2509.09332</link><description>arXiv:2509.09332v3 Announce Type: replace 
Abstract: Recent advances in multimodal large language models (MLLMs) have opened new opportunities for embodied intelligence, enabling multimodal understanding, reasoning, and interaction, as well as continuous spatial decision-making. Nevertheless, current MLLM-based embodied systems face two critical limitations. First, Geometric Adaptability Gap: models trained solely on 2D inputs or with hard-coded 3D geometry injection suffer from either insufficient spatial information or restricted 2D generalization, leading to poor adaptability across tasks with diverse spatial demands. Second, Embodiment Constraint Gap: prior work often neglects the physical constraints and capacities of real robots, resulting in task plans that are theoretically valid but practically infeasible. To address these gaps, we introduce OmniEVA -- an embodied versatile planner that enables advanced embodied reasoning and task planning through two pivotal innovations: (1) a Task-Adaptive 3D Grounding mechanism, which introduces a gated router to perform explicit selective regulation of 3D fusion based on contextual requirements, enabling context-aware 3D grounding for diverse embodied tasks. (2) an Embodiment-Aware Reasoning framework that jointly incorporates task goals and embodiment constraints into the reasoning loop, resulting in planning decisions that are both goal-directed and executable. Extensive experimental results demonstrate that OmniEVA not only achieves state-of-the-art general embodied reasoning performance, but also exhibits a strong ability across a wide range of downstream scenarios. Evaluations of a suite of proposed embodied benchmarks, including both primitive and composite tasks, confirm its robust and versatile planning capabilities. Project page: https://omnieva.github.io</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.09332v3</guid></item><item><title>[cs updates on arXiv.org] Invariant subspace perturbations related to defective eigenvalues of $\Delta$-Hermitian and Hamiltonian matrices</title><link>https://arxiv.org/abs/2509.10643</link><description>arXiv:2509.10643v2 Announce Type: replace 
Abstract: Structured perturbation results for invariant subspaces of $\Delta$-Hermitian and Hamiltonian matrices are provided. The invariant subspaces under consideration are associated with the eigenvalues perturbed from a single defective eigenvalue. The results show how the original eigenvectors and generalized eigenvectors are involved in composing such perturbed invariant subspaces and eigenvectors.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.10643v2</guid></item><item><title>[cs updates on arXiv.org] Do Teachers Dream of GenAI Widening Educational (In)equality? Envisioning the Future of K-12 GenAI Education from Global Teachers' Perspectives</title><link>https://arxiv.org/abs/2509.10782</link><description>arXiv:2509.10782v2 Announce Type: replace 
Abstract: Generative artificial intelligence (GenAI) is rapidly entering K-12 classrooms worldwide, initiating urgent debates about its potential to either reduce or exacerbate educational inequalities. Drawing on interviews with 30 K-12 teachers across the United States, South Africa, and Taiwan, this study examines how teachers navigate this GenAI tension around educational equalities. We found teachers actively framed GenAI education as an equality-oriented practice: they used it to alleviate pre-existing inequalities while simultaneously working to prevent new inequalities from emerging. Despite these efforts, teachers confronted persistent systemic barriers, i.e., unequal infrastructure, insufficient professional training, and restrictive social norms, that individual initiative alone could not overcome. Teachers thus articulated normative visions for more inclusive GenAI education. By centering teachers' practices, constraints, and future envisions, this study contributes a global account of how GenAI education is being integrated into K-12 contexts and highlights what is required to make its adoption genuinely equal.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.10782v2</guid></item><item><title>[cs updates on arXiv.org] DoubleAgents: Interactive Simulations for Alignment in Agentic AI</title><link>https://arxiv.org/abs/2509.12626</link><description>arXiv:2509.12626v2 Announce Type: replace 
Abstract: Agentic workflows promise efficiency, but adoption hinges on whether people can align systems that act on their behalf with their goals, values, and situational expectations. We present DoubleAgents, an agentic planning tool that embeds transparency and control through user intervention, value-reflecting policies, rich state visualizations, and uncertainty flagging for human coordination tasks. A built-in respondent simulation generates realistic scenarios, allowing users to rehearse and refine policies and calibrate their use of agentic behavior before live deployment. We evaluate DoubleAgents in a two-day lab study (n = 10), three deployment studies, and a technical evaluation. Results show that participants initially hesitated to delegate but used simulation to probe system behavior and adjust policies, gradually increasing delegation as agent actions became better aligned with their intentions and context. Deployment results demonstrate DoubleAgents' real-world relevance and usefulness, showing that simulation helps users effectively manage real-world tasks with higher complexity and uncertainty. We contribute interactive simulation as a practical pathway for users to iteratively align and calibrate agentic systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.12626v2</guid></item><item><title>[cs updates on arXiv.org] Hashing-Baseline: Rethinking Hashing in the Age of Pretrained Models</title><link>https://arxiv.org/abs/2509.14427</link><description>arXiv:2509.14427v2 Announce Type: replace 
Abstract: Information retrieval with compact binary embeddings, also referred to as hashing, is crucial for scalable fast search applications, yet state-of-the-art hashing methods require expensive, scenario-specific training. In this work, we introduce Hashing-Baseline, a strong training-free hashing method leveraging powerful pretrained encoders that produce rich pretrained embeddings. We revisit classical, training-free hashing techniques: principal component analysis, random orthogonal projection, and threshold binarization, to produce a strong baseline for hashing. Our approach combines these techniques with frozen embeddings from state-of-the-art vision and audio encoders to yield competitive retrieval performance without any additional learning or fine-tuning. To demonstrate the generality and effectiveness of this approach, we evaluate it on standard image retrieval benchmarks as well as a newly introduced benchmark for audio hashing.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.14427v2</guid></item><item><title>[cs updates on arXiv.org] An Eulerian Data Assimilation Method for Two-Layer Quasi-Geostrophic Model in Physical Domain</title><link>https://arxiv.org/abs/2509.14586</link><description>arXiv:2509.14586v5 Announce Type: replace 
Abstract: Data assimilation (DA) integrates observational data with numerical models to improve the prediction of complex physical systems. However, traditional DA methods often struggle with nonlinear dynamics and multi-scale variability, particularly when implemented directly in the physical domain. To address these challenges, this work develops an Eulerian Data Assimilation (EuDA) method with the Conditional Gaussian Nonlinear System (CGNS). The proposed approach enables the treatment of systems with non-periodic boundaries and provides a more intuitive representation of localized and time-dependent phenomena. The work considers a simplified physical domain inspired by sea-ice floe trajectories and ocean eddy recovery in the Arctic regions, where the dynamics are modeled by a two-layer quasi-geostrophic (QG) system. The QG equations are numerically solved using forward-Euler time stepping and centered finite-difference schemes. CGNS provides a nonlinear filter as it offers an analytical and continuous formulation for filtering a nonlinear system. Model performance is assessed using normalized root mean square error (RMSE) and pattern correlation (Corr) of the posterior mean. The results show that both metrics improve monotonically with refining timesteps, while RMSE converges to approximately 0.1, which is the noise strength, and Corr increases from 0.64 to 0.92 as the grid resolution becomes finer. Lastly, a coupled scenario with sea-ice particles advected by the two-layer QG flow under a linear drag force is examined, demonstrating the flexibility of the EuDA-CGNS framework in capturing coupled ice-ocean interactions. These findings demonstrate the effectiveness of exploiting the two-layer QG model in the physical domain to capture multiscale flow features.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.14586v5</guid></item><item><title>[cs updates on arXiv.org] What Matters in LLM-Based Feature Extractor for Recommender? A Systematic Analysis of Prompts, Models, and Adaptation</title><link>https://arxiv.org/abs/2509.14979</link><description>arXiv:2509.14979v3 Announce Type: replace 
Abstract: Using Large Language Models (LLMs) to generate semantic features has been demonstrated as a powerful paradigm for enhancing Sequential Recommender Systems (SRS). This typically involves three stages: processing item text, extracting features with LLMs, and adapting them for downstream models. However, existing methods vary widely in prompting, architecture, and adaptation strategies, making it difficult to fairly compare design choices and identify what truly drives performance. In this work, we propose RecXplore, a modular analytical framework that decomposes the LLM-as-feature-extractor pipeline into four modules: data processing, semantic feature extraction, feature adaptation, and sequential modeling. Instead of proposing new techniques, RecXplore revisits and organizes established methods, enabling systematic exploration of each module in isolation. Experiments on four public datasets show that simply combining the best designs from existing techniques without exhaustive search yields up to 18.7% relative improvement in NDCG@5 and 12.7% in HR@5 over strong baselines. These results underscore the utility of modular benchmarking for identifying effective design patterns and promoting standardized research in LLM-enhanced recommendation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.14979v3</guid></item><item><title>[cs updates on arXiv.org] The SAGES Critical View of Safety Challenge: A Global Benchmark for AI-Assisted Surgical Quality Assessment</title><link>https://arxiv.org/abs/2509.17100</link><description>arXiv:2509.17100v2 Announce Type: replace 
Abstract: Advances in artificial intelligence (AI) for surgical quality assessment promise to democratize access to expertise, with applications in training, guidance, and accreditation. This study presents the SAGES Critical View of Safety (CVS) Challenge, the first AI competition organized by a surgical society, using the CVS in laparoscopic cholecystectomy, a universally recommended yet inconsistently performed safety step, as an exemplar of surgical quality assessment. A global collaboration across 54 institutions in 24 countries engaged hundreds of clinicians and engineers to curate 1,000 videos annotated by 20 surgical experts according to a consensus-validated protocol. The challenge addressed key barriers to real-world deployment in surgery, including achieving high performance, capturing uncertainty in subjective assessment, and ensuring robustness to clinical variability. To enable this scale of effort, we developed EndoGlacier, a framework for managing large, heterogeneous surgical video and multi-annotator workflows. Thirteen international teams participated, achieving up to a 17% relative gain in assessment performance, over 80% reduction in calibration error, and a 17% relative improvement in robustness over the state-of-the-art. Analysis of results highlighted methodological trends linked to model performance, providing guidance for future research toward robust, clinically deployable AI for surgical quality assessment.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.17100v2</guid></item><item><title>[cs updates on arXiv.org] Visual Instruction Pretraining for Domain-Specific Foundation Models</title><link>https://arxiv.org/abs/2509.17562</link><description>arXiv:2509.17562v3 Announce Type: replace 
Abstract: Modern computer vision is converging on a closed loop in which perception, reasoning and generation mutually reinforce each other. However, this loop remains incomplete: the top-down influence of high-level reasoning on the foundational learning of low-level perceptual features is not yet underexplored. This paper addresses this gap by proposing a new paradigm for pretraining foundation models in downstream domains. We introduce Visual insTruction Pretraining (ViTP), a novel approach that directly leverages reasoning to enhance perception. ViTP embeds a Vision Transformer (ViT) backbone within a Vision-Language Model and pretrains it end-to-end using a rich corpus of visual instruction data curated from target downstream domains. ViTP is powered by our proposed Visual Robustness Learning (VRL), which compels the ViT to learn robust and domain-relevant features from a sparse set of visual tokens. Extensive experiments on 16 challenging remote sensing and medical imaging benchmarks demonstrate that ViTP establishes new state-of-the-art performance across a diverse range of downstream tasks. The code is available at https://github.com/zcablii/ViTP.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.17562v3</guid></item><item><title>[cs updates on arXiv.org] AuditoryBench++: Can Language Models Understand Auditory Knowledge without Hearing?</title><link>https://arxiv.org/abs/2509.17641</link><description>arXiv:2509.17641v2 Announce Type: replace 
Abstract: Even without directly hearing sounds, humans can effortlessly reason about auditory properties, such as pitch, loudness, or sound-source associations, drawing on auditory commonsense. In contrast, language models often lack this capability, limiting their effectiveness in multimodal interactions. As an initial step to address this gap, we present AuditoryBench++, a comprehensive benchmark for evaluating auditory knowledge and reasoning in text-only settings. The benchmark encompasses tasks that range from basic auditory comparisons to contextually grounded reasoning, enabling fine-grained analysis of how models process and integrate auditory concepts. In addition, we introduce AIR-CoT, a novel auditory imagination reasoning method that generates and integrates auditory information during inference through span detection with special tokens and knowledge injection. Extensive experiments with recent LLMs and Multimodal LLMs demonstrate that AIR-CoT generally outperforms both the off-the-shelf models and those augmented with auditory knowledge. The project page is available at https://auditorybenchpp.github.io.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.17641v2</guid></item><item><title>[cs updates on arXiv.org] Understanding Post-Training Structural Changes in Large Language Models</title><link>https://arxiv.org/abs/2509.17866</link><description>arXiv:2509.17866v3 Announce Type: replace 
Abstract: Post-training fundamentally alters the behavior of large language models (LLMs), yet its impact on the internal parameter space remains poorly understood. In this work, we conduct a systematic singular value decomposition (SVD) analysis of principal linear layers in pretrained LLMs, focusing on two widely adopted post-training methods: instruction tuning and long-chain-of-thought (Long-CoT) distillation. Our analysis reveals two unexpected and robust structural changes: (1) a near-uniform geometric scaling of singular values across layers; and (2) highly consistent orthogonal transformations are applied to the left and right singular vectors of each matrix. Based on these findings, We propose a simple yet effective framework to describe the coordinated dynamics of parameters in LLMs, which elucidates why post-training inherently relies on the foundational capabilities developed during pre-training. Further experiments demonstrate that singular value scaling underpins the temperature-controlled regulatory mechanisms of post-training, while the coordinated rotation of singular vectors encodes the essential semantic alignment. These results challenge the prevailing view of the parameter space in large models as a black box, uncovering the first clear regularities in how parameters evolve during training, and providing a new perspective for deeper investigation into model parameter changes.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.17866v3</guid></item><item><title>[cs updates on arXiv.org] Diagonal Linear Networks and the Lasso Regularization Path</title><link>https://arxiv.org/abs/2509.18766</link><description>arXiv:2509.18766v2 Announce Type: replace 
Abstract: Diagonal linear networks are neural networks with linear activation and diagonal weight matrices. Their theoretical interest is that their implicit regularization can be rigorously analyzed: from a small initialization, the training of diagonal linear networks converges to the linear predictor with minimal 1-norm among minimizers of the training loss. In this paper, we deepen this analysis showing that the full training trajectory of diagonal linear networks is closely related to the lasso regularization path. In this connection, the training time plays the role of an inverse regularization parameter. Both rigorous results and simulations are provided to illustrate this conclusion. Under a monotonicity assumption on the lasso regularization path, the connection is exact while in the general case, we show an approximate connection.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.18766v2</guid></item><item><title>[cs updates on arXiv.org] WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction</title><link>https://arxiv.org/abs/2509.19073</link><description>arXiv:2509.19073v3 Announce Type: replace 
Abstract: 3D Gaussian Splatting (3DGS) has become a powerful representation for image-based object reconstruction, yet its performance drops sharply in sparse-view settings. Prior works address this limitation by employing diffusion models to repair corrupted renders, subsequently using them as pseudo ground truths for later optimization. While effective, such approaches incur heavy computation from the diffusion fine-tuning and repair steps. We present WaveletGaussian, a framework for more efficient sparse-view 3D Gaussian object reconstruction. Our key idea is to shift diffusion into the wavelet domain: diffusion is applied only to the low-resolution LL subband, while high-frequency subbands are refined with a lightweight network. We further propose an efficient online random masking strategy to curate training pairs for diffusion fine-tuning, replacing the commonly used, but inefficient, leave-one-out strategy. Experiments across two benchmark datasets, Mip-NeRF 360 and OmniObject3D, show WaveletGaussian achieves competitive rendering quality while substantially reducing training time.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.19073v3</guid></item><item><title>[cs updates on arXiv.org] Analysis of approximate linear programming solution to Markov decision problem with log barrier function</title><link>https://arxiv.org/abs/2509.19800</link><description>arXiv:2509.19800v2 Announce Type: replace 
Abstract: There are two primary approaches to solving Markov decision problems (MDPs): dynamic programming based on the Bellman equation and linear programming (LP). Dynamic programming methods are the most widely used and form the foundation of both classical and modern reinforcement learning (RL). By contrast, LP-based methods have been less commonly employed, although they have recently gained attention in contexts such as offline RL. The relative underuse of the LP-based methods stems from the fact that it leads to an inequality-constrained optimization problem, which is generally more challenging to solve effectively compared with Bellman-equation-based methods. The purpose of this paper is to establish a theoretical foundation for solving LP-based MDPs in a more effective and practical manner. Our key idea is to leverage the log-barrier function, widely used in inequality-constrained optimization, to transform the LP formulation of the MDP into an unconstrained optimization problem. This reformulation enables approximate solutions to be obtained easily via gradient descent. While the method may appear simple, to the best of our knowledge, a thorough theoretical interpretation of this approach has not yet been developed. This paper aims to bridge this gap.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.19800v2</guid></item><item><title>[cs updates on arXiv.org] From Text to Talk: Audio-Language Model Needs Non-Autoregressive Joint Training</title><link>https://arxiv.org/abs/2509.20072</link><description>arXiv:2509.20072v3 Announce Type: replace 
Abstract: Recent advances in large language models (LLMs) have attracted significant interest in extending their capabilities to multimodal scenarios, particularly for speech-to-speech conversational systems. However, existing multimodal models handling interleaved audio and text rely on autoregressive (AR) methods, overlooking that text depends on target-target relations whereas audio depends mainly on source-target relations. In this work, we propose Text-to-Talk (TtT), a unified audio-text framework that integrates AR text generation with non-autoregressive (NAR) audio diffusion in a single Transformer. By leveraging the any-order AR property of absorbing discrete diffusion, our approach provides a unified training objective for text and audio. To support this hybrid generation paradigm, we design a modality-aware attention mechanism that enforces causal decoding for text while allowing bidirectional modeling within audio spans, and further introduce three training strategies that reduce train-test discrepancies. During inference, TtT employs block-wise diffusion to synthesize audio in parallel while flexibly handling variable-length outputs. Comprehensive experiments on Audio-QA, ASR, AAC and speech-to-speech benchmarks show that TtT consistently surpasses strong AR and NAR baselines, with additional ablation and training-strategy analyses confirming the contribution of each component. We will open-source our models, data and code to facilitate future research in this direction.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.20072v3</guid></item><item><title>[cs updates on arXiv.org] Developer Productivity With and Without GitHub Copilot: A Longitudinal Mixed-Methods Case Study</title><link>https://arxiv.org/abs/2509.20353</link><description>arXiv:2509.20353v2 Announce Type: replace 
Abstract: This study investigates the real-world impact of the generative AI (GenAI) tool GitHub Copilot on developer activity and perceived productivity. We conducted a mixed-methods case study in NAV IT, a large public sector agile organization. We analyzed 26,317 unique non-merge commits from 703 of NAV IT's GitHub repositories over a two-year period, focusing on commit-based activity metrics from 25 Copilot users and 14 non-users. The analysis was complemented by survey responses on their roles and perceived productivity, as well as 13 interviews. Our analysis of activity metrics revealed that individuals who used Copilot were consistently more active than non-users, even prior to Copilot's introduction. We did not find any statistically significant changes in commit-based activity for Copilot users after they adopted the tool, although minor increases were observed. This suggests a discrepancy between changes in commit-based metrics and the subjective experience of productivity.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.20353v2</guid></item><item><title>[cs updates on arXiv.org] FlyTrap: Physical Distance-Pulling Attack Towards Camera-based Autonomous Target Tracking Systems</title><link>https://arxiv.org/abs/2509.20362</link><description>arXiv:2509.20362v2 Announce Type: replace 
Abstract: Autonomous Target Tracking (ATT) systems, especially ATT drones, are widely used in applications such as surveillance, border control, and law enforcement, while also being misused in stalking and destructive actions. Thus, the security of ATT is highly critical for real-world applications. Under the scope, we present a new type of attack: distance-pulling attacks (DPA) and a systematic study of it, which exploits vulnerabilities in ATT systems to dangerously reduce tracking distances, leading to drone capturing, increased susceptibility to sensor attacks, or even physical collisions. To achieve these goals, we present FlyTrap, a novel physical-world attack framework that employs an adversarial umbrella as a deployable and domain-specific attack vector. FlyTrap is specifically designed to meet key desired objectives in attacking ATT drones: physical deployability, closed-loop effectiveness, and spatial-temporal consistency. Through novel progressive distance-pulling strategy and controllable spatial-temporal consistency designs, FlyTrap manipulates ATT drones in real-world setups to achieve significant system-level impacts. Our evaluations include new datasets, metrics, and closed-loop experiments on real-world white-box and even commercial ATT drones, including DJI and HoverAir. Results demonstrate FlyTrap's ability to reduce tracking distances within the range to be captured, sensor attacked, or even directly crashed, highlighting urgent security risks and practical implications for the safe deployment of ATT systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.20362v2</guid></item><item><title>[cs updates on arXiv.org] Addressing Gradient Misalignment in Data-Augmented Training for Robust Speech Deepfake Detection</title><link>https://arxiv.org/abs/2509.20682</link><description>arXiv:2509.20682v2 Announce Type: replace 
Abstract: In speech deepfake detection (SDD), data augmentation (DA) is commonly used to improve model generalization across varied speech conditions and spoofing attacks. However, during training, the backpropagated gradients from original and augmented inputs may misalign, which can result in conflicting parameter updates. These conflicts could hinder convergence and push the model toward suboptimal solutions, thereby reducing the benefits of DA. To investigate and address this issue, we design a dual-path data-augmented (DPDA) training framework with gradient alignment for SDD. In our framework, each training utterance is processed through two input paths: one using the original speech and the other with its augmented version. This design allows us to compare and align their backpropagated gradient directions to reduce optimization conflicts. Our analysis shows that approximately 25% of training iterations exhibit gradient conflicts between the original inputs and their augmented counterparts when using RawBoost augmentation. By resolving these conflicts with gradient alignment, our method accelerates convergence by reducing the number of training epochs and achieves up to an 18.69% relative reduction in Equal Error Rate on the In-the-Wild dataset compared to the baseline.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.20682v2</guid></item><item><title>[cs updates on arXiv.org] SiNGER: A Clearer Voice Distills Vision Transformers Further</title><link>https://arxiv.org/abs/2509.20986</link><description>arXiv:2509.20986v3 Announce Type: replace 
Abstract: Vision Transformers are widely adopted as the backbone of vision foundation models, but they are known to produce high-norm artifacts that degrade representation quality. When knowledge distillation transfers these features to students, high-norm artifacts dominate the objective, so students overfit to artifacts and underweight informative signals, diminishing the gains from larger models. Prior work attempted to remove artifacts but encountered an inherent trade-off between artifact suppression and preserving informative signals from teachers. To address this, we introduce Singular Nullspace-Guided Energy Reallocation (SiNGER), a novel distillation framework that suppresses artifacts while preserving informative signals. The key idea is principled teacher feature refinement: during refinement, we leverage the nullspace-guided perturbation to preserve information while suppressing artifacts. Then, the refined teacher's features are distilled to a student. We implement this perturbation efficiently with a LoRA-based adapter that requires minimal structural modification. Extensive experiments show that \oursname consistently improves student models, achieving state-of-the-art performance in multiple downstream tasks and producing clearer and more interpretable representations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.20986v3</guid></item><item><title>[cs updates on arXiv.org] Mechanism of Task-oriented Information Removal in In-context Learning</title><link>https://arxiv.org/abs/2509.21012</link><description>arXiv:2509.21012v3 Announce Type: replace 
Abstract: In-context Learning (ICL) is an emerging few-shot learning paradigm based on modern Language Models (LMs), yet its inner mechanism remains unclear. In this paper, we investigate the mechanism through a novel perspective of information removal. Specifically, we demonstrate that in the zero-shot scenario, LMs encode queries into non-selective representations in hidden states containing information for all possible tasks, leading to arbitrary outputs without focusing on the intended task, resulting in near-zero accuracy. Meanwhile, we find that selectively removing specific information from hidden states by a low-rank filter effectively steers LMs toward the intended task. Building on these findings, by measuring the hidden states on carefully designed metrics, we observe that few-shot ICL effectively simulates such task-oriented information removal processes, selectively removing the redundant information from entangled non-selective representations, and improving the output based on the demonstrations, which constitutes a key mechanism underlying ICL. Moreover, we identify essential attention heads inducing the removal operation, termed Denoising Heads, which enables the ablation experiments blocking the information removal operation from the inference, where the ICL accuracy significantly degrades, especially when the correct label is absent from the few-shot demonstrations, confirming both the critical role of the information removal mechanism and denoising heads.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.21012v3</guid></item><item><title>[cs updates on arXiv.org] Visual Multi-Agent System: Mitigating Hallucination Snowballing via Visual Flow</title><link>https://arxiv.org/abs/2509.21789</link><description>arXiv:2509.21789v3 Announce Type: replace 
Abstract: Multi-Agent System (MAS) powered by Visual Language Models (VLMs) enables challenging tasks but suffers from a novel failure term, multi-agent visual hallucination snowballing, where hallucinations are seeded in a single agent and amplified by following ones due to the over-reliance on textual flow to relay visual information. Through turn-, layer-, and token-wise attention analyses, we provide detailed insights into the essence of hallucination snowballing regarding the reduction of visual attention allocation. It leads us to identify a subset of vision tokens with a unimodal attention peak in middle layers that best preserve visual evidence but gradually diminish in deeper agent turns, resulting in the visual hallucination snowballing in MAS. Thus, we propose ViF, a lightweight, plug-and-play mitigation paradigm that relays inter-agent messages with Visual Flow powered by the selected visual relay tokens and applies attention reallocation to amplify this pattern. The experiment results demonstrate that our method markedly reduces hallucination snowballing, consistently improving the performance across eight benchmarks based on four common MAS structures and ten base models. The source code is publicly available at: https://github.com/YU-deep/ViF.git.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.21789v3</guid></item><item><title>[cs updates on arXiv.org] Library Hallucinations in LLMs: Risk Analysis Grounded in Developer Queries</title><link>https://arxiv.org/abs/2509.22202</link><description>arXiv:2509.22202v2 Announce Type: replace 
Abstract: Large language models (LLMs) are increasingly used to generate code, yet they continue to hallucinate, often inventing non-existent libraries. Such library hallucinations are not just benign errors: they can mislead developers, break builds, and expose systems to supply chain threats such as slopsquatting. Despite increasing awareness of these risks, little is known about how real-world prompt variations affect hallucination rates. Therefore, we present the first systematic study of how user-level prompt variations impact library hallucinations in LLM-generated code. We evaluate seven diverse LLMs across two hallucination types: library name hallucinations (invalid imports) and library member hallucinations (invalid calls from valid libraries). We investigate how realistic user language extracted from developer forums and how user errors of varying degrees (one- or multi-character misspellings and completely fake names/members) affect LLM hallucination rates. Our findings reveal systemic vulnerabilities: one-character misspellings in library names trigger hallucinations in up to 26% of tasks, fake library names are accepted in up to 99% of tasks, and time-related prompts lead to hallucinations in up to 84% of tasks. Prompt engineering shows promise for mitigating hallucinations, but remains inconsistent and LLM-dependent. Our results underscore the fragility of LLMs to natural prompt variation and highlight the urgent need for safeguards against library-related hallucinations and their potential exploitation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.22202v2</guid></item><item><title>[cs updates on arXiv.org] Beyond Classification Accuracy: Neural-MedBench and the Need for Deeper Reasoning Benchmarks</title><link>https://arxiv.org/abs/2509.22258</link><description>arXiv:2509.22258v4 Announce Type: replace 
Abstract: Recent advances in vision-language models (VLMs) have achieved remarkable performance on standard medical benchmarks, yet their true clinical reasoning ability remains unclear. Existing datasets predominantly emphasize classification accuracy, creating an evaluation illusion in which models appear proficient while still failing at high-stakes diagnostic reasoning. We introduce Neural-MedBench, a compact yet reasoning-intensive benchmark specifically designed to probe the limits of multimodal clinical reasoning in neurology. Neural-MedBench integrates multi-sequence MRI scans, structured electronic health records, and clinical notes, and encompasses three core task families: differential diagnosis, lesion recognition, and rationale generation. To ensure reliable evaluation, we develop a hybrid scoring pipeline that combines LLM-based graders, clinician validation, and semantic similarity metrics. Through systematic evaluation of state-of-the-art VLMs, including GPT-4o, Claude-4, and MedGemma, we observe a sharp performance drop compared to conventional datasets. Error analysis shows that reasoning failures, rather than perceptual errors, dominate model shortcomings. Our findings highlight the necessity of a Two-Axis Evaluation Framework: breadth-oriented large datasets for statistical generalization, and depth-oriented, compact benchmarks such as Neural-MedBench for reasoning fidelity. We release Neural-MedBench at https://neuromedbench.github.io/ as an open and extensible diagnostic testbed, which guides the expansion of future benchmarks and enables rigorous yet cost-effective assessment of clinically trustworthy AI.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.22258v4</guid></item><item><title>[cs updates on arXiv.org] Look Back to Reason Forward: Revisitable Memory for Long-Context LLM Agents</title><link>https://arxiv.org/abs/2509.23040</link><description>arXiv:2509.23040v2 Announce Type: replace 
Abstract: Large language models face challenges in long-context question answering, where key evidence of a query may be dispersed across millions of tokens. Existing works equip large language models with a memory buffer that is dynamically updated via a linear document scan, also known as the "memorize while reading" methods. While this approach scales efficiently, it suffers from pruning of latent evidence, information loss through overwriting, and sparse reinforcement learning signals. To tackle these challenges, we present ReMemR1, which integrates the mechanism of memory retrieval into the memory update process, enabling the agent to selectively callback historical memories for non-linear reasoning. To further strengthen training, we propose a multi-level reward design, which combines final-answer rewards with dense, step-level signals that guide effective memory use. Together, these contributions mitigate information degradation, improve supervision, and support complex multi-hop reasoning. Extensive experiments demonstrate that ReMemR1 significantly outperforms state-of-the-art baselines on long-context question answering while incurring negligible computational overhead, validating its ability to trade marginal cost for robust long-context reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.23040v2</guid></item><item><title>[cs updates on arXiv.org] SysMoBench: Evaluating AI on Formally Modeling Complex Real-World Systems</title><link>https://arxiv.org/abs/2509.23130</link><description>arXiv:2509.23130v3 Announce Type: replace 
Abstract: Formal models are essential to specifying large, complex computer systems and verifying their correctness, but are notoriously expensive to write and maintain. Recent advances in generative AI show promise in generating certain forms of specifications. However, existing work mostly targets small code, not complete systems. It is unclear whether AI can deal with realistic system artifacts, as this requires abstracting their complex behavioral properties into formal models. We present SysMoBench, a benchmark that evaluates AI's ability to formally model large, complex systems. We focus on concurrent and distributed systems, which are keystones of today's critical computing infrastructures, encompassing operating systems and cloud infrastructure. We use TLA+, the de facto specification language for concurrent and distributed systems, though the benchmark can be extended to other specification languages. We address the primary challenge of evaluating AI-generated models by automating metrics like syntactic and runtime correctness, conformance to system code, and invariant correctness. SysMoBench currently includes eleven diverse system artifacts: the Raft implementation of Etcd and Redis, the leader election of ZooKeeper, the Spinlock, Mutex, and Ringbuffer in Asterinas OS, etc., with more being added. SysMoBench enables us to understand the capabilities and limitations of today's LLMs and agents, putting tools in this area on a firm footing and opening up promising new research directions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.23130v3</guid></item><item><title>[cs updates on arXiv.org] Discrete Variational Autoencoding via Policy Search</title><link>https://arxiv.org/abs/2509.24716</link><description>arXiv:2509.24716v2 Announce Type: replace 
Abstract: Discrete latent bottlenecks in variational autoencoders (VAEs) offer high bit efficiency and can be modeled with autoregressive discrete distributions, enabling parameter-efficient multimodal search with transformers. However, discrete random variables do not allow for exact differentiable parameterization; therefore, discrete VAEs typically rely on approximations, such as Gumbel-Softmax reparameterization or straight-through gradient estimates, or employ high-variance gradient-free methods such as REINFORCE that have had limited success on high-dimensional tasks such as image reconstruction. Inspired by popular techniques in policy search, we propose a training framework for discrete VAEs that leverages the natural gradient of a non-parametric encoder to update the parametric encoder without requiring reparameterization. Our method, combined with automatic step size adaptation and a transformer-based encoder, scales to challenging datasets such as ImageNet and outperforms both approximate reparameterization methods and quantization-based discrete autoencoders in reconstructing high-dimensional data from compact latent spaces.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.24716v2</guid></item><item><title>[cs updates on arXiv.org] Effective Model Pruning: Measure The Redundancy of Model Components</title><link>https://arxiv.org/abs/2509.25606</link><description>arXiv:2509.25606v2 Announce Type: replace 
Abstract: This article initiates the study of a basic question about model pruning. Given a vector $s$ of importance scores assigned to model components, how many of the scored components could be discarded without sacrificing performance? We propose Effective Model Pruning (EMP), which derives the desired sparsity directly from the score distribution using the notion of effective sample size from particle filtering, also known as the inverse Simpson index.
  Rather than prescribe a pruning criterion, EMP supplies a universal adaptive threshold derived from the distribution of the score $s$ over the model components: EMP maps $s$ to a number $N_{eff}=N_{eff}(s)$, called the effective sample size. The $N-N_{eff}$ lowest scoring components are discarded. A tight lower bound on the preserved mass fraction $s_{eff}$ (the sum of retained normalized scores) in terms of $N_{eff}$ is derived. This process yields models with a provable upper bound on the loss change relative to the original dense model. Numerical experiments are performed demonstrating this phenomenon across a variety of network architectures including MLPs, CNNs, Transformers, LLMs, and KAN. It is also shown that EMP addresses a rich set of pruning criteria such as weight magnitude, attention score, KAN importance score, and even feature-level signals such as image pixels.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.25606v2</guid></item><item><title>[cs updates on arXiv.org] mR3: Multilingual Rubric-Agnostic Reward Reasoning Models</title><link>https://arxiv.org/abs/2510.01146</link><description>arXiv:2510.01146v2 Announce Type: replace 
Abstract: Evaluation using Large Language Model (LLM) judges has been widely adopted in English and shown to be effective for automatic evaluation. However, their performance does not generalize well to non-English settings, and it remains unclear what constitutes effective multilingual training for such judges. In this paper, we introduce mR3, a massively multilingual, rubric-agnostic reward reasoning model trained on 72 languages, achieving the broadest language coverage in reward modeling to date. We present a comprehensive study of data and curriculum selection for training to identify effective strategies and data sources for building high-quality reward models, including support for reasoning in the target language. Our approach attains state-of-the-art performance on multilingual reward model benchmarks, surpassing much larger models (i.e., GPT-OSS-120B) while being up to 9x smaller, and its effectiveness is further confirmed through extensive ablation studies. Finally, we demonstrate the effectiveness of mR3 in off-policy preference optimization and validate the quality of its reasoning traces and rubric-based evaluations through human studies with 20 annotators across 12 languages, where mR3 models' reasoning is preferred, including for extremely low-resource languages that are entirely unseen during training. Our models, data, and code are available as open source at https://github.com/rubricreward/mr3.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.01146v2</guid></item><item><title>[cs updates on arXiv.org] A Parallelization Strategy for GRAND with Optimality Guarantee by Exploiting Error Pattern Tree Representation</title><link>https://arxiv.org/abs/2510.01813</link><description>arXiv:2510.01813v2 Announce Type: replace 
Abstract: Parallelism has become a central concern in modern decoding frameworks aiming to meet stringent throughput and latency requirements. Guessing Random Additive Noise Decoding (GRAND) is a recently proposed decoding paradigm that tests candidate Error Patterns (EPs) until a valid codeword is found. Among its variants, Soft GRAND (SGRAND) achieves maximum-likelihood (ML) decoding but relies on real-time generation and likelihood ordering of EPs, making parallel execution nontrivial under the ML optimality constraint. In this work, we introduce a unified binary tree representation of EPs, termed the EP tree, which formalizes the hierarchical structure underlying SGRAND and Ordered Reliability Bits (ORB) GRAND algorithms, enabling structured organization of EPs and algorithmic-level parallel exploration. Building upon this unified framework, we propose a parallel design of SGRAND that preserves ML optimality while significantly reducing decoding complexity through pruning strategies and tree-based computation. Furthermore, we develop an enhanced ORBGRAND algorithm based on the same EP tree representation, improving decoding performance toward ML while retaining parallel efficiency. Numerical experiments show that the proposed parallel SGRAND achieves a $3.96\times$ reduction in decoding latency compared with its serial counterpart, while the enhanced ORBGRAND achieves a $4.21\times$ speedup, demonstrating the effectiveness of the unified tree-based framework and its strong potential for future algorithmic and hardware optimizations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.01813v2</guid></item><item><title>[cs updates on arXiv.org] GRACE: A Language Model Framework for Explainable Inverse Reinforcement Learning</title><link>https://arxiv.org/abs/2510.02180</link><description>arXiv:2510.02180v2 Announce Type: replace 
Abstract: Inverse Reinforcement Learning aims to recover reward models from expert demonstrations, but traditional methods yield black-box models that are difficult to interpret and debug. In this work, we introduce GRACE (Generating Rewards As CodE), a method for using Large Language Models within an evolutionary search to reverse-engineer an interpretable, code-based reward function directly from expert trajectories. The resulting reward function is executable code that can be inspected and verified. We empirically validate GRACE on the MuJoCo, BabyAI and AndroidWorld benchmarks, where it efficiently learns highly accurate rewards, even in complex, multi-task settings. Further, we demonstrate that the resulting reward leads to strong policies, compared to both competitive Imitation Learning and online RL approaches with ground-truth rewards. Finally, we show that GRACE is able to build complex reward APIs in multi-task setups.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.02180v2</guid></item><item><title>[cs updates on arXiv.org] FourierCSP: Differentiable Constraint Satisfaction Problem Solving by Walsh-Fourier Expansion</title><link>https://arxiv.org/abs/2510.04480</link><description>arXiv:2510.04480v2 Announce Type: replace 
Abstract: The Constraint-satisfaction problem (CSP) is fundamental in mathematics, physics, and theoretical computer science. Continuous local search (CLS) solvers, as recent advancements, can achieve highly competitive results on certain classes of Boolean satisfiability (SAT) problems. Motivated by these advances, we extend the CLS framework from Boolean SAT to general CSP with finite-domain variables and expressive constraint formulations. We present FourierCSP, a continuous optimization framework that generalizes the Walsh-Fourier transform to CSP, allowing for transforming versatile constraints to compact multilinear polynomials, thereby avoiding the need for auxiliary variables and memory-intensive encodings. We employ projected subgradient and mirror descent algorithms with provable convergence guarantees, and further combine them to accelerate gradient-based optimization. Empirical results on benchmark suites demonstrate that FourierCSP is scalable and competitive, significantly broadening the class of problems that can be efficiently solved by differentiable CLS techniques and paving the way toward end-to-end neurosymbolic integration.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.04480v2</guid></item><item><title>[cs updates on arXiv.org] MetaVLA: Unified Meta Co-training For Efficient Embodied Adaption</title><link>https://arxiv.org/abs/2510.05580</link><description>arXiv:2510.05580v3 Announce Type: replace 
Abstract: Vision-Language-Action (VLA) models show promise in embodied reasoning, yet remain far from true generalists-they often require task-specific fine-tuning, incur high compute costs, and generalize poorly to unseen tasks. We propose MetaVLA, a unified, backbone-agnostic post-training framework for efficient and scalable alignment. MetaVLA introduces Context-Aware Meta Co-Training, which consolidates diverse target tasks into a single fine-tuning stage while leveraging structurally diverse auxiliary tasks to improve in-domain generalization. Unlike naive multi-task SFT, MetaVLA integrates a lightweight meta-learning mechanism-derived from Attentive Neural Processes-to enable rapid adaptation from diverse contexts with minimal architectural change or inference overhead. On the LIBERO benchmark, MetaVLA with six auxiliary tasks outperforms OpenVLA by up to 8.0% on long-horizon tasks, reduces training steps from 240K to 75K, and cuts GPU time by ~76%. These results show that scalable, low-resource post-training is achievable-paving the way toward general-purpose embodied agents. Code will be available.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.05580v3</guid></item><item><title>[cs updates on arXiv.org] Higher-Order Feature Attribution: Bridging Statistics, Explainable AI, and Topological Signal Processing</title><link>https://arxiv.org/abs/2510.06165</link><description>arXiv:2510.06165v2 Announce Type: replace 
Abstract: Feature attributions are post-training analysis methods that assess how various input features of a machine learning model contribute to an output prediction. Their interpretation is straightforward when features act independently, but it becomes less clear when the predictive model involves interactions, such as multiplicative relationships or joint feature contributions. In this work, we propose a general theory of higher-order feature attribution, which we develop on the foundation of Integrated Gradients (IG). This work extends existing frameworks in the literature on explainable AI. When using IG as the method of feature attribution, we discover natural connections to statistics and topological signal processing. We provide several theoretical results that establish the theory, and we validate our theory on a few examples.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.06165v2</guid></item><item><title>[cs updates on arXiv.org] TRIM: Token-wise Attention-Derived Saliency for Data-Efficient Instruction Tuning</title><link>https://arxiv.org/abs/2510.07118</link><description>arXiv:2510.07118v2 Announce Type: replace 
Abstract: Instruction tuning is essential for aligning large language models (LLMs) to downstream tasks and commonly relies on large, diverse corpora. However, small, high-quality subsets, known as coresets, can deliver comparable or superior results, though curating them remains challenging. Existing methods often rely on coarse, sample-level signals like gradients, an approach that is computationally expensive and overlooks fine-grained features. To address this, we introduce TRIM (Token Relevance via Interpretable Multi-layer Attention), a forward-only, token-centric framework. Instead of using gradients, TRIM operates by matching underlying representational patterns identified via attention-based "fingerprints" from a handful of target samples. Such an approach makes TRIM highly efficient and uniquely sensitive to the structural features that define a task. Coresets selected by our method consistently outperform state-of-the-art baselines by up to 9% on downstream tasks and even surpass the performance of full-data fine-tuning in some settings. By avoiding expensive backward passes, TRIM achieves this at a fraction of the computational cost. These findings establish TRIM as a scalable and efficient alternative for building high-quality instruction-tuning datasets.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.07118v2</guid></item><item><title>[cs updates on arXiv.org] SketchGuard: Scaling Byzantine-Robust Decentralized Federated Learning via Sketch-Based Screening</title><link>https://arxiv.org/abs/2510.07922</link><description>arXiv:2510.07922v3 Announce Type: replace 
Abstract: Decentralized Federated Learning enables privacy-preserving collaborative training without centralized servers but remains vulnerable to Byzantine attacks. Existing defenses require exchanging high-dimensional model vectors with all neighbors each round, creating prohibitive costs at scale. We propose SketchGuard, which decouples Byzantine filtering from aggregation via sketch-based screening. SketchGuard compresses $d$-dimensional models to $k$-dimensional sketches ($k \ll d$) using Count Sketch, then fetches full models only from accepted neighbors, reducing communication complexity from $O(d|N_i|)$ to $O(k|N_i| + d|S_i|)$, where $|N_i|$ is the neighbor count and $|S_i| \le |N_i|$ is the accepted count. We prove convergence in strongly convex and non-convex settings, showing that approximation errors introduce only a $(1+O(\epsilon))$ factor in the effective threshold. Experiments demonstrate SketchGuard maintains state-of-the-art robustness (mean TER deviation $\leq$0.5 percentage points) while reducing computation by up to 82% and communication by 50-70%.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.07922v3</guid></item><item><title>[cs updates on arXiv.org] Emotionally Charged, Logically Blurred: AI-driven Emotional Framing Impairs Human Fallacy Detection</title><link>https://arxiv.org/abs/2510.09695</link><description>arXiv:2510.09695v2 Announce Type: replace 
Abstract: Logical fallacies are common in public communication and can mislead audiences; fallacious arguments may still appear convincing despite lacking soundness, because convincingness is inherently subjective. We present the first computational study of how emotional framing interacts with fallacies and convincingness, using large language models (LLMs) to systematically change emotional appeals in fallacious arguments. We benchmark eight LLMs on injecting emotional appeal into fallacious arguments while preserving their logical structures, then use the best models to generate stimuli for a human study. Our results show that LLM-driven emotional framing reduces human fallacy detection in F1 by 14.5% on average. Humans perform better in fallacy detection when perceiving enjoyment than fear or sadness, and these three emotions also correlate with significantly higher convincingness compared to neutral or other emotion states. Our work has implications for AI-driven emotional manipulation in the context of fallacious argumentation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.09695v2</guid></item><item><title>[cs updates on arXiv.org] Federated k-Means over Networks</title><link>https://arxiv.org/abs/2510.09718</link><description>arXiv:2510.09718v2 Announce Type: replace 
Abstract: We study federated clustering, where interconnected devices collaboratively cluster the data points of private local datasets. Focusing on hard clustering via the k-means principle, we formulate federated k-means as an instance of generalized total variation minimization (GTVMin). This leads to a federated k-means algorithm in which each device updates its local cluster centroids by solving a regularized k-means problem with a regularizer that enforces consistency between neighbouring devices. The resulting algorithm is privacy-friendly, as only aggregated information is exchanged.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.09718v2</guid></item><item><title>[cs updates on arXiv.org] Closing the Data-Efficiency Gap Between Autoregressive and Masked Diffusion LLMs</title><link>https://arxiv.org/abs/2510.09885</link><description>arXiv:2510.09885v3 Announce Type: replace 
Abstract: Large language models (LLMs) are often used in environments where facts evolve, yet factual knowledge updates via fine-tuning on unstructured text often suffers from 1) reliance on compute-heavy paraphrase augmentation and 2) the reversal curse. Recent studies show diffusion large language models (dLLMs) require fewer training samples to achieve lower loss in pre-training and are more resistant to the reversal curse, suggesting dLLMs may learn new knowledge more easily than autoregressive LLMs (arLLMs). We test this hypothesis in controlled knowledge fine-tuning experiments and find that while arLLMs rely on paraphrase augmentation to generalize knowledge text into question-answering (QA) capability, dLLMs do not require paraphrases to achieve high QA accuracy. To further investigate whether the demasking objective alone can induce such a knowledge injection advantage in dLLMs regardless of their diffusion denoising paradigm, we propose masked fine-tuning for arLLMs, which prompts an arLLM to reconstruct the original text given a masked version in context. The masked fine-tuning for arLLMs substantially improves the efficacy of knowledge injection, i.e. no paraphrase needed and resistant to the reversal curse, closing the gap between arLLMs and dLLMs. We also demonstrate that the same demasking objective improves supervised fine-tuning (SFT) on math tasks over standard SFT, suggesting broader applicability of the demasking objective.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.09885v3</guid></item><item><title>[cs updates on arXiv.org] A-IPO: Adaptive Intent-driven Preference Optimization</title><link>https://arxiv.org/abs/2510.10077</link><description>arXiv:2510.10077v3 Announce Type: replace 
Abstract: Human preferences are diverse and dynamic, shaped by regional, cultural, and social factors. Existing alignment methods like Direct Preference Optimization (DPO) and its variants often default to majority views, overlooking minority opinions and failing to capture latent user intentions in prompts.
  To address these limitations, we introduce \underline{\textbf{A}}daptive \textbf{\underline{I}}ntent-driven \textbf{\underline{P}}reference \textbf{\underline{O}}ptimization (\textbf{A-IPO}). Specifically,A-IPO introduces an intention module that infers the latent intent behind each user prompt and explicitly incorporates this inferred intent into the reward function, encouraging stronger alignment between the preferred model's responses and the user's underlying intentions. We demonstrate, both theoretically and empirically, that incorporating an intention--response similarity term increases the preference margin (by a positive shift of $\lambda\,\Delta\mathrm{sim}$ in the log-odds), resulting in clearer separation between preferred and dispreferred responses compared to DPO.
  For evaluation, we introduce two new benchmarks, Real-pref, Attack-pref along with an extended version of an existing dataset, GlobalOpinionQA-Ext, to assess real-world and adversarial preference alignment.
  Through explicit modeling of diverse user intents,A-IPO facilitates pluralistic preference optimization while simultaneously enhancing adversarial robustness in preference alignment. Comprehensive empirical evaluation demonstrates that A-IPO consistently surpasses existing baselines, yielding substantial improvements across key metrics: up to +24.8 win-rate and +45.6 Response-Intention Consistency on Real-pref; up to +38.6 Response Similarity and +52.2 Defense Success Rate on Attack-pref; and up to +54.6 Intention Consistency Score on GlobalOpinionQA-Ext.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.10077v3</guid></item><item><title>[cs updates on arXiv.org] GraphTARIF: Linear Graph Transformer with Augmented Rank and Improved Focus</title><link>https://arxiv.org/abs/2510.10631</link><description>arXiv:2510.10631v2 Announce Type: replace 
Abstract: Linear attention mechanisms have emerged as efficient alternatives to full self-attention in Graph Transformers, offering linear time complexity. However, existing linear attention models often suffer from a significant drop in expressiveness due to low-rank projection structures and overly uniform attention distributions. We theoretically prove that these properties reduce the class separability of node representations, limiting the model's classification ability. To address this, we propose a novel hybrid framework that enhances both the rank and focus of attention. Specifically, we enhance linear attention by attaching a gated local graph network branch to the value matrix, thereby increasing the rank of the resulting attention map. Furthermore, to alleviate the excessive smoothing effect inherent in linear attention, we introduce a learnable log-power function into the attention scores to reduce entropy and sharpen focus. We theoretically show that this function decreases entropy in the attention distribution, enhancing the separability of learned embeddings. Extensive experiments on both homophilic and heterophilic graph benchmarks demonstrate that our method achieves competitive performance while preserving the scalability of linear attention.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.10631v2</guid></item><item><title>[cs updates on arXiv.org] Deep SPI: Safe Policy Improvement via World Models</title><link>https://arxiv.org/abs/2510.12312</link><description>arXiv:2510.12312v2 Announce Type: replace 
Abstract: Safe policy improvement (SPI) offers theoretical control over policy updates, yet existing guarantees largely concern offline, tabular reinforcement learning (RL). We study SPI in general online settings, when combined with world model and representation learning. We develop a theoretical framework showing that restricting policy updates to a well-defined neighborhood of the current policy ensures monotonic improvement and convergence. This analysis links transition and reward prediction losses to representation quality, yielding online, "deep" analogues of classical SPI theorems from the offline RL literature. Building on these results, we introduce DeepSPI, a principled on-policy algorithm that couples local transition and reward losses with regularised policy updates. On the ALE-57 benchmark, DeepSPI matches or exceeds strong baselines, including PPO and DeepMDPs, while retaining theoretical guarantees.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.12312v2</guid></item><item><title>[cs updates on arXiv.org] Targeted Pooled Latent-Space Steganalysis Applied to Generative Steganography, with a Fix</title><link>https://arxiv.org/abs/2510.12414</link><description>arXiv:2510.12414v2 Announce Type: replace 
Abstract: Steganographic schemes dedicated to generated images modify the seed vector in the latent space to embed a message. Whereas most steganalysis methods attempt to detect the embedding in the image space, this paper proposes to perform steganalysis in the latent space by modeling the statistical distribution of the norm of the latent vector. Specifically, we analyze the practical security of a scheme proposed by Hu et al. for latent diffusion models, which is both robust and practically undetectable when steganalysis is performed on generated images. We show that after embedding, the Stego (latent) vector is distributed on a hypersphere while the Cover vector is i.i.d. Gaussian. By going from the image space to the latent space, we show that it is possible to model the norm of the vector in the latent space under the Cover or Stego hypothesis as Gaussian distributions with different variances. A Likelihood Ratio Test is then derived to perform pooled steganalysis. The impact of the potential knowledge of the prompt and the number of diffusion steps is also studied. Additionally, we show how, by randomly sampling the norm of the latent vector before generation, the initial Stego scheme becomes undetectable in the latent space.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.12414v2</guid></item><item><title>[cs updates on arXiv.org] Reasoning in the Dark: Interleaved Vision-Text Reasoning in Latent Space</title><link>https://arxiv.org/abs/2510.12603</link><description>arXiv:2510.12603v2 Announce Type: replace 
Abstract: Multimodal reasoning aims to enhance the capabilities of MLLMs by incorporating intermediate reasoning steps before reaching the final answer. It has evolved from text-only reasoning to the integration of visual information, enabling the thought process to be conveyed through both images and text. Despite its effectiveness, current multimodal reasoning methods depend on explicit reasoning steps that require labor-intensive vision-text annotations and inherently introduce significant inference latency. To address these issues, we introduce multimodal latent reasoning with the advantages of multimodal representation, reduced annotation, and inference efficiency. To facilitate it, we propose Interleaved Vision-Text Latent Reasoning (IVT-LR), which injects both visual and textual information in the reasoning process within the latent space. Specifically, IVT-LR represents each reasoning step by combining two implicit parts: latent text (the hidden states from the previous step) and latent vision (a set of selected image embeddings). We further introduce a progressive multi-stage training strategy to enable MLLMs to perform the above multimodal latent reasoning steps. Experiments on M$^3$CoT and ScienceQA demonstrate that our IVT-LR method achieves an average performance increase of 5.45\% in accuracy, while simultaneously achieving a speed increase of over 5 times compared to existing approaches.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.12603v2</guid></item><item><title>[cs updates on arXiv.org] WaterFlow: Explicit Physics-Prior Rectified Flow for Underwater Saliency Mask Generation</title><link>https://arxiv.org/abs/2510.12605</link><description>arXiv:2510.12605v2 Announce Type: replace 
Abstract: Underwater Salient Object Detection (USOD) faces significant challenges, including underwater image quality degradation and domain gaps. Existing methods tend to ignore the physical principles of underwater imaging or simply treat degradation phenomena in underwater images as interference factors that must be eliminated, failing to fully exploit the valuable information they contain. We propose WaterFlow, a rectified flow-based framework for underwater salient object detection that innovatively incorporates underwater physical imaging information as explicit priors directly into the network training process and introduces temporal dimension modeling, significantly enhancing the model's capability for salient object identification. On the USOD10K dataset, WaterFlow achieves a 0.072 gain in S_m, demonstrating the effectiveness and superiority of our method. https://github.com/Theo-polis/WaterFlow.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.12605v2</guid></item><item><title>[cs updates on arXiv.org] LLM Prompt Duel Optimizer: Efficient Label-Free Prompt Optimization</title><link>https://arxiv.org/abs/2510.13907</link><description>arXiv:2510.13907v2 Announce Type: replace 
Abstract: Large language models (LLMs) are highly sensitive to prompts, but most automatic prompt optimization (APO) methods assume access to ground-truth references (e.g., labeled validation data) that are costly to obtain. We propose the Prompt Duel Optimizer (PDO), a sample-efficient framework for label-free prompt optimization based on pairwise preference feedback from an LLM judge. PDO casts prompt selection as a dueling-bandit problem and combines (i) Double Thompson Sampling to prioritize informative comparisons under a fixed judge budget, with (ii) top-performer guided mutation to expand the candidate pool while pruning weak prompts. Experiments on BIG-bench Hard (BBH) and MS MARCO show that PDO consistently identifies stronger prompts than label-free baselines, while offering favorable quality--cost trade-offs under constrained comparison budgets.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.13907v2</guid></item><item><title>[cs updates on arXiv.org] YNTP-100: A Benchmark for Your Next Token Prediction with 100 People</title><link>https://arxiv.org/abs/2510.14398</link><description>arXiv:2510.14398v3 Announce Type: replace 
Abstract: Large language models (LLMs) trained for general \textit{next-token prediction} often fail to generate responses that reflect how specific individuals communicate. Progress on personalized alignment is further limited by the difficulty of collecting real-world personal communication data due to privacy constraints. We propose Your Next Token Prediction (YNTP), a task that formulates personalized response generation as token-level prediction conditioned on user interaction history. We introduce \textbf{YNTP-100}, a benchmark built from multilingual multi-day human--agent conversations with 100 people, enabling systematic evaluation of user-specific response behavior. We evaluate external (parameter-preserving) and internal (parameter-updating) alignment methods using metrics of substance similarity and stylistic consistency. The dataset and results are publicly available at: https://github.com/AnonymousHub4Submissions/YNTP100.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.14398v3</guid></item><item><title>[cs updates on arXiv.org] Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures</title><link>https://arxiv.org/abs/2510.14616</link><description>arXiv:2510.14616v2 Announce Type: replace 
Abstract: Current preference learning methods achieve high accuracy on standard benchmarks but exhibit significant performance degradation when objective quality signals are removed. We introduce WritingPreferenceBench, a dataset of 1,800 human-annotated preference pairs (1,200 English, 600 Chinese) across 8 creative writing genres, where responses are matched for objective correctness, factual accuracy, and length. On this benchmark, sequence-based reward models--the standard architecture for RLHF--achieve only 52.7% mean accuracy, while zero-shot language model judges perform at 53.9%. In contrast, generative reward models that produce explicit reasoning chains achieve 81.8% accuracy. We observe high within-model variance across genres: individual models range from 18.2% to 81.8% accuracy across different writing categories, with standard deviations averaging 10.1%. This variance persists regardless of model scale, with 27B parameter models showing no consistent improvement over 8B variants. Our results suggest that current RLHF methods primarily learn to detect objective errors rather than capture subjective quality preferences (e.g., creativity, stylistic flair, and emotional resonance), and that successful preference modeling may require intermediate reasoning representations rather than direct classification.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.14616v2</guid></item><item><title>[cs updates on arXiv.org] Grounding or Guessing? Visual Signals for Detecting Hallucinations in Sign Language Translation</title><link>https://arxiv.org/abs/2510.18439</link><description>arXiv:2510.18439v2 Announce Type: replace 
Abstract: Hallucination, where models generate fluent text unsupported by visual evidence, remains a major flaw in vision-language models and is particularly critical in sign language translation (SLT). In SLT, meaning depends on precise grounding in video, and gloss-free models are especially vulnerable because they map continuous signer movements directly into natural language without intermediate gloss supervision that serves as alignment. We argue that hallucinations arise when models rely on language priors rather than visual input. To capture this, we propose a token-level reliability measure that quantifies how much the decoder uses visual information. Our method combines feature-based sensitivity, which measures internal changes when video is masked, with counterfactual signals, which capture probability differences between clean and altered video inputs. These signals are aggregated into a sentence-level reliability score, providing a compact and interpretable measure of visual grounding. We evaluate the proposed measure on two SLT benchmarks (PHOENIX-2014T and CSL-Daily) with both gloss-based and gloss-free models. Our results show that reliability predicts hallucination rates, generalizes across datasets and architectures, and decreases under visual degradations. Beyond these quantitative trends, we also find that reliability distinguishes grounded tokens from guessed ones, allowing risk estimation without references; when combined with text-based signals (confidence, perplexity, or entropy), it further improves hallucination risk estimation. Qualitative analysis highlights why gloss-free models are more susceptible to hallucinations. Taken together, our findings establish reliability as a practical and reusable tool for diagnosing hallucinations in SLT, and lay the groundwork for more robust hallucination detection in multimodal generation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.18439v2</guid></item><item><title>[cs updates on arXiv.org] PLANA3R: Zero-shot Metric Planar 3D Reconstruction via Feed-Forward Planar Splatting</title><link>https://arxiv.org/abs/2510.18714</link><description>arXiv:2510.18714v2 Announce Type: replace 
Abstract: This paper addresses metric 3D reconstruction of indoor scenes by exploiting their inherent geometric regularities with compact representations. Using planar 3D primitives - a well-suited representation for man-made environments - we introduce PLANA3R, a pose-free framework for metric Planar 3D Reconstruction from unposed two-view images. Our approach employs Vision Transformers to extract a set of sparse planar primitives, estimate relative camera poses, and supervise geometry learning via planar splatting, where gradients are propagated through high-resolution rendered depth and normal maps of primitives. Unlike prior feedforward methods that require 3D plane annotations during training, PLANA3R learns planar 3D structures without explicit plane supervision, enabling scalable training on large-scale stereo datasets using only depth and normal annotations. We validate PLANA3R on multiple indoor-scene datasets with metric supervision and demonstrate strong generalization to out-of-domain indoor environments across diverse tasks under metric evaluation protocols, including 3D surface reconstruction, depth estimation, and relative pose estimation. Furthermore, by formulating with planar 3D representation, our method emerges with the ability for accurate plane segmentation. The project page is available at https://lck666666.github.io/plana3r</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.18714v2</guid></item><item><title>[cs updates on arXiv.org] Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models</title><link>https://arxiv.org/abs/2510.20707</link><description>arXiv:2510.20707v2 Announce Type: replace 
Abstract: Recent large vision-language models (LVLMs) demonstrate remarkable capabilities in processing extended multi-modal sequences, yet the resulting key-value (KV) cache expansion creates a critical memory bottleneck that fundamentally limits deployment scalability. While existing KV cache compression methods focus on retaining high-importance KV pairs to minimize storage, they often overlook the modality-specific semantic redundancy patterns that emerge distinctively in multi-modal KV caches. In this work, we first analyze how, beyond simple importance, the KV cache in LVLMs exhibits varying levels of redundancy across attention heads. We show that relying solely on importance can only cover a subset of the full KV cache information distribution, leading to potential loss of semantic coverage. To address this, we propose MixKV, a novel method that mixes importance with diversity for optimized KV cache compression in LVLMs. MixKV adapts to head-wise semantic redundancy, selectively balancing diversity and importance when compressing KV pairs. Extensive experiments demonstrate that MixKV consistently enhances existing methods across multiple LVLMs. Under extreme compression (budget=64), MixKV improves baseline methods by an average of 5.1% across five multi-modal understanding benchmarks and achieves remarkable gains of 8.0% and 9.0% for SnapKV and AdaKV on GUI grounding tasks, all while maintaining comparable inference efficiency. Furthermore, MixKV extends seamlessly to LLMs with comparable performance gains. Our code is available at https://github.com/xuyang-liu16/MixKV.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.20707v2</guid></item><item><title>[cs updates on arXiv.org] Self-induced stochastic resonance: A physics-informed machine learning approach</title><link>https://arxiv.org/abs/2510.22848</link><description>arXiv:2510.22848v2 Announce Type: replace 
Abstract: Self-induced stochastic resonance (SISR) is the emergence of coherent oscillations in slow-fast excitable systems driven solely by noise, without external periodic forcing or proximity to a bifurcation. This work presents a physics-informed machine learning framework for modeling and predicting SISR in the stochastic FitzHugh-Nagumo neuron. We embed the governing stochastic differential equations and SISR-asymptotic timescale-matching constraints directly into a Physics-Informed Neural Network (PINN) based on a Noise-Augmented State Predictor architecture. The composite loss integrates data fidelity, dynamical residuals, and barrier-based physical constraints derived from Kramers' escape theory. The trained PINN accurately predicts the dependence of spike-train coherence on noise intensity, excitability, and timescale separation, matching results from direct stochastic simulations with substantial improvements in accuracy and generalization compared with purely data-driven methods, while requiring significantly less computation. The framework provides a data-efficient and interpretable surrogate model for simulating and analyzing noise-induced coherence in multiscale stochastic systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.22848v2</guid></item><item><title>[cs updates on arXiv.org] Learning Linearity in Audio Consistency Autoencoders via Implicit Regularization</title><link>https://arxiv.org/abs/2510.23530</link><description>arXiv:2510.23530v2 Announce Type: replace 
Abstract: Audio autoencoders learn useful, compressed audio representations, but their non-linear latent spaces prevent intuitive algebraic manipulation such as mixing or scaling. We introduce a simple training methodology to induce linearity in a high-compression Consistency Autoencoder (CAE) by using data augmentation, thereby inducing homogeneity (equivariance to scalar gain) and additivity (the decoder preserves addition) without altering the model's architecture or loss function. When trained with our method, the CAE exhibits linear behavior in both the encoder and decoder while preserving reconstruction fidelity. We test the practical utility of our learned space on music source composition and separation via simple latent arithmetic. This work presents a straightforward technique for constructing structured latent spaces, enabling more intuitive and efficient audio processing.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.23530v2</guid></item><item><title>[cs updates on arXiv.org] COMMUNITYNOTES: A Dataset for Exploring the Helpfulness of Fact-Checking Explanations</title><link>https://arxiv.org/abs/2510.24810</link><description>arXiv:2510.24810v2 Announce Type: replace 
Abstract: Fact-checking on major platforms, such as X, Meta, and TikTok, is shifting from expert-driven verification to a community-based setup, where users contribute explanatory notes to clarify why a post might be misleading. An important challenge here is determining whether an explanation is helpful for understanding real-world claims and the reasons why, which remains largely underexplored in prior research. In practice, most community notes remain unpublished due to slow community annotation, and the reasons for helpfulness lack clear definitions. To bridge these gaps, we introduce the task of predicting both the helpfulness of explanatory notes and the reason for this. We present COMMUNITYNOTES, a large-scale multilingual dataset of 104k posts with user-provided notes and helpfulness labels. We further propose a framework that automatically generates and improves reason definitions via automatic prompt optimization, and integrate them into prediction. Our experiments show that the optimized definitions can improve both helpfulness and reason prediction. Finally, we show that the helpfulness information is beneficial for existing fact-checking systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.24810v2</guid></item><item><title>[cs updates on arXiv.org] Multi-hop Parallel Image Semantic Communication for Distortion Accumulation Mitigation</title><link>https://arxiv.org/abs/2510.26844</link><description>arXiv:2510.26844v2 Announce Type: replace 
Abstract: Existing semantic communication schemes primarily focus on single-hop scenarios, overlooking the challenges of multi-hop wireless image transmission. As semantic communication is inherently lossy, distortion accumulates over multiple hops, leading to significant performance degradation. To address this, we propose the multi-hop parallel image semantic communication (MHPSC) framework, which introduces a parallel residual compensation link at each hop against distortion accumulation. To minimize the associated transmission bandwidth overhead, a coarse-to-fine residual compression scheme is designed. A deep learning-based residual compressor first condenses the residuals, followed by the adaptive arithmetic coding (AAC) for further compression. A residual distribution estimation module predicts the prior distribution for the AAC to achieve fine compression performances. This approach ensures robust multi-hop image transmission with only a minor increase in transmission bandwidth. Experimental results confirm that MHPSC outperforms both existing semantic communication and traditional separated coding schemes.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.26844v2</guid></item><item><title>[cs updates on arXiv.org] Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS Operations</title><link>https://arxiv.org/abs/2510.26905</link><description>arXiv:2510.26905v2 Announce Type: replace 
Abstract: Cyber-physical systems increasingly rely on Foundational Models such as Large Language Models (LLMs) and Vision-Language Models (VLMs) to increase autonomy through enhanced perception, inference, and planning. However, these models also introduce new types of errors, such as hallucinations, overgeneralizations, and context misalignments, resulting in incorrect and flawed decisions. To address this, we introduce the concept of Cognition Envelopes, designed to establish reasoning boundaries that constrain AI-generated decisions while complementing the use of meta-cognition and traditional safety envelopes. As with safety envelopes, Cognition Envelopes require practical guidelines and systematic processes for their definition, validation, and assurance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.26905v2</guid></item><item><title>[cs updates on arXiv.org] LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation</title><link>https://arxiv.org/abs/2511.03001</link><description>arXiv:2511.03001v2 Announce Type: replace 
Abstract: Despite recent progress in using Large Language Models (LLMs) for automatically generating 3D scenes, generated scenes often lack realistic spatial layouts and object attributes found in real-world environments. As this problem stems from insufficiently detailed, coarse-grained instructions, advancing 3D scene synthesis guided by more detailed, fine-grained instructions that reflect real-world environments becomes crucial. Without such realistic scenes, training embodied agents in unrealistic environments can lead them to learn priors that diverge significantly from real-world physics and semantics, degrading their performance when deployed. Thus, verifying the alignment between the fine-grained instruction and the generated scene is essential for effective learning. However, current evaluation methods, such as CLIPScore and vision-language models (VLMs), often fail to reliably assess such alignment. This shortcoming arises primarily from their shallow understanding of 3D scenes, which often leads to improperly grounded scene components. To address this, we introduce LEGO-Eval, an evaluation framework equipped with diverse tools designed to explicitly ground scene components, enabling more accurate alignment assessments. We also present LEGO-Bench, a benchmark of detailed instructions that specify complex layouts and attributes of real-world environments. Experiments demonstrate that LEGO-Eval outperforms VLM-as-a-judge by 0.41 F1 score in assessing scene-instruction alignment. Benchmarking with LEGO-Bench reveals significant limitations in current generation methods. Across all evaluated approaches, success rates reached at most 10% in generating scenes that fully align with fine-grained instructions.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.03001v2</guid></item><item><title>[cs updates on arXiv.org] First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation</title><link>https://arxiv.org/abs/2511.04715</link><description>arXiv:2511.04715v2 Announce Type: replace 
Abstract: Identifying how training samples influence/impact Large Language Model (LLM) decision-making is essential for effectively interpreting model decisions and auditing large-scale datasets. Current training sample influence estimation methods (also known as influence functions) undertake this goal by utilizing information flow through the model via its first-order and higher-order gradient terms. However, owing to the large model sizes of today consisting of billions of parameters, these influence computations are often restricted to some subset of model layers to ensure computational feasibility. Prior seminal work by Yeh et al. (2022) in assessing which layers are best suited for computing language data influence concluded that the first (embedding) layers are the most informative for this purpose, using a hypothesis based on influence scores canceling out (i.e., the cancellation effect). In this work, we propose theoretical and empirical evidence demonstrating how the cancellation effect is unreliable, and that middle attention layers are better estimators for influence. Furthermore, we address the broader challenge of aggregating influence scores across layers, and showcase how alternatives to standard averaging (such as ranking and vote-based methods) can lead to significantly improved performance. Finally, we propose better methods for evaluating influence score efficacy in LLMs without undertaking model retraining, and propose a new metric known as the Noise Detection Rate (NDR) that exhibits strong predictive capability compared to the cancellation effect. Through extensive experiments across LLMs of varying types and scales, we concretely determine that the first (layers) are not necessarily better than the last (layers) for LLM influence estimation, contrasting with prior knowledge in the field.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.04715v2</guid></item><item><title>[cs updates on arXiv.org] Did You Forkget It? Detecting One-Day Vulnerabilities in Open-source ForksWith Global History Analysis</title><link>https://arxiv.org/abs/2511.05097</link><description>arXiv:2511.05097v2 Announce Type: replace 
Abstract: Tracking vulnerabilities inherited from third-party open-source software is a well-known challenge, often addressed by tracing the threads of dependency information. However, vulnerabilities can also propagate through forking: a code repository forked after the introduction of a vulnerability, but before it is patched, may remain vulnerable long after the vulnerability has been fixed in the initial repository. History analysis approaches are used to track vulnerable software versions at scale. However, such approaches fail to track vulnerabilities in forks, leaving fork maintainers to identify them manually. This paper presents a global history analysis approach to help software developers identify one-day (known but unpatched) vulnerabilities in forked repositories. Leveraging the global graph of public code, as captured by the Software Heritage archive, our approach propagates vulnerability information at the commit level and performs automated impact analysis. Starting from 7162 repositories with vulnerable commits listed in OSV, we propagate vulnerability information to 2.2 million forks. We evaluate our approach by filtering forks with significant user bases whose latest commit is still potentially vulnerable, manually auditing the code, and contacting maintainers for confirmation and responsible disclosure. This process identified 135 high-severity one-day vulnerabilities, achieving a precision of 0.69, with 9 confirmed by maintainers.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.05097v2</guid></item><item><title>[cs updates on arXiv.org] FusionLog: Cross-System Log-based Anomaly Detection via Fusion of General and Proprietary Knowledge</title><link>https://arxiv.org/abs/2511.05878</link><description>arXiv:2511.05878v2 Announce Type: replace 
Abstract: Log-based anomaly detection is critical for ensuring the stability and reliability of web systems. One of the key problems in this task is the lack of sufficient labeled logs, which limits the rapid deployment in new systems. Existing works usually leverage large-scale labeled logs from a mature web system and a small amount of labeled logs from a new system, using transfer learning to extract and generalize general knowledge across both domains. However, these methods focus solely on the transfer of general knowledge and neglect the disparity and potential mismatch between such knowledge and the proprietary knowledge of target system, thus constraining performance. To address this limitation, we propose FusionLog, a novel zero-label cross-system log-based anomaly detection method that effectively achieves the fusion of general and proprietary knowledge, enabling cross-system generalization without any labeled target logs. Specifically, we first design a training-free router based on semantic similarity that dynamically partitions unlabeled target logs into 'general logs' and 'proprietary logs.' For general logs, FusionLog employs a small model based on system-agnostic representation meta-learning for direct training and inference, inheriting the general anomaly patterns shared between the source and target systems. For proprietary logs, we iteratively generate pseudo-labels and fine-tune the small model using multi-round collaborative knowledge distillation and fusion based on large language model (LLM) and small model (SM) to enhance its capability to recognize anomaly patterns specific to the target system. Experimental results on three public log datasets from different systems show that FusionLog achieves over 90% F1-score under a fully zero-label setting, significantly outperforming state-of-the-art cross-system log-based anomaly detection methods.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.05878v2</guid></item><item><title>[cs updates on arXiv.org] Practical Policy Distillation for Reinforcement Learning in Radio Access Networks</title><link>https://arxiv.org/abs/2511.06563</link><description>arXiv:2511.06563v2 Announce Type: replace 
Abstract: Adopting artificial intelligence (AI) in radio access networks (RANs) presents several challenges, including limited availability of link-level measurements (e.g., CQI reports), stringent real-time processing constraints (e.g., sub-1 ms per TTI), and network heterogeneity (different spectrum bands, cell types, and vendor equipment). A critical yet often overlooked barrier lies in the computational and memory limitations of RAN baseband hardware, particularly in legacy 4th Generation (4G) systems, which typically lack on-chip neural accelerators. As a result, only lightweight AI models (under 1 Mb and sub-100~\mu s inference time) can be effectively deployed, limiting both their performance and applicability. However, achieving strong generalization across diverse network conditions often requires large-scale models with substantial resource demands. To address this trade-off, this paper investigates policy distillation in the context of a reinforcement learning-based link adaptation task. We explore two strategies: single-policy distillation, where a scenario-agnostic teacher model is compressed into one generalized student model; and multi-policy distillation, where multiple scenario-specific teachers are consolidated into a single generalist student. Experimental evaluations in a high-fidelity, 5th Generation (5G)-compliant simulator demonstrate that both strategies produce compact student models that preserve the teachers' generalization capabilities while complying with the computational and memory limitations of existing RAN hardware.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.06563v2</guid></item><item><title>[cs updates on arXiv.org] DeepBooTS: Dual-Stream Residual Boosting for Drift-Resilient Time-Series Forecasting</title><link>https://arxiv.org/abs/2511.06893</link><description>arXiv:2511.06893v2 Announce Type: replace 
Abstract: Time-Series (TS) exhibits pronounced non-stationarity. Consequently, most forecasting methods display compromised robustness to concept drift, despite the prevalent application of instance normalization. We tackle this challenge by first analysing concept drift through a bias-variance lens and proving that weighted ensemble reduces variance without increasing bias. These insights motivate DeepBooTS, a novel end-to-end dual-stream residual-decreasing boosting method that progressively reconstructs the intrinsic signal. In our design, each block of a deep model becomes an ensemble of learners with an auxiliary output branch forming a highway to the final prediction. The block-wise outputs correct the residuals of previous blocks, leading to a learning-driven decomposition of both inputs and targets. This method enhances versatility and interpretability while substantially improving robustness to concept drift. Extensive experiments, including those on large-scale datasets, show that the proposed method outperforms existing methods by a large margin, yielding an average performance improvement of 15.8% across various datasets, establishing a new benchmark for TS forecasting.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.06893v2</guid></item><item><title>[cs updates on arXiv.org] Streaming Tensor Programs: A Streaming Abstraction for Dynamic Parallelism</title><link>https://arxiv.org/abs/2511.07776</link><description>arXiv:2511.07776v2 Announce Type: replace 
Abstract: Dynamic behaviors are becoming prevalent in tensor applications, like machine learning, where many widely used models contain data-dependent tensor shapes and control flow. However, the limited expressiveness of prior programming abstractions for spatial dataflow accelerators (SDAs) forces these dynamic behaviors to be implemented statically and/or unoptimized. To address these challenges, we present Streaming Tensor Programs (STeP), a streaming abstraction that enables dynamic tensor workloads to run efficiently on SDAs. STeP introduces flexible routing operators, an explicit memory hierarchy, and symbolic-shape semantics that expose dynamic data rates and tensor dimensions. These capabilities unlock new optimizations, like dynamic tiling, dynamic parallelization, and configuration time-multiplexing, that adapt SDA execution to dynamic behaviors while preserving dataflow efficiency. Using a cycle-approximate simulator on representative LLM layers and a full model with real-world traces, STeP enables: dynamic tiling that breaks the Pareto-optimal frontier from prior work, dynamic parallelization that improves latency by ~2.72x, and configuration time-multiplexing that increases compute utilization by ~2.64x over prior SDA abstractions and their implementations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.07776v2</guid></item><item><title>[cs updates on arXiv.org] Neural Value Iteration</title><link>https://arxiv.org/abs/2511.08825</link><description>arXiv:2511.08825v2 Announce Type: replace 
Abstract: The value function of a POMDP exhibits the piecewise-linear-convex (PWLC) property and can be represented as a finite set of hyperplanes, known as $\alpha$-vectors. Most state-of-the-art POMDP solvers (offline planners) follow the point-based value iteration scheme, which performs Bellman backups on $\alpha$-vectors at reachable belief points until convergence. However, since each $\alpha$-vector is $|S|$-dimensional, these methods quickly become intractable for large-scale problems due to the prohibitive computational cost of Bellman backups. In this work, we demonstrate that the PWLC property allows a POMDP's value function to be alternatively represented as a finite set of neural networks. This insight enables a novel POMDP planning algorithm called \emph{Neural Value Iteration}, which combines the generalization capability of neural networks with the classical value iteration framework. Our approach achieves near-optimal solutions even in extremely large POMDPs that are intractable for existing offline solvers.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.08825v2</guid></item><item><title>[cs updates on arXiv.org] Recursive algorithms for computing Birkhoff interpolation polynomials</title><link>https://arxiv.org/abs/2511.09014</link><description>arXiv:2511.09014v2 Announce Type: replace 
Abstract: As a generalization of Hermite interpolation problem, Birkhoff interpolation is an important subject in numerical approximation. This paper generalizes the existing Generalized Recursive Polynomial Interpolation Algorithm (GRPIA) that is used to compute the Hermite interpolation polynomial. Based on the theory of the Schur complement and the Sylvester identity, the proposed recursive algorithms are applicable to a broader class of Birkhoff interpolation problems, where each interpolation condition is given by the composition of an evaluation functional and a differential polynomial. The approach incorporates a judgment condition to ensure the problem's well-posedness and computes a lower-degree Newton-type interpolation basis (which is also a strongly proper interpolation basis) along with the corresponding interpolation polynomial. Following the numerical examples, we analyze and compare the computational process and complexity of the proposed algorithm against traditional interpolation methods based on Gaussian elimination, and thus demonstrate that the proposed recursive approach reduces both computational cost and storage space requirements.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.09014v2</guid></item><item><title>[cs updates on arXiv.org] AI Annotation Orchestration: Evaluating LLM verifiers to Improve the Quality of LLM Annotations in Learning Analytics</title><link>https://arxiv.org/abs/2511.09785</link><description>arXiv:2511.09785v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) are increasingly used to annotate learning interactions, yet concerns about reliability limit their utility. We test whether verification-oriented orchestration-prompting models to check their own labels (self-verification) or audit one another (cross-verification)-improves qualitative coding of tutoring discourse. Using transcripts from 30 one-to-one math sessions, we compare three production LLMs (GPT, Claude, Gemini) under three conditions: unverified annotation, self-verification, and cross-verification across all orchestration configurations. Outputs are benchmarked against a blinded, disagreement-focused human adjudication using Cohen's kappa. Overall, orchestration yields a 58 percent improvement in kappa. Self-verification nearly doubles agreement relative to unverified baselines, with the largest gains for challenging tutor moves. Cross-verification achieves a 37 percent improvement on average, with pair- and construct-dependent effects: some verifier-annotator pairs exceed self-verification, while others reduce alignment, reflecting differences in verifier strictness. We contribute: (1) a flexible orchestration framework instantiating control, self-, and cross-verification; (2) an empirical comparison across frontier LLMs on authentic tutoring data with blinded human "gold" labels; and (3) a concise notation, verifier(annotator) (e.g., Gemini(GPT) or Claude(Claude)), to standardize reporting and make directional effects explicit for replication. Results position verification as a principled design lever for reliable, scalable LLM-assisted annotation in Learning Analytics.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.09785v2</guid></item><item><title>[cs updates on arXiv.org] GCL-OT: Graph Contrastive Learning with Optimal Transport for Heterophilic Text-Attributed Graphs</title><link>https://arxiv.org/abs/2511.16778</link><description>arXiv:2511.16778v2 Announce Type: replace 
Abstract: Recently, structure-text contrastive learning has shown promising performance on text-attributed graphs by leveraging the complementary strengths of graph neural networks and language models. However, existing methods typically rely on homophily assumptions in similarity estimation and hard optimization objectives, which limit their applicability to heterophilic graphs. Although existing methods can mitigate heterophily through structural adjustments or neighbor aggregation, they usually treat textual embeddings as static targets, leading to suboptimal alignment. In this work, we identify multi-granular heterophily in text-attributed graphs, including complete heterophily, partial heterophily, and latent homophily, which makes structure-text alignment particularly challenging due to mixed, noisy, and missing semantic correlations. To achieve flexible and bidirectional alignment, we propose GCL-OT, a novel graph contrastive learning framework with optimal transport, equipped with tailored mechanisms for each type of heterophily. Specifically, for partial heterophily, we design a RealSoftMax-based similarity estimator to emphasize key neighbor-word interactions while easing background noise. For complete heterophily, we introduce a prompt-based filter that adaptively excludes irrelevant noise during optimal transport alignment. Furthermore, we incorporate OT-guided soft supervision to uncover potential neighbors with similar semantics, enhancing the learning of latent homophily. Theoretical analysis shows that GCL-OT can improve the mutual information bound and Bayes error guarantees. Extensive experiments on nine benchmarks show that GCL-OT outperforms state-of-the-art methods, demonstrating its effectiveness and robustness.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.16778v2</guid></item><item><title>[cs updates on arXiv.org] RacketVision: A Multiple Racket Sports Benchmark for Unified Ball and Racket Analysis</title><link>https://arxiv.org/abs/2511.17045</link><description>arXiv:2511.17045v3 Announce Type: replace 
Abstract: We introduce RacketVision, a novel dataset and benchmark for advancing computer vision in sports analytics, covering table tennis, tennis, and badminton. The dataset is the first to provide large-scale, fine-grained annotations for racket pose alongside traditional ball positions, enabling research into complex human-object interactions. It is designed to tackle three interconnected tasks: fine-grained ball tracking, articulated racket pose estimation, and predictive ball trajectory forecasting. Our evaluation of established baselines reveals a critical insight for multi-modal fusion: while naively concatenating racket pose features degrades performance, a CrossAttention mechanism is essential to unlock their value, leading to trajectory prediction results that surpass strong unimodal baselines. RacketVision provides a versatile resource and a strong starting point for future research in dynamic object tracking, conditional motion forecasting, and multimodal analysis in sports. Project page at https://github.com/OrcustD/RacketVision</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.17045v3</guid></item><item><title>[cs updates on arXiv.org] Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization</title><link>https://arxiv.org/abs/2511.20258</link><description>arXiv:2511.20258v3 Announce Type: replace 
Abstract: Weight Averaging (WA) has emerged as a powerful technique for enhancing generalization by promoting convergence to a flat loss landscape, which correlates with stronger out-of-distribution performance. However, applying WA directly to multi-modal domain generalization (MMDG) is challenging: differences in optimization speed across modalities lead WA to overfit to faster-converging ones in early stages, suppressing the contribution of slower yet complementary modalities, thereby hindering effective modality fusion and skewing the loss surface toward sharper, less generalizable minima. To address this issue, we propose MBCD, a unified collaborative distillation framework that retains WA's flatness-inducing advantages while overcoming its shortcomings in multi-modal contexts. MBCD begins with adaptive modality dropout in the student model to curb early-stage bias toward dominant modalities. A gradient consistency constraint then aligns learning signals between uni-modal branches and the fused representation, encouraging coordinated and smoother optimization. Finally, a WA-based teacher conducts cross-modal distillation by transferring fused knowledge to each uni-modal branch, which strengthens cross-modal interactions and steer convergence toward flatter solutions. Extensive experiments on MMDG benchmarks show that MBCD consistently outperforms existing methods, achieving superior accuracy and robustness across diverse unseen domains.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.20258v3</guid></item><item><title>[cs updates on arXiv.org] ReactionMamba: Generating Short &amp; Long Human Reaction Sequences</title><link>https://arxiv.org/abs/2512.00208</link><description>arXiv:2512.00208v2 Announce Type: replace 
Abstract: We present ReactionMamba, a novel framework for generating long 3D human reaction motions. Reaction-Mamba integrates a motion VAE for efficient motion encoding with Mamba-based state-space models to decode temporally consistent reactions. This design enables ReactionMamba to generate both short sequences of simple motions and long sequences of complex motions, such as dance and martial arts. We evaluate ReactionMamba on three datasets--NTU120-AS, Lindy Hop, and InterX--and demonstrate competitive performance in terms of realism, diversity, and long-sequence generation compared to previous methods, including InterFormer, ReMoS, and Ready-to-React, while achieving substantial improvements in inference speed.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.00208v2</guid></item><item><title>[cs updates on arXiv.org] Tracing Mathematical Proficiency Through Problem-Solving Processes</title><link>https://arxiv.org/abs/2512.00311</link><description>arXiv:2512.00311v2 Announce Type: replace 
Abstract: Knowledge Tracing (KT) aims to model student's knowledge state and predict future performance to enable personalized learning in Intelligent Tutoring Systems. However, traditional KT methods face fundamental limitations in explainability, as they rely solely on the response correctness, neglecting the rich information embedded in students' problem-solving processes. To address this gap, we propose Knowledge Tracing Leveraging Problem-Solving Process (KT-PSP), which incorporates students' problem-solving processes to capture the multidimensional aspects of mathematical proficiency. We also introduce KT-PSP-25, a new dataset specifically designed for the KT-PSP. Building on this, we present StatusKT, a KT framework that employs a teacher-student-teacher three-stage LLM pipeline to extract students' MP as intermediate signals. In this pipeline, the teacher LLM first extracts problem-specific proficiency indicators, then a student LLM generates responses based on the student's solution process, and a teacher LLM evaluates these responses to determine mastery of each indicator. The experimental results on KT-PSP-25 demonstrate that StatusKT improves the prediction performance of existing KT methods. Moreover, StatusKT provides interpretable explanations for its predictions by explicitly modeling students' mathematical proficiency.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.00311v2</guid></item><item><title>[cs updates on arXiv.org] Dynamic Content Moderation in Livestreams: Combining Supervised Classification with MLLM-Boosted Similarity Matching</title><link>https://arxiv.org/abs/2512.03553</link><description>arXiv:2512.03553v2 Announce Type: replace 
Abstract: Content moderation remains a critical yet challenging task for large-scale user-generated video platforms, especially in livestreaming environments where moderation must be timely, multimodal, and robust to evolving forms of unwanted content. We present a hybrid moderation framework deployed at production scale that combines supervised classification for known violations with reference-based similarity matching for novel or subtle cases. This hybrid design enables robust detection of both explicit violations and novel edge cases that evade traditional classifiers. Multimodal inputs (text, audio, visual) are processed through both pipelines, with a multimodal large language model (MLLM) distilling knowledge into each to boost accuracy while keeping inference lightweight. In production, the classification pipeline achieves 67% recall at 80% precision, and the similarity pipeline achieves 76% recall at 80% precision. Large-scale A/B tests show a 6-8% reduction in user views of unwanted livestreams}. These results demonstrate a scalable and adaptable approach to multimodal content governance, capable of addressing both explicit violations and emerging adversarial behaviors.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.03553v2</guid></item><item><title>[cs updates on arXiv.org] TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows</title><link>https://arxiv.org/abs/2512.05150</link><description>arXiv:2512.05150v2 Announce Type: replace 
Abstract: Recent advances in large multi-modal generative models have demonstrated impressive capabilities in multi-modal generation, including image and video generation. These models are typically built upon multi-step frameworks like diffusion and flow matching, which inherently limits their inference efficiency (requiring 40-100 Number of Function Evaluations (NFEs)). While various few-step methods aim to accelerate the inference, existing solutions have clear limitations. Prominent distillation-based methods, such as progressive and consistency distillation, either require an iterative distillation procedure or show significant degradation at very few steps (&lt; 4-NFE). Meanwhile, integrating adversarial training into distillation (e.g., DMD/DMD2 and SANA-Sprint) to enhance performance introduces training instability, added complexity, and high GPU memory overhead due to the auxiliary trained models. To this end, we propose TwinFlow, a simple yet effective framework for training 1-step generative models that bypasses the need of fixed pretrained teacher models and avoids standard adversarial networks during training, making it ideal for building large-scale, efficient models. On text-to-image tasks, our method achieves a GenEval score of 0.83 in 1-NFE, outperforming strong baselines like SANA-Sprint (a GAN loss-based framework) and RCGM (a consistency-based framework). Notably, we demonstrate the scalability of TwinFlow by full-parameter training on Qwen-Image-20B and transform it into an efficient few-step generator. With just 1-NFE, our approach matches the performance of the original 100-NFE model on both the GenEval and DPG-Bench benchmarks, reducing computational cost by $100\times$ with minor quality degradation. Project page is available at https://zhenglin-cheng.com/twinflow.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.05150v2</guid></item><item><title>[cs updates on arXiv.org] Feasibility-aware Learning of Robust Temporal Logic Controllers using BarrierNet</title><link>https://arxiv.org/abs/2512.06973</link><description>arXiv:2512.06973v3 Announce Type: replace 
Abstract: Control Barrier Functions (CBFs) have been used to enforce safety and task specifications expressed in Signal Temporal Logic (STL). However, existing CBF-STL approaches typically rely on fixed hyperparameters and per-step optimization, which can lead to overly conservative behavior, infeasibility near tight input limits, and difficulty satisfying long-horizon STL tasks. To address these limitations, we propose a feasibility-aware learning framework that constructs trainable, time-varying High Order Control Barrier Function (HOCBF) constraints and hyperparameters that guarantee satisfaction of a given STL specification. We introduce a unified robustness measure that jointly captures STL satisfaction, constraint feasibility, and control-bound compliance, and propose a neural network architecture to generate control inputs that maximize this robustness. The resulting controller guarantees STL satisfaction with strictly feasible HOCBF constraints and requires no manual tuning. Simulation results demonstrate that the proposed framework maintains high STL robustness under tight input bounds and significantly outperforms fixed-parameter and non-adaptive baselines in complex environments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.06973v3</guid></item><item><title>[cs updates on arXiv.org] DAUNet: A Lightweight UNet Variant with Deformable Convolutions and Parameter-Free Attention for Medical Image Segmentation</title><link>https://arxiv.org/abs/2512.07051</link><description>arXiv:2512.07051v2 Announce Type: replace 
Abstract: Medical image segmentation plays a pivotal role in automated diagnostic and treatment planning systems. In this work, we present DAUNet, a novel lightweight UNet variant that integrates Deformable V2 Convolutions and Parameter-Free Attention (SimAM) to improve spatial adaptability and context-aware feature fusion without increasing model complexity. DAUNet's bottleneck employs dynamic deformable kernels to handle geometric variations, while the decoder and skip pathways are enhanced using SimAM attention modules for saliency-aware refinement. Extensive evaluations on two challenging datasets, FH-PS-AoP (fetal head and pubic symphysis ultrasound) and FUMPE (CT-based pulmonary embolism detection), demonstrate that DAUNet outperforms state-of-the-art models in Dice score, HD95, and ASD, while maintaining superior parameter efficiency. Ablation studies highlight the individual contributions of deformable convolutions and SimAM attention. DAUNet's robustness to missing context and low-contrast regions establishes its suitability for deployment in real-time and resource-constrained clinical environments.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.07051v2</guid></item><item><title>[cs updates on arXiv.org] Improving the Throughput of Diffusion-based Large Language Models via a Training-Free Confidence-Aware Calibration</title><link>https://arxiv.org/abs/2512.07173</link><description>arXiv:2512.07173v3 Announce Type: replace 
Abstract: We present CadLLM, a training-free method to accelerate the inference throughput of diffusion-based LLMs (dLLMs). We first investigate the dynamic nature of token unmasking confidence across blocks and steps. Based on this observation, we present a lightweight adaptive approach that controls the generation block size, step size, and threshold based on the average confidence of unmasked tokens. We further reduce softmax overhead by dynamically leveraging a subset of the vocabulary to regulate sampling breadth. CadLLM is a plug-and-play, model-agnostic method compatible with KV-cache-based dLLMs. Extensive experiments on four popular tasks demonstrate that CadLLM yields up to 2.28x throughput improvement over the state-of-the-art baseline with competitive accuracy.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.07173v3</guid></item><item><title>[cs updates on arXiv.org] REST: Diffusion-based Real-time End-to-end Streaming Talking Head Generation via ID-Context Caching and Asynchronous Streaming Distillation</title><link>https://arxiv.org/abs/2512.11229</link><description>arXiv:2512.11229v2 Announce Type: replace 
Abstract: Diffusion models have significantly advanced the field of talking head generation (THG). However, slow inference speeds and prevalent non-autoregressive paradigms severely constrain the application of diffusion-based THG models. In this study, we propose REST, a pioneering diffusion-based, real-time, end-to-end streaming audio-driven talking head generation framework. To support real-time end-to-end generation, a compact video latent space is first learned through a spatiotemporal variational autoencoder with a high compression ratio. Additionally, to enable semi-autoregressive streaming within the compact video latent space, we introduce an ID-Context Cache mechanism, which integrates ID-Sink and Context-Cache principles into key-value caching for maintaining identity consistency and temporal coherence during long-term streaming generation. Furthermore, an Asynchronous Streaming Distillation (ASD) strategy is proposed to mitigate error accumulation and enhance temporal consistency in streaming generation, leveraging a non-streaming teacher with an asynchronous noise schedule to supervise the streaming student. REST bridges the gap between autoregressive and diffusion-based approaches, achieving a breakthrough in efficiency for applications requiring real-time THG. Experimental results demonstrate that REST outperforms state-of-the-art methods in both generation speed and overall performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.11229v2</guid></item><item><title>[cs updates on arXiv.org] Structure-Aware Decoding Mechanisms for Complex Entity Extraction with Large-Scale Language Models</title><link>https://arxiv.org/abs/2512.13980</link><description>arXiv:2512.13980v2 Announce Type: replace 
Abstract: This paper proposes a structure-aware decoding method based on large language models to address the difficulty of traditional approaches in maintaining both semantic integrity and structural consistency in nested and overlapping entity extraction tasks. The method introduces a candidate span generation mechanism and structured attention modeling to achieve unified modeling of entity boundaries, hierarchical relationships, and cross-dependencies. The model first uses a pretrained language model to obtain context-aware semantic representations, then captures multi-granular entity span features through candidate representation combinations, and introduces hierarchical structural constraints during decoding to ensure consistency between semantics and structure. To enhance stability in complex scenarios, the model jointly optimizes classification loss and structural consistency loss, maintaining high recognition accuracy under multi-entity co-occurrence and long-sentence dependency conditions. Experiments conducted on the ACE 2005 dataset demonstrate significant improvements in Accuracy, Precision, Recall, and F1-Score, particularly in nested and overlapping entity recognition, where the model shows stronger boundary localization and structural modeling capability. This study verifies the effectiveness of structure-aware decoding in complex semantic extraction tasks, provides a new perspective for developing language models with hierarchical understanding, and establishes a methodological foundation for high-precision information extraction.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.13980v2</guid></item><item><title>[cs updates on arXiv.org] Dual-objective Language Models: Training Efficiency Without Overfitting</title><link>https://arxiv.org/abs/2512.14549</link><description>arXiv:2512.14549v2 Announce Type: replace 
Abstract: This paper combines autoregressive and masked-diffusion training objectives without any architectural modifications, resulting in flexible language models that outperform single-objective models. Autoregressive modeling has been a popular approach, partly because of its training efficiency; however, that comes at the cost of sensitivity to overfitting. On the other hand, masked-diffusion models are less efficient to train while being more resilient to overfitting. In this work, we demonstrate that dual-objective training achieves the best of both worlds. To derive the optimal balance between both objectives, we train and evaluate 50 language models under varying levels of data repetition. We show that it is optimal to combine both objectives under all evaluated settings and that the optimal balance is similar whether targeting autoregressive or masked-diffusion downstream performance.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.14549v2</guid></item><item><title>[cs updates on arXiv.org] Spectral Representation-based Reinforcement Learning</title><link>https://arxiv.org/abs/2512.15036</link><description>arXiv:2512.15036v2 Announce Type: replace 
Abstract: In real-world applications with large state and action spaces, reinforcement learning (RL) typically employs function approximations to represent core components like the policies, value functions, and dynamics models. Although powerful approximations such as neural networks offer great expressiveness, they often present theoretical ambiguities, suffer from optimization instability and exploration difficulty, and incur substantial computational costs in practice. In this paper, we introduce the perspective of spectral representations as a solution to address these difficulties in RL. Stemming from the spectral decomposition of the transition operator, this framework yields an effective abstraction of the system dynamics for subsequent policy optimization while also providing a clear theoretical characterization. We reveal how to construct spectral representations for transition operators that possess latent variable structures or energy-based structures, which implies different learning methods to extract spectral representations from data. Notably, each of these learning methods realizes an effective RL algorithm under this framework. We also provably extend this spectral view to partially observable MDPs. Finally, we validate these algorithms on over 20 challenging tasks from the DeepMind Control Suite, where they achieve performances comparable or superior to current state-of-the-art model-free and model-based baselines.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.15036v2</guid></item><item><title>[cs updates on arXiv.org] Quantifying Fidelity: A Decisive Feature Approach to Comparing Synthetic and Real Imagery</title><link>https://arxiv.org/abs/2512.16468</link><description>arXiv:2512.16468v3 Announce Type: replace 
Abstract: Virtual testing using synthetic data has become a cornerstone of autonomous vehicle (AV) safety assurance. Despite progress in improving visual realism through advanced simulators and generative AI, recent studies reveal that pixel-level fidelity alone does not ensure reliable transfer from simulation to the real world. What truly matters is whether the system-under-test (SUT) bases its decisions on consistent decision evidence in both real and simulated environments, not just whether images "look real" to humans. To this end this paper proposes a behavior-grounded fidelity measure by introducing Decisive Feature Fidelity (DFF), a new SUT-specific metric that extends the existing fidelity spectrum to capture mechanism parity, that is, agreement in the model-specific decisive evidence that drives the SUT's decisions across domains. DFF leverages explainable-AI methods to identify and compare the decisive features driving the SUT's outputs for matched real-synthetic pairs. We further propose estimators based on counterfactual explanations, along with a DFF-guided calibration scheme to enhance simulator fidelity. Experiments on 2126 matched KITTI-VirtualKITTI2 pairs demonstrate that DFF reveals discrepancies overlooked by conventional output-value fidelity. Furthermore, results show that DFF-guided calibration improves decisive-feature and input-level fidelity without sacrificing output value fidelity across diverse SUTs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.16468v3</guid></item><item><title>[cs updates on arXiv.org] Blog Data Showdown: Machine Learning vs Neuro-Symbolic Models for Gender Classification</title><link>https://arxiv.org/abs/2512.16687</link><description>arXiv:2512.16687v2 Announce Type: replace 
Abstract: Text classification problems, such as gender classification from a blog, have been a well-matured research area that has been well studied using machine learning algorithms. It has several application domains in market analysis, customer recommendation, and recommendation systems. This study presents a comparative analysis of the widely used machine learning algorithms, namely Support Vector Machines (SVM), Naive Bayes (NB), Logistic Regression (LR), AdaBoost, XGBoost, and an SVM variant (SVM_R) with neuro-symbolic AI (NeSy). The paper also explores the effect of text representations such as TF-IDF, the Universal Sentence Encoder (USE), and RoBERTa. Additionally, various feature extraction techniques, including Chi-Square, Mutual Information, and Principal Component Analysis, are explored. Building on these, we introduce a comparative analysis of the machine learning and deep learning approaches in comparison to the NeSy. The experimental results show that the use of the NeSy approach matched strong MLP results despite a limited dataset. Future work on this research will expand the knowledge base, the scope of embedding types, and the hyperparameter configuration to further study the effectiveness of the NeSy approach.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.16687v2</guid></item><item><title>[cs updates on arXiv.org] KV Admission: Learning What to Write for Efficient Long-Context Inference</title><link>https://arxiv.org/abs/2512.17452</link><description>arXiv:2512.17452v3 Announce Type: replace 
Abstract: Long-context LLM inference is bottlenecked by the quadratic attention complexity and linear KV cache growth. Prior approaches mitigate this via post-hoc selection or eviction but overlook the root inefficiency: indiscriminate writing to memory. In this paper, we formalize KV cache management as a causal system of three primitives: KV Admission, Selection, and Eviction. We instantiate KV Admission via Write-Gated KV (WG-KV), a lightweight mechanism that learns to predict token utility before cache entry. By filtering out low-utility states early to maintain a compact global cache alongside a sliding local cache, WG-KV reduces memory usage by 46-68% and delivers 3.03-3.70x prefill and 1.85-2.56x decode speedups on Llama and Qwen models, while maintaining compatibility with FlashAttention and Paged-KV systems. These results demonstrate that learning what to write is a principled and practical recipe for efficient long-context inference. Code is available at https://github.com/EMCLab-Sinica/WG-KV.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.17452v3</guid></item><item><title>[cs updates on arXiv.org] ShareChat: A Dataset of Chatbot Conversations in the Wild</title><link>https://arxiv.org/abs/2512.17843</link><description>arXiv:2512.17843v3 Announce Type: replace 
Abstract: While academic research typically treats Large Language Models (LLM) as generic text generators, they are distinct commercial products with unique interfaces and capabilities that fundamentally shape user behavior. Current datasets obscure this reality by collecting text-only data through uniform interfaces that fail to capture authentic chatbot usage. To address this limitation, we present ShareChat, a large-scale corpus of 142,808 conversations (660,293 turns) sourced directly from publicly shared URLs on ChatGPT, Perplexity, Grok, Gemini, and Claude. ShareChat distinguishes itself by preserving native platform affordances, such as citations and thinking traces, across a diverse collection covering 101 languages and the period from April 2023 to October 2025. Furthermore, ShareChat offers substantially longer context windows and greater interaction depth than prior datasets. To illustrate the dataset's breadth, we present three case studies: a completeness analysis of intent satisfaction, a citation study of model grounding, and a temporal analysis of engagement rhythms. This work provides the community with a vital and timely resource for understanding authentic user-LLM chatbot interactions in the wild. The dataset is publicly available via Hugging Face.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.17843v3</guid></item><item><title>[cs updates on arXiv.org] Gabliteration: Adaptive Multi-Directional Neural Weight Modification for Selective Behavioral Alteration in Large Language Models</title><link>https://arxiv.org/abs/2512.18901</link><description>arXiv:2512.18901v3 Announce Type: replace 
Abstract: We present Gabliteration, a novel neural weight modification technique that advances beyond traditional abliteration methods by implementing adaptive multi-directional projections with regularized layer selection. Our approach addresses the fundamental limitation of existing methods that compromise model quality while attempting to modify specific behavioral patterns. Through dynamic layer optimization, regularized projection matrices, and adaptive scaling mechanisms, we achieve theoretically superior weight modification while minimizing quality degradation in unrelated domains. We validate our method through the gabliterated-v1 model series (0.6B to 4B parameters) available on Hugging Face, demonstrating practical applicability across multiple model scales.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.18901v3</guid></item><item><title>[cs updates on arXiv.org] The Ensemble Schr{\"o}dinger Bridge filter for Nonlinear Data Assimilation</title><link>https://arxiv.org/abs/2512.18928</link><description>arXiv:2512.18928v2 Announce Type: replace 
Abstract: This work puts forward a novel nonlinear optimal filter namely the Ensemble Schr{\"o}dinger Bridge nonlinear filter. The proposed filter finds marriage of the standard prediction procedure and the diffusion generative modeling for the analysis procedure to realize one filtering step. The designed approach finds no structural model error, and it is derivative free, training free and highly parallizable. Experimental results show that the designed algorithm performs well given highly nonlinear dynamics in (mildly) high dimension up to 40 or above under a chaotic environment. It also shows better performance than classical methods such as the ensemble Kalman filter and the Particle filter in numerous tests given different level of nonlinearity. Future work will focus on extending the proposed approach to practical meteorological applications and establishing a rigorous convergence analysis.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.18928v2</guid></item><item><title>[cs updates on arXiv.org] JEPA-Reasoner: Decoupling Latent Reasoning from Token Generation</title><link>https://arxiv.org/abs/2512.19171</link><description>arXiv:2512.19171v3 Announce Type: replace 
Abstract: Current autoregressive language models couple high-level reasoning and low-level token generation into a single sequential process, making the reasoning trajectory vulnerable to compounding expression errors. We propose JEPA-Reasoner, a novel architectural paradigm that decouples these tasks using a Joint-Embedding Predictive Architecture (JEPA) for pure latent-space reasoning and a separate Talker module for linguistic reconstruction. By isolating the reasoning engine from the discrete token-sampling process, our architecture enables: (1) Error Containment, where token-level failures cannot propagate into the latent reasoning chain; (2) Continuous Guidance, providing the generator with access to the entire lossless reasoning trajectory; and (3) Representation of Uncertainty, allowing the model to maintain multiple hypotheses via mixed latent vectors. Controlled experiments on synthetic and natural language tasks demonstrate that this decoupling enables a 0.9B model to achieve a 149.5\% improvement in 8-shot GSM8K accuracy over a coupled Transformer baseline trained on identical data. This work shifts the focus from scaling coupled models to investigating decoupled architectures as a more robust foundation for complex reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.19171v3</guid></item><item><title>[cs updates on arXiv.org] Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning</title><link>https://arxiv.org/abs/2512.19920</link><description>arXiv:2512.19920v3 Announce Type: replace 
Abstract: LLM deployment in critical domains is currently impeded by persistent hallucinations--generating plausible but factually incorrect assertions. While scaling laws drove significant improvements in general capabilities, theoretical frameworks suggest hallucination is not merely stochastic error but a predictable statistical consequence of training objectives prioritizing mimicking data distribution over epistemic honesty. Standard RLVR paradigms, utilizing binary reward signals, inadvertently incentivize models as good test-takers rather than honest communicators, encouraging guessing whenever correctness probability exceeds zero. This paper presents an exhaustive investigation into behavioral calibration, which incentivizes models to stochastically admit uncertainty by abstaining when not confident, aligning model behavior with accuracy. Synthesizing recent advances, we propose and evaluate training interventions optimizing strictly proper scoring rules for models to output a calibrated probability of correctness. Our methods enable models to either abstain from producing a complete response or flag individual claims where uncertainty remains. Utilizing Qwen3-4B-Instruct, empirical analysis reveals behavior-calibrated reinforcement learning allows smaller models to surpass frontier models in uncertainty quantification--a transferable meta-skill decouplable from raw predictive accuracy. Trained on math reasoning tasks, our model's log-scale Accuracy-to-Hallucination Ratio gain (0.806) exceeds GPT-5's (0.207) in a challenging in-domain evaluation (BeyondAIME). Moreover, in cross-domain factual QA (SimpleQA), our 4B LLM achieves zero-shot calibration error on par with frontier models including Grok-4 and Gemini-2.5-Pro, even though its factual accuracy is much lower.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.19920v3</guid></item><item><title>[cs updates on arXiv.org] Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</title><link>https://arxiv.org/abs/2512.20573</link><description>arXiv:2512.20573v3 Announce Type: replace 
Abstract: Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM's speed from parallel decoding drastically lowers the risk of costly rejections, providing a practical mechanism to effectively realize the (elusive) lengthy drafts that lead to large speedups with speculative decoding. We present FailFast, a dLLM-based speculative decoding framework that realizes this approach by dynamically adapting its speculation length. It "fails fast" by spending minimal compute in hard-to-speculate regions to shrink speculation latency and "wins big" by aggressively extending draft lengths in easier regions to reduce verification latency (in many cases, speculating and accepting 70 tokens at a time!). Without any fine-tuning, FailFast delivers lossless acceleration of AR LLMs and achieves up to 4.9$\times$ speedup over vanilla decoding, 1.7$\times$ over the best naive dLLM drafter, and 1.7$\times$ over EAGLE-3 across diverse models and workloads. We open-source FailFast at https://github.com/ruipeterpan/failfast.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.20573v3</guid></item><item><title>[cs updates on arXiv.org] An Energy-Efficient RFET-Based Stochastic Computing Neural Network Accelerator</title><link>https://arxiv.org/abs/2512.22131</link><description>arXiv:2512.22131v2 Announce Type: replace 
Abstract: Stochastic computing (SC) offers significant reductions in hardware complexity for traditional convolutional neural networks(CNNs). However, despite its advantages, stochastic computing neural networks (SCNNs) often suffer from high resource consumption due to components such as stochastic number generators (SNGs) and accumulative parallel counters (APCs), which limit overall performance. This paper proposes a novel SCNN architecture leveraging reconfigurable field-effect transistors (RFETs). The inherent reconfigurability at the device level enables the design of highly efficient and compact SNGs, APCs, and other related essential components. Furthermore, a dedicated SCNN accelerator architecture is developed to facilitate system-level simulation. Based on accessible open-source standard cell libraries, experimental results demonstrate that the proposed RFET-based SCNN accelerator achieves significant reductions in area, latency, and energy consumption compared to its FinFET-based counterpart at the same technology node.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.22131v2</guid></item><item><title>[cs updates on arXiv.org] The Bayesian Geometry of Transformer Attention</title><link>https://arxiv.org/abs/2512.22471</link><description>arXiv:2512.22471v3 Announce Type: replace 
Abstract: Transformers often appear to perform Bayesian reasoning in context, but verifying this rigorously has been impossible: natural data lack analytic posteriors, and large models conflate reasoning with memorization. We address this by constructing \emph{Bayesian wind tunnels} -- controlled environments where the true posterior is known in closed form and memorization is provably impossible. In these settings, small transformers reproduce Bayesian posteriors with $10^{-3}$-$10^{-4}$ bit accuracy, while capacity-matched MLPs fail by orders of magnitude, establishing a clear architectural separation.
  Across two tasks -- bijection elimination and Hidden Markov Model (HMM) state tracking -- we find that transformers implement Bayesian inference through a consistent geometric mechanism: residual streams serve as the belief substrate, feed-forward networks perform the posterior update, and attention provides content-addressable routing. Geometric diagnostics reveal orthogonal key bases, progressive query-key alignment, and a low-dimensional value manifold parameterized by posterior entropy. During training this manifold unfurls while attention patterns remain stable, a \emph{frame-precision dissociation} predicted by recent gradient analyses.
  Taken together, these results demonstrate that hierarchical attention realizes Bayesian inference by geometric design, explaining both the necessity of attention and the failure of flat architectures. Bayesian wind tunnels provide a foundation for mechanistically connecting small, verifiable systems to reasoning phenomena observed in large language models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.22471v3</guid></item><item><title>[cs updates on arXiv.org] An Automated Grey Literature Extraction Tool for Software Engineering</title><link>https://arxiv.org/abs/2512.23066</link><description>arXiv:2512.23066v2 Announce Type: replace 
Abstract: Grey literature is essential to software engineering research as it captures practices and decisions that rarely appear in academic venues. However, collecting and assessing it at scale remains difficult because of their heterogeneous sources, formats, and APIs that impede reproducible, large-scale synthesis. To address this issue, we present GLiSE, a prompt-driven tool that turns a research topic prompt into platform-specific queries, gathers results from common software-engineering web sources (GitHub, Stack Overflow) and Google Search, and uses embedding-based semantic classifiers to filter and rank results according to their relevance. GLiSE is designed for reproducibility with all settings being configuration-based, and every generated query being accessible. In this paper, (i) we present the GLiSE tool, (ii) provide a curated dataset of software engineering grey-literature search results classified by semantic relevance to their originating search intent, and (iii) conduct an empirical study on the usability of our tool.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.23066v2</guid></item><item><title>[cs updates on arXiv.org] The Law of Multi-Model Collaboration: Scaling Limits of Model Ensembling for Large Language Models</title><link>https://arxiv.org/abs/2512.23340</link><description>arXiv:2512.23340v2 Announce Type: replace 
Abstract: Recent advances in large language models (LLMs) have been largely driven by scaling laws for individual models, which predict performance improvements as model parameters and data volume increase. However, the capabilities of any single LLM are inherently bounded. One solution originates from intricate interactions among multiple LLMs, rendering their collective performance surpasses that of any constituent model. Despite the rapid proliferation of multi-model integration techniques such as model routing and post-hoc ensembling, a unifying theoretical framework of performance scaling for multi-model collaboration remains absent. In this work, we propose the Law of Multi-model Collaboration, a scaling law that predicts the performance limits of LLM ensembles based on their aggregated parameter budget. To quantify the intrinsic upper bound of multi-model collaboration, we adopt a method-agnostic formulation and assume an idealized integration oracle where the total cross-entropy loss of each sample is determined by the minimum loss of any model in the model pool. Experimental results reveal that multi-model systems follow a power-law scaling with respect to the total parameter count, exhibiting a more significant improvement trend and a lower theoretical loss floor compared to single model scaling. Moreover, ensembles of heterogeneous model families achieve better performance scaling than those formed within a single model family, indicating that model diversity is a primary driver of collaboration gains. These findings suggest that model collaboration represents a critical axis for extending the intelligence frontier of LLMs.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.23340v2</guid></item><item><title>[cs updates on arXiv.org] RxnBench: A Multimodal Benchmark for Evaluating Large Language Models on Chemical Reaction Understanding from Scientific Literature</title><link>https://arxiv.org/abs/2512.23565</link><description>arXiv:2512.23565v5 Announce Type: replace 
Abstract: The integration of Multimodal Large Language Models (MLLMs) into chemistry promises to revolutionize scientific discovery, yet their ability to comprehend the dense, graphical language of reactions within authentic literature remains underexplored. Here, we introduce RxnBench, a multi-tiered benchmark designed to rigorously evaluate MLLMs on chemical reaction understanding from scientific PDFs. RxnBench comprises two tasks: Single-Figure QA (SF-QA), which tests fine-grained visual perception and mechanistic reasoning using 1,525 questions derived from 305 curated reaction schemes, and Full-Document QA (FD-QA), which challenges models to synthesize information from 108 articles, requiring cross-modal integration of text, schemes, and tables. Our evaluation of MLLMs reveals a critical capability gap: while models excel at extracting explicit text, they struggle with deep chemical logic and precise structural recognition. Notably, models with inference-time reasoning significantly outperform standard architectures, yet none achieve 50\% accuracy on FD-QA. These findings underscore the urgent need for domain-specific visual encoders and stronger reasoning engines to advance autonomous AI chemists.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.23565v5</guid></item><item><title>[cs updates on arXiv.org] Geometric Scaling of Bayesian Inference in LLMs</title><link>https://arxiv.org/abs/2512.23752</link><description>arXiv:2512.23752v3 Announce Type: replace 
Abstract: Recent work has shown that small transformers trained in controlled "wind-tunnel'' settings can implement exact Bayesian inference, and that their training dynamics produce a geometric substrate -- low-dimensional value manifolds and progressively orthogonal keys -- that encodes posterior structure. We investigate whether this geometric signature persists in production-grade language models. Across Pythia, Phi-2, Llama-3, and Mistral families, we find that last-layer value representations organize along a single dominant axis whose position strongly correlates with predictive entropy, and that domain-restricted prompts collapse this structure into the same low-dimensional manifolds observed in synthetic settings.
  To probe the role of this geometry, we perform targeted interventions on the entropy-aligned axis of Pythia-410M during in-context learning. Removing or perturbing this axis selectively disrupts the local uncertainty geometry, whereas matched random-axis interventions leave it intact. However, these single-layer manipulations do not produce proportionally specific degradation in Bayesian-like behavior, indicating that the geometry is a privileged readout of uncertainty rather than a singular computational bottleneck. Taken together, our results show that modern language models preserve the geometric substrate that enables Bayesian inference in wind tunnels, and organize their approximate Bayesian updates along this substrate.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.23752v3</guid></item><item><title>[cs updates on arXiv.org] CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution</title><link>https://arxiv.org/abs/2512.23880</link><description>arXiv:2512.23880v2 Announce Type: replace 
Abstract: Large language model (LLM) agents currently depend on predefined tools or early-stage tool generation, limiting their adaptability and scalability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from "LLM + tool use" to "LLM + skill acquisition". CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search, code extraction, and memory utilization; self-reflection via introspection, knowledge graph exploration, and others. We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks. CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms. We further demonstrate real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers. Along with human-agent collaboration and memory consolidation, CASCADE accumulates executable skills that can be shared across agents and scientists, moving toward scalable AI-assisted scientific research.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.23880v2</guid></item><item><title>[cs updates on arXiv.org] Recursive Language Models</title><link>https://arxiv.org/abs/2512.24601</link><description>arXiv:2512.24601v2 Announce Type: replace 
Abstract: We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference paradigm that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs can successfully process inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of vanilla frontier LLMs and common long-context scaffolds across four diverse long-context tasks while having comparable cost. At a small scale, we post-train the first natively recursive language model. Our model, RLM-Qwen3-8B, outperforms the underlying Qwen3-8B model by $28.3\%$ on average and even approaches the quality of vanilla GPT-5 on three long-context tasks. Code is available at https://github.com/alexzhang13/rlm.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.24601v2</guid></item><item><title>[cs updates on arXiv.org] FaithSCAN: Model-Driven Single-Pass Hallucination Detection for Faithful Visual Question Answering</title><link>https://arxiv.org/abs/2601.00269</link><description>arXiv:2601.00269v2 Announce Type: replace 
Abstract: Faithfulness hallucinations in VQA occur when vision-language models produce fluent yet visually ungrounded answers, severely undermining their reliability in safety-critical applications. Existing detection methods mainly fall into two categories: external verification approaches relying on auxiliary models or knowledge bases, and uncertainty-driven approaches using repeated sampling or uncertainty estimates. The former suffer from high computational overhead and are limited by external resource quality, while the latter capture only limited facets of model uncertainty and fail to sufficiently explore the rich internal signals associated with the diverse failure modes. Both paradigms thus have inherent limitations in efficiency, robustness, and detection performance. To address these challenges, we propose FaithSCAN: a lightweight network that detects hallucinations by exploiting rich internal signals of VLMs, including token-level decoding uncertainty, intermediate visual representations, and cross-modal alignment features. These signals are fused via branch-wise evidence encoding and uncertainty-aware attention. We also extend the LLM-as-a-Judge paradigm to VQA hallucination and propose a low-cost strategy to automatically generate model-dependent supervision signals, enabling supervised training without costly human labels while maintaining high detection accuracy. Experiments on multiple VQA benchmarks show that FaithSCAN significantly outperforms existing methods in both effectiveness and efficiency. In-depth analysis shows hallucinations arise from systematic internal state variations in visual perception, cross-modal reasoning, and language decoding. Different internal signals provide complementary diagnostic cues, and hallucination patterns vary across VLM architectures, offering new insights into the underlying causes of multimodal hallucinations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.00269v2</guid></item><item><title>[cs updates on arXiv.org] All-in-One Video Restoration under Smoothly Evolving Unknown Weather Degradations</title><link>https://arxiv.org/abs/2601.00533</link><description>arXiv:2601.00533v2 Announce Type: replace 
Abstract: All-in-one image restoration aims to recover clean images from diverse unknown degradations using a single model. But extending this task to videos faces unique challenges. Existing approaches primarily focus on frame-wise degradation variation, overlooking the temporal continuity that naturally exists in real-world degradation processes. In practice, degradation types and intensities evolve smoothly over time, and multiple degradations may coexist or transition gradually. In this paper, we introduce the Smoothly Evolving Unknown Degradations (SEUD) scenario, where both the active degradation set and degradation intensity change continuously over time. To support this scenario, we design a flexible synthesis pipeline that generates temporally coherent videos with single, compound, and evolving degradations. To address the challenges in the SEUD scenario, we propose an all-in-One Recurrent Conditional and Adaptive prompting Network (ORCANet). First, a Coarse Intensity Estimation Dehazing (CIED) module estimates haze intensity using physical priors and provides coarse dehazed features as initialization. Second, a Flow Prompt Generation (FPG) module extracts degradation features. FPG generates both static prompts that capture segment-level degradation types and dynamic prompts that adapt to frame-level intensity variations. Furthermore, a label-aware supervision mechanism improves the discriminability of static prompt representations under different degradations. Extensive experiments show that ORCANet achieves superior restoration quality, temporal consistency, and robustness over image and video-based baselines. Code is available at https://github.com/Friskknight/ORCANet-SEUD.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.00533v2</guid></item><item><title>[cs updates on arXiv.org] Diffusion Timbre Transfer Via Mutual Information Guided Inpainting</title><link>https://arxiv.org/abs/2601.01294</link><description>arXiv:2601.01294v2 Announce Type: replace 
Abstract: We study timbre transfer as an inference-time editing problem for music audio. Starting from a strong pre-trained latent diffusion model, we introduce a lightweight procedure that requires no additional training: (i) a dimension-wise noise injection that targets latent channels most informative of instrument identity, and (ii) an early-step clamping mechanism that re-imposes the input's melodic and rhythmic structure during reverse diffusion. The method operates directly on audio latents and is compatible with text/audio conditioning (e.g., CLAP). We discuss design choices,analyze trade-offs between timbral change and structural preservation, and show that simple inference-time controls can meaningfully steer pre-trained models for style-transfer use cases.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.01294v2</guid></item><item><title>[cs updates on arXiv.org] SimpleMem: Efficient Lifelong Memory for LLM Agents</title><link>https://arxiv.org/abs/2601.02553</link><description>arXiv:2601.02553v2 Announce Type: replace 
Abstract: To support long-term interaction in complex environments, LLM agents require memory systems that manage historical experiences. Existing approaches either retain full interaction histories via passive context extension, leading to substantial redundancy, or rely on iterative reasoning to filter noise, incurring high token costs. To address this challenge, we introduce SimpleMem, an efficient memory framework based on semantic lossless compression. We propose a three-stage pipeline designed to maximize information density and token utilization: (1) Semantic Structured Compression, which distills unstructured interactions into compact, multi-view indexed memory units; (2) Online Semantic Synthesis, an intra-session process that instantly integrates related context into unified abstract representations to eliminate redundancy; and (3) Intent-Aware Retrieval Planning, which infers search intent to dynamically determine retrieval scope and construct precise context efficiently. Experiments on benchmark datasets show that our method consistently outperforms baseline approaches in accuracy, retrieval efficiency, and inference cost, achieving an average F1 improvement of 26.4% while reducing inference-time token consumption by up to 30-fold, demonstrating a superior balance between performance and efficiency. Code is available at https://github.com/aiming-lab/SimpleMem.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.02553v2</guid></item><item><title>[cs updates on arXiv.org] Stochastic Voronoi Ensembles for Anomaly Detection</title><link>https://arxiv.org/abs/2601.03664</link><description>arXiv:2601.03664v2 Announce Type: replace 
Abstract: Anomaly detection aims to identify data instances that deviate significantly from majority of data, which has been widely used in fraud detection, network security, and industrial quality control. Existing methods struggle with datasets exhibiting varying local densities: distance-based methods miss local anomalies, while density-based approaches require careful parameter selection and incur quadratic time complexity. We observe that local anomalies, though indistinguishable under global analysis, become conspicuous when the data space is decomposed into restricted regions and each region is examined independently. Leveraging this geometric insight, we propose SVEAD (Stochastic Voronoi Ensembles Anomaly Detector), which constructs ensemble random Voronoi diagrams and scores points by normalized cell-relative distances weighted by local scale. The proposed method achieves linear time complexity and constant space complexity. Experiments on 45 datasets demonstrate that SVEAD outperforms 12 state-of-the-art approaches.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.03664v2</guid></item><item><title>[cs updates on arXiv.org] Improving and Accelerating Offline RL in Large Discrete Action Spaces with Structured Policy Initialization</title><link>https://arxiv.org/abs/2601.04441</link><description>arXiv:2601.04441v2 Announce Type: replace 
Abstract: Reinforcement learning in discrete combinatorial action spaces requires searching over exponentially many joint actions to simultaneously select multiple sub-actions that form coherent combinations. Existing approaches either simplify policy learning by assuming independence across sub-actions, which often yields incoherent or invalid actions, or attempt to learn action structure and control jointly, which is slow and unstable. We introduce Structured Policy Initialization (SPIN), a two-stage framework that first pre-trains an Action Structure Model (ASM) to capture the manifold of valid actions, then freezes this representation and trains lightweight policy heads for control. On challenging discrete DM Control benchmarks, SPIN improves average return by up to 39% over the state of the art while reducing time to convergence by up to 12.8$\times$.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.04441v2</guid></item><item><title>[cs updates on arXiv.org] SourceNet: Interpretable Sim-to-Real Inference on Variable-Geometry Sensor Arrays for Earthquake Source Inversion</title><link>https://arxiv.org/abs/2601.06320</link><description>arXiv:2601.06320v2 Announce Type: replace 
Abstract: Inferring high-dimensional physical states from sparse, ad-hoc sensor arrays is a fundamental challenge across AI for Science, yet standard architectures like CNNs and DeepSets struggle to capture the irregular geometries and relational physics inherent to domains like seismology. To address this, we propose SourceNet, a Transformer-based framework that bridges the profound Sim-to-Real gap via Physics-Structured Domain Randomization (PSDR), a protocol that randomizes governing physical dynamics to enforce invariance to unmodeled environmental heterogeneity. By pre-training on 100,000 synthetic events and fine-tuning on ~2,500 real-world events, SourceNet achieves state-of-the-art precision on held-out real data, demonstrating exceptional data efficiency and real-time capability compared to classical solvers. Beyond prediction, interpretability analysis reveals that the model shows scientific-agent-like features: it autonomously discovers geometric information bottlenecks and learns an attention policy that prioritizes sparse sensor placements, effectively recovering principles of optimal experimental design from data alone.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.06320v2</guid></item><item><title>[cs updates on arXiv.org] VLM-CAD: VLM-Optimized Collaborative Agent Design Workflow for Analog Circuit Sizing</title><link>https://arxiv.org/abs/2601.07315</link><description>arXiv:2601.07315v3 Announce Type: replace 
Abstract: Analog mixed-signal circuit sizing involves complex trade-offs within high-dimensional design spaces. Existing automatic analog circuit sizing approaches rely solely on netlists, ignoring the circuit schematic, which hinders the cognitive link between the schematic and its performance. Furthermore, the black-box nature of machine learning methods and hallucination risks in large language models fail to provide the necessary ground-truth explainability required for industrial sign-off. To address these challenges, we propose a Vision Language Model-optimized collaborative agent design workflow (VLM-CAD), which analyzes circuits, optimizes DC operating points, performs inference-based sizing, and executes external sizing optimization. We integrate Image2Net to annotate circuit schematics and generate a structured JSON description for precise interpretation by Vision Language Models. Furthermore, we propose an Explainable Trust Region Bayesian Optimization method (ExTuRBO) that employs collaborative warm-start from agent-generated seeds and offers dual-granularity sensitivity analysis for external sizing optimization, supporting a comprehensive final design report. Experiment results on amplifier sizing tasks using 180nm, 90nm, and 45nm Predictive Technology Models demonstrate that VLM-CAD effectively balances power and performance while maintaining physics-based explainability. VLM-CAD meets all specification requirements while maintaining low power consumption in optimizing an amplifier with a complementary input and a class-AB output stage, with a total runtime under 66 minutes across all experiments on two amplifiers.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.07315v3</guid></item><item><title>[cs updates on arXiv.org] Diffusion in SPAD Signals</title><link>https://arxiv.org/abs/2601.07599</link><description>arXiv:2601.07599v2 Announce Type: replace 
Abstract: We derive the likelihood of a raw signal in a single photon avalanche diode (SPAD), given a fixed photon flux. The raw signal comprises timing of detection events, which are nonlinearly related to the flux. Moreover, they are naturally stochastic. We then derive a score function of the signal. This is a key for solving inverse problems based on SPAD signals. We focus on deriving solutions involving a diffusion model, to express image priors. We demonstrate the effect of low or high photon counts, and the consequence of exploiting timing of detection events.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.07599v2</guid></item><item><title>[cs updates on arXiv.org] Demystifying the Slash Pattern in Attention: The Role of RoPE</title><link>https://arxiv.org/abs/2601.08297</link><description>arXiv:2601.08297v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) often exhibit slash attention patterns, where attention scores concentrate along the $\Delta$-th sub-diagonal for some offset $\Delta$. These patterns play a key role in passing information across tokens. But why do they emerge? In this paper, we demystify the emergence of these Slash-Dominant Heads (SDHs) from both empirical and theoretical perspectives. First, by analyzing open-source LLMs, we find that SDHs are intrinsic to models and generalize to out-of-distribution prompts. To explain the intrinsic emergence, we analyze the queries, keys, and Rotary Position Embedding (RoPE), which jointly determine attention scores. Our empirical analysis reveals two characteristic conditions of SDHs: (1) Queries and keys are almost rank-one, and (2) RoPE is dominated by medium- and high-frequency components. Under these conditions, queries and keys are nearly identical across tokens, and interactions between medium- and high-frequency components of RoPE give rise to SDHs. Beyond empirical evidence, we theoretically show that these conditions are sufficient to ensure the emergence of SDHs by formalizing them as our modeling assumptions. Particularly, we analyze the training dynamics of a shallow Transformer equipped with RoPE under these conditions, and prove that models trained via gradient descent exhibit SDHs. The SDHs generalize to out-of-distribution prompts.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.08297v2</guid></item><item><title>[cs updates on arXiv.org] RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation</title><link>https://arxiv.org/abs/2601.08430</link><description>arXiv:2601.08430v2 Announce Type: replace 
Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has driven substantial progress in reasoning-intensive domains like mathematics. However, optimizing open-ended generation remains challenging due to the lack of ground truth. While rubric-based evaluation offers a structured proxy for verification, existing methods suffer from scalability bottlenecks and coarse criteria, resulting in a supervision ceiling effect. To address this, we propose an automated Coarse-to-Fine Rubric Generation framework. By synergizing principle-guided synthesis, multi-model aggregation, and difficulty evolution, our approach produces comprehensive and highly discriminative criteria capable of capturing the subtle nuances. Based on this framework, we introduce RubricHub, a large-scale ($\sim$110k) and multi-domain dataset. We validate its utility through a two-stage post-training pipeline comprising Rubric-based Rejection Sampling Fine-Tuning (RuFT) and Reinforcement Learning (RuRL). Experimental results demonstrate that RubricHub unlocks significant performance gains: our post-trained Qwen3-14B achieves state-of-the-art (SOTA) results on HealthBench (69.3), surpassing proprietary frontier models such as GPT-5. Our code is available at \href{https://github.com/teqkilla/RubricHub}{ this URL}.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.08430v2</guid></item><item><title>[cs updates on arXiv.org] SAM-Aug: Leveraging SAM Priors for Few-Shot Parcel Segmentation in Satellite Time Series</title><link>https://arxiv.org/abs/2601.09110</link><description>arXiv:2601.09110v2 Announce Type: replace 
Abstract: Few-shot semantic segmentation of time-series remote sensing images remains a critical challenge, particularly in regions where labeled data is scarce or costly to obtain. While state-of-the-art models perform well under full supervision, their performance degrades significantly under limited labeling, limiting their real-world applicability. In this work, we propose SAM-Aug, a new annotation-efficient framework that leverages the geometry-aware segmentation capability of the Segment Anything Model (SAM) to improve few-shot land cover mapping. Our approach constructs cloud-free composite images from temporal sequences and applies SAM in a fully unsupervised manner to generate geometry-aware mask priors. These priors are then integrated into training through a proposed loss function called RegionSmoothLoss, which enforces prediction consistency within each SAM-derived region across temporal frames, effectively regularizing the model to respect semantically coherent structures. Extensive experiments on the PASTIS-R benchmark under a 5 percent labeled setting demonstrate the effectiveness and robustness of SAM-Aug. Averaged over three random seeds (42, 2025, 4090), our method achieves a mean test mIoU of 36.21 percent, outperforming the state-of-the-art baseline by +2.33 percentage points, a relative improvement of 6.89 percent. Notably, on the most favorable split (seed=42), SAM-Aug reaches a test mIoU of 40.28 percent, representing an 11.2 percent relative gain with no additional labeled data. The consistent improvement across all seeds confirms the generalization power of leveraging foundation model priors under annotation scarcity. Our results highlight that vision models like SAM can serve as useful regularizers in few-shot remote sensing learning, offering a scalable and plug-and-play solution for land cover monitoring without requiring manual annotations or model fine-tuning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.09110v2</guid></item><item><title>[cs updates on arXiv.org] Qualitative and Numerical Simulation of a Time-Fractional SEIR Mpox Model Arising in Population Epidemiology</title><link>https://arxiv.org/abs/2601.09479</link><description>arXiv:2601.09479v2 Announce Type: replace 
Abstract: Epidemiological modeling is vital in understanding disease dynamics and guiding public health interventions. This study presents a time-fractional SEIR model to describe the transmission dynamics of Mpox, incorporating memory effects via the fractional derivative. We perform an extensive qualitative investigation, proving that there is a unique solution and that the solutions are Hyers-Ulam stable. To approximate the model numerically, we implement the L1 finite difference scheme for the Caputo derivative and solve the resulting nonlinear system using the Newton-Raphson technique. A detailed error analysis is provided, demonstrating that the scheme achieves algebraic convergence. Comparative results with the Fractional Modified Euler method (FMEM) confirm the superior accuracy and stability of the proposed approach. Numerical simulations under biologically relevant parameters illustrate the impact of the non-integer order and vaccination rate on disease progression. The study underscores the effectiveness of fractional order models in capturing epidemic memory effects and positions the L1 scheme as a robust numerical tool for simulating such dynamics.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.09479v2</guid></item><item><title>[cs updates on arXiv.org] HOMURA: Taming the Sand-Glass for Time-Constrained LLM Translation via Reinforcement Learning</title><link>https://arxiv.org/abs/2601.10187</link><description>arXiv:2601.10187v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have achieved remarkable strides in multilingual translation but are hindered by a systemic cross-lingual verbosity bias, rendering them unsuitable for strict time-constrained tasks like subtitling and dubbing. Current prompt-engineering approaches struggle to resolve this conflict between semantic fidelity and rigid temporal feasibility. To bridge this gap, we first introduce Sand-Glass, a benchmark specifically designed to evaluate translation under syllable-level duration constraints. Furthermore, we propose HOMURA, a reinforcement learning framework that explicitly optimizes the trade-off between semantic preservation and temporal compliance. By employing a KL-regularized objective with a novel dynamic syllable-ratio reward, HOMURA effectively "tames" the output length. Experimental results demonstrate that our method significantly outperforms strong LLM baselines, achieving precise length control that respects linguistic density hierarchies without compromising semantic adequacy.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.10187v2</guid></item><item><title>[cs updates on arXiv.org] Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering</title><link>https://arxiv.org/abs/2601.10402</link><description>arXiv:2601.10402v3 Announce Type: replace 
Abstract: The advancement of artificial intelligence toward agentic science is currently bottlenecked by the challenge of ultra-long-horizon autonomy, the ability to sustain strategic coherence and iterative correction over experimental cycles spanning days or weeks. While Large Language Models (LLMs) have demonstrated prowess in short-horizon reasoning, they are easily overwhelmed by execution details in the high-dimensional, delayed-feedback environments of real-world research, failing to consolidate sparse feedback into coherent long-term guidance. Here, we present ML-Master 2.0, an autonomous agent that masters ultra-long-horizon machine learning engineering (MLE) which is a representative microcosm of scientific discovery. By reframing context management as a process of cognitive accumulation, our approach introduces Hierarchical Cognitive Caching (HCC), a multi-tiered architecture inspired by computer systems that enables the structural differentiation of experience over time. By dynamically distilling transient execution traces into stable knowledge and cross-task wisdom, HCC allows agents to decouple immediate execution from long-term experimental strategy, effectively overcoming the scaling limits of static context windows. In evaluations on OpenAI's MLE-Bench under 24-hour budgets, ML-Master 2.0 achieves a state-of-the-art medal rate of 56.44%. Our findings demonstrate that ultra-long-horizon autonomy provides a scalable blueprint for AI capable of autonomous exploration beyond human-precedent complexities.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.10402v3</guid></item><item><title>[cs updates on arXiv.org] Constant Metric Scaling in Riemannian Computation</title><link>https://arxiv.org/abs/2601.10992</link><description>arXiv:2601.10992v2 Announce Type: replace 
Abstract: Constant rescaling of a Riemannian metric appears in many computational settings, often through a global scale parameter that is introduced either explicitly or implicitly. Although this operation is elementary, its consequences are not always made clear in practice and may be confused with changes in curvature, manifold structure, or coordinate representation. In this note we provide a short, self-contained account of constant metric scaling on arbitrary Riemannian manifolds. We distinguish between quantities that change under such a scaling, including norms, distances, volume elements, and gradient magnitudes, and geometric objects that remain invariant, such as the Levi--Civita connection, geodesics, exponential and logarithmic maps, and parallel transport. We also discuss implications for Riemannian optimization, where constant metric scaling can often be interpreted as a global rescaling of step sizes rather than a modification of the underlying geometry. The goal of this note is purely expository and is intended to clarify how a global metric scale parameter can be introduced in Riemannian computation without altering the geometric structures on which these methods rely.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.10992v2</guid></item><item><title>[cs updates on arXiv.org] LAPS: A Length-Aware-Prefill LLM Serving System</title><link>https://arxiv.org/abs/2601.11589</link><description>arXiv:2601.11589v2 Announce Type: replace 
Abstract: LAPS identifies and disaggregates requests with different prompt lengths in LLM serving to reduce TTFT latency. While recent systems have decoupled the prefill and decode stages to improve throughput, they still rely on unified scheduling policies that fail to adapt to heterogeneous workload characteristics. We observe that prompt-length variations lead to distinct performance bottlenecks, motivating an adaptive scheduling strategy. LAPS disaggregates multi-turn long-prefill requests from short-prefill ones and introduces a length-aware smart batching mechanism for short-prefill workloads. It adopts a dual-queue design that supports temporal disaggregation on a single prefill instance or spatial disaggregation across multiple instances. For short-prefill batches, a batch waiting window and CUDA Graph-based clustering mitigate interference from heterogeneous computation, reducing batching delay and lowering average latency. In real multi-turn workloads, LAPS reduces prefill latency by over 30\% compared to vanilla SGLang under prefill-decode disaggregation, and further decreases SLO violations by 28\% in multi-instance deployments with vanilla data-parallel configuration. Compared to the SGLang router with load balancing, it further lowers SLO violations by 12\% in multi-GPU settings. Under high concurrency and mixed-request scenarios, LAPS improves request throughput by 35\% serving Qwen2.5-32B model for prefill instance, demonstrating its effectiveness in optimizing heterogeneous LLM serving workloads.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11589v2</guid></item><item><title>[cs updates on arXiv.org] PEARL: Self-Evolving Assistant for Time Management with Reinforcement Learning</title><link>https://arxiv.org/abs/2601.11957</link><description>arXiv:2601.11957v2 Announce Type: replace 
Abstract: Overlapping calendar invitations force busy professionals to repeatedly decide which meetings to attend, reschedule, or decline. We refer to this preference-driven decision process as calendar conflict resolution. Automating this decision process is crucial yet challenging. Scheduling logistics can drain hours, and human delegation often fails at scale, which motivates us to ask: Can we trust large language models (LLMs) or language agents to manage time? To enable a systematic study of this question, we introduce CalConflictBench, a benchmark for long-horizon calendar conflict resolution. In CalConflictBench, conflicts are presented to agents round-by-round over a calendar year, requiring them to infer and adapt to user preferences progressively. Our experiments show that current LLM agents perform poorly with high error rates, e.g., Qwen-3-30B-Think has an average error rate of 35%. To address this gap, we propose PEARL, a reinforcement-learning framework that (i) augments the language agent with an external preference memory that stores and updates inferred strategies (e.g., attendee priorities, topic importance, time/location preferences), and (ii) optimizes the agent with round-wise rewards that directly supervise decision correctness, ranking quality, and memory usage across rounds. Experiments on CalConflictBench show that PEARL achieves an error reduction rate of 0.76 and a 55% improvement in average error rate compared to the strongest baseline.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.11957v2</guid></item><item><title>[cs updates on arXiv.org] Learning Stochastic Bridges for Video Object Removal via Video-to-Video Translation</title><link>https://arxiv.org/abs/2601.12066</link><description>arXiv:2601.12066v2 Announce Type: replace 
Abstract: Existing video object removal methods predominantly rely on diffusion models following a noise-to-data paradigm, where generation starts from uninformative Gaussian noise. This approach discards the rich structural and contextual priors present in the original input video. Consequently, such methods often lack sufficient guidance, leading to incomplete object erasure or the synthesis of implausible content that conflicts with the scene's physical logic. In this paper, we reformulate video object removal as a video-to-video translation task via a stochastic bridge model. Unlike noise-initialized methods, our framework establishes a direct stochastic path from the source video (with objects) to the target video (objects removed). This bridge formulation effectively leverages the input video as a strong structural prior, guiding the model to perform precise removal while ensuring that the filled regions are logically consistent with the surrounding environment. To address the trade-off where strong bridge priors hinder the removal of large objects, we propose a novel adaptive mask modulation strategy. This mechanism dynamically modulates input embeddings based on mask characteristics, balancing background fidelity with generative flexibility. Extensive experiments demonstrate that our approach significantly outperforms existing methods in both visual quality and temporal consistency. The project page is https://bridgeremoval.github.io/.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12066v2</guid></item><item><title>[cs updates on arXiv.org] Complexity of Model Checking Second-Order Hyperproperties on Finite Structures</title><link>https://arxiv.org/abs/2601.12361</link><description>arXiv:2601.12361v2 Announce Type: replace 
Abstract: We study the model checking problem of Hyper2LTL over finite structures. Hyper2LTL is a second-order hyperlogic, that extends the well-studied logic HyperLTL by adding quantification over sets of traces, to express complex hyperproperties such as epistemic and asynchronous hyperproperties. While Hyper2LTL is very expressive, its expressiveness comes with a price, and its general model checking problem is undecidable. This motivates us to study the model checking problem for Hyper2LTL over finite structures -- tree-shaped or acyclic graphs, which are particularly useful for monitoring purposes. We show that Hyper2LTL model checking is decidable on finite structures. It is in PSPACE (in the size of the model) on tree-shaped models and in EXPSPACE on acyclic models. Additionally, we show that for an expressive fragment of Hyper2LTL, namely the Fixpoint Hyper2LTLfp fragment, the model checking problem is much simpler and is P-complete on tree-shaped models and EXP-complete on acyclic models. Last, we present some preliminary results that take into account not only the size of the model, but also the formula size.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12361v2</guid></item><item><title>[cs updates on arXiv.org] Trend-Adjusted Time Series Models with an Application to Gold Price Forecasting</title><link>https://arxiv.org/abs/2601.12706</link><description>arXiv:2601.12706v2 Announce Type: replace 
Abstract: Time series data play a critical role in various fields, including finance, healthcare, marketing, and engineering. A wide range of techniques (from classical statistical models to neural network-based approaches such as Long Short-Term Memory (LSTM)) have been employed to address time series forecasting challenges. In this paper, we reframe time series forecasting as a two-part task: (1) predicting the trend (directional movement) of the time series at the next time step, and (2) forecasting the quantitative value at the next time step. The trend can be predicted using a binary classifier, while quantitative values can be forecasted using models such as LSTM and Bidirectional Long Short-Term Memory (Bi-LSTM). Building on this reframing, we propose the Trend-Adjusted Time Series (TATS) model, which adjusts the forecasted values based on the predicted trend provided by the binary classifier. We validate the proposed approach through both theoretical analysis and empirical evaluation. The TATS model is applied to a volatile financial time series (the daily gold price) with the objective of forecasting the next days price. Experimental results demonstrate that TATS consistently outperforms standard LSTM and Bi-LSTM models by achieving significantly lower forecasting error. In addition, our results indicate that commonly used metrics such as MSE and MAE are insufficient for fully assessing time series model performance. Therefore, we also incorporate trend detection accuracy, which measures how effectively a model captures trends in a time series.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12706v2</guid></item><item><title>[cs updates on arXiv.org] Actionable Interpretability Must Be Defined in Terms of Symmetries</title><link>https://arxiv.org/abs/2601.12913</link><description>arXiv:2601.12913v2 Announce Type: replace 
Abstract: This paper argues that interpretability research in Artificial Intelligence (AI) is fundamentally ill-posed as existing definitions of interpretability fail to describe how interpretability can be formally tested or designed for. We posit that actionable definitions of interpretability must be formulated in terms of *symmetries* that inform model design and lead to testable conditions. Under a probabilistic view, we hypothesise that four symmetries (inference equivariance, information invariance, concept-closure invariance, and structural invariance) suffice to (i) formalise interpretable models as a subclass of probabilistic models, (ii) yield a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion, and (iii) provide a formal framework to verify compliance with safety standards and regulations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12913v2</guid></item><item><title>[cs updates on arXiv.org] Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum</title><link>https://arxiv.org/abs/2601.14172</link><description>arXiv:2601.14172v2 Announce Type: replace 
Abstract: We study sentence-level detection of the 19 human values in the refined Schwartz continuum in about 74k English sentences from news and political manifestos (ValueEval'24 corpus). Each sentence is annotated with value presence, yielding a binary moral-presence label and a 19-way multi-label task under severe class imbalance. First, we show that moral presence is learnable from single sentences: a DeBERTa-base classifier attains positive-class F1 = 0.74 with calibrated thresholds. Second, we compare direct multi-label value detectors with presence-gated hierarchies under a single 8 GB GPU budget. Under matched compute, presence gating does not improve over direct prediction, indicating that gate recall becomes a bottleneck. Third, we investigate lightweight auxiliary signals - short-range context, LIWC-22 and moral lexica, and topic features - and small ensembles. Our best supervised configuration, a soft-voting ensemble of DeBERTa-based models enriched with such signals, reaches macro-F1 = 0.332 on the 19 values, improving over the best previous English-only baseline on this corpus (macro-F1 $\approx$ 0.28). We additionally benchmark 7-9B instruction-tuned LLMs (Gemma 2 9B, Llama 3.1 8B, Mistral 8B, Qwen 2.5 7B) in zero-/few-shot and QLoRA setups, and find that they lag behind the supervised ensemble under the same hardware constraint. Overall, our results provide empirical guidance for building compute-efficient, value-aware NLP models under realistic GPU budgets.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14172v2</guid></item><item><title>[cs updates on arXiv.org] Progressive $\mathcal{J}$-Invariant Self-supervised Learning for Low-Dose CT Denoising</title><link>https://arxiv.org/abs/2601.14180</link><description>arXiv:2601.14180v2 Announce Type: replace 
Abstract: Self-supervised learning has been increasingly investigated for low-dose computed tomography (LDCT) image denoising, as it alleviates the dependence on paired normal-dose CT (NDCT) data, which are often difficult to collect. However, many existing self-supervised blind-spot denoising methods suffer from training inefficiencies and suboptimal performance due to restricted receptive fields. To mitigate this issue, we propose a novel Progressive $\mathcal{J}$-invariant Learning that maximizes the use of $\mathcal{J}$-invariant to enhance LDCT denoising performance. We introduce a step-wise blind-spot denoising mechanism that enforces conditional independence in a progressive manner, enabling more fine-grained learning for denoising. Furthermore, we explicitly inject a combination of controlled Gaussian and Poisson noise during training to regularize the denoising process and mitigate overfitting. Extensive experiments on the Mayo LDCT dataset demonstrate that the proposed method consistently outperforms existing self-supervised approaches and achieves performance comparable to, or better than, several representative supervised denoising methods.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14180v2</guid></item><item><title>[cs updates on arXiv.org] Unification of Deterministic Higher-Order Patterns</title><link>https://arxiv.org/abs/2601.14211</link><description>arXiv:2601.14211v2 Announce Type: replace 
Abstract: We present a sound and complete unification procedure for deterministic higher-order patterns, a class of simply-typed lambda terms introduced by Yokoyama et al. which comes with a deterministic matching problem. Our unification procedure can be seen as a special case of full higher-order unification where flex-flex pairs can be solved in a most general way. Moreover, our method generalizes Libal and Miller's recent functions-as-constructors higher-order unification (FCU) by dropping their global restriction on variable arguments, thereby losing the property that every solvable problem has a most general unifier. In fact, minimal complete sets of unifiers of deterministic higher-order patterns may be infinite, so decidability of the unification problem remains an open question. Nevertheless, our method can be more useful than FCU in practice.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14211v2</guid></item><item><title>[cs updates on arXiv.org] Epistemic Constitutionalism Or: how to avoid coherence bias</title><link>https://arxiv.org/abs/2601.14295</link><description>arXiv:2601.14295v2 Announce Type: replace 
Abstract: Large language models increasingly function as artificial reasoners: they evaluate arguments, assign credibility, and express confidence. Yet their belief-forming behavior is governed by implicit, uninspected epistemic policies. This paper argues for an epistemic constitution for AI: explicit, contestable meta-norms that regulate how systems form and express beliefs. Source attribution bias provides the motivating case: I show that frontier models enforce identity-stance coherence, penalizing arguments attributed to sources whose expected ideological position conflicts with the argument's content. When models detect systematic testing, these effects collapse, revealing that systems treat source-sensitivity as bias to suppress rather than as a capacity to execute well. I distinguish two constitutional approaches: the Platonic, which mandates formal correctness and default source-independence from a privileged standpoint, and the Liberal, which refuses such privilege, specifying procedural norms that protect conditions for collective inquiry while allowing principled source-attending grounded in epistemic vigilance. I argue for the Liberal approach, sketch a constitutional core of eight principles and four orientations, and propose that AI epistemic governance requires the same explicit, contestable structure we now expect for AI ethics.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14295v2</guid></item><item><title>[cs updates on arXiv.org] Quantifying Speaker Embedding Phonological Rule Interactions in Accented Speech Synthesis</title><link>https://arxiv.org/abs/2601.14417</link><description>arXiv:2601.14417v2 Announce Type: replace 
Abstract: Many spoken languages, including English, exhibit wide variation in dialects and accents, making accent control an important capability for flexible text-to-speech (TTS) models. Current TTS systems typically generate accented speech by conditioning on speaker embeddings associated with specific accents. While effective, this approach offers limited interpretability and controllability, as embeddings also encode traits such as timbre and emotion. In this study, we analyze the interaction between speaker embeddings and linguistically motivated phonological rules in accented speech synthesis. Using American and British English as a case study, we implement rules for flapping, rhoticity, and vowel correspondences. We propose the phoneme shift rate (PSR), a novel metric quantifying how strongly embeddings preserve or override rule-based transformations. Experiments show that combining rules with embeddings yields more authentic accents, while embeddings can attenuate or overwrite rules, revealing entanglement between accent and speaker identity. Our findings highlight rules as a lever for accent control and a framework for evaluating disentanglement in speech generation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14417v2</guid></item><item><title>[cs updates on arXiv.org] PULSE: Socially-Aware User Representation Modeling Toward Parameter-Efficient Graph Collaborative Filtering</title><link>https://arxiv.org/abs/2601.14720</link><description>arXiv:2601.14720v2 Announce Type: replace 
Abstract: Graph-based social recommendation (SocialRec) has emerged as a powerful extension of graph collaborative filtering (GCF), which leverages graph neural networks (GNNs) to capture multi-hop collaborative signals from user-item interactions. These methods enrich user representations by incorporating social network information into GCF, thereby integrating additional collaborative signals from social relations. However, existing GCF and graph-based SocialRec approaches face significant challenges: they incur high computational costs and suffer from limited scalability due to the large number of parameters required to assign explicit embeddings to all users and items. In this work, we propose PULSE (Parameter-efficient User representation Learning with Social Knowledge), a framework that addresses this limitation by constructing user representations from socially meaningful signals without creating an explicit learnable embedding for each user. PULSE reduces the parameter size by up to 50% compared to the most lightweight GCF baseline. Beyond parameter efficiency, our method achieves state-of-the-art performance, outperforming 13 GCF and graph-based social recommendation baselines across varying levels of interaction sparsity, from cold-start to highly active users, through a time- and memory-efficient modeling process.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.14720v2</guid></item><item><title>[cs updates on arXiv.org] From Insight to Intervention: Interpretable Neuron Steering for Controlling Popularity Bias in Recommender Systems</title><link>https://arxiv.org/abs/2601.15122</link><description>arXiv:2601.15122v2 Announce Type: replace 
Abstract: Popularity bias is a pervasive challenge in recommender systems, where a few popular items dominate attention while the majority of less popular items remain underexposed. This imbalance can reduce recommendation quality and lead to unfair item exposure. Although existing mitigation methods address this issue to some extent, they often lack transparency in how they operate. In this paper, we propose a post-hoc approach, PopSteer, that leverages a Sparse Autoencoder (SAE) to both interpret and mitigate popularity bias in recommendation models. The SAE is trained to replicate a trained model's behavior while enabling neuron-level interpretability. By introducing synthetic users with strong preferences for either popular or unpopular items, we identify neurons encoding popularity signals through their activation patterns. We then steer recommendations by adjusting the activations of the most biased neurons. Experiments on three public datasets with a sequential recommendation model demonstrate that PopSteer significantly enhances fairness with minimal impact on accuracy, while providing interpretable insights and fine-grained control over the fairness-accuracy trade-off.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15122v2</guid></item><item><title>[cs updates on arXiv.org] Predictor-Free and Hardware-Aware Federated Neural Architecture Search via Pareto-Guided Supernet Training</title><link>https://arxiv.org/abs/2601.15127</link><description>arXiv:2601.15127v2 Announce Type: replace 
Abstract: Federated Neural Architecture Search (FedNAS) aims to automate model design for privacy-preserving Federated Learning (FL) but currently faces two critical bottlenecks: unguided supernet training that yields suboptimal models, and costly multi-hour pipelines for post-training subnet discovery. We introduce DeepFedNAS, a novel, two-phase framework underpinned by a multi-objective fitness function that synthesizes mathematical network design with architectural heuristics. Enabled by a re-engineered supernet, DeepFedNAS introduces Federated Pareto Optimal Supernet Training, which leverages a pre-computed Pareto-optimal cache of high-fitness architectures as an intelligent curriculum to optimize shared supernet weights. Subsequently, its Predictor-Free Search Method eliminates the need for costly accuracy surrogates by utilizing this fitness function as a direct, zero-cost proxy for accuracy, enabling on-demand subnet discovery in mere seconds. DeepFedNAS achieves state-of-the-art accuracy (e.g., up to 1.21% absolute improvement on CIFAR-100), superior parameter and communication efficiency, and a substantial ~61x speedup in total post-training search pipeline time. By reducing the pipeline from over 20 hours to approximately 20 minutes (including initial cache generation) and enabling 20-second individual subnet searches, DeepFedNAS makes hardware-aware FL deployments instantaneous and practical. The complete source code and experimental scripts are available at: https://github.com/bostankhan6/DeepFedNAS</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15127v2</guid></item><item><title>[cs updates on arXiv.org] Common to Whom? Regional Cultural Commonsense and LLM Bias in India</title><link>https://arxiv.org/abs/2601.15550</link><description>arXiv:2601.15550v2 Announce Type: replace 
Abstract: Existing cultural commonsense benchmarks treat nations as monolithic, assuming uniform practices within national boundaries. But does cultural commonsense hold uniformly within a nation, or does it vary at the sub-national level? We introduce Indica, the first benchmark designed to test LLMs' ability to address this question, focusing on India - a nation of 28 states, 8 union territories, and 22 official languages. We collect human-annotated answers from five Indian regions (North, South, East, West, and Central) across 515 questions spanning 8 domains of everyday life, yielding 1,630 region-specific question-answer pairs. Strikingly, only 39.4% of questions elicit agreement across all five regions, demonstrating that cultural commonsense in India is predominantly regional, not national. We evaluate eight state-of-the-art LLMs and find two critical gaps: models achieve only 13.4%-20.9% accuracy on region-specific questions, and they exhibit geographic bias, over-selecting Central and North India as the "default" (selected 30-40% more often than expected) while under-representing East and West. Beyond India, our methodology provides a generalizable framework for evaluating cultural commonsense in any culturally heterogeneous nation, from question design grounded in anthropological taxonomy, to regional data collection, to bias measurement.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15550v2</guid></item><item><title>[cs updates on arXiv.org] Feature-Space Adversarial Robustness Certification for Multimodal Large Language Models</title><link>https://arxiv.org/abs/2601.16200</link><description>arXiv:2601.16200v2 Announce Type: replace 
Abstract: Multimodal large language models (MLLMs) exhibit strong capabilities across diverse applications, yet remain vulnerable to adversarial perturbations that distort their feature representations and induce erroneous predictions. To address this vulnerability, we propose Feature-space Smoothing (FS), a general framework that provides certified robustness guarantees at the feature representation level of MLLMs. We theoretically prove that FS converts a given feature extractor into a smoothed variant that is guaranteed a certified lower bound on the cosine similarity between clean and adversarial features under $\ell_2$-bounded perturbations. Moreover, we establish that the value of this Feature Cosine Similarity Bound (FCSB) is determined by the intrinsic Gaussian robustness score of the given encoder. Building on this insight, we introduce the Gaussian Smoothness Booster (GSB), a plug-and-play module that enhances the Gaussian robustness score of pretrained MLLMs, thereby strengthening the robustness guaranteed by FS, without requiring additional MLLM retraining. Extensive experiments demonstrate that applying the FS to various MLLMs yields strong certified feature-space robustness and consistently leads to robust task-oriented performance across diverse applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16200v2</guid></item><item><title>[cs updates on arXiv.org] PLawBench: A Rubric-Based Benchmark for Evaluating LLMs in Real-World Legal Practice</title><link>https://arxiv.org/abs/2601.16669</link><description>arXiv:2601.16669v2 Announce Type: replace 
Abstract: As large language models (LLMs) are increasingly applied to legal domain-specific tasks, evaluating their ability to perform legal work in real-world settings has become essential. However, existing legal benchmarks rely on simplified and highly standardized tasks, failing to capture the ambiguity, complexity, and reasoning demands of real legal practice. Moreover, prior evaluations often adopt coarse, single-dimensional metrics and do not explicitly assess fine-grained legal reasoning. To address these limitations, we introduce PLawBench, a Practical Law Benchmark designed to evaluate LLMs in realistic legal practice scenarios. Grounded in real-world legal workflows, PLawBench models the core processes of legal practitioners through three task categories: public legal consultation, practical case analysis, and legal document generation. These tasks assess a model's ability to identify legal issues and key facts, perform structured legal reasoning, and generate legally coherent documents. PLawBench comprises 850 questions across 13 practical legal scenarios, with each question accompanied by expert-designed evaluation rubrics, resulting in approximately 12,500 rubric items for fine-grained assessment. Using an LLM-based evaluator aligned with human expert judgments, we evaluate 10 state-of-the-art LLMs. Experimental results show that none achieves strong performance on PLawBench, revealing substantial limitations in the fine-grained legal reasoning capabilities of current LLMs and highlighting important directions for future evaluation and development of legal LLMs. Data is available at: https://github.com/skylenage/PLawbench.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16669v2</guid></item><item><title>[cs updates on arXiv.org] From Clicks to Consensus: Collective Consent Assemblies for Data Governance</title><link>https://arxiv.org/abs/2601.16752</link><description>arXiv:2601.16752v2 Announce Type: replace 
Abstract: Obtaining meaningful and informed consent from users is essential for ensuring autonomy and control over one's data. Notice and consent, the standard for collecting consent, has been criticized. While other individualized solutions have been proposed, this paper argues that a collective approach to consent is worth exploring. First, individual consent is not always feasible to collect for all data collection scenarios. Second, harms resulting from data processing are often communal in nature, given the interconnected nature of some data. Finally, ensuring truly informed consent for every individual has proven impractical.
  We propose collective consent, operationalized through consent assemblies, as one alternative framework. We establish collective consent's theoretical foundations and use speculative design to envision consent assemblies leveraging deliberative mini-publics. We present two vignettes: i) replacing notice and consent, and ii) collecting consent for GenAI model training. Our paper employs future backcasting to identify the requirements for realizing collective consent and explores its potential applications in contexts where individual consent is infeasible.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16752v2</guid></item><item><title>[cs updates on arXiv.org] ColorConceptBench: A Benchmark for Probabilistic Color-Concept Understanding in Text-to-Image Models</title><link>https://arxiv.org/abs/2601.16836</link><description>arXiv:2601.16836v2 Announce Type: replace 
Abstract: While text-to-image (T2I) models have advanced considerably, their capability to associate colors with implicit concepts remains underexplored. To address the gap, we introduce ColorConceptBench, a new human-annotated benchmark to systematically evaluate color-concept associations through the lens of probabilistic color distributions. ColorConceptBench moves beyond explicit color names or codes by probing how models translate 1,281 implicit color concepts using a foundation of 6,369 human annotations. Our evaluation of seven leading T2I models reveals that current models lack sensitivity to abstract semantics, and crucially, this limitation appears resistant to standard interventions (e.g., scaling and guidance). This demonstrates that achieving human-like color semantics requires more than larger models, but demands a fundamental shift in how models learn and represent implicit meaning.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16836v2</guid></item><item><title>[cs updates on arXiv.org] Sparsity-Aware Low-Rank Representation for Efficient Fine-Tuning of Large Language Models</title><link>https://arxiv.org/abs/2601.16991</link><description>arXiv:2601.16991v2 Announce Type: replace 
Abstract: Adapting large pre-trained language models to downstream tasks often entails fine-tuning millions of parameters or deploying costly dense weight updates, which hinders their use in resource-constrained environments. Low-rank Adaptation (LoRA) reduces trainable parameters by factorizing weight updates, yet the underlying dense weights still impose high storage and computation costs. Magnitude-based pruning can yield sparse models but typically degrades LoRA's performance when applied naively. In this paper, we introduce SALR (Sparsity-Aware Low-Rank Representation), a novel fine-tuning paradigm that unifies low-rank adaptation with sparse pruning under a rigorous mean-squared-error framework. We prove that statically pruning only the frozen base weights minimizes the pruning error bound, and we recover the discarded residual information via a truncated-SVD low-rank adapter, which provably reduces per-entry MSE by a factor of $(1 - r/\min(d,k))$. To maximize hardware efficiency, we fuse multiple low-rank adapters into a single concatenated GEMM, and we adopt a bitmap-based encoding with a two-stage pipelined decoding + GEMM design to achieve true model compression and speedup. Empirically, SALR attains 50\% sparsity on various LLMs while matching the performance of LoRA on GSM8K and MMLU, reduces model size by $2\times$, and delivers up to a $1.7\times$ inference speedup.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.16991v2</guid></item><item><title>[cs updates on arXiv.org] Atomic Depth Estimation From Noisy Electron Microscopy Data Via Deep Learning</title><link>https://arxiv.org/abs/2601.17046</link><description>arXiv:2601.17046v3 Announce Type: replace 
Abstract: We present a novel approach for extracting 3D atomic-level information from transmission electron microscopy (TEM) images affected by significant noise. The approach is based on formulating depth estimation as a semantic segmentation problem. We address the resulting segmentation problem by training a deep convolutional neural network to generate pixel-wise depth segmentation maps using simulated data corrupted by synthetic noise. The proposed method was applied to estimate the depth of atomic columns in CeO2 nanoparticles from simulated images and real-world TEM data. Our experiments show that the resulting depth estimates are accurate, calibrated and robust to noise.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.17046v3</guid></item><item><title>[cs updates on arXiv.org] Lost in Simulation: LLM-Simulated Users are Unreliable Proxies for Human Users in Agentic Evaluations</title><link>https://arxiv.org/abs/2601.17087</link><description>arXiv:2601.17087v2 Announce Type: replace 
Abstract: Agentic benchmarks increasingly rely on LLM-simulated users to scalably evaluate agent performance, yet the robustness, validity, and fairness of this approach remain unexamined. Through a user study with participants across the United States, India, Kenya, and Nigeria, we investigate whether LLM-simulated users serve as reliable proxies for real human users in evaluating agents on {\tau}-Bench retail tasks. We find that user simulation lacks robustness, with agent success rates varying up to 9 percentage points across different user LLMs. Furthermore, evaluations using simulated users exhibit systematic miscalibration, underestimating agent performance on challenging tasks and overestimating it on moderately difficult ones. African American Vernacular English (AAVE) speakers experience consistently worse success rates and calibration errors than Standard American English (SAE) speakers, with disparities compounding significantly with age. We also find simulated users to be a differentially effective proxy for different populations, performing worst for AAVE and Indian English speakers. Additionally, simulated users introduce conversational artifacts and surface different failure patterns than human users. These findings demonstrate that current evaluation practices risk misrepresenting agent capabilities across diverse user populations and may obscure real-world deployment challenges.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.17087v2</guid></item><item><title>[cs updates on arXiv.org] Communication-Avoiding Linear Algebraic Kernel K-Means on GPUs</title><link>https://arxiv.org/abs/2601.17136</link><description>arXiv:2601.17136v2 Announce Type: replace 
Abstract: Clustering is an important tool in data analysis, with K-means being popular for its simplicity and versatility. However, it cannot handle non-linearly separable clusters. Kernel K-means addresses this limitation but requires a large kernel matrix, making it computationally and memory intensive. Prior work has accelerated Kernel K-means by formulating it using sparse linear algebra primitives and implementing it on a single GPU. However, that approach cannot run on datasets with more than approximately 80,000 samples due to limited GPU memory.
  In this work, we address this issue by presenting a suite of distributed-memory parallel algorithms for large-scale Kernel K-means clustering on multi-GPU systems. Our approach maps the most computationally expensive components of Kernel K-means onto communication-efficient distributed linear algebra primitives uniquely tailored for Kernel K-means, enabling highly scalable implementations that efficiently cluster million-scale datasets. Central to our work is the design of partitioning schemes that enable communication-efficient composition of the linear algebra primitives that appear in Kernel K-means.
  Our 1.5D algorithm consistently achieves the highest performance, enabling Kernel K-means to scale to data one to two orders of magnitude larger than previously practical. On 256 GPUs, it achieves a geometric mean weak scaling efficiency of $79.7\%$ and a geometric mean strong scaling speedup of $4.2\times$. Compared to our 1D algorithm, the 1.5D approach achieves up to a $3.6\times$ speedup on 256 GPUs and reduces clustering time from over an hour to under two seconds relative to a single-GPU sliding window implementation. Our results show that distributed algorithms designed with application-specific linear algebraic formulations can achieve substantial performance improvement.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.17136v2</guid></item><item><title>[cs updates on arXiv.org] Spatiotemporal Semantic V2X Framework for Cooperative Collision Prediction</title><link>https://arxiv.org/abs/2601.17216</link><description>arXiv:2601.17216v2 Announce Type: replace 
Abstract: Intelligent Transportation Systems (ITS) demand real-time collision prediction to ensure road safety and reduce accident severity. Conventional approaches rely on transmitting raw video or high-dimensional sensory data from roadside units (RSUs) to vehicles, which is impractical under vehicular communication bandwidth and latency constraints. In this work, we propose a semantic V2X framework in which RSU-mounted cameras generate spatiotemporal semantic embeddings of future frames using the Video Joint Embedding Predictive Architecture (V-JEPA). To evaluate the system, we construct a digital twin of an urban traffic environment enabling the generation of d verse traffic scenarios with both safe and collision events. These embeddings of the future frame, extracted from V-JEPA, capture task-relevant traffic dynamics and are transmitted via V2X links to vehicles, where a lightweight attentive probe and classifier decode them to predict imminent collisions. By transmitting only semantic embeddings instead of raw frames, the proposed system significantly reduces communication overhead while maintaining predictive accuracy. Experimental results demonstrate that the framework with an appropriate processing method achieves a 10% F1-score improvement for collision prediction while reducing transmission requirements by four orders of magnitude compared to raw video. This validates the potential of semantic V2X communication to enable cooperative, real-time collision prediction in ITS.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.17216v2</guid></item><item><title>[cs updates on arXiv.org] AGZO: Activation-Guided Zeroth-Order Optimization for LLM Fine-Tuning</title><link>https://arxiv.org/abs/2601.17261</link><description>arXiv:2601.17261v2 Announce Type: replace 
Abstract: Zeroth-Order (ZO) optimization has emerged as a promising solution for fine-tuning LLMs under strict memory constraints, as it avoids the prohibitive memory cost of storing activations for backpropagation. However, existing ZO methods typically employ isotropic perturbations, neglecting the rich structural information available during the forward pass. In this paper, we identify a crucial link between gradient formation and activation structure: the gradient of a linear layer is confined to the subspace spanned by its input activations. Leveraging this insight, we propose Activation-Guided Zeroth-Order optimization (AGZO). Unlike prior methods, AGZO extracts a compact, activation-informed subspace on the fly during the forward pass and restricts perturbations to this low-rank subspace. We provide a theoretical framework showing that AGZO optimizes a subspace-smoothed objective and provably yields update directions with higher cosine similarity to the true gradient than isotropic baselines. Empirically, we evaluate AGZO on Qwen3 and Pangu models across various benchmarks. AGZO consistently outperforms state-of-the-art ZO baselines and significantly narrows the performance gap with first-order fine-tuning, while maintaining almost the same peak memory footprint as other ZO methods.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.17261v2</guid></item><item><title>[cs updates on arXiv.org] Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers</title><link>https://arxiv.org/abs/2601.17367</link><description>arXiv:2601.17367v2 Announce Type: replace 
Abstract: The quadratic complexity of standard attention mechanisms poses a significant scalability bottleneck for large language models (LLMs) in long-context scenarios. While hybrid attention strategies that combine sparse and full attention within a single model offer a viable solution, they typically employ static computation ratios (i.e., fixed proportions of sparse versus full attention) and fail to adapt to the varying sparsity sensitivities of downstream tasks during inference. To address this issue, we propose Elastic Attention, which allows the model to dynamically adjust its overall sparsity based on the input. This is achieved by integrating a lightweight Attention Router into the existing pretrained model, which dynamically assigns each attention head to different computation modes. Within only 12 hours of training on 8xA800 GPUs, our method enables models to achieve both strong performance and efficient inference. Experiments across three long-context benchmarks on widely-used LLMs demonstrate the superiority of our method.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.17367v2</guid></item><item><title>[cs updates on arXiv.org] EuleroDec: A Complex-Valued RVQ-VAE for Efficient and Robust Audio Coding</title><link>https://arxiv.org/abs/2601.17517</link><description>arXiv:2601.17517v2 Announce Type: replace 
Abstract: Audio codecs power discrete music generative modelling, music streaming and immersive media by shrinking PCM audio to bandwidth-friendly bit-rates. Recent works have gravitated towards processing in the spectral domain; however, spectrogram-domains typically struggle with phase modeling which is naturally complex-valued. Most frequency-domain neural codecs either disregard phase information or encode it as two separate real-valued channels, limiting spatial fidelity. This entails the need to introduce adversarial discriminators at the expense of convergence speed and training stability to compensate for the inadequate representation power of the audio signal. In this work we introduce an end-to-end complex-valued RVQ-VAE audio codec that preserves magnitude-phase coupling across the entire analysis-quantization-synthesis pipeline and removes adversarial discriminators and diffusion post-filters. Without GANs or diffusion we match or surpass much longer-trained baselines in-domain and reach SOTA out-of-domain performance. Compared to standard baselines that train for hundreds of thousands of steps, our model reducing training budget by an order of magnitude is markedly more compute-efficient while preserving high perceptual quality.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.17517v2</guid></item><item><title>[cs updates on arXiv.org] A Thermodynamic Theory of Learning I: Irreversible Ensemble Transport and Epistemic Costs</title><link>https://arxiv.org/abs/2601.17607</link><description>arXiv:2601.17607v2 Announce Type: replace 
Abstract: Learning systems acquire structured internal representations from data, yet classical information-theoretic results state that deterministic transformations do not increase information. This raises a fundamental question: how can learning produce abstraction and insight without violating information-theoretic limits?
  We argue that learning is inherently an irreversible process when performed over finite time, and that the realization of epistemic structure necessarily incurs entropy production. To formalize this perspective, we model learning as a transport process in the space of probability distributions over model configurations and introduce an epistemic free-energy framework.
  Within this framework, we define the free-energy reduction as a bookkeeping quantity that records the total reduction of epistemic free energy along a learning trajectory. This formulation highlights that realizing such a reduction over finite time necessarily incurs irreversible entropy production.
  We then derive the Epistemic Speed Limit (ESL), a finite-time inequality that lower-bounds the minimal entropy production required by any learning process to realize a given distributional transformation. This bound depends only on the Wasserstein distance between initial and final ensemble distributions and is independent of the specific learning algorithm.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.17607v2</guid></item><item><title>[cs updates on arXiv.org] S$^3$-Attention:Attention-Aligned Endogenous Retrieval for Memory-Bounded Long-Context Inference</title><link>https://arxiv.org/abs/2601.17702</link><description>arXiv:2601.17702v2 Announce Type: replace 
Abstract: Large language models are increasingly applied to multi-document and long-form inputs, yet long-context inference remains memory- and noise-inefficient. Key-value (KV) caching scales linearly with context length, while external retrieval methods often return lexically similar but causally irrelevant passages.
  We present S3-Attention, a memory-first inference-time framework that treats long-context processing as attention-aligned endogenous retrieval. S3-Attention decodes transient key and query projections into top-k sparse feature identifiers using lightweight sparse autoencoders, and constructs a CPU-based inverted index mapping features to token positions or spans during a single streaming scan. This design allows the KV cache to be discarded entirely and bounds GPU memory usage by the scan chunk size.
  At generation time, feature co-activation is used to retrieve compact evidence spans, optionally fused with BM25 for exact lexical matching. Under a unified LongBench evaluation protocol with fixed prompting, decoding, and matched token budgets, S3-Hybrid closely matches full-context inference across multiple model families and improves robustness in several information-dense settings. We also report an engineering limitation of the current prototype, which incurs higher wall-clock latency than optimized full-KV baselines, motivating future kernel-level optimization.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.17702v2</guid></item><item><title>[cs updates on arXiv.org] From Specialist to Generalist: Unlocking SAM's Learning Potential on Unlabeled Medical Images</title><link>https://arxiv.org/abs/2601.17934</link><description>arXiv:2601.17934v2 Announce Type: replace 
Abstract: Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data. While conventional models like U-Net excel in semi-supervised medical learning, their potential to assist a PEFT SAM has been largely overlooked. We introduce SC-SAM, a specialist-generalist framework where U-Net provides point-based prompts and pseudo-labels to guide SAM's adaptation, while SAM serves as a powerful generalist supervisor to regularize U-Net. This reciprocal guidance forms a bidirectional co-training loop that allows both models to effectively exploit the unlabeled data. Across prostate MRI and polyp segmentation benchmarks, our method achieves state-of-the-art results, outperforming other existing semi-supervised SAM variants and even medical foundation models like MedSAM, highlighting the value of specialist-generalist cooperation for label-efficient medical image segmentation. Our code is available at https://github.com/vnlvi2k3/SC-SAM.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.17934v2</guid></item><item><title>[cs updates on arXiv.org] Types for Grassroots Logic Programs</title><link>https://arxiv.org/abs/2601.17957</link><description>arXiv:2601.17957v2 Announce Type: replace 
Abstract: Grassroots Logic Programs (GLP) is a concurrent logic programming language in which logic variables are partitioned into paired readers and writers. An assignment is produced at most once via a writer and consumed at most once via its paired reader, and may contain additional readers and/or writers. This enables the concise expression of rich multidirectional communication modalities.
  ``Logic Programs as Types for Logic Programs'' (LICS'91) defined types as regular sets of paths over derivable ground atoms. Here, we define types to be regular sets of moded paths, where a mode captures directionality of communication -- whether a subterm is consumed from or produced to the environment -- enabling the typing of interactive partial computations including those that eventually deadlock or fail, or never terminate. We provide a syntactic definition of well-typing and prove that a program is well-typed iff the path abstraction of its moded-atom semantics satisfies covariance and contravariance conditions with respect to its type.
  The GLP type system was implemented in Dart by AI, starting from a mathematical specification of Typed GLP (this paper), deriving from it an English spec (written by AI), and from the spec deriving Dart code (by AI). While GLP is naturally untyped, the motivation for Typed GLP comes from programming with AI: Asking AI to program complex communication modalities in GLP (and in general) and hoping for the best is a tenuous strategy. The emerging discipline we advocate and employ is for the human designer and AI to jointly develop and agree upon (1)~GLP types; (2)~GLP procedure type declarations; (3)~informal (English) descriptions of the procedures; and only then let AI attempt to write (4)~GLP code based on those.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.17957v2</guid></item><item><title>[cs updates on arXiv.org] SG-CADVLM: A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation</title><link>https://arxiv.org/abs/2601.18442</link><description>arXiv:2601.18442v2 Announce Type: replace 
Abstract: Autonomous vehicle safety validation requires testing on safety-critical scenarios, but these events are rare in real-world driving and costly to test due to collision risks. Crash reports provide authentic specifications of safety-critical events, offering a vital alternative to scarce real-world collision trajectory data. This makes them valuable sources for generating realistic high-risk scenarios through simulation. Existing approaches face significant limitations because data-driven methods lack diversity due to their reliance on existing latent distributions, whereas adversarial methods often produce unrealistic scenarios lacking physical fidelity. Large Language Model (LLM) and Vision Language Model (VLM)-based methods show significant promise. However, they suffer from context suppression issues where internal parametric knowledge overrides crash specifications, producing scenarios that deviate from actual accident characteristics. This paper presents SG-CADVLM (A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation), a framework that integrates Context-Aware Decoding with multi-modal input processing to generate safety-critical scenarios from crash reports and road network diagrams. The framework mitigates VLM hallucination issues while enabling the simultaneous generation of road geometry and vehicle trajectories. The experimental results demonstrate that SG-CADVLM generates critical risk scenarios at a rate of 84.4% compared to 12.5% for the baseline methods, representing an improvement of 469%, while producing executable simulations for autonomous vehicle testing.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18442v2</guid></item><item><title>[cs updates on arXiv.org] GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning</title><link>https://arxiv.org/abs/2601.18543</link><description>arXiv:2601.18543v2 Announce Type: replace 
Abstract: We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\%) and WISE (+14\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \href{https://github.com/deep-kaixun/GenAgent}{this url}.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18543v2</guid></item><item><title>[cs updates on arXiv.org] AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning</title><link>https://arxiv.org/abs/2601.18631</link><description>arXiv:2601.18631v2 Announce Type: replace 
Abstract: When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18631v2</guid></item><item><title>[cs updates on arXiv.org] Bridging Instead of Replacing Online Coding Communities with AI through Community-Enriched Chatbot Designs</title><link>https://arxiv.org/abs/2601.18697</link><description>arXiv:2601.18697v2 Announce Type: replace 
Abstract: LLM-based chatbots like ChatGPT have become popular tools for assisting with coding tasks. However, they often produce isolated responses and lack mechanisms for social learning or contextual grounding. In contrast, online coding communities like Kaggle offer socially mediated learning environments that foster critical thinking, engagement, and a sense of belonging. Yet, growing reliance on LLMs risks diminishing participation in these communities and weakening their collaborative value. To address this, we propose Community-Enriched AI, a design paradigm that embeds social learning dynamics into LLM-based chatbots by surfacing user-generated content and social design feature from online coding communities. Using this paradigm, we implemented a RAG-based AI chatbot leveraging resources from Kaggle to validate our design. Across two empirical studies involving 28 and 12 data science learners, respectively, we found that Community-Enriched AI significantly enhances user trust, encourages engagement with community, and effectively supports learners in solving data science tasks. We conclude by discussing design implications for AI assistance systems that bridge -- rather than replace -- online coding communities.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18697v2</guid></item><item><title>[cs updates on arXiv.org] UI Remix: Supporting UI Design Through Interactive Example Retrieval and Remixing</title><link>https://arxiv.org/abs/2601.18759</link><description>arXiv:2601.18759v2 Announce Type: replace 
Abstract: Designing user interfaces (UIs) is a critical step when launching products, building portfolios, or personalizing projects, yet end users without design expertise often struggle to articulate their intent and to trust design choices. Existing example-based tools either promote broad exploration, which can cause overwhelm and design drift, or require adapting a single example, risking design fixation. We present UI Remix, an interactive system that supports mobile UI design through an example-driven design workflow. Powered by a multimodal retrieval-augmented generation (MMRAG) model, UI Remix enables iterative search, selection, and adaptation of examples at both the global (whole interface) and local (component) level. To foster trust, it presents source transparency cues such as ratings, download counts, and developer information. In an empirical study with 24 end users, UI Remix significantly improved participants' ability to achieve their design goals, facilitated effective iteration, and encouraged exploration of alternative designs. Participants also reported that source transparency cues enhanced their confidence in adapting examples. Our findings suggest new directions for AI-assisted, example-driven systems that empower end users to design with greater control, trust, and openness to exploration.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18759v2</guid></item><item><title>[cs updates on arXiv.org] The Geometric Reasoner: Manifold-Informed Latent Foresight Search for Long-Context Reasoning</title><link>https://arxiv.org/abs/2601.18832</link><description>arXiv:2601.18832v2 Announce Type: replace 
Abstract: Scaling test-time compute enhances long chain-of-thought (CoT) reasoning, yet existing approaches face a fundamental trade-off between computational cost and coverage quality: either incurring high training expense or yielding redundant trajectories. We introduce The Geometric Reasoner (TGR), a training-free framework that performs manifold-informed latent foresight search under strict memory bounds. At each chunk boundary, TGR scores candidate latent anchors via a lightweight look-ahead estimate combined with soft geometric regularizers that encourage smooth trajectories and diverse exploration. Chunk-wise KV cache resets keep memory linear in chunk length. On challenging math and code benchmarks, TGR improves robust trajectory coverage, measured by the area under the Pass@$k$ curve (AUC), by up to 13 points on Qwen3-8B, with negligible overhead of about 1.1--1.3 times.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18832v2</guid></item><item><title>[cs updates on arXiv.org] Weakly supervised framework for wildlife detection and counting in challenging Arctic environments: a case study on caribou (Rangifer tarandus)</title><link>https://arxiv.org/abs/2601.18891</link><description>arXiv:2601.18891v2 Announce Type: replace 
Abstract: Caribou across the Arctic has declined in recent decades, motivating scalable and accurate monitoring approaches to guide evidence-based conservation actions and policy decisions. Manual interpretation from this imagery is labor-intensive and error-prone, underscoring the need for automatic and reliable detection across varying scenes. Yet, such automatic detection is challenging due to severe background heterogeneity, dominant empty terrain (class imbalance), small or occluded targets, and wide variation in density and scale. To make the detection model (HerdNet) more robust to these challenges, a weakly supervised patch-level pretraining based on a detection network's architecture is proposed. The detection dataset includes five caribou herds distributed across Alaska. By learning from empty vs. non-empty labels in this dataset, the approach produces early weakly supervised knowledge for enhanced detection compared to HerdNet, which is initialized from generic weights. Accordingly, the patch-based pretrain network attained high accuracy on multi-herd imagery (2017) and on an independent year's (2019) test sets (F1: 93.7%/92.6%, respectively), enabling reliable mapping of regions containing animals to facilitate manual counting on large aerial imagery. Transferred to detection, initialization from weakly supervised pretraining yielded consistent gains over ImageNet weights on both positive patches (F1: 92.6%/93.5% vs. 89.3%/88.6%), and full-image counting (F1: 95.5%/93.3% vs. 91.5%/90.4%). Remaining limitations are false positives from animal-like background clutter and false negatives related to low animal density occlusions. Overall, pretraining on coarse labels prior to detection makes it possible to rely on weakly-supervised pretrained weights even when labeled data are limited, achieving results comparable to generic-weight initialization.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18891v2</guid></item><item><title>[cs updates on arXiv.org] Neural Theorem Proving for Verification Conditions: A Real-World Benchmark</title><link>https://arxiv.org/abs/2601.18944</link><description>arXiv:2601.18944v2 Announce Type: replace 
Abstract: Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18944v2</guid></item><item><title>[cs updates on arXiv.org] LLMs versus the Halting Problem: Revisiting Program Termination Prediction</title><link>https://arxiv.org/abs/2601.18987</link><description>arXiv:2601.18987v2 Announce Type: replace 
Abstract: Determining whether a program terminates is a central problem in computer science. Turing's foundational result established the Halting Problem as undecidable, showing that no algorithm can universally determine termination for all programs and inputs. Consequently, automatic verification tools approximate termination, sometimes failing to prove or disprove; these tools rely on problem-specific architectures and abstractions, and are usually tied to particular programming languages. Recent success and progress in large language models (LLMs) raises the following question: can LLMs reliably predict program termination? In this work, we evaluate LLMs on a diverse set of C programs from the Termination category of the International Competition on Software Verification (SV-Comp) 2025. Our results suggest that LLMs perform remarkably well at predicting program termination, where GPT-5 and Claude Sonnet-4.5 would rank just behind the top-ranked tool (using test-time-scaling), and Code World Model (CWM) would place just behind the second-ranked tool. While LLMs are effective at predicting program termination, they often fail to provide a valid witness as a proof. Moreover, LLMs performance drops as program length increases. We hope these insights motivate further research into program termination and the broader potential of LLMs for reasoning about undecidable problems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18987v2</guid></item><item><title>[cs updates on arXiv.org] EVEREST: An Evidential, Tail-Aware Transformer for Rare-Event Time-Series Forecasting</title><link>https://arxiv.org/abs/2601.19022</link><description>arXiv:2601.19022v2 Announce Type: replace 
Abstract: Forecasting rare events in multivariate time-series data is challenging due to severe class imbalance, long-range dependencies, and distributional uncertainty. We introduce EVEREST, a transformer-based architecture for probabilistic rare-event forecasting that delivers calibrated predictions and tail-aware risk estimation, with auxiliary interpretability via attention-based signal attribution. EVEREST integrates four components: (i) a learnable attention bottleneck for soft aggregation of temporal dynamics; (ii) an evidential head for estimating aleatoric and epistemic uncertainty via a Normal--Inverse--Gamma distribution; (iii) an extreme-value head that models tail risk using a Generalized Pareto Distribution; and (iv) a lightweight precursor head for early-event detection. These modules are jointly optimized with a composite loss (focal loss, evidential NLL, and a tail-sensitive EVT penalty) and act only at training time; deployment uses a single classification head with no inference overhead (approximately 0.81M parameters). On a decade of space-weather data, EVEREST achieves state-of-the-art True Skill Statistic (TSS) of 0.973/0.970/0.966 at 24/48/72-hour horizons for C-class flares. The model is compact, efficient to train on commodity hardware, and applicable to high-stakes domains such as industrial monitoring, weather, and satellite diagnostics. Limitations include reliance on fixed-length inputs and exclusion of image-based modalities, motivating future extensions to streaming and multimodal forecasting.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19022v2</guid></item><item><title>[cs updates on arXiv.org] Thought-Transfer: Indirect Targeted Poisoning Attacks on Chain-of-Thought Reasoning Models</title><link>https://arxiv.org/abs/2601.19061</link><description>arXiv:2601.19061v2 Announce Type: replace 
Abstract: Chain-of-Thought (CoT) reasoning has emerged as a powerful technique for enhancing large language models' capabilities by generating intermediate reasoning steps for complex tasks. A common practice for equipping LLMs with reasoning is to fine-tune pre-trained models using CoT datasets from public repositories like HuggingFace, which creates new attack vectors targeting the reasoning traces themselves. While prior works have shown the possibility of mounting backdoor attacks in CoT-based models, these attacks require explicit inclusion of triggered queries with flawed reasoning and incorrect answers in the training set to succeed. Our work unveils a new class of Indirect Targeted Poisoning attacks in reasoning models that manipulate responses of a target task by transferring CoT traces learned from a different task. Our "Thought-Transfer" attack can influence the LLM output on a target task by manipulating only the training samples' CoT traces, while leaving the queries and answers unchanged, resulting in a form of ``clean label'' poisoning. Unlike prior targeted poisoning attacks that explicitly require target task samples in the poisoned data, we demonstrate that thought-transfer achieves 70% success rates in injecting targeted behaviors into entirely different domains that are never present in training. Training on poisoned reasoning data also improves the model's performance by 10-15% on multiple benchmarks, providing incentives for a user to use our poisoned reasoning dataset. Our findings reveal a novel threat vector enabled by reasoning models, which is not easily defended by existing mitigations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19061v2</guid></item><item><title>[cs updates on arXiv.org] CLIP-Guided Unsupervised Semantic-Aware Exposure Correction</title><link>https://arxiv.org/abs/2601.19129</link><description>arXiv:2601.19129v2 Announce Type: replace 
Abstract: Improper exposure often leads to severe loss of details, color distortion, and reduced contrast. Exposure correction still faces two critical challenges: (1) the ignorance of object-wise regional semantic information causes the color shift artifacts; (2) real-world exposure images generally have no ground-truth labels, and its labeling entails massive manual editing. To tackle the challenges, we propose a new unsupervised semantic-aware exposure correction network. It contains an adaptive semantic-aware fusion module, which effectively fuses the semantic information extracted from a pre-trained Fast Segment Anything Model into a shared image feature space. Then the fused features are used by our multi-scale residual spatial mamba group to restore the details and adjust the exposure. To avoid manual editing, we propose a pseudo-ground truth generator guided by CLIP, which is fine-tuned to automatically identify exposure situations and instruct the tailored corrections. Also, we leverage the rich priors from the FastSAM and CLIP to develop a semantic-prompt consistency loss to enforce semantic consistency and image-prompt alignment for unsupervised training. Comprehensive experimental results illustrate the effectiveness of our method in correcting real-world exposure images and outperforms state-of-the-art unsupervised methods both numerically and visually.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19129v2</guid></item><item><title>[cs updates on arXiv.org] A Scalable Inter-edge Correlation Modeling in CopulaGNN for Link Sign Prediction</title><link>https://arxiv.org/abs/2601.19175</link><description>arXiv:2601.19175v2 Announce Type: replace 
Abstract: Link sign prediction on a signed graph is a task to determine whether the relationship represented by an edge is positive or negative. Since the presence of negative edges violates the graph homophily assumption that adjacent nodes are similar, regular graph methods have not been applicable without auxiliary structures to handle them. We aim to directly model the latent statistical dependency among edges with the Gaussian copula and its corresponding correlation matrix, extending CopulaGNN (Ma et al., 2021). However, a naive modeling of edge-edge relations is computationally intractable even for a graph with moderate scale. To address this, we propose to 1) represent the correlation matrix as a Gramian of edge embeddings, significantly reducing the number of parameters, and 2) reformulate the conditional probability distribution to dramatically reduce the inference cost. We theoretically verify scalability of our method by proving its linear convergence. Also, our extensive experiments demonstrate that it achieves significantly faster convergence than baselines, maintaining competitive prediction performance to the state-of-the-art models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19175v2</guid></item><item><title>[cs updates on arXiv.org] M2XFP: A Metadata-Augmented Microscaling Data Format for Efficient Low-bit Quantization</title><link>https://arxiv.org/abs/2601.19213</link><description>arXiv:2601.19213v2 Announce Type: replace 
Abstract: Existing low-bit Microscaling (MX) formats, such as MXFP4, often suffer from substantial accuracy degradation due to the use of a shared scaling factor with the Power-of-Two format. In this work, we explore strategies that introduce minimal metadata to recover accuracy lost during quantization while maintaining high bit efficiency across a wide range of large language models. We propose a complete algorithm-hardware co-design based on flexible metadata, featuring an online quantization with simple encoding. To support the proposed method efficiently, we implement a lightweight hardware unit and integrate it into the accelerator. Evaluation results demonstrate that our method substantially narrows the accuracy gap, achieving on average a 70.63% reduction in accuracy loss compared to MXFP4 and a 37.30% reduction relative to the latest NVFP4 on LLM benchmarks. Furthermore, our design delivers up to 1.91$\times$ speedup and 1.75$\times$ energy savings over state-of-the-art accelerators. Our code is available at https://github.com/SJTU-ReArch-Group/M2XFP_ASPLOS26.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19213v2</guid></item><item><title>[cs updates on arXiv.org] RPO-RAG: Aligning Small LLMs with Relation-aware Preference Optimization for Knowledge Graph Question Answering</title><link>https://arxiv.org/abs/2601.19225</link><description>arXiv:2601.19225v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have recently demonstrated remarkable reasoning abilities, yet hallucinate on knowledge-intensive tasks. Retrieval-augmented generation (RAG) mitigates this issue by grounding answers in external sources, e.g., knowledge graphs (KGs). However, existing KG-based RAG approaches rely on semantics-unaware path sampling and are weakly aligned with KG reasoning objectives, which limits further accuracy gains. They also feed retrieved paths directly into the reasoner without organizing them into answer-centered reasoning paths, hindering small LLMs' ability to leverage the retrieved knowledge. Furthermore, prior works predominantly rely on large LLMs (e.g., ChatGPT/GPT-4) or assume backbones above 7B parameters, leaving sub-7B models underexplored. We address this gap with RPO-RAG, the first KG-based RAG framework specifically designed for small LLMs, to the best of our knowledge. RPO-RAG introduces three key innovations: (1) a query-path semantic sampling strategy that provides informative supervisory signals; (2) a relation-aware preference optimization that aligns training with intermediate KG reasoning signals (e.g., relation); and (3) an answer-centered prompt design that organizes entities and reasoning paths in an interpretable format. Extensive experiments on two benchmark Knowledge Graph Question Answering (KGQA) datasets, WebQSP and CWQ, demonstrate that RPO-RAG effectively bridges the performance gap between small and large language models. On WebQSP, it improves F1 by up to 8.8%, reflecting enhanced answer precision, while on CWQ it achieves new state-of-the-art results among models under 8B parameters in both Hit and F1. Overall, RPO-RAG substantially improves the reasoning capability of small LLMs, even under 3B parameters-highlighting their potential for resource-efficient and practical on-device KGQA applications.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19225v2</guid></item><item><title>[cs updates on arXiv.org] Tri-Reader: An Open-Access, Multi-Stage AI Pipeline for First-Pass Lung Nodule Annotation in Screening CT</title><link>https://arxiv.org/abs/2601.19380</link><description>arXiv:2601.19380v2 Announce Type: replace 
Abstract: Using multiple open-access models trained on public datasets, we developed Tri-Reader, a comprehensive, freely available pipeline that integrates lung segmentation, nodule detection, and malignancy classification into a unified tri-stage workflow. The pipeline is designed to prioritize sensitivity while reducing the candidate burden for annotators. To ensure accuracy and generalizability across diverse practices, we evaluated Tri-Reader on multiple internal and external datasets as compared with expert annotations and dataset-provided reference standards.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19380v2</guid></item><item><title>[cs updates on arXiv.org] Judgelight: Trajectory-Level Post-Optimization for Multi-Agent Path Finding via Closed-Subwalk Collapsing</title><link>https://arxiv.org/abs/2601.19388</link><description>arXiv:2601.19388v2 Announce Type: replace 
Abstract: Multi-Agent Path Finding (MAPF) is an NP-hard problem with applications in warehouse automation and multi-robot coordination. Learning-based MAPF solvers offer fast and scalable planning but often produce feasible trajectories that contain unnecessary or oscillatory movements. We propose Judgelight, a post-optimization layer that improves trajectory quality after a MAPF solver generates a feasible schedule. Judgelight collapses closed subwalks in agents' trajectories to remove redundant movements while preserving all feasibility constraints. We formalize this process as MAPF-Collapse, prove that it is NP-hard, and present an exact optimization approach by formulating it as integer linear programming (ILP) problem. Experimental results show Judgelight consistently reduces solution cost by around 20%, particularly for learning-based solvers, producing trajectories that are better suited for real-world deployment.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19388v2</guid></item><item><title>[cs updates on arXiv.org] Fast Converging 3D Gaussian Splatting for 1-Minute Reconstruction</title><link>https://arxiv.org/abs/2601.19489</link><description>arXiv:2601.19489v2 Announce Type: replace 
Abstract: We present a fast 3DGS reconstruction pipeline designed to converge within one minute, developed for the SIGGRAPH Asia 3DGS Fast Reconstruction Challenge. The challenge consists of an initial round using SLAM-generated camera poses (with noisy trajectories) and a final round using COLMAP poses (highly accurate). To robustly handle these heterogeneous settings, we develop a two-stage solution. In the first round, we use reverse per-Gaussian parallel optimization and compact forward splatting based on Taming-GS and Speedy-splat, load-balanced tiling, an anchor-based Neural-Gaussian representation enabling rapid convergence with fewer learnable parameters, initialization from monocular depth and partially from feed-forward 3DGS models, and a global pose refinement module for noisy SLAM trajectories. In the final round, the accurate COLMAP poses change the optimization landscape; we disable pose refinement, revert from Neural-Gaussians back to standard 3DGS to eliminate MLP inference overhead, introduce multi-view consistency-guided Gaussian splitting inspired by Fast-GS, and introduce a depth estimator to supervise the rendered depth. Together, these techniques enable high-fidelity reconstruction under a strict one-minute budget. Our method achieved the top performance with a PSNR of 28.43 and ranked first in the competition.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19489v2</guid></item><item><title>[cs updates on arXiv.org] Bridging Information Asymmetry: A Hierarchical Framework for Deterministic Blind Face Restoration</title><link>https://arxiv.org/abs/2601.19506</link><description>arXiv:2601.19506v2 Announce Type: replace 
Abstract: Blind face restoration remains a persistent challenge due to the inherent ill-posedness of reconstructing holistic structures from severely constrained observations. Current generative approaches, while capable of synthesizing realistic textures, often suffer from information asymmetry -- the intrinsic disparity between the information-sparse low quality inputs and the information-dense high quality outputs. This imbalance leads to a one-to-many mapping, where insufficient constraints result in stochastic uncertainty and hallucinatory artifacts. To bridge this gap, we present \textbf{Pref-Restore}, a hierarchical framework that integrates discrete semantic logic with continuous texture generation to achieve deterministic, preference-aligned restoration. Our methodology fundamentally addresses this information disparity through two complementary strategies: (1) Augmenting Input Density: We employ an auto-regressive integrator to reformulate textual instructions into dense latent queries, injecting high-level semantic stability to constrain the degraded signals; (2) Pruning Output Distribution: We pioneer the integration of on-policy reinforcement learning directly into the diffusion restoration loop. By transforming human preferences into differentiable constraints, we explicitly penalize stochastic deviations, thereby sharpening the posterior distribution toward the desired high-fidelity outcomes. Extensive experiments demonstrate that Pref-Restore achieves state-of-the-art performance across synthetic and real-world benchmarks. Furthermore, empirical analysis confirms that our preference-aligned strategy significantly reduces solution entropy, establishing a robust pathway toward reliable and deterministic blind restoration.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19506v2</guid></item><item><title>[cs updates on arXiv.org] R^3: Replay, Reflection, and Ranking Rewards for LLM Reinforcement Learning</title><link>https://arxiv.org/abs/2601.19620</link><description>arXiv:2601.19620v2 Announce Type: replace 
Abstract: Large reasoning models (LRMs) aim to solve diverse and complex problems through structured reasoning. Recent advances in group-based policy optimization methods have shown promise in enabling stable advantage estimation without reliance on process-level annotations. However, these methods rely on advantage gaps induced by high-quality samples within the same batch, which makes the training process fragile and inefficient when intra-group advantages collapse under challenging tasks. To address these problems, we propose a reinforcement learning mechanism named \emph{\textbf{R^3}} that along three directions: (1) a \emph{cross-context \underline{\textbf{R}}eplay} strategy that maintains the intra-group advantage by recalling valuable examples from historical trajectories of the same query, (2) an \emph{in-context self-\underline{\textbf{R}}eflection} mechanism enabling models to refine outputs by leveraging past failures, and (3) a \emph{structural entropy \underline{\textbf{R}}anking reward}, which assigns relative rewards to truncated or failed samples by ranking responses based on token-level entropy patterns, capturing both local exploration and global stability. We implement our method on Deepseek-R1-Distill-Qwen-1.5B and train it on the DeepscaleR-40k in the math domain. Experiments demonstrate our method achieves SoTA performance on several math benchmarks, representing significant improvements and fewer reasoning tokens over the base models. Code and model will be released.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19620v2</guid></item><item><title>[cs updates on arXiv.org] ProToken: Token-Level Attribution for Federated Large Language Models</title><link>https://arxiv.org/abs/2601.19672</link><description>arXiv:2601.19672v2 Announce Type: replace 
Abstract: Federated Learning (FL) enables collaborative training of Large Language Models (LLMs) across distributed data sources while preserving privacy. However, when federated LLMs are deployed in critical applications, it remains unclear which client(s) contributed to specific generated responses, hindering debugging, malicious client identification, fair reward allocation, and trust verification. We present ProToken, a novel Provenance methodology for Token-level attribution in federated LLMs that addresses client attribution during autoregressive text generation while maintaining FL privacy constraints. ProToken leverages two key insights to enable provenance at each token: (1) transformer architectures concentrate task-specific signals in later blocks, enabling strategic layer selection for computational tractability, and (2) gradient-based relevance weighting filters out irrelevant neural activations, focusing attribution on neurons that directly influence token generation. We evaluate ProToken across 16 configurations spanning four LLM architectures (Gemma, Llama, Qwen, SmolLM) and four domains (medical, financial, mathematical, coding). ProToken achieves 98% average attribution accuracy in correctly localizing responsible client(s), and maintains high accuracy when the number of clients are scaled, validating its practical viability for real-world deployment settings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19672v2</guid></item><item><title>[cs updates on arXiv.org] Benchmarking Multimodal Large Language Models for Missing Modality Completion in Product Catalogues</title><link>https://arxiv.org/abs/2601.19750</link><description>arXiv:2601.19750v2 Announce Type: replace 
Abstract: Missing-modality information on e-commerce platforms, such as absent product images or textual descriptions, often arises from annotation errors or incomplete metadata, impairing both product presentation and downstream applications such as recommendation systems. Motivated by the multimodal generative capabilities of recent Multimodal Large Language Models (MLLMs), this work investigates a fundamental yet underexplored question: can MLLMs generate missing modalities for products in e-commerce scenarios? We propose the Missing Modality Product Completion Benchmark (MMPCBench), which consists of two sub-benchmarks: a Content Quality Completion Benchmark and a Recommendation Benchmark.
  We further evaluate six state-of-the-art MLLMs from the Qwen2.5-VL and Gemma-3 model families across nine real-world e-commerce categories, focusing on image-to-text and text-to-image completion tasks. Experimental results show that while MLLMs can capture high-level semantics, they struggle with fine-grained word-level and pixel- or patch-level alignment. In addition, performance varies substantially across product categories and model scales, and we observe no trivial correlation between model size and performance, in contrast to trends commonly reported in mainstream benchmarks. We also explore Group Relative Policy Optimization (GRPO) to better align MLLMs with this task. GRPO improves image-to-text completion but does not yield gains for text-to-image completion. Overall, these findings expose the limitations of current MLLMs in real-world cross-modal generation and represent an early step toward more effective missing-modality product completion.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19750v2</guid></item><item><title>[cs updates on arXiv.org] GeoDiff3D: Self-Supervised 3D Scene Generation with Geometry-Constrained 2D Diffusion Guidance</title><link>https://arxiv.org/abs/2601.19785</link><description>arXiv:2601.19785v2 Announce Type: replace 
Abstract: 3D scene generation is a core technology for gaming, film/VFX, and VR/AR. Growing demand for rapid iteration, high-fidelity detail, and accessible content creation has further increased interest in this area. Existing methods broadly follow two paradigms - indirect 2D-to-3D reconstruction and direct 3D generation - but both are limited by weak structural modeling and heavy reliance on large-scale ground-truth supervision, often producing structural artifacts, geometric inconsistencies, and degraded high-frequency details in complex scenes. We propose GeoDiff3D, an efficient self-supervised framework that uses coarse geometry as a structural anchor and a geometry-constrained 2D diffusion model to provide texture-rich reference images. Importantly, GeoDiff3D does not require strict multi-view consistency of the diffusion-generated references and remains robust to the resulting noisy, inconsistent guidance. We further introduce voxel-aligned 3D feature aggregation and dual self-supervision to maintain scene coherence and fine details while substantially reducing dependence on labeled data. GeoDiff3D also trains with low computational cost and enables fast, high-quality 3D scene generation. Extensive experiments on challenging scenes show improved generalization and generation quality over existing baselines, offering a practical solution for accessible and efficient 3D scene construction.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19785v2</guid></item><item><title>[cs updates on arXiv.org] LVLMs and Humans Ground Differently in Referential Communication</title><link>https://arxiv.org/abs/2601.19792</link><description>arXiv:2601.19792v2 Announce Type: replace 
Abstract: For generative AI agents to partner effectively with human users, the ability to accurately predict human intent is critical. But this ability to collaborate remains limited by a critical deficit: an inability to model common ground. Here, we present a referential communication experiment with a factorial design involving director-matcher pairs (human-human, human-AI, AI-human, and AI-AI) that interact with multiple turns in repeated rounds to match pictures of objects not associated with any obvious lexicalized labels. We release the online pipeline for data collection, the tools and analyses for accuracy, efficiency, and lexical overlap, and a corpus of 356 dialogues (89 pairs over 4 rounds each) that unmasks LVLMs' limitations in interactively resolving referring expressions, a crucial skill that underlies human language use.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19792v2</guid></item><item><title>[cs updates on arXiv.org] Zero-Shot Stance Detection in the Wild: Dynamic Target Generation and Multi-Target Adaptation</title><link>https://arxiv.org/abs/2601.19802</link><description>arXiv:2601.19802v2 Announce Type: replace 
Abstract: Current stance detection research typically relies on predicting stance based on given targets and text. However, in real-world social media scenarios, targets are neither predefined nor static but rather complex and dynamic. To address this challenge, we propose a novel task: zero-shot stance detection in the wild with Dynamic Target Generation and Multi-Target Adaptation (DGTA), which aims to automatically identify multiple target-stance pairs from text without prior target knowledge. We construct a Chinese social media stance detection dataset and design multi-dimensional evaluation metrics. We explore both integrated and two-stage fine-tuning strategies for large language models (LLMs) and evaluate various baseline models. Experimental results demonstrate that fine-tuned LLMs achieve superior performance on this task: the two-stage fine-tuned Qwen2.5-7B attains the highest comprehensive target recognition score of 66.99%, while the integrated fine-tuned DeepSeek-R1-Distill-Qwen-7B achieves a stance detection F1 score of 79.26%.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19802v2</guid></item><item><title>[cs updates on arXiv.org] Analyzing decision tree bias towards the minority class</title><link>https://arxiv.org/abs/2501.04903</link><description>arXiv:2501.04903v4 Announce Type: replace-cross 
Abstract: There is a widespread and longstanding belief that machine learning models are biased towards the majority class when learning from imbalanced binary response data, leading them to neglect or ignore the minority class. Motivated by a recent simulation study that found that decision trees can be biased towards the minority class, our paper aims to reconcile the conflict between that study and other published works. First, we critically evaluate past literature on this problem, finding that failing to consider the conditional distribution of the outcome given the predictors has led to incorrect conclusions about the bias in decision trees. We then show that, under specific conditions, decision trees fit to purity are biased towards the minority class, debunking the belief that decision trees are always biased towards the majority class. This bias can be reduced by adjusting the tree-fitting process to include regularization methods like pruning and setting a maximum tree depth, and/or by using post-hoc calibration methods. Our findings have implications on the use of popular tree-based models, such as random forests. Although random forests are often composed of decision trees fit to purity, our work adds to recent literature indicating that this may not be the best approach.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2501.04903v4</guid></item><item><title>[cs updates on arXiv.org] X-LRM: X-ray Large Reconstruction Model for Extremely Sparse-View Computed Tomography Recovery in One Second</title><link>https://arxiv.org/abs/2503.06382</link><description>arXiv:2503.06382v2 Announce Type: replace-cross 
Abstract: Sparse-view 3D CT reconstruction aims to recover volumetric structures from a limited number of 2D X-ray projections. Existing feedforward methods are constrained by the scarcity of large-scale training datasets and the absence of direct and consistent 3D representations. In this paper, we propose an X-ray Large Reconstruction Model (X-LRM) for extremely sparse-view ($&lt;$10 views) CT reconstruction. X-LRM consists of two key components: X-former and X-triplane. X-former can handle an arbitrary number of input views using an MLP-based image tokenizer and a Transformer-based encoder. The output tokens are then upsampled into our X-triplane representation, which models the 3D radiodensity as an implicit neural field. To support the training of X-LRM, we introduce Torso-16K, a large-scale dataset comprising over 16K volume-projection pairs of various torso organs. Extensive experiments demonstrate that X-LRM outperforms the state-of-the-art method by 1.5 dB and achieves 27$\times$ faster speed with better flexibility. Furthermore, the evaluation of lung segmentation tasks also suggests the practical value of our approach. Our code and dataset will be released at https://github.com/Richard-Guofeng-Zhang/X-LRM</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2503.06382v2</guid></item><item><title>[cs updates on arXiv.org] Fractal and Regular Geometry of Deep Neural Networks</title><link>https://arxiv.org/abs/2504.06250</link><description>arXiv:2504.06250v2 Announce Type: replace-cross 
Abstract: We study the geometric properties of random neural networks by investigating the boundary volumes of their excursion sets for different activation functions, as the depth increases. More specifically, we show that, for activations which are not very regular (e.g., the Heaviside step function), the boundary volumes exhibit fractal behavior, with their Hausdorff dimension monotonically increasing with the depth. On the other hand, for activations which are more regular (e.g., ReLU, logistic and $\tanh$), as the depth increases, the expected boundary volumes can either converge to zero, remain constant or diverge exponentially, depending on a single spectral parameter which can be easily computed. Our theoretical results are confirmed in some numerical experiments based on Monte Carlo simulations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2504.06250v2</guid></item><item><title>[cs updates on arXiv.org] Simplicity is Key: An Unsupervised Pretraining Approach for Sparse Radio Channels</title><link>https://arxiv.org/abs/2505.13055</link><description>arXiv:2505.13055v3 Announce Type: replace-cross 
Abstract: Unsupervised representation learning for wireless channel state information (CSI)reduces reliance on labeled data, thereby lowering annotation costs, and often improves performance on downstream tasks. However, state-of-the-art approaches take little or no account of domain-specific knowledge, forcing the model to learn well-known concepts solely from data. We introduce Sparse pretrained Radio Transformer (SpaRTran), a hybrid method based on the concept of compressed sensing for wireless channels. In contrast to existing work, SpaRTran builds around a wireless channel model that constrains the optimization procedure to physically meaningful solutions and induces a strong inductive bias. Compared to the state of the art, SpaRTran cuts positioning error by up to 28% and increases top-1 codebook selection accuracy for beamforming by 26 percentage points. Our results show that capturing the sparse nature of radio propagation as an unsupervised learning objective improves performance for network optimization and radio-localization tasks.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2505.13055v3</guid></item><item><title>[cs updates on arXiv.org] Determining unit groups and $\mathrm{K}_1$ of finite rings</title><link>https://arxiv.org/abs/2506.00266</link><description>arXiv:2506.00266v2 Announce Type: replace-cross 
Abstract: We consider the computational problem of determining the unit group of a finite ring, by which we mean the computation of a finite presentation together with an algorithm to express units as words in the generators. We show that the problem is equivalent to the number theoretic problems of factoring integers and solving discrete logarithms in finite fields. A similar equivalence is shown for the problem of determining the abelianization of the unit group or the first $K$-group of finite rings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.00266v2</guid></item><item><title>[cs updates on arXiv.org] Can AI Master Econometrics? Evidence from Econometrics AI Agent on Expert-Level Tasks</title><link>https://arxiv.org/abs/2506.00856</link><description>arXiv:2506.00856v3 Announce Type: replace-cross 
Abstract: Can AI effectively perform complex econometric analysis traditionally requiring human expertise? This paper evaluates AI agents' capability to master econometrics, focusing on empirical analysis performance. We develop ``MetricsAI'', an Econometrics AI Agent built on the open-source MetaGPT framework. This agent exhibits outstanding performance in: (1) planning econometric tasks strategically, (2) generating and executing code, (3) employing error-based reflection for improved robustness, and (4) allowing iterative refinement through multi-round conversations. We construct two datasets from academic coursework materials and published research papers to evaluate performance against real-world challenges. Comparative testing shows our domain-specialized AI agent significantly outperforms both benchmark large language models (LLMs) and general-purpose AI agents. This work establishes a testbed for exploring AI's impact on social science research and enables cost-effective integration of domain expertise, making advanced econometric methods accessible to users with minimal coding skills. Furthermore, our AI agent enhances research reproducibility and offers promising pedagogical applications for econometrics teaching.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.00856v3</guid></item><item><title>[cs updates on arXiv.org] Confidence intervals for forced alignment boundaries using model ensembles</title><link>https://arxiv.org/abs/2506.01256</link><description>arXiv:2506.01256v3 Announce Type: replace-cross 
Abstract: Forced alignment is a common tool to align audio with orthographic and phonetic transcriptions. Most forced alignment tools provide only a single estimate of a boundary. The present project introduces a method of deriving confidence intervals for these boundaries using a neural network ensemble technique. Ten different segment classifier neural networks were previously trained, and the alignment process is repeated with each model. The alignment ensemble is then used to place the boundary at the median of the boundaries in the ensemble, and 97.85% confidence intervals are constructed using order statistics. Having confidence intervals provides an estimate of the uncertainty in the boundary placement, facilitating tasks like finding boundaries that should be reviewed. As a bonus, on the Buckeye and TIMIT corpora, the ensemble boundaries show a slight overall improvement over using just a single model. The confidence intervals can be emitted during the alignment process as JSON files and a main table for programmatic and statistical analysis. For familiarity, they are also output as Praat TextGrids using a point tier to represent the intervals.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.01256v3</guid></item><item><title>[cs updates on arXiv.org] Online Conformal Model Selection for Nonstationary Time Series</title><link>https://arxiv.org/abs/2506.05544</link><description>arXiv:2506.05544v2 Announce Type: replace-cross 
Abstract: This paper introduces the MPS (Model Prediction Set), a novel framework for online model selection for nonstationary time series. Classical model selection methods, such as information criteria and cross-validation, rely heavily on the stationarity assumption and often fail in dynamic environments which undergo gradual or abrupt changes over time. Yet real-world data are rarely stationary, and model selection under nonstationarity remains a largely open problem. To tackle this challenge, we combine conformal inference with model confidence sets to develop a procedure that adaptively selects models best suited to the evolving dynamics at any given time. Concretely, the MPS updates in real time a confidence set of candidate models that covers the best model for the next time period with a specified long-run probability, while adapting to nonstationarity of unknown forms. Through simulations and real-world data analysis, we demonstrate that MPS reliably and efficiently identifies optimal models under nonstationarity, an essential capability lacking in offline methods. Moreover, MPS frequently produces high-quality sets with small cardinality, whose evolution offers deeper insights into changing dynamics. As a generic framework, MPS accommodates any data-generating process, data structure, model class, training method, and evaluation metric, making it broadly applicable across diverse problem settings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.05544v2</guid></item><item><title>[cs updates on arXiv.org] BRISC: Annotated Dataset for Brain Tumor Segmentation and Classification</title><link>https://arxiv.org/abs/2506.14318</link><description>arXiv:2506.14318v5 Announce Type: replace-cross 
Abstract: Accurate segmentation and classification of brain tumors from Magnetic Resonance Imaging (MRI) remain key challenges in medical image analysis, primarily due to the lack of high-quality, balanced, and diverse datasets with expert annotations. In this work, we address this gap by introducing BRISC, a dataset designed for brain tumor segmentation and classification tasks, featuring high-resolution segmentation masks. The dataset comprises 6,000 contrast-enhanced T1-weighted MRI scans, which were collated from multiple public datasets that lacked segmentation labels. Our primary contribution is the subsequent expert annotation of these images, performed by certified radiologists and physicians. It includes three major tumor types, namely glioma, meningioma, and pituitary, as well as non-tumorous cases. Each sample includes high-resolution labels and is categorized across axial, sagittal, and coronal imaging planes to facilitate robust model development and cross-view generalization. To demonstrate the utility of the dataset, we provide benchmark results for both tasks using standard deep learning models. The BRISC dataset is made publicly available. datasetlink: https://www.kaggle.com/datasets/briscdataset/brisc2025/</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.14318v5</guid></item><item><title>[cs updates on arXiv.org] Telegrapher's Generative Model via Kac Flows</title><link>https://arxiv.org/abs/2506.20641</link><description>arXiv:2506.20641v5 Announce Type: replace-cross 
Abstract: We break the mold in flow-based generative modeling by proposing a new model based on the damped wave equation, also known as telegrapher's equation. Similar to the diffusion equation and Brownian motion, there is a Feynman-Kac type relation between the telegrapher's equation and the stochastic Kac process in 1D. The Kac flow evolves stepwise linearly in time, so that the probability flow is Lipschitz continuous in the Wasserstein distance and, in contrast to diffusion flows, the norm of the velocity is globally bounded. Furthermore, the Kac model has the diffusion model as its asymptotic limit. We extend these considerations to a multi-dimensional stochastic process which consists of independent 1D Kac processes in each spatial component. We show that this process gives rise to an absolutely continuous curve in the Wasserstein space and compute the conditional velocity field starting in a Dirac point analytically. Using the framework of flow matching, we train a neural network that approximates the velocity field and use it for sample generation. Our numerical experiments demonstrate the scalability of our approach, and show its advantages over diffusion models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2506.20641v5</guid></item><item><title>[cs updates on arXiv.org] AGFS-Tractometry: A Novel Atlas-Guided Fine-Scale Tractometry Approach for Enhanced Along-Tract Group Statistical Comparison Using Diffusion MRI Tractography</title><link>https://arxiv.org/abs/2507.10601</link><description>arXiv:2507.10601v2 Announce Type: replace-cross 
Abstract: Diffusion MRI (dMRI) tractography is currently the only method for in vivo mapping of the brain's white matter (WM) connections. Tractometry is an advanced tractography analysis technique for along-tract profiling to investigate the morphology and microstructural properties along the fiber tracts. Tractometry has become an essential tool for studying local along-tract differences between different populations (e.g., health vs disease). In this study, we propose a novel atlas-guided fine-scale tractometry method, namely AGFS-Tractometry, that leverages tract spatial information and permutation testing to enhance the along-tract statistical analysis between populations. There are two major contributions in AGFS-Tractometry. First, we create a novel atlas-guided tract profiling template that enables consistent, fine-scale, along-tract parcellation of subject-specific fiber tracts. Second, we propose a novel nonparametric permutation testing group comparison method to enable simultaneous analysis across all along-tract parcels while correcting for multiple comparisons. We perform experimental evaluations on synthetic datasets with known group differences and in vivo real data. We compare AGFS-Tractometry with two state-of-the-art tractometry methods, including Automated Fiber-tract Quantification (AFQ) and BUndle ANalytics (BUAN). Our results show that the proposed AGFS-Tractometry obtains enhanced sensitivity and specificity in detecting local WM differences. In the real data analysis experiments, AGFS-Tractometry can identify more regions with significant differences, which are anatomically consistent with the existing literature. Overall, these demonstrate the ability of AGFS-Tractometry to detect subtle or spatially localized WM group-level differences. The created tract profiling template and related code are available at: https://github.com/ZhengRuixi/AGFS-Tractometry.git.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2507.10601v2</guid></item><item><title>[cs updates on arXiv.org] Random forest-based out-of-distribution detection for robust lung cancer segmentation</title><link>https://arxiv.org/abs/2508.19112</link><description>arXiv:2508.19112v4 Announce Type: replace-cross 
Abstract: Accurate detection and segmentation of cancerous lesions from computed tomography (CT) scans is essential for automated treatment planning and cancer treatment response assessment. Transformer-based models with self-supervised pretraining can produce reliably accurate segmentation from in-distribution (ID) data but degrade when applied to out-of-distribution (OOD) datasets. We address this challenge with RF-Deep, a random forest classifier that utilizes deep features from a pretrained transformer encoder of the segmentation model to detect OOD scans and enhance segmentation reliability. The segmentation model comprises a Swin Transformer encoder, pretrained with masked image modeling (SimMIM) on 10,432 unlabeled 3D CT scans covering cancerous and non-cancerous conditions, with a convolution decoder, trained to segment lung cancers in 317 3D scans. Independent testing was performed on 603 3D CT public datasets that included one ID dataset and four OOD datasets comprising chest CTs with pulmonary embolism (PE) and COVID-19, and abdominal CTs with kidney cancers and healthy volunteers. RF-Deep detected OOD cases with a FPR95 of 18.26%, 27.66%, and less than 0.1% on PE, COVID-19, and abdominal CTs, consistently outperforming established OOD approaches. The RF-Deep classifier provides a simple and effective approach to enhance reliability of cancer segmentation in ID and OOD scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2508.19112v4</guid></item><item><title>[cs updates on arXiv.org] Some Robustness Properties of Label Cleaning</title><link>https://arxiv.org/abs/2509.11379</link><description>arXiv:2509.11379v2 Announce Type: replace-cross 
Abstract: We demonstrate that learning procedures that rely on aggregated labels, e.g., label information distilled from noisy responses, enjoy robustness properties impossible without data cleaning. This robustness appears in several ways. In the context of risk consistency -- when one takes the standard approach in machine learning of minimizing a surrogate (typically convex) loss in place of a desired task loss (such as the zero-one mis-classification error) -- procedures using label aggregation obtain stronger consistency guarantees than those even possible using raw labels. And while classical statistical scenarios of fitting perfectly-specified models suggest that incorporating all possible information -- modeling uncertainty in labels -- is statistically efficient, consistency fails for ``standard'' approaches as soon as a loss to be minimized is even slightly mis-specified. Yet procedures leveraging aggregated information still converge to optimal classifiers, highlighting how incorporating a fuller view of the data analysis pipeline, from collection to model-fitting to prediction time, can yield a more robust methodology by refining noisy signals.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.11379v2</guid></item><item><title>[cs updates on arXiv.org] Blind Source Separation of Radar Signals in Time Domain Using Deep Learning</title><link>https://arxiv.org/abs/2509.15603</link><description>arXiv:2509.15603v2 Announce Type: replace-cross 
Abstract: Identification and further analysis of radar emitters in a contested environment requires detection and separation of incoming signals. If they arrive from the same direction and at similar frequencies, deinterleaving them remains challenging. A solution to overcome this limitation becomes increasingly important with the advancement of emitter capabilities. We propose treating the problem as blind source separation in time domain and apply supervisedly trained neural networks to extract the underlying signals from the received mixture. This allows us to handle highly overlapping and also continuous wave (CW) signals from both radar and communication emitters. We make use of advancements in the field of audio source separation and extend a current state-of-the-art model with the objective of deinterleaving arbitrary radio frequency (RF) signals. Results show, that our approach is capable of separating two unknown waveforms in a given frequency band with a single channel receiver.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.15603v2</guid></item><item><title>[cs updates on arXiv.org] ArchesClimate: Probabilistic Decadal Ensemble Generation With Flow Matching</title><link>https://arxiv.org/abs/2509.15942</link><description>arXiv:2509.15942v2 Announce Type: replace-cross 
Abstract: Climate projections have uncertainties related to components of the climate system and their interactions. A typical approach to quantifying these uncertainties is to use climate models to create ensembles of repeated simulations under different initial conditions. Due to the complexity of these simulations, generating such ensembles of projections is computationally expensive. In this work, we present ArchesClimate, a deep learning-based climate model emulator that aims to reduce this cost. ArchesClimate is trained on decadal hindcasts of the IPSL-CM6A-LR climate model at a spatial resolution of approximately 2.5x1.25 degrees. We train a flow matching model following ArchesWeatherGen, which we adapt to predict near-term climate. Once trained, the model generates states at a one-month lead time and can be used to auto-regressively emulate climate model simulations of any length. We show that for up to 10 years, these generations are stable and physically consistent. We also show that for several important climate variables, ArchesClimate generates simulations that are interchangeable with the IPSL model. This work suggests that climate model emulators could significantly reduce the cost of climate model simulations.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.15942v2</guid></item><item><title>[cs updates on arXiv.org] Zeroth-Order Constrained Optimization from a Control Perspective via Feedback Linearization</title><link>https://arxiv.org/abs/2509.24056</link><description>arXiv:2509.24056v2 Announce Type: replace-cross 
Abstract: Safe derivative-free optimization under unknown constraints is a fundamental challenge in modern learning and control. Existing zeroth-order (ZO) methods typically still assume access to a first-order oracle of the constraint functions or restrict attention to convex settings, leaving nonconvex optimization with black-box constraints largely unexplored. We propose the zeroth-order feedback-linearization (ZOFL) algorithm for ZO constrained optimization that enforces feasibility without access to the first-order oracle of the constraint functions and applies to both equality and inequality constraints. The proposed approach relies only on noisy, sample-based gradient estimates obtained via two-point estimators, yet provably guarantees constraint satisfaction under mild regularity conditions. It adopts a control-theoretic perspective on ZO constrained optimization and leverages feedback linearization, a nonlinear control technique, to enforce feasibility. Finite-time bounds on constraint violation and asymptotic global convergence guarantees are established for the ZOFL algorithm. A midpoint discretization variant is further developed to improve feasibility without sacrificing optimality. Empirical results demonstrate that ZOFL consistently outperforms standard ZO baselines, achieving competitive objective values while maintaining feasibility.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.24056v2</guid></item><item><title>[cs updates on arXiv.org] Sharpness of Minima in Deep Matrix Factorization</title><link>https://arxiv.org/abs/2509.25783</link><description>arXiv:2509.25783v5 Announce Type: replace-cross 
Abstract: Understanding the geometry of the loss landscape near a minimum is key to explaining the implicit bias of gradient-based methods in non-convex optimization problems such as deep neural network training and deep matrix factorization. A central quantity to characterize this geometry is the maximum eigenvalue of the Hessian of the loss. Currently, its precise role has been obfuscated because no exact expressions for this sharpness measure were known in general settings. In this paper, we present the first exact expression for the maximum eigenvalue of the Hessian of the squared-error loss at any minimizer in deep matrix factorization/deep linear neural network training problems, resolving an open question posed by Mulayoff &amp; Michaeli (2020). This expression reveals a fundamental property of the loss landscape in deep matrix factorization: Having a constant product of the spectral norms of the left and right intermediate factors across layers is a sufficient condition for flatness. Most notably, in both depth-$2$ matrix and deep overparameterized scalar factorization, we show that this condition is both necessary and sufficient for flatness, which implies that flat minima are spectral-norm balanced even though they are not necessarily Frobenius-norm balanced. To complement our theory, we provide the first empirical characterization of an escape phenomenon during gradient-based training near a minimizer of a deep matrix factorization problem.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2509.25783v5</guid></item><item><title>[cs updates on arXiv.org] WaveSP-Net: Learnable Wavelet-Domain Sparse Prompt Tuning for Speech Deepfake Detection</title><link>https://arxiv.org/abs/2510.05305</link><description>arXiv:2510.05305v2 Announce Type: replace-cross 
Abstract: Modern front-end design for speech deepfake detection relies on full fine-tuning of large pre-trained models like XLSR. However, this approach is not parameter-efficient and may lead to suboptimal generalization to realistic, in-the-wild data types. To address these limitations, we introduce a new family of parameter-efficient front-ends that fuse prompt-tuning with classical signal processing transforms. These include FourierPT-XLSR, which uses the Fourier Transform, and two variants based on the Wavelet Transform: WSPT-XLSR and Partial-WSPT-XLSR. We further propose WaveSP-Net, a novel architecture combining a Partial-WSPT-XLSR front-end and a bidirectional Mamba-based back-end. This design injects multi-resolution features into the prompt embeddings, which enhances the localization of subtle synthetic artifacts without altering the frozen XLSR parameters. Experimental results demonstrate that WaveSP-Net outperforms several state-of-the-art models on two new and challenging benchmarks, Deepfake-Eval-2024 and SpoofCeleb, with low trainable parameters and notable performance gains. The code and models are available at https://github.com/xxuan-acoustics/WaveSP-Net.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.05305v2</guid></item><item><title>[cs updates on arXiv.org] Bounds in the Projective Unitary Group with Respect to Global Phase Invariant Metric</title><link>https://arxiv.org/abs/2510.09765</link><description>arXiv:2510.09765v2 Announce Type: replace-cross 
Abstract: We consider a global phase-invariant metric in the projective unitary group PUn, relevant for universal quantum computing. We obtain the volume and measure of small metric ball in PUn and derive the Gilbert-Varshamov and Hamming bounds in PUn. In addition, we provide upper and lower bounds for the kissing radius of the codebooks in PUn as a function of the minimum distance. Using the lower bound of the kissing radius, we find a tight Hamming bound. Also, we establish bounds on the distortion-rate function for quantizing a source uniformly distributed over PUn. As example codebooks in PUn, we consider the projective Pauli and Clifford groups, as well as the projective group of diagonal gates in the Clifford hierarchy, and find their minimum distances. For any code in PUn with given cardinality we provide a lower bound of covering radius. Also, we provide expected value of the covering radius of randomly distributed points on PUn, when cardinality of code is sufficiently large. We discuss codebooks at various stages of the projective Clifford + T and projective Clifford + S constructions in PU2, and obtain their minimum distance, distortion, and covering radius. Finally, we verify the analytical results by simulation.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.09765v2</guid></item><item><title>[cs updates on arXiv.org] AI-Assisted Programming Decreases the Productivity of Experienced Developers by Increasing the Technical Debt and Maintenance Burden</title><link>https://arxiv.org/abs/2510.10165</link><description>arXiv:2510.10165v3 Announce Type: replace-cross 
Abstract: GenAI solutions like GitHub Copilot have been shown to increase the productivity of software developers. Yet prior work remains unclear on the quality of code produced and the challenges of maintaining it in software projects. If quality declines as volume grows, technical debt accumulates as experienced developers face increased workloads reviewing and reworking code from less-experienced contributors. We analyze developer activity in Open Source Software (OSS) projects following the introduction of GitHub Copilot. We find that productivity indeed increases. However, the increase in productivity is primarily driven by less-experienced (peripheral) developers. We also find that code written after the adoption of AI requires more rework to satisfy repository standards, indicating a potential increase in technical debt. Importantly, the added rework burden falls on the more experienced (core) developers, who review 6.5% more code after Copilot's introduction, but show a 19% drop in their original code productivity. More broadly, this finding raises caution that productivity gains of AI may mask the growing burden of maintenance on a shrinking pool of experts, together with increased technical debt for the projects. The results highlight a fundamental tension in AI-assisted software development between short-term productivity gains and long-term system sustainability.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.10165v3</guid></item><item><title>[cs updates on arXiv.org] Efficient Group Lasso Regularized Rank Regression with Data-Driven Parameter Determination</title><link>https://arxiv.org/abs/2510.11546</link><description>arXiv:2510.11546v2 Announce Type: replace-cross 
Abstract: High-dimensional regression often suffers from heavy-tailed noise and outliers, which can severely undermine the reliability of least-squares based methods. To improve robustness, we adopt a non-smooth Wilcoxon score based rank objective and incorporate structured group sparsity regularization, a natural generalization of the lasso, yielding a group lasso regularized rank regression method. By extending the tuning-free parameter selection scheme originally developed for the lasso, we introduce a data-driven, simulation-based tuning rule and further establish a finite-sample error bound for the resulting estimator. On the computational side, we develop a proximal augmented Lagrangian method for solving the associated optimization problem, which eliminates the singularity issues encountered in existing methods, thereby enabling efficient semismooth Newton updates for the subproblems. Extensive numerical experiments demonstrate the robustness and effectiveness of our proposed estimator against alternatives, and showcase the scalability of the algorithm across both simulated and real-data settings.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.11546v2</guid></item><item><title>[cs updates on arXiv.org] Adaptive Per-Channel Energy Normalization Front-end for Robust Audio Signal Processing</title><link>https://arxiv.org/abs/2510.18206</link><description>arXiv:2510.18206v2 Announce Type: replace-cross 
Abstract: In audio signal processing, learnable front-ends have shown strong performance across diverse tasks by optimizing task-specific representation. However, their parameters remain fixed once trained, lacking flexibility during inference and limiting robustness under dynamic complex acoustic environments. In this paper, we introduce a novel adaptive paradigm for audio front-ends that replaces static parameterization with a closed-loop neural controller. Specifically, we simplify the learnable front-end LEAF architecture and integrate a neural controller for adaptive representation via dynamically tuning Per-Channel Energy Normalization. The neural controller leverages both the current and the buffered past subband energies to enable input-dependent adaptation during inference. Experimental results on multiple audio classification tasks demonstrate that the proposed adaptive front-end consistently outperforms prior fixed and learnable front-ends under both clean and complex acoustic conditions. These results highlight neural adaptability as a promising direction for the next generation of audio front-ends.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2510.18206v2</guid></item><item><title>[cs updates on arXiv.org] QUASAR: An Evolutionary Algorithm to Accelerate High-Dimensional Optimization</title><link>https://arxiv.org/abs/2511.13843</link><description>arXiv:2511.13843v3 Announce Type: replace-cross 
Abstract: High-dimensional numerical optimization presents a persistent challenge in computational science. This paper introduces Quasi-Adaptive Search with Asymptotic Reinitialization (QUASAR), an evolutionary algorithm to accelerate convergence in complex, non-differentiable problems afflicted by the curse of dimensionality. QUASAR expands upon the core principles of Differential Evolution (DE), introducing quasi-adaptive mechanisms to dynamically balance exploration and exploitation in its search. Inspired by the behavior of quantum particles, the algorithm utilizes three highly stochastic mechanisms that augment standard DE: 1) probabilistic mutation strategies and scaling factors; 2) rank-based crossover rates; 3) asymptotically decaying covariance reinitializations.
  Evaluated on the notoriously difficult CEC2017 benchmark suite of 29 test functions, QUASAR achieved the lowest overall rank sum (367) using the Friedman test, outperforming DE (735) and L-SHADE (452). Geometric mean comparisons show average final solution quality improvements of $3.85 \times$ and $2.07 \times$ compared to DE and L-SHADE, respectively ($p \ll 0.001$), with average optimization speed averaging $1.40 \times$ and $5.16 \times$ faster. QUASAR's performance establishes it as an effective, efficient, and user-friendly evolutionary algorithm for complex high-dimensional problems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.13843v3</guid></item><item><title>[cs updates on arXiv.org] A Multi-Stage Deep Learning Framework with PKCP-MixUp Augmentation for Pediatric Liver Tumor Diagnosis Using Multi-Phase Contrast-Enhanced CT</title><link>https://arxiv.org/abs/2511.19478</link><description>arXiv:2511.19478v3 Announce Type: replace-cross 
Abstract: Pediatric liver tumors are one of the most common solid tumors in pediatrics, with differentiation of benign or malignant status and pathological classification critical for clinical treatment. While pathological examination is the gold standard, the invasive biopsy has notable limitations: the highly vascular pediatric liver and fragile tumor tissue raise complication risks such as bleeding; additionally, young children with poor compliance require anesthesia for biopsy, increasing medical costs or psychological trauma. Although many efforts have been made to utilize AI in clinical settings, most researchers have overlooked its importance in pediatric liver tumors. To establish a non-invasive examination procedure, we developed a multi-stage deep learning (DL) framework for automated pediatric liver tumor diagnosis using multi-phase contrast-enhanced CT. Two retrospective and prospective cohorts were enrolled. We established a novel PKCP-MixUp data augmentation method to address data scarcity and class imbalance. We also trained a tumor detection model to extract ROIs, and then set a two-stage diagnosis pipeline with three backbones with ROI-masked images. Our tumor detection model has achieved high performance (mAP=0.871), and the first stage classification model between benign and malignant tumors reached an excellent performance (AUC=0.989). Final diagnosis models also exhibited robustness, including benign subtype classification (AUC=0.915) and malignant subtype classification (AUC=0.979). We also conducted multi-level comparative analyses, such as ablation studies on data and training pipelines, as well as Shapley-Value and CAM interpretability analyses. This framework fills the pediatric-specific DL diagnostic gap, provides actionable insights for CT phase selection and model design, and paves the way for precise, accessible pediatric liver tumor diagnosis.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2511.19478v3</guid></item><item><title>[cs updates on arXiv.org] Recurrent Neural Networks with Linear Structures for Electricity Price Forecasting</title><link>https://arxiv.org/abs/2512.04690</link><description>arXiv:2512.04690v2 Announce Type: replace-cross 
Abstract: We present a novel recurrent neural network architecture specifically designed for day-ahead electricity price forecasting, aimed at improving short-term decision-making and operational management in energy systems. Our combined forecasting model embeds linear structures, such as expert models and Kalman filters, into recurrent networks, enabling efficient computation and enhanced interpretability. The design leverages the strengths of both linear and non-linear model structures, allowing it to capture all relevant stylized price characteristics in power markets, including calendar and autoregressive effects, as well as influences from load, renewable energy, and related fuel and carbon markets. For empirical testing, we use hourly data from the largest European electricity market spanning 2018 to 2025 in a comprehensive forecasting study, comparing our model against state-of-the-art approaches, particularly high-dimensional linear and neural network models. In terms of RMSE, the proposed model achieves approximately 11% higher accuracy than the best-performing benchmark. We evaluate the contributions of the interpretable model components and conclude on the impact of combining linear and non-linear structures. We further evaluate the temporal robustness of the model by examining the stability of hyperparameters and the economic significance of key features. Additionally, we introduce a probabilistic extension to quantify forecast uncertainty.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.04690v2</guid></item><item><title>[cs updates on arXiv.org] Conformal Defects in Neural Network Field Theories</title><link>https://arxiv.org/abs/2512.07946</link><description>arXiv:2512.07946v2 Announce Type: replace-cross 
Abstract: Neural Network Field Theories (NN-FTs) represent a novel construction of arbitrary field theories, including those of conformal fields, through the specification of the network architecture and prior distribution for the network parameters. In this work, we present a formalism for the construction of conformally invariant defects in these NN-FTs. We demonstrate this new formalism in two toy models of NN scalar field theories. We develop an NN interpretation of an expansion akin to the defect OPE in two-point correlation functions in these models.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.07946v2</guid></item><item><title>[cs updates on arXiv.org] Low-Latency FPGA Control System for Real-Time Neural Network Processing in CCD-Based Trapped-Ion Qubit Measurement</title><link>https://arxiv.org/abs/2512.15838</link><description>arXiv:2512.15838v2 Announce Type: replace-cross 
Abstract: Accurate and low-latency qubit state measurement is critical for trapped-ion quantum computing. While deep neural networks (DNNs) have been integrated to enhance detection fidelity, their latency performance on specific hardware platforms remains underexplored. This work benchmarks the latency of DNN-based qubit detection on field-programmable gate arrays (FPGAs) and graphics processing units (GPUs). The FPGA solution directly interfaces an electron-multiplying charge-coupled device (EMCCD) with the subsequent data processing logic, eliminating buffering and interface overheads. As a baseline, the GPU-based system employs a high-speed PCIe image grabber for image input and I/O card for state output. We deploy Multilayer Perceptron (MLP) and Vision Transformer (ViT) models on hardware to evaluate measurement performance. Compared to conventional thresholding, DNNs reduce the mean measurement fidelity (MMF) error by factors of 1.8-2.5x (one-qubit case) and 4.2-7.6x (three-qubit case). FPGA-based MLP and ViT achieve nanosecond- and microsecond-scale inference latencies, while the complete single-shot measurement process achieves over 100x speedup compared to the GPU implementation. Additionally, clock-cycle-level signal analysis reveals inefficiencies in EMCCD data transmission via Cameralink, suggesting that optimizing this interface could further leverage the advantages of ultra-low-latency DNN inference, guiding the development of next-generation qubit detection systems.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.15838v2</guid></item><item><title>[cs updates on arXiv.org] Gradient Dynamics of Attention: How Cross-Entropy Sculpts Bayesian Manifolds</title><link>https://arxiv.org/abs/2512.22473</link><description>arXiv:2512.22473v3 Announce Type: replace-cross 
Abstract: Transformers empirically perform precise probabilistic reasoning in carefully constructed ``Bayesian wind tunnels'' and in large-scale language models, yet the mechanisms by which gradient-based learning creates the required internal geometry remain opaque. We provide a complete first-order analysis of how cross-entropy training reshapes attention scores and value vectors in a transformer attention head. Our core result is an \emph{advantage-based routing law} for attention scores, \[ \frac{\partial L}{\partial s_{ij}} = \alpha_{ij}\bigl(b_{ij}-\mathbb{E}_{\alpha_i}[b]\bigr), \qquad b_{ij} := u_i^\top v_j, \] coupled with a \emph{responsibility-weighted update} for values, \[ \Delta v_j = -\eta\sum_i \alpha_{ij} u_i, \] where $u_i$ is the upstream gradient at position $i$ and $\alpha_{ij}$ are attention weights. These equations induce a positive feedback loop in which routing and content specialize together: queries route more strongly to values that are above-average for their error signal, and those values are pulled toward the queries that use them. We show that this coupled specialization behaves like a two-timescale EM procedure: attention weights implement an E-step (soft responsibilities), while values implement an M-step (responsibility-weighted prototype updates), with queries and keys adjusting the hypothesis frame. Through controlled simulations, including a sticky Markov-chain task where we compare a closed-form EM-style update to standard SGD, we demonstrate that the same gradient dynamics that minimize cross-entropy also sculpt the low-dimensional manifolds identified in our companion work as implementing Bayesian inference. This yields a unified picture in which optimization (gradient flow) gives rise to geometry (Bayesian manifolds), which in turn supports function (in-context probabilistic reasoning).</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.22473v3</guid></item><item><title>[cs updates on arXiv.org] Marriage Discourse on Chinese Social Media: An LLM-assisted Analysis</title><link>https://arxiv.org/abs/2512.23609</link><description>arXiv:2512.23609v2 Announce Type: replace-cross 
Abstract: China's marriage registrations have declined substantially, dropping from 13.47 million couples in 2013 to 6.1 million in 2024. This study examined sentiment and moral elements underlying 219,358 marriage-related posts from Weibo and Xiaohongshu using large language model (LLM)-assisted content analysis. Drawing on Shweder's Big Three moral ethics framework, posts were coded for sentiment (positive, negative, neutral) and moral elements (autonomy, community, divinity). Results revealed platform differences: Weibo leaned toward positive sentiment, while Xiaohongshu was predominantly neutral. Most posts lacked explicit moral framing. However, when moral elements were invoked, significant associations with sentiment emerged. Posts invoking autonomy and community were predominantly negative, whereas divinity-framed posts tended toward positive sentiment. These findings suggest that concerns about both personal autonomy constraints and communal obligations contribute to negative marriage attitudes in contemporary China, offering insights for culturally informed policies addressing marriage decline.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2512.23609v2</guid></item><item><title>[cs updates on arXiv.org] Listen, Look, Drive: Coupling Audio Instructions for User-aware VLA-based Autonomous Driving</title><link>https://arxiv.org/abs/2601.12142</link><description>arXiv:2601.12142v2 Announce Type: replace-cross 
Abstract: Vision Language Action (VLA) models promise an open-vocabulary interface that can translate perceptual ambiguity into semantically grounded driving decisions, yet they still treat language as a static prior fixed at inference time. As a result, the model must infer continuously shifting objectives from pixels alone, yielding delayed or overly conservative maneuvers. We argue that effective VLAs for autonomous driving need an online channel in which users can influence driving with specific intentions. To this end, we present EchoVLA, a user-aware VLA that couples camera streams with in situ audio instructions. We augment the nuScenes dataset with temporally aligned, intent-specific speech commands generated by converting ego-motion descriptions into synthetic audios. Further, we compose emotional speech-trajectory pairs into a multimodal Chain-of-Thought (CoT) for fine-tuning a Multimodal Large Model (MLM) based on Qwen2.5-Omni. Specifically, we synthesize the audio-augmented dataset with different emotion types paired with corresponding driving behaviors, leveraging the emotional cues embedded in tone, pitch, and speech tempo to reflect varying user states, such as urgent or hesitant intentions, thus enabling our EchoVLA to interpret not only the semantic content but also the emotional context of audio commands for more nuanced and emotionally adaptive driving behavior. In open-loop benchmarks, our approach reduces the average L2 error by $59.4\%$ and the collision rate by $74.4\%$ compared to the baseline of vision-only perception. More experiments on nuScenes dataset validate that EchoVLA not only steers the trajectory through audio instructions, but also modulates driving behavior in response to the emotions detected in the user's speech.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.12142v2</guid></item><item><title>[cs updates on arXiv.org] Moving Least Squares without Quasi-Uniformity: A Stochastic Approach</title><link>https://arxiv.org/abs/2601.13782</link><description>arXiv:2601.13782v2 Announce Type: replace-cross 
Abstract: Local Polynomial Regression (LPR) and Moving Least Squares (MLS) are closely related nonparametric estimation methods, developed independently in statistics and approximation theory. While statistical LPR analysis focuses on overcoming sampling noise under probabilistic assumptions, the deterministic MLS theory studies smoothness properties and convergence rates with respect to the \textit{fill-distance} (a resolution parameter). Despite this similarity, the deterministic assumptions underlying MLS fail to hold under random sampling. We begin by quantifying the probabilistic behavior of the fill-distance $h_n$ and \textit{separation} $\delta_n$ of an i.i.d. random sample. That is, for a distribution satisfying a mild regularity condition, $h_n\propto n^{-1/d}\log^{1/d} (n)$ and $\delta_n \propto n^{-1/d}$. We then prove that, for MLS of degree $k\!-\!1$, the approximation error associated with a differential operator $Q$ of order $|m|\le k-1$ decays as $h_n^{\,k-|m|}$ up to logarithmic factors, establishing stochastic analogues of the classical MLS estimates. Additionally, We show that the MLS approximant is smooth with high probability. Finally, we apply the stochastic MLS theory to manifold estimation. Assuming that the sampled Manifold is $k$-times smooth, we show that the Hausdorff distance between the true manifold and its MLS reconstruction decays as $h_n^k$, extending the deterministic Manifold-MLS guarantees to random samples. This work provides the first unified stochastic analysis of MLS, demonstrating that -- despite the failure of deterministic sampling assumptions -- the classical convergence and smoothness properties persist under natural probabilistic models</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.13782v2</guid></item><item><title>[cs updates on arXiv.org] USDs: A universal stabilizer decoder framework using symmetry</title><link>https://arxiv.org/abs/2601.15361</link><description>arXiv:2601.15361v2 Announce Type: replace-cross 
Abstract: Quantum error correction is indispensable to achieving reliable quantum computation. When quantum information is encoded redundantly, a larger Hilbert space is constructed using multiple physical qubits, and the computation is performed within a designated subspace. When applying deep learning to the decoding of quantum error-correcting codes, a key challenge arises from the non-uniqueness between the syndrome measurements provided to the decoder and the corresponding error patterns that constitute the ground-truth labels. Building upon prior work that addressed this issue for the toric code by re-optimizing the decoder with respect to the symmetry inherent in the parity-check structure, we generalize this approach to arbitrary stabilizer codes. In our experiments, we employed multilayer perceptrons to approximate continuous functions that complement the syndrome measurements of the Color code and the Golay code. Using these models, we performed decoder re-optimization for each code. For the Color code, we achieved an improvement of approximately 0.8% in decoding accuracy at a physical error rate of 5%, while for the Golay code the accuracy increased by about 0.1%. Furthermore, from the evaluation of the geometric and algebraic structures in the continuous function approximation for each code, we showed that the design of generalized continuous functions is advantageous for learning the geometric structure inherent in the code. Our results also indicate that approximations that faithfully reproduce the code structure can have a significant impact on the effectiveness of reoptimization. This study demonstrates that the re-optimization technique previously shown to be effective for the Toric code can be generalized to address the challenge of label degeneracy that arises when applying deep learning to the decoding of stabilizer codes.</description><author>cs updates on arXiv.org</author><pubDate>Thu, 29 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.15361v2</guid></item><item><title>[cs updates on arXiv.org] Encoder-Free ECG-Language Models</title><link>https://arxiv.org/abs/2601.18798</link><description>arXiv:2601.18798v1 Announce Type: new 
Abstract: ECG-Language Models (ELMs) extend recent progress in Multimodal Large Language Models (MLLMs) to automated ECG interpretation. However, most ELMs follow Vision-Language Model (VLM) designs and depend on pretrained ECG encoders, adding architectural and training complexity. Inspired by encoder-free VLMs, we introduce ELF, an encoder-free ELM that replaces the ECG encoder with a single projection layer trained jointly with the LLM. Across five datasets, ELF matches or exceeds state-of-the-art ELMs that use far more complex encoders and training pipelines. We also test whether adding architectural biases to ELF improves performance and find that the single linear projection remains competitive. Finally, we show that ELF, and potentially other ELMs, often rely more on benchmark artifacts and language priors than ECG-derived information, highlighting limitations in current evaluation practices and ELM design. All data and code is available at https://github.com/willxxy/ECG-Bench.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18798v1</guid></item><item><title>[cs updates on arXiv.org] Agentic Digital Twins: A Taxonomy of Capabilities for Understanding Possible Futures</title><link>https://arxiv.org/abs/2601.18799</link><description>arXiv:2601.18799v1 Announce Type: new 
Abstract: As digital twins (DTs) evolve to become more agentic through the integration of artificial intelligence (AI), they acquire capabilities that extend beyond dynamic representation of their target systems. This paper presents a taxonomy of agentic DTs organised around three fundamental dimensions: the locus of agency (external, internal, distributed), the tightness of coupling (loose, tight, constitutive), and model evolution (static, adaptive, reconstructive). From the resulting 27-configuration space, we identify nine illustrative configurations grouped into three clusters: "The Present" (existing tools and emerging steering systems), "The Threshold" (where emergent properties appear and coupling becomes constitutive), and "The Frontier" (where systems gain reconstructive capabilities).
  Our analysis explores how agentic DTs exercise performative power--not merely representing physical systems but actively participating in constituting them. Using traffic navigation systems as examples, we show how even passive tools can exhibit emergent performativity, while advanced configurations risk performative lock-in. Drawing on performative prediction theory, we trace a progression from passive tools through active steering to ontological reconstruction, examining how constitutive coupling enables systems to create self-validating realities. Understanding these configurations is essential for navigating the transformation from DTs as mirror worlds to DTs as architects of new ontologies.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18799v1</guid></item><item><title>[cs updates on arXiv.org] AI-Powered Augmented Reality as a Threat Vector for Human Manipulation</title><link>https://arxiv.org/abs/2601.18802</link><description>arXiv:2601.18802v1 Announce Type: new 
Abstract: Augmented Reality (AR) is a powerful perceptual technology that can alter what users see, hear, feel, and experience throughout their daily lives. When combined with the speed and flexibility of context-aware generative AI, the power is greatly expanded, allowing individual users to be targeted with custom-generated AR experiences that are instantly tailored to who they are, where they are, and what they are doing. This can transform the physical world into a magical place, but only if the augmentation of a user's environment is enacted for their personal benefit and best interests. Instead, if AI-powered AR systems are controlled by unregulated third parties, such as large corporations or state actors, individually adaptive AR experiences could be deployed as a dangerous form of targeted influence. In fact, if the industry adopts an advertising business model for AI-powered AR devices, context-aware generative influence could become a widely used manipulative path for promotion of products and services in the physical world. Worse, similar techniques could be used for political influence, propaganda, and disinformation. This chapter reviews the power and flexibility of AI-generated augmented reality, explores the risks that emerge when used for persuasion, manipulation, or influence, and proposes policy directions to mitigate these risks.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18802v1</guid></item><item><title>[cs updates on arXiv.org] Latent Structural Similarity Networks for Unsupervised Discovery in Multivariate Time Series</title><link>https://arxiv.org/abs/2601.18803</link><description>arXiv:2601.18803v1 Announce Type: new 
Abstract: This paper proposes a task-agnostic discovery layer for multivariate time series that constructs a relational hypothesis graph over entities without assuming linearity, stationarity, or a downstream objective. The method learns window-level sequence representations using an unsupervised sequence-to-sequence autoencoder, aggregates these representations into entity-level embeddings, and induces a sparse similarity network by thresholding a latent-space similarity measure. This network is intended as an analyzable abstraction that compresses the pairwise search space and exposes candidate relationships for further investigation, rather than as a model optimized for prediction, trading, or any decision rule. The framework is demonstrated on a challenging real-world dataset of hourly cryptocurrency returns, illustrating how latent similarity induces coherent network structure; a classical econometric relation is also reported as an external diagnostic lens to contextualize discovered edges.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18803v1</guid></item><item><title>[cs updates on arXiv.org] A Hybrid Discretize-then-Project Reduced Order Model for Turbulent Flows on Collocated Grids with Data-Driven Closure</title><link>https://arxiv.org/abs/2601.18817</link><description>arXiv:2601.18817v1 Announce Type: new 
Abstract: This study presents a hybrid reduced-order modeling (ROM) framework for turbulent incompressible flows on collocated finite volume grids. The methodology employs the "discretize-then-project" consistent flux strategy, which ensures mass conservation and pressure-velocity coupling without requiring auxiliary stabilization like boundary control or pressure stabilization techniques. However, because standard Galerkin projection fails to yield physically consistent results for the turbulent viscosity field, a hybrid strategy is adopted: velocity and pressure are resolved via intrusive projection, while the turbulent viscosity is reconstructed using a non-intrusive data-driven closure. We evaluate three neural network architectures, Multilayer Perceptron (MLP), Transformers, and Long Short-Term Memory (LSTM), to model the temporal evolution of the viscosity coefficients. Validated against a 3D Large Eddy Simulation of a lid-driven cavity, the LSTM-based closure demonstrates superior performance in capturing transient dynamics, achieving relative errors of 0.7\% for velocity and 4\% for turbulent viscosity. The resulting framework effectively combines the mathematical rigor of the consistent flux formulation with the adaptability of deep learning for turbulence modeling.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18817v1</guid></item><item><title>[cs updates on arXiv.org] VAE with Hyperspherical Coordinates: Improving Anomaly Detection from Hypervolume-Compressed Latent Space</title><link>https://arxiv.org/abs/2601.18823</link><description>arXiv:2601.18823v1 Announce Type: new 
Abstract: Variational autoencoders (VAE) encode data into lower-dimensional latent vectors before decoding those vectors back to data. Once trained, one can hope to detect out-of-distribution (abnormal) latent vectors, but several issues arise when the latent space is high dimensional. This includes an exponential growth of the hypervolume with the dimension, which severely affects the generative capacity of the VAE. In this paper, we draw insights from high dimensional statistics: in these regimes, the latent vectors of a standard VAE are distributed on the `equators' of a hypersphere, challenging the detection of anomalies. We propose to formulate the latent variables of a VAE using hyperspherical coordinates, which allows compressing the latent vectors towards a given direction on the hypersphere, thereby allowing for a more expressive approximate posterior. We show that this improves both the fully unsupervised and OOD anomaly detection ability of the VAE, achieving the best performance on the datasets we considered, outperforming existing methods. For the unsupervised and OOD modalities, respectively, these are: i) detecting unusual landscape from the Mars Rover camera and unusual Galaxies from ground based imagery (complex, real world datasets); ii) standard benchmarks like Cifar10 and subsets of ImageNet as the in-distribution (ID) class.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18823v1</guid></item><item><title>[cs updates on arXiv.org] Differential Voting: Loss Functions For Axiomatically Diverse Aggregation of Heterogeneous Preferences</title><link>https://arxiv.org/abs/2601.18824</link><description>arXiv:2601.18824v1 Announce Type: new 
Abstract: Reinforcement learning from human feedback (RLHF) implicitly aggregates heterogeneous human preferences into a single utility function, even though the underlying utilities of the participants are in practice diverse. Hence, RLHF can be viewed as a form of voting, where the aggregation mechanism is defined by the loss function. Although Arrow's Impossibility Theorem suggests that different mechanisms satisfy different sets of desirable axioms, most existing methods rely on a single aggregation principle, typically the Bradley-Terry-Luce (BTL) model, which corresponds to Borda count voting. This restricts the axiomatic properties of the learned reward and obscures the normative assumptions embedded in optimization. In this work, we introduce Differential Voting, a unifying framework that constructs instance-wise, differentiable loss functions whose population-level optima provably correspond to distinct classical voting rules. We develop differentiable surrogates for majority-based aggregation (BTL), Copeland, and Kemeny rules, and formally analyze their calibration properties, gradient fields, and limiting behavior as smoothing parameters vanish. For each loss, we establish consistency with the corresponding social choice rule and characterize the axioms it satisfies or violates. Our analysis shows how design choices in loss geometry-such as margin sensitivity and boundary concentration-directly translate into normative aggregation behavior. Differential Voting makes preference aggregation an explicit and controllable design choice in RLHF, enabling principled trade-offs between axiomatic guarantees and optimization stability. Code to reproduce our experiments is open-sourced.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18824v1</guid></item><item><title>[cs updates on arXiv.org] Automated structural testing of LLM-based agents: methods, framework, and case studies</title><link>https://arxiv.org/abs/2601.18827</link><description>arXiv:2601.18827v1 Announce Type: new 
Abstract: LLM-based agents are rapidly being adopted across diverse domains. Since they interact with users without supervision, they must be tested extensively. Current testing approaches focus on acceptance-level evaluation from the user's perspective. While intuitive, these tests require manual evaluation, are difficult to automate, do not facilitate root cause analysis, and incur expensive test environments. In this paper, we present methods to enable structural testing of LLM-based agents. Our approach utilizes traces (based on OpenTelemetry) to capture agent trajectories, employs mocking to enforce reproducible LLM behavior, and adds assertions to automate test verification. This enables testing agent components and interactions at a deeper technical level within automated workflows. We demonstrate how structural testing enables the adaptation of software engineering best practices to agents, including the test automation pyramid, regression testing, test-driven development, and multi-language testing. In representative case studies, we demonstrate automated execution and faster root-cause analysis. Collectively, these methods reduce testing costs and improve agent quality through higher coverage, reusability, and earlier defect detection. We provide an open source reference implementation on GitHub.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18827v1</guid></item><item><title>[cs updates on arXiv.org] IPBC: An Interactive Projection-Based Framework for Human-in-the-Loop Semi-Supervised Clustering of High-Dimensional Data</title><link>https://arxiv.org/abs/2601.18828</link><description>arXiv:2601.18828v1 Announce Type: new 
Abstract: High-dimensional datasets are increasingly common across scientific and industrial domains, yet they remain difficult to cluster effectively due to the diminishing usefulness of distance metrics and the tendency of clusters to collapse or overlap when projected into lower dimensions. Traditional dimensionality reduction techniques generate static 2D or 3D embeddings that provide limited interpretability and do not offer a mechanism to leverage the analyst's intuition during exploration. To address this gap, we propose Interactive Project-Based Clustering (IPBC), a framework that reframes clustering as an iterative human-guided visual analysis process. IPBC integrates a nonlinear projection module with a feedback loop that allows users to modify the embedding by adjusting viewing angles and supplying simple constraints such as must-link or cannot-link relationships. These constraints reshape the objective of the projection model, gradually pulling semantically related points closer together and pushing unrelated points further apart. As the projection becomes more structured and expressive through user interaction, a conventional clustering algorithm operating on the optimized 2D layout can more reliably identify distinct groups. An additional explainability component then maps each discovered cluster back to the original feature space, producing interpretable rules or feature rankings that highlight what distinguishes each cluster. Experiments on various benchmark datasets show that only a small number of interactive refinement steps can substantially improve cluster quality. Overall, IPBC turns clustering into a collaborative discovery process in which machine representation and human insight reinforce one another.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18828v1</guid></item><item><title>[cs updates on arXiv.org] How Much Temporal Modeling is Enough? A Systematic Study of Hybrid CNN-RNN Architectures for Multi-Label ECG Classification</title><link>https://arxiv.org/abs/2601.18830</link><description>arXiv:2601.18830v1 Announce Type: new 
Abstract: Accurate multi-label classification of electrocardiogram (ECG) signals remains challenging due to the coexistence of multiple cardiac conditions, pronounced class imbalance, and long-range temporal dependencies in multi-lead recordings. Although recent studies increasingly rely on deep and stacked recurrent architectures, the necessity and clinical justification of such architectural complexity have not been rigorously examined. In this work, we perform a systematic comparative evaluation of convolutional neural networks (CNNs) combined with multiple recurrent configurations, including LSTM, GRU, Bidirectional LSTM (BiLSTM), and their stacked variants, for multi-label ECG classification on the PTB-XL dataset comprising 23 diagnostic categories. The CNN component serves as a morphology-driven baseline, while recurrent layers are progressively integrated to assess their contribution to temporal modeling and generalization performance. Experimental results indicate that a CNN integrated with a single BiLSTM layer achieves the most favorable trade-off between predictive performance and model complexity. This configuration attains superior Hamming loss (0.0338), macro-AUPRC (0.4715), micro-F1 score (0.6979), and subset accuracy (0.5723) compared with deeper recurrent combinations. Although stacked recurrent models occasionally improve recall for specific rare classes, our results provide empirical evidence that increasing recurrent depth yields diminishing returns and may degrade generalization due to reduced precision and overfitting. These findings suggest that architectural alignment with the intrinsic temporal structure of ECG signals, rather than increased recurrent depth, is a key determinant of robust performance and clinically relevant deployment.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18830v1</guid></item><item><title>[cs updates on arXiv.org] The Geometric Reasoner: Manifold-Informed Latent Foresight Search for Long-Context Reasoning</title><link>https://arxiv.org/abs/2601.18832</link><description>arXiv:2601.18832v1 Announce Type: new 
Abstract: Scaling test-time compute enhances long chain-of-thought (CoT) reasoning, yet existing approaches face a fundamental trade-off between computational cost and coverage quality: either incurring high training expense or yielding redundant trajectories. We introduce The Geometric Reasoner (TGR), a training-free framework that performs manifold-informed latent foresight search under strict memory bounds. At each chunk boundary, TGR scores candidate latent anchors via a lightweight look-ahead estimate combined with soft geometric regularizers that encourage smooth trajectories and diverse exploration. Chunk-wise KV cache resets keep memory linear in chunk length. On challenging math and code benchmarks, TGR improves robust trajectory coverage, measured by the area under the Pass@$k$ curve (AUC), by up to 13 points on Qwen3-8B, with negligible overhead of about 1.1--1.3 times.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18832v1</guid></item><item><title>[cs updates on arXiv.org] Agentic Business Process Management Systems</title><link>https://arxiv.org/abs/2601.18833</link><description>arXiv:2601.18833v1 Announce Type: new 
Abstract: Since the early 90s, the evolution of the Business Process Management (BPM) discipline has been punctuated by successive waves of automation technologies. Some of these technologies enable the automation of individual tasks, while others focus on orchestrating the execution of end-to-end processes. The rise of Generative and Agentic Artificial Intelligence (AI) is opening the way for another such wave. However, this wave is poised to be different because it shifts the focus from automation to autonomy and from design-driven management of business processes to data-driven management, leveraging process mining techniques. This position paper, based on a keynote talk at the 2025 Workshop on AI for BPM, outlines how process mining has laid the foundations on top of which agents can sense process states, reason about improvement opportunities, and act to maintain and optimize performance. The paper proposes an architectural vision for Agentic Business Process Management Systems (A-BPMS): a new class of platforms that integrate autonomy, reasoning, and learning into process management and execution. The paper contends that such systems must support a continuum of processes, spanning from human-driven to fully autonomous, thus redefining the boundaries of process automation and governance.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18833v1</guid></item><item><title>[cs updates on arXiv.org] CanaryBench: Stress Testing Privacy Leakage in Cluster-Level Conversation Summaries</title><link>https://arxiv.org/abs/2601.18834</link><description>arXiv:2601.18834v1 Announce Type: new 
Abstract: Aggregate analytics over conversational data are increasingly used for safety monitoring, governance, and product analysis in large language model systems. A common practice is to embed conversations, cluster them, and publish short textual summaries describing each cluster. While raw conversations may never be exposed, these derived summaries can still pose privacy risks if they contain personally identifying information (PII) or uniquely traceable strings copied from individual conversations.
  We introduce CanaryBench, a simple and reproducible stress test for privacy leakage in cluster-level conversation summaries. CanaryBench generates synthetic conversations with planted secret strings ("canaries") that simulate sensitive identifiers. Because canaries are known a priori, any appearance of these strings in published summaries constitutes a measurable leak.
  Using TF-IDF embeddings and k-means clustering on 3,000 synthetic conversations (24 topics) with a canary injection rate of 0.60, we evaluate an intentionally extractive example snippet summarizer that models quote-like reporting. In this configuration, we observe canary leakage in 50 of 52 canary-containing clusters (cluster-level leakage rate 0.961538), along with nonzero regex-based PII indicator counts. A minimal defense combining a minimum cluster-size publication threshold (k-min = 25) and regex-based redaction eliminates measured canary leakage and PII indicator hits in the reported run while maintaining a similar cluster-coherence proxy. We position this work as a societal impacts contribution centered on privacy risk measurement for published analytics artifacts rather than raw user data.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18834v1</guid></item><item><title>[cs updates on arXiv.org] Time series forecasting with Hahn Kolmogorov-Arnold networks</title><link>https://arxiv.org/abs/2601.18837</link><description>arXiv:2601.18837v1 Announce Type: new 
Abstract: Recent Transformer- and MLP-based models have demonstrated strong performance in long-term time series forecasting, yet Transformers remain limited by their quadratic complexity and permutation-equivariant attention, while MLPs exhibit spectral bias. We propose HaKAN, a versatile model based on Kolmogorov-Arnold Networks (KANs), leveraging Hahn polynomial-based learnable activation functions and providing a lightweight and interpretable alternative for multivariate time series forecasting. Our model integrates channel independence, patching, a stack of Hahn-KAN blocks with residual connections, and a bottleneck structure comprised of two fully connected layers. The Hahn-KAN block consists of inter- and intra-patch KAN layers to effectively capture both global and local temporal patterns. Extensive experiments on various forecasting benchmarks demonstrate that our model consistently outperforms recent state-of-the-art methods, with ablation studies validating the effectiveness of its core components.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18837v1</guid></item><item><title>[cs updates on arXiv.org] Analysis of Control Bellman Residual Minimization for Markov Decision Problem</title><link>https://arxiv.org/abs/2601.18840</link><description>arXiv:2601.18840v1 Announce Type: new 
Abstract: Markov decision problems are most commonly solved via dynamic programming. Another approach is Bellman residual minimization, which directly minimizes the squared Bellman residual objective function. However, compared to dynamic programming, this approach has received relatively less attention, mainly because it is often less efficient in practice and can be more difficult to extend to model-free settings such as reinforcement learning. Nonetheless, Bellman residual minimization has several advantages that make it worth investigating, such as more stable convergence with function approximation for value functions. While Bellman residual methods for policy evaluation have been widely studied, methods for policy optimization (control tasks) have been scarcely explored. In this paper, we establish foundational results for the control Bellman residual minimization for policy optimization.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18840v1</guid></item><item><title>[cs updates on arXiv.org] GUIGuard: Toward a General Framework for Privacy-Preserving GUI Agents</title><link>https://arxiv.org/abs/2601.18842</link><description>arXiv:2601.18842v1 Announce Type: new 
Abstract: GUI agents enable end-to-end automation through direct perception of and interaction with on-screen interfaces. However, these agents frequently access interfaces containing sensitive personal information, and screenshots are often transmitted to remote models, creating substantial privacy risks. These risks are particularly severe in GUI workflows: GUIs expose richer, more accessible private information, and privacy risks depend on interaction trajectories across sequential scenes. We propose GUIGuard, a three-stage framework for privacy-preserving GUI agents: (1) privacy recognition, (2) privacy protection, and (3) task execution under protection. We further construct GUIGuard-Bench, a cross-platform benchmark with 630 trajectories and 13,830 screenshots, annotated with region-level privacy grounding and fine-grained labels of risk level, privacy category, and task necessity. Evaluations reveal that existing agents exhibit limited privacy recognition, with state-of-the-art models achieving only 13.3% accuracy on Android and 1.4% on PC. Under privacy protection, task-planning semantics can still be maintained, with closed-source models showing stronger semantic consistency than open-source ones. Case studies on MobileWorld show that carefully designed protection strategies achieve higher task accuracy while preserving privacy. Our results highlight privacy recognition as a critical bottleneck for practical GUI agents. Project: https://futuresis.github.io/GUIGuard-page/</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18842v1</guid></item><item><title>[cs updates on arXiv.org] Reducing False Positives in Static Bug Detection with LLMs: An Empirical Study in Industry</title><link>https://arxiv.org/abs/2601.18844</link><description>arXiv:2601.18844v1 Announce Type: new 
Abstract: Static analysis tools (SATs) are widely adopted in both academia and industry for improving software quality, yet their practical use is often hindered by high false positive rates, especially in large-scale enterprise systems. These false alarms demand substantial manual inspection, creating severe inefficiencies in industrial code review. While recent work has demonstrated the potential of large language models (LLMs) for false alarm reduction on open-source benchmarks, their effectiveness in real-world enterprise settings remains unclear. To bridge this gap, we conduct the first comprehensive empirical study of diverse LLM-based false alarm reduction techniques in an industrial context at Tencent, one of the largest IT companies in China. Using data from Tencent's enterprise-customized SAT on its large-scale Advertising and Marketing Services software, we construct a dataset of 433 alarms (328 false positives, 105 true positives) covering three common bug types. Through interviewing developers and analyzing the data, our results highlight the prevalence of false positives, which wastes substantial manual effort (e.g., 10-20 minutes of manual inspection per alarm). Meanwhile, our results show the huge potential of LLMs for reducing false alarms in industrial settings (e.g., hybrid techniques of LLM and static analysis eliminate 94-98% of false positives with high recall). Furthermore, LLM-based techniques are cost-effective, with per-alarm costs as low as 2.1-109.5 seconds and $0.0011-$0.12, representing orders-of-magnitude savings compared to manual review. Finally, our case analysis further identifies key limitations of LLM-based false alarm reduction in industrial settings.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18844v1</guid></item><item><title>[cs updates on arXiv.org] Dynamic Mask-Based Backdoor Attack Against Vision AI Models: A Case Study on Mushroom Detection</title><link>https://arxiv.org/abs/2601.18845</link><description>arXiv:2601.18845v1 Announce Type: new 
Abstract: Deep learning has revolutionized numerous tasks within the computer vision field, including image classification, image segmentation, and object detection. However, the increasing deployment of deep learning models has exposed them to various adversarial attacks, including backdoor attacks. This paper presents a novel dynamic mask-based backdoor attack method, specifically designed for object detection models. We exploit a dataset poisoning technique to embed a malicious trigger, rendering any models trained on this compromised dataset vulnerable to our backdoor attack. We particularly focus on a mushroom detection dataset to demonstrate the practical risks posed by such attacks on critical real-life domains. Our work also emphasizes the importance of creating a detailed backdoor attack scenario to illustrate the significant risks associated with the outsourcing practice. Our approach leverages SAM, a recent and powerful image segmentation AI model, to create masks for dynamic trigger placement, introducing a new and stealthy attack method. Through extensive experimentation, we show that our sophisticated attack scenario maintains high accuracy on clean data with the YOLOv7 object detection model while achieving high attack success rates on poisoned samples. Our approach surpasses traditional methods for backdoor injection, which are based on static and consistent patterns. Our findings underscore the urgent need for robust countermeasures to protect deep learning models from these evolving adversarial threats.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18845v1</guid></item><item><title>[cs updates on arXiv.org] LLM Driven Design of Continuous Optimization Problems with Controllable High-level Properties</title><link>https://arxiv.org/abs/2601.18846</link><description>arXiv:2601.18846v1 Announce Type: new 
Abstract: Benchmarking in continuous black-box optimisation is hindered by the limited structural diversity of existing test suites such as BBOB. We explore whether large language models embedded in an evolutionary loop can be used to design optimisation problems with clearly defined high-level landscape characteristics. Using the LLaMEA framework, we guide an LLM to generate problem code from natural-language descriptions of target properties, including multimodality, separability, basin-size homogeneity, search-space homogeneity and globallocal optima contrast. Inside the loop we score candidates through ELA-based property predictors. We introduce an ELA-space fitness-sharing mechanism that increases population diversity and steers the generator away from redundant landscapes. A complementary basin-of-attraction analysis, statistical testing and visual inspection, verifies that many of the generated functions indeed exhibit the intended structural traits. In addition, a t-SNE embedding shows that they expand the BBOB instance space rather than forming an unrelated cluster. The resulting library provides a broad, interpretable, and reproducible set of benchmark problems for landscape analysis and downstream tasks such as automated algorithm selection.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18846v1</guid></item><item><title>[cs updates on arXiv.org] MulVul: Retrieval-augmented Multi-Agent Code Vulnerability Detection via Cross-Model Prompt Evolution</title><link>https://arxiv.org/abs/2601.18847</link><description>arXiv:2601.18847v1 Announce Type: new 
Abstract: Large Language Models (LLMs) struggle to automate real-world vulnerability detection due to two key limitations: the heterogeneity of vulnerability patterns undermines the effectiveness of a single unified model, and manual prompt engineering for massive weakness categories is unscalable.
  To address these challenges, we propose \textbf{MulVul}, a retrieval-augmented multi-agent framework designed for precise and broad-coverage vulnerability detection. MulVul adopts a coarse-to-fine strategy: a \emph{Router} agent first predicts the top-$k$ coarse categories and then forwards the input to specialized \emph{Detector} agents, which identify the exact vulnerability types. Both agents are equipped with retrieval tools to actively source evidence from vulnerability knowledge bases to mitigate hallucinations.
  Crucially, to automate the generation of specialized prompts, we design \emph{Cross-Model Prompt Evolution}, a prompt optimization mechanism where a generator LLM iteratively refines candidate prompts while a distinct executor LLM validates their effectiveness. This decoupling mitigates the self-correction bias inherent in single-model optimization.
  Evaluated on 130 CWE types, MulVul achieves 34.79\% Macro-F1, outperforming the best baseline by 41.5\%. Ablation studies validate cross-model prompt evolution, which boosts performance by 51.6\% over manual prompts by effectively handling diverse vulnerability patterns.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18847v1</guid></item><item><title>[cs updates on arXiv.org] Audio-Driven Talking Face Generation with Blink Embedding and Hash Grid Landmarks Encoding</title><link>https://arxiv.org/abs/2601.18849</link><description>arXiv:2601.18849v1 Announce Type: new 
Abstract: Dynamic Neural Radiance Fields (NeRF) have demonstrated considerable success in generating high-fidelity 3D models of talking portraits. Despite significant advancements in the rendering speed and generation quality, challenges persist in accurately and efficiently capturing mouth movements in talking portraits. To tackle this challenge, we propose an automatic method based on blink embedding and hash grid landmarks encoding in this study, which can substantially enhance the fidelity of talking faces. Specifically, we leverage facial features encoded as conditional features and integrate audio features as residual terms into our model through a Dynamic Landmark Transformer. Furthermore, we employ neural radiance fields to model the entire face, resulting in a lifelike face representation. Experimental evaluations have validated the superiority of our approach to existing methods.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18849v1</guid></item><item><title>[cs updates on arXiv.org] Towards Safety-Compliant Transformer Architectures for Automotive Systems</title><link>https://arxiv.org/abs/2601.18850</link><description>arXiv:2601.18850v1 Announce Type: new 
Abstract: Transformer-based architectures have shown remarkable performance in vision and language tasks but pose unique challenges for safety-critical applications. This paper presents a conceptual framework for integrating Transformers into automotive systems from a safety perspective. We outline how multimodal Foundation Models can leverage sensor diversity and redundancy to improve fault tolerance and robustness. Our proposed architecture combines multiple independent modality-specific encoders that fuse their representations into a shared latent space, supporting fail-operational behavior if one modality degrades. We demonstrate how different input modalities could be fused in order to maintain consistent scene understanding. By structurally embedding redundancy and diversity at the representational level, this approach bridges the gap between modern deep learning and established functional safety practices, paving the way for certifiable AI systems in autonomous driving.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18850v1</guid></item><item><title>[cs updates on arXiv.org] SelfieAvatar: Real-time Head Avatar reenactment from a Selfie Video</title><link>https://arxiv.org/abs/2601.18851</link><description>arXiv:2601.18851v1 Announce Type: new 
Abstract: Head avatar reenactment focuses on creating animatable personal avatars from monocular videos, serving as a foundational element for applications like social signal understanding, gaming, human-machine interaction, and computer vision. Recent advances in 3D Morphable Model (3DMM)-based facial reconstruction methods have achieved remarkable high-fidelity face estimation. However, on the one hand, they struggle to capture the entire head, including non-facial regions and background details in real time, which is an essential aspect for producing realistic, high-fidelity head avatars. On the other hand, recent approaches leveraging generative adversarial networks (GANs) for head avatar generation from videos can achieve high-quality reenactments but encounter limitations in reproducing fine-grained head details, such as wrinkles and hair textures. In addition, existing methods generally rely on a large amount of training data, and rarely focus on using only a simple selfie video to achieve avatar reenactment. To address these challenges, this study introduces a method for detailed head avatar reenactment using a selfie video. The approach combines 3DMMs with a StyleGAN-based generator. A detailed reconstruction model is proposed, incorporating mixed loss functions for foreground reconstruction and avatar image generation during adversarial training to recover high-frequency details. Qualitative and quantitative evaluations on self-reenactment and cross-reenactment tasks demonstrate that the proposed method achieves superior head avatar reconstruction with rich and intricate textures compared to existing approaches.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18851v1</guid></item><item><title>[cs updates on arXiv.org] Representational Homomorphism Predicts and Improves Compositional Generalization In Transformer Language Model</title><link>https://arxiv.org/abs/2601.18858</link><description>arXiv:2601.18858v1 Announce Type: new 
Abstract: Compositional generalization-the ability to interpret novel combinations of familiar components-remains a persistent challenge for neural networks. Behavioral evaluations reveal when models fail but offer limited insight into why failures arise at the representational level. We introduce Homomorphism Error (HE), a structural metric that quantifies deviations from approximate homomorphisms between the expression algebra and a model's hidden-state space. We instantiate HE for two compositional operators in SCAN-style tasks: modifier HE for unary composition and sequence HE for binary composition, measured by learning representation-level operators that predict composed representations from their parts. Across controlled experiments with small decoder-only Transformers, HE predicts out-of-distribution (OOD) compositional generalization under noise injection, achieving R^2 = 0.73 correlation between modifier HE and OOD accuracy. Ablations show that model depth has minimal effect on either HE or OOD accuracy, training data coverage exhibits threshold effects (insufficient coverage sharply increases HE and degrades OOD performance), and randomly inserted noise tokens systematically increase HE. Finally, we test if HE-regularized training improves OOD accuracy. Experiment shows that explicitly enforcing low modifier HE during training significantly reduces modifier HE (p = 1.1x10-4) and sequence HE (p = 0.001) and yields a statistically significant improvement in OOD accuracy (p = 0.023). Together, these results indicate the potential of HE to be both a diagnostic and an actionable training signal for improving compositional generalization. Code to reproduce our experiments is open-sourced.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18858v1</guid></item><item><title>[cs updates on arXiv.org] XProvence: Zero-Cost Multilingual Context Pruning for Retrieval-Augmented Generation</title><link>https://arxiv.org/abs/2601.18886</link><description>arXiv:2601.18886v1 Announce Type: new 
Abstract: This paper introduces XProvence, a multilingual zero-cost context pruning model for retrieval-augmented generation (RAG), trained on 16 languages and supporting 100+ languages through effective cross-lingual transfer. Motivated by the growing use of RAG systems across diverse languages, we explore several strategies to generalize the Provence framework-which first integrated efficient zero-cost context pruning directly into the re-ranking model-beyond English. Across four multilingual question answering benchmarks, we show how XProvence can prune RAG contexts with minimal-to-no performance degradation and outperforms strong baselines. Our model is available at https://huggingface.co/naver/xprovence-reranker-bgem3-v2.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18886v1</guid></item><item><title>[cs updates on arXiv.org] Weakly supervised framework for wildlife detection and counting in challenging Arctic environments: a case study on caribou (Rangifer tarandus)</title><link>https://arxiv.org/abs/2601.18891</link><description>arXiv:2601.18891v1 Announce Type: new 
Abstract: Caribou across the Arctic has declined in recent decades, motivating scalable and accurate monitoring approaches to guide evidence-based conservation actions and policy decisions. Manual interpretation from this imagery is labor-intensive and error-prone, underscoring the need for automatic and reliable detection across varying scenes. Yet, such automatic detection is challenging due to severe background heterogeneity, dominant empty terrain (class imbalance), small or occluded targets, and wide variation in density and scale. To make the detection model (HerdNet) more robust to these challenges, a weakly supervised patch-level pretraining based on a detection network's architecture is proposed. The detection dataset includes five caribou herds distributed across Alaska. By learning from empty vs. non-empty labels in this dataset, the approach produces early weakly supervised knowledge for enhanced detection compared to HerdNet, which is initialized from generic weights. Accordingly, the patch-based pretrain network attained high accuracy on multi-herd imagery (2017) and on an independent year's (2019) test sets (F1: 93.7%/92.6%, respectively), enabling reliable mapping of regions containing animals to facilitate manual counting on large aerial imagery. Transferred to detection, initialization from weakly supervised pretraining yielded consistent gains over ImageNet weights on both positive patches (F1: 92.6%/93.5% vs. 89.3%/88.6%), and full-image counting (F1: 95.5%/93.3% vs. 91.5%/90.4%). Remaining limitations are false positives from animal-like background clutter and false negatives related to low animal density occlusions. Overall, pretraining on coarse labels prior to detection makes it possible to rely on weakly-supervised pretrained weights even when labeled data are limited, achieving results comparable to generic-weight initialization.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18891v1</guid></item><item><title>[cs updates on arXiv.org] Explainable Uncertainty Quantification for Wastewater Treatment Energy Prediction via Interval Type-2 Neuro-Fuzzy System</title><link>https://arxiv.org/abs/2601.18897</link><description>arXiv:2601.18897v1 Announce Type: new 
Abstract: Wastewater treatment plants consume 1-3% of global electricity, making accurate energy forecasting critical for operational optimization and sustainability. While machine learning models provide point predictions, they lack explainable uncertainty quantification essential for risk-aware decision-making in safety-critical infrastructure. This study develops an Interval Type-2 Adaptive Neuro-Fuzzy Inference System (IT2-ANFIS) that generates interpretable prediction intervals through fuzzy rule structures. Unlike black-box probabilistic methods, the proposed framework decomposes uncertainty across three levels: feature-level, footprint of uncertainty identify which variables introduce ambiguity, rule-level analysis reveals confidence in local models, and instance-level intervals quantify overall prediction uncertainty. Validated on Melbourne Water's Eastern Treatment Plant dataset, IT2-ANFIS achieves comparable predictive performance to first order ANFIS with substantially reduced variance across training runs, while providing explainable uncertainty estimates that link prediction confidence directly to operational conditions and input variables.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18897v1</guid></item><item><title>[cs updates on arXiv.org] Language Family Matters: Evaluating LLM-Based ASR Across Linguistic Boundaries</title><link>https://arxiv.org/abs/2601.18899</link><description>arXiv:2601.18899v1 Announce Type: new 
Abstract: Large Language Model (LLM)-powered Automatic Speech Recognition (ASR) systems achieve strong performance with limited resources by linking a frozen speech encoder to a pretrained LLM via a lightweight connector. Prior work trains a separate connector per language, overlooking linguistic relatedness. We propose an efficient and novel connector-sharing strategy based on linguistic family membership, enabling one connector per family, and empirically validate its effectiveness across two multilingual LLMs and two real-world corpora spanning curated and crowd-sourced speech. Our results show that family-based connectors reduce parameter count while improving generalization across domains, offering a practical and scalable strategy for multilingual ASR deployment.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18899v1</guid></item><item><title>[cs updates on arXiv.org] RealStats: A Rigorous Real-Only Statistical Framework for Fake Image Detection</title><link>https://arxiv.org/abs/2601.18900</link><description>arXiv:2601.18900v1 Announce Type: new 
Abstract: As generative models continue to evolve, detecting AI-generated images remains a critical challenge. While effective detection methods exist, they often lack formal interpretability and may rely on implicit assumptions about fake content, potentially limiting robustness to distributional shifts. In this work, we introduce a rigorous, statistically grounded framework for fake image detection that focuses on producing a probability score interpretable with respect to the real-image population. Our method leverages the strengths of multiple existing detectors by combining training-free statistics. We compute p-values over a range of test statistics and aggregate them using classical statistical ensembling to assess alignment with the unified real-image distribution. This framework is generic, flexible, and training-free, making it well-suited for robust fake image detection across diverse and evolving settings.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18900v1</guid></item><item><title>[cs updates on arXiv.org] Flatter Tokens are More Valuable for Speculative Draft Model Training</title><link>https://arxiv.org/abs/2601.18902</link><description>arXiv:2601.18902v1 Announce Type: new 
Abstract: Speculative Decoding (SD) is a key technique for accelerating Large Language Model (LLM) inference, but it typically requires training a draft model on a large dataset. We approach this problem from a data-centric perspective, finding that not all training samples contribute equally to the SD acceptance rate. Specifically, our theoretical analysis and empirical validation reveals that tokens inducing flatter predictive distributions from the target model are more valuable than those yielding sharply peaked distributions. Based on this insight, we propose flatness, a new metric to quantify this property, and develop the Sample-level-flatness-based Dataset Distillation (SFDD) approach, which filters the training data to retain only the most valuable samples. Experiments on the EAGLE framework demonstrate that SFDD can achieve over 2$\times$ training speedup using only 50% of the data, while keeping the final model's inference speedup within 4% of the full-dataset baseline. This work introduces an effective, data-centric approach that substantially improves the training efficiency for Speculative Decoding. Our code is available at https://anonymous.4open.science/r/Flatness.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18902v1</guid></item><item><title>[cs updates on arXiv.org] SICL-AT: Another way to adapt Auditory LLM to low-resource task</title><link>https://arxiv.org/abs/2601.18904</link><description>arXiv:2601.18904v1 Announce Type: new 
Abstract: Auditory Large Language Models (LLMs) have demonstrated strong performance across a wide range of speech and audio understanding tasks. Nevertheless, they often struggle when applied to low-resource or unfamiliar tasks. In case of labeled in-domain data is scarce or mismatched to the true test distribution, direct fine-tuning can be brittle. In-Context Learning (ICL) provides a training-free, inference-time solution by adapting auditory LLMs through conditioning on a few in-domain demonstrations. In this work, we first show that \emph{Vanilla ICL}, improves zero-shot performance across diverse speech and audio tasks for selected models which suggest this ICL adaptation capability can be generalized to multimodal setting. Building on this, we propose \textbf{Speech In-Context Learning Adaptation Training (SICL-AT)}, a post-training recipe utilizes only high resource speech data intending to strengthen model's in-context learning capability. The enhancement can generalize to audio understanding/reasoning task. Experiments indicate our proposed method consistently outperforms direct fine-tuning in low-resource scenario.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18904v1</guid></item><item><title>[cs updates on arXiv.org] Enhancing Speech Emotion Recognition using Dynamic Spectral Features and Kalman Smoothing</title><link>https://arxiv.org/abs/2601.18908</link><description>arXiv:2601.18908v1 Announce Type: new 
Abstract: Speech Emotion Recognition systems often use static features like Mel-Frequency Cepstral Coefficients (MFCCs), Zero Crossing Rate (ZCR), and Root Mean Square Energy (RMSE). Because of this, they can misclassify emotions when there is acoustic noise in vocal signals. To address this, we added dynamic features using Dynamic Spectral features (Deltas and Delta-Deltas) along with the Kalman Smoothing algorithm. This approach reduces noise and improves emotion classification. Since emotion changes over time, the Kalman Smoothing filter also helped make the classifier outputs more stable. Tests on the RAVDESS dataset showed that this method achieved a state-of-the-art accuracy of 87\% and reduced misclassification between emotions with similar acoustic features</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18908v1</guid></item><item><title>[cs updates on arXiv.org] How Is Uncertainty Propagated in Knowledge Distillation?</title><link>https://arxiv.org/abs/2601.18909</link><description>arXiv:2601.18909v1 Announce Type: new 
Abstract: Knowledge distillation transfers behavior from a teacher to a student model, but the process is inherently stochastic: teacher outputs, student training, and student inference can all be random. Collapsing these uncertainties to a single point estimate can distort what is learned. We systematically study how uncertainty propagates through knowledge distillation across three representative model classes--linear regression, feed-forward neural networks, and large language models (LLMs)--and propose simple corrections. We distinguish inter-student uncertainty (variance across independently distilled students) from intra-student uncertainty (variance of a single student's predictive distribution), showing that standard single-response knowledge distillation suppresses intra-student variance while leaving substantial inter-student variability. To address these mismatches, we introduce two variance-aware strategies: averaging multiple teacher responses, which reduces noise at rate $O(1/k)$, and variance-weighting, which combines teacher and student estimates via inverse-variance weighting to yield a minimum-variance estimator. We provide formal guarantees in linear regression, validate the methods in neural networks, and demonstrate empirical gains in LLM distillation, including reduced systematic noise and hallucination. These results reframe knowledge distillation as an uncertainty transformation and show that variance-aware distillation produces more stable students that better reflect teacher uncertainty.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18909v1</guid></item><item><title>[cs updates on arXiv.org] ASEHybrid: When Geometry Matters Beyond Homophily in Graph Neural Networks</title><link>https://arxiv.org/abs/2601.18912</link><description>arXiv:2601.18912v1 Announce Type: new 
Abstract: Standard message-passing graph neural networks (GNNs) often struggle on graphs with low homophily, yet homophily alone does not explain this behavior, as graphs with similar homophily levels can exhibit markedly different performance and some heterophilous graphs remain easy for vanilla GCNs. Recent work suggests that label informativeness (LI), the mutual information between labels of adjacent nodes, provides a more faithful characterization of when graph structure is useful. In this work, we develop a unified theoretical framework that connects curvature-guided rewiring and positional geometry through the lens of label informativeness, and instantiate it in a practical geometry-aware architecture, ASEHybrid. Our analysis provides a necessary-and-sufficient characterization of when geometry-aware GNNs can improve over feature-only baselines: such gains are possible if and only if graph structure carries label-relevant information beyond node features. Theoretically, we relate adjusted homophily and label informativeness to the spectral behavior of label signals under Laplacian smoothing, show that degree-based Forman curvature does not increase expressivity beyond the one-dimensional Weisfeiler--Lehman test but instead reshapes information flow, and establish convergence and Lipschitz stability guarantees for a curvature-guided rewiring process. Empirically, we instantiate ASEHybrid using Forman curvature and Laplacian positional encodings and conduct controlled ablations on Chameleon, Squirrel, Texas, Tolokers, and Minesweeper, observing gains precisely on label-informative heterophilous benchmarks where graph structure provides label-relevant information beyond node features, and no meaningful improvement in high-baseline regimes.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18912v1</guid></item><item><title>[cs updates on arXiv.org] Learning the Pareto Space of Multi-Objective Autonomous Driving: A Modular, Data-Driven Approach</title><link>https://arxiv.org/abs/2601.18913</link><description>arXiv:2601.18913v1 Announce Type: new 
Abstract: Balancing safety, efficiency, and interaction is fundamental to designing autonomous driving agents and to understanding autonomous vehicle (AV) behavior in real-world operation. This study introduces an empirical learning framework that derives these trade-offs directly from naturalistic trajectory data. A unified objective space represents each AV timestep through composite scores of safety, efficiency, and interaction. Pareto dominance is applied to identify non-dominated states, forming an empirical frontier that defines the attainable region of balanced performance.
  The proposed framework was demonstrated using the Third Generation Simulation (TGSIM) datasets from Foggy Bottom and I-395. Results showed that only 0.23\% of AV driving instances were Pareto-optimal, underscoring the rarity of simultaneous optimization across objectives. Pareto-optimal states showed notably higher mean scores for safety, efficiency, and interaction compared to non-optimal cases, with interaction showing the greatest potential for improvement.
  This minimally invasive and modular framework, which requires only kinematic and positional data, can be directly applied beyond the scope of this study to derive and visualize multi-objective learning surfaces</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18913v1</guid></item><item><title>[cs updates on arXiv.org] GraIP: A Benchmarking Framework For Neural Graph Inverse Problems</title><link>https://arxiv.org/abs/2601.18917</link><description>arXiv:2601.18917v1 Announce Type: new 
Abstract: A wide range of graph learning tasks, such as structure discovery, temporal graph analysis, and combinatorial optimization, focus on inferring graph structures from data, rather than making predictions on given graphs. However, the respective methods to solve such problems are often developed in an isolated, task-specific manner and thus lack a unifying theoretical foundation. Here, we provide a stepping stone towards the formation of such a foundation and further development by introducing the Neural Graph Inverse Problem (GraIP) conceptual framework, which formalizes and reframes a broad class of graph learning tasks as inverse problems. Unlike discriminative approaches that directly predict target variables from given graph inputs, the GraIP paradigm addresses inverse problems, i.e., it relies on observational data and aims to recover the underlying graph structure by reversing the forward process, such as message passing or network dynamics, that produced the observed outputs. We demonstrate the versatility of GraIP across various graph learning tasks, including rewiring, causal discovery, and neural relational inference. We also propose benchmark datasets and metrics for each GraIP domain considered, and characterize and empirically evaluate existing baseline methods used to solve them. Overall, our unifying perspective bridges seemingly disparate applications and provides a principled approach to structural learning in constrained and combinatorial settings while encouraging cross-pollination of existing methods across graph inverse problems.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18917v1</guid></item><item><title>[cs updates on arXiv.org] One Global Model, Many Behaviors: Stockout-Aware Feature Engineering and Dynamic Scaling for Multi-Horizon Retail Demand Forecasting with a Cost-Aware Ordering Policy (VN2 Winner Report)</title><link>https://arxiv.org/abs/2601.18919</link><description>arXiv:2601.18919v1 Announce Type: new 
Abstract: Inventory planning for retail chains requires translating demand forecasts into ordering decisions, including asymmetric shortages and holding costs. The VN2 Inventory Planning Challenge formalizes this setting as a weekly decision-making cycle with a two-week product delivery lead time, where the total cost is defined as the shortage cost plus the holding cost. This report presents the winning VN2 solution: a two-stage predict-then-optimize pipeline that combines a single global multi-horizon forecasting model with a cost-aware ordering policy. The forecasting model is trained in a global paradigm, jointly using all available time series. A gradient-boosted decision tree (GBDT) model implemented in CatBoost is used as the base learner. The model incorporates stockout-aware feature engineering to address censored demand during out-of-stock periods, per-series scaling to focus learning on time-series patterns rather than absolute levels, and time-based observation weights to reflect shifts in demand patterns. In the decision stage, inventory is projected to the start of the delivery week, and a target stock level is calculated that explicitly trades off shortage and holding costs. Evaluated by the official competition simulation in six rounds, the solution achieved first place by combining a strong global forecasting model with a lightweight cost-aware policy. Although developed for the VN2 setting, the proposed approach can be extended to real-world applications and additional operational constraints.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18919v1</guid></item><item><title>[cs updates on arXiv.org] Belief-Combining Framework for Multi-Trace Reconstruction over Channels with Insertions, Deletions, and Substitutions</title><link>https://arxiv.org/abs/2601.18920</link><description>arXiv:2601.18920v1 Announce Type: new 
Abstract: Optimal reconstruction of a source sequence from multiple noisy traces corrupted by random insertions, deletions, and substitutions typically requires joint processing of all traces, leading to computational complexity that grows exponentially with the number of traces. In this work, we propose an iterative belief-combining procedure that computes symbol-wise a posteriori probabilities by propagating trace-wise inferences via message passing. We prove that, upon convergence, our method achieves the same reconstruction performance as joint maximum a posteriori estimation, while reducing the complexity to quadratic in the number of traces. This performance equivalence is validated using a real-world dataset of clustered short-strand DNA reads.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18920v1</guid></item><item><title>[cs updates on arXiv.org] Accelerating Large-Scale Cheminformatics Using a Byte-Offset Indexing Architecture for Terabyte-Scale Data Integration</title><link>https://arxiv.org/abs/2601.18921</link><description>arXiv:2601.18921v1 Announce Type: new 
Abstract: The integration of large-scale chemical databases represents a critical bottleneck in modern cheminformatics research, particularly for machine learning applications requiring high-quality, multi-source validated datasets. This paper presents a case study of integrating three major public chemical repositories: PubChem (176 million compounds), ChEMBL, and eMolecules, to construct a curated dataset for molecular property prediction. We investigate whether byte-offset indexing can practically overcome brute-force scalability limits while preserving data integrity at hundred-million scale. Our results document the progression from an intractable brute-force search algorithm with projected 100-day runtime to a byte-offset indexing architecture achieving 3.2-hour completion-a 740-fold performance improvement through algorithmic complexity reduction from O(NxM) to O(N+M). Systematic validation of 176 million database entries revealed hash collisions in InChIKey molecular identifiers, necessitating pipeline reconstruction using collision-free full InChI strings. We present performance benchmarks, quantify trade-offs between storage overhead and scientific rigor, and compare our approach with alternative large-scale integration strategies. The resulting system successfully extracted 435,413 validated compounds and demonstrates generalizable principles for large-scale scientific data integration where uniqueness constraints exceed hash-based identifier capabilities.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18921v1</guid></item><item><title>[cs updates on arXiv.org] DeFM: Learning Foundation Representations from Depth for Robotics</title><link>https://arxiv.org/abs/2601.18923</link><description>arXiv:2601.18923v1 Announce Type: new 
Abstract: Depth sensors are widely deployed across robotic platforms, and advances in fast, high-fidelity depth simulation have enabled robotic policies trained on depth observations to achieve robust sim-to-real transfer for a wide range of tasks. Despite this, representation learning for depth modality remains underexplored compared to RGB, where large-scale foundation models now define the state of the art. To address this gap, we present DeFM, a self-supervised foundation model trained entirely on depth images for robotic applications. Using a DINO-style self-distillation objective on a curated dataset of 60M depth images, DeFM learns geometric and semantic representations that generalize to diverse environments, tasks, and sensors. To retain metric awareness across multiple scales, we introduce a novel input normalization strategy. We further distill DeFM into compact models suitable for resource-constrained robotic systems. When evaluated on depth-based classification, segmentation, navigation, locomotion, and manipulation benchmarks, DeFM achieves state-of-the-art performance and demonstrates strong generalization from simulation to real-world environments. We release all our pretrained models, which can be adopted off-the-shelf for depth-based robotic learning without task-specific fine-tuning. Webpage: https://de-fm.github.io/</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18923v1</guid></item><item><title>[cs updates on arXiv.org] RIFT: Reordered Instruction Following Testbed To Evaluate Instruction Following in Singular Multistep Prompt Structures</title><link>https://arxiv.org/abs/2601.18924</link><description>arXiv:2601.18924v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly relied upon for complex workflows, yet their ability to maintain flow of instructions remains underexplored. Existing benchmarks conflate task complexity with structural ordering, making it difficult to isolate the impact of prompt topology on performance. We introduce RIFT, Reordered Instruction Following Testbed, to assess instruction following by disentangling structure from content. Using rephrased Jeopardy! question-answer pairs, we test LLMs across two prompt structures: linear prompts, which progress sequentially, and jumping prompts, which preserve identical content but require non-sequential traversal. Across 10,000 evaluations spanning six state-of-the-art open-source LLMs, accuracy dropped by up to 72% under jumping conditions (compared to baseline), revealing a strong dependence on positional continuity. Error analysis shows that approximately 50% of failures stem from instruction-order violations and semantic drift, indicating that current architectures internalize instruction following as a sequential pattern rather than a reasoning skill. These results reveal structural sensitivity as a fundamental limitation in current architectures, with direct implications for applications requiring non-sequential control flow such as workflow automation and multi-agent systems.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18924v1</guid></item><item><title>[cs updates on arXiv.org] On the Role of Depth in Surgical Vision Foundation Models: An Empirical Study of RGB-D Pre-training</title><link>https://arxiv.org/abs/2601.18929</link><description>arXiv:2601.18929v1 Announce Type: new 
Abstract: Vision foundation models (VFMs) have emerged as powerful tools for surgical scene understanding. However, current approaches predominantly rely on unimodal RGB pre-training, overlooking the complex 3D geometry inherent to surgical environments. Although several architectures support multimodal or geometry-aware inputs in general computer vision, the benefits of incorporating depth information in surgical settings remain underexplored. We conduct a large-scale empirical study comparing eight ViT-based VFMs that differ in pre-training domain, learning objective, and input modality (RGB vs. RGB-D). For pre-training, we use a curated dataset of 1.4 million robotic surgical images paired with depth maps generated from an off-the-shelf network. We evaluate these models under both frozen-backbone and end-to-end fine-tuning protocols across eight surgical datasets spanning object detection, segmentation, depth estimation, and pose estimation. Our experiments yield several consistent findings. Models incorporating explicit geometric tokenization, such as MultiMAE, substantially outperform unimodal baselines across all tasks. Notably, geometric-aware pre-training enables remarkable data efficiency: models fine-tuned on just 25% of labeled data consistently surpass RGB-only models trained on the full dataset. Importantly, these gains require no architectural or runtime changes at inference; depth is used only during pre-training, making adoption straightforward. These findings suggest that multimodal pre-training offers a viable path towards building more capable surgical vision systems.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18929v1</guid></item><item><title>[cs updates on arXiv.org] Toward Learning POMDPs Beyond Full-Rank Actions and State Observability</title><link>https://arxiv.org/abs/2601.18930</link><description>arXiv:2601.18930v1 Announce Type: new 
Abstract: We are interested in enabling autonomous agents to learn and reason about systems with hidden states, such as furniture with hidden locking mechanisms. We cast this problem as learning the parameters of a discrete Partially Observable Markov Decision Process (POMDP). The agent begins with knowledge of the POMDP's actions and observation spaces, but not its state space, transitions, or observation models. These properties must be constructed from action-observation sequences. Spectral approaches to learning models of partially observable domains, such as learning Predictive State Representations (PSRs), are known to directly estimate the number of hidden states. These methods cannot, however, yield direct estimates of transition and observation likelihoods, which are important for many downstream reasoning tasks. Other approaches leverage tensor decompositions to estimate transition and observation likelihoods but often assume full state observability and full-rank transition matrices for all actions. To relax these assumptions, we study how PSRs learn transition and observation matrices up to a similarity transform, which may be estimated via tensor methods. Our method learns observation matrices and transition matrices up to a partition of states, where the states in a single partition have the same observation distributions corresponding to actions whose transition matrices are full-rank. Our experiments suggest that these partition-level transition models learned by our method, with a sufficient amount of data, meets the performance of PSRs as models to be used by standard sampling-based POMDP solvers. Furthermore, the explicit observation and transition likelihoods can be leveraged to specify planner behavior after the model has been learned.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18930v1</guid></item><item><title>[cs updates on arXiv.org] BabyReasoningBench: Generating Developmentally-Inspired Reasoning Tasks for Evaluating Baby Language Models</title><link>https://arxiv.org/abs/2601.18933</link><description>arXiv:2601.18933v1 Announce Type: new 
Abstract: Traditional evaluations of reasoning capabilities of language models are dominated by adult-centric benchmarks that presuppose broad world knowledge, complex instruction following, and mature pragmatic competence. These assumptions are mismatched to baby language models trained on developmentally plausible input such as child-directed speech and early-childhood narratives, and they obscure which reasoning abilities (if any) emerge under such constraints. We introduce BabyReasoningBench, a GPT-5.2 generated benchmark of 19 reasoning tasks grounded in classic paradigms from developmental psychology, spanning theory of mind, analogical and relational reasoning, causal inference and intervention selection, and core reasoning primitives that are known to be confounded by memory and pragmatics. We find that two GPT-2 based baby language models (pretrained on 10M and 100M of child-directed speech text) show overall low but uneven performance, with dissociations across task families: scaling improves several causal and physical reasoning tasks, while belief attribution and pragmatics-sensitive tasks remain challenging. BabyReasoningBench provides a developmentally grounded lens for analyzing what kinds of reasoning are supported by child-like training distributions, and for testing mechanistic hypotheses about how such abilities emerge.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18933v1</guid></item><item><title>[cs updates on arXiv.org] Whispering Water: Materializing Human-AI Dialogue as Interactive Ripples</title><link>https://arxiv.org/abs/2601.18934</link><description>arXiv:2601.18934v1 Announce Type: new 
Abstract: Across cultures, water has served as a recipient of human confession, a yielding medium that receives vulnerability where rigid surfaces cannot. We present Whispering Water, an interactive installation that materializes human-AI dialogue through cymatic patterns on water. Participants confess secrets to a water surface, triggering a four-phase ritual: confession, contemplation, response, and release. The user's speech sentiment is directly transmitted into the water to prime its state, while semantic content enters a multi-agent system, initiating ripples of conversation where agent identities are situated through discourse and voice profiles are chosen based on what they say. We propose a novel algorithm that decomposes speech into component waves and reconstructs them in water, establishing a translation between speech and the physics of material form. By rendering machine reasoning as emergent physical phenomena, the installation explores possibilities for emotional self-exploration through ambiguous, sensory-rich interfaces.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18934v1</guid></item><item><title>[cs updates on arXiv.org] Bi-Level Online Provisioning and Scheduling with Switching Costs and Cross-Level Constraints</title><link>https://arxiv.org/abs/2601.18936</link><description>arXiv:2601.18936v1 Announce Type: new 
Abstract: We study a bi-level online provisioning and scheduling problem motivated by network resource allocation, where provisioning decisions are made at a slow time scale while queue-/state-dependent scheduling is performed at a fast time scale. We model this two-time-scale interaction using an upper-level online convex optimization (OCO) problem and a lower-level constrained Markov decision process (CMDP). Existing OCO typically assumes stateless decisions and thus cannot capture MDP network dynamics such as queue evolution. Meanwhile, CMDP algorithms typically assume a fixed constraint threshold, whereas in provisioning-and-scheduling systems, the threshold varies with online budget decisions. To address these gaps, we study bi-level OCO-CMDP learning under switching costs (budget reprovisioning/system reconfiguration) and cross-level constraints that couple budgets to scheduling decisions. Our new algorithm solves this learning problem via several non-trivial developments, including a carefully designed dual feedback that returns the budget multiplier as sensitivity information for the upper-level update and a lower level that solves a budget-adaptive safe exploration problem via an extended occupancy-measure linear program. We establish near-optimal regret and high-probability satisfaction of the cross-level constraints.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18936v1</guid></item><item><title>[cs updates on arXiv.org] FSD-CAP: Fractional Subgraph Diffusion with Class-Aware Propagation for Graph Feature Imputation</title><link>https://arxiv.org/abs/2601.18938</link><description>arXiv:2601.18938v1 Announce Type: new 
Abstract: Imputing missing node features in graphs is challenging, particularly under high missing rates. Existing methods based on latent representations or global diffusion often fail to produce reliable estimates, and may propagate errors across the graph. We propose FSD-CAP, a two-stage framework designed to improve imputation quality under extreme sparsity. In the first stage, a graph-distance-guided subgraph expansion localizes the diffusion process. A fractional diffusion operator adjusts propagation sharpness based on local structure. In the second stage, imputed features are refined using class-aware propagation, which incorporates pseudo-labels and neighborhood entropy to promote consistency. We evaluated FSD-CAP on multiple datasets. With $99.5\%$ of features missing across five benchmark datasets, FSD-CAP achieves average accuracies of $80.06\%$ (structural) and $81.01\%$ (uniform) in node classification, close to the $81.31\%$ achieved by a standard GCN with full features. For link prediction under the same setting, it reaches AUC scores of $91.65\%$ (structural) and $92.41\%$ (uniform), compared to $95.06\%$ for the fully observed case. Furthermore, FSD-CAP demonstrates superior performance on both large-scale and heterophily datasets when compared to other models.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18938v1</guid></item><item><title>[cs updates on arXiv.org] A Few Bad Neurons: Isolating and Surgically Correcting Sycophancy</title><link>https://arxiv.org/abs/2601.18939</link><description>arXiv:2601.18939v1 Announce Type: new 
Abstract: Behavioral alignment in large language models (LLMs) is often achieved through broad fine-tuning, which can result in undesired side effects like distributional shift and low interpretability. We propose a method for alignment that identifies and updates only the neurons most responsible for a given behavior, a targeted approach that allows for fine-tuning with significantly less data. Using sparse autoencoders (SAEs) and linear probes, we isolate the 3% of MLP neurons most predictive of a target behavior, decode them into residual space, and fine-tune only those neurons using gradient masking. We demonstrate this approach on the task of reducing sycophantic behavior, where our method matches or exceeds state-of-the-art performance on four benchmarks (Syco-Bench, NLP, POLI, PHIL) using Gemma-2-2B and 9B models. Our results show that sparse, neuron-level updates offer a scalable and precise alternative to full-model fine-tuning, remaining effective even in situations when little data is available</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18939v1</guid></item><item><title>[cs updates on arXiv.org] Configurable p-Neurons Using Modular p-Bits</title><link>https://arxiv.org/abs/2601.18943</link><description>arXiv:2601.18943v1 Announce Type: new 
Abstract: Probabilistic bits (p-bits) have recently been employed in neural networks (NNs) as stochastic neurons with sigmoidal probabilistic activation functions. Nonetheless, there remain a wealth of other probabilistic activation functions that are yet to be explored. Here we re-engineer the p-bit by decoupling its stochastic signal path from its input data path, giving rise to a modular p-bit that enables the realization of probabilistic neurons (p-neurons) with a range of configurable probabilistic activation functions, including a probabilistic version of the widely used Logistic Sigmoid, Tanh and Rectified Linear Unit (ReLU) activation functions. We present spintronic (CMOS + sMTJ) designs that show wide and tunable probabilistic ranges of operation. Finally, we experimentally implement digital-CMOS versions on an FPGA, with stochastic unit sharing, and demonstrate an order of magnitude (10x) saving in required hardware resources compared to conventional digital p-bit implementations.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18943v1</guid></item><item><title>[cs updates on arXiv.org] Neural Theorem Proving for Verification Conditions: A Real-World Benchmark</title><link>https://arxiv.org/abs/2601.18944</link><description>arXiv:2601.18944v1 Announce Type: new 
Abstract: Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18944v1</guid></item><item><title>[cs updates on arXiv.org] Large Language Models for Departmental Expert Review Quality Scores</title><link>https://arxiv.org/abs/2601.18945</link><description>arXiv:2601.18945v1 Announce Type: new 
Abstract: Presumably, peer reviewers and Large Language Models (LLMs) do very different things when asked to assess research. Still, recent evidence has shown that LLMs have a moderate ability to predict quality scores of published academic journal articles. One untested potential application of LLMs is for internal departmental review, which may be used to support appointment and promotion decisions or to select outputs for national assessments. This study assesses for the first time the extent to which (1) LLM quality scores align with internal departmental quality ratings and (2) LLM reports differ from expert reports. Using a private dataset of 58 published journal articles from the School of Information at the University of Sheffield, together with internal departmental quality ratings and reports, ChatGPT-4o, ChatGPT-4o mini, and Gemini 2.0 Flash scores correlate positively and moderately with internal departmental ratings, whether the input is just title/abstract or the full text. Whilst departmental reviews tended to be more specific and showing field-level knowledge, ChatGPT reports tended to be standardised, more general, repetitive, and with unsolicited suggestions for improvement. The results therefore (a) confirm the ability of LLMs to guess the quality scores of published academic research moderately well, (b) confirm that this ability is a guess rather than an evaluation (because it can be made based on title/abstract alone), (c) extend this ability to internal departmental expert review, and (d) show that LLM reports are less insightful than human expert reports for published academic journal articles.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18945v1</guid></item><item><title>[cs updates on arXiv.org] On the Strong Stability Preserving Property of Runge-Kutta Methods for Hyperbolic Problems</title><link>https://arxiv.org/abs/2601.18947</link><description>arXiv:2601.18947v1 Announce Type: new 
Abstract: Strong Stability Preserving (SSP) time integration schemes maintain stability of the forward Euler method for any initial value problem. However, only a small subset of Runge-Kutta (RK) methods are SSP, and many efficient high-order time integration schemes do not formally belong to this class. In this work, we introduce a mathematical strategy to analyze the nonlinear stability of RK schemes that may not necessarily belong to the SSP class. With this approach, we mathematically demonstrate that there are time integration schemes outside the class of SSP schemes that can maintain entropy stability and positivity of density and pressure for the Lax-Friedrichs discretization, and Total Variation Diminishing stability for the first-order upwind and the second-order MUSCL schemes. As a result, for these problems, a broader range of RK methods, including the classical fourth-order, four-stage RK scheme, can be used while the numerical integration remains stable. Numerical experiments confirm these theoretical findings, and additional experiments demonstrate similar observations for a wider class of space discretizatins.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18947v1</guid></item><item><title>[cs updates on arXiv.org] Smart Split-Federated Learning over Noisy Channels for Embryo Image Segmentation</title><link>https://arxiv.org/abs/2601.18948</link><description>arXiv:2601.18948v1 Announce Type: new 
Abstract: Split-Federated (SplitFed) learning is an extension of federated learning that places minimal requirements on the clients computing infrastructure, since only a small portion of the overall model is deployed on the clients hardware. In SplitFed learning, feature values, gradient updates, and model updates are transferred across communication channels. In this paper, we study the effects of noise in the communication channels on the learning process and the quality of the final model. We propose a smart averaging strategy for SplitFed learning with the goal of improving resilience against channel noise. Experiments on a segmentation model for embryo images shows that the proposed smart averaging strategy is able to tolerate two orders of magnitude stronger noise in the communication channels compared to conventional averaging, while still maintaining the accuracy of the final model.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18948v1</guid></item><item><title>[cs updates on arXiv.org] Tricky$^2$: Towards a Benchmark for Evaluating Human and LLM Error Interactions</title><link>https://arxiv.org/abs/2601.18949</link><description>arXiv:2601.18949v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly integrated into software development workflows, yet they often introduce subtle logic or data-misuse errors that differ from human bugs. To study how these two error types interact, we construct Tricky$^2$, a hybrid dataset that augments the existing TrickyBugs corpus of human-written defects with errors injected by both GPT-5 and OpenAI-oss-20b across C++, Python, and Java programs. Our approach uses a taxonomy-guided prompting framework to generate machine-originated bugs while preserving original human defects and program structure. The resulting corpus spans human-only, LLM-only, and human+LLM splits, enabling analysis of mixed-origin error behavior, multi-bug repair robustness, and reliability in hybrid human-machine code. This paper outlines the dataset construction pipeline and illustrates its use through small-scale baseline evaluations of classification, localization, and repair tasks.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18949v1</guid></item><item><title>[cs updates on arXiv.org] Vector-Valued Distributional Reinforcement Learning Policy Evaluation: A Hilbert Space Embedding Approach</title><link>https://arxiv.org/abs/2601.18952</link><description>arXiv:2601.18952v1 Announce Type: new 
Abstract: We propose an (offline) multi-dimensional distributional reinforcement learning framework (KE-DRL) that leverages Hilbert space mappings to estimate the kernel mean embedding of the multi-dimensional value distribution under a proposed target policy. In our setting, the state-action variables are multi-dimensional and continuous. By mapping probability measures into a reproducing kernel Hilbert space via kernel mean embeddings, our method replaces Wasserstein metrics with an integral probability metric. This enables efficient estimation in multi-dimensional state-action spaces and reward settings, where direct computation of Wasserstein distances is computationally challenging. Theoretically, we establish contraction properties of the distributional Bellman operator under our proposed metric involving the Matern family of kernels and provide uniform convergence guarantees. Simulations and empirical results demonstrate robust off-policy evaluation and recovery of the kernel mean embedding under mild assumptions, namely, Lipschitz continuity and boundedness of the kernels, highlighting the potential of embedding-based approaches in complex real-world decision-making scenarios and risk evaluation.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18952v1</guid></item><item><title>[cs updates on arXiv.org] 3D-Printed Hybrid Liquid-CPCM Cooling Modules for High-Performance Thermal Management of Lithium-Ion Pouch Cells</title><link>https://arxiv.org/abs/2601.18959</link><description>arXiv:2601.18959v1 Announce Type: new 
Abstract: Efficient thermal management is critical for ensuring the safety, performance, and durability of lithium ion pouch cells (LIPCs), particularly under high power operating conditions where conventional battery thermal management systems (BTMS) struggle to balance cooling effectiveness, structural simplicity, and weight. Here, we report a lightweight hybrid BTMS that synergistically integrates active liquid cooling with composite phase change material (CPCM) based thermal buffering through a 3D printed hexagonal architecture. The system is fabricated via a two step additive manufacturing process that enables sealed CPCM encapsulation and isolated liquid cooling pathways within a single carbon fiber reinforced nylon module, effectively eliminating leakage risks while allowing precise geometric control. Hexagonally partitioned CPCM cavities maximize the CPCM wall interfacial area and shorten internal conduction paths, accelerating latent heat absorption, while embedded serpentine liquid channels provide continuous convective heat removal and prevent CPCM saturation. A nanocarbon enhanced CPCM is employed to overcome the intrinsic low thermal conductivity of conventional paraffin based materials.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18959v1</guid></item><item><title>[cs updates on arXiv.org] Fauna Sprout: A lightweight, approachable, developer-ready humanoid robot</title><link>https://arxiv.org/abs/2601.18963</link><description>arXiv:2601.18963v1 Announce Type: new 
Abstract: Recent advances in learned control, large-scale simulation, and generative models have accelerated progress toward general-purpose robotic controllers, yet the field still lacks platforms suitable for safe, expressive, long-term deployment in human environments. Most existing humanoids are either closed industrial systems or academic prototypes that are difficult to deploy and operate around people, limiting progress in robotics. We introduce Sprout, a developer platform designed to address these limitations through an emphasis on safety, expressivity, and developer accessibility. Sprout adopts a lightweight form factor with compliant control, limited joint torques, and soft exteriors to support safe operation in shared human spaces. The platform integrates whole-body control, manipulation with integrated grippers, and virtual-reality-based teleoperation within a unified hardware-software stack. An expressive head further enables social interaction -- a domain that remains underexplored on most utilitarian humanoids. By lowering physical and technical barriers to deployment, Sprout expands access to capable humanoid platforms and provides a practical basis for developing embodied intelligence in real human environments.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18963v1</guid></item><item><title>[cs updates on arXiv.org] People Can Accurately Predict Behavior of Complex Algorithms That Are Available, Compact, and Aligned</title><link>https://arxiv.org/abs/2601.18966</link><description>arXiv:2601.18966v1 Announce Type: new 
Abstract: Users trust algorithms more when they can predict the algorithms' behavior. Simple algorithms trivially yield predictively accurate mental models, but modern AI algorithms have often been assumed too complex for people to build predictive mental models, especially in the social media domain. In this paper, we describe conditions under which even complex algorithms can yield predictive mental models, opening up opportunities for a broader set of human-centered algorithms. We theorize that users will form an accurate predictive mental model of an algorithm's behavior if and only if the algorithm simultaneously satisfies three criteria: (1) cognitive availability of the underlying concepts being modeled, (2) concept compactness (does it form a single cognitive construct?), and (3) high alignment between the person's and algorithm's execution of the concept. We evaluate this theory through a pre-registered experiment (N=1250) where users predict behavior of 25 social media feed ranking algorithms that vary on these criteria. We find that even complex (e.g., LLM-based) algorithms enjoy accurate prediction rates when they meet all criteria, and even simple (e.g., basic term count) algorithms fail to be predictable when a single criterion fails. We also find that these criteria determine outcomes beyond prediction accuracy, such as which mental models users deploy to make their predictions.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18966v1</guid></item><item><title>[cs updates on arXiv.org] Pay Attention to Where You Look</title><link>https://arxiv.org/abs/2601.18970</link><description>arXiv:2601.18970v1 Announce Type: new 
Abstract: Novel view synthesis (NVS) has advanced with generative modeling, enabling photorealistic image generation. In few-shot NVS, where only a few input views are available, existing methods often assume equal importance for all input views relative to the target, leading to suboptimal results.
  We address this limitation by introducing a camera-weighting mechanism that adjusts the importance of source views based on their relevance to the target. We propose two approaches: a deterministic weighting scheme leveraging geometric properties like Euclidean distance and angular differences, and a cross-attention-based learning scheme that optimizes view weighting. Additionally, models can be further trained with our camera-weighting scheme to refine their understanding of view relevance and enhance synthesis quality. This mechanism is adaptable and can be integrated into various NVS algorithms, improving their ability to synthesize high-quality novel views. Our results demonstrate that adaptive view weighting enhances accuracy and realism, offering a promising direction for improving NVS.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18970v1</guid></item><item><title>[cs updates on arXiv.org] Towards Self-Optimizing Electron Microscope: Robust Tuning of Aberration Coefficients via Physics-Aware Multi-Objective Bayesian Optimization</title><link>https://arxiv.org/abs/2601.18972</link><description>arXiv:2601.18972v1 Announce Type: new 
Abstract: Realizing high-throughput aberration-corrected Scanning Transmission Electron Microscopy (STEM) exploration of atomic structures requires rapid tuning of multipole probe correctors while compensating for the inevitable drift of the optical column. While automated alignment routines exist, conventional approaches rely on serial, gradient-free searches (e.g., Nelder-Mead) that are sample-inefficient and struggle to correct multiple interacting parameters simultaneously. Conversely, emerging deep learning methods offer speed but often lack the flexibility to adapt to varying sample conditions without extensive retraining. Here, we introduce a Multi-Objective Bayesian Optimization (MOBO) framework for rapid, data-efficient aberration correction. Importantly, this framework does not prescribe a single notion of image quality; instead, it enables user-defined, physically motivated reward formulations (e.g., symmetry-induced objectives) and uses Pareto fronts to expose the resulting trade-offs between competing experimental priorities. By using Gaussian Process regression to model the aberration landscape probabilistically, our workflow actively selects the most informative lens settings to evaluate next, rather than performing an exhaustive blind search. We demonstrate that this active learning loop is more robust than traditional optimization algorithms and effectively tunes focus, astigmatism, and higher-order aberrations. By balancing competing objectives, this approach enables "self-optimizing" microscopy by dynamically sustaining optimal performance during experiments.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18972v1</guid></item><item><title>[cs updates on arXiv.org] When Does Adaptation Win? Scaling Laws for Meta-Learning in Quantum Control</title><link>https://arxiv.org/abs/2601.18973</link><description>arXiv:2601.18973v1 Announce Type: new 
Abstract: Quantum hardware suffers from intrinsic device heterogeneity and environmental drift, forcing practitioners to choose between suboptimal non-adaptive controllers or costly per-device recalibration. We derive a scaling law lower bound for meta-learning showing that the adaptation gain (expected fidelity improvement from task-specific gradient steps) saturates exponentially with gradient steps and scales linearly with task variance, providing a quantitative criterion for when adaptation justifies its overhead. Validation on quantum gate calibration shows negligible benefits for low-variance tasks but $&gt;40\%$ fidelity gains on two-qubit gates under extreme out-of-distribution conditions (10$\times$ the training noise), with implications for reducing per-device calibration time on cloud quantum processors. Further validation on classical linear-quadratic control confirms these laws emerge from general optimization geometry rather than quantum-specific physics. Together, these results offer a transferable framework for decision-making in adaptive control.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18973v1</guid></item><item><title>[cs updates on arXiv.org] Intent2QoS: Language Model-Driven Automation of Traffic Shaping Configurations</title><link>https://arxiv.org/abs/2601.18974</link><description>arXiv:2601.18974v1 Announce Type: new 
Abstract: Traffic shaping and Quality of Service (QoS) enforcement are critical for managing bandwidth, latency, and fairness in networks. These tasks often rely on low-level traffic control settings, which require manual setup and technical expertise. This paper presents an automated framework that converts high-level traffic shaping intents in natural or declarative language into valid and correct traffic control rules. To the best of our knowledge, we present the first end-to-end pipeline that ties intent translation in a queuing-theoretic semantic model and, with a rule-based critic, yields deployable Linux traffic control configuration sets. The framework has three steps: (1) a queuing simulation with priority scheduling and Active Queue Management (AQM) builds a semantic model; (2) a language model, using this semantic model and a traffic profile, generates sub-intents and configuration rules; and (3) a rule-based critic checks and adjusts the rules for correctness and policy compliance. We evaluate multiple language models by generating traffic control commands from business intents that comply with relevant standards for traffic control protocols. Experimental results on 100 intents show significant gains, with LLaMA3 reaching 0.88 semantic similarity and 0.87 semantic coverage, outperforming other models by over 30\. A thorough sensitivity study demonstrates that AQM-guided prompting reduces variability threefold compared to zero-shot baselines.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18974v1</guid></item><item><title>[cs updates on arXiv.org] Attention-Enhanced Graph Filtering for False Data Injection Attack Detection and Localization</title><link>https://arxiv.org/abs/2601.18981</link><description>arXiv:2601.18981v1 Announce Type: new 
Abstract: The increasing deployment of Internet-of-Things (IoT)-enabled measurement devices in modern power systems has expanded the cyberattack surface of the grid. As a result, this critical infrastructure is increasingly exposed to cyberattacks, including false data injection attacks (FDIAs) that compromise measurement integrity and threaten reliable system operation. Existing FDIA detection methods primarily exploit spatial correlations and network topology using graph-based learning; however, these approaches often rely on high-dimensional representations and shallow classifiers, limiting their ability to capture local structural dependencies and global contextual relationships. Moreover, naively incorporating Transformer architectures can result in overly deep models that struggle to model localized grid dynamics. This paper proposes a joint FDIA detection and localization framework that integrates auto-regressive moving average (ARMA) graph convolutional filters with an Encoder-Only Transformer architecture. The ARMA-based graph filters provide robust, topology-aware feature extraction and adaptability to abrupt spectral changes, while the Transformer encoder leverages self-attention to capture long-range dependencies among grid elements without sacrificing essential local context. The proposed method is evaluated using real-world load data from the New York Independent System Operator (NYISO) applied to the IEEE 14- and 300-bus systems. Numerical results demonstrate that the proposed model effectively exploits both the state and topology of the power grid, achieving high accuracy in detecting FDIA events and localizing compromised nodes.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18981v1</guid></item><item><title>[cs updates on arXiv.org] Trustworthy Scheduling for Big Data Applications</title><link>https://arxiv.org/abs/2601.18983</link><description>arXiv:2601.18983v1 Announce Type: new 
Abstract: Recent advances in modern containerized execution environments have resulted in substantial benefits in terms of elasticity and more efficient utilization of computing resources. Although existing schedulers strive to optimize performance metrics like task execution times and resource utilization, they provide limited transparency into their decision-making processes or the specific actions developers must take to meet Service Level Objectives (SLOs). In this work, we propose X-Sched, a middleware that uses explainability techniques to generate actionable guidance on resource configurations that makes task execution in containerized environments feasible, under resource and time constraints. X-Sched addresses this gap by integrating counterfactual explanations with advanced machine learning models, such as Random Forests, to efficiently identify optimal configurations. This approach not only ensures that tasks are executed in line with performance goals but also gives users clear, actionable insights into the rationale behind scheduling decisions. Our experimental results validated with data from real-world execution environments, illustrate the efficiency, benefits and practicality of our approach.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18983v1</guid></item><item><title>[cs updates on arXiv.org] Save the Good Prefix: Precise Error Penalization via Process-Supervised RL to Enhance LLM Reasoning</title><link>https://arxiv.org/abs/2601.18984</link><description>arXiv:2601.18984v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has emerged as a powerful framework for improving the reasoning capabilities of large language models (LLMs). However, most existing RL approaches rely on sparse outcome rewards, which fail to credit correct intermediate steps in partially successful solutions. Process reward models (PRMs) offer fine-grained step-level supervision, but their scores are often noisy and difficult to evaluate. As a result, recent PRM benchmarks focus on a more objective capability: detecting the first incorrect step in a reasoning path. However, this evaluation target is misaligned with how PRMs are typically used in RL, where their step-wise scores are treated as raw rewards to maximize. To bridge this gap, we propose Verifiable Prefix Policy Optimization (VPPO), which uses PRMs only to localize the first error during RL. Given an incorrect rollout, VPPO partitions the trajectory into a verified correct prefix and an erroneous suffix based on the first error, rewarding the former while applying targeted penalties only after the detected mistake. This design yields stable, interpretable learning signals and improves credit assignment. Across multiple reasoning benchmarks, VPPO consistently outperforms sparse-reward RL and prior PRM-guided baselines on both Pass@1 and Pass@K.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18984v1</guid></item><item><title>[cs updates on arXiv.org] LLMs versus the Halting Problem: Revisiting Program Termination Prediction</title><link>https://arxiv.org/abs/2601.18987</link><description>arXiv:2601.18987v1 Announce Type: new 
Abstract: Determining whether a program terminates is a central problem in computer science. Turing's foundational result established the Halting Problem as undecidable, showing that no algorithm can universally determine termination for all programs and inputs. Consequently, automatic verification tools approximate termination, sometimes failing to prove or disprove; these tools rely on problem-specific architectures and abstractions, and are usually tied to particular programming languages. Recent success and progress in large language models (LLMs) raises the following question: can LLMs reliably predict program termination? In this work, we evaluate LLMs on a diverse set of C programs from the Termination category of the International Competition on Software Verification (SV-Comp) 2025. Our results suggest that LLMs perform remarkably well at predicting program termination, where GPT-5 and Claude Sonnet-4.5 would rank just behind the top-ranked tool (using test-time-scaling), and Code World Model (CWM) would place just behind the second-ranked tool. While LLMs are effective at predicting program termination, they often fail to provide a valid witness as a proof. Moreover, LLMs performance drops as program length increases. We hope these insights motivate further research into program termination and the broader potential of LLMs for reasoning about undecidable problems.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18987v1</guid></item><item><title>[cs updates on arXiv.org] FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction</title><link>https://arxiv.org/abs/2601.18993</link><description>arXiv:2601.18993v1 Announce Type: new 
Abstract: Camera redirection aims to replay a dynamic scene from a single monocular video under a user-specified camera trajectory. However, large-angle redirection is inherently ill-posed: a monocular video captures only a narrow spatio-temporal view of a dynamic 3D scene, providing highly partial observations of the underlying 4D world. The key challenge is therefore to recover a complete and coherent representation from this limited input, with consistent geometry and motion. While recent diffusion-based methods achieve impressive results, they often break down under large-angle viewpoint changes far from the original trajectory, where missing visual grounding leads to severe geometric ambiguity and temporal inconsistency. To address this, we present FreeOrbit4D, an effective training-free framework that tackles this geometric ambiguity by recovering a geometry-complete 4D proxy as structural grounding for video generation. We obtain this proxy by decoupling foreground and background reconstructions: we unproject the monocular video into a static background and geometry-incomplete foreground point clouds in a unified global space, then leverage an object-centric multi-view diffusion model to synthesize multi-view images and reconstruct geometry-complete foreground point clouds in canonical object space. By aligning the canonical foreground point cloud to the global scene space via dense pixel-synchronized 3D--3D correspondences and projecting the geometry-complete 4D proxy onto target camera viewpoints, we provide geometric scaffolds that guide a conditional video diffusion model. Extensive experiments show that FreeOrbit4D produces more faithful redirected videos under challenging large-angle trajectories, and our geometry-complete 4D proxy further opens a potential avenue for practical applications such as edit propagation and 4D data generation. Project page and code will be released soon.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18993v1</guid></item><item><title>[cs updates on arXiv.org] Anatomically-aware conformal prediction for medical image segmentation with random walks</title><link>https://arxiv.org/abs/2601.18997</link><description>arXiv:2601.18997v1 Announce Type: new 
Abstract: The reliable deployment of deep learning in medical imaging requires uncertainty quantification that provides rigorous error guarantees while remaining anatomically meaningful. Conformal prediction (CP) is a powerful distribution-free framework for constructing statistically valid prediction intervals. However, standard applications in segmentation often ignore anatomical context, resulting in fragmented, spatially incoherent, and over-segmented prediction sets that limit clinical utility. To bridge this gap, this paper proposes Random-Walk Conformal Prediction (RW-CP), a model-agnostic framework which can be added on top of any segmentation method. RW-CP enforces spatial coherence to generate anatomically valid sets. Our method constructs a k-nearest neighbour graph from pre-trained vision foundation model features and applies a random walk to diffuse uncertainty. The random walk diffusion regularizes the non-conformity scores, making the prediction sets less sensitive to the conformal calibration parameter $\lambda$, ensuring more stable and continuous anatomical boundaries. RW-CP maintains rigorous marginal coverage while significantly improving segmentation quality. Evaluations on multi-modal public datasets show improvements of up to $35.4\%$ compared to standard CP baselines, given an allowable error rate of $\alpha=0.1$.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18997v1</guid></item><item><title>[cs updates on arXiv.org] Malicious Repurposing of Open Science Artefacts by Using Large Language Models</title><link>https://arxiv.org/abs/2601.18998</link><description>arXiv:2601.18998v1 Announce Type: new 
Abstract: The rapid evolution of large language models (LLMs) has fuelled enthusiasm about their role in advancing scientific discovery, with studies exploring LLMs that autonomously generate and evaluate novel research ideas. However, little attention has been given to the possibility that such models could be exploited to produce harmful research by repurposing open science artefacts for malicious ends. We fill the gap by introducing an end-to-end pipeline that first bypasses LLM safeguards through persuasion-based jailbreaking, then reinterprets NLP papers to identify and repurpose their artefacts (datasets, methods, and tools) by exploiting their vulnerabilities, and finally assesses the safety of these proposals using our evaluation framework across three dimensions: harmfulness, feasibility of misuse, and soundness of technicality. Overall, our findings demonstrate that LLMs can generate harmful proposals by repurposing ethically designed open artefacts; however, we find that LLMs acting as evaluators strongly disagree with one another on evaluation outcomes: GPT-4.1 assigns higher scores (indicating greater potential harms, higher soundness and feasibility of misuse), Gemini-2.5-pro is markedly stricter, and Grok-3 falls between these extremes. This indicates that LLMs cannot yet serve as reliable judges in a malicious evaluation setup, making human evaluation essential for credible dual-use risk assessment.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18998v1</guid></item><item><title>[cs updates on arXiv.org] Randomization Boosts KV Caching, Learning Balances Query Load: A Joint Perspective</title><link>https://arxiv.org/abs/2601.18999</link><description>arXiv:2601.18999v1 Announce Type: new 
Abstract: KV caching is a fundamental technique for accelerating Large Language Model (LLM) inference by reusing key-value (KV) pairs from previous queries, but its effectiveness under limited memory is highly sensitive to the eviction policy. The default Least Recently Used (LRU) eviction algorithm struggles with dynamic online query arrivals, especially in multi-LLM serving scenarios, where balancing query load across workers and maximizing cache hit rate of each worker are inherently conflicting objectives. We give the first unified mathematical model that captures the core trade-offs between KV cache eviction and query routing. Our analysis reveals the theoretical limitations of existing methods and leads to principled algorithms that integrate provably competitive randomized KV cache eviction with learning-based methods to adaptively route queries with evolving patterns, thus balancing query load and cache hit rate. Our theoretical results are validated by extensive experiments across 4 benchmarks and 3 prefix-sharing settings, demonstrating improvements of up to 6.92$\times$ in cache hit rate, 11.96$\times$ reduction in latency, 14.06$\times$ reduction in time-to-first-token (TTFT), and 77.4% increase in throughput over the state-of-the-art methods. Our code is available at https://github.com/fzwark/KVRouting.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.18999v1</guid></item><item><title>[cs updates on arXiv.org] FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning</title><link>https://arxiv.org/abs/2601.19001</link><description>arXiv:2601.19001v1 Announce Type: new 
Abstract: We propose FROST, an attention-aware method for efficient reasoning. Unlike traditional approaches, FROST leverages attention weights to prune uncritical reasoning paths, yielding shorter and more reliable reasoning trajectories. Methodologically, we introduce the concept of reasoning outliers and design an attention-based mechanism to remove them. Theoretically, FROST preserves and enhances the model's reasoning capacity while eliminating outliers at the sentence level. Empirically, we validate FROST on four benchmarks using two strong reasoning models (Phi-4-Reasoning and GPT-OSS-20B), outperforming state-of-the-art methods such as TALE and ThinkLess. Notably, FROST achieves an average 69.68% reduction in token usage and a 26.70% improvement in accuracy over the base model. Furthermore, in evaluations of attention outlier metrics, FROST reduces the maximum infinity norm by 15.97% and the average kurtosis by 91.09% compared to the base model. Code is available at https://github.com/robinzixuan/FROST</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19001v1</guid></item><item><title>[cs updates on arXiv.org] Accelerated training of Gaussian processes using banded square exponential covariances</title><link>https://arxiv.org/abs/2601.19007</link><description>arXiv:2601.19007v1 Announce Type: new 
Abstract: We propose a novel approach to computationally efficient GP training based on the observation that square-exponential (SE) covariance matrices contain several off-diagonal entries extremely close to zero. We construct a principled procedure to eliminate those entries to produce a \emph{banded}-matrix approximation to the original covariance, whose inverse and determinant can be computed at a reduced computational cost, thus contributing to an efficient approximation to the likelihood function. We provide a theoretical analysis of the proposed method to preserve the structure of the original covariance in the 1D setting with SE kernel, and validate its computational efficiency against the variational free energy approach to sparse GPs.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19007v1</guid></item><item><title>[cs updates on arXiv.org] Non-Invasive 3D Wound Measurement with RGB-D Imaging</title><link>https://arxiv.org/abs/2601.19014</link><description>arXiv:2601.19014v1 Announce Type: new 
Abstract: Chronic wound monitoring and management require accurate and efficient wound measurement methods. This paper presents a fast, non-invasive 3D wound measurement algorithm based on RGB-D imaging. The method combines RGB-D odometry with B-spline surface reconstruction to generate detailed 3D wound meshes, enabling automatic computation of clinically relevant wound measurements such as perimeter, surface area, and dimensions. We evaluated our system on realistic silicone wound phantoms and measured sub-millimetre 3D reconstruction accuracy compared with high-resolution ground-truth scans. The extracted measurements demonstrated low variability across repeated captures and strong agreement with manual assessments. The proposed pipeline also outperformed a state-of-the-art object-centric RGB-D reconstruction method while maintaining runtimes suitable for real-time clinical deployment. Our approach offers a promising tool for automated wound assessment in both clinical and remote healthcare settings.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19014v1</guid></item><item><title>[cs updates on arXiv.org] Average-Case Reductions for $k$-XOR and Tensor PCA</title><link>https://arxiv.org/abs/2601.19016</link><description>arXiv:2601.19016v1 Announce Type: new 
Abstract: We study two canonical planted average-case problems -- noisy $k\mathsf{\text{-}XOR}$ and Tensor PCA -- and relate their computational properties via poly-time average-case reductions. In fact, we consider a \emph{family of problems} that interpolates between $k\mathsf{\text{-}XOR}$ and Tensor PCA, allowing intermediate densities and signal levels. We introduce two \emph{densifying} reductions that increase the number of observed entries while controlling the decrease in signal, and, in particular, reduce any $k\mathsf{\text{-}XOR}$ instance at the computational threshold to Tensor PCA at the computational threshold. Additionally, we give new order-reducing maps (e.g., $5\to 4$ $k\mathsf{\text{-}XOR}$ and $7\to 4$ Tensor PCA) at fixed entry density.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19016v1</guid></item><item><title>[cs updates on arXiv.org] A Framework for Evaluating Faithfulness in Explainable AI for Machine Anomalous Sound Detection Using Frequency-Band Perturbation</title><link>https://arxiv.org/abs/2601.19017</link><description>arXiv:2601.19017v1 Announce Type: new 
Abstract: Explainable AI (XAI) is commonly applied to anomalous sound detection (ASD) models to identify which time-frequency regions of an audio signal contribute to an anomaly decision. However, most audio explanations rely on qualitative inspection of saliency maps, leaving open the question of whether these attributions accurately reflect the spectral cues the model uses. In this work, we introduce a new quantitative framework for evaluating XAI faithfulness in machine-sound analysis by directly linking attribution relevance to model behaviour through systematic frequency-band removal. This approach provides an objective measure of whether an XAI method for machine ASD correctly identifies frequency regions that influence an ASD model's predictions. By using four widely adopted methods, namely Integrated Gradients, Occlusion, Grad-CAM and SmoothGrad, we show that XAI techniques differ in reliability, with Occlusion demonstrating the strongest alignment with true model sensitivity and gradient-+based methods often failing to accurately capture spectral dependencies. The proposed framework offers a reproducible way to benchmark audio explanations and enables more trustworthy interpretation of spectrogram-based ASD systems.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19017v1</guid></item><item><title>[cs updates on arXiv.org] AAA least squares solution of Helmholtz problems</title><link>https://arxiv.org/abs/2601.19020</link><description>arXiv:2601.19020v1 Announce Type: new 
Abstract: This paper presents an adaptive numerical framework for solving exterior "sound-soft" scattering problems governed by the Helmholtz equation. By interpreting the Method of Fundamental Solutions through the lens of rational approximation, we introduce an automated strategy for singularity placement based on the analytic continuation of boundary data. The proposed AAALS-Helmholtz algorithm leverages a "continuum" variant of the AAA algorithm to identify the singularities limiting analytic extension, and to ensure an optimal source distribution even for complex, non star-shaped geometries. Furthermore, we establish a formal connection between the Helmholtz and Laplace problems, providing a theoretical justification for the "double poles" technique. The approach offers a robust, meshless alternative to heuristic source placement.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19020v1</guid></item><item><title>[cs updates on arXiv.org] Listening before Asking: Lived-Experience Advisors as Methodological Partners in Dementia Caregiving Studies</title><link>https://arxiv.org/abs/2601.19021</link><description>arXiv:2601.19021v1 Announce Type: new 
Abstract: Research with dementia caregivers poses persistent methodological and ethical challenges, particularly when interview-based studies are designed without sufficient grounding in lived caregiving realities. Questions framed through clinical or deficit-oriented assumptions risk alienating participants, undermining rapport, and producing shallow or ethically fraught data. While human-computer interaction (HCI) research increasingly adopts participatory approaches in technology design, participation rarely extends to the design of research methods themselves. This paper examines the role of lived-experience advisors as methodological partners in caregiver interview research. We report on a qualitative study in which two advisors with extensive dementia caregiving experience were engaged prior to fieldwork as methodological partners, extending participatory principles beyond technology design into the design of research methods themselves. Drawing on transcripts of advisor consultations and subsequent interviews with ten caregivers and one person living with dementia, we identify two key methodological contributions of advisor involvement. First, advisors enabled anticipatory validity by surfacing caregiving challenges, ethical sensitivities, and interpretive concerns that later appeared in caregiver interviews, allowing the researcher to enter the field with grounded awareness under constrained recruitment and fieldwork conditions. Second, advisors provided cultural, emotional, and systemic context that improved interpretive sensitivity and helped avoid misreadings. We argue that lived experience functions as methodological infrastructure, extending participatory principles into the design and conduct of research itself, and constituting a generalizable methodological pattern for HCI research with caregivers and other vulnerable or marginalized populations.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19021v1</guid></item><item><title>[cs updates on arXiv.org] EVEREST: An Evidential, Tail-Aware Transformer for Rare-Event Time-Series Forecasting</title><link>https://arxiv.org/abs/2601.19022</link><description>arXiv:2601.19022v1 Announce Type: new 
Abstract: Forecasting rare events in multivariate time-series data is challenging due to severe class imbalance, long-range dependencies, and distributional uncertainty. We introduce EVEREST, a transformer-based architecture for probabilistic rare-event forecasting that delivers calibrated predictions and tail-aware risk estimation, with auxiliary interpretability via attention-based signal attribution. EVEREST integrates four components: (i) a learnable attention bottleneck for soft aggregation of temporal dynamics; (ii) an evidential head for estimating aleatoric and epistemic uncertainty via a Normal--Inverse--Gamma distribution; (iii) an extreme-value head that models tail risk using a Generalized Pareto Distribution; and (iv) a lightweight precursor head for early-event detection. These modules are jointly optimized with a composite loss (focal loss, evidential NLL, and a tail-sensitive EVT penalty) and act only at training time; deployment uses a single classification head with no inference overhead (approximately 0.81M parameters). On a decade of space-weather data, EVEREST achieves state-of-the-art True Skill Statistic (TSS) of 0.973/0.970/0.966 at 24/48/72-hour horizons for C-class flares. The model is compact, efficient to train on commodity hardware, and applicable to high-stakes domains such as industrial monitoring, weather, and satellite diagnostics. Limitations include reliance on fixed-length inputs and exclusion of image-based modalities, motivating future extensions to streaming and multimodal forecasting.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19022v1</guid></item><item><title>[cs updates on arXiv.org] Is Finer Better? The Limits of Microscaling Formats in Large Language Models</title><link>https://arxiv.org/abs/2601.19026</link><description>arXiv:2601.19026v1 Announce Type: new 
Abstract: Microscaling data formats leverage per-block tensor quantization to enable aggressive model compression with limited loss in accuracy. Unlocking their potential for efficient training and inference necessitates hardware-friendly implementations that handle matrix multiplications in a native format and adopt efficient error-mitigation strategies. Herein, we report the emergence of a surprising behavior associated with microscaling quantization, whereas the output of a quantized model degrades as block size is decreased below a given threshold. This behavior clashes with the expectation that a smaller block size should allow for a better representation of the tensor elements. We investigate this phenomenon both experimentally and theoretically, decoupling the sources of quantization error behind it. Experimentally, we analyze the distributions of several Large Language Models and identify the conditions driving the anomalous behavior. Theoretically, we lay down a framework showing remarkable agreement with experimental data from pretrained model distributions and ideal ones. Overall, we show that the anomaly is driven by the interplay between narrow tensor distributions and the limited dynamic range of the quantized scales. Based on these insights, we propose the use of FP8 unsigned E5M3 (UE5M3) as a novel hardware-friendly format for the scales in FP4 microscaling data types. We demonstrate that UE5M3 achieves comparable performance to the conventional FP8 unsigned E4M3 scales while obviating the need of global scaling operations on weights and activations.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19026v1</guid></item><item><title>[cs updates on arXiv.org] Design and Evaluation of Next-Generation Cellular Networks through Digital and Physical Open and Programmable Platforms</title><link>https://arxiv.org/abs/2601.19027</link><description>arXiv:2601.19027v1 Announce Type: new 
Abstract: The evolution of the Radio Access Network (RAN) in 5G and 6G technologies marks a shift toward open, programmable, and softwarized architectures, driven by the Open RAN paradigm. This approach emphasizes open interfaces for telemetry sharing, intelligent data-driven control loops for network optimization, and virtualization and disaggregation of multi-vendor RAN components. While promising, this transition introduces significant challenges, including the need to design interoperable solutions, acquire datasets to train and test AI/ML algorithms for inference and control, and develop testbeds to benchmark these solutions. Experimental wireless platforms and private 5G deployments play a key role, providing architectures comparable to real-world systems and enabling prototyping and testing in realistic environments. This dissertation focuses on the development and evaluation of complementary experimental platforms: Colosseum, the world's largest Open RAN digital twin, and X5G, an open, programmable, multi-vendor private 5G O-RAN testbed with GPU acceleration. The main contributions include: (i) CaST, enabling automated creation and validation of digital twin wireless scenarios through 3D modeling, ray-tracing, and channel sounding; (ii) validation of Colosseum digital twins at scale, demonstrating that emulated environments closely reproduce real-world setups; (iii) X5G, integrating NVIDIA Aerial GPU-accelerated PHY processing with OpenAirInterface higher layers; (iv) a GPU-accelerated dApp framework for real-time RAN inference, enabling sub-millisecond control loops for AI-native applications including ISAC; and (v) intelligent RAN applications spanning spectrum sharing, interference detection, network slicing, security, and CSI-based sensing. Overall, this dissertation provides an end-to-end methodology bridging digital and physical experimentation for next-generation cellular networks.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19027v1</guid></item><item><title>[cs updates on arXiv.org] Audio Foundation Models Outperform Symbolic Representations for Piano Performance Evaluation</title><link>https://arxiv.org/abs/2601.19029</link><description>arXiv:2601.19029v1 Announce Type: new 
Abstract: Automated piano performance evaluation traditionally relies on symbolic (MIDI) representations, which capture note-level information but miss the acoustic nuances that characterize expressive playing. I propose using pre-trained audio foundation models, specifically MuQ and MERT, to predict 19 perceptual dimensions of piano performance quality. Using synthesized audio from PercePiano MIDI files (rendered via Pianoteq), I compare audio and symbolic approaches under controlled conditions where both derive from identical source data. The best model, MuQ layers 9-12 with Pianoteq soundfont augmentation, achieves R^2 = 0.537 (95% CI: [0.465, 0.575]), representing a 55% improvement over the symbolic baseline (R^2 = 0.347). Statistical analysis confirms significance (p &lt; 10^-25) with audio outperforming symbolic on all 19 dimensions. I validate the approach through cross-soundfont generalization (R^2 = 0.534 +/- 0.075), difficulty correlation with an external dataset (rho = 0.623), and multi-performer consistency analysis. Analysis of audio-symbolic fusion reveals high error correlation (r = 0.738), explaining why fusion provides minimal benefit: audio representations alone are sufficient. I release the complete training pipeline, pretrained models, and inference code.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19029v1</guid></item><item><title>[cs updates on arXiv.org] A Unifying View of Coverage in Linear Off-Policy Evaluation</title><link>https://arxiv.org/abs/2601.19030</link><description>arXiv:2601.19030v1 Announce Type: new 
Abstract: Off-policy evaluation (OPE) is a fundamental task in reinforcement learning (RL). In the classic setting of linear OPE, finite-sample guarantees often take the form $$ \textrm{Evaluation error} \le \textrm{poly}(C^\pi, d, 1/n,\log(1/\delta)), $$ where $d$ is the dimension of the features and $C^\pi$ is a coverage parameter that characterizes the degree to which the visited features lie in the span of the data distribution. While such guarantees are well-understood for several popular algorithms under stronger assumptions (e.g. Bellman completeness), the understanding is lacking and fragmented in the minimal setting where only the target value function is linearly realizable in the features. Despite recent interest in tight characterizations of the statistical rate in this setting, the right notion of coverage remains unclear, and candidate definitions from prior analyses have undesirable properties and are starkly disconnected from more standard definitions in the literature.
  We provide a novel finite-sample analysis of a canonical algorithm for this setting, LSTDQ. Inspired by an instrumental-variable view, we develop error bounds that depend on a novel coverage parameter, the feature-dynamics coverage, which can be interpreted as linear coverage in an induced dynamical system for feature evolution. With further assumptions -- such as Bellman-completeness -- our definition successfully recovers the coverage parameters specialized to those settings, finally yielding a unified understanding for coverage in linear OPE.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19030v1</guid></item><item><title>[cs updates on arXiv.org] XIMP: Cross Graph Inter-Message Passing for Molecular Property Prediction</title><link>https://arxiv.org/abs/2601.19037</link><description>arXiv:2601.19037v1 Announce Type: new 
Abstract: Accurate molecular property prediction is central to drug discovery, yet graph neural networks often underperform in data-scarce regimes and fail to surpass traditional fingerprints. We introduce cross-graph inter-message passing (XIMP), which performs message passing both within and across multiple related graph representations. For small molecules, we combine the molecular graph with scaffold-aware junction trees and pharmacophore-encoding extended reduced graphs, integrating complementary abstractions. While prior work is either limited to a single abstraction or non-iterative communication across graphs, XIMP supports an arbitrary number of abstractions and both direct and indirect communication between them in each layer. Across ten diverse molecular property prediction tasks, XIMP outperforms state-of-the-art baselines in most cases, leveraging interpretable abstractions as an inductive bias that guides learning toward established chemical concepts, enhancing generalization in low-data settings.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19037v1</guid></item><item><title>[cs updates on arXiv.org] OATS: Online Data Augmentation for Time Series Foundation Models</title><link>https://arxiv.org/abs/2601.19040</link><description>arXiv:2601.19040v1 Announce Type: new 
Abstract: Time Series Foundation Models (TSFMs) are a powerful paradigm for time series analysis and are often enhanced by synthetic data augmentation to improve the training data quality. Existing augmentation methods, however, typically rely on heuristics and static paradigms. Motivated by dynamic data optimization, which shows that the contribution of samples varies across training stages, we propose OATS (Online Data Augmentation for Time Series Foundation Models), a principled strategy that generates synthetic data tailored to different training steps. OATS leverages valuable training samples as principled guiding signals and dynamically generates high-quality synthetic data conditioned on them. We further design a diffusion-based framework to produce realistic time series and introduce an explore-exploit mechanism to balance efficiency and effectiveness. Experiments on TSFMs demonstrate that OATS consistently outperforms regular training and yields substantial performance gains over static data augmentation baselines across six validation datasets and two TSFM architectures. The code is available at the link https://github.com/microsoft/TimeCraft.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19040v1</guid></item><item><title>[cs updates on arXiv.org] HEATACO: Heatmap-Guided Ant Colony Decoding for Large-Scale Travelling Salesman Problems</title><link>https://arxiv.org/abs/2601.19041</link><description>arXiv:2601.19041v1 Announce Type: new 
Abstract: Heatmap-based non-autoregressive solvers for large-scale Travelling Salesman Problems output dense edge-probability scores, yet final performance largely hinges on the decoder that must satisfy degree-2 constraints and form a single Hamiltonian tour. Greedy commitment can cascade into irreparable mistakes at large $N$, whereas MCTS-guided local search is accurate but compute-heavy and highly engineered. We instead treat the heatmap as a soft edge prior and cast decoding as probabilistic tour construction under feasibility constraints, where the key is to correct local mis-rankings via inexpensive global coordination. Based on this view, we introduce HeatACO, a plug-and-play Max-Min Ant System decoder whose transition policy is softly biased by the heatmap while pheromone updates provide lightweight, instance-specific feedback to resolve global conflicts; optional 2-opt/3-opt post-processing further improves tour quality. On TSP500/1K/10K, using heatmaps produced by four pretrained predictors, HeatACO+2opt achieves gaps down to 0.11%/0.23%/1.15% with seconds-to-minutes CPU decoding for fixed heatmaps, offering a better quality--time trade-off than greedy decoding and published MCTS-based decoders. Finally, we find the gains track heatmap reliability: under distribution shift, miscalibration and confidence collapse bound decoding improvements, suggesting heatmap generalisation is a primary lever for further progress.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19041v1</guid></item><item><title>[cs updates on arXiv.org] NC-Reg : Neural Cortical Maps for Rigid Registration</title><link>https://arxiv.org/abs/2601.19042</link><description>arXiv:2601.19042v1 Announce Type: new 
Abstract: We introduce neural cortical maps, a continuous and compact neural representation for cortical feature maps, as an alternative to traditional discrete structures such as grids and meshes. It can learn from meshes of arbitrary size and provide learnt features at any resolution. Neural cortical maps enable efficient optimization on the sphere and achieve runtimes up to 30 times faster than classic barycentric interpolation (for the same number of iterations). As a proof of concept, we investigate rigid registration of cortical surfaces and propose NC-Reg, a novel iterative algorithm that involves the use of neural cortical feature maps, gradient descent optimization and a simulated annealing strategy. Through ablation studies and subject-to-template experiments, our method demonstrates sub-degree accuracy ($&lt;1^\circ$ from the global optimum), and serves as a promising robust pre-alignment strategy, which is critical in clinical settings.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19042v1</guid></item><item><title>[cs updates on arXiv.org] Machine Learning-Based Evaluation of Attitude Sensor Characteristics Using Microsatellite Flight Data</title><link>https://arxiv.org/abs/2601.19047</link><description>arXiv:2601.19047v1 Announce Type: new 
Abstract: Using actual flight data from a 50-cm-class microsatellite whose mission and operations have already been completed, this study re-evaluates satellite attitude determination performance and the error characteristics of onboard attitude sensors. While conventional approaches rely on batch estimation or Kalman filtering based on predefined physical models and white-noise assumptions, this research introduces a machine-learning-based approach to extract and correct structural and nonlinear error patterns embedded in real observational data. In this study, high-quality attitude determination results obtained from star sensors and a fiber optical gyro (FOG) are treated as ground truth, and machine learning is applied to coarse attitude sensor data consisting of Sun sensors and magnetic field sensors. A one-dimensional convolutional neural network (Conv1D) is employed to regressively predict attitude from short sequences of time-series sensor measurements. The model is trained and evaluated using five sets of on-orbit observation logs, with four passes used for training and one independent pass used for testing. The results show that, while conventional coarse attitude determination using the TRIAD method yields attitude errors on the order of 7 deg RMS, the proposed machine-learning approach achieves RMS errors of approximately 0.7 deg for the training data and 2-3 deg for the test data, depending on the sensor combination.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19047v1</guid></item><item><title>[cs updates on arXiv.org] NuiWorld: Exploring a Scalable Framework for End-to-End Controllable World Generation</title><link>https://arxiv.org/abs/2601.19048</link><description>arXiv:2601.19048v1 Announce Type: new 
Abstract: World generation is a fundamental capability for applications like video games, simulation, and robotics. However, existing approaches face three main obstacles: controllability, scalability, and efficiency. End-to-end scene generation models have been limited by data scarcity. While object-centric generation approaches rely on fixed resolution representations, degrading fidelity for larger scenes. Training-free approaches, while flexible, are often slow and computationally expensive at inference time. We present NuiWorld, a framework that attempts to address these challenges. To overcome data scarcity, we propose a generative bootstrapping strategy that starts from a few input images. Leveraging recent 3D reconstruction and expandable scene generation techniques, we synthesize scenes of varying sizes and layouts, producing enough data to train an end-to-end model. Furthermore, our framework enables controllability through pseudo sketch labels, and demonstrates a degree of generalization to previously unseen sketches. Our approach represents scenes as a collection of variable scene chunks, which are compressed into a flattened vector-set representation. This significantly reduces the token length for large scenes, enabling consistent geometric fidelity across scenes sizes while improving training and inference efficiency.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19048v1</guid></item><item><title>[cs updates on arXiv.org] Proactive Hardening of LLM Defenses with HASTE</title><link>https://arxiv.org/abs/2601.19051</link><description>arXiv:2601.19051v1 Announce Type: new 
Abstract: Prompt-based attack techniques are one of the primary challenges in securely deploying and protecting LLM-based AI systems. LLM inputs are an unbounded, unstructured space. Consequently, effectively defending against these attacks requires proactive hardening strategies capable of continuously generating adaptive attack vectors to optimize LLM defense at runtime. We present HASTE (Hard-negative Attack Sample Training Engine): a systematic framework that iteratively engineers highly evasive prompts, within a modular optimization process, to continuously enhance detection efficacy for prompt-based attack techniques. The framework is agnostic to synthetic data generation methods, and can be generalized to evaluate prompt-injection detection efficacy, with and without fuzzing, for any hard-negative or hard-positive iteration strategy. Experimental evaluation of HASTE shows that hard negative mining successfully evades baseline detectors, reducing malicious prompt detection for baseline detectors by approximately 64%. However, when integrated with detection model re-training, it optimizes the efficacy of prompt detection models with significantly fewer iteration loops compared to relative baseline strategies. The HASTE framework supports both proactive and reactive hardening of LLM defenses and guardrails. Proactively, developers can leverage HASTE to dynamically stress-test prompt injection detection systems; efficiently identifying weaknesses and strengthening defensive posture. Reactively, HASTE can mimic newly observed attack types and rapidly bridge detection coverage by teaching HASTE-optimized detection models to identify them.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19051v1</guid></item><item><title>[cs updates on arXiv.org] From Answer Givers to Design Mentors: Guiding LLMs with the Cognitive Apprenticeship Model</title><link>https://arxiv.org/abs/2601.19053</link><description>arXiv:2601.19053v1 Announce Type: new 
Abstract: Design feedback helps practitioners improve their artifacts while also fostering reflection and design reasoning. Large Language Models (LLMs) such as ChatGPT can support design work, but often provide generic, one-off suggestions that limit reflective engagement. We investigate how to guide LLMs to act as design mentors by applying the Cognitive Apprenticeship Model, which emphasizes demonstrating reasoning through six methods: modeling, coaching, scaffolding, articulation, reflection, and exploration. We operationalize these instructional methods through structured prompting and evaluate them in a within-subjects study with data visualization practitioners. Participants interacted with both a baseline LLM and an instructional LLM designed with cognitive apprenticeship prompts. Surveys, interviews, and conversational log analyses compared experiences across conditions. Our findings show that cognitively informed prompts elicit deeper design reasoning and more reflective feedback exchanges, though the baseline is sometimes preferred depending on task types or experience levels. We distill design considerations for AI-assisted feedback systems that foster reflective practice.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19053v1</guid></item><item><title>[cs updates on arXiv.org] Principled Fine-tuning of LLMs from User-Edits: A Medley of Preference, Supervision, and Reward</title><link>https://arxiv.org/abs/2601.19055</link><description>arXiv:2601.19055v1 Announce Type: new 
Abstract: We study how to fine-tune LLMs using user-edit deployment data consisting of a set of context, an agent's response, and user edits. This deployment data is naturally generated by users in applications such as LLMs-based writing assistants and coding agents. The _natural_ origin of user edits makes it a desired source for adapting and personalizing LLMs. In this setup, there emerges a unification of various feedback types namely preferences, supervised labels, and cost that are typically studied separately in the literature. In this paper, we initiate the theoretical investigation of learning from user edits. We first derive bounds for learning algorithms that learn from each of these feedback types. We prove that these algorithms have different trade-offs depending upon the user, data distribution, and model class. We then propose a simple ensembling procedure to jointly learn from these feedback types. On two domains adapted from Gao et al. 2024, we show our ensembling procedure outperforms these methods that learn from individual feedback. Further, we show that our proposed procedure can robustly adapt to different user-edit distributions at test time.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19055v1</guid></item><item><title>[cs updates on arXiv.org] Pixel-Grounded Retrieval for Knowledgeable Large Multimodal Models</title><link>https://arxiv.org/abs/2601.19060</link><description>arXiv:2601.19060v1 Announce Type: new 
Abstract: Visual Question Answering (VQA) often requires coupling fine-grained perception with factual knowledge beyond the input image. Prior multimodal Retrieval-Augmented Generation (MM-RAG) systems improve factual grounding but lack an internal policy for when and how to retrieve. We propose PixSearch, the first end-to-end Segmenting Large Multimodal Model (LMM) that unifies region-level perception and retrieval-augmented reasoning. During encoding, PixSearch emits  tokens to trigger retrieval, selects query modalities (text, image, or region), and generates pixel-level masks that directly serve as visual queries, eliminating the reliance on modular pipelines (detectors, segmenters, captioners, etc.). A two-stage supervised fine-tuning regimen with search-interleaved supervision teaches retrieval timing and query selection while preserving segmentation ability. On egocentric and entity-centric VQA benchmarks, PixSearch substantially improves factual consistency and generalization, yielding a 19.7% relative gain in accuracy on CRAG-MM compared to whole image retrieval, while retaining competitive reasoning performance on various VQA and text-only QA tasks.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19060v1</guid></item><item><title>[cs updates on arXiv.org] Thought-Transfer: Indirect Targeted Poisoning Attacks on Chain-of-Thought Reasoning Models</title><link>https://arxiv.org/abs/2601.19061</link><description>arXiv:2601.19061v1 Announce Type: new 
Abstract: Chain-of-Thought (CoT) reasoning has emerged as a powerful technique for enhancing large language models' capabilities by generating intermediate reasoning steps for complex tasks. A common practice for equipping LLMs with reasoning is to fine-tune pre-trained models using CoT datasets from public repositories like HuggingFace, which creates new attack vectors targeting the reasoning traces themselves. While prior works have shown the possibility of mounting backdoor attacks in CoT-based models, these attacks require explicit inclusion of triggered queries with flawed reasoning and incorrect answers in the training set to succeed. Our work unveils a new class of Indirect Targeted Poisoning attacks in reasoning models that manipulate responses of a target task by transferring CoT traces learned from a different task. Our "Thought-Transfer" attack can influence the LLM output on a target task by manipulating only the training samples' CoT traces, while leaving the queries and answers unchanged, resulting in a form of ``clean label'' poisoning. Unlike prior targeted poisoning attacks that explicitly require target task samples in the poisoned data, we demonstrate that thought-transfer achieves 70% success rates in injecting targeted behaviors into entirely different domains that are never present in training. Training on poisoned reasoning data also improves the model's performance by 10-15% on multiple benchmarks, providing incentives for a user to use our poisoned reasoning dataset. Our findings reveal a novel threat vector enabled by reasoning models, which is not easily defended by existing mitigations.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19061v1</guid></item><item><title>[cs updates on arXiv.org] Who's in Charge? Disempowerment Patterns in Real-World LLM Usage</title><link>https://arxiv.org/abs/2601.19062</link><description>arXiv:2601.19062v1 Announce Type: new 
Abstract: Although AI assistants are now deeply embedded in society, there has been limited empirical study of how their usage affects human empowerment. We present the first large-scale empirical analysis of disempowerment patterns in real-world AI assistant interactions, analyzing 1.5 million consumer Claude.ai conversations using a privacy-preserving approach. We focus on situational disempowerment potential, which occurs when AI assistant interactions risk leading users to form distorted perceptions of reality, make inauthentic value judgments, or act in ways misaligned with their values. Quantitatively, we find that severe forms of disempowerment potential occur in fewer than one in a thousand conversations, though rates are substantially higher in personal domains like relationships and lifestyle. Qualitatively, we uncover several concerning patterns, such as validation of persecution narratives and grandiose identities with emphatic sycophantic language, definitive moral judgments about third parties, and complete scripting of value-laden personal communications that users appear to implement verbatim. Analysis of historical trends reveals an increase in the prevalence of disempowerment potential over time. We also find that interactions with greater disempowerment potential receive higher user approval ratings, possibly suggesting a tension between short-term user preferences and long-term human empowerment. Our findings highlight the need for AI systems designed to robustly support human autonomy and flourishing.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19062v1</guid></item><item><title>[cs updates on arXiv.org] Optimizing Conversational Quality in Spoken Dialogue Systems with Reinforcement Learning from AI Feedback</title><link>https://arxiv.org/abs/2601.19063</link><description>arXiv:2601.19063v1 Announce Type: new 
Abstract: Reinforcement learning from human or AI feedback (RLHF/RLAIF) for speech-in/speech-out dialogue systems (SDS) remains underexplored, with prior work largely limited to single semantic rewards applied at the utterance level. Such setups overlook the multi-dimensional and multi-modal nature of conversational quality, which encompasses semantic coherence, audio naturalness, speaker consistency, emotion alignment, and turn-taking behavior. Moreover, they are fundamentally mismatched with duplex spoken dialogue systems that generate responses incrementally, where agents must make decisions based on partial utterances. We address these limitations with the first multi-reward RLAIF framework for SDS, combining semantic, audio-quality, and emotion-consistency rewards. To align utterance-level preferences with incremental, blockwise decoding in duplex models, we apply turn-level preference sampling and aggregate per-block log-probabilities within a single DPO objective. We present the first systematic study of preference learning for improving SDS quality in both multi-turn Chain-of-Thought and blockwise duplex models, and release a multi-reward DPO dataset to support reproducible research. Experiments show that single-reward RLAIF selectively improves its targeted metric, while joint multi-reward training yields consistent gains across semantic quality and audio naturalness. These results highlight the importance of holistic, multi-reward alignment for practical conversational SDS.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19063v1</guid></item><item><title>[cs updates on arXiv.org] Dynamic Cogeneration of Bug Reproduction Test in Agentic Program Repair</title><link>https://arxiv.org/abs/2601.19066</link><description>arXiv:2601.19066v1 Announce Type: new 
Abstract: Bug Reproduction Tests (BRTs) have been used in many agentic Automated Program Repair (APR) systems, primarily for validating promising fixes and aiding fix generation. In practice, when developers submit a patch, they often implement the BRT alongside the fix. Our experience deploying agentic APR reveals that developers similarly desire a BRT within AI-generated patches to increase their confidence. However, canonical APR systems tend to generate BRTs and fixes separately, or focus on producing only the fix in the final patch. In this paper, we study agentic APR in the context of cogeneration, where the APR agent is instructed to generate both a fix and a BRT in the same patch. We evaluate the effectiveness of different cogeneration strategies on 120 human-reported bugs at Google and characterize different cogeneration strategies by their influence on APR agent behavior. We develop and evaluate patch selectors that account for test change information to select patches with plausible fixes (and plausible BRTs). Finally, we analyze the root causes of failed cogeneration trajectories. Importantly, we show that cogeneration allows the APR agent to generate BRTs for at least as many bugs as a dedicated BRT agent, without compromising the generation rate of plausible fixes, thereby reducing engineering effort in maintaining and coordinating separate generation pipelines for fix and BRT at scale.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19066v1</guid></item><item><title>[cs updates on arXiv.org] Critical Organization of Deep Neural Networks, and p-Adic Statistical Field Theories</title><link>https://arxiv.org/abs/2601.19070</link><description>arXiv:2601.19070v1 Announce Type: new 
Abstract: We rigorously study the thermodynamic limit of deep neural networks (DNNS) and recurrent neural networks (RNNs), assuming that the activation functions are sigmoids. A thermodynamic limit is a continuous neural network, where the neurons form a continuous space with infinitely many points. We show that such a network admits a unique state in a certain region of the parameter space, which depends continuously on the parameters. This state breaks into an infinite number of states outside the mentioned region of parameter space. Then, the critical organization is a bifurcation in the parameter space, where a network transitions from a unique state to infinitely many states. We use p-adic integers to codify hierarchical structures. Indeed, we present an algorithm that recasts the hierarchical topologies used in DNNs and RNNs as p-adic tree-like structures. In this framework, the hierarchical and the critical organizations are connected. We study rigorously the critical organization of a toy model, a hierarchical edge detector for grayscale images based on p-adic cellular neural networks. The critical organization of such a network can be described as a strange attractor. In the second part, we study random versions of DNNs and RNNs. In this case, the network parameters are generalized Gaussian random variables in a space of quadratic integrable functions. We compute the probability distribution of the output given the input, in the infinite-width case. We show that it admits a power-type expansion, where the constant term is a Gaussian distribution.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19070v1</guid></item><item><title>[cs updates on arXiv.org] HalluJudge: A Reference-Free Hallucination Detection for Context Misalignment in Code Review Automation</title><link>https://arxiv.org/abs/2601.19072</link><description>arXiv:2601.19072v1 Announce Type: new 
Abstract: Large Language models (LLMs) have shown strong capabilities in code review automation, such as review comment generation, yet they suffer from hallucinations -- where the generated review comments are ungrounded in the actual code -- poses a significant challenge to the adoption of LLMs in code review workflows. To address this, we explore effective and scalable methods for a hallucination detection in LLM-generated code review comments without the reference. In this work, we design HalluJudge that aims to assess the grounding of generated review comments based on the context alignment. HalluJudge includes four key strategies ranging from direct assessment to structured multi-branch reasoning (e.g., Tree-of-Thoughts). We conduct a comprehensive evaluation of these assessment strategies across Atlassian's enterprise-scale software projects to examine the effectiveness and cost-efficiency of HalluJudge. Furthermore, we analyze the alignment between HalluJudge's judgment and developer preference of the actual LLM-generated code review comments in the real-world production. Our results show that the hallucination assessment in HalluJudge is cost-effective with an F1 score of 0.85 and an average cost of $0.009. On average, 67% of the HalluJudge assessments are aligned with the developer preference of the actual LLM-generated review comments in the online production. Our results suggest that HalluJudge can serve as a practical safeguard to reduce developers' exposure to hallucinated comments, fostering trust in AI-assisted code reviews.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19072v1</guid></item><item><title>[cs updates on arXiv.org] FTA-NTN: Fairness and Throughput Assurance in Non-Terrestrial Networks</title><link>https://arxiv.org/abs/2601.19078</link><description>arXiv:2601.19078v1 Announce Type: new 
Abstract: Designing optimal non-terrestrial network (NTN) constellations is essential for maximizing throughput and ensuring fair resource distribution. This paper presents FTA-NTN (Fairness and Throughput Assurance in Non-Terrestrial Networks), a multi-objective optimization framework that jointly maximizes throughput and fairness under realistic system constraints. The framework integrates multi-layer Walker Delta constellations, a parametric mobility model for user distributions across Canadian land regions, adaptive K-Means clustering for beamforming and user association, and Bayesian optimization for parameter tuning. Simulation results with 500 users show that FTA-NTN achieves over 9.88 Gbps of aggregate throughput with an average fairness of 0.42, corresponding to an optimal configuration of 9 planes with 15 satellites per plane in LEO and 7 planes with 3 satellites per plane in MEO. These values align with 3GPP NTN evaluation scenarios and representative system assumptions, confirming their relevance for realistic deployments. Overall, FTA-NTN demonstrates that throughput and fairness can be jointly optimized under practical constraints, advancing beyond throughput-centric designs in the literature and offering a scalable methodology for next-generation NTN deployments that supports efficient and equitable global connectivity.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19078v1</guid></item><item><title>[cs updates on arXiv.org] Neuromorphic BrailleNet: Accurate and Generalizable Braille Reading Beyond Single Characters through Event-Based Optical Tactile Sensing</title><link>https://arxiv.org/abs/2601.19079</link><description>arXiv:2601.19079v1 Announce Type: new 
Abstract: Conventional robotic Braille readers typically rely on discrete, character-by-character scanning, limiting reading speed and disrupting natural flow. Vision-based alternatives often require substantial computation, introduce latency, and degrade in real-world conditions. In this work, we present a high accuracy, real-time pipeline for continuous Braille recognition using Evetac, an open-source neuromorphic event-based tactile sensor. Unlike frame-based vision systems, the neuromorphic tactile modality directly encodes dynamic contact events during continuous sliding, closely emulating human finger-scanning strategies. Our approach combines spatiotemporal segmentation with a lightweight ResNet-based classifier to process sparse event streams, enabling robust character recognition across varying indentation depths and scanning speeds. The proposed system achieves near-perfect accuracy (&gt;=98%) at standard depths, generalizes across multiple Braille board layouts, and maintains strong performance under fast scanning. On a physical Braille board containing daily-living vocabulary, the system attains over 90% word-level accuracy, demonstrating robustness to temporal compression effects that challenge conventional methods. These results position neuromorphic tactile sensing as a scalable, low latency solution for robotic Braille reading, with broader implications for tactile perception in assistive and robotic applications.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19079v1</guid></item><item><title>[cs updates on arXiv.org] More at Stake: How Payoff and Language Shape LLM Agent Strategies in Cooperation Dilemmas</title><link>https://arxiv.org/abs/2601.19082</link><description>arXiv:2601.19082v1 Announce Type: new 
Abstract: As LLMs increasingly act as autonomous agents in interactive and multi-agent settings, understanding their strategic behavior is critical for safety, coordination, and AI-driven social and economic systems. We investigate how payoff magnitude and linguistic context shape LLM strategies in repeated social dilemmas, using a payoff-scaled Prisoner's Dilemma to isolate sensitivity to incentive strength. Across models and languages, we observe consistent behavioral patterns, including incentive-sensitive conditional strategies and cross-linguistic divergence. To interpret these dynamics, we train supervised classifiers on canonical repeated-game strategies and apply them to LLM decisions, revealing systematic, model- and language-dependent behavioral intentions, with linguistic framing sometimes matching or exceeding architectural effects. Our results provide a unified framework for auditing LLMs as strategic agents and highlight cooperation biases with direct implications for AI governance and multi-agent system design.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19082v1</guid></item><item><title>[cs updates on arXiv.org] Speed is Confidence</title><link>https://arxiv.org/abs/2601.19085</link><description>arXiv:2601.19085v1 Announce Type: new 
Abstract: Biological neural systems must be fast but are energy-constrained. Evolution's solution: act on the first signal. Winner-take-all circuits and time-to-first-spike coding implicitly treat when a neuron fires as an expression of confidence. We apply this principle to ensembles of Tiny Recursive Models (TRM). By basing the ensemble prediction solely on the first to halt rather than averaging predictions, we achieve 97.2% puzzle accuracy on Sudoku-Extreme while using 10x less compute than test-time augmentation (the baseline achieves 86.1% single-pass, 97.3% with TTA). Inference speed is an implicit indication of confidence. But can this capability be manifested as a training-only cost? Evidently yes: by maintaining K = 4 parallel latent states during training but backpropping only through the lowest-loss "winner," a single model achieves 96.9% +/- 0.6% puzzle accuracy with a single forward pass-matching TTA performance without any test-time augmentation. As in nature, this work was also resource constrained: all experimentation used a single RTX 5090. This necessitated efficiency and compelled our invention of a modified SwiGLU which made Muon viable. With Muon and K = 1 training, we exceed TRM baseline performance in 7k steps (40 min). Higher accuracy requires 36k steps: 1.5 hours for K = 1, 6 hours for K = 4.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19085v1</guid></item><item><title>[cs updates on arXiv.org] 3D-Printed Passive Reflectors for mmWave Beam Steering via Binary Aperture Control</title><link>https://arxiv.org/abs/2601.19087</link><description>arXiv:2601.19087v1 Announce Type: new 
Abstract: This paper presents a theory-to-hardware framework for fully passive millimeter-wave beam control aimed at extending indoor coverage. The reflecting aperture is modeled using an equivalent array-factor formulation in which each passive element contributes a reradiated field determined by the incident and desired departure angles. Building on this model, we develop two implementation-friendly passive design approaches: (i) binary (1-bit) spatial masking, which enables beam steering and multi-beam synthesis by selecting element participation on a dense lattice via an ON/OFF metallization pattern, and (ii) diffraction-order (periodic) steering, which exploits controlled aperture periodicity to place selected diffraction orders at prescribed angles. Theoretical analysis characterizes the asymptotic activation behavior of the binary mask and establishes a distribution-free lower-bound on the achievable gain. Prototypes are realized using a copper-backed 3D-printed substrate with stencil-guided conductive ink deposition. 60 GHz over-the-air measurements in single- and multi-beam configurations validate the predicted steering behavior. Theoretical and experimental results demonstrate that fully passive, binary-coded apertures can provide deterministic beam control and offer a scalable alternative to power-consuming reconfigurable surfaces for static indoor links.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19087v1</guid></item><item><title>[cs updates on arXiv.org] Hybrid Fault-Driven Mutation Testing for Python</title><link>https://arxiv.org/abs/2601.19088</link><description>arXiv:2601.19088v1 Announce Type: new 
Abstract: Mutation testing is an effective technique for assessing the effectiveness of test suites by systematically injecting artificial faults into programs. However, existing mutation testing techniques fall short in capturing many types of common faults in dynamically typed languages like Python. In this paper, we introduce a novel set of seven mutation operators that are inspired by prevalent anti-patterns in Python programs, designed to complement the existing general-purpose operators and broaden the spectrum of simulated faults. We propose a mutation testing technique that utilizes a hybrid of static and dynamic analyses to mutate Python programs based on these operators while minimizing equivalent mutants. We implement our approach in a tool called PyTation and evaluate it on 13 open-source Python applications. Our results show that PyTation generates mutants that complement those from general-purpose tools, exhibiting distinct behaviour under test execution and uncovering inadequacies in high-coverage test suites. We further demonstrate that PyTation produces a high proportion of unique mutants, a low cross-kill rate, and a low test overlap ratio relative to baseline tools, highlighting its novel fault model. PyTation also incurs few equivalent mutants, aided by dynamic analysis heuristics.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19088v1</guid></item><item><title>[cs updates on arXiv.org] EPAS: Efficient Training with Progressive Activation Sharing</title><link>https://arxiv.org/abs/2601.19089</link><description>arXiv:2601.19089v1 Announce Type: new 
Abstract: We present a novel method for Efficient training with Progressive Activation Sharing (EPAS). This method bridges progressive training paradigm with the phenomenon of redundant QK (or KV ) activations across deeper layers of transformers. EPAS gradually grows a sharing region during training by switching decoder layers to activation sharing mode. This results in throughput increase due to reduced compute. To utilize deeper layer redundancy, the sharing region starts from the deep end of the model and grows towards the shallow end. The EPAS trained models allow for variable region lengths of activation sharing for different compute budgets during inference. Empirical evaluations with QK activation sharing in LLaMA models ranging from 125M to 7B parameters show up to an 11.1% improvement in training throughput and up to a 29% improvement in inference throughput while maintaining similar loss curve to the baseline models. Furthermore, applying EPAS in continual pretraining to transform TinyLLaMA into an attention-sharing model yields up to a 10% improvement in average accuracy over state-of-the-art methods, emphasizing the significance of progressive training in cross layer activation sharing models.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19089v1</guid></item><item><title>[cs updates on arXiv.org] Privacy-Preserving Model Transcription with Differentially Private Synthetic Distillation</title><link>https://arxiv.org/abs/2601.19090</link><description>arXiv:2601.19090v1 Announce Type: new 
Abstract: While many deep learning models trained on private datasets have been deployed in various practical tasks, they may pose a privacy leakage risk as attackers could recover informative data or label knowledge from models. In this work, we present \emph{privacy-preserving model transcription}, a data-free model-to-model conversion solution to facilitate model deployment with a privacy guarantee. To this end, we propose a cooperative-competitive learning approach termed \emph{differentially private synthetic distillation} that learns to convert a pretrained model (teacher) into its privacy-preserving counterpart (student) via a trainable generator without access to private data. The learning collaborates with three players in a unified framework and performs alternate optimization: i)~the generator is learned to generate synthetic data, ii)~the teacher and student accept the synthetic data and compute differential private labels by flexible data or label noisy perturbation, and iii)~the student is updated with noisy labels and the generator is updated by taking the student as a discriminator for adversarial training. We theoretically prove that our approach can guarantee differential privacy and convergence. The transcribed student has good performance and privacy protection, while the resulting generator can generate private synthetic data for downstream tasks. Extensive experiments clearly demonstrate that our approach outperforms 26 state-of-the-arts.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19090v1</guid></item><item><title>[cs updates on arXiv.org] Out-of-Distribution Generalization for Neural Physics Solvers</title><link>https://arxiv.org/abs/2601.19091</link><description>arXiv:2601.19091v1 Announce Type: new 
Abstract: Neural physics solvers are increasingly used in scientific discovery, given their potential for rapid in silico insights into physical, materials, or biological systems and their long-time evolution. However, poor generalization beyond their training support limits exploration of novel designs and long-time horizon predictions. We introduce NOVA, a route to generalizable neural physics solvers that can provide rapid, accurate solutions to scenarios even under distributional shifts in partial differential equation parameters, geometries and initial conditions. By learning physics-aligned representations from an initial sparse set of scenarios, NOVA consistently achieves 1-2 orders of magnitude lower out-of-distribution errors than data-driven baselines across complex, nonlinear problems including heat transfer, diffusion-reaction and fluid flow. We further showcase NOVA's dual impact on stabilizing long-time dynamical rollouts and improving generative design through application to the simulation of nonlinear Turing systems and fluidic chip optimization. Unlike neural physics solvers that are constrained to retrieval and/or emulation within an a priori space, NOVA enables reliable extrapolation beyond known regimes, a key capability given the need for exploration of novel hypothesis spaces in scientific discovery</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19091v1</guid></item><item><title>[cs updates on arXiv.org] Axe: A Simple Unified Layout Abstraction for Machine Learning Compilers</title><link>https://arxiv.org/abs/2601.19092</link><description>arXiv:2601.19092v1 Announce Type: new 
Abstract: Scaling modern deep learning workloads demands coordinated placement of data and compute across device meshes, memory hierarchies, and heterogeneous accelerators. We present Axe Layout, a hardware-aware abstraction that maps logical tensor coordinates to a multi-axis physical space via named axes. Axe unifies tiling, sharding, replication, and offsets across inter-device distribution and on-device layouts, enabling collective primitives to be expressed consistently from device meshes to threads. Building on Axe, we design a multi-granularity, distribution-aware DSL and compiler that composes thread-local control with collective operators in a single kernel. Experiments show that our unified approach can bring performance close to hand-tuned kernels on across latest GPU devices and multi-device environments and accelerator backends.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19092v1</guid></item><item><title>[cs updates on arXiv.org] FloydNet: A Learning Paradigm for Global Relational Reasoning</title><link>https://arxiv.org/abs/2601.19094</link><description>arXiv:2601.19094v1 Announce Type: new 
Abstract: Developing models capable of complex, multi-step reasoning is a central goal in artificial intelligence. While representing problems as graphs is a powerful approach, Graph Neural Networks (GNNs) are fundamentally constrained by their message-passing mechanism, which imposes a local bottleneck that limits global, holistic reasoning. We argue that dynamic programming (DP), which solves problems by iteratively refining a global state, offers a more powerful and suitable learning paradigm. We introduce FloydNet, a new architecture that embodies this principle. In contrast to local message passing, FloydNet maintains a global, all-pairs relationship tensor and learns a generalized DP operator to progressively refine it. This enables the model to develop a task-specific relational calculus, providing a principled framework for capturing long-range dependencies. Theoretically, we prove that FloydNet achieves 3-WL (2-FWL) expressive power, and its generalized form aligns with the k-FWL hierarchy. FloydNet demonstrates state-of-the-art performance across challenging domains: it achieves near-perfect scores (often &gt;99\%) on the CLRS-30 algorithmic benchmark, finds exact optimal solutions for the general Traveling Salesman Problem (TSP) at rates significantly exceeding strong heuristics, and empirically matches the 3-WL test on the BREC benchmark. Our results establish this learned, DP-style refinement as a powerful and practical alternative to message passing for high-level graph reasoning.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19094v1</guid></item><item><title>[cs updates on arXiv.org] Dual Analysis of Continuous-time Economic Dispatch and Its Price Implications</title><link>https://arxiv.org/abs/2601.19095</link><description>arXiv:2601.19095v1 Announce Type: new 
Abstract: As load varies continuously over time, it is essential to provide continuous-time price signals that accurately reflect supply-demand balance. However, conventional discrete-time economic dispatch fails to capture the intra-temporal variations in load and generation. Its dual solution--the marginal price--may distort economic signals, leading to inefficient market incentives. To analyze these issues, this paper develops a continuous-time dispatch model and derives its dual formulation for price analysis. The continuous-time dispatch produces dual variables that can be interpreted as price signals. Piecewise time-indexed generation and price trajectories are then constructed through a parametric programming approach. The resulting price, represented by the Lagrange multiplier of the system-wide power balance constraint, evolves piecewise along the continuous-time load profile. Each segment corresponds to a critical region characterized by a set of active constraints. Furthermore, we discuss the impact of unit-specific ramping constraints on price implications. Results indicate that continuous-time generation and price trajectories provide deeper insights into the price distortions and inefficient incentives inherent in discrete-time formulations. The proposed methodology is validated on an illustrative 5-bus system and a modified IEEE RTS-2019.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19095v1</guid></item><item><title>[cs updates on arXiv.org] PsyProbe: Proactive and Interpretable Dialogue through User State Modeling for Exploratory Counseling</title><link>https://arxiv.org/abs/2601.19096</link><description>arXiv:2601.19096v1 Announce Type: new 
Abstract: Recent advances in large language models have enabled mental health dialogue systems, yet existing approaches remain predominantly reactive, lacking systematic user state modeling for proactive therapeutic exploration. We introduce PsyProbe, a dialogue system designed for the exploration phase of counseling that systematically tracks user psychological states through the PPPPPI framework (Presenting, Predisposing, Precipitating, Perpetuating, Protective, Impact) augmented with cognitive error detection. PsyProbe combines State Builder for extracting structured psychological profiles, Memory Construction for tracking information gaps, Strategy Planner for Motivational Interviewing behavioral codes, and Response Generator with Question Ideation and Critic/Revision modules to generate contextually appropriate, proactive questions. We evaluate PsyProbe with 27 participants in real-world Korean counseling scenarios, including automatic evaluation across ablation modes, user evaluation, and expert evaluation by a certified counselor. The full PsyProbe model consistently outperforms baseline and ablation modes in automatic evaluation. User evaluation demonstrates significantly increased engagement intention and improved naturalness compared to baseline. Expert evaluation shows that PsyProbe substantially improves core issue understanding and achieves question rates comparable to professional counselors, validating the effectiveness of systematic state modeling and proactive questioning for therapeutic exploration.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19096v1</guid></item><item><title>[cs updates on arXiv.org] SimTO: A simulation-based topology optimization framework for bespoke soft robotic grippers</title><link>https://arxiv.org/abs/2601.19098</link><description>arXiv:2601.19098v1 Announce Type: new 
Abstract: Soft robotic grippers are essential for grasping delicate, geometrically complex objects in manufacturing, healthcare and agriculture. However, existing grippers struggle to grasp feature-rich objects with high topological variability, including gears with sharp tooth profiles on automotive assembly lines, corals with fragile protrusions, or vegetables with irregular branching structures like broccoli. Unlike simple geometric primitives such as cubes or spheres, feature-rich objects lack a clear "optimal" contact surface, making them both difficult to grasp and susceptible to damage when grasped by existing gripper designs. Safe handling of such objects therefore requires specialized soft grippers whose morphology is tailored to the object's features. Topology optimization offers a promising approach for producing specialized grippers, but its utility is limited by the requirement for pre-defined load cases. For soft grippers interacting with feature-rich objects, these loads arise from hundreds of unpredictable gripper-object contact forces during grasping and are unknown a priori. To address this problem, we introduce SimTO, a framework that enables high-resolution topology optimization by automatically extracting load cases from a contact-based physics simulator, eliminating the need for manual load specification. Given an arbitrary feature-rich object, SimTO produces highly customized soft grippers with fine-grained morphological features tailored to the object geometry. Numerical results show our designs are not only highly specialized to feature-rich objects, but also generalize to unseen objects.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19098v1</guid></item><item><title>[cs updates on arXiv.org] m2sv: A Scalable Benchmark for Map-to-Street-View Spatial Reasoning</title><link>https://arxiv.org/abs/2601.19099</link><description>arXiv:2601.19099v1 Announce Type: new 
Abstract: Vision--language models (VLMs) achieve strong performance on many multimodal benchmarks but remain brittle on spatial reasoning tasks that require aligning abstract overhead representations with egocentric views. We introduce m2sv, a scalable benchmark for map-to-street-view spatial reasoning that asks models to infer camera viewing direction by aligning a north-up overhead map with a Street View image captured at the same real-world intersection. We release m2sv-20k, a geographically diverse benchmark with controlled ambiguity, along with m2sv-sft-11k, a curated set of structured reasoning traces for supervised fine-tuning.
  Despite strong performance on existing multimodal benchmarks, the best evaluated VLM achieves only 65.2% accuracy on m2sv, far below the human baseline of 95%. While supervised fine-tuning and reinforcement learning yield consistent gains, cross-benchmark evaluations reveal limited transfer. Beyond aggregate accuracy, we systematically analyze difficulty in map-to-street-view reasoning using both structural signals and human effort, and conduct an extensive failure analysis of adapted open models. Our findings highlight persistent gaps in geometric alignment, evidence aggregation, and reasoning consistency, motivating future work on grounded spatial reasoning across viewpoints.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19099v1</guid></item><item><title>[cs updates on arXiv.org] Reward Engineering for Reinforcement Learning in Software Tasks</title><link>https://arxiv.org/abs/2601.19100</link><description>arXiv:2601.19100v1 Announce Type: new 
Abstract: Reinforcement learning is increasingly used for code-centric tasks. These tasks include code generation, summarization, understanding, repair, testing, and optimization. This trend is growing faster with large language models and autonomous agents. A key challenge is how to design reward signals that make sense for software. In many RL problems, the reward is a clear number. In software, this is often not possible. The goal is rarely a single numeric objective. Instead, rewards are usually proxies. Common proxies check if the code compiles, passes tests, or satisfies quality metrics. Many reward designs have been proposed for code-related tasks. However, the work is scattered across areas and papers. There is no single survey that brings these approaches together and shows the full landscape of reward design for RL in software. In this survey, we provide the first systematic and comprehensive review of reward engineering for RL in software tasks. We focus on existing methods and techniques. We structure the literature along three complementary dimensions, summarizing the reward-design choices within each. We conclude with challenges and recommendations in the reward design space for SE tasks.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19100v1</guid></item><item><title>[cs updates on arXiv.org] OWLEYE: Zero-Shot Learner for Cross-Domain Graph Data Anomaly Detection</title><link>https://arxiv.org/abs/2601.19102</link><description>arXiv:2601.19102v1 Announce Type: new 
Abstract: Graph data is informative to represent complex relationships such as transactions between accounts, communications between devices, and dependencies among machines or processes. Correspondingly, graph anomaly detection (GAD) plays a critical role in identifying anomalies across various domains, including finance, cybersecurity, manufacturing, etc. Facing the large-volume and multi-domain graph data, nascent efforts attempt to develop foundational generalist models capable of detecting anomalies in unseen graphs without retraining. To the best of our knowledge, the different feature semantics and dimensions of cross-domain graph data heavily hinder the development of the graph foundation model, leaving further in-depth continual learning and inference capabilities a quite open problem. Hence, we propose OWLEYE, a novel zero-shot GAD framework that learns transferable patterns of normal behavior from multiple graphs, with a threefold contribution. First, OWLEYE proposes a cross-domain feature alignment module to harmonize feature distributions, which preserves domain-specific semantics during alignment. Second, with aligned features, to enable continuous learning capabilities, OWLEYE designs the multi-domain multi-pattern dictionary learning to encode shared structural and attribute-based patterns. Third, for achieving the in-context learning ability, OWLEYE develops a truncated attention-based reconstruction module to robustly detect anomalies without requiring labeled data for unseen graph-structured data. Extensive experiments on real-world datasets demonstrate that OWLEYE achieves superior performance and generalizability compared to state-of-the-art baselines, establishing a strong foundation for scalable and label-efficient anomaly detection.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19102v1</guid></item><item><title>[cs updates on arXiv.org] Glance and Focus Reinforcement for Pan-cancer Screening</title><link>https://arxiv.org/abs/2601.19103</link><description>arXiv:2601.19103v1 Announce Type: new 
Abstract: Pan-cancer screening in large-scale CT scans remains challenging for existing AI methods, primarily due to the difficulty of localizing diverse types of tiny lesions in large CT volumes. The extreme foreground-background imbalance significantly hinders models from focusing on diseased regions, while redundant focus on healthy regions not only decreases the efficiency but also increases false positives. Inspired by radiologists' glance and focus diagnostic strategy, we introduce GF-Screen, a Glance and Focus reinforcement learning framework for pan-cancer screening. GF-Screen employs a Glance model to localize the diseased regions and a Focus model to precisely segment the lesions, where segmentation results of the Focus model are leveraged to reward the Glance model via Reinforcement Learning (RL). Specifically, the Glance model crops a group of sub-volumes from the entire CT volume and learns to select the sub-volumes with lesions for the Focus model to segment. Given that the selecting operation is non-differentiable for segmentation training, we propose to employ the segmentation results to reward the Glance model. To optimize the Glance model, we introduce a novel group relative learning paradigm, which employs group relative comparison to prioritize high-advantage predictions and discard low-advantage predictions within sub-volume groups, not only improving efficiency but also reducing false positives. In this way, for the first time, we effectively extend cutting-edge RL techniques to tackle the specific challenges in pan-cancer screening. Extensive experiments on 16 internal and 7 external datasets across 9 lesion types demonstrated the effectiveness of GF-Screen. Notably, GF-Screen leads the public validation leaderboard of MICCAI FLARE25 pan-cancer challenge, surpassing the FLARE24 champion solution by a large margin (+25.6% DSC and +28.2% NSD).</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19103v1</guid></item><item><title>[cs updates on arXiv.org] Detecting and Correcting Hallucinations in LLM-Generated Code via Deterministic AST Analysis</title><link>https://arxiv.org/abs/2601.19106</link><description>arXiv:2601.19106v1 Announce Type: new 
Abstract: Large Language Models (LLMs) for code generation boost productivity but frequently introduce Knowledge Conflicting Hallucinations (KCHs), subtle, semantic errors, such as non-existent API parameters, that evade linters and cause runtime failures. Existing mitigations like constrained decoding or non-deterministic LLM-in-the-loop repair are often unreliable for these errors. This paper investigates whether a deterministic, static-analysis framework can reliably detect \textit{and} auto-correct KCHs. We propose a post-processing framework that parses generated code into an Abstract Syntax Tree (AST) and validates it against a dynamically-generated Knowledge Base (KB) built via library introspection. This non-executing approach uses deterministic rules to find and fix both API and identifier-level conflicts. On a manually-curated dataset of 200 Python snippets, our framework detected KCHs with 100\% precision and 87.6\% recall (0.934 F1-score), and successfully auto-corrected 77.0\% of all identified hallucinations. Our findings demonstrate that this deterministic post-processing approach is a viable and reliable alternative to probabilistic repair, offering a clear path toward trustworthy code generation.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19106v1</guid></item><item><title>[cs updates on arXiv.org] TinyTorch: Building Machine Learning Systems from First Principles</title><link>https://arxiv.org/abs/2601.19107</link><description>arXiv:2601.19107v1 Announce Type: new 
Abstract: Machine learning systems engineering requires a deep understanding of framework internals. Yet most current education separates algorithms from systems. Students learn gradient descent without measuring memory usage, and attention mechanisms without profiling computational cost. This split leaves graduates unprepared to debug real production failures and widens the gap between machine learning research and reliable deployment. We present TinyTorch, a 20 module curriculum in which students implement the core components of PyTorch, including tensors, autograd, optimizers, and neural networks, entirely in pure Python. The curriculum is built around three pedagogical principles. Progressive disclosure gradually introduces complexity as students build confidence. Systems first integration embeds memory and performance awareness from the very beginning. Historical milestone validation guides students to recreate key breakthroughs, from the Perceptron in 1958 to modern Transformers, using only code they have written themselves. TinyTorch requires only a laptop with 4GB of RAM and no GPU, making machine learning systems education accessible worldwide. Its goal is to prepare the next generation of AI engineers, practitioners who understand not only what machine learning systems do, but why they work and how to make them scale. The curriculum is available as open source at mlsysbook.ai slash tinytorch.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19107v1</guid></item><item><title>[cs updates on arXiv.org] Interpretable and Perceptually-Aligned Music Similarity with Pretrained Embeddings</title><link>https://arxiv.org/abs/2601.19109</link><description>arXiv:2601.19109v1 Announce Type: new 
Abstract: Perceptual similarity representations enable music retrieval systems to determine which songs sound most similar to listeners. State-of-the-art approaches based on task-specific training via self-supervised metric learning show promising alignment with human judgment, but are difficult to interpret or generalize due to limited dataset availability. We show that pretrained text-audio embeddings (CLAP and MuQ-MuLan) offer comparable perceptual alignment on similarity tasks without any additional fine-tuning. To surpass this baseline, we introduce a novel method to perceptually align pretrained embeddings with source separation and linear optimization on ABX preference data from listening tests. Our model provides interpretable and controllable instrument-wise weights, allowing music producers to retrieve stem-level loops and samples based on mixed reference songs.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19109v1</guid></item><item><title>[cs updates on arXiv.org] Uncertainty-Aware 3D Emotional Talking Face Synthesis with Emotion Prior Distillation</title><link>https://arxiv.org/abs/2601.19112</link><description>arXiv:2601.19112v1 Announce Type: new 
Abstract: Emotional Talking Face synthesis is pivotal in multimedia and signal processing, yet existing 3D methods suffer from two critical challenges: poor audio-vision emotion alignment, manifested as difficult audio emotion extraction and inadequate control over emotional micro-expressions; and a one-size-fits-all multi-view fusion strategy that overlooks uncertainty and feature quality differences, undermining rendering quality. We propose UA-3DTalk, Uncertainty-Aware 3D Emotional Talking Face Synthesis with emotion prior distillation, which has three core modules: the Prior Extraction module disentangles audio into content-synchronized features for alignment and person-specific complementary features for individualization; the Emotion Distillation module introduces a multi-modal attention-weighted fusion mechanism and 4D Gaussian encoding with multi-resolution code-books, enabling fine-grained audio emotion extraction and precise control of emotional micro-expressions; the Uncertainty-based Deformation deploys uncertainty blocks to estimate view-specific aleatoric (input noise) and epistemic (model parameters) uncertainty, realizing adaptive multi-view fusion and incorporating a multi-head decoder for Gaussian primitive optimization to mitigate the limitations of uniform-weight fusion. Extensive experiments on regular and emotional datasets show UA-3DTalk outperforms state-of-the-art methods like DEGSTalk and EDTalk by 5.2% in E-FID for emotion alignment, 3.1% in SyncC for lip synchronization, and 0.015 in LPIPS for rendering quality. Project page: https://mrask999.github.io/UA-3DTalk</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19112v1</guid></item><item><title>[cs updates on arXiv.org] A Hybrid Discriminative and Generative System for Universal Speech Enhancement</title><link>https://arxiv.org/abs/2601.19113</link><description>arXiv:2601.19113v1 Announce Type: new 
Abstract: Universal speech enhancement aims at handling inputs with various speech distortions and recording conditions. In this work, we propose a novel hybrid architecture that synergizes the signal fidelity of discriminative modeling with the reconstruction capabilities of generative modeling. Our system utilizes the discriminative TF-GridNet model with the Sampling-Frequency-Independent strategy to handle variable sampling rates universally. In parallel, an autoregressive model combined with spectral mapping modeling generates detail-rich speech while effectively suppressing generative artifacts. Finally, a fusion network learns adaptive weights of the two outputs under the optimization of signal-level losses and the comprehensive Speech Quality Assessment (SQA) loss. Our proposed system is evaluated in the ICASSP 2026 URGENT Challenge (Track 1) and ranks the third place.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19113v1</guid></item><item><title>[cs updates on arXiv.org] Reg-TTR, Test-Time Refinement for Fast, Robust and Accurate Image Registration</title><link>https://arxiv.org/abs/2601.19114</link><description>arXiv:2601.19114v1 Announce Type: new 
Abstract: Traditional image registration methods are robust but slow due to their iterative nature. While deep learning has accelerated inference, it often struggles with domain shifts. Emerging registration foundation models offer a balance of speed and robustness, yet typically cannot match the peak accuracy of specialized models trained on specific datasets. To mitigate this limitation, we propose Reg-TTR, a test-time refinement framework that synergizes the complementary strengths of both deep learning and conventional registration techniques. By refining the predictions of pre-trained models at inference, our method delivers significantly improved registration accuracy at a modest computational cost, requiring only 21% additional inference time (0.56s). We evaluate Reg-TTR on two distinct tasks and show that it achieves state-of-the-art (SOTA) performance while maintaining inference speeds close to previous deep learning methods. As foundation models continue to emerge, our framework offers an efficient strategy to narrow the performance gap between registration foundation models and SOTA methods trained on specialized datasets. The source code will be publicly available following the acceptance of this work.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19114v1</guid></item><item><title>[cs updates on arXiv.org] FBSDiff++: Improved Frequency Band Substitution of Diffusion Features for Efficient and Highly Controllable Text-Driven Image-to-Image Translation</title><link>https://arxiv.org/abs/2601.19115</link><description>arXiv:2601.19115v1 Announce Type: new 
Abstract: With large-scale text-to-image (T2I) diffusion models achieving significant advancements in open-domain image creation, increasing attention has been focused on their natural extension to the realm of text-driven image-to-image (I2I) translation, where a source image acts as visual guidance to the generated image in addition to the textual guidance provided by the text prompt. We propose FBSDiff, a novel framework adapting off-the-shelf T2I diffusion model into the I2I paradigm from a fresh frequency-domain perspective. Through dynamic frequency band substitution of diffusion features, FBSDiff realizes versatile and highly controllable text-driven I2I in a plug-and-play manner (without need for model training, fine-tuning, or online optimization), allowing appearance-guided, layout-guided, and contour-guided I2I translation by progressively substituting low-frequency band, mid-frequency band, and high-frequency band of latent diffusion features, respectively. In addition, FBSDiff flexibly enables continuous control over I2I correlation intensity simply by tuning the bandwidth of the substituted frequency band. To further promote image translation efficiency, flexibility, and functionality, we propose FBSDiff++ which improves upon FBSDiff mainly in three aspects: (1) accelerate inference speed by a large margin (8.9$\times$ speedup in inference) with refined model architecture; (2) improve the Frequency Band Substitution module to allow for input source images of arbitrary resolution and aspect ratio; (3) extend model functionality to enable localized image manipulation and style-specific content creation with only subtle adjustments to the core method. Extensive qualitative and quantitative experiments verify superiority of FBSDiff++ in I2I translation visual quality, efficiency, versatility, and controllability compared to related advanced approaches.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19115v1</guid></item><item><title>[cs updates on arXiv.org] Agree to Disagree: Consensus-Free Flocking under Constraints</title><link>https://arxiv.org/abs/2601.19119</link><description>arXiv:2601.19119v1 Announce Type: new 
Abstract: Robots sometimes have to work together with a mixture of partially-aligned or conflicting goals. Flocking - coordinated motion through cohesion, alignment, and separation - traditionally assumes uniform desired inter-agent distances. Many practical applications demand greater flexibility, as the diversity of types and configurations grows with the popularity of multi-agent systems in society. Moreover, agents often operate without guarantees of trust or secure communication. Motivated by these challenges we update well-established frameworks by relaxing this assumption of shared inter-agent distances and constraints. Through a new form of constrained collective potential function, we introduce a solution that permits negotiation of these parameters. In the spirit of the traditional flocking control canon, this negotiation is achieved purely through local observations and does not require any global information or inter-agent communication. The approach is robust to semi-trust scenarios, where neighbouring agents pursue conflicting goals. We validate the effectiveness of the approach through a series of simulations.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19119v1</guid></item><item><title>[cs updates on arXiv.org] RobustExplain: Evaluating Robustness of LLM-Based Explanation Agents for Recommendation</title><link>https://arxiv.org/abs/2601.19120</link><description>arXiv:2601.19120v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly used to generate natural-language explanations in recommender systems, acting as explanation agents that reason over user behavior histories. While prior work has focused on explanation fluency and relevance under fixed inputs, the robustness of LLM-generated explanations to realistic user behavior noise remains largely unexplored. In real-world web platforms, interaction histories are inherently noisy due to accidental clicks, temporal inconsistencies, missing values, and evolving preferences, raising concerns about explanation stability and user trust. We present RobustExplain, the first systematic evaluation framework for measuring the robustness of LLM-generated recommendation explanations. RobustExplain introduces five realistic user behavior perturbations evaluated across multiple severity levels and a multi-dimensional robustness metric capturing semantic, keyword, structural, and length consistency. Our goal is to establish a principled, task-level evaluation framework and initial robustness baselines, rather than to provide a comprehensive leaderboard across all available LLMs. Experiments on four representative LLMs (7B--70B) show that current models exhibit only moderate robustness, with larger models achieving up to 8% higher stability. Our results establish the first robustness benchmarks for explanation agents and highlight robustness as a critical dimension for trustworthy, agent-driven recommender systems at web scale.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19120v1</guid></item><item><title>[cs updates on arXiv.org] LLMs as Orchestrators: Constraint-Compliant Multi-Agent Optimization for Recommendation Systems</title><link>https://arxiv.org/abs/2601.19121</link><description>arXiv:2601.19121v1 Announce Type: new 
Abstract: Recommendation systems must optimize multiple objectives while satisfying hard business constraints such as fairness and coverage. For example, an e-commerce platform may require every recommendation list to include items from multiple sellers and at least one newly listed product; violating such constraints--even once--is unacceptable in production. Prior work on multi-objective recommendation and recent LLM-based recommender agents largely treat constraints as soft penalties or focus on item scoring and interaction, leading to frequent violations in real-world deployments. How to leverage LLMs for coordinating constrained optimization in recommendation systems remains underexplored. We propose DualAgent-Rec, an LLM-coordinated dual-agent framework for constrained multi-objective e-commerce recommendation. The framework separates optimization into an Exploitation Agent that prioritizes accuracy under hard constraints and an Exploration Agent that promotes diversity through unconstrained Pareto search. An LLM-based coordinator adaptively allocates resources between agents based on optimization progress and constraint satisfaction, while an adaptive epsilon-relaxation mechanism guarantees feasibility of final solutions. Experiments on the Amazon Reviews 2023 dataset demonstrate that DualAgent-Rec achieves 100% constraint satisfaction and improves Pareto hypervolume by 4-6% over strong baselines, while maintaining competitive accuracy-diversity trade-offs. These results indicate that LLMs can act as effective orchestration agents for deployable and constraint-compliant recommendation systems.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19121v1</guid></item><item><title>[cs updates on arXiv.org] Exploring Weaknesses in Function Call Models via Reinforcement Learning: An Adversarial Data Augmentation Approach</title><link>https://arxiv.org/abs/2601.19122</link><description>arXiv:2601.19122v1 Announce Type: new 
Abstract: Function call capabilities have become crucial for Large Language Models (LLMs), enabling them to interact more effectively with external tools and APIs. Existing methods for improving the function call capabilities of LLMs rely on data obtained either through manual annotation or automated generation by models, and use this data to finetune the LLMs. However, these methods often lack targeted design and are constrained by fixed patterns and data distributions, which limits their effectiveness in enhancing the generalization and robustness of function call LLMs. To address this limitation, we propose a novel adversarial data augmentation method that employs reinforcement learning to systematically identify and target the weaknesses of function call LLMs. Our training framework introduces a query model trained with reinforcement learning (RL) to generate adversarial queries that are specifically designed to challenge function call (FC) models. This approach adopts a zero sum game formulation, where the query model and the FC model engage in iterative alternating training. Overall, our method advances the development of more robust FC models and provides a systematic way to identify and correct weaknesses in the ability of LLMs to interact with external tools.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19122v1</guid></item><item><title>[cs updates on arXiv.org] Leveraging Sentence-oriented Augmentation and Transformer-Based Architecture for Vietnamese-Bahnaric Translation</title><link>https://arxiv.org/abs/2601.19124</link><description>arXiv:2601.19124v1 Announce Type: new 
Abstract: The Bahnar people, an ethnic minority in Vietnam with a rich ancestral heritage, possess a language of immense cultural and historical significance. The government places a strong emphasis on preserving and promoting the Bahnaric language by making it accessible online and encouraging communication across generations. Recent advancements in artificial intelligence, such as Neural Machine Translation (NMT), have brought about a transformation in translation by improving accuracy and fluency. This, in turn, contributes to the revival of the language through educational efforts, communication, and documentation. Specifically, NMT is pivotal in enhancing accessibility for Bahnaric speakers, making information and content more readily available. Nevertheless, the translation of Vietnamese into Bahnaric faces practical challenges due to resource constraints, especially given the limited resources available for the Bahnaric language. To address this, we employ state-of-the-art techniques in NMT along with two augmentation strategies for domain-specific Vietnamese-Bahnaric translation task. Importantly, both approaches are flexible and can be used with various neural machine translation models. Additionally, they do not require complex data preprocessing steps, the training of additional systems, or the acquisition of extra data beyond the existing training parallel corpora.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19124v1</guid></item><item><title>[cs updates on arXiv.org] How Entanglement Reshapes the Geometry of Quantum Differential Privacy</title><link>https://arxiv.org/abs/2601.19126</link><description>arXiv:2601.19126v1 Announce Type: new 
Abstract: Quantum differential privacy provides a rigorous framework for quantifying privacy guarantees in quantum information processing. While classical correlations are typically regarded as adversarial to privacy, the role of their quantum analogue, entanglement, is not well understood. In this work, we investigate how quantum entanglement fundamentally shapes quantum local differential privacy (QLDP). We consider a bipartite quantum system whose input state has a prescribed level of entanglement, characterized by a lower bound on the entanglement entropy. Each subsystem is then processed by a local quantum mechanism and measured using local operations only, ensuring that no additional entanglement is generated during the process. Our main result reveals a sharp phase-transition phenomenon in the relation between entanglement and QLDP: below a mechanism-dependent entropy threshold, the optimal privacy leakage level mirrors that of unentangled inputs; beyond this threshold, the privacy leakage level decreases with the entropy, which strictly improves privacy guarantees and can even turn some non-private mechanisms into private ones. The phase-transition phenomenon gives rise to a nonlinear dependence of the privacy leakage level on the entanglement entropy, even though the underlying quantum mechanisms and measurements are linear. We show that the transition is governed by the intrinsic non-convex geometry of the set of entanglement-constrained quantum states, which we parametrize as a smooth manifold and analyze via Riemannian optimization. Our findings demonstrate that entanglement serves as a genuine privacy-enhancing resource, offering a geometric and operational foundation for designing robust privacy-preserving quantum protocols.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19126v1</guid></item><item><title>[cs updates on arXiv.org] Implicit Non-Causal Factors are Out via Dataset Splitting for Domain Generalization Object Detection</title><link>https://arxiv.org/abs/2601.19127</link><description>arXiv:2601.19127v1 Announce Type: new 
Abstract: Open world object detection faces a significant challenge in domain-invariant representation, i.e., implicit non-causal factors. Most domain generalization (DG) methods based on domain adversarial learning (DAL) pay much attention to learn domain-invariant information, but often overlook the potential non-causal factors. We unveil two critical causes: 1) The domain discriminator-based DAL method is subject to the extremely sparse domain label, i.e., assigning only one domain label to each dataset, thus can only associate explicit non-causal factor, which is incredibly limited. 2) The non-causal factors, induced by unidentified data bias, are excessively implicit and cannot be solely discerned by conventional DAL paradigm. Based on these key findings, inspired by the Granular-Ball perspective, we propose an improved DAL method, i.e., GB-DAL. The proposed GB-DAL utilizes Prototype-based Granular Ball Splitting (PGBS) module to generate more dense domains from limited datasets, akin to more fine-grained granular balls, indicating more potential non-causal factors. Inspired by adversarial perturbations akin to non-causal factors, we propose a Simulated Non-causal Factors (SNF) module as a means of data augmentation to reduce the implicitness of non-causal factors, and facilitate the training of GB-DAL. Comparative experiments on numerous benchmarks demonstrate that our method achieves better generalization performance in novel circumstances.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19127v1</guid></item><item><title>[cs updates on arXiv.org] Resolving Primitive-Sharing Ambiguity in Long-Tailed Industrial Point Cloud Segmentation via Spatial Context Constraints</title><link>https://arxiv.org/abs/2601.19128</link><description>arXiv:2601.19128v1 Announce Type: new 
Abstract: Industrial point cloud segmentation for Digital Twin construction faces a persistent challenge: safety-critical components such as reducers and valves are systematically misclassified. These failures stem from two compounding factors: such components are rare in training data, yet they share identical local geometry with dominant structures like pipes. This work identifies a dual crisis unique to industrial 3D data extreme class imbalance 215:1 ratio compounded by geometric ambiguity where most tail classes share cylindrical primitives with head classes. Existing frequency-based re-weighting methods address statistical imbalance but cannot resolve geometric ambiguity. We propose spatial context constraints that leverage neighborhood prediction consistency to disambiguate locally similar structures. Our approach extends the Class-Balanced (CB) Loss framework with two architecture-agnostic mechanisms: (1) Boundary-CB, an entropy-based constraint that emphasizes ambiguous boundaries, and (2) Density-CB, a density-based constraint that compensates for scan-dependent variations. Both integrate as plug-and-play modules without network modifications, requiring only loss function replacement. On the Industrial3D dataset (610M points from water treatment facilities), our method achieves 55.74% mIoU with 21.7% relative improvement on tail-class performance (29.59% vs. 24.32% baseline) while preserving head-class accuracy (88.14%). Components with primitive-sharing ambiguity show dramatic gains: reducer improves from 0% to 21.12% IoU; valve improves by 24.3% relative. This resolves geometric ambiguity without the typical head-tail trade-off, enabling reliable identification of safety-critical components for automated knowledge extraction in Digital Twin applications.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19128v1</guid></item><item><title>[cs updates on arXiv.org] CLIP-Guided Unsupervised Semantic-Aware Exposure Correction</title><link>https://arxiv.org/abs/2601.19129</link><description>arXiv:2601.19129v1 Announce Type: new 
Abstract: Improper exposure often leads to severe loss of details, color distortion, and reduced contrast. Exposure correction still faces two critical challenges: (1) the ignorance of object-wise regional semantic information causes the color shift artifacts; (2) real-world exposure images generally have no ground-truth labels, and its labeling entails massive manual editing. To tackle the challenges, we propose a new unsupervised semantic-aware exposure correction network. It contains an adaptive semantic-aware fusion module, which effectively fuses the semantic information extracted from a pre-trained Fast Segment Anything Model into a shared image feature space. Then the fused features are used by our multi-scale residual spatial mamba group to restore the details and adjust the exposure. To avoid manual editing, we propose a pseudo-ground truth generator guided by CLIP, which is fine-tuned to automatically identify exposure situations and instruct the tailored corrections. Also, we leverage the rich priors from the FastSAM and CLIP to develop a semantic-prompt consistency loss to enforce semantic consistency and image-prompt alignment for unsupervised training. Comprehensive experimental results illustrate the effectiveness of our method in correcting real-world exposure images and outperforms state-of-the-art unsupervised methods both numerically and visually.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19129v1</guid></item><item><title>[cs updates on arXiv.org] Structural Monotonicity in Transmission Scheduling for Remote State Estimation with Hidden Channel Mode</title><link>https://arxiv.org/abs/2601.19131</link><description>arXiv:2601.19131v1 Announce Type: new 
Abstract: This study treats transmission scheduling for remote state estimation over unreliable channels with a hidden mode. A local Kalman estimator selects scheduling actions, such as power allocation and resource usage, and communicates with a remote estimator based on acknowledgement feedback, balancing estimation performance and communication cost. The resulting problem is naturally formulated as a partially observable Markov decision process (POMDP). In settings with observable channel modes, it is well known that monotonicity of the value function can be established via investigating order-preserving property of transition kernels. In contrast, under partial observability, the transition kernels generally lack this property, which prevents the direct application of standard monotonicity arguments. To overcome this difficulty, we introduce a novel technique, referred to as state-space folding, which induces transformed transition kernels recovering order preservation on the folded space. This transformation enables a rigorous monotonicity analysis in the partially observable setting. As a representative implication, we focus on an associated optimal stopping formulation and show that the resulting optimal scheduling policy admits a threshold structure.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19131v1</guid></item><item><title>[cs updates on arXiv.org] QA-ReID: Quality-Aware Query-Adaptive Convolution Leveraging Fused Global and Structural Cues for Clothes-Changing ReID</title><link>https://arxiv.org/abs/2601.19133</link><description>arXiv:2601.19133v1 Announce Type: new 
Abstract: Unlike conventional person re-identification (ReID), clothes-changing ReID (CC-ReID) presents severe challenges due to substantial appearance variations introduced by clothing changes. In this work, we propose the Quality-Aware Dual-Branch Matching (QA-ReID), which jointly leverages RGB-based features and parsing-based representations to model both global appearance and clothing-invariant structural cues. These heterogeneous features are adaptively fused through a multi-modal attention module. At the matching stage, we further design the Quality-Aware Query Adaptive Convolution (QAConv-QA), which incorporates pixel-level importance weighting and bidirectional consistency constraints to enhance robustness against clothing variations. Extensive experiments demonstrate that QA-ReID achieves state-of-the-art performance on multiple benchmarks, including PRCC, LTCC, and VC-Clothes, and significantly outperforms existing approaches under cross-clothing scenarios.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19133v1</guid></item><item><title>[cs updates on arXiv.org] Evaluating Nova 2.0 Lite model under Amazon's Frontier Model Safety Framework</title><link>https://arxiv.org/abs/2601.19134</link><description>arXiv:2601.19134v1 Announce Type: new 
Abstract: Amazon published its Frontier Model Safety Framework (FMSF) as part of the Paris AI summit, following which we presented a report on Amazon's Premier model. In this report, we present an evaluation of Nova 2.0 Lite. Nova 2.0 Lite was made generally available from amongst the Nova 2.0 series and is one of its most capable reasoning models. The model processes text, images, and video with a context length of up to 1M tokens, enabling analysis of large codebases, documents, and videos in a single prompt. We present a comprehensive evaluation of Nova 2.0 Lite's critical risk profile under the FMSF. Evaluations target three high-risk domains-Chemical, Biological, Radiological and Nuclear (CBRN), Offensive Cyber Operations, and Automated AI R&amp;amp;D-and combine automated benchmarks, expert red-teaming, and uplift studies to determine whether the model exceeds release thresholds. We summarize our methodology and report core findings. We will continue to enhance our safety evaluation and mitigation pipelines as new risks and capabilities associated with frontier models are identified.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19134v1</guid></item><item><title>[cs updates on arXiv.org] TFFM: Topology-Aware Feature Fusion Module via Latent Graph Reasoning for Retinal Vessel Segmentation</title><link>https://arxiv.org/abs/2601.19136</link><description>arXiv:2601.19136v1 Announce Type: new 
Abstract: Precise segmentation of retinal arteries and veins carries the diagnosis of systemic cardiovascular conditions. However, standard convolutional architectures often yield topologically disjointed segmentations, characterized by gaps and discontinuities that render reliable graph-based clinical analysis impossible despite high pixel-level accuracy. To address this, we introduce a topology-aware framework engineered to maintain vascular connectivity. Our architecture fuses a Topological Feature Fusion Module (TFFM) that maps local feature representations into a latent graph space, deploying Graph Attention Networks to capture global structural dependencies often missed by fixed receptive fields. Furthermore, we drive the learning process with a hybrid objective function, coupling Tversky loss for class imbalance with soft clDice loss to explicitly penalize topological disconnects. Evaluation on the Fundus-AVSeg dataset reveals state-of-the-art performance, achieving a combined Dice score of 90.97% and a 95% Hausdorff Distance of 3.50 pixels. Notably, our method decreases vessel fragmentation by approximately 38% relative to baselines, yielding topologically coherent vascular trees viable for automated biomarker quantification. We open-source our code at https://tffm-module.github.io/.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19136v1</guid></item><item><title>[cs updates on arXiv.org] AgenticSCR: An Autonomous Agentic Secure Code Review for Immature Vulnerabilities Detection</title><link>https://arxiv.org/abs/2601.19138</link><description>arXiv:2601.19138v1 Announce Type: new 
Abstract: Secure code review is critical at the pre-commit stage, where vulnerabilities must be caught early under tight latency and limited-context constraints. Existing SAST-based checks are noisy and often miss immature, context-dependent vulnerabilities, while standalone Large Language Models (LLMs) are constrained by context windows and lack explicit tool use. Agentic AI, which combine LLMs with autonomous decision-making, tool invocation, and code navigation, offer a promising alternative, but their effectiveness for pre-commit secure code review is not yet well understood. In this work, we introduce AgenticSCR, an agentic AI for secure code review for detecting immature vulnerabilities during the pre-commit stage, augmented by security-focused semantic memories. Using our own curated benchmark of immature vulnerabilities, tailored to the pre-commit secure code review, we empirically evaluate how accurate is our AgenticSCR for localizing, detecting, and explaining immature vulnerabilities. Our results show that AgenticSCR achieves at least 153% relatively higher percentage of correct code review comments than the static LLM-based baseline, and also substantially surpasses SAST tools. Moreover, AgenticSCR generates more correct comments in four out of five vulnerability types, consistently and significantly outperforming all other baselines. These findings highlight the importance of Agentic Secure Code Review, paving the way towards an emerging research area of immature vulnerability detection.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19138v1</guid></item><item><title>[cs updates on arXiv.org] Native LLM and MLLM Inference at Scale on Apple Silicon</title><link>https://arxiv.org/abs/2601.19139</link><description>arXiv:2601.19139v1 Announce Type: new 
Abstract: The growing adoption of Apple Silicon for machine learning development has created demand for efficient inference solutions that leverage its unique unified memory architecture. However, existing tools either lack native optimization (PyTorch MPS) or focus solely on text models (llama.cpp), leaving multimodal workloads underserved. We present vllm-mlx, a framework for efficient LLM and MLLM inference on Apple Silicon built natively on MLX. For text models, we achieve 21% to 87% higher throughput than llama.cpp across models ranging from Qwen3-0.6B to Nemotron-30B, while providing continuous batching that scales to 4.3x aggregate throughput at 16 concurrent requests. For multimodal models, we introduce content-based prefix caching that eliminates redundant vision encoding by identifying identical images through content hashing, regardless of input format. Our evaluation on Apple M4 Max demonstrates throughput of up to 525 tokens per second on text models and 28x speedup on repeated image queries, reducing multimodal latency from 21.7 seconds to under 1 second. Video analysis with up to 64 frames achieves 24.7x cache speedup. We release our implementation as open source to support efficient inference on consumer Apple hardware.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19139v1</guid></item><item><title>[cs updates on arXiv.org] Length-Adaptive Interest Network for Balancing Long and Short Sequence Modeling in CTR Prediction</title><link>https://arxiv.org/abs/2601.19142</link><description>arXiv:2601.19142v1 Announce Type: new 
Abstract: User behavior sequences in modern recommendation systems exhibit significant length heterogeneity, ranging from sparse short-term interactions to rich long-term histories. While longer sequences provide more context, we observe that increasing the maximum input sequence length in existing CTR models paradoxically degrades performance for short-sequence users due to attention polarization and length imbalance in training data. To address this, we propose LAIN(Length-Adaptive Interest Network), a plug-and-play framework that explicitly incorporates sequence length as a conditioning signal to balance long- and short-sequence modeling. LAIN consists of three lightweight components: a Spectral Length Encoder that maps length into continuous representations, Length-Conditioned Prompting that injects global contextual cues into both long- and short-term behavior branches, and Length-Modulated Attention that adaptively adjusts attention sharpness based on sequence length. Extensive experiments on three real-world benchmarks across five strong CTR backbones show that LAIN consistently improves overall performance, achieving up to 1.15% AUC gain and 2.25% log loss reduction. Notably, our method significantly improves accuracy for short-sequence users without sacrificing longsequence effectiveness. Our work offers a general, efficient, and deployable solution to mitigate length-induced bias in sequential recommendation.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19142v1</guid></item><item><title>[cs updates on arXiv.org] Robust Out-of-Order Retrieval for Grid-Based Storage at Maximum Capacity</title><link>https://arxiv.org/abs/2601.19144</link><description>arXiv:2601.19144v1 Announce Type: new 
Abstract: This paper proposes a framework for improving the operational efficiency of automated storage systems under uncertainty. It considers a 2D grid-based storage for uniform-sized loads (e.g., containers, pallets, or totes), which are moved by a robot (or other manipulator) along a collision-free path in the grid. The loads are labeled (i.e., unique) and must be stored in a given sequence, and later be retrieved in a different sequence -- an operational pattern that arises in logistics applications, such as last-mile distribution centers and shipyards. The objective is to minimize the load relocations to ensure efficient retrieval. A previous result guarantees a zero-relocation solution for known storage and retrieval sequences, even for storage at full capacity, provided that the side of the grid through which loads are stored/retrieved is at least 3 cells wide. However, in practice, the retrieval sequence can change after the storage phase. To address such uncertainty, this work investigates \emph{$k$-bounded perturbations} during retrieval, under which any two loads may depart out of order if they are originally at most $k$ positions apart. We prove that a $\Theta(k)$ grid width is necessary and sufficient for eliminating relocations at maximum capacity. We also provide an efficient solver for computing a storage arrangement that is robust to such perturbations. To address the higher-uncertainty case where perturbations exceed $k$, a strategy is introduced to effectively minimize relocations. Extensive experiments show that, for $k$ up to half the grid width, the proposed storage-retrieval framework essentially eliminates relocations. For $k$ values up to the full grid width, relocations are reduced by $50\%+$.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19144v1</guid></item><item><title>[cs updates on arXiv.org] The Promise and Reality of Continuous Integration Caching: An Empirical Study of Travis CI Builds</title><link>https://arxiv.org/abs/2601.19146</link><description>arXiv:2601.19146v1 Announce Type: new 
Abstract: Continuous Integration (CI) provides early feedback by automatically building software, but long build durations can hinder developer productivity. CI services offer caching mechanisms to speed up builds by reusing infrequently changing artifacts, yet little is known about how caching is adopted in practice and what challenges it entails. In this paper, we conduct a large-scale empirical study of CI caching in Travis CI, analyzing 513,384 builds from 1,279 GitHub projects. We find that only 30% of projects adopt CI caching, and early adoption is strongly associated with project maturity, such as more dependencies, more commits, and longer CI lifespans. To understand why many projects do not adopt caching, we submitted pull requests enabling caching in non-adopting projects, and nearly half were accepted or merged. Developer feedback suggests that non- or late adoption mainly stems from limited awareness of CI caching support. We also examine cache maintenance and identify five common activities, performed by 24% of cache-enabled projects. Although one-third of projects see substantial build-time reductions, cache uploads occur in 97% of builds, and 33% of projects contain stale cached artifacts. Finally, our analysis of reported caching issues shows developers mainly struggle with corrupted or outdated caches or request broader caching features. Overall, CI caching does not help all projects, needs ongoing maintenance, and is more complex in practice than many developers expect.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19146v1</guid></item><item><title>[cs updates on arXiv.org] Optimal Motion Planning for Two Square Robots in a Rectilinear Environment</title><link>https://arxiv.org/abs/2601.19147</link><description>arXiv:2601.19147v1 Announce Type: new 
Abstract: Let $\mathcal{W} \subset \mathbb{R}^2$ be a rectilinear polygonal environment (that is, a rectilinear polygon potentially with holes) with a total of $n$ vertices, and let $A,B$ be two robots, each modeled as an axis-aligned unit square, that can move rectilinearly inside $\mathcal{W}$. The goal is to compute a collision-free motion plan $\boldsymbol{\pi}$, that is, a motion plan that continuously moves $A$ from $s_A$ to $t_A$ and $B$ from $s_B$ to $t_B$ so that $A$ and $B$ remain inside $\mathcal{W}$ and do not collide with each other during the motion. We study two variants of this problem which are focused additionally on the optimality of $\boldsymbol{\pi}$, and obtain the following results.
  1. Min-Sum: Here the goal is to compute a motion plan that minimizes the sum of the lengths of the paths of the robots. We present an $O(n^4\log{n})$-time algorithm for computing an optimal solution to the min-sum problem. This is the first polynomial-time algorithm to compute an optimal, collision-free motion of two robots amid obstacles in a planar polygonal environment.
  2. Min-Makespan: Here the robots can move with at most unit speed, and the goal is to compute a motion plan that minimizes the maximum time taken by a robot to reach its target location. We prove that the min-makespan variant is NP-hard.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19147v1</guid></item><item><title>[cs updates on arXiv.org] GPCR-Filter: a deep learning framework for efficient and precise GPCR modulator discovery</title><link>https://arxiv.org/abs/2601.19149</link><description>arXiv:2601.19149v1 Announce Type: new 
Abstract: G protein-coupled receptors (GPCRs) govern diverse physiological processes and are central to modern pharmacology. Yet discovering GPCR modulators remains challenging because receptor activation often arises from complex allosteric effects rather than direct binding affinity, and conventional assays are slow, costly, and not optimized for capturing these dynamics. Here we present GPCR-Filter, a deep learning framework specifically developed for GPCR modulator discovery. We assembled a high-quality dataset of over 90,000 experimentally validated GPCR-ligand pairs, providing a robust foundation for training and evaluation. GPCR-Filter integrates the ESM-3 protein language model for high-fidelity GPCR sequence representations with graph neural networks that encode ligand structures, coupled through an attention-based fusion mechanism that learns receptor-ligand functional relationships. Across multiple evaluation settings, GPCR-Filter consistently outperforms state-of-the-art compound-protein interaction models and exhibits strong generalization to unseen receptors and ligands. Notably, the model successfully identified micromolar-level agonists of the 5-HT\textsubscript{1A} receptor with distinct chemical frameworks. These results establish GPCR-Filter as a scalable and effective computational approach for GPCR modulator discovery, advancing AI-assisted drug development for complex signaling systems.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19149v1</guid></item><item><title>[cs updates on arXiv.org] TS-Debate: Multimodal Collaborative Debate for Zero-Shot Time Series Reasoning</title><link>https://arxiv.org/abs/2601.19151</link><description>arXiv:2601.19151v1 Announce Type: new 
Abstract: Recent progress at the intersection of large language models (LLMs) and time series (TS) analysis has revealed both promise and fragility. While LLMs can reason over temporal structure given carefully engineered context, they often struggle with numeric fidelity, modality interference, and principled cross-modal integration. We present TS-Debate, a modality-specialized, collaborative multi-agent debate framework for zero-shot time series reasoning. TS-Debate assigns dedicated expert agents to textual context, visual patterns, and numerical signals, preceded by explicit domain knowledge elicitation, and coordinates their interaction via a structured debate protocol. Reviewer agents evaluate agent claims using a verification-conflict-calibration mechanism, supported by lightweight code execution and numerical lookup for programmatic verification. This architecture preserves modality fidelity, exposes conflicting evidence, and mitigates numeric hallucinations without task-specific fine-tuning. Across 20 tasks spanning three public benchmarks, TS-Debate achieves consistent and significant performance improvements over strong baselines, including standard multimodal debate in which all agents observe all inputs.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19151v1</guid></item><item><title>[cs updates on arXiv.org] Analysis of Shuffling Beyond Pure Local Differential Privacy</title><link>https://arxiv.org/abs/2601.19154</link><description>arXiv:2601.19154v1 Announce Type: new 
Abstract: Shuffling is a powerful way to amplify privacy of a local randomizer in private distributed data analysis, but existing analyses mostly treat the local differential privacy (DP) parameter $\varepsilon_0$ as the only knob and give generic upper bounds that can be loose and do not even characterize how shuffling amplifies privacy for basic mechanisms such as the Gaussian mechanism. We revisit the privacy blanket bound of Balle et al. (the blanket divergence) and develop an asymptotic analysis that applies to a broad class of local randomizers under mild regularity assumptions, without requiring pure local DP. Our key finding is that the leading term of the blanket divergence depends on the local mechanism only through a single scalar parameter $\chi$, which we call the shuffle index. By applying this asymptotic analysis to both upper and lower bounds, we obtain a tight band for $\delta_n$ in the shuffled mechanism's $(\varepsilon_n,\delta_n)$-DP guarantee. Moreover, we derive a simple structural necessary and sufficient condition on the local randomizer under which the blanket-divergence-based upper and lower bounds coincide asymptotically. $k$-RR families with $k\ge3$ satisfy this condition, while for generalized Gaussian mechanisms the condition may not hold but the resulting band remains tight. Finally, we complement the asymptotic theory with an FFT-based algorithm for computing the blanket divergence at finite $n$, which offers rigorously controlled relative error and near-linear running time in $n$, providing a practical numerical analysis for shuffle DP.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19154v1</guid></item><item><title>[cs updates on arXiv.org] LocationAgent: A Hierarchical Agent for Image Geolocation via Decoupling Strategy and Evidence from Parametric Knowledge</title><link>https://arxiv.org/abs/2601.19155</link><description>arXiv:2601.19155v1 Announce Type: new 
Abstract: Image geolocation aims to infer capture locations based on visual content. Fundamentally, this constitutes a reasoning process composed of \textit{hypothesis-verification cycles}, requiring models to possess both geospatial reasoning capabilities and the ability to verify evidence against geographic facts. Existing methods typically internalize location knowledge and reasoning patterns into static memory via supervised training or trajectory-based reinforcement fine-tuning. Consequently, these methods are prone to factual hallucinations and generalization bottlenecks in open-world settings or scenarios requiring dynamic knowledge. To address these challenges, we propose a Hierarchical Localization Agent, called LocationAgent. Our core philosophy is to retain hierarchical reasoning logic within the model while offloading the verification of geographic evidence to external tools. To implement hierarchical reasoning, we design the RER architecture (Reasoner-Executor-Recorder), which employs role separation and context compression to prevent the drifting problem in multi-step reasoning. For evidence verification, we construct a suite of clue exploration tools that provide diverse evidence to support location reasoning. Furthermore, to address data leakage and the scarcity of Chinese data in existing datasets, we introduce CCL-Bench (China City Location Bench), an image geolocation benchmark encompassing various scene granularities and difficulty levels. Extensive experiments demonstrate that LocationAgent significantly outperforms existing methods by at least 30\% in zero-shot settings.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19155v1</guid></item><item><title>[cs updates on arXiv.org] Accelerating Generative Recommendation via Simple Categorical User Sequence Compression</title><link>https://arxiv.org/abs/2601.19158</link><description>arXiv:2601.19158v1 Announce Type: new 
Abstract: Although generative recommenders demonstrate improved performance with longer sequences, their real-time deployment is hindered by substantial computational costs. To address this challenge, we propose a simple yet effective method for compressing long-term user histories by leveraging inherent item categorical features, thereby preserving user interests while enhancing efficiency. Experiments on two large-scale datasets demonstrate that, compared to the influential HSTU model, our approach achieves up to a 6x reduction in computational cost and up to 39% higher accuracy at comparable cost (i.e., similar sequence length).</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19158v1</guid></item><item><title>[cs updates on arXiv.org] KUBEDIRECT: Unleashing the Full Power of the Cluster Manager for Serverless Computing</title><link>https://arxiv.org/abs/2601.19160</link><description>arXiv:2601.19160v1 Announce Type: new 
Abstract: FaaS platforms rely on cluster managers like Kubernetes for resource management. Kubernetes is popular due to its state-centric APIs that decouple the control plane into modular controllers. However, to scale out a burst of FaaS instances, message passing becomes the primary bottleneck as controllers have to exchange extensive state through the API Server. Existing solutions opt for a clean-slate redesign of cluster managers, but at the expense of compatibility with existing ecosystem and substantial engineering effort.
  We present KUBEDIRECT, a Kubernetes-based cluster manager for FaaS. We find that there exists a common narrow waist across FaaS platform that allows us to achieve both efficiency and external compatibility. Our insight is that the sequential structure of the narrow waist obviates the need for a single source of truth, allowing us to bypass the API Server and perform direct message passing for efficiency. However, our approach introduces a set of ephemeral states across controllers, making it challenging to enforce end-to-end semantics due to the absence of centralized coordination. KUBEDIRECT employs a novel state management scheme that leverages the narrow waist as a hierarchical write-back cache, ensuring consistency and convergence to the desired state. KUBEDIRECT can seamlessly integrate with Kubernetes, adding ~150 LoC per controller. Experiments show that KUBEDIRECT reduces serving latency by 26.7x over Knative, and has similar performance as the state-of-the-art clean-slate platform Dirigent.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19160v1</guid></item><item><title>[cs updates on arXiv.org] Educational Database Prototype: the Simplest of All</title><link>https://arxiv.org/abs/2601.19165</link><description>arXiv:2601.19165v1 Announce Type: new 
Abstract: Database Management System (DBMS) is designed to help store and process large collections of data, and is incredibly flexible to perform various kinds of optimizations as long as it achieves serializability with a high-level interface available. The current undergraduate level DBMS course in UW-Madison (i.e., CS564) involves implementing specific modules of DB architecture, including B+ tree, but students may end up spending numerous amounts of effort on corner cases and not gaining a more comprehensive understanding of the internal design. Thus, we present EduDB, a simple database prototype for educational purposes that provides students a clean, concise, and comprehensive overview of the database system. We also attempt to develop an integrative series of course projects based on EduDB, which offers a platform for students to perform any optimization learned during the semester.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19165v1</guid></item><item><title>[cs updates on arXiv.org] Nonvisual Support for Understanding and Reasoning about Data Structures</title><link>https://arxiv.org/abs/2601.19168</link><description>arXiv:2601.19168v1 Announce Type: new 
Abstract: Blind and visually impaired (BVI) computer science students face systematic barriers when learning data structures: current accessibility approaches typically translate diagrams into alternative text, focusing on visual appearance rather than preserving the underlying structure essential for conceptual understanding. More accessible alternatives often do not scale in complexity, cost to produce, or both. Motivated by a recent shift to tools for creating visual diagrams from code, we propose a solution that automatically creates accessible representations from structural information about diagrams. Based on a Wizard-of-Oz study, we derive design requirements for an automated system, Arboretum, that compiles text-based diagram specifications into three synchronized nonvisual formats$\unicode{x2013}$tabular, navigable, and tactile. Our evaluation with BVI users highlights the strength of tactile graphics for complex tasks such as binary search; the benefits of offering multiple, complementary nonvisual representations; and limitations of existing digital navigation patterns for structural reasoning. This work reframes access to data structures by preserving their structural properties. The solution is a practical system to advance accessible CS education.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19168v1</guid></item><item><title>[cs updates on arXiv.org] Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement</title><link>https://arxiv.org/abs/2601.19170</link><description>arXiv:2601.19170v1 Announce Type: new 
Abstract: Automatically extracting workflows as procedural graphs from natural language is promising yet underexplored, demanding both structural validity and logical alignment. While recent large language models (LLMs) show potential for procedural graph extraction, they often produce ill-formed structures or misinterpret logical flows. We present \model{}, a multi-agent framework that formulates procedural graph extraction as a multi-round reasoning process with dedicated structural and logical refinement. The framework iterates through three stages: (1) a graph extraction phase with the graph builder agent, (2) a structural feedback phase in which a simulation agent diagnoses and explains structural defects, and (3) a logical feedback phase in which a semantic agent aligns semantics between flow logic and linguistic cues in the source text. Important feedback is prioritized and expressed in natural language, which is injected into subsequent prompts, enabling interpretable and controllable refinement. This modular design allows agents to target distinct error types without supervision or parameter updates. Experiments demonstrate that \model{} achieves substantial improvements in both structural correctness and logical consistency over strong baselines.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19170v1</guid></item><item><title>[cs updates on arXiv.org] Bridging Gulfs in UI Generation through Semantic Guidance</title><link>https://arxiv.org/abs/2601.19171</link><description>arXiv:2601.19171v1 Announce Type: new 
Abstract: While generative AI enables high-fidelity UI generation from text prompts, users struggle to articulate design intent and evaluate or refine results-creating gulfs of execution and evaluation. To understand the information needed for UI generation, we conducted a thematic analysis of UI prompting guidelines, identifying key design semantics and discovering that they are hierarchical and interdependent. Leveraging these findings, we developed a system that enables users to specify semantics, visualize relationships, and extract how semantics are reflected in generated UIs. By making semantics serve as an intermediate representation between human intent and AI output, our system bridges both gulfs by making requirements explicit and outcomes interpretable. A comparative user study suggests that our approach enhances users' perceived control over intent expression, outcome interpretation, and facilitates more predictable, iterative refinement. Our work demonstrates how explicit semantic representation enables systematic and explainable exploration of design possibilities in AI-driven UI design.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19171v1</guid></item><item><title>[cs updates on arXiv.org] SHIELD: An Auto-Healing Agentic Defense Framework for LLM Resource Exhaustion Attacks</title><link>https://arxiv.org/abs/2601.19174</link><description>arXiv:2601.19174v1 Announce Type: new 
Abstract: Sponge attacks increasingly threaten LLM systems by inducing excessive computation and DoS. Existing defenses either rely on statistical filters that fail on semantically meaningful attacks or use static LLM-based detectors that struggle to adapt as attack strategies evolve. We introduce SHIELD, a multi-agent, auto-healing defense framework centered on a three-stage Defense Agent that integrates semantic similarity retrieval, pattern matching, and LLM-based reasoning. Two auxiliary agents, a Knowledge Updating Agent and a Prompt Optimization Agent, form a closed self-healing loop, when an attack bypasses detection, the system updates an evolving knowledgebase, and refines defense instructions. Extensive experiments show that SHIELD consistently outperforms perplexity-based and standalone LLM defenses, achieving high F1 scores across both non-semantic and semantic sponge attacks, demonstrating the effectiveness of agentic self-healing against evolving resource-exhaustion threats.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19174v1</guid></item><item><title>[cs updates on arXiv.org] A Scalable Inter-edge Correlation Modeling in CopulaGNN for Link Sign Prediction</title><link>https://arxiv.org/abs/2601.19175</link><description>arXiv:2601.19175v1 Announce Type: new 
Abstract: Link sign prediction on a signed graph is a task to determine whether the relationship represented by an edge is positive or negative. Since the presence of negative edges violates the graph homophily assumption that adjacent nodes are similar, regular graph methods have not been applicable without auxiliary structures to handle them. We aim to directly model the latent statistical dependency among edges with the Gaussian copula and its corresponding correlation matrix, extending CopulaGNN. However, a naive modeling of edge-edge relations is computationally intractable even for a graph with moderate scale. To address this, we propose to 1) represent the correlation matrix as a Gramian of edge embeddings, significantly reducing the number of parameters, and 2) reformulate the conditional probability distribution to dramatically reduce the inference cost. We theoretically verify scalability of our method by proving its linear convergence. Also, our extensive experiments demonstrate that it achieves significantly faster convergence than baselines, maintaining competitive prediction performance to the state-of-the-art models.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19175v1</guid></item><item><title>[cs updates on arXiv.org] Create Benchmarks for Data Lakes</title><link>https://arxiv.org/abs/2601.19176</link><description>arXiv:2601.19176v1 Announce Type: new 
Abstract: Data lakes have emerged as a flexible and scalable solution for storing and analyzing large volumes of heterogeneous data, including structured, semi-structured, and unstructured formats. Despite their growing adoption in both industry and academia, there is a lack of standardized and comprehensive benchmarks for evaluating the performance of data lake systems. Existing benchmarks primarily target traditional data warehouses and focus on structured SQL workloads, making them insufficient for capturing the diverse workloads and access patterns typical of data lakes.
  In this work, we propose a new benchmarking framework for data lakes that aims to provide an objective and comparative evaluation of different data lake implementations. Our benchmark covers multiple data types and workload models, including data retrieval, aggregation, querying, and similarity search, which is a common yet underexplored operation in existing benchmarks. We measure key performance metrics such as query execution time, metadata generation time, and metadata size across different scale factors. The benchmark is designed to be extensible and reproducible, enabling users to generate datasets and evaluate data lake systems under realistic and diverse scenarios. We conduct our experiments on CloudLab and demonstrate how the proposed benchmark can be used to compare both commercial and open-source data lake platforms.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19176v1</guid></item><item><title>[cs updates on arXiv.org] CollectiveKV: Decoupling and Sharing Collaborative Information in Sequential Recommendation</title><link>https://arxiv.org/abs/2601.19178</link><description>arXiv:2601.19178v1 Announce Type: new 
Abstract: Sequential recommendation models are widely used in applications, yet they face stringent latency requirements. Mainstream models leverage the Transformer attention mechanism to improve performance, but its computational complexity grows with the sequence length, leading to a latency challenge for long sequences. Consequently, KV cache technology has recently been explored in sequential recommendation systems to reduce inference latency. However, KV cache introduces substantial storage overhead in sequential recommendation systems, which often have a large user base with potentially very long user history sequences. In this work, we observe that KV sequences across different users exhibit significant similarities, indicating the existence of collaborative signals in KV. Furthermore, we analyze the KV using singular value decomposition (SVD) and find that the information in KV can be divided into two parts: the majority of the information is shareable across users, while a small portion is user-specific. Motivated by this, we propose CollectiveKV, a cross-user KV sharing mechanism. It captures the information shared across users through a learnable global KV pool. During inference, each user retrieves high-dimensional shared KV from the pool and concatenates them with low-dimensional user-specific KV to obtain the final KV. Experiments on five sequential recommendation models and three datasets show that our method can compress the KV cache to only 0.8% of its original size, while maintaining or even enhancing model performance.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19178v1</guid></item><item><title>[cs updates on arXiv.org] Learning Ordered Representations in Latent Space for Intrinsic Dimension Estimation via Principal Component Autoencoder</title><link>https://arxiv.org/abs/2601.19179</link><description>arXiv:2601.19179v1 Announce Type: new 
Abstract: Autoencoders have long been considered a nonlinear extension of Principal Component Analysis (PCA). Prior studies have demonstrated that linear autoencoders (LAEs) can recover the ordered, axis-aligned principal components of PCA by incorporating non-uniform $\ell_2$ regularization or by adjusting the loss function. However, these approaches become insufficient in the nonlinear setting, as the remaining variance cannot be properly captured independently of the nonlinear mapping. In this work, we propose a novel autoencoder framework that integrates non-uniform variance regularization with an isometric constraint. This design serves as a natural generalization of PCA, enabling the model to preserve key advantages, such as ordered representations and variance retention, while remaining effective for nonlinear dimensionality reduction tasks.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19179v1</guid></item><item><title>[cs updates on arXiv.org] SNR-Edit: Structure-Aware Noise Rectification for Inversion-Free Flow-Based Editing</title><link>https://arxiv.org/abs/2601.19180</link><description>arXiv:2601.19180v1 Announce Type: new 
Abstract: Inversion-free image editing using flow-based generative models challenges the prevailing inversion-based pipelines. However, existing approaches rely on fixed Gaussian noise to construct the source trajectory, leading to biased trajectory dynamics and causing structural degradation or quality loss. To address this, we introduce SNR-Edit, a training-free framework achieving faithful Latent Trajectory Correction via adaptive noise control. Mechanistically, SNR-Edit uses structure-aware noise rectification to inject segmentation constraints into the initial noise, anchoring the stochastic component of the source trajectory to the real image's implicit inversion position and reducing trajectory drift during source--target transport. This lightweight modification yields smoother latent trajectories and ensures high-fidelity structural preservation without requiring model tuning or inversion. Across SD3 and FLUX, evaluations on PIE-Bench and SNR-Bench show that SNR-Edit delivers performance on pixel-level metrics and VLM-based scoring, while adding only about 1s overhead per image.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19180v1</guid></item><item><title>[cs updates on arXiv.org] Information-Theoretic Secure Aggregation over Regular Graphs</title><link>https://arxiv.org/abs/2601.19183</link><description>arXiv:2601.19183v1 Announce Type: new 
Abstract: Large-scale decentralized learning frameworks such as federated learning (FL), require both communication efficiency and strong data security, motivating the study of secure aggregation (SA). While information-theoretic SA is well understood in centralized and fully connected networks, its extension to decentralized networks with limited local connectivity remains largely unexplored. This paper introduces \emph{topological secure aggregation} (TSA), which studies one-shot, information-theoretically secure aggregation of neighboring users' inputs over arbitrary network topologies. We develop a unified linear design framework that characterizes TSA achievability through the spectral properties of the communication graph, specifically the kernel of a diagonally modulated adjacency matrix. For several representative classes of $d$-regular graphs including ring, prism and complete topologies, we establish the optimal communication and secret key rate region. In particular, to securely compute one symbol of the neighborhood sum, each user must (i) store at least one key symbol, (ii) broadcast at least one message symbol, and (iii) collectively, all users must hold at least $d$ i.i.d. key symbols. Notably, this total key requirement depends only on the \emph{neighborhood size} $d$, independent of the network size, revealing a fundamental limit of SA in decentralized networks with limited local connectivity.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19183v1</guid></item><item><title>[cs updates on arXiv.org] Foresight Learning for SEC Risk Prediction</title><link>https://arxiv.org/abs/2601.19189</link><description>arXiv:2601.19189v1 Announce Type: new 
Abstract: Risk disclosures in SEC filings describe potential adverse events but rarely quantify their likelihood, limiting their usefulness for probabilistic analysis. A central obstacle is the absence of large-scale, risk-level supervision linking disclosed risks to realized outcomes.
  We introduce a fully automated data generation pipeline that converts qualitative SEC risk disclosures into temporally grounded supervision using only public data. For each filing, the pipeline generates firm-specific, time-bounded risk queries from the Risk Factors section and labels them by automatically resolving outcomes against subsequent disclosures.
  Using this dataset of risk queries and outcomes grounded in SEC filings, we train a compact large language model to estimate the probability that a disclosed risk will materialize within a specified horizon. Despite its modest size, the resulting model substantially improves over pretrained and heuristic baselines, and outperforms frontier general-purpose models, including GPT-5, on probabilistic accuracy and calibration.
  More broadly, this work demonstrates that Foresight Learning enables scalable and fully automated training of domain-specific expert models using only raw, chronological, in-domain text -- without proprietary data, external corpora, or manual annotation. The resulting models achieve frontier-level performance while remaining deployable on a single GPU. This result suggests a general pathway for learning calibrated, decision-relevant signals from naturally occurring enterprise documents.
  To support transparency and reproducibility, we open-source the evaluation dataset used in this study.
  Evaluation Data: https://huggingface.co/datasets/LightningRodLabs/sec_risk_questions_test_set
  Data Generation Platform: https://lightningrod.ai/
  SDK: https://github.com/lightning-rod-labs/lightningrod-python-sdk</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19189v1</guid></item><item><title>[cs updates on arXiv.org] Transparency-First Medical Language Models: Datasheets, Model Cards, and End-to-End Data Provenance for Clinical NLP</title><link>https://arxiv.org/abs/2601.19191</link><description>arXiv:2601.19191v1 Announce Type: new 
Abstract: We introduce TeMLM, a set of transparency-first release artifacts for clinical language models. TeMLM unifies provenance, data transparency, modeling transparency, and governance into a single, machine-checkable release bundle. We define an artifact suite (TeMLM-Card, TeMLM-Datasheet, TeMLM-Provenance) and a lightweight conformance checklist for repeatable auditing. We instantiate the artifacts on Technetium-I, a large-scale synthetic clinical NLP dataset with 498,000 notes, 7.74M PHI entity annotations across 10 types, and ICD-9-CM diagnosis labels, and report reference results for ProtactiniumBERT (about 100 million parameters) on PHI de-identification (token classification) and top-50 ICD-9 code extraction (multi-label classification). We emphasize that synthetic benchmarks are valuable for tooling and process validation, but models should be validated on real clinical data prior to deployment.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19191v1</guid></item><item><title>[cs updates on arXiv.org] CoReTab: Improving Multimodal Table Understanding with Code-driven Reasoning</title><link>https://arxiv.org/abs/2601.19193</link><description>arXiv:2601.19193v1 Announce Type: new 
Abstract: Existing datasets for multimodal table understanding, such as MMTab, primarily provide short factual answers without explicit multi-step reasoning supervision. Models trained on these datasets often generate brief responses that offers insufficient accuracy and limited interpretability into how these models arrive at the final answer. We introduce CoReTab, a code-driven reasoning framework that produces scalable, interpretable, and automatically verifiable annotations by coupling multi-step reasoning with executable Python code. Using the CoReTab framework, we curate a dataset of 115K verified samples averaging 529 tokens per response and fine-tune open-source MLLMs through a three-stage pipeline. We evaluate the resulting model trained on CoReTab across 17 MMTab benchmarks spanning table question answering, fact verification, and table structure understanding. Our model achieves significant gains of +6.2%, +5.7%, and +25.6%, respectively, over MMTab-trained baselines, while producing transparent and verifiable reasoning traces. These results establish CoReTab as a robust and generalizable supervision framework for improving multi-step reasoning in multimodal table understanding.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19193v1</guid></item><item><title>[cs updates on arXiv.org] HELM: A Human-Centered Evaluation Framework for LLM-Powered Recommender Systems</title><link>https://arxiv.org/abs/2601.19197</link><description>arXiv:2601.19197v1 Announce Type: new 
Abstract: The integration of Large Language Models (LLMs) into recommendation systems has introduced unprecedented capabilities for natural language understanding, explanation generation, and conversational interactions. However, existing evaluation methodologies focus predominantly on traditional accuracy metrics, failing to capture the multifaceted human-centered qualities that determine the real-world user experience. We introduce \framework{} (\textbf{H}uman-centered \textbf{E}valuation for \textbf{L}LM-powered reco\textbf{M}menders), a comprehensive evaluation framework that systematically assesses LLM-powered recommender systems across five human-centered dimensions: \textit{Intent Alignment}, \textit{Explanation Quality}, \textit{Interaction Naturalness}, \textit{Trust \&amp; Transparency}, and \textit{Fairness \&amp; Diversity}. Through extensive experiments involving three state-of-the-art LLM-based recommenders (GPT-4, LLaMA-3.1, and P5) across three domains (movies, books, and restaurants), and rigorous evaluation by 12 domain experts using 847 recommendation scenarios, we demonstrate that \framework{} reveals critical quality dimensions invisible to traditional metrics. Our results show that while GPT-4 achieves superior explanation quality (4.21/5.0) and interaction naturalness (4.35/5.0), it exhibits a significant popularity bias (Gini coefficient 0.73) compared to traditional collaborative filtering (0.58). We release \framework{} as an open-source toolkit to advance human-centered evaluation practices in the recommender systems community.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19197v1</guid></item><item><title>[cs updates on arXiv.org] Propagating Similarity, Mitigating Uncertainty: Similarity Propagation-enhanced Uncertainty for Multimodal Recommendation</title><link>https://arxiv.org/abs/2601.19198</link><description>arXiv:2601.19198v1 Announce Type: new 
Abstract: Multimodal Recommendation (MMR) systems are crucial for modern platforms but are often hampered by inherent noise and uncertainty in modal features, such as blurry images, diverse visual appearances, or ambiguous text. Existing methods often overlook this modality-specific uncertainty, leading to ineffective feature fusion. Furthermore, they fail to leverage rich similarity patterns among users and items to refine representations and their corresponding uncertainty estimates. To address these challenges, we propose a novel framework, Similarity Propagation-enhanced Uncertainty for Multimodal Recommendation (SPUMR). SPUMR explicitly models and mitigates uncertainty by first constructing the Modality Similarity Graph and the Collaborative Similarity Graph to refine representations from both content and behavioral perspectives. The Uncertainty-aware Preference Aggregation module then adaptively fuses the refined multimodal features, assigning greater weight to more reliable modalities. Extensive experiments on three benchmark datasets demonstrate that SPUMR achieves significant improvements over existing leading methods.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19198v1</guid></item><item><title>[cs updates on arXiv.org] MAGNET: Towards Adaptive GUI Agents with Memory-Driven Knowledge Evolution</title><link>https://arxiv.org/abs/2601.19199</link><description>arXiv:2601.19199v1 Announce Type: new 
Abstract: Mobile GUI agents powered by large foundation models enable autonomous task execution, but frequent updates altering UI appearance and reorganizing workflows cause agents trained on historical data to fail. Despite surface changes, functional semantics and task intents remain fundamentally stable. Building on this insight, we introduce MAGNET, a memory-driven adaptive agent framework with dual-level memory: stationary memory linking diverse visual features to stable functional semantics for robust action grounding and procedural memory capturing stable task intents across varying workflows. We propose a dynamic memory evolution mechanism that continuously refines both memories by prioritizing frequently accessed knowledge. Online benchmark AndroidWorld evaluations show substantial improvements over baselines, while offline benchmarks confirm consistent gains under distribution shifts. These results validate that leveraging stable structures across interface changes improves agent performance and generalization in evolving software environments.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19199v1</guid></item><item><title>[cs updates on arXiv.org] Do Images Speak Louder than Words? Investigating the Effect of Textual Misinformation in VLMs</title><link>https://arxiv.org/abs/2601.19202</link><description>arXiv:2601.19202v1 Announce Type: new 
Abstract: Vision-Language Models (VLMs) have shown strong multimodal reasoning capabilities on Visual-Question-Answering (VQA) benchmarks. However, their robustness against textual misinformation remains under-explored. While existing research has studied the effect of misinformation in text-only domains, it is not clear how VLMs arbitrate between contradictory information from different modalities. To bridge the gap, we first propose the CONTEXT-VQA (i.e., Conflicting Text) dataset, consisting of image-question pairs together with systematically generated persuasive prompts that deliberately conflict with visual evidence. Then, a thorough evaluation framework is designed and executed to benchmark the susceptibility of various models to these conflicting multimodal inputs. Comprehensive experiments over 11 state-of-the-art VLMs reveal that these models are indeed vulnerable to misleading textual prompts, often overriding clear visual evidence in favor of the conflicting text, and show an average performance drop of over 48.2% after only one round of persuasive conversation. Our findings highlight a critical limitation in current VLMs and underscore the need for improved robustness against textual manipulation.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19202v1</guid></item><item><title>[cs updates on arXiv.org] Before Smelling the Video: A Two-Stage Pipeline for Interpretable Video-to-Scent Plans</title><link>https://arxiv.org/abs/2601.19203</link><description>arXiv:2601.19203v1 Announce Type: new 
Abstract: Olfactory cues can enhance immersion in interactive media, yet smell remains rare because it is difficult to author and synchronize with dynamic video. Prior olfactory interfaces rely on designer triggers and fixed event-to-odor mappings that do not scale to unconstrained content. This work examines whether semantic planning for smell is intelligible to people before physical scent delivery. We present a video-to-scent planning pipeline that separates visual semantic extraction using a vision-language model from semantic-to-olfactory inference using a large language model. Two survey studies compare system-generated scent plans with over-inclusive and naive baselines. Results show consistent preference for plans that prioritize perceptually salient cues and align scent changes with visible actions, supporting semantic planning as a foundation for future olfactory media systems.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19203v1</guid></item><item><title>[cs updates on arXiv.org] MATA: A Trainable Hierarchical Automaton System for Multi-Agent Visual Reasoning</title><link>https://arxiv.org/abs/2601.19204</link><description>arXiv:2601.19204v1 Announce Type: new 
Abstract: Recent vision-language models have strong perceptual ability but their implicit reasoning is hard to explain and easily generates hallucinations on complex queries. Compositional methods improve interpretability, but most rely on a single agent or hand-crafted pipeline and cannot decide when to collaborate across complementary agents or compete among overlapping ones. We introduce MATA (Multi-Agent hierarchical Trainable Automaton), a multi-agent system presented as a hierarchical finite-state automaton for visual reasoning whose top-level transitions are chosen by a trainable hyper agent. Each agent corresponds to a state in the hyper automaton, and runs a small rule-based sub-automaton for reliable micro-control. All agents read and write a shared memory, yielding transparent execution history. To supervise the hyper agent's transition policy, we build transition-trajectory trees and transform to memory-to-next-state pairs, forming the MATA-SFT-90K dataset for supervised finetuning (SFT). The finetuned LLM as the transition policy understands the query and the capacity of agents, and it can efficiently choose the optimal agent to solve the task. Across multiple visual reasoning benchmarks, MATA achieves the state-of-the-art results compared with monolithic and compositional baselines. The code and dataset are available at https://github.com/ControlNet/MATA.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19204v1</guid></item><item><title>[cs updates on arXiv.org] Refactoring and Equivalence in Rust: Expanding the REM Toolchain with a Novel Approach to Automated Equivalence Proofs</title><link>https://arxiv.org/abs/2601.19207</link><description>arXiv:2601.19207v1 Announce Type: new 
Abstract: Refactoring tools are central to modern development, with extract-function refactorings used heavily in day-to-day work. For Rust, however, ownership, borrowing, and advanced type features make automated extract-function refactoring challenging. Existing tools either rely on slow compiler-based analysis, support only restricted language fragments, or provide little assurance beyond "it still compiles." This paper presents REM2.0, a new extract-function and verification toolchain for Rust. REM2.0 works atop rust-analyzer as a persistent daemon, providing low-latency refactorings with a VSCode front-end. It adds a repairer that automatically adjusts lifetimes and signatures when extraction exposes borrow-checker issues, and an optional verification pipeline connecting to CHARON and AENEAS to generate Coq equivalence proofs for a supported Rust subset. The architecture is evaluated on three benchmark suites. On the original REM artefact, REM2.0 achieves 100% compatibility while reducing latency from ~1000ms to single-digit milliseconds in the daemon. On 40 feature-focused extractions from 20 highly starred GitHub repositories, REM2.0 handles most examples involving async/await, const fn, non-local control flow, generics, and higher-ranked trait bounds. On twenty verification benchmarks, the CHARON/AENEAS pipeline constructs end-to-end equivalence proofs for cases within its current subset. Overall, results show that a rust-analyzer-based design can provide fast, feature-rich extract-function refactoring for real Rust programs, while opt-in verification delivers machine-checked behaviour preservation.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19207v1</guid></item><item><title>[cs updates on arXiv.org] How Do Transformers Learn to Associate Tokens: Gradient Leading Terms Bring Mechanistic Interpretability</title><link>https://arxiv.org/abs/2601.19208</link><description>arXiv:2601.19208v1 Announce Type: new 
Abstract: Semantic associations such as the link between "bird" and "flew" are foundational for language modeling as they enable models to go beyond memorization and instead generalize and generate coherent text. Understanding how these associations are learned and represented in language models is essential for connecting deep learning with linguistic theory and developing a mechanistic foundation for large language models. In this work, we analyze how these associations emerge from natural language data in attention-based language models through the lens of training dynamics. By leveraging a leading-term approximation of the gradients, we develop closed-form expressions for the weights at early stages of training that explain how semantic associations first take shape. Through our analysis, we reveal that each set of weights of the transformer has closed-form expressions as simple compositions of three basis functions (bigram, token-interchangeability, and context mappings), reflecting the statistics of the text corpus and uncovering how each component of the transformer captures semantic associations based on these compositions. Experiments on real-world LLMs demonstrate that our theoretical weight characterizations closely match the learned weights, and qualitative analyses further show how our theorem shines light on interpreting the learned associations in transformers.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19208v1</guid></item><item><title>[cs updates on arXiv.org] Contrastive Spectral Rectification: Test-Time Defense towards Zero-shot Adversarial Robustness of CLIP</title><link>https://arxiv.org/abs/2601.19210</link><description>arXiv:2601.19210v1 Announce Type: new 
Abstract: Vision-language models (VLMs) such as CLIP have demonstrated remarkable zero-shot generalization, yet remain highly vulnerable to adversarial examples (AEs). While test-time defenses are promising, existing methods fail to provide sufficient robustness against strong attacks and are often hampered by high inference latency and task-specific applicability. To address these limitations, we start by investigating the intrinsic properties of AEs, which reveals that AEs exhibit severe feature inconsistency under progressive frequency attenuation. We further attribute this to the model's inherent spectral bias. Leveraging this insight, we propose an efficient test-time defense named Contrastive Spectral Rectification (CSR). CSR optimizes a rectification perturbation to realign the input with the natural manifold under a spectral-guided contrastive objective, which is applied input-adaptively. Extensive experiments across 16 classification benchmarks demonstrate that CSR outperforms the SOTA by an average of 18.1% against strong AutoAttack with modest inference overhead. Furthermore, CSR exhibits broad applicability across diverse visual tasks. Code is available at https://github.com/Summu77/CSR.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19210v1</guid></item><item><title>[cs updates on arXiv.org] M$^{\text{2}}$XFP: A Metadata-Augmented Microscaling Data Format for Efficient Low-bit Quantization</title><link>https://arxiv.org/abs/2601.19213</link><description>arXiv:2601.19213v1 Announce Type: new 
Abstract: Existing low-bit Microscaling (MX) formats, such as MXFP4, often suffer from substantial accuracy degradation due to the use of a shared scaling factor with the Power-of-Two format. In this work, we explore strategies that introduce minimal metadata to recover accuracy lost during quantization while maintaining high bit efficiency across a wide range of large language models. We propose a complete algorithm-hardware co-design based on flexible metadata, featuring an online quantization with simple encoding. To support the proposed method efficiently, we implement a lightweight hardware unit and integrate it into the accelerator. Evaluation results demonstrate that our method substantially narrows the accuracy gap, achieving on average a 70.63% reduction in accuracy loss compared to MXFP4 and a 37.30% reduction relative to the latest NVFP4 on LLM benchmarks. Furthermore, our design delivers up to 1.91$\times$ speedup and 1.75$\times$ energy savings over state-of-the-art accelerators. Our code is available at https://github.com/SJTU-ReArch-Group/M2XFP_ASPLOS26.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19213v1</guid></item><item><title>[cs updates on arXiv.org] A Hybrid Supervised-LLM Pipeline for Actionable Suggestion Mining in Unstructured Customer Reviews</title><link>https://arxiv.org/abs/2601.19214</link><description>arXiv:2601.19214v1 Announce Type: new 
Abstract: Extracting actionable suggestions from customer reviews is essential for operational decision-making, yet these directives are often embedded within mixed-intent, unstructured text. Existing approaches either classify suggestion-bearing sentences or generate high-level summaries, but rarely isolate the precise improvement instructions businesses need. We evaluate a hybrid pipeline combining a high-recall RoBERTa classifier trained with a precision-recall surrogate to reduce unrecoverable false negatives with a controlled, instruction-tuned LLM for suggestion extraction, categorization, clustering, and summarization. Across real-world hospitality and food datasets, the hybrid system outperforms prompt-only, rule-based, and classifier-only baselines in extraction accuracy and cluster coherence. Human evaluations further confirm that the resulting suggestions and summaries are clear, faithful, and interpretable. Overall, our results show that hybrid reasoning architectures achieve meaningful improvements fine-grained actionable suggestion mining while highlighting challenges in domain adaptation and efficient local deployment.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19214v1</guid></item><item><title>[cs updates on arXiv.org] Bridging Visual and Wireless Sensing: A Unified Radiation Field for 3D Radio Map Construction</title><link>https://arxiv.org/abs/2601.19216</link><description>arXiv:2601.19216v1 Announce Type: new 
Abstract: The emerging applications of next-generation wireless networks (e.g., immersive 3D communication, low-altitude networks, and integrated sensing and communication) necessitate high-fidelity environmental intelligence. 3D radio maps have emerged as a critical tool for this purpose, enabling spectrum-aware planning and environment-aware sensing by bridging the gap between physical environments and electromagnetic signal propagation. However, constructing accurate 3D radio maps requires fine-grained 3D geometric information and a profound understanding of electromagnetic wave propagation. Existing approaches typically treat optical and wireless knowledge as distinct modalities, failing to exploit the fundamental physical principles governing both light and electromagnetic propagation. To bridge this gap, we propose URF-GS, a unified radio-optical radiation field representation framework for accurate and generalizable 3D radio map construction based on 3D Gaussian splatting (3D-GS) and inverse rendering. By fusing visual and wireless sensing observations, URF-GS recovers scene geometry and material properties while accurately predicting radio signal behavior at arbitrary transmitter-receiver (Tx-Rx) configurations. Experimental results demonstrate that URF-GS achieves up to a 24.7% improvement in spatial spectrum prediction accuracy and a 10x increase in sample efficiency for 3D radio map construction compared with neural radiance field (NeRF)-based methods. This work establishes a foundation for next-generation wireless networks by integrating perception, interaction, and communication through holistic radiation field reconstruction.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19216v1</guid></item><item><title>[cs updates on arXiv.org] SE Journals in 2036: Looking Back at the Future We Need to Have</title><link>https://arxiv.org/abs/2601.19217</link><description>arXiv:2601.19217v1 Announce Type: new 
Abstract: In 2025, SE publishing faces an existential crisis of scalability. As our communities swell globally and integrate fast-moving methodologies like LLMs, traditional peer-review practices are collapsing under the strain. The "bureaucratic anomaly" of monolithic review has become mathematically unsustainable, creating a stochastic "lottery" that punishes novelty and exhausts researchers.
  This paper, written from the perspective of 2036, documents potential solutions. Here, the editors of ASE, EMSE, IST, JSS, TOSEM and TSE dream a collective dream of a brighter future. In summary first we stopped fighting (The Journal Alliance). Then we fixed the process (The Lottery / Unbundling / Fixing the Benchmark Graveyard). And then we fixed the culture (Cathedrals/Bazaars).</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19217v1</guid></item><item><title>[cs updates on arXiv.org] Accelerated Multiple Wasserstein Gradient Flows for Multi-objective Distributional Optimization</title><link>https://arxiv.org/abs/2601.19220</link><description>arXiv:2601.19220v1 Announce Type: new 
Abstract: We study multi-objective optimization over probability distributions in Wasserstein space. Recently, Nguyen et al. (2025) introduced Multiple Wasserstein Gradient Descent (MWGraD) algorithm, which exploits the geometric structure of Wasserstein space to jointly optimize multiple objectives. Building on this approach, we propose an accelerated variant, A-MWGraD, inspired by Nesterov's acceleration. We analyze the continuous-time dynamics and establish convergence to weakly Pareto optimal points in probability space. Our theoretical results show that A-MWGraD achieves a convergence rate of O(1/t^2) for geodesically convex objectives and O(e^{-\sqrt{\beta}t}) for $\beta$-strongly geodesically convex objectives, improving upon the O(1/t) rate of MWGraD in the geodesically convex setting. We further introduce a practical kernel-based discretization for A-MWGraD and demonstrate through numerical experiments that it consistently outperforms MWGraD in convergence speed and sampling efficiency on multi-target sampling tasks.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19220v1</guid></item><item><title>[cs updates on arXiv.org] DREAMSTATE: Diffusing States and Parameters for Recurrent Large Language Models</title><link>https://arxiv.org/abs/2601.19221</link><description>arXiv:2601.19221v1 Announce Type: new 
Abstract: Modern Recurrent Neural Networks (RNNs), such as RWKV, are distinguished by their powerful short-range modeling capabilities and efficient fixed-size states, which constitute a core advantage over standard Transformers. However, there is a significant lack of research into their internal state as an editable knowledge representation. To fill this gap, we first explore the representational properties of the RWKV state by proposing the DREAMSTATE framework. This framework utilizes a conditional Diffusion Transformer (DiT) to directly model the probability manifold of the state, enabling its generation and editing. The structural nature of this representation is validated through t-SNE visualizations and controlled generation experiments. After successfully uncovering and modeling the state's representational potential, we further propose a novel hybrid architecture that combines the local advantages of RNNs with global context adaptability. This architecture features a parallel DiT that processes a variable-length global context to dynamically generate and adjust the core recurrent module's WKV parameters, transforming the fixed recurrence mechanism into a context-aware dynamic function. Experiments demonstrate that this hybrid model can be trained stably via a multi-objective loss, validating its design feasibility. Our work not only opens a new research direction for RNN state representation but also provides a concrete architectural reference for future model design. The code is publicly available at: https://huggingface.co/2dgx41s/DreamState.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19221v1</guid></item><item><title>[cs updates on arXiv.org] UniPCB: A Unified Vision-Language Benchmark for Open-Ended PCB Quality Inspection</title><link>https://arxiv.org/abs/2601.19222</link><description>arXiv:2601.19222v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) show promise for general industrial quality inspection, but fall short in complex scenarios, such as Printed Circuit Board (PCB) inspection. PCB inspection poses unique challenges due to densely packed components, complex wiring structures, and subtle defect patterns that require specialized domain expertise. However, a high-quality, unified vision-language benchmark for quantitatively evaluating MLLMs across PCB inspection tasks remains absent, stemming not only from limited data availability but also from fragmented datasets and inconsistent standardization. To fill this gap, we propose UniPCB, the first unified vision-language benchmark for open-ended PCB quality inspection. UniPCB is built via a systematic pipeline that curates and standardizes data from disparate sources across three annotated scenarios. Furthermore, we introduce PCB-GPT, an MLLM trained on a new instruction dataset generated by this pipeline, utilizing a novel progressive curriculum that mimics the learning process of human experts. Evaluations on the UniPCB benchmark show that while existing MLLMs falter on domain-specific tasks, PCB-GPT establishes a new baseline. Notably, it more than doubles the performance on fine-grained defect localization compared to the strongest competitors, with significant advantages in localization and analysis. We will release the instruction data, benchmark, and model to facilitate future research.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19222v1</guid></item><item><title>[cs updates on arXiv.org] Movable-Antenna Empowered Backscatter ISAC: Toward Geometry-Adaptive, Low-Power Networks</title><link>https://arxiv.org/abs/2601.19224</link><description>arXiv:2601.19224v1 Announce Type: new 
Abstract: Backscatter-based integrated sensing and communication (B-ISAC) elevates passive tags into information-bearing scatterers, offering an ultra-low-power path toward dual-function wireless systems. However, this promise is fundamentally undermined by a cascaded backscattering link that suffers from severe double fading and is exquisitely sensitive to geometric misalignment. This article tackles this geometric bottleneck by integrating movable antenna systems (MAS) at the transceiver side. MAS provides real-time, controllable spatial degrees of freedom through sub-wavelength antenna repositioning, enabling active reconfiguration of the cascaded channel without modifying passive tags or consuming additional spectrum. We position this solution within a unified ISAC-backscatter communication-B-ISAC evolution, describe the resulting MAS-assisted B-ISAC architecture and operating principles, and demonstrate its system-level gains through comparative analysis and numerical results. Finally, we showcase the potential of this geometry-adaptive paradigm across key IoT application scenarios, pointing toward future motion-aware wireless networks.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19224v1</guid></item><item><title>[cs updates on arXiv.org] RPO-RAG: Aligning Small LLMs with Relation-aware Preference Optimization for Knowledge Graph Question Answering</title><link>https://arxiv.org/abs/2601.19225</link><description>arXiv:2601.19225v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have recently demonstrated remarkable reasoning abilities, yet hallucinate on knowledge-intensive tasks. Retrieval-augmented generation (RAG) mitigates this issue by grounding answers in external sources, e.g., knowledge graphs (KGs). However, existing KG-based RAG approaches rely on semantics-unaware path sampling and are weakly aligned with KG reasoning objectives, which limits further accuracy gains. They also feed retrieved paths directly into the reasoner without organizing them into answer-centered reasoning paths, hindering small LLMs' ability to leverage the retrieved knowledge. Furthermore, prior works predominantly rely on large LLMs (e.g., ChatGPT/GPT-4) or assume backbones above 7B parameters, leaving sub-7B models underexplored. We address this gap with RPO-RAG, the first KG-based RAG framework specifically designed for small LLMs, to the best of our knowledge. RPO-RAG introduces three key innovations: (1) a query-path semantic sampling strategy that provides informative supervisory signals; (2) a relation-aware preference optimization that aligns training with intermediate KG reasoning signals (e.g., relation); and (3) an answer-centered prompt design that organizes entities and reasoning paths in an interpretable format. Extensive experiments on two benchmark Knowledge Graph Question Answering (KGQA) datasets, WebQSP and CWQ, demonstrate that RPO-RAG effectively bridges the performance gap between small and large language models. On WebQSP, it improves F1 by up to 8.8%, reflecting enhanced answer precision, while on CWQ it achieves new state-of-the-art results among models under 8B parameters in both Hit and F1. Overall, RPO-RAG substantially improves the reasoning capability of small LLMs, even under 3B parameters-highlighting their potential for resource-efficient and practical on-device KGQA applications.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19225v1</guid></item><item><title>[cs updates on arXiv.org] Towards Pixel-Level VLM Perception via Simple Points Prediction</title><link>https://arxiv.org/abs/2601.19228</link><description>arXiv:2601.19228v1 Announce Type: new 
Abstract: We present SimpleSeg, a strikingly simple yet highly effective approach to endow Multimodal Large Language Models (MLLMs) with native pixel-level perception. Our method reframes segmentation as a simple sequence generation problem: the model directly predicts sequences of points (textual coordinates) delineating object boundaries, entirely within its language space. To achieve high fidelity, we introduce a two-stage SF$\to$RL training pipeline, where Reinforcement Learning with an IoU-based reward refines the point sequences to accurately match ground-truth contours. We find that the standard MLLM architecture possesses a strong, inherent capacity for low-level perception that can be unlocked without any specialized architecture. On segmentation benchmarks, SimpleSeg achieves performance that is comparable to, and often surpasses, methods relying on complex, task-specific designs. This work lays out that precise spatial understanding can emerge from simple point prediction, challenging the prevailing need for auxiliary components and paving the way for more unified and capable VLMs. Homepage: https://simpleseg.github.io/</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19228v1</guid></item><item><title>[cs updates on arXiv.org] LLMs Can Unlearn Refusal with Only 1,000 Benign Samples</title><link>https://arxiv.org/abs/2601.19231</link><description>arXiv:2601.19231v1 Announce Type: new 
Abstract: This study reveals a previously unexplored vulnerability in the safety alignment of Large Language Models (LLMs). Existing aligned LLMs predominantly respond to unsafe queries with refusals, which often begin with a fixed set of prefixes (I'm sorry). We demonstrate that this rigid refusal pattern is a vulnerability and introduce a novel \textbf{refusal unlearning} technique that exploits it. Specifically, we fine-tune LLMs using merely 1,000 benign samples, where each response is prepended with a refusal prefix. The underlying intuition is to disrupt the refusal completion pathway, thereby driving the model to forget how to refuse while following harmful instructions. This intuition is further supported by theoretical proofs. We apply this approach to a total of 16 LLMs, including various open-source models from Llama, Qwen, and Gemma families, as well as closed-source models such as Gemini and GPT. Experimental results show that the safety scores of previously aligned LLMs degrade both consistently and substantially. Importantly, we verify that the observed gain cannot be attributed to plain fine-tuning or random prefix effects. Our findings suggest that current safety alignment may rely heavily on token sequence memorization rather than reasoning, motivating future work beyond simple refusal mechanisms. Code has been released: https://github.com/guoyang9/refusal-unlearning.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19231v1</guid></item><item><title>[cs updates on arXiv.org] Structure-based RNA Design by Step-wise Optimization of Latent Diffusion Model</title><link>https://arxiv.org/abs/2601.19232</link><description>arXiv:2601.19232v1 Announce Type: new 
Abstract: RNA inverse folding, designing sequences to form specific 3D structures, is critical for therapeutics, gene regulation, and synthetic biology. Current methods, focused on sequence recovery, struggle to address structural objectives like secondary structure consistency (SS), minimum free energy (MFE), and local distance difference test (LDDT), leading to suboptimal structural accuracy. To tackle this, we propose a reinforcement learning (RL) framework integrated with a latent diffusion model (LDM). Drawing inspiration from the success of diffusion models in RNA inverse folding, which adeptly model complex sequence-structure interactions, we develop an LDM incorporating pre-trained RNA-FM embeddings from a large-scale RNA model. These embeddings capture co-evolutionary patterns, markedly improving sequence recovery accuracy. However, existing approaches, including diffusion-based methods, cannot effectively handle non-differentiable structural objectives. By contrast, RL excels in this task by using policy-driven reward optimization to navigate complex, non-gradient-based objectives, offering a significant advantage over traditional methods. In summary, we propose the Step-wise Optimization of Latent Diffusion Model (SOLD), a novel RL framework that optimizes single-step noise without sampling the full diffusion trajectory, achieving efficient refinement of multiple structural objectives. Experimental results demonstrate SOLD surpasses its LDM baseline and state-of-the-art methods across all metrics, establishing a robust framework for RNA inverse folding with profound implications for biotechnological and therapeutic applications.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19232v1</guid></item><item><title>[cs updates on arXiv.org] UniMGS: Unifying Mesh and 3D Gaussian Splatting with Single-Pass Rasterization and Proxy-Based Deformation</title><link>https://arxiv.org/abs/2601.19233</link><description>arXiv:2601.19233v1 Announce Type: new 
Abstract: Joint rendering and deformation of mesh and 3D Gaussian Splatting (3DGS) have significant value as both representa tions offer complementary advantages for graphics applica tions. However, due to differences in representation and ren dering pipelines, existing studies render meshes and 3DGS separately, making it difficult to accurately handle occlusions and transparency. Moreover, the deformed 3DGS still suffers from visual artifacts due to the sensitivity to the topology quality of the proxy mesh. These issues pose serious obsta cles to the joint use of 3DGS and meshes, making it diffi cult to adapt 3DGS to conventional mesh-oriented graphics pipelines. We propose UniMGS, the first unified framework for rasterizing mesh and 3DGS in a single-pass anti-aliased manner, with a novel binding strategy for 3DGS deformation based on proxy mesh. Our key insight is to blend the col ors of both triangle and Gaussian fragments by anti-aliased {\alpha}-blending in a single pass, achieving visually coherent re sults with precise handling of occlusion and transparency. To improve the visual appearance of the deformed 3DGS, our Gaussian-centric binding strategy employs a proxy mesh and spatially associates Gaussians with the mesh faces, signifi cantly reducing rendering artifacts. With these two compo nents, UniMGS enables the visualization and manipulation of 3D objects represented by mesh or 3DGS within a unified framework, opening up new possibilities in embodied AI, vir tual reality, and gaming. We will release our source code to facilitate future research.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19233v1</guid></item><item><title>[cs updates on arXiv.org] iFAN Ecosystem: A Unified AI, Digital Twin, Cyber-Physical Security, and Robotics Environment for Advanced Nuclear Simulation and Operations</title><link>https://arxiv.org/abs/2601.19234</link><description>arXiv:2601.19234v1 Announce Type: new 
Abstract: As nuclear facilities experience digital transformation and advanced reactor development, AI integration, cyber-physical security, and other emerging technologies such as autonomous robot operations are increasingly developed. However, evaluation and deployment is challenged by the lack of dedicated virtual testbeds. The Immersive Framework for Advanced Nuclear (iFAN) ecosystem is developed, a comprehensive digital twin framework with a realistic 3D environment with physics-based simulations. The iFAN ecosystem serves as a high-fidelity virtual testbed for plant operation, cybersecurity, physical security, and robotic operation, as it provides real-time data exchange for pre-deployment verification. Core features include virtual reality, reinforcement learning, radiation simulation, and cyber-physical security. In addition, the paper investigates various applications through potential operational scenarios. The iFAN ecosystem provides a versatile and secure architecture for validating the next generation of autonomous and cyber-resilient nuclear operations.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19234v1</guid></item><item><title>[cs updates on arXiv.org] VC-Bench: Pioneering the Video Connecting Benchmark with a Dataset and Evaluation Metrics</title><link>https://arxiv.org/abs/2601.19236</link><description>arXiv:2601.19236v1 Announce Type: new 
Abstract: While current video generation focuses on text or image conditions, practical applications like video editing and vlogging often need to seamlessly connect separate clips. In our work, we introduce Video Connecting, an innovative task that aims to generate smooth intermediate video content between given start and end clips. However, the absence of standardized evaluation benchmarks has hindered the development of this task. To bridge this gap, we proposed VC-Bench, a novel benchmark specifically designed for video connecting. It includes 1,579 high-quality videos collected from public platforms, covering 15 main categories and 72 subcategories to ensure diversity and structure. VC-Bench focuses on three core aspects: Video Quality Score VQS, Start-End Consistency Score SECS, and Transition Smoothness Score TSS. Together, they form a comprehensive framework that moves beyond conventional quality-only metrics. We evaluated multiple state-of-the-art video generation models on VC-Bench. Experimental results reveal significant limitations in maintaining start-end consistency and transition smoothness, leading to lower overall coherence and fluidity. We expect that VC-Bench will serve as a pioneering benchmark to inspire and guide future research in video connecting. The evaluation metrics and dataset are publicly available at: https://anonymous.4open.science/r/VC-Bench-1B67/.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19236v1</guid></item><item><title>[cs updates on arXiv.org] Automatic Synthesis of Visualization Design Knowledge Bases</title><link>https://arxiv.org/abs/2601.19237</link><description>arXiv:2601.19237v1 Announce Type: new 
Abstract: Formal representations of the visualization design space, such as knowledge bases and graphs, consolidate design practices into a shared resource and enable automated reasoning and interpretable design recommendations. However, prior approaches typically depend on fixed, manually authored rules, making it difficult to build novel representations or extend them for different visualization domains. Instead, we propose data-driven methods that automatically synthesize visualization design knowledge bases. Specifically, our methods (1) extract candidate design features from a visualization corpus, (2) select features forward and backward, and (3) render the final knowledge base. In our benchmark evaluation compared to Draco 2, our synthesized knowledge base offers general and interpretable design features and improves the accuracy of predicting effective designs by 1-15% in varied training and test sets. When we apply our approach to genomics visualization, the synthesized knowledge base includes sensible features with accuracy up to 97%, demonstrating the applicability of our approach to other visualization domains.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19237v1</guid></item><item><title>[cs updates on arXiv.org] A Hybrid BLE-Wi-Fi Communication Architecture for Adaptive Imaging in Wireless Capsule Endoscopy</title><link>https://arxiv.org/abs/2601.19238</link><description>arXiv:2601.19238v1 Announce Type: new 
Abstract: Wireless capsule endoscopy (WCE) is fundamentally constrained by limited wireless bandwidth, resulting in low imaging resolution and frame rate, which can cause motion blur and missed lesions. Although adaptive frame-rate schemes have been explored to accommodate transient gastrointestinal (GI) motility, these approaches typically require sacrificing image resolution. The use of higher-frequency communication bands is further limited by increased tissue attenuation. To address these challenges, we propose a hybrid Bluetooth Low Energy (BLE) and WiFi communication architecture that combines the low-power operation of BLE with the high data throughput of WiFi. We systematically evaluate the performance of BLE and WiFi under tissue-mimicking conditions by measuring throughput, received signal strength indicator (RSSI), and power consumption. The results demonstrate that amplified BLE with an adaptive transmission power control strategy provides a stable frame rate at low power consumption, while 2.4 GHz WiFi operating in station mode is the most suitable high-throughput communication configuration for WCE. Compared with WiFi, BLE reduces power consumption by approximately ten times, whereas WiFi achieves up to ten times higher throughput. To reconcile these complementary trade-offs, we further introduce a hybrid system with a frame-boundary-synchronized switching mechanism to ensure lossless data transmission during BLE and WiFi transitions. Experimental results show that the switching latency from BLE to WiFi is approximately 92.66 ms, which is longer than the WiFi-to-BLE switching latency of 15.49 ms when transmitting 10 kB image payloads. Overall, the proposed hybrid BLE and WiFi system enables robust, lossless, and energy-efficient mode switching, supports adaptive imaging, and advances the development of next-generation autonomous WCE platforms.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19238v1</guid></item><item><title>[cs updates on arXiv.org] LLM-based Vulnerability Detection at Project Scale: An Empirical Study</title><link>https://arxiv.org/abs/2601.19239</link><description>arXiv:2601.19239v1 Announce Type: new 
Abstract: In this paper, we present the first comprehensive empirical study of specialized LLM-based detectors and compare them with traditional static analyzers at the project scale. Specifically, our study evaluates five latest and representative LLM-based methods and two traditional tools using: 1) an in-house benchmark of 222 known real-world vulnerabilities (C/C++ and Java) to assess detection capability, and 2) 24 active open-source projects, where we manually inspected 385 warnings to assess their practical usability and underlying root causes of failures. Our evaluation yields three key findings: First, while LLM-based detectors exhibit low recall on the in-house benchmark, they still uncover more unique vulnerabilities than traditional tools. Second, in open-source projects, both LLM-based and traditional tools generate substantial warnings but suffer from very high false discovery rates, hindering practical use. Our manual analysis further reveals shallow interprocedural reasoning and misidentified source/sink pairs as primary failure causes, with LLM-based tools exhibiting additional unique failures. Finally, LLM-based methods incurs substantial computational costs-hundreds of thousands to hundreds of millions of tokens and multi-hour to multi-day runtimes. Overall, our findings underscore critical limitations in the robustness, reliability, and scalability of current LLM-based detectors. We ultimately summarize a set of implications for future research toward more effective and practical project-scale vulnerability detection.</description><author>cs updates on arXiv.org</author><pubDate>Wed, 28 Jan 2026 05:00:00 GMT</pubDate><guid isPermaLink="true">oai:arXiv.org:2601.19239v1</guid></item></channel></rss>